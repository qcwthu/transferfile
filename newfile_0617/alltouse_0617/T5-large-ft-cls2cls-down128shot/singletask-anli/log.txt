05/22/2022 21:54:15 - INFO - __main__ - Namespace(task_dir='data_128/anli/', task_name='anli', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-anli', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/22/2022 21:54:15 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-anli
05/22/2022 21:54:15 - INFO - __main__ - Namespace(task_dir='data_128/anli/', task_name='anli', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-anli', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/22/2022 21:54:15 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-anli
05/22/2022 21:54:17 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/22/2022 21:54:17 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/22/2022 21:54:17 - INFO - __main__ - args.device: cuda:0
05/22/2022 21:54:17 - INFO - __main__ - args.device: cuda:1
05/22/2022 21:54:17 - INFO - __main__ - Using 2 gpus
05/22/2022 21:54:17 - INFO - __main__ - Using 2 gpus
05/22/2022 21:54:17 - INFO - __main__ - Fine-tuning the following samples: ['anli_128_100', 'anli_128_13', 'anli_128_21', 'anli_128_42', 'anli_128_87']
05/22/2022 21:54:17 - INFO - __main__ - Fine-tuning the following samples: ['anli_128_100', 'anli_128_13', 'anli_128_21', 'anli_128_42', 'anli_128_87']
05/22/2022 21:54:22 - INFO - __main__ - Running ... prefix=anli_128_100, lr=0.0005, bsz=8 ...
05/22/2022 21:54:23 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 21:54:23 - INFO - __main__ - Printing 3 examples
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:54:23 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 21:54:23 - INFO - __main__ - Printing 3 examples
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:54:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:54:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:54:23 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 21:54:23 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 21:54:23 - INFO - __main__ - Printing 3 examples
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:54:23 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 21:54:23 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 21:54:23 - INFO - __main__ - Printing 3 examples
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 21:54:23 - INFO - __main__ - ['neutral']
05/22/2022 21:54:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:54:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:54:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:54:24 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 21:54:24 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 21:54:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 21:54:37 - INFO - __main__ - Starting training!
05/22/2022 21:54:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 21:54:38 - INFO - __main__ - Starting training!
05/22/2022 21:54:43 - INFO - __main__ - Step 10 Global step 10 Train loss 25.105488 on epoch=0
05/22/2022 21:54:47 - INFO - __main__ - Step 20 Global step 20 Train loss 16.101156 on epoch=0
05/22/2022 21:54:52 - INFO - __main__ - Step 30 Global step 30 Train loss 11.985071 on epoch=1
05/22/2022 21:54:57 - INFO - __main__ - Step 40 Global step 40 Train loss 10.533770 on epoch=1
05/22/2022 21:55:03 - INFO - __main__ - Step 50 Global step 50 Train loss 8.120778 on epoch=2
05/22/2022 21:55:13 - INFO - __main__ - Global step 50 Train loss 14.369253 Classification-F1 0.012318029115341545 on epoch=2
05/22/2022 21:55:20 - INFO - __main__ - Step 60 Global step 60 Train loss 8.184668 on epoch=2
05/22/2022 21:55:25 - INFO - __main__ - Step 70 Global step 70 Train loss 6.337529 on epoch=2
05/22/2022 21:55:30 - INFO - __main__ - Step 80 Global step 80 Train loss 4.494326 on epoch=3
05/22/2022 21:55:35 - INFO - __main__ - Step 90 Global step 90 Train loss 3.445165 on epoch=3
05/22/2022 21:55:40 - INFO - __main__ - Step 100 Global step 100 Train loss 2.946975 on epoch=4
05/22/2022 21:55:48 - INFO - __main__ - Global step 100 Train loss 5.081732 Classification-F1 0.16666666666666666 on epoch=4
05/22/2022 21:55:55 - INFO - __main__ - Step 110 Global step 110 Train loss 2.674191 on epoch=4
05/22/2022 21:56:00 - INFO - __main__ - Step 120 Global step 120 Train loss 2.274222 on epoch=4
05/22/2022 21:56:05 - INFO - __main__ - Step 130 Global step 130 Train loss 2.673627 on epoch=5
05/22/2022 21:56:10 - INFO - __main__ - Step 140 Global step 140 Train loss 1.908667 on epoch=5
05/22/2022 21:56:15 - INFO - __main__ - Step 150 Global step 150 Train loss 1.834883 on epoch=6
05/22/2022 21:56:22 - INFO - __main__ - Global step 150 Train loss 2.273118 Classification-F1 0.16666666666666666 on epoch=6
05/22/2022 21:56:27 - INFO - __main__ - Step 160 Global step 160 Train loss 1.757065 on epoch=6
05/22/2022 21:56:32 - INFO - __main__ - Step 170 Global step 170 Train loss 1.771188 on epoch=7
05/22/2022 21:56:37 - INFO - __main__ - Step 180 Global step 180 Train loss 1.519675 on epoch=7
05/22/2022 21:56:42 - INFO - __main__ - Step 190 Global step 190 Train loss 1.546844 on epoch=7
05/22/2022 21:56:47 - INFO - __main__ - Step 200 Global step 200 Train loss 1.381476 on epoch=8
05/22/2022 21:56:53 - INFO - __main__ - Global step 200 Train loss 1.595250 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 21:56:58 - INFO - __main__ - Step 210 Global step 210 Train loss 1.267734 on epoch=8
05/22/2022 21:57:03 - INFO - __main__ - Step 220 Global step 220 Train loss 1.056508 on epoch=9
05/22/2022 21:57:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.861930 on epoch=9
05/22/2022 21:57:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.964740 on epoch=9
05/22/2022 21:57:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.860848 on epoch=10
05/22/2022 21:57:25 - INFO - __main__ - Global step 250 Train loss 1.002352 Classification-F1 0.16666666666666666 on epoch=10
05/22/2022 21:57:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.797676 on epoch=10
05/22/2022 21:57:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.805517 on epoch=11
05/22/2022 21:57:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.850204 on epoch=11
05/22/2022 21:57:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.499941 on epoch=12
05/22/2022 21:57:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.676644 on epoch=12
05/22/2022 21:57:56 - INFO - __main__ - Global step 300 Train loss 0.725997 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 21:58:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.557737 on epoch=12
05/22/2022 21:58:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.649639 on epoch=13
05/22/2022 21:58:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.631739 on epoch=13
05/22/2022 21:58:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.540929 on epoch=14
05/22/2022 21:58:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.731270 on epoch=14
05/22/2022 21:58:27 - INFO - __main__ - Global step 350 Train loss 0.622263 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 21:58:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.599043 on epoch=14
05/22/2022 21:58:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.761791 on epoch=15
05/22/2022 21:58:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.613224 on epoch=15
05/22/2022 21:58:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.499948 on epoch=16
05/22/2022 21:58:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.604116 on epoch=16
05/22/2022 21:58:59 - INFO - __main__ - Global step 400 Train loss 0.615624 Classification-F1 0.32836372792998386 on epoch=16
05/22/2022 21:59:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.647318 on epoch=17
05/22/2022 21:59:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.653473 on epoch=17
05/22/2022 21:59:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.534706 on epoch=17
05/22/2022 21:59:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.622306 on epoch=18
05/22/2022 21:59:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.487254 on epoch=18
05/22/2022 21:59:33 - INFO - __main__ - Global step 450 Train loss 0.589011 Classification-F1 0.16666666666666666 on epoch=18
05/22/2022 21:59:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.553150 on epoch=19
05/22/2022 21:59:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.499857 on epoch=19
05/22/2022 21:59:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.458048 on epoch=19
05/22/2022 21:59:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.430593 on epoch=20
05/22/2022 21:59:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.553890 on epoch=20
05/22/2022 22:00:04 - INFO - __main__ - Global step 500 Train loss 0.499108 Classification-F1 0.16666666666666666 on epoch=20
05/22/2022 22:00:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.479292 on epoch=21
05/22/2022 22:00:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.442926 on epoch=21
05/22/2022 22:00:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.464373 on epoch=22
05/22/2022 22:00:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.511728 on epoch=22
05/22/2022 22:00:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.519071 on epoch=22
05/22/2022 22:00:36 - INFO - __main__ - Global step 550 Train loss 0.483478 Classification-F1 0.16666666666666666 on epoch=22
05/22/2022 22:00:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.489306 on epoch=23
05/22/2022 22:00:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.406343 on epoch=23
05/22/2022 22:00:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.446442 on epoch=24
05/22/2022 22:00:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.442641 on epoch=24
05/22/2022 22:01:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.473412 on epoch=24
05/22/2022 22:01:08 - INFO - __main__ - Global step 600 Train loss 0.451629 Classification-F1 0.27805443998215085 on epoch=24
05/22/2022 22:01:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.679475 on epoch=25
05/22/2022 22:01:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.461177 on epoch=25
05/22/2022 22:01:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.494225 on epoch=26
05/22/2022 22:01:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.551024 on epoch=26
05/22/2022 22:01:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.455767 on epoch=27
05/22/2022 22:01:40 - INFO - __main__ - Global step 650 Train loss 0.528333 Classification-F1 0.23545899961090525 on epoch=27
05/22/2022 22:01:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.489943 on epoch=27
05/22/2022 22:01:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.408663 on epoch=27
05/22/2022 22:01:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.439991 on epoch=28
05/22/2022 22:02:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.413485 on epoch=28
05/22/2022 22:02:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.503129 on epoch=29
05/22/2022 22:02:12 - INFO - __main__ - Global step 700 Train loss 0.451042 Classification-F1 0.27070411070411066 on epoch=29
05/22/2022 22:02:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.456806 on epoch=29
05/22/2022 22:02:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.449899 on epoch=29
05/22/2022 22:02:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.482897 on epoch=30
05/22/2022 22:02:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.413551 on epoch=30
05/22/2022 22:02:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.500151 on epoch=31
05/22/2022 22:02:45 - INFO - __main__ - Global step 750 Train loss 0.460661 Classification-F1 0.16666666666666666 on epoch=31
05/22/2022 22:02:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.424257 on epoch=31
05/22/2022 22:02:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.415632 on epoch=32
05/22/2022 22:03:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.448944 on epoch=32
05/22/2022 22:03:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.388261 on epoch=32
05/22/2022 22:03:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.437040 on epoch=33
05/22/2022 22:03:17 - INFO - __main__ - Global step 800 Train loss 0.422827 Classification-F1 0.16633922724296005 on epoch=33
05/22/2022 22:03:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.423798 on epoch=33
05/22/2022 22:03:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.359933 on epoch=34
05/22/2022 22:03:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.431364 on epoch=34
05/22/2022 22:03:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.449033 on epoch=34
05/22/2022 22:03:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.450659 on epoch=35
05/22/2022 22:03:49 - INFO - __main__ - Global step 850 Train loss 0.422957 Classification-F1 0.25718062560167826 on epoch=35
05/22/2022 22:03:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.425359 on epoch=35
05/22/2022 22:03:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.416110 on epoch=36
05/22/2022 22:04:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.434644 on epoch=36
05/22/2022 22:04:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.413559 on epoch=37
05/22/2022 22:04:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.392805 on epoch=37
05/22/2022 22:04:20 - INFO - __main__ - Global step 900 Train loss 0.416496 Classification-F1 0.2603133660964068 on epoch=37
05/22/2022 22:04:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.422322 on epoch=37
05/22/2022 22:04:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.439610 on epoch=38
05/22/2022 22:04:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.392657 on epoch=38
05/22/2022 22:04:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.390969 on epoch=39
05/22/2022 22:04:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.385003 on epoch=39
05/22/2022 22:04:52 - INFO - __main__ - Global step 950 Train loss 0.406112 Classification-F1 0.27662618083670715 on epoch=39
05/22/2022 22:04:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.403301 on epoch=39
05/22/2022 22:05:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.411008 on epoch=40
05/22/2022 22:05:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.380225 on epoch=40
05/22/2022 22:05:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.380206 on epoch=41
05/22/2022 22:05:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.418841 on epoch=41
05/22/2022 22:05:19 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:05:19 - INFO - __main__ - Printing 3 examples
05/22/2022 22:05:19 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 22:05:19 - INFO - __main__ - ['neutral']
05/22/2022 22:05:19 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 22:05:19 - INFO - __main__ - ['neutral']
05/22/2022 22:05:19 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 22:05:19 - INFO - __main__ - ['neutral']
05/22/2022 22:05:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:05:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:05:20 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:05:20 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:05:20 - INFO - __main__ - Printing 3 examples
05/22/2022 22:05:20 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 22:05:20 - INFO - __main__ - ['neutral']
05/22/2022 22:05:20 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 22:05:20 - INFO - __main__ - ['neutral']
05/22/2022 22:05:20 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 22:05:20 - INFO - __main__ - ['neutral']
05/22/2022 22:05:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:05:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:05:20 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:05:25 - INFO - __main__ - Global step 1000 Train loss 0.398716 Classification-F1 0.22936261953728573 on epoch=41
05/22/2022 22:05:25 - INFO - __main__ - save last model!
05/22/2022 22:05:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:05:31 - INFO - __main__ - Starting training!
05/22/2022 22:05:32 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 22:05:33 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 22:05:33 - INFO - __main__ - Printing 3 examples
05/22/2022 22:05:33 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 22:05:33 - INFO - __main__ - ['contradiction']
05/22/2022 22:05:33 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 22:05:33 - INFO - __main__ - ['entailment']
05/22/2022 22:05:33 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 22:05:33 - INFO - __main__ - ['contradiction']
05/22/2022 22:05:33 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:05:33 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:05:34 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 22:05:52 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_100_0.0005_8_predictions.txt
05/22/2022 22:05:52 - INFO - __main__ - Classification-F1 on test data: 0.3127
05/22/2022 22:05:52 - INFO - __main__ - prefix=anli_128_100, lr=0.0005, bsz=8, dev_performance=0.32836372792998386, test_performance=0.3127390307034849
05/22/2022 22:05:53 - INFO - __main__ - Running ... prefix=anli_128_100, lr=0.0003, bsz=8 ...
05/22/2022 22:05:53 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:05:53 - INFO - __main__ - Printing 3 examples
05/22/2022 22:05:53 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 22:05:53 - INFO - __main__ - ['neutral']
05/22/2022 22:05:53 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 22:05:53 - INFO - __main__ - ['neutral']
05/22/2022 22:05:53 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 22:05:53 - INFO - __main__ - ['neutral']
05/22/2022 22:05:53 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:05:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:05:54 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:05:54 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:05:54 - INFO - __main__ - Printing 3 examples
05/22/2022 22:05:54 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 22:05:54 - INFO - __main__ - ['neutral']
05/22/2022 22:05:54 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 22:05:54 - INFO - __main__ - ['neutral']
05/22/2022 22:05:54 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 22:05:54 - INFO - __main__ - ['neutral']
05/22/2022 22:05:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:05:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:05:55 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:06:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:06:07 - INFO - __main__ - Starting training!
05/22/2022 22:06:12 - INFO - __main__ - Step 10 Global step 10 Train loss 24.322035 on epoch=0
05/22/2022 22:06:16 - INFO - __main__ - Step 20 Global step 20 Train loss 22.594679 on epoch=0
05/22/2022 22:06:21 - INFO - __main__ - Step 30 Global step 30 Train loss 14.031624 on epoch=1
05/22/2022 22:06:27 - INFO - __main__ - Step 40 Global step 40 Train loss 12.494360 on epoch=1
05/22/2022 22:06:32 - INFO - __main__ - Step 50 Global step 50 Train loss 11.238017 on epoch=2
05/22/2022 22:06:40 - INFO - __main__ - Global step 50 Train loss 16.936144 Classification-F1 0.03558718861209965 on epoch=2
05/22/2022 22:06:46 - INFO - __main__ - Step 60 Global step 60 Train loss 11.623781 on epoch=2
05/22/2022 22:06:51 - INFO - __main__ - Step 70 Global step 70 Train loss 9.151059 on epoch=2
05/22/2022 22:06:56 - INFO - __main__ - Step 80 Global step 80 Train loss 9.687819 on epoch=3
05/22/2022 22:07:01 - INFO - __main__ - Step 90 Global step 90 Train loss 8.422537 on epoch=3
05/22/2022 22:07:06 - INFO - __main__ - Step 100 Global step 100 Train loss 7.977352 on epoch=4
05/22/2022 22:07:15 - INFO - __main__ - Global step 100 Train loss 9.372510 Classification-F1 0.04566929133858268 on epoch=4
05/22/2022 22:07:21 - INFO - __main__ - Step 110 Global step 110 Train loss 7.052224 on epoch=4
05/22/2022 22:07:26 - INFO - __main__ - Step 120 Global step 120 Train loss 5.801105 on epoch=4
05/22/2022 22:07:31 - INFO - __main__ - Step 130 Global step 130 Train loss 4.546022 on epoch=5
05/22/2022 22:07:36 - INFO - __main__ - Step 140 Global step 140 Train loss 3.398862 on epoch=5
05/22/2022 22:07:41 - INFO - __main__ - Step 150 Global step 150 Train loss 2.996827 on epoch=6
05/22/2022 22:07:48 - INFO - __main__ - Global step 150 Train loss 4.759008 Classification-F1 0.16666666666666666 on epoch=6
05/22/2022 22:07:54 - INFO - __main__ - Step 160 Global step 160 Train loss 2.574110 on epoch=6
05/22/2022 22:07:59 - INFO - __main__ - Step 170 Global step 170 Train loss 3.285788 on epoch=7
05/22/2022 22:08:04 - INFO - __main__ - Step 180 Global step 180 Train loss 2.422447 on epoch=7
05/22/2022 22:08:09 - INFO - __main__ - Step 190 Global step 190 Train loss 2.361588 on epoch=7
05/22/2022 22:08:14 - INFO - __main__ - Step 200 Global step 200 Train loss 2.453873 on epoch=8
05/22/2022 22:08:20 - INFO - __main__ - Global step 200 Train loss 2.619561 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 22:08:26 - INFO - __main__ - Step 210 Global step 210 Train loss 1.857418 on epoch=8
05/22/2022 22:08:31 - INFO - __main__ - Step 220 Global step 220 Train loss 2.013253 on epoch=9
05/22/2022 22:08:36 - INFO - __main__ - Step 230 Global step 230 Train loss 2.028029 on epoch=9
05/22/2022 22:08:41 - INFO - __main__ - Step 240 Global step 240 Train loss 2.202509 on epoch=9
05/22/2022 22:08:46 - INFO - __main__ - Step 250 Global step 250 Train loss 1.830523 on epoch=10
05/22/2022 22:08:53 - INFO - __main__ - Global step 250 Train loss 1.986347 Classification-F1 0.16666666666666666 on epoch=10
05/22/2022 22:08:58 - INFO - __main__ - Step 260 Global step 260 Train loss 2.288063 on epoch=10
05/22/2022 22:09:03 - INFO - __main__ - Step 270 Global step 270 Train loss 2.047811 on epoch=11
05/22/2022 22:09:08 - INFO - __main__ - Step 280 Global step 280 Train loss 2.024363 on epoch=11
05/22/2022 22:09:13 - INFO - __main__ - Step 290 Global step 290 Train loss 1.641162 on epoch=12
05/22/2022 22:09:18 - INFO - __main__ - Step 300 Global step 300 Train loss 1.710077 on epoch=12
05/22/2022 22:09:25 - INFO - __main__ - Global step 300 Train loss 1.942295 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 22:09:30 - INFO - __main__ - Step 310 Global step 310 Train loss 1.526103 on epoch=12
05/22/2022 22:09:35 - INFO - __main__ - Step 320 Global step 320 Train loss 1.462915 on epoch=13
05/22/2022 22:09:40 - INFO - __main__ - Step 330 Global step 330 Train loss 1.585400 on epoch=13
05/22/2022 22:09:45 - INFO - __main__ - Step 340 Global step 340 Train loss 1.603829 on epoch=14
05/22/2022 22:09:50 - INFO - __main__ - Step 350 Global step 350 Train loss 1.240991 on epoch=14
05/22/2022 22:09:56 - INFO - __main__ - Global step 350 Train loss 1.483847 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 22:10:02 - INFO - __main__ - Step 360 Global step 360 Train loss 1.107608 on epoch=14
05/22/2022 22:10:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.959859 on epoch=15
05/22/2022 22:10:12 - INFO - __main__ - Step 380 Global step 380 Train loss 1.279515 on epoch=15
05/22/2022 22:10:17 - INFO - __main__ - Step 390 Global step 390 Train loss 1.062174 on epoch=16
05/22/2022 22:10:22 - INFO - __main__ - Step 400 Global step 400 Train loss 1.132094 on epoch=16
05/22/2022 22:10:29 - INFO - __main__ - Global step 400 Train loss 1.108250 Classification-F1 0.2803363983991712 on epoch=16
05/22/2022 22:10:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.957624 on epoch=17
05/22/2022 22:10:40 - INFO - __main__ - Step 420 Global step 420 Train loss 1.188372 on epoch=17
05/22/2022 22:10:45 - INFO - __main__ - Step 430 Global step 430 Train loss 1.115356 on epoch=17
05/22/2022 22:10:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.824840 on epoch=18
05/22/2022 22:10:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.917197 on epoch=18
05/22/2022 22:11:02 - INFO - __main__ - Global step 450 Train loss 1.000678 Classification-F1 0.16666666666666666 on epoch=18
05/22/2022 22:11:07 - INFO - __main__ - Step 460 Global step 460 Train loss 1.090627 on epoch=19
05/22/2022 22:11:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.789921 on epoch=19
05/22/2022 22:11:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.863956 on epoch=19
05/22/2022 22:11:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.767431 on epoch=20
05/22/2022 22:11:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.928522 on epoch=20
05/22/2022 22:11:34 - INFO - __main__ - Global step 500 Train loss 0.888091 Classification-F1 0.16666666666666666 on epoch=20
05/22/2022 22:11:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.815996 on epoch=21
05/22/2022 22:11:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.791580 on epoch=21
05/22/2022 22:11:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.634054 on epoch=22
05/22/2022 22:11:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.673443 on epoch=22
05/22/2022 22:11:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.727850 on epoch=22
05/22/2022 22:12:06 - INFO - __main__ - Global step 550 Train loss 0.728585 Classification-F1 0.16666666666666666 on epoch=22
05/22/2022 22:12:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.621378 on epoch=23
05/22/2022 22:12:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.668822 on epoch=23
05/22/2022 22:12:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.728006 on epoch=24
05/22/2022 22:12:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.600327 on epoch=24
05/22/2022 22:12:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.638101 on epoch=24
05/22/2022 22:12:38 - INFO - __main__ - Global step 600 Train loss 0.651327 Classification-F1 0.2183025749904731 on epoch=24
05/22/2022 22:12:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.578584 on epoch=25
05/22/2022 22:12:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.802257 on epoch=25
05/22/2022 22:12:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.498648 on epoch=26
05/22/2022 22:12:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.663502 on epoch=26
05/22/2022 22:13:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.598276 on epoch=27
05/22/2022 22:13:11 - INFO - __main__ - Global step 650 Train loss 0.628254 Classification-F1 0.20326865683457226 on epoch=27
05/22/2022 22:13:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.550232 on epoch=27
05/22/2022 22:13:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.480526 on epoch=27
05/22/2022 22:13:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.458453 on epoch=28
05/22/2022 22:13:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.677746 on epoch=28
05/22/2022 22:13:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.556294 on epoch=29
05/22/2022 22:13:43 - INFO - __main__ - Global step 700 Train loss 0.544650 Classification-F1 0.16666666666666666 on epoch=29
05/22/2022 22:13:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.541807 on epoch=29
05/22/2022 22:13:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.640988 on epoch=29
05/22/2022 22:13:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.513377 on epoch=30
05/22/2022 22:14:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.556780 on epoch=30
05/22/2022 22:14:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.573454 on epoch=31
05/22/2022 22:14:16 - INFO - __main__ - Global step 750 Train loss 0.565281 Classification-F1 0.22717560555304414 on epoch=31
05/22/2022 22:14:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.554682 on epoch=31
05/22/2022 22:14:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.638028 on epoch=32
05/22/2022 22:14:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.445879 on epoch=32
05/22/2022 22:14:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.480349 on epoch=32
05/22/2022 22:14:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.562133 on epoch=33
05/22/2022 22:14:48 - INFO - __main__ - Global step 800 Train loss 0.536214 Classification-F1 0.22108815604750565 on epoch=33
05/22/2022 22:14:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.522791 on epoch=33
05/22/2022 22:14:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.544768 on epoch=34
05/22/2022 22:15:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.579666 on epoch=34
05/22/2022 22:15:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.612224 on epoch=34
05/22/2022 22:15:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.516215 on epoch=35
05/22/2022 22:15:21 - INFO - __main__ - Global step 850 Train loss 0.555133 Classification-F1 0.28522555519646925 on epoch=35
05/22/2022 22:15:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.487340 on epoch=35
05/22/2022 22:15:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.482768 on epoch=36
05/22/2022 22:15:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.493930 on epoch=36
05/22/2022 22:15:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.443566 on epoch=37
05/22/2022 22:15:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.524765 on epoch=37
05/22/2022 22:15:54 - INFO - __main__ - Global step 900 Train loss 0.486474 Classification-F1 0.2525117907147199 on epoch=37
05/22/2022 22:15:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.435773 on epoch=37
05/22/2022 22:16:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.476915 on epoch=38
05/22/2022 22:16:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.498525 on epoch=38
05/22/2022 22:16:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.521944 on epoch=39
05/22/2022 22:16:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.477136 on epoch=39
05/22/2022 22:16:27 - INFO - __main__ - Global step 950 Train loss 0.482059 Classification-F1 0.257043047103899 on epoch=39
05/22/2022 22:16:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.442464 on epoch=39
05/22/2022 22:16:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.519028 on epoch=40
05/22/2022 22:16:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.461070 on epoch=40
05/22/2022 22:16:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.437497 on epoch=41
05/22/2022 22:16:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.399838 on epoch=41
05/22/2022 22:16:54 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:16:54 - INFO - __main__ - Printing 3 examples
05/22/2022 22:16:54 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 22:16:54 - INFO - __main__ - ['neutral']
05/22/2022 22:16:54 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 22:16:54 - INFO - __main__ - ['neutral']
05/22/2022 22:16:54 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 22:16:54 - INFO - __main__ - ['neutral']
05/22/2022 22:16:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:16:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:16:55 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:16:55 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:16:55 - INFO - __main__ - Printing 3 examples
05/22/2022 22:16:55 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 22:16:55 - INFO - __main__ - ['neutral']
05/22/2022 22:16:55 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 22:16:55 - INFO - __main__ - ['neutral']
05/22/2022 22:16:55 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 22:16:55 - INFO - __main__ - ['neutral']
05/22/2022 22:16:55 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:16:55 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:16:55 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:17:00 - INFO - __main__ - Global step 1000 Train loss 0.451980 Classification-F1 0.3325534476988825 on epoch=41
05/22/2022 22:17:00 - INFO - __main__ - save last model!
05/22/2022 22:17:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:17:06 - INFO - __main__ - Starting training!
05/22/2022 22:17:08 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 22:17:08 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 22:17:08 - INFO - __main__ - Printing 3 examples
05/22/2022 22:17:08 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 22:17:08 - INFO - __main__ - ['contradiction']
05/22/2022 22:17:08 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 22:17:08 - INFO - __main__ - ['entailment']
05/22/2022 22:17:08 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 22:17:08 - INFO - __main__ - ['contradiction']
05/22/2022 22:17:08 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:17:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:17:10 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 22:17:28 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_100_0.0003_8_predictions.txt
05/22/2022 22:17:28 - INFO - __main__ - Classification-F1 on test data: 0.2889
05/22/2022 22:17:28 - INFO - __main__ - prefix=anli_128_100, lr=0.0003, bsz=8, dev_performance=0.3325534476988825, test_performance=0.2889440916543571
05/22/2022 22:17:28 - INFO - __main__ - Running ... prefix=anli_128_100, lr=0.0002, bsz=8 ...
05/22/2022 22:17:29 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:17:29 - INFO - __main__ - Printing 3 examples
05/22/2022 22:17:29 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 22:17:29 - INFO - __main__ - ['neutral']
05/22/2022 22:17:29 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 22:17:29 - INFO - __main__ - ['neutral']
05/22/2022 22:17:29 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 22:17:29 - INFO - __main__ - ['neutral']
05/22/2022 22:17:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:17:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:17:30 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:17:30 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:17:30 - INFO - __main__ - Printing 3 examples
05/22/2022 22:17:30 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 22:17:30 - INFO - __main__ - ['neutral']
05/22/2022 22:17:30 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 22:17:30 - INFO - __main__ - ['neutral']
05/22/2022 22:17:30 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 22:17:30 - INFO - __main__ - ['neutral']
05/22/2022 22:17:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:17:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:17:31 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:17:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:17:41 - INFO - __main__ - Starting training!
05/22/2022 22:17:46 - INFO - __main__ - Step 10 Global step 10 Train loss 23.888288 on epoch=0
05/22/2022 22:17:50 - INFO - __main__ - Step 20 Global step 20 Train loss 19.485241 on epoch=0
05/22/2022 22:17:55 - INFO - __main__ - Step 30 Global step 30 Train loss 16.672121 on epoch=1
05/22/2022 22:18:00 - INFO - __main__ - Step 40 Global step 40 Train loss 15.958231 on epoch=1
05/22/2022 22:18:05 - INFO - __main__ - Step 50 Global step 50 Train loss 12.459017 on epoch=2
05/22/2022 22:18:12 - INFO - __main__ - Global step 50 Train loss 17.692579 Classification-F1 0.04367816091954023 on epoch=2
05/22/2022 22:18:18 - INFO - __main__ - Step 60 Global step 60 Train loss 13.079531 on epoch=2
05/22/2022 22:18:23 - INFO - __main__ - Step 70 Global step 70 Train loss 12.019944 on epoch=2
05/22/2022 22:18:29 - INFO - __main__ - Step 80 Global step 80 Train loss 12.020541 on epoch=3
05/22/2022 22:18:34 - INFO - __main__ - Step 90 Global step 90 Train loss 10.972257 on epoch=3
05/22/2022 22:18:39 - INFO - __main__ - Step 100 Global step 100 Train loss 10.617477 on epoch=4
05/22/2022 22:19:01 - INFO - __main__ - Global step 100 Train loss 11.741951 Classification-F1 0.003603603603603603 on epoch=4
05/22/2022 22:19:06 - INFO - __main__ - Step 110 Global step 110 Train loss 9.991136 on epoch=4
05/22/2022 22:19:11 - INFO - __main__ - Step 120 Global step 120 Train loss 8.966452 on epoch=4
05/22/2022 22:19:16 - INFO - __main__ - Step 130 Global step 130 Train loss 9.388089 on epoch=5
05/22/2022 22:19:21 - INFO - __main__ - Step 140 Global step 140 Train loss 8.068619 on epoch=5
05/22/2022 22:19:26 - INFO - __main__ - Step 150 Global step 150 Train loss 7.890141 on epoch=6
05/22/2022 22:19:35 - INFO - __main__ - Global step 150 Train loss 8.860887 Classification-F1 0.0048192771084337345 on epoch=6
05/22/2022 22:19:40 - INFO - __main__ - Step 160 Global step 160 Train loss 7.727101 on epoch=6
05/22/2022 22:19:45 - INFO - __main__ - Step 170 Global step 170 Train loss 6.329116 on epoch=7
05/22/2022 22:19:50 - INFO - __main__ - Step 180 Global step 180 Train loss 6.864268 on epoch=7
05/22/2022 22:19:55 - INFO - __main__ - Step 190 Global step 190 Train loss 5.580287 on epoch=7
05/22/2022 22:20:01 - INFO - __main__ - Step 200 Global step 200 Train loss 5.350957 on epoch=8
05/22/2022 22:20:17 - INFO - __main__ - Global step 200 Train loss 6.370347 Classification-F1 0.00348297213622291 on epoch=8
05/22/2022 22:20:22 - INFO - __main__ - Step 210 Global step 210 Train loss 4.200751 on epoch=8
05/22/2022 22:20:27 - INFO - __main__ - Step 220 Global step 220 Train loss 3.572834 on epoch=9
05/22/2022 22:20:32 - INFO - __main__ - Step 230 Global step 230 Train loss 3.564466 on epoch=9
05/22/2022 22:20:37 - INFO - __main__ - Step 240 Global step 240 Train loss 3.318136 on epoch=9
05/22/2022 22:20:42 - INFO - __main__ - Step 250 Global step 250 Train loss 2.733166 on epoch=10
05/22/2022 22:20:53 - INFO - __main__ - Global step 250 Train loss 3.477871 Classification-F1 0.006818181818181817 on epoch=10
05/22/2022 22:20:58 - INFO - __main__ - Step 260 Global step 260 Train loss 2.315260 on epoch=10
05/22/2022 22:21:03 - INFO - __main__ - Step 270 Global step 270 Train loss 2.156892 on epoch=11
05/22/2022 22:21:08 - INFO - __main__ - Step 280 Global step 280 Train loss 2.552877 on epoch=11
05/22/2022 22:21:13 - INFO - __main__ - Step 290 Global step 290 Train loss 2.433582 on epoch=12
05/22/2022 22:21:18 - INFO - __main__ - Step 300 Global step 300 Train loss 2.618411 on epoch=12
05/22/2022 22:21:26 - INFO - __main__ - Global step 300 Train loss 2.415405 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 22:21:31 - INFO - __main__ - Step 310 Global step 310 Train loss 2.349456 on epoch=12
05/22/2022 22:21:37 - INFO - __main__ - Step 320 Global step 320 Train loss 2.010326 on epoch=13
05/22/2022 22:21:42 - INFO - __main__ - Step 330 Global step 330 Train loss 2.025481 on epoch=13
05/22/2022 22:21:47 - INFO - __main__ - Step 340 Global step 340 Train loss 2.108742 on epoch=14
05/22/2022 22:21:52 - INFO - __main__ - Step 350 Global step 350 Train loss 1.502100 on epoch=14
05/22/2022 22:21:59 - INFO - __main__ - Global step 350 Train loss 1.999221 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 22:22:04 - INFO - __main__ - Step 360 Global step 360 Train loss 1.745401 on epoch=14
05/22/2022 22:22:09 - INFO - __main__ - Step 370 Global step 370 Train loss 1.890429 on epoch=15
05/22/2022 22:22:14 - INFO - __main__ - Step 380 Global step 380 Train loss 1.492103 on epoch=15
05/22/2022 22:22:20 - INFO - __main__ - Step 390 Global step 390 Train loss 2.097275 on epoch=16
05/22/2022 22:22:25 - INFO - __main__ - Step 400 Global step 400 Train loss 1.685406 on epoch=16
05/22/2022 22:22:34 - INFO - __main__ - Global step 400 Train loss 1.782123 Classification-F1 0.16666666666666666 on epoch=16
05/22/2022 22:22:39 - INFO - __main__ - Step 410 Global step 410 Train loss 1.941135 on epoch=17
05/22/2022 22:22:44 - INFO - __main__ - Step 420 Global step 420 Train loss 1.683431 on epoch=17
05/22/2022 22:22:49 - INFO - __main__ - Step 430 Global step 430 Train loss 1.508300 on epoch=17
05/22/2022 22:22:54 - INFO - __main__ - Step 440 Global step 440 Train loss 1.958836 on epoch=18
05/22/2022 22:22:59 - INFO - __main__ - Step 450 Global step 450 Train loss 1.542528 on epoch=18
05/22/2022 22:23:09 - INFO - __main__ - Global step 450 Train loss 1.726846 Classification-F1 0.16666666666666666 on epoch=18
05/22/2022 22:23:14 - INFO - __main__ - Step 460 Global step 460 Train loss 1.894182 on epoch=19
05/22/2022 22:23:19 - INFO - __main__ - Step 470 Global step 470 Train loss 1.436683 on epoch=19
05/22/2022 22:23:24 - INFO - __main__ - Step 480 Global step 480 Train loss 1.760313 on epoch=19
05/22/2022 22:23:29 - INFO - __main__ - Step 490 Global step 490 Train loss 1.642489 on epoch=20
05/22/2022 22:23:34 - INFO - __main__ - Step 500 Global step 500 Train loss 1.629958 on epoch=20
05/22/2022 22:23:42 - INFO - __main__ - Global step 500 Train loss 1.672725 Classification-F1 0.16666666666666666 on epoch=20
05/22/2022 22:23:47 - INFO - __main__ - Step 510 Global step 510 Train loss 1.247504 on epoch=21
05/22/2022 22:23:52 - INFO - __main__ - Step 520 Global step 520 Train loss 1.433304 on epoch=21
05/22/2022 22:23:57 - INFO - __main__ - Step 530 Global step 530 Train loss 1.231365 on epoch=22
05/22/2022 22:24:02 - INFO - __main__ - Step 540 Global step 540 Train loss 1.563816 on epoch=22
05/22/2022 22:24:07 - INFO - __main__ - Step 550 Global step 550 Train loss 1.592984 on epoch=22
05/22/2022 22:24:15 - INFO - __main__ - Global step 550 Train loss 1.413795 Classification-F1 0.16666666666666666 on epoch=22
05/22/2022 22:24:20 - INFO - __main__ - Step 560 Global step 560 Train loss 1.221487 on epoch=23
05/22/2022 22:24:25 - INFO - __main__ - Step 570 Global step 570 Train loss 1.097106 on epoch=23
05/22/2022 22:24:30 - INFO - __main__ - Step 580 Global step 580 Train loss 1.539593 on epoch=24
05/22/2022 22:24:35 - INFO - __main__ - Step 590 Global step 590 Train loss 1.084768 on epoch=24
05/22/2022 22:24:41 - INFO - __main__ - Step 600 Global step 600 Train loss 1.122028 on epoch=24
05/22/2022 22:24:47 - INFO - __main__ - Global step 600 Train loss 1.212996 Classification-F1 0.16666666666666666 on epoch=24
05/22/2022 22:24:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.973008 on epoch=25
05/22/2022 22:24:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.878273 on epoch=25
05/22/2022 22:25:02 - INFO - __main__ - Step 630 Global step 630 Train loss 1.049670 on epoch=26
05/22/2022 22:25:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.871391 on epoch=26
05/22/2022 22:25:12 - INFO - __main__ - Step 650 Global step 650 Train loss 1.101951 on epoch=27
05/22/2022 22:25:18 - INFO - __main__ - Global step 650 Train loss 0.974859 Classification-F1 0.16666666666666666 on epoch=27
05/22/2022 22:25:23 - INFO - __main__ - Step 660 Global step 660 Train loss 1.047820 on epoch=27
05/22/2022 22:25:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.795736 on epoch=27
05/22/2022 22:25:33 - INFO - __main__ - Step 680 Global step 680 Train loss 1.024490 on epoch=28
05/22/2022 22:25:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.922132 on epoch=28
05/22/2022 22:25:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.810753 on epoch=29
05/22/2022 22:25:49 - INFO - __main__ - Global step 700 Train loss 0.920186 Classification-F1 0.16666666666666666 on epoch=29
05/22/2022 22:25:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.887556 on epoch=29
05/22/2022 22:25:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.864802 on epoch=29
05/22/2022 22:26:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.813255 on epoch=30
05/22/2022 22:26:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.946909 on epoch=30
05/22/2022 22:26:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.683390 on epoch=31
05/22/2022 22:26:21 - INFO - __main__ - Global step 750 Train loss 0.839183 Classification-F1 0.16666666666666666 on epoch=31
05/22/2022 22:26:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.794530 on epoch=31
05/22/2022 22:26:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.680758 on epoch=32
05/22/2022 22:26:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.675680 on epoch=32
05/22/2022 22:26:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.759136 on epoch=32
05/22/2022 22:26:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.580144 on epoch=33
05/22/2022 22:26:52 - INFO - __main__ - Global step 800 Train loss 0.698049 Classification-F1 0.16666666666666666 on epoch=33
05/22/2022 22:26:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.715696 on epoch=33
05/22/2022 22:27:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.781177 on epoch=34
05/22/2022 22:27:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.743263 on epoch=34
05/22/2022 22:27:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.675812 on epoch=34
05/22/2022 22:27:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.739408 on epoch=35
05/22/2022 22:27:24 - INFO - __main__ - Global step 850 Train loss 0.731071 Classification-F1 0.16666666666666666 on epoch=35
05/22/2022 22:27:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.606045 on epoch=35
05/22/2022 22:27:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.595863 on epoch=36
05/22/2022 22:27:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.601480 on epoch=36
05/22/2022 22:27:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.615513 on epoch=37
05/22/2022 22:27:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.623104 on epoch=37
05/22/2022 22:27:55 - INFO - __main__ - Global step 900 Train loss 0.608401 Classification-F1 0.16666666666666666 on epoch=37
05/22/2022 22:28:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.452716 on epoch=37
05/22/2022 22:28:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.660707 on epoch=38
05/22/2022 22:28:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.729654 on epoch=38
05/22/2022 22:28:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.623866 on epoch=39
05/22/2022 22:28:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.587922 on epoch=39
05/22/2022 22:28:28 - INFO - __main__ - Global step 950 Train loss 0.610973 Classification-F1 0.24891131669937386 on epoch=39
05/22/2022 22:28:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.574088 on epoch=39
05/22/2022 22:28:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.623339 on epoch=40
05/22/2022 22:28:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.573586 on epoch=40
05/22/2022 22:28:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.606821 on epoch=41
05/22/2022 22:28:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.521747 on epoch=41
05/22/2022 22:28:55 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:28:55 - INFO - __main__ - Printing 3 examples
05/22/2022 22:28:55 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 22:28:55 - INFO - __main__ - ['neutral']
05/22/2022 22:28:55 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 22:28:55 - INFO - __main__ - ['neutral']
05/22/2022 22:28:55 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 22:28:55 - INFO - __main__ - ['neutral']
05/22/2022 22:28:55 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:28:55 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:28:56 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:28:56 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:28:56 - INFO - __main__ - Printing 3 examples
05/22/2022 22:28:56 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 22:28:56 - INFO - __main__ - ['neutral']
05/22/2022 22:28:56 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 22:28:56 - INFO - __main__ - ['neutral']
05/22/2022 22:28:56 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 22:28:56 - INFO - __main__ - ['neutral']
05/22/2022 22:28:56 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:28:56 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:28:56 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:29:01 - INFO - __main__ - Global step 1000 Train loss 0.579916 Classification-F1 0.23613359716975477 on epoch=41
05/22/2022 22:29:01 - INFO - __main__ - save last model!
05/22/2022 22:29:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:29:07 - INFO - __main__ - Starting training!
05/22/2022 22:29:08 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 22:29:08 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 22:29:08 - INFO - __main__ - Printing 3 examples
05/22/2022 22:29:08 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 22:29:08 - INFO - __main__ - ['contradiction']
05/22/2022 22:29:08 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 22:29:08 - INFO - __main__ - ['entailment']
05/22/2022 22:29:08 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 22:29:08 - INFO - __main__ - ['contradiction']
05/22/2022 22:29:08 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:29:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:29:10 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 22:29:28 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_100_0.0002_8_predictions.txt
05/22/2022 22:29:28 - INFO - __main__ - Classification-F1 on test data: 0.2147
05/22/2022 22:29:29 - INFO - __main__ - prefix=anli_128_100, lr=0.0002, bsz=8, dev_performance=0.24891131669937386, test_performance=0.2147267806240256
05/22/2022 22:29:29 - INFO - __main__ - Running ... prefix=anli_128_100, lr=0.0001, bsz=8 ...
05/22/2022 22:29:30 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:29:30 - INFO - __main__ - Printing 3 examples
05/22/2022 22:29:30 - INFO - __main__ -  [anli] premise: John Zdechlik ("Zuh-DEK-lik") (born 2 May 1937) is an American composer, music teacher, and conductor. Zdechlik has been elected to the American Bandmasters Association and many of his compositions have become standard concert band repertoire, including Chorale and Shaker Dance and Psalm 46. [SEP] hypothesis: John Zdechlik is a savant of music. 
05/22/2022 22:29:30 - INFO - __main__ - ['neutral']
05/22/2022 22:29:30 - INFO - __main__ -  [anli] premise: "No Words" is a song written by Paul McCartney and Denny Laine, and first released on 7 December 1973 on "Band on the Run" by Paul McCartney and Wings. The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run". [SEP] hypothesis: The song was Laine's first co-writing on a Wings album and his only writing credit on "Band on the Run" even though Laine had written a few songs before for other singers
05/22/2022 22:29:30 - INFO - __main__ - ['neutral']
05/22/2022 22:29:30 - INFO - __main__ -  [anli] premise: Askold Anatolievich Makarov (Russian: Аско́льд Анато́льевич Мака́ров ; 3 May 1925 – 25 December 2000) was a Russian ballet dancer and ballet professor, leading soloist at the Kirov Ballet during the 1960s and early 1970s. Director of the Saint-Petesburg State Academic Ballet from 1976 to 2000. Awarded with: State Prize of the USSR (1951) and People's Artist of the USSR (1983). [SEP] hypothesis: The USSR is home to some of the finest ballet dancers in the world.
05/22/2022 22:29:30 - INFO - __main__ - ['neutral']
05/22/2022 22:29:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:29:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:29:30 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:29:30 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:29:30 - INFO - __main__ - Printing 3 examples
05/22/2022 22:29:30 - INFO - __main__ -  [anli] premise: Nauset Regional High School an NEASC accredited high school located in North Eastham, Massachusetts. Nauset is inside the Cape Cod National Seashore, making it the only high school on the East Coast located within a National Park. The open campus is situated about a half-mile from Nauset Light. Nauset's colors are Black and Gold and the school's mascot is the Warrior. [SEP] hypothesis: Nauset Regional High School is a short walk from the Atlantic Ocean.
05/22/2022 22:29:30 - INFO - __main__ - ['neutral']
05/22/2022 22:29:30 - INFO - __main__ -  [anli] premise: Manchester City Football Club is a football club in Manchester, England. Founded in 1880 as St. Mark's (West Gorton), they became Ardwick Association Football Club in 1887 and Manchester City in 1894. The club moved to the City of Manchester Stadium in 2003, having played at Maine Road since 1923. [SEP] hypothesis: Manchester City Football Club is the oldest football club in England. 
05/22/2022 22:29:30 - INFO - __main__ - ['neutral']
05/22/2022 22:29:30 - INFO - __main__ -  [anli] premise: Brontë was a 2005 play by British playwright Polly Teale about the lives of the Brontë sisters, their brother Branwell and their father Patrick. It also featured characters from the sisters' novels such as Cathy and Heathcliff from "Wuthering Heights". [SEP] hypothesis: Bronte features characters from more than 3 other novels.
05/22/2022 22:29:30 - INFO - __main__ - ['neutral']
05/22/2022 22:29:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:29:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:29:31 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:29:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:29:43 - INFO - __main__ - Starting training!
05/22/2022 22:29:48 - INFO - __main__ - Step 10 Global step 10 Train loss 25.351732 on epoch=0
05/22/2022 22:29:53 - INFO - __main__ - Step 20 Global step 20 Train loss 20.267735 on epoch=0
05/22/2022 22:29:58 - INFO - __main__ - Step 30 Global step 30 Train loss 15.142001 on epoch=1
05/22/2022 22:30:03 - INFO - __main__ - Step 40 Global step 40 Train loss 14.654030 on epoch=1
05/22/2022 22:30:08 - INFO - __main__ - Step 50 Global step 50 Train loss 12.707529 on epoch=2
05/22/2022 22:30:58 - INFO - __main__ - Global step 50 Train loss 17.624605 Classification-F1 0.015233742740169476 on epoch=2
05/22/2022 22:31:04 - INFO - __main__ - Step 60 Global step 60 Train loss 13.265409 on epoch=2
05/22/2022 22:31:09 - INFO - __main__ - Step 70 Global step 70 Train loss 11.207243 on epoch=2
05/22/2022 22:31:14 - INFO - __main__ - Step 80 Global step 80 Train loss 12.585713 on epoch=3
05/22/2022 22:31:19 - INFO - __main__ - Step 90 Global step 90 Train loss 11.310609 on epoch=3
05/22/2022 22:31:24 - INFO - __main__ - Step 100 Global step 100 Train loss 11.426177 on epoch=4
05/22/2022 22:31:36 - INFO - __main__ - Global step 100 Train loss 11.959028 Classification-F1 0.007962840079628402 on epoch=4
05/22/2022 22:31:41 - INFO - __main__ - Step 110 Global step 110 Train loss 10.845484 on epoch=4
05/22/2022 22:31:46 - INFO - __main__ - Step 120 Global step 120 Train loss 11.018412 on epoch=4
05/22/2022 22:31:51 - INFO - __main__ - Step 130 Global step 130 Train loss 10.690731 on epoch=5
05/22/2022 22:31:56 - INFO - __main__ - Step 140 Global step 140 Train loss 10.109289 on epoch=5
05/22/2022 22:32:01 - INFO - __main__ - Step 150 Global step 150 Train loss 10.044849 on epoch=6
05/22/2022 22:32:10 - INFO - __main__ - Global step 150 Train loss 10.541754 Classification-F1 0.004395604395604396 on epoch=6
05/22/2022 22:32:15 - INFO - __main__ - Step 160 Global step 160 Train loss 10.112779 on epoch=6
05/22/2022 22:32:20 - INFO - __main__ - Step 170 Global step 170 Train loss 9.154888 on epoch=7
05/22/2022 22:32:25 - INFO - __main__ - Step 180 Global step 180 Train loss 9.626605 on epoch=7
05/22/2022 22:32:30 - INFO - __main__ - Step 190 Global step 190 Train loss 8.478395 on epoch=7
05/22/2022 22:32:35 - INFO - __main__ - Step 200 Global step 200 Train loss 9.237701 on epoch=8
05/22/2022 22:32:43 - INFO - __main__ - Global step 200 Train loss 9.322074 Classification-F1 0.002197802197802198 on epoch=8
05/22/2022 22:32:48 - INFO - __main__ - Step 210 Global step 210 Train loss 8.613064 on epoch=8
05/22/2022 22:32:53 - INFO - __main__ - Step 220 Global step 220 Train loss 8.640826 on epoch=9
05/22/2022 22:32:58 - INFO - __main__ - Step 230 Global step 230 Train loss 7.925473 on epoch=9
05/22/2022 22:33:03 - INFO - __main__ - Step 240 Global step 240 Train loss 7.403821 on epoch=9
05/22/2022 22:33:09 - INFO - __main__ - Step 250 Global step 250 Train loss 7.901835 on epoch=10
05/22/2022 22:33:16 - INFO - __main__ - Global step 250 Train loss 8.097004 Classification-F1 0.0 on epoch=10
05/22/2022 22:33:21 - INFO - __main__ - Step 260 Global step 260 Train loss 6.649448 on epoch=10
05/22/2022 22:33:26 - INFO - __main__ - Step 270 Global step 270 Train loss 6.627063 on epoch=11
05/22/2022 22:33:31 - INFO - __main__ - Step 280 Global step 280 Train loss 7.339369 on epoch=11
05/22/2022 22:33:36 - INFO - __main__ - Step 290 Global step 290 Train loss 5.762504 on epoch=12
05/22/2022 22:33:41 - INFO - __main__ - Step 300 Global step 300 Train loss 6.723596 on epoch=12
05/22/2022 22:33:49 - INFO - __main__ - Global step 300 Train loss 6.620396 Classification-F1 0.0 on epoch=12
05/22/2022 22:33:54 - INFO - __main__ - Step 310 Global step 310 Train loss 4.581179 on epoch=12
05/22/2022 22:33:59 - INFO - __main__ - Step 320 Global step 320 Train loss 5.144086 on epoch=13
05/22/2022 22:34:04 - INFO - __main__ - Step 330 Global step 330 Train loss 4.450013 on epoch=13
05/22/2022 22:34:09 - INFO - __main__ - Step 340 Global step 340 Train loss 4.502875 on epoch=14
05/22/2022 22:34:14 - INFO - __main__ - Step 350 Global step 350 Train loss 3.810722 on epoch=14
05/22/2022 22:34:21 - INFO - __main__ - Global step 350 Train loss 4.497775 Classification-F1 0.09942870163902409 on epoch=14
05/22/2022 22:34:27 - INFO - __main__ - Step 360 Global step 360 Train loss 3.741824 on epoch=14
05/22/2022 22:34:32 - INFO - __main__ - Step 370 Global step 370 Train loss 2.679889 on epoch=15
05/22/2022 22:34:37 - INFO - __main__ - Step 380 Global step 380 Train loss 3.375568 on epoch=15
05/22/2022 22:34:42 - INFO - __main__ - Step 390 Global step 390 Train loss 2.983036 on epoch=16
05/22/2022 22:34:47 - INFO - __main__ - Step 400 Global step 400 Train loss 3.045595 on epoch=16
05/22/2022 22:34:53 - INFO - __main__ - Global step 400 Train loss 3.165183 Classification-F1 0.16666666666666666 on epoch=16
05/22/2022 22:34:59 - INFO - __main__ - Step 410 Global step 410 Train loss 2.424328 on epoch=17
05/22/2022 22:35:04 - INFO - __main__ - Step 420 Global step 420 Train loss 2.931471 on epoch=17
05/22/2022 22:35:09 - INFO - __main__ - Step 430 Global step 430 Train loss 2.865253 on epoch=17
05/22/2022 22:35:14 - INFO - __main__ - Step 440 Global step 440 Train loss 2.652727 on epoch=18
05/22/2022 22:35:19 - INFO - __main__ - Step 450 Global step 450 Train loss 2.667483 on epoch=18
05/22/2022 22:35:25 - INFO - __main__ - Global step 450 Train loss 2.708252 Classification-F1 0.16666666666666666 on epoch=18
05/22/2022 22:35:30 - INFO - __main__ - Step 460 Global step 460 Train loss 2.480716 on epoch=19
05/22/2022 22:35:36 - INFO - __main__ - Step 470 Global step 470 Train loss 2.095515 on epoch=19
05/22/2022 22:35:41 - INFO - __main__ - Step 480 Global step 480 Train loss 2.371364 on epoch=19
05/22/2022 22:35:46 - INFO - __main__ - Step 490 Global step 490 Train loss 2.271996 on epoch=20
05/22/2022 22:35:51 - INFO - __main__ - Step 500 Global step 500 Train loss 2.464432 on epoch=20
05/22/2022 22:35:57 - INFO - __main__ - Global step 500 Train loss 2.336805 Classification-F1 0.22252557584886712 on epoch=20
05/22/2022 22:36:03 - INFO - __main__ - Step 510 Global step 510 Train loss 2.141680 on epoch=21
05/22/2022 22:36:08 - INFO - __main__ - Step 520 Global step 520 Train loss 2.937245 on epoch=21
05/22/2022 22:36:13 - INFO - __main__ - Step 530 Global step 530 Train loss 2.094537 on epoch=22
05/22/2022 22:36:18 - INFO - __main__ - Step 540 Global step 540 Train loss 1.929144 on epoch=22
05/22/2022 22:36:23 - INFO - __main__ - Step 550 Global step 550 Train loss 2.022914 on epoch=22
05/22/2022 22:36:29 - INFO - __main__ - Global step 550 Train loss 2.225104 Classification-F1 0.16666666666666666 on epoch=22
05/22/2022 22:36:34 - INFO - __main__ - Step 560 Global step 560 Train loss 2.087289 on epoch=23
05/22/2022 22:36:40 - INFO - __main__ - Step 570 Global step 570 Train loss 2.540728 on epoch=23
05/22/2022 22:36:45 - INFO - __main__ - Step 580 Global step 580 Train loss 1.894913 on epoch=24
05/22/2022 22:36:50 - INFO - __main__ - Step 590 Global step 590 Train loss 1.676315 on epoch=24
05/22/2022 22:36:55 - INFO - __main__ - Step 600 Global step 600 Train loss 2.101957 on epoch=24
05/22/2022 22:37:01 - INFO - __main__ - Global step 600 Train loss 2.060240 Classification-F1 0.18203299174959095 on epoch=24
05/22/2022 22:37:06 - INFO - __main__ - Step 610 Global step 610 Train loss 2.076046 on epoch=25
05/22/2022 22:37:11 - INFO - __main__ - Step 620 Global step 620 Train loss 1.953872 on epoch=25
05/22/2022 22:37:16 - INFO - __main__ - Step 630 Global step 630 Train loss 1.957491 on epoch=26
05/22/2022 22:37:22 - INFO - __main__ - Step 640 Global step 640 Train loss 2.201725 on epoch=26
05/22/2022 22:37:27 - INFO - __main__ - Step 650 Global step 650 Train loss 1.560791 on epoch=27
05/22/2022 22:37:33 - INFO - __main__ - Global step 650 Train loss 1.949985 Classification-F1 0.2789472108273198 on epoch=27
05/22/2022 22:37:38 - INFO - __main__ - Step 660 Global step 660 Train loss 1.793743 on epoch=27
05/22/2022 22:37:44 - INFO - __main__ - Step 670 Global step 670 Train loss 1.620856 on epoch=27
05/22/2022 22:37:49 - INFO - __main__ - Step 680 Global step 680 Train loss 1.470604 on epoch=28
05/22/2022 22:37:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.487085 on epoch=28
05/22/2022 22:37:59 - INFO - __main__ - Step 700 Global step 700 Train loss 1.720084 on epoch=29
05/22/2022 22:38:05 - INFO - __main__ - Global step 700 Train loss 1.618474 Classification-F1 0.16666666666666666 on epoch=29
05/22/2022 22:38:10 - INFO - __main__ - Step 710 Global step 710 Train loss 1.516464 on epoch=29
05/22/2022 22:38:15 - INFO - __main__ - Step 720 Global step 720 Train loss 1.379871 on epoch=29
05/22/2022 22:38:20 - INFO - __main__ - Step 730 Global step 730 Train loss 1.283459 on epoch=30
05/22/2022 22:38:25 - INFO - __main__ - Step 740 Global step 740 Train loss 1.454169 on epoch=30
05/22/2022 22:38:30 - INFO - __main__ - Step 750 Global step 750 Train loss 1.421469 on epoch=31
05/22/2022 22:38:37 - INFO - __main__ - Global step 750 Train loss 1.411086 Classification-F1 0.16666666666666666 on epoch=31
05/22/2022 22:38:42 - INFO - __main__ - Step 760 Global step 760 Train loss 1.115972 on epoch=31
05/22/2022 22:38:47 - INFO - __main__ - Step 770 Global step 770 Train loss 1.447241 on epoch=32
05/22/2022 22:38:52 - INFO - __main__ - Step 780 Global step 780 Train loss 1.335922 on epoch=32
05/22/2022 22:38:57 - INFO - __main__ - Step 790 Global step 790 Train loss 1.097449 on epoch=32
05/22/2022 22:39:02 - INFO - __main__ - Step 800 Global step 800 Train loss 1.054772 on epoch=33
05/22/2022 22:39:09 - INFO - __main__ - Global step 800 Train loss 1.210271 Classification-F1 0.1676489849377865 on epoch=33
05/22/2022 22:39:14 - INFO - __main__ - Step 810 Global step 810 Train loss 1.278707 on epoch=33
05/22/2022 22:39:19 - INFO - __main__ - Step 820 Global step 820 Train loss 1.095140 on epoch=34
05/22/2022 22:39:24 - INFO - __main__ - Step 830 Global step 830 Train loss 1.569900 on epoch=34
05/22/2022 22:39:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.952241 on epoch=34
05/22/2022 22:39:34 - INFO - __main__ - Step 850 Global step 850 Train loss 1.157913 on epoch=35
05/22/2022 22:39:41 - INFO - __main__ - Global step 850 Train loss 1.210780 Classification-F1 0.19337297879808002 on epoch=35
05/22/2022 22:39:46 - INFO - __main__ - Step 860 Global step 860 Train loss 1.028682 on epoch=35
05/22/2022 22:39:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.984905 on epoch=36
05/22/2022 22:39:56 - INFO - __main__ - Step 880 Global step 880 Train loss 1.079615 on epoch=36
05/22/2022 22:40:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.860259 on epoch=37
05/22/2022 22:40:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.905296 on epoch=37
05/22/2022 22:40:12 - INFO - __main__ - Global step 900 Train loss 0.971752 Classification-F1 0.271066491112574 on epoch=37
05/22/2022 22:40:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.861339 on epoch=37
05/22/2022 22:40:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.797715 on epoch=38
05/22/2022 22:40:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.644489 on epoch=38
05/22/2022 22:40:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.703154 on epoch=39
05/22/2022 22:40:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.821303 on epoch=39
05/22/2022 22:40:43 - INFO - __main__ - Global step 950 Train loss 0.765600 Classification-F1 0.16601307189542483 on epoch=39
05/22/2022 22:40:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.765034 on epoch=39
05/22/2022 22:40:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.583463 on epoch=40
05/22/2022 22:40:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.704744 on epoch=40
05/22/2022 22:41:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.645398 on epoch=41
05/22/2022 22:41:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.608238 on epoch=41
05/22/2022 22:41:10 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:41:10 - INFO - __main__ - Printing 3 examples
05/22/2022 22:41:10 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 22:41:10 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:10 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 22:41:10 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:10 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 22:41:10 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:41:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:41:11 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:41:11 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:41:11 - INFO - __main__ - Printing 3 examples
05/22/2022 22:41:11 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 22:41:11 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:11 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 22:41:11 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:11 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 22:41:11 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:41:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:41:11 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:41:14 - INFO - __main__ - Global step 1000 Train loss 0.661376 Classification-F1 0.18291479112374634 on epoch=41
05/22/2022 22:41:14 - INFO - __main__ - save last model!
05/22/2022 22:41:20 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 22:41:21 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 22:41:21 - INFO - __main__ - Printing 3 examples
05/22/2022 22:41:21 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 22:41:21 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:21 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 22:41:21 - INFO - __main__ - ['entailment']
05/22/2022 22:41:21 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 22:41:21 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:41:22 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:41:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:41:22 - INFO - __main__ - Starting training!
05/22/2022 22:41:23 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 22:41:40 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_100_0.0001_8_predictions.txt
05/22/2022 22:41:40 - INFO - __main__ - Classification-F1 on test data: 0.2845
05/22/2022 22:41:40 - INFO - __main__ - prefix=anli_128_100, lr=0.0001, bsz=8, dev_performance=0.2789472108273198, test_performance=0.28445683669564265
05/22/2022 22:41:40 - INFO - __main__ - Running ... prefix=anli_128_13, lr=0.0005, bsz=8 ...
05/22/2022 22:41:41 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:41:41 - INFO - __main__ - Printing 3 examples
05/22/2022 22:41:41 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 22:41:41 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:41 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 22:41:41 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:41 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 22:41:41 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:41:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:41:41 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:41:41 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:41:41 - INFO - __main__ - Printing 3 examples
05/22/2022 22:41:41 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 22:41:41 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:41 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 22:41:41 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:41 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 22:41:41 - INFO - __main__ - ['contradiction']
05/22/2022 22:41:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:41:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:41:42 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:41:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:41:55 - INFO - __main__ - Starting training!
05/22/2022 22:41:59 - INFO - __main__ - Step 10 Global step 10 Train loss 24.615639 on epoch=0
05/22/2022 22:42:04 - INFO - __main__ - Step 20 Global step 20 Train loss 19.623611 on epoch=0
05/22/2022 22:42:08 - INFO - __main__ - Step 30 Global step 30 Train loss 15.230600 on epoch=1
05/22/2022 22:42:13 - INFO - __main__ - Step 40 Global step 40 Train loss 12.746000 on epoch=1
05/22/2022 22:42:18 - INFO - __main__ - Step 50 Global step 50 Train loss 10.793173 on epoch=2
05/22/2022 22:42:25 - INFO - __main__ - Global step 50 Train loss 16.601805 Classification-F1 0.0 on epoch=2
05/22/2022 22:42:31 - INFO - __main__ - Step 60 Global step 60 Train loss 9.794340 on epoch=2
05/22/2022 22:42:36 - INFO - __main__ - Step 70 Global step 70 Train loss 7.280160 on epoch=2
05/22/2022 22:42:41 - INFO - __main__ - Step 80 Global step 80 Train loss 7.222712 on epoch=3
05/22/2022 22:42:46 - INFO - __main__ - Step 90 Global step 90 Train loss 4.722571 on epoch=3
05/22/2022 22:42:51 - INFO - __main__ - Step 100 Global step 100 Train loss 3.318262 on epoch=4
05/22/2022 22:42:58 - INFO - __main__ - Global step 100 Train loss 6.467608 Classification-F1 0.16666666666666666 on epoch=4
05/22/2022 22:43:03 - INFO - __main__ - Step 110 Global step 110 Train loss 2.521931 on epoch=4
05/22/2022 22:43:08 - INFO - __main__ - Step 120 Global step 120 Train loss 2.383186 on epoch=4
05/22/2022 22:43:13 - INFO - __main__ - Step 130 Global step 130 Train loss 2.286166 on epoch=5
05/22/2022 22:43:18 - INFO - __main__ - Step 140 Global step 140 Train loss 2.349693 on epoch=5
05/22/2022 22:43:23 - INFO - __main__ - Step 150 Global step 150 Train loss 1.898555 on epoch=6
05/22/2022 22:43:30 - INFO - __main__ - Global step 150 Train loss 2.287906 Classification-F1 0.16666666666666666 on epoch=6
05/22/2022 22:43:35 - INFO - __main__ - Step 160 Global step 160 Train loss 1.900289 on epoch=6
05/22/2022 22:43:40 - INFO - __main__ - Step 170 Global step 170 Train loss 1.784260 on epoch=7
05/22/2022 22:43:45 - INFO - __main__ - Step 180 Global step 180 Train loss 1.758205 on epoch=7
05/22/2022 22:43:50 - INFO - __main__ - Step 190 Global step 190 Train loss 1.671466 on epoch=7
05/22/2022 22:43:55 - INFO - __main__ - Step 200 Global step 200 Train loss 1.492393 on epoch=8
05/22/2022 22:44:01 - INFO - __main__ - Global step 200 Train loss 1.721323 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 22:44:07 - INFO - __main__ - Step 210 Global step 210 Train loss 1.500036 on epoch=8
05/22/2022 22:44:12 - INFO - __main__ - Step 220 Global step 220 Train loss 1.476955 on epoch=9
05/22/2022 22:44:17 - INFO - __main__ - Step 230 Global step 230 Train loss 1.256011 on epoch=9
05/22/2022 22:44:22 - INFO - __main__ - Step 240 Global step 240 Train loss 1.164796 on epoch=9
05/22/2022 22:44:27 - INFO - __main__ - Step 250 Global step 250 Train loss 1.132508 on epoch=10
05/22/2022 22:44:33 - INFO - __main__ - Global step 250 Train loss 1.306061 Classification-F1 0.16666666666666666 on epoch=10
05/22/2022 22:44:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.993399 on epoch=10
05/22/2022 22:44:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.896682 on epoch=11
05/22/2022 22:44:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.879514 on epoch=11
05/22/2022 22:44:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.855165 on epoch=12
05/22/2022 22:44:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.645523 on epoch=12
05/22/2022 22:45:05 - INFO - __main__ - Global step 300 Train loss 0.854056 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 22:45:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.864788 on epoch=12
05/22/2022 22:45:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.742145 on epoch=13
05/22/2022 22:45:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.703357 on epoch=13
05/22/2022 22:45:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.726260 on epoch=14
05/22/2022 22:45:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.672964 on epoch=14
05/22/2022 22:45:36 - INFO - __main__ - Global step 350 Train loss 0.741903 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 22:45:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.645737 on epoch=14
05/22/2022 22:45:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.652306 on epoch=15
05/22/2022 22:45:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.650876 on epoch=15
05/22/2022 22:45:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.686345 on epoch=16
05/22/2022 22:46:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.680102 on epoch=16
05/22/2022 22:46:09 - INFO - __main__ - Global step 400 Train loss 0.663073 Classification-F1 0.30433689640850764 on epoch=16
05/22/2022 22:46:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.528832 on epoch=17
05/22/2022 22:46:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.504937 on epoch=17
05/22/2022 22:46:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.611902 on epoch=17
05/22/2022 22:46:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.606757 on epoch=18
05/22/2022 22:46:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.611537 on epoch=18
05/22/2022 22:46:41 - INFO - __main__ - Global step 450 Train loss 0.572793 Classification-F1 0.19047619047619047 on epoch=18
05/22/2022 22:46:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.580248 on epoch=19
05/22/2022 22:46:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.450532 on epoch=19
05/22/2022 22:46:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.461692 on epoch=19
05/22/2022 22:47:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.643645 on epoch=20
05/22/2022 22:47:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.511247 on epoch=20
05/22/2022 22:47:13 - INFO - __main__ - Global step 500 Train loss 0.529473 Classification-F1 0.16666666666666666 on epoch=20
05/22/2022 22:47:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.502680 on epoch=21
05/22/2022 22:47:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.795409 on epoch=21
05/22/2022 22:47:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.560204 on epoch=22
05/22/2022 22:47:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.591628 on epoch=22
05/22/2022 22:47:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.441784 on epoch=22
05/22/2022 22:47:45 - INFO - __main__ - Global step 550 Train loss 0.578341 Classification-F1 0.1901572454144774 on epoch=22
05/22/2022 22:47:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.519070 on epoch=23
05/22/2022 22:47:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.480086 on epoch=23
05/22/2022 22:48:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.435741 on epoch=24
05/22/2022 22:48:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.474301 on epoch=24
05/22/2022 22:48:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.504140 on epoch=24
05/22/2022 22:48:18 - INFO - __main__ - Global step 600 Train loss 0.482668 Classification-F1 0.22345110087045575 on epoch=24
05/22/2022 22:48:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.482760 on epoch=25
05/22/2022 22:48:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.423049 on epoch=25
05/22/2022 22:48:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.460290 on epoch=26
05/22/2022 22:48:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.455364 on epoch=26
05/22/2022 22:48:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.438338 on epoch=27
05/22/2022 22:48:50 - INFO - __main__ - Global step 650 Train loss 0.451960 Classification-F1 0.16699282452707112 on epoch=27
05/22/2022 22:48:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.480661 on epoch=27
05/22/2022 22:49:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.460597 on epoch=27
05/22/2022 22:49:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.477339 on epoch=28
05/22/2022 22:49:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.486405 on epoch=28
05/22/2022 22:49:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.456157 on epoch=29
05/22/2022 22:49:23 - INFO - __main__ - Global step 700 Train loss 0.472232 Classification-F1 0.2633444283294553 on epoch=29
05/22/2022 22:49:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.445483 on epoch=29
05/22/2022 22:49:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.460237 on epoch=29
05/22/2022 22:49:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.466239 on epoch=30
05/22/2022 22:49:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.485848 on epoch=30
05/22/2022 22:49:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.434492 on epoch=31
05/22/2022 22:49:55 - INFO - __main__ - Global step 750 Train loss 0.458460 Classification-F1 0.24386776993412065 on epoch=31
05/22/2022 22:50:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.477039 on epoch=31
05/22/2022 22:50:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.451539 on epoch=32
05/22/2022 22:50:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.450555 on epoch=32
05/22/2022 22:50:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.408522 on epoch=32
05/22/2022 22:50:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.425345 on epoch=33
05/22/2022 22:50:28 - INFO - __main__ - Global step 800 Train loss 0.442600 Classification-F1 0.24975990456838426 on epoch=33
05/22/2022 22:50:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.422805 on epoch=33
05/22/2022 22:50:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.458266 on epoch=34
05/22/2022 22:50:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.431213 on epoch=34
05/22/2022 22:50:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.434166 on epoch=34
05/22/2022 22:50:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.450306 on epoch=35
05/22/2022 22:51:00 - INFO - __main__ - Global step 850 Train loss 0.439351 Classification-F1 0.25753984663123247 on epoch=35
05/22/2022 22:51:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.401390 on epoch=35
05/22/2022 22:51:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.448974 on epoch=36
05/22/2022 22:51:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.484669 on epoch=36
05/22/2022 22:51:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.416882 on epoch=37
05/22/2022 22:51:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.453478 on epoch=37
05/22/2022 22:51:31 - INFO - __main__ - Global step 900 Train loss 0.441079 Classification-F1 0.19378030509723956 on epoch=37
05/22/2022 22:51:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.403366 on epoch=37
05/22/2022 22:51:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.419725 on epoch=38
05/22/2022 22:51:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.420002 on epoch=38
05/22/2022 22:51:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.403506 on epoch=39
05/22/2022 22:51:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.459353 on epoch=39
05/22/2022 22:52:02 - INFO - __main__ - Global step 950 Train loss 0.421191 Classification-F1 0.16666666666666666 on epoch=39
05/22/2022 22:52:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.446120 on epoch=39
05/22/2022 22:52:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.412483 on epoch=40
05/22/2022 22:52:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.376178 on epoch=40
05/22/2022 22:52:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.440868 on epoch=41
05/22/2022 22:52:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.472237 on epoch=41
05/22/2022 22:52:29 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:52:29 - INFO - __main__ - Printing 3 examples
05/22/2022 22:52:29 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 22:52:29 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:29 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 22:52:29 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:29 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 22:52:29 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:52:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:52:29 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:52:29 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:52:29 - INFO - __main__ - Printing 3 examples
05/22/2022 22:52:29 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 22:52:29 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:29 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 22:52:29 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:29 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 22:52:29 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:52:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:52:30 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:52:32 - INFO - __main__ - Global step 1000 Train loss 0.429577 Classification-F1 0.17651134592066517 on epoch=41
05/22/2022 22:52:32 - INFO - __main__ - save last model!
05/22/2022 22:52:39 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 22:52:39 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 22:52:39 - INFO - __main__ - Printing 3 examples
05/22/2022 22:52:39 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 22:52:39 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:39 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 22:52:39 - INFO - __main__ - ['entailment']
05/22/2022 22:52:39 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 22:52:39 - INFO - __main__ - ['contradiction']
05/22/2022 22:52:39 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:52:40 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:52:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:52:41 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 22:52:41 - INFO - __main__ - Starting training!
05/22/2022 22:52:59 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_13_0.0005_8_predictions.txt
05/22/2022 22:52:59 - INFO - __main__ - Classification-F1 on test data: 0.2988
05/22/2022 22:52:59 - INFO - __main__ - prefix=anli_128_13, lr=0.0005, bsz=8, dev_performance=0.30433689640850764, test_performance=0.2987518261977287
05/22/2022 22:52:59 - INFO - __main__ - Running ... prefix=anli_128_13, lr=0.0003, bsz=8 ...
05/22/2022 22:53:00 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:53:00 - INFO - __main__ - Printing 3 examples
05/22/2022 22:53:00 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 22:53:00 - INFO - __main__ - ['contradiction']
05/22/2022 22:53:00 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 22:53:00 - INFO - __main__ - ['contradiction']
05/22/2022 22:53:00 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 22:53:00 - INFO - __main__ - ['contradiction']
05/22/2022 22:53:00 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:53:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:53:01 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 22:53:01 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 22:53:01 - INFO - __main__ - Printing 3 examples
05/22/2022 22:53:01 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 22:53:01 - INFO - __main__ - ['contradiction']
05/22/2022 22:53:01 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 22:53:01 - INFO - __main__ - ['contradiction']
05/22/2022 22:53:01 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 22:53:01 - INFO - __main__ - ['contradiction']
05/22/2022 22:53:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:53:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:53:01 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 22:53:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 22:53:14 - INFO - __main__ - Starting training!
05/22/2022 22:53:18 - INFO - __main__ - Step 10 Global step 10 Train loss 24.564999 on epoch=0
05/22/2022 22:53:22 - INFO - __main__ - Step 20 Global step 20 Train loss 20.969387 on epoch=0
05/22/2022 22:53:27 - INFO - __main__ - Step 30 Global step 30 Train loss 14.997427 on epoch=1
05/22/2022 22:53:33 - INFO - __main__ - Step 40 Global step 40 Train loss 12.664740 on epoch=1
05/22/2022 22:53:38 - INFO - __main__ - Step 50 Global step 50 Train loss 10.433949 on epoch=2
05/22/2022 22:53:44 - INFO - __main__ - Global step 50 Train loss 16.726099 Classification-F1 0.0 on epoch=2
05/22/2022 22:53:49 - INFO - __main__ - Step 60 Global step 60 Train loss 11.307229 on epoch=2
05/22/2022 22:53:54 - INFO - __main__ - Step 70 Global step 70 Train loss 9.725150 on epoch=2
05/22/2022 22:53:59 - INFO - __main__ - Step 80 Global step 80 Train loss 9.914239 on epoch=3
05/22/2022 22:54:04 - INFO - __main__ - Step 90 Global step 90 Train loss 8.821866 on epoch=3
05/22/2022 22:54:09 - INFO - __main__ - Step 100 Global step 100 Train loss 8.201975 on epoch=4
05/22/2022 22:54:18 - INFO - __main__ - Global step 100 Train loss 9.594091 Classification-F1 0.01056338028169014 on epoch=4
05/22/2022 22:54:23 - INFO - __main__ - Step 110 Global step 110 Train loss 6.813544 on epoch=4
05/22/2022 22:54:28 - INFO - __main__ - Step 120 Global step 120 Train loss 6.568258 on epoch=4
05/22/2022 22:54:33 - INFO - __main__ - Step 130 Global step 130 Train loss 5.272182 on epoch=5
05/22/2022 22:54:38 - INFO - __main__ - Step 140 Global step 140 Train loss 3.963878 on epoch=5
05/22/2022 22:54:43 - INFO - __main__ - Step 150 Global step 150 Train loss 3.155692 on epoch=6
05/22/2022 22:54:48 - INFO - __main__ - Global step 150 Train loss 5.154711 Classification-F1 0.0 on epoch=6
05/22/2022 22:54:53 - INFO - __main__ - Step 160 Global step 160 Train loss 3.156675 on epoch=6
05/22/2022 22:54:58 - INFO - __main__ - Step 170 Global step 170 Train loss 2.304242 on epoch=7
05/22/2022 22:55:03 - INFO - __main__ - Step 180 Global step 180 Train loss 2.600781 on epoch=7
05/22/2022 22:55:08 - INFO - __main__ - Step 190 Global step 190 Train loss 2.665121 on epoch=7
05/22/2022 22:55:13 - INFO - __main__ - Step 200 Global step 200 Train loss 2.426201 on epoch=8
05/22/2022 22:55:18 - INFO - __main__ - Global step 200 Train loss 2.630604 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 22:55:24 - INFO - __main__ - Step 210 Global step 210 Train loss 2.224588 on epoch=8
05/22/2022 22:55:29 - INFO - __main__ - Step 220 Global step 220 Train loss 2.490210 on epoch=9
05/22/2022 22:55:34 - INFO - __main__ - Step 230 Global step 230 Train loss 2.171876 on epoch=9
05/22/2022 22:55:39 - INFO - __main__ - Step 240 Global step 240 Train loss 2.593988 on epoch=9
05/22/2022 22:55:44 - INFO - __main__ - Step 250 Global step 250 Train loss 1.944733 on epoch=10
05/22/2022 22:55:50 - INFO - __main__ - Global step 250 Train loss 2.285079 Classification-F1 0.16666666666666666 on epoch=10
05/22/2022 22:55:55 - INFO - __main__ - Step 260 Global step 260 Train loss 1.904254 on epoch=10
05/22/2022 22:56:00 - INFO - __main__ - Step 270 Global step 270 Train loss 1.403593 on epoch=11
05/22/2022 22:56:05 - INFO - __main__ - Step 280 Global step 280 Train loss 1.992069 on epoch=11
05/22/2022 22:56:10 - INFO - __main__ - Step 290 Global step 290 Train loss 1.673076 on epoch=12
05/22/2022 22:56:15 - INFO - __main__ - Step 300 Global step 300 Train loss 1.761293 on epoch=12
05/22/2022 22:56:21 - INFO - __main__ - Global step 300 Train loss 1.746857 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 22:56:26 - INFO - __main__ - Step 310 Global step 310 Train loss 1.772124 on epoch=12
05/22/2022 22:56:31 - INFO - __main__ - Step 320 Global step 320 Train loss 1.607064 on epoch=13
05/22/2022 22:56:36 - INFO - __main__ - Step 330 Global step 330 Train loss 1.641371 on epoch=13
05/22/2022 22:56:41 - INFO - __main__ - Step 340 Global step 340 Train loss 1.564001 on epoch=14
05/22/2022 22:56:47 - INFO - __main__ - Step 350 Global step 350 Train loss 1.608796 on epoch=14
05/22/2022 22:56:53 - INFO - __main__ - Global step 350 Train loss 1.638671 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 22:56:58 - INFO - __main__ - Step 360 Global step 360 Train loss 1.230111 on epoch=14
05/22/2022 22:57:03 - INFO - __main__ - Step 370 Global step 370 Train loss 1.241868 on epoch=15
05/22/2022 22:57:08 - INFO - __main__ - Step 380 Global step 380 Train loss 1.224401 on epoch=15
05/22/2022 22:57:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.992216 on epoch=16
05/22/2022 22:57:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.944125 on epoch=16
05/22/2022 22:57:25 - INFO - __main__ - Global step 400 Train loss 1.126544 Classification-F1 0.16666666666666666 on epoch=16
05/22/2022 22:57:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.988937 on epoch=17
05/22/2022 22:57:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.792379 on epoch=17
05/22/2022 22:57:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.809182 on epoch=17
05/22/2022 22:57:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.850194 on epoch=18
05/22/2022 22:57:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.815000 on epoch=18
05/22/2022 22:57:57 - INFO - __main__ - Global step 450 Train loss 0.851139 Classification-F1 0.2415458937198068 on epoch=18
05/22/2022 22:58:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.616630 on epoch=19
05/22/2022 22:58:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.546202 on epoch=19
05/22/2022 22:58:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.690366 on epoch=19
05/22/2022 22:58:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.572567 on epoch=20
05/22/2022 22:58:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.442964 on epoch=20
05/22/2022 22:58:29 - INFO - __main__ - Global step 500 Train loss 0.573746 Classification-F1 0.24544381413351987 on epoch=20
05/22/2022 22:58:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.586619 on epoch=21
05/22/2022 22:58:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.548521 on epoch=21
05/22/2022 22:58:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.397735 on epoch=22
05/22/2022 22:58:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.538781 on epoch=22
05/22/2022 22:58:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.455773 on epoch=22
05/22/2022 22:59:02 - INFO - __main__ - Global step 550 Train loss 0.505486 Classification-F1 0.23440898136718982 on epoch=22
05/22/2022 22:59:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.474452 on epoch=23
05/22/2022 22:59:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.477767 on epoch=23
05/22/2022 22:59:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.534022 on epoch=24
05/22/2022 22:59:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.494814 on epoch=24
05/22/2022 22:59:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.471690 on epoch=24
05/22/2022 22:59:34 - INFO - __main__ - Global step 600 Train loss 0.490549 Classification-F1 0.16666666666666666 on epoch=24
05/22/2022 22:59:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.454214 on epoch=25
05/22/2022 22:59:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.442501 on epoch=25
05/22/2022 22:59:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.468806 on epoch=26
05/22/2022 22:59:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.479086 on epoch=26
05/22/2022 22:59:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.505244 on epoch=27
05/22/2022 23:00:06 - INFO - __main__ - Global step 650 Train loss 0.469970 Classification-F1 0.16666666666666666 on epoch=27
05/22/2022 23:00:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.452432 on epoch=27
05/22/2022 23:00:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.428066 on epoch=27
05/22/2022 23:00:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.455074 on epoch=28
05/22/2022 23:00:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.441112 on epoch=28
05/22/2022 23:00:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.465200 on epoch=29
05/22/2022 23:00:38 - INFO - __main__ - Global step 700 Train loss 0.448377 Classification-F1 0.2688016727883014 on epoch=29
05/22/2022 23:00:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.435960 on epoch=29
05/22/2022 23:00:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.417519 on epoch=29
05/22/2022 23:00:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.441577 on epoch=30
05/22/2022 23:00:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.467840 on epoch=30
05/22/2022 23:01:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.422304 on epoch=31
05/22/2022 23:01:10 - INFO - __main__ - Global step 750 Train loss 0.437040 Classification-F1 0.31713986713986714 on epoch=31
05/22/2022 23:01:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.492827 on epoch=31
05/22/2022 23:01:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.420718 on epoch=32
05/22/2022 23:01:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.436638 on epoch=32
05/22/2022 23:01:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.400552 on epoch=32
05/22/2022 23:01:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.455169 on epoch=33
05/22/2022 23:01:42 - INFO - __main__ - Global step 800 Train loss 0.441181 Classification-F1 0.26240391334730956 on epoch=33
05/22/2022 23:01:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.431511 on epoch=33
05/22/2022 23:01:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.411780 on epoch=34
05/22/2022 23:01:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.415702 on epoch=34
05/22/2022 23:02:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.378240 on epoch=34
05/22/2022 23:02:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.463636 on epoch=35
05/22/2022 23:02:14 - INFO - __main__ - Global step 850 Train loss 0.420174 Classification-F1 0.24258909255759223 on epoch=35
05/22/2022 23:02:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.425542 on epoch=35
05/22/2022 23:02:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.428610 on epoch=36
05/22/2022 23:02:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.420669 on epoch=36
05/22/2022 23:02:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.379773 on epoch=37
05/22/2022 23:02:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.463468 on epoch=37
05/22/2022 23:02:46 - INFO - __main__ - Global step 900 Train loss 0.423613 Classification-F1 0.2758974358974359 on epoch=37
05/22/2022 23:02:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.424309 on epoch=37
05/22/2022 23:02:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.464342 on epoch=38
05/22/2022 23:03:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.444567 on epoch=38
05/22/2022 23:03:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.469886 on epoch=39
05/22/2022 23:03:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.374875 on epoch=39
05/22/2022 23:03:18 - INFO - __main__ - Global step 950 Train loss 0.435596 Classification-F1 0.25072558149177165 on epoch=39
05/22/2022 23:03:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.433009 on epoch=39
05/22/2022 23:03:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.461252 on epoch=40
05/22/2022 23:03:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.409259 on epoch=40
05/22/2022 23:03:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.442468 on epoch=41
05/22/2022 23:03:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.468335 on epoch=41
05/22/2022 23:03:44 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:03:44 - INFO - __main__ - Printing 3 examples
05/22/2022 23:03:44 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 23:03:44 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:44 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 23:03:44 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:44 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 23:03:44 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:03:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:03:45 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:03:45 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:03:45 - INFO - __main__ - Printing 3 examples
05/22/2022 23:03:45 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 23:03:45 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:45 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 23:03:45 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:45 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 23:03:45 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:03:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:03:46 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:03:50 - INFO - __main__ - Global step 1000 Train loss 0.442865 Classification-F1 0.26801303631321755 on epoch=41
05/22/2022 23:03:50 - INFO - __main__ - save last model!
05/22/2022 23:03:56 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 23:03:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:03:57 - INFO - __main__ - Starting training!
05/22/2022 23:03:57 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 23:03:57 - INFO - __main__ - Printing 3 examples
05/22/2022 23:03:57 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 23:03:57 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:57 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 23:03:57 - INFO - __main__ - ['entailment']
05/22/2022 23:03:57 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 23:03:57 - INFO - __main__ - ['contradiction']
05/22/2022 23:03:57 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:03:58 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:03:59 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 23:04:16 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_13_0.0003_8_predictions.txt
05/22/2022 23:04:16 - INFO - __main__ - Classification-F1 on test data: 0.3187
05/22/2022 23:04:16 - INFO - __main__ - prefix=anli_128_13, lr=0.0003, bsz=8, dev_performance=0.31713986713986714, test_performance=0.31868795099276587
05/22/2022 23:04:16 - INFO - __main__ - Running ... prefix=anli_128_13, lr=0.0002, bsz=8 ...
05/22/2022 23:04:17 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:04:17 - INFO - __main__ - Printing 3 examples
05/22/2022 23:04:17 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 23:04:17 - INFO - __main__ - ['contradiction']
05/22/2022 23:04:17 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 23:04:17 - INFO - __main__ - ['contradiction']
05/22/2022 23:04:17 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 23:04:17 - INFO - __main__ - ['contradiction']
05/22/2022 23:04:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:04:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:04:18 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:04:18 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:04:18 - INFO - __main__ - Printing 3 examples
05/22/2022 23:04:18 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 23:04:18 - INFO - __main__ - ['contradiction']
05/22/2022 23:04:18 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 23:04:18 - INFO - __main__ - ['contradiction']
05/22/2022 23:04:18 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 23:04:18 - INFO - __main__ - ['contradiction']
05/22/2022 23:04:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:04:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:04:18 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:04:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:04:29 - INFO - __main__ - Starting training!
05/22/2022 23:04:33 - INFO - __main__ - Step 10 Global step 10 Train loss 24.064066 on epoch=0
05/22/2022 23:04:38 - INFO - __main__ - Step 20 Global step 20 Train loss 21.221004 on epoch=0
05/22/2022 23:04:43 - INFO - __main__ - Step 30 Global step 30 Train loss 15.113251 on epoch=1
05/22/2022 23:04:48 - INFO - __main__ - Step 40 Global step 40 Train loss 15.145172 on epoch=1
05/22/2022 23:04:53 - INFO - __main__ - Step 50 Global step 50 Train loss 12.728895 on epoch=2
05/22/2022 23:05:03 - INFO - __main__ - Global step 50 Train loss 17.654478 Classification-F1 0.0 on epoch=2
05/22/2022 23:05:09 - INFO - __main__ - Step 60 Global step 60 Train loss 12.200964 on epoch=2
05/22/2022 23:05:14 - INFO - __main__ - Step 70 Global step 70 Train loss 10.460569 on epoch=2
05/22/2022 23:05:19 - INFO - __main__ - Step 80 Global step 80 Train loss 11.185242 on epoch=3
05/22/2022 23:05:24 - INFO - __main__ - Step 90 Global step 90 Train loss 9.719519 on epoch=3
05/22/2022 23:05:29 - INFO - __main__ - Step 100 Global step 100 Train loss 10.161079 on epoch=4
05/22/2022 23:05:36 - INFO - __main__ - Global step 100 Train loss 10.745475 Classification-F1 0.0 on epoch=4
05/22/2022 23:05:41 - INFO - __main__ - Step 110 Global step 110 Train loss 8.989752 on epoch=4
05/22/2022 23:05:46 - INFO - __main__ - Step 120 Global step 120 Train loss 8.304477 on epoch=4
05/22/2022 23:05:51 - INFO - __main__ - Step 130 Global step 130 Train loss 8.508763 on epoch=5
05/22/2022 23:05:56 - INFO - __main__ - Step 140 Global step 140 Train loss 7.458480 on epoch=5
05/22/2022 23:06:01 - INFO - __main__ - Step 150 Global step 150 Train loss 7.114890 on epoch=6
05/22/2022 23:06:10 - INFO - __main__ - Global step 150 Train loss 8.075273 Classification-F1 0.002506265664160401 on epoch=6
05/22/2022 23:06:15 - INFO - __main__ - Step 160 Global step 160 Train loss 6.846882 on epoch=6
05/22/2022 23:06:20 - INFO - __main__ - Step 170 Global step 170 Train loss 5.203712 on epoch=7
05/22/2022 23:06:25 - INFO - __main__ - Step 180 Global step 180 Train loss 5.031017 on epoch=7
05/22/2022 23:06:30 - INFO - __main__ - Step 190 Global step 190 Train loss 4.408494 on epoch=7
05/22/2022 23:06:36 - INFO - __main__ - Step 200 Global step 200 Train loss 3.420991 on epoch=8
05/22/2022 23:06:42 - INFO - __main__ - Global step 200 Train loss 4.982219 Classification-F1 0.0 on epoch=8
05/22/2022 23:06:47 - INFO - __main__ - Step 210 Global step 210 Train loss 3.259202 on epoch=8
05/22/2022 23:06:52 - INFO - __main__ - Step 220 Global step 220 Train loss 3.209556 on epoch=9
05/22/2022 23:06:57 - INFO - __main__ - Step 230 Global step 230 Train loss 2.588018 on epoch=9
05/22/2022 23:07:02 - INFO - __main__ - Step 240 Global step 240 Train loss 3.016226 on epoch=9
05/22/2022 23:07:07 - INFO - __main__ - Step 250 Global step 250 Train loss 2.492156 on epoch=10
05/22/2022 23:07:13 - INFO - __main__ - Global step 250 Train loss 2.913031 Classification-F1 0.16666666666666666 on epoch=10
05/22/2022 23:07:19 - INFO - __main__ - Step 260 Global step 260 Train loss 1.827718 on epoch=10
05/22/2022 23:07:24 - INFO - __main__ - Step 270 Global step 270 Train loss 2.506598 on epoch=11
05/22/2022 23:07:30 - INFO - __main__ - Step 280 Global step 280 Train loss 2.241077 on epoch=11
05/22/2022 23:07:35 - INFO - __main__ - Step 290 Global step 290 Train loss 2.206369 on epoch=12
05/22/2022 23:07:40 - INFO - __main__ - Step 300 Global step 300 Train loss 2.141551 on epoch=12
05/22/2022 23:07:46 - INFO - __main__ - Global step 300 Train loss 2.184663 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 23:07:51 - INFO - __main__ - Step 310 Global step 310 Train loss 1.900311 on epoch=12
05/22/2022 23:07:56 - INFO - __main__ - Step 320 Global step 320 Train loss 2.138383 on epoch=13
05/22/2022 23:08:01 - INFO - __main__ - Step 330 Global step 330 Train loss 2.024868 on epoch=13
05/22/2022 23:08:06 - INFO - __main__ - Step 340 Global step 340 Train loss 2.119595 on epoch=14
05/22/2022 23:08:11 - INFO - __main__ - Step 350 Global step 350 Train loss 1.647721 on epoch=14
05/22/2022 23:08:18 - INFO - __main__ - Global step 350 Train loss 1.966176 Classification-F1 0.1775766716943188 on epoch=14
05/22/2022 23:08:24 - INFO - __main__ - Step 360 Global step 360 Train loss 1.346692 on epoch=14
05/22/2022 23:08:29 - INFO - __main__ - Step 370 Global step 370 Train loss 1.594219 on epoch=15
05/22/2022 23:08:34 - INFO - __main__ - Step 380 Global step 380 Train loss 1.781664 on epoch=15
05/22/2022 23:08:39 - INFO - __main__ - Step 390 Global step 390 Train loss 1.520416 on epoch=16
05/22/2022 23:08:44 - INFO - __main__ - Step 400 Global step 400 Train loss 1.856557 on epoch=16
05/22/2022 23:08:50 - INFO - __main__ - Global step 400 Train loss 1.619909 Classification-F1 0.16666666666666666 on epoch=16
05/22/2022 23:08:56 - INFO - __main__ - Step 410 Global step 410 Train loss 1.337448 on epoch=17
05/22/2022 23:09:01 - INFO - __main__ - Step 420 Global step 420 Train loss 1.340508 on epoch=17
05/22/2022 23:09:06 - INFO - __main__ - Step 430 Global step 430 Train loss 1.004738 on epoch=17
05/22/2022 23:09:11 - INFO - __main__ - Step 440 Global step 440 Train loss 1.298999 on epoch=18
05/22/2022 23:09:16 - INFO - __main__ - Step 450 Global step 450 Train loss 1.151913 on epoch=18
05/22/2022 23:09:23 - INFO - __main__ - Global step 450 Train loss 1.226721 Classification-F1 0.16666666666666666 on epoch=18
05/22/2022 23:09:28 - INFO - __main__ - Step 460 Global step 460 Train loss 1.301718 on epoch=19
05/22/2022 23:09:33 - INFO - __main__ - Step 470 Global step 470 Train loss 1.279160 on epoch=19
05/22/2022 23:09:38 - INFO - __main__ - Step 480 Global step 480 Train loss 1.119310 on epoch=19
05/22/2022 23:09:43 - INFO - __main__ - Step 490 Global step 490 Train loss 1.168989 on epoch=20
05/22/2022 23:09:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.950879 on epoch=20
05/22/2022 23:09:55 - INFO - __main__ - Global step 500 Train loss 1.164011 Classification-F1 0.16666666666666666 on epoch=20
05/22/2022 23:10:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.867549 on epoch=21
05/22/2022 23:10:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.665823 on epoch=21
05/22/2022 23:10:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.536784 on epoch=22
05/22/2022 23:10:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.537998 on epoch=22
05/22/2022 23:10:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.464865 on epoch=22
05/22/2022 23:10:27 - INFO - __main__ - Global step 550 Train loss 0.614604 Classification-F1 0.18182343091402506 on epoch=22
05/22/2022 23:10:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.542212 on epoch=23
05/22/2022 23:10:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.466188 on epoch=23
05/22/2022 23:10:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.422913 on epoch=24
05/22/2022 23:10:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.414175 on epoch=24
05/22/2022 23:10:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.467220 on epoch=24
05/22/2022 23:11:00 - INFO - __main__ - Global step 600 Train loss 0.462542 Classification-F1 0.19196260624832054 on epoch=24
05/22/2022 23:11:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.401063 on epoch=25
05/22/2022 23:11:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.408275 on epoch=25
05/22/2022 23:11:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.460159 on epoch=26
05/22/2022 23:11:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.461682 on epoch=26
05/22/2022 23:11:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.345937 on epoch=27
05/22/2022 23:11:33 - INFO - __main__ - Global step 650 Train loss 0.415423 Classification-F1 0.27282676672920575 on epoch=27
05/22/2022 23:11:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.432814 on epoch=27
05/22/2022 23:11:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.352748 on epoch=27
05/22/2022 23:11:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.365828 on epoch=28
05/22/2022 23:11:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.439249 on epoch=28
05/22/2022 23:11:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.375982 on epoch=29
05/22/2022 23:12:06 - INFO - __main__ - Global step 700 Train loss 0.393324 Classification-F1 0.30260221024552236 on epoch=29
05/22/2022 23:12:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.372906 on epoch=29
05/22/2022 23:12:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.344263 on epoch=29
05/22/2022 23:12:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.311764 on epoch=30
05/22/2022 23:12:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.355936 on epoch=30
05/22/2022 23:12:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.333837 on epoch=31
05/22/2022 23:12:39 - INFO - __main__ - Global step 750 Train loss 0.343741 Classification-F1 0.3492897579003093 on epoch=31
05/22/2022 23:12:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.277956 on epoch=31
05/22/2022 23:12:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.242528 on epoch=32
05/22/2022 23:12:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.281577 on epoch=32
05/22/2022 23:12:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.302165 on epoch=32
05/22/2022 23:13:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.313870 on epoch=33
05/22/2022 23:13:11 - INFO - __main__ - Global step 800 Train loss 0.283619 Classification-F1 0.3856079923984174 on epoch=33
05/22/2022 23:13:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.273603 on epoch=33
05/22/2022 23:13:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.260944 on epoch=34
05/22/2022 23:13:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.237685 on epoch=34
05/22/2022 23:13:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.225152 on epoch=34
05/22/2022 23:13:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.222441 on epoch=35
05/22/2022 23:13:44 - INFO - __main__ - Global step 850 Train loss 0.243965 Classification-F1 0.44724033017209175 on epoch=35
05/22/2022 23:13:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.192845 on epoch=35
05/22/2022 23:13:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.163613 on epoch=36
05/22/2022 23:14:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.198612 on epoch=36
05/22/2022 23:14:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.159717 on epoch=37
05/22/2022 23:14:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.183610 on epoch=37
05/22/2022 23:14:17 - INFO - __main__ - Global step 900 Train loss 0.179680 Classification-F1 0.3164965861537332 on epoch=37
05/22/2022 23:14:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.150778 on epoch=37
05/22/2022 23:14:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.154194 on epoch=38
05/22/2022 23:14:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.130091 on epoch=38
05/22/2022 23:14:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.090955 on epoch=39
05/22/2022 23:14:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.072250 on epoch=39
05/22/2022 23:14:49 - INFO - __main__ - Global step 950 Train loss 0.119654 Classification-F1 0.5089803813208068 on epoch=39
05/22/2022 23:14:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.109944 on epoch=39
05/22/2022 23:15:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.110846 on epoch=40
05/22/2022 23:15:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.112086 on epoch=40
05/22/2022 23:15:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.046953 on epoch=41
05/22/2022 23:15:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.030109 on epoch=41
05/22/2022 23:15:16 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:15:16 - INFO - __main__ - Printing 3 examples
05/22/2022 23:15:16 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 23:15:16 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:16 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 23:15:16 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:16 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 23:15:16 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:15:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:15:17 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:15:17 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:15:17 - INFO - __main__ - Printing 3 examples
05/22/2022 23:15:17 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 23:15:17 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:17 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 23:15:17 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:17 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 23:15:17 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:15:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:15:17 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:15:22 - INFO - __main__ - Global step 1000 Train loss 0.081987 Classification-F1 0.5295239010112324 on epoch=41
05/22/2022 23:15:22 - INFO - __main__ - save last model!
05/22/2022 23:15:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:15:28 - INFO - __main__ - Starting training!
05/22/2022 23:15:29 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 23:15:30 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 23:15:30 - INFO - __main__ - Printing 3 examples
05/22/2022 23:15:30 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 23:15:30 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:30 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 23:15:30 - INFO - __main__ - ['entailment']
05/22/2022 23:15:30 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 23:15:30 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:15:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:15:32 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 23:15:49 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_13_0.0002_8_predictions.txt
05/22/2022 23:15:49 - INFO - __main__ - Classification-F1 on test data: 0.1760
05/22/2022 23:15:50 - INFO - __main__ - prefix=anli_128_13, lr=0.0002, bsz=8, dev_performance=0.5295239010112324, test_performance=0.17595220540786408
05/22/2022 23:15:50 - INFO - __main__ - Running ... prefix=anli_128_13, lr=0.0001, bsz=8 ...
05/22/2022 23:15:51 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:15:51 - INFO - __main__ - Printing 3 examples
05/22/2022 23:15:51 - INFO - __main__ -  [anli] premise: The South Kalgoorlie Gold Mine is a gold mine located south-west of Kalgoorlie, Western Australia. The mine is sometimes also referred to as "South Kal Mines - New Celebration", being a merger of the former "New Celebration Gold Mine" and the "Jubilee Gold Mine", which were combined in 2002. [SEP] hypothesis: The South Kalgoorlie Gold Mine is located northwest of Perth,Australia. 
05/22/2022 23:15:51 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:51 - INFO - __main__ -  [anli] premise: Julia Gjika (born 1949) is an Albanian-born poet living in the United States. She is one of the few writers publishing in the Albanian language and writes poetry as well working as a journalist. Her poems have been praised by her peers and have been included in several publications of collected works. [SEP] hypothesis: Julia Gjika publishes her work in French.
05/22/2022 23:15:51 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:51 - INFO - __main__ -  [anli] premise: Curtis Lee Hanson (March 24, 1945 – September 20, 2016) was an American film director, producer, and screenwriter. His directing work included the psychological thriller "The Hand That Rocks the Cradle" (1992), the neo-noir crime film "L.A. Confidential" (1997), the comedy "Wonder Boys" (2000), the hip hop drama "8 Mile" (2002), and the romantic comedy-drama "In Her Shoes" (2005). [SEP] hypothesis: Curtis Lee Hanson was born in Italy.
05/22/2022 23:15:51 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:51 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:15:51 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:15:51 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:15:51 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:15:51 - INFO - __main__ - Printing 3 examples
05/22/2022 23:15:51 - INFO - __main__ -  [anli] premise: Dexter Alexander Nottage (born November 14, 1970) is a former American football defensive end in the National Football League (NFL) for the Washington Redskins and the Kansas City Chiefs. He played college football at Florida A&M University and was selected in the sixth round of the 1994 NFL Draft. He played high school football at Hollywood Hills High School. [SEP] hypothesis: Dexter Alexander Nottage (born November 14, 1970) is a former power forward basketball in the NBA.
05/22/2022 23:15:51 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:51 - INFO - __main__ -  [anli] premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from crème de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. [SEP] hypothesis: The drink is white
05/22/2022 23:15:51 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:51 - INFO - __main__ -  [anli] premise: Denis Hale Johnson (July 1, 1949 – May 24, 2017) was an American writer best known for his short story collection "Jesus' Son" (1992) and his novel "Tree of Smoke" (2007), which won the National Book Award for Fiction. He also wrote plays, poetry, journalism, and non-fiction. [SEP] hypothesis: Denis Hale Johnson (July 1, 1949 – May 24, 2010) was an American writer best known for his short story collection "Jesus' Son"
05/22/2022 23:15:51 - INFO - __main__ - ['contradiction']
05/22/2022 23:15:51 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:15:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:15:52 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:16:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:16:03 - INFO - __main__ - Starting training!
05/22/2022 23:16:07 - INFO - __main__ - Step 10 Global step 10 Train loss 23.782209 on epoch=0
05/22/2022 23:16:11 - INFO - __main__ - Step 20 Global step 20 Train loss 21.122913 on epoch=0
05/22/2022 23:16:16 - INFO - __main__ - Step 30 Global step 30 Train loss 19.473288 on epoch=1
05/22/2022 23:16:21 - INFO - __main__ - Step 40 Global step 40 Train loss 14.973297 on epoch=1
05/22/2022 23:16:26 - INFO - __main__ - Step 50 Global step 50 Train loss 12.393785 on epoch=2
05/22/2022 23:16:36 - INFO - __main__ - Global step 50 Train loss 18.349096 Classification-F1 0.0 on epoch=2
05/22/2022 23:16:42 - INFO - __main__ - Step 60 Global step 60 Train loss 13.485332 on epoch=2
05/22/2022 23:16:47 - INFO - __main__ - Step 70 Global step 70 Train loss 11.908246 on epoch=2
05/22/2022 23:16:52 - INFO - __main__ - Step 80 Global step 80 Train loss 11.676476 on epoch=3
05/22/2022 23:16:57 - INFO - __main__ - Step 90 Global step 90 Train loss 12.069250 on epoch=3
05/22/2022 23:17:02 - INFO - __main__ - Step 100 Global step 100 Train loss 11.809314 on epoch=4
05/22/2022 23:17:12 - INFO - __main__ - Global step 100 Train loss 12.189723 Classification-F1 0.0012626262626262627 on epoch=4
05/22/2022 23:17:18 - INFO - __main__ - Step 110 Global step 110 Train loss 11.519711 on epoch=4
05/22/2022 23:17:23 - INFO - __main__ - Step 120 Global step 120 Train loss 11.044020 on epoch=4
05/22/2022 23:17:28 - INFO - __main__ - Step 130 Global step 130 Train loss 10.616246 on epoch=5
05/22/2022 23:17:33 - INFO - __main__ - Step 140 Global step 140 Train loss 10.086237 on epoch=5
05/22/2022 23:17:38 - INFO - __main__ - Step 150 Global step 150 Train loss 10.198057 on epoch=6
05/22/2022 23:17:48 - INFO - __main__ - Global step 150 Train loss 10.692855 Classification-F1 0.004132231404958678 on epoch=6
05/22/2022 23:17:54 - INFO - __main__ - Step 160 Global step 160 Train loss 10.270433 on epoch=6
05/22/2022 23:17:59 - INFO - __main__ - Step 170 Global step 170 Train loss 9.468946 on epoch=7
05/22/2022 23:18:04 - INFO - __main__ - Step 180 Global step 180 Train loss 10.424921 on epoch=7
05/22/2022 23:18:09 - INFO - __main__ - Step 190 Global step 190 Train loss 8.799897 on epoch=7
05/22/2022 23:18:14 - INFO - __main__ - Step 200 Global step 200 Train loss 9.312257 on epoch=8
05/22/2022 23:18:22 - INFO - __main__ - Global step 200 Train loss 9.655292 Classification-F1 0.0 on epoch=8
05/22/2022 23:18:27 - INFO - __main__ - Step 210 Global step 210 Train loss 8.520743 on epoch=8
05/22/2022 23:18:32 - INFO - __main__ - Step 220 Global step 220 Train loss 9.291537 on epoch=9
05/22/2022 23:18:37 - INFO - __main__ - Step 230 Global step 230 Train loss 8.437222 on epoch=9
05/22/2022 23:18:42 - INFO - __main__ - Step 240 Global step 240 Train loss 8.536745 on epoch=9
05/22/2022 23:18:47 - INFO - __main__ - Step 250 Global step 250 Train loss 8.318007 on epoch=10
05/22/2022 23:18:56 - INFO - __main__ - Global step 250 Train loss 8.620852 Classification-F1 0.004132231404958678 on epoch=10
05/22/2022 23:19:01 - INFO - __main__ - Step 260 Global step 260 Train loss 7.525050 on epoch=10
05/22/2022 23:19:06 - INFO - __main__ - Step 270 Global step 270 Train loss 7.714334 on epoch=11
05/22/2022 23:19:11 - INFO - __main__ - Step 280 Global step 280 Train loss 7.306657 on epoch=11
05/22/2022 23:19:16 - INFO - __main__ - Step 290 Global step 290 Train loss 6.539693 on epoch=12
05/22/2022 23:19:21 - INFO - __main__ - Step 300 Global step 300 Train loss 7.252602 on epoch=12
05/22/2022 23:19:30 - INFO - __main__ - Global step 300 Train loss 7.267667 Classification-F1 0.0 on epoch=12
05/22/2022 23:19:35 - INFO - __main__ - Step 310 Global step 310 Train loss 6.471936 on epoch=12
05/22/2022 23:19:40 - INFO - __main__ - Step 320 Global step 320 Train loss 6.602015 on epoch=13
05/22/2022 23:19:45 - INFO - __main__ - Step 330 Global step 330 Train loss 5.717196 on epoch=13
05/22/2022 23:19:50 - INFO - __main__ - Step 340 Global step 340 Train loss 4.793263 on epoch=14
05/22/2022 23:19:55 - INFO - __main__ - Step 350 Global step 350 Train loss 4.590911 on epoch=14
05/22/2022 23:20:04 - INFO - __main__ - Global step 350 Train loss 5.635065 Classification-F1 0.002775850104094379 on epoch=14
05/22/2022 23:20:09 - INFO - __main__ - Step 360 Global step 360 Train loss 4.351074 on epoch=14
05/22/2022 23:20:14 - INFO - __main__ - Step 370 Global step 370 Train loss 4.216917 on epoch=15
05/22/2022 23:20:19 - INFO - __main__ - Step 380 Global step 380 Train loss 3.717606 on epoch=15
05/22/2022 23:20:24 - INFO - __main__ - Step 390 Global step 390 Train loss 3.349799 on epoch=16
05/22/2022 23:20:29 - INFO - __main__ - Step 400 Global step 400 Train loss 2.911173 on epoch=16
05/22/2022 23:20:36 - INFO - __main__ - Global step 400 Train loss 3.709313 Classification-F1 0.16666666666666666 on epoch=16
05/22/2022 23:20:42 - INFO - __main__ - Step 410 Global step 410 Train loss 3.082965 on epoch=17
05/22/2022 23:20:47 - INFO - __main__ - Step 420 Global step 420 Train loss 2.910084 on epoch=17
05/22/2022 23:20:52 - INFO - __main__ - Step 430 Global step 430 Train loss 4.038402 on epoch=17
05/22/2022 23:20:57 - INFO - __main__ - Step 440 Global step 440 Train loss 3.032055 on epoch=18
05/22/2022 23:21:02 - INFO - __main__ - Step 450 Global step 450 Train loss 2.321665 on epoch=18
05/22/2022 23:21:08 - INFO - __main__ - Global step 450 Train loss 3.077034 Classification-F1 0.16666666666666666 on epoch=18
05/22/2022 23:21:13 - INFO - __main__ - Step 460 Global step 460 Train loss 3.229047 on epoch=19
05/22/2022 23:21:18 - INFO - __main__ - Step 470 Global step 470 Train loss 3.478097 on epoch=19
05/22/2022 23:21:23 - INFO - __main__ - Step 480 Global step 480 Train loss 2.619452 on epoch=19
05/22/2022 23:21:28 - INFO - __main__ - Step 490 Global step 490 Train loss 2.368541 on epoch=20
05/22/2022 23:21:33 - INFO - __main__ - Step 500 Global step 500 Train loss 2.419580 on epoch=20
05/22/2022 23:21:39 - INFO - __main__ - Global step 500 Train loss 2.822944 Classification-F1 0.16666666666666666 on epoch=20
05/22/2022 23:21:44 - INFO - __main__ - Step 510 Global step 510 Train loss 2.371833 on epoch=21
05/22/2022 23:21:49 - INFO - __main__ - Step 520 Global step 520 Train loss 2.612623 on epoch=21
05/22/2022 23:21:54 - INFO - __main__ - Step 530 Global step 530 Train loss 2.485437 on epoch=22
05/22/2022 23:21:59 - INFO - __main__ - Step 540 Global step 540 Train loss 2.637995 on epoch=22
05/22/2022 23:22:04 - INFO - __main__ - Step 550 Global step 550 Train loss 2.853146 on epoch=22
05/22/2022 23:22:10 - INFO - __main__ - Global step 550 Train loss 2.592207 Classification-F1 0.16666666666666666 on epoch=22
05/22/2022 23:22:15 - INFO - __main__ - Step 560 Global step 560 Train loss 2.506255 on epoch=23
05/22/2022 23:22:20 - INFO - __main__ - Step 570 Global step 570 Train loss 2.162681 on epoch=23
05/22/2022 23:22:25 - INFO - __main__ - Step 580 Global step 580 Train loss 2.753880 on epoch=24
05/22/2022 23:22:30 - INFO - __main__ - Step 590 Global step 590 Train loss 2.270602 on epoch=24
05/22/2022 23:22:35 - INFO - __main__ - Step 600 Global step 600 Train loss 2.159384 on epoch=24
05/22/2022 23:22:41 - INFO - __main__ - Global step 600 Train loss 2.370560 Classification-F1 0.16404199475065617 on epoch=24
05/22/2022 23:22:46 - INFO - __main__ - Step 610 Global step 610 Train loss 1.875865 on epoch=25
05/22/2022 23:22:51 - INFO - __main__ - Step 620 Global step 620 Train loss 2.188754 on epoch=25
05/22/2022 23:22:56 - INFO - __main__ - Step 630 Global step 630 Train loss 2.317899 on epoch=26
05/22/2022 23:23:01 - INFO - __main__ - Step 640 Global step 640 Train loss 2.121219 on epoch=26
05/22/2022 23:23:06 - INFO - __main__ - Step 650 Global step 650 Train loss 2.197629 on epoch=27
05/22/2022 23:23:12 - INFO - __main__ - Global step 650 Train loss 2.140274 Classification-F1 0.16666666666666666 on epoch=27
05/22/2022 23:23:17 - INFO - __main__ - Step 660 Global step 660 Train loss 2.068071 on epoch=27
05/22/2022 23:23:22 - INFO - __main__ - Step 670 Global step 670 Train loss 1.803941 on epoch=27
05/22/2022 23:23:27 - INFO - __main__ - Step 680 Global step 680 Train loss 2.036511 on epoch=28
05/22/2022 23:23:32 - INFO - __main__ - Step 690 Global step 690 Train loss 1.937931 on epoch=28
05/22/2022 23:23:37 - INFO - __main__ - Step 700 Global step 700 Train loss 1.890318 on epoch=29
05/22/2022 23:23:44 - INFO - __main__ - Global step 700 Train loss 1.947354 Classification-F1 0.16666666666666666 on epoch=29
05/22/2022 23:23:49 - INFO - __main__ - Step 710 Global step 710 Train loss 1.953127 on epoch=29
05/22/2022 23:23:54 - INFO - __main__ - Step 720 Global step 720 Train loss 2.414257 on epoch=29
05/22/2022 23:23:59 - INFO - __main__ - Step 730 Global step 730 Train loss 1.974527 on epoch=30
05/22/2022 23:24:04 - INFO - __main__ - Step 740 Global step 740 Train loss 1.673020 on epoch=30
05/22/2022 23:24:09 - INFO - __main__ - Step 750 Global step 750 Train loss 1.600961 on epoch=31
05/22/2022 23:24:15 - INFO - __main__ - Global step 750 Train loss 1.923179 Classification-F1 0.16666666666666666 on epoch=31
05/22/2022 23:24:20 - INFO - __main__ - Step 760 Global step 760 Train loss 1.776501 on epoch=31
05/22/2022 23:24:25 - INFO - __main__ - Step 770 Global step 770 Train loss 1.450650 on epoch=32
05/22/2022 23:24:30 - INFO - __main__ - Step 780 Global step 780 Train loss 1.760233 on epoch=32
05/22/2022 23:24:35 - INFO - __main__ - Step 790 Global step 790 Train loss 1.645016 on epoch=32
05/22/2022 23:24:40 - INFO - __main__ - Step 800 Global step 800 Train loss 1.301925 on epoch=33
05/22/2022 23:24:46 - INFO - __main__ - Global step 800 Train loss 1.586865 Classification-F1 0.16666666666666666 on epoch=33
05/22/2022 23:24:51 - INFO - __main__ - Step 810 Global step 810 Train loss 1.423165 on epoch=33
05/22/2022 23:24:56 - INFO - __main__ - Step 820 Global step 820 Train loss 1.430205 on epoch=34
05/22/2022 23:25:01 - INFO - __main__ - Step 830 Global step 830 Train loss 1.640751 on epoch=34
05/22/2022 23:25:06 - INFO - __main__ - Step 840 Global step 840 Train loss 1.464472 on epoch=34
05/22/2022 23:25:11 - INFO - __main__ - Step 850 Global step 850 Train loss 1.394248 on epoch=35
05/22/2022 23:25:17 - INFO - __main__ - Global step 850 Train loss 1.470568 Classification-F1 0.16666666666666666 on epoch=35
05/22/2022 23:25:22 - INFO - __main__ - Step 860 Global step 860 Train loss 1.504560 on epoch=35
05/22/2022 23:25:27 - INFO - __main__ - Step 870 Global step 870 Train loss 1.713786 on epoch=36
05/22/2022 23:25:32 - INFO - __main__ - Step 880 Global step 880 Train loss 1.422674 on epoch=36
05/22/2022 23:25:37 - INFO - __main__ - Step 890 Global step 890 Train loss 1.506948 on epoch=37
05/22/2022 23:25:42 - INFO - __main__ - Step 900 Global step 900 Train loss 1.061144 on epoch=37
05/22/2022 23:25:48 - INFO - __main__ - Global step 900 Train loss 1.441822 Classification-F1 0.16666666666666666 on epoch=37
05/22/2022 23:25:53 - INFO - __main__ - Step 910 Global step 910 Train loss 1.176704 on epoch=37
05/22/2022 23:25:59 - INFO - __main__ - Step 920 Global step 920 Train loss 1.309396 on epoch=38
05/22/2022 23:26:04 - INFO - __main__ - Step 930 Global step 930 Train loss 1.293468 on epoch=38
05/22/2022 23:26:09 - INFO - __main__ - Step 940 Global step 940 Train loss 1.583697 on epoch=39
05/22/2022 23:26:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.992055 on epoch=39
05/22/2022 23:26:20 - INFO - __main__ - Global step 950 Train loss 1.271064 Classification-F1 0.16666666666666666 on epoch=39
05/22/2022 23:26:25 - INFO - __main__ - Step 960 Global step 960 Train loss 1.198879 on epoch=39
05/22/2022 23:26:30 - INFO - __main__ - Step 970 Global step 970 Train loss 1.250417 on epoch=40
05/22/2022 23:26:35 - INFO - __main__ - Step 980 Global step 980 Train loss 1.267116 on epoch=40
05/22/2022 23:26:40 - INFO - __main__ - Step 990 Global step 990 Train loss 1.237673 on epoch=41
05/22/2022 23:26:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.233241 on epoch=41
05/22/2022 23:26:46 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:26:46 - INFO - __main__ - Printing 3 examples
05/22/2022 23:26:46 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/22/2022 23:26:46 - INFO - __main__ - ['entailment']
05/22/2022 23:26:46 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/22/2022 23:26:46 - INFO - __main__ - ['entailment']
05/22/2022 23:26:46 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/22/2022 23:26:46 - INFO - __main__ - ['entailment']
05/22/2022 23:26:46 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:26:46 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:26:46 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:26:46 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:26:46 - INFO - __main__ - Printing 3 examples
05/22/2022 23:26:46 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/22/2022 23:26:46 - INFO - __main__ - ['entailment']
05/22/2022 23:26:46 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/22/2022 23:26:46 - INFO - __main__ - ['entailment']
05/22/2022 23:26:46 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/22/2022 23:26:46 - INFO - __main__ - ['entailment']
05/22/2022 23:26:46 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:26:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:26:47 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:26:51 - INFO - __main__ - Global step 1000 Train loss 1.237465 Classification-F1 0.29330880722215696 on epoch=41
05/22/2022 23:26:52 - INFO - __main__ - save last model!
05/22/2022 23:26:59 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 23:26:59 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 23:26:59 - INFO - __main__ - Printing 3 examples
05/22/2022 23:26:59 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 23:26:59 - INFO - __main__ - ['contradiction']
05/22/2022 23:26:59 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 23:26:59 - INFO - __main__ - ['entailment']
05/22/2022 23:26:59 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 23:26:59 - INFO - __main__ - ['contradiction']
05/22/2022 23:26:59 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:27:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:27:00 - INFO - __main__ - Starting training!
05/22/2022 23:27:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:27:01 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 23:27:18 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_13_0.0001_8_predictions.txt
05/22/2022 23:27:18 - INFO - __main__ - Classification-F1 on test data: 0.2818
05/22/2022 23:27:18 - INFO - __main__ - prefix=anli_128_13, lr=0.0001, bsz=8, dev_performance=0.29330880722215696, test_performance=0.2817958565990062
05/22/2022 23:27:18 - INFO - __main__ - Running ... prefix=anli_128_21, lr=0.0005, bsz=8 ...
05/22/2022 23:27:19 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:27:19 - INFO - __main__ - Printing 3 examples
05/22/2022 23:27:19 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/22/2022 23:27:19 - INFO - __main__ - ['entailment']
05/22/2022 23:27:19 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/22/2022 23:27:19 - INFO - __main__ - ['entailment']
05/22/2022 23:27:19 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/22/2022 23:27:19 - INFO - __main__ - ['entailment']
05/22/2022 23:27:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:27:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:27:19 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:27:19 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:27:19 - INFO - __main__ - Printing 3 examples
05/22/2022 23:27:19 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/22/2022 23:27:19 - INFO - __main__ - ['entailment']
05/22/2022 23:27:19 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/22/2022 23:27:19 - INFO - __main__ - ['entailment']
05/22/2022 23:27:19 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/22/2022 23:27:19 - INFO - __main__ - ['entailment']
05/22/2022 23:27:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:27:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:27:20 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:27:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:27:33 - INFO - __main__ - Starting training!
05/22/2022 23:27:37 - INFO - __main__ - Step 10 Global step 10 Train loss 23.900951 on epoch=0
05/22/2022 23:27:42 - INFO - __main__ - Step 20 Global step 20 Train loss 14.533491 on epoch=0
05/22/2022 23:27:47 - INFO - __main__ - Step 30 Global step 30 Train loss 12.107264 on epoch=1
05/22/2022 23:27:52 - INFO - __main__ - Step 40 Global step 40 Train loss 10.924265 on epoch=1
05/22/2022 23:27:57 - INFO - __main__ - Step 50 Global step 50 Train loss 9.693037 on epoch=2
05/22/2022 23:28:13 - INFO - __main__ - Global step 50 Train loss 14.231803 Classification-F1 0.002876318312559923 on epoch=2
05/22/2022 23:28:18 - INFO - __main__ - Step 60 Global step 60 Train loss 8.564810 on epoch=2
05/22/2022 23:28:23 - INFO - __main__ - Step 70 Global step 70 Train loss 7.181731 on epoch=2
05/22/2022 23:28:29 - INFO - __main__ - Step 80 Global step 80 Train loss 5.299767 on epoch=3
05/22/2022 23:28:34 - INFO - __main__ - Step 90 Global step 90 Train loss 3.234098 on epoch=3
05/22/2022 23:28:39 - INFO - __main__ - Step 100 Global step 100 Train loss 2.146217 on epoch=4
05/22/2022 23:28:45 - INFO - __main__ - Global step 100 Train loss 5.285325 Classification-F1 0.16666666666666666 on epoch=4
05/22/2022 23:28:51 - INFO - __main__ - Step 110 Global step 110 Train loss 1.863215 on epoch=4
05/22/2022 23:28:56 - INFO - __main__ - Step 120 Global step 120 Train loss 1.779718 on epoch=4
05/22/2022 23:29:01 - INFO - __main__ - Step 130 Global step 130 Train loss 2.395470 on epoch=5
05/22/2022 23:29:06 - INFO - __main__ - Step 140 Global step 140 Train loss 1.852443 on epoch=5
05/22/2022 23:29:11 - INFO - __main__ - Step 150 Global step 150 Train loss 1.904830 on epoch=6
05/22/2022 23:29:17 - INFO - __main__ - Global step 150 Train loss 1.959135 Classification-F1 0.16666666666666666 on epoch=6
05/22/2022 23:29:23 - INFO - __main__ - Step 160 Global step 160 Train loss 1.819512 on epoch=6
05/22/2022 23:29:28 - INFO - __main__ - Step 170 Global step 170 Train loss 1.754011 on epoch=7
05/22/2022 23:29:33 - INFO - __main__ - Step 180 Global step 180 Train loss 1.718710 on epoch=7
05/22/2022 23:29:38 - INFO - __main__ - Step 190 Global step 190 Train loss 1.185272 on epoch=7
05/22/2022 23:29:43 - INFO - __main__ - Step 200 Global step 200 Train loss 1.434632 on epoch=8
05/22/2022 23:29:49 - INFO - __main__ - Global step 200 Train loss 1.582427 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 23:29:55 - INFO - __main__ - Step 210 Global step 210 Train loss 1.231435 on epoch=8
05/22/2022 23:30:00 - INFO - __main__ - Step 220 Global step 220 Train loss 1.256409 on epoch=9
05/22/2022 23:30:05 - INFO - __main__ - Step 230 Global step 230 Train loss 1.135002 on epoch=9
05/22/2022 23:30:10 - INFO - __main__ - Step 240 Global step 240 Train loss 1.019642 on epoch=9
05/22/2022 23:30:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.963992 on epoch=10
05/22/2022 23:30:22 - INFO - __main__ - Global step 250 Train loss 1.121296 Classification-F1 0.23365079365079364 on epoch=10
05/22/2022 23:30:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.899789 on epoch=10
05/22/2022 23:30:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.768046 on epoch=11
05/22/2022 23:30:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.881835 on epoch=11
05/22/2022 23:30:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.801580 on epoch=12
05/22/2022 23:30:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.603800 on epoch=12
05/22/2022 23:30:55 - INFO - __main__ - Global step 300 Train loss 0.791010 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 23:31:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.766874 on epoch=12
05/22/2022 23:31:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.770463 on epoch=13
05/22/2022 23:31:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.693307 on epoch=13
05/22/2022 23:31:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.547190 on epoch=14
05/22/2022 23:31:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.503442 on epoch=14
05/22/2022 23:31:27 - INFO - __main__ - Global step 350 Train loss 0.656255 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 23:31:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.613802 on epoch=14
05/22/2022 23:31:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.513565 on epoch=15
05/22/2022 23:31:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.607822 on epoch=15
05/22/2022 23:31:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.525531 on epoch=16
05/22/2022 23:31:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.507643 on epoch=16
05/22/2022 23:32:00 - INFO - __main__ - Global step 400 Train loss 0.553672 Classification-F1 0.30023540794064746 on epoch=16
05/22/2022 23:32:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.447272 on epoch=17
05/22/2022 23:32:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.488406 on epoch=17
05/22/2022 23:32:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.572211 on epoch=17
05/22/2022 23:32:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.555540 on epoch=18
05/22/2022 23:32:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.475746 on epoch=18
05/22/2022 23:32:33 - INFO - __main__ - Global step 450 Train loss 0.507835 Classification-F1 0.1784113322574861 on epoch=18
05/22/2022 23:32:38 - INFO - __main__ - Step 460 Global step 460 Train loss 1.359834 on epoch=19
05/22/2022 23:32:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.455084 on epoch=19
05/22/2022 23:32:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.413885 on epoch=19
05/22/2022 23:32:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.506456 on epoch=20
05/22/2022 23:32:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.389817 on epoch=20
05/22/2022 23:33:07 - INFO - __main__ - Global step 500 Train loss 0.625015 Classification-F1 0.17651734429130608 on epoch=20
05/22/2022 23:33:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.504807 on epoch=21
05/22/2022 23:33:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.464563 on epoch=21
05/22/2022 23:33:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.390840 on epoch=22
05/22/2022 23:33:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.428167 on epoch=22
05/22/2022 23:33:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.362939 on epoch=22
05/22/2022 23:33:40 - INFO - __main__ - Global step 550 Train loss 0.430263 Classification-F1 0.39555822520609957 on epoch=22
05/22/2022 23:33:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.394337 on epoch=23
05/22/2022 23:33:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.367927 on epoch=23
05/22/2022 23:33:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.396716 on epoch=24
05/22/2022 23:34:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.373001 on epoch=24
05/22/2022 23:34:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.366563 on epoch=24
05/22/2022 23:34:13 - INFO - __main__ - Global step 600 Train loss 0.379709 Classification-F1 0.3797011548064919 on epoch=24
05/22/2022 23:34:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.243907 on epoch=25
05/22/2022 23:34:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.316483 on epoch=25
05/22/2022 23:34:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.280276 on epoch=26
05/22/2022 23:34:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.220411 on epoch=26
05/22/2022 23:34:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.227014 on epoch=27
05/22/2022 23:34:45 - INFO - __main__ - Global step 650 Train loss 0.257618 Classification-F1 0.40622632595121716 on epoch=27
05/22/2022 23:34:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.282643 on epoch=27
05/22/2022 23:34:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.160337 on epoch=27
05/22/2022 23:35:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.230383 on epoch=28
05/22/2022 23:35:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.141907 on epoch=28
05/22/2022 23:35:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.096074 on epoch=29
05/22/2022 23:35:18 - INFO - __main__ - Global step 700 Train loss 0.182269 Classification-F1 0.3888797243945985 on epoch=29
05/22/2022 23:35:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.128932 on epoch=29
05/22/2022 23:35:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.115611 on epoch=29
05/22/2022 23:35:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.204255 on epoch=30
05/22/2022 23:35:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.114250 on epoch=30
05/22/2022 23:35:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.080293 on epoch=31
05/22/2022 23:35:51 - INFO - __main__ - Global step 750 Train loss 0.128668 Classification-F1 0.4699792717645774 on epoch=31
05/22/2022 23:35:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.064687 on epoch=31
05/22/2022 23:36:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.098166 on epoch=32
05/22/2022 23:36:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.058702 on epoch=32
05/22/2022 23:36:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.064034 on epoch=32
05/22/2022 23:36:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.043792 on epoch=33
05/22/2022 23:36:24 - INFO - __main__ - Global step 800 Train loss 0.065876 Classification-F1 0.5086338923204013 on epoch=33
05/22/2022 23:36:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.076117 on epoch=33
05/22/2022 23:36:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.045987 on epoch=34
05/22/2022 23:36:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.054621 on epoch=34
05/22/2022 23:36:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.038085 on epoch=34
05/22/2022 23:36:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.021371 on epoch=35
05/22/2022 23:36:57 - INFO - __main__ - Global step 850 Train loss 0.047236 Classification-F1 0.49668999464098346 on epoch=35
05/22/2022 23:37:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.015502 on epoch=35
05/22/2022 23:37:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.006762 on epoch=36
05/22/2022 23:37:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.038541 on epoch=36
05/22/2022 23:37:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.009775 on epoch=37
05/22/2022 23:37:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.009883 on epoch=37
05/22/2022 23:37:29 - INFO - __main__ - Global step 900 Train loss 0.016093 Classification-F1 0.5045326753750146 on epoch=37
05/22/2022 23:37:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.006224 on epoch=37
05/22/2022 23:37:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.015834 on epoch=38
05/22/2022 23:37:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.033697 on epoch=38
05/22/2022 23:37:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.028848 on epoch=39
05/22/2022 23:37:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.005728 on epoch=39
05/22/2022 23:38:02 - INFO - __main__ - Global step 950 Train loss 0.018066 Classification-F1 0.5242843814083514 on epoch=39
05/22/2022 23:38:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.039451 on epoch=39
05/22/2022 23:38:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.023568 on epoch=40
05/22/2022 23:38:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.007480 on epoch=40
05/22/2022 23:38:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.036958 on epoch=41
05/22/2022 23:38:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.003976 on epoch=41
05/22/2022 23:38:29 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:38:29 - INFO - __main__ - Printing 3 examples
05/22/2022 23:38:29 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/22/2022 23:38:29 - INFO - __main__ - ['entailment']
05/22/2022 23:38:29 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/22/2022 23:38:29 - INFO - __main__ - ['entailment']
05/22/2022 23:38:29 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/22/2022 23:38:29 - INFO - __main__ - ['entailment']
05/22/2022 23:38:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:38:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:38:30 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:38:30 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:38:30 - INFO - __main__ - Printing 3 examples
05/22/2022 23:38:30 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/22/2022 23:38:30 - INFO - __main__ - ['entailment']
05/22/2022 23:38:30 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/22/2022 23:38:30 - INFO - __main__ - ['entailment']
05/22/2022 23:38:30 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/22/2022 23:38:30 - INFO - __main__ - ['entailment']
05/22/2022 23:38:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:38:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:38:31 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:38:35 - INFO - __main__ - Global step 1000 Train loss 0.022287 Classification-F1 0.5129308694526086 on epoch=41
05/22/2022 23:38:35 - INFO - __main__ - save last model!
05/22/2022 23:38:42 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 23:38:43 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 23:38:43 - INFO - __main__ - Printing 3 examples
05/22/2022 23:38:43 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 23:38:43 - INFO - __main__ - ['contradiction']
05/22/2022 23:38:43 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 23:38:43 - INFO - __main__ - ['entailment']
05/22/2022 23:38:43 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 23:38:43 - INFO - __main__ - ['contradiction']
05/22/2022 23:38:43 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:38:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:38:43 - INFO - __main__ - Starting training!
05/22/2022 23:38:43 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:38:44 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 23:39:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_21_0.0005_8_predictions.txt
05/22/2022 23:39:02 - INFO - __main__ - Classification-F1 on test data: 0.3474
05/22/2022 23:39:02 - INFO - __main__ - prefix=anli_128_21, lr=0.0005, bsz=8, dev_performance=0.5242843814083514, test_performance=0.34742654532315376
05/22/2022 23:39:02 - INFO - __main__ - Running ... prefix=anli_128_21, lr=0.0003, bsz=8 ...
05/22/2022 23:39:03 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:39:03 - INFO - __main__ - Printing 3 examples
05/22/2022 23:39:03 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/22/2022 23:39:03 - INFO - __main__ - ['entailment']
05/22/2022 23:39:03 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/22/2022 23:39:03 - INFO - __main__ - ['entailment']
05/22/2022 23:39:03 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/22/2022 23:39:03 - INFO - __main__ - ['entailment']
05/22/2022 23:39:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:39:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:39:04 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:39:04 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:39:04 - INFO - __main__ - Printing 3 examples
05/22/2022 23:39:04 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/22/2022 23:39:04 - INFO - __main__ - ['entailment']
05/22/2022 23:39:04 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/22/2022 23:39:04 - INFO - __main__ - ['entailment']
05/22/2022 23:39:04 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/22/2022 23:39:04 - INFO - __main__ - ['entailment']
05/22/2022 23:39:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:39:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:39:05 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:39:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:39:15 - INFO - __main__ - Starting training!
05/22/2022 23:39:19 - INFO - __main__ - Step 10 Global step 10 Train loss 23.912794 on epoch=0
05/22/2022 23:39:24 - INFO - __main__ - Step 20 Global step 20 Train loss 18.980722 on epoch=0
05/22/2022 23:39:29 - INFO - __main__ - Step 30 Global step 30 Train loss 13.471092 on epoch=1
05/22/2022 23:39:34 - INFO - __main__ - Step 40 Global step 40 Train loss 12.531197 on epoch=1
05/22/2022 23:39:39 - INFO - __main__ - Step 50 Global step 50 Train loss 11.907396 on epoch=2
05/22/2022 23:39:54 - INFO - __main__ - Global step 50 Train loss 16.160641 Classification-F1 0.04918032786885245 on epoch=2
05/22/2022 23:40:00 - INFO - __main__ - Step 60 Global step 60 Train loss 11.001379 on epoch=2
05/22/2022 23:40:05 - INFO - __main__ - Step 70 Global step 70 Train loss 8.967354 on epoch=2
05/22/2022 23:40:10 - INFO - __main__ - Step 80 Global step 80 Train loss 9.051915 on epoch=3
05/22/2022 23:40:15 - INFO - __main__ - Step 90 Global step 90 Train loss 8.308031 on epoch=3
05/22/2022 23:40:20 - INFO - __main__ - Step 100 Global step 100 Train loss 7.521564 on epoch=4
05/22/2022 23:40:28 - INFO - __main__ - Global step 100 Train loss 8.970048 Classification-F1 0.013245033112582781 on epoch=4
05/22/2022 23:40:34 - INFO - __main__ - Step 110 Global step 110 Train loss 6.969570 on epoch=4
05/22/2022 23:40:39 - INFO - __main__ - Step 120 Global step 120 Train loss 5.737573 on epoch=4
05/22/2022 23:40:44 - INFO - __main__ - Step 130 Global step 130 Train loss 5.313455 on epoch=5
05/22/2022 23:40:49 - INFO - __main__ - Step 140 Global step 140 Train loss 3.223166 on epoch=5
05/22/2022 23:40:54 - INFO - __main__ - Step 150 Global step 150 Train loss 3.203067 on epoch=6
05/22/2022 23:41:01 - INFO - __main__ - Global step 150 Train loss 4.889366 Classification-F1 0.16666666666666666 on epoch=6
05/22/2022 23:41:07 - INFO - __main__ - Step 160 Global step 160 Train loss 2.729590 on epoch=6
05/22/2022 23:41:12 - INFO - __main__ - Step 170 Global step 170 Train loss 2.560569 on epoch=7
05/22/2022 23:41:17 - INFO - __main__ - Step 180 Global step 180 Train loss 2.391154 on epoch=7
05/22/2022 23:41:22 - INFO - __main__ - Step 190 Global step 190 Train loss 2.154176 on epoch=7
05/22/2022 23:41:27 - INFO - __main__ - Step 200 Global step 200 Train loss 2.524890 on epoch=8
05/22/2022 23:41:34 - INFO - __main__ - Global step 200 Train loss 2.472076 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 23:41:39 - INFO - __main__ - Step 210 Global step 210 Train loss 1.788424 on epoch=8
05/22/2022 23:41:44 - INFO - __main__ - Step 220 Global step 220 Train loss 1.861692 on epoch=9
05/22/2022 23:41:49 - INFO - __main__ - Step 230 Global step 230 Train loss 2.271581 on epoch=9
05/22/2022 23:41:54 - INFO - __main__ - Step 240 Global step 240 Train loss 2.340667 on epoch=9
05/22/2022 23:41:59 - INFO - __main__ - Step 250 Global step 250 Train loss 2.342000 on epoch=10
05/22/2022 23:42:06 - INFO - __main__ - Global step 250 Train loss 2.120873 Classification-F1 0.16666666666666666 on epoch=10
05/22/2022 23:42:11 - INFO - __main__ - Step 260 Global step 260 Train loss 1.494727 on epoch=10
05/22/2022 23:42:16 - INFO - __main__ - Step 270 Global step 270 Train loss 1.688731 on epoch=11
05/22/2022 23:42:21 - INFO - __main__ - Step 280 Global step 280 Train loss 1.601695 on epoch=11
05/22/2022 23:42:27 - INFO - __main__ - Step 290 Global step 290 Train loss 1.858570 on epoch=12
05/22/2022 23:42:32 - INFO - __main__ - Step 300 Global step 300 Train loss 1.612503 on epoch=12
05/22/2022 23:42:38 - INFO - __main__ - Global step 300 Train loss 1.651245 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 23:42:43 - INFO - __main__ - Step 310 Global step 310 Train loss 1.269386 on epoch=12
05/22/2022 23:42:49 - INFO - __main__ - Step 320 Global step 320 Train loss 1.217664 on epoch=13
05/22/2022 23:42:54 - INFO - __main__ - Step 330 Global step 330 Train loss 1.450570 on epoch=13
05/22/2022 23:42:59 - INFO - __main__ - Step 340 Global step 340 Train loss 1.245833 on epoch=14
05/22/2022 23:43:04 - INFO - __main__ - Step 350 Global step 350 Train loss 1.403381 on epoch=14
05/22/2022 23:43:11 - INFO - __main__ - Global step 350 Train loss 1.317367 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 23:43:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.973851 on epoch=14
05/22/2022 23:43:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.938756 on epoch=15
05/22/2022 23:43:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.967025 on epoch=15
05/22/2022 23:43:31 - INFO - __main__ - Step 390 Global step 390 Train loss 1.337219 on epoch=16
05/22/2022 23:43:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.790675 on epoch=16
05/22/2022 23:43:43 - INFO - __main__ - Global step 400 Train loss 1.001505 Classification-F1 0.1775766716943188 on epoch=16
05/22/2022 23:43:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.846955 on epoch=17
05/22/2022 23:43:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.908736 on epoch=17
05/22/2022 23:43:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.991459 on epoch=17
05/22/2022 23:44:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.709796 on epoch=18
05/22/2022 23:44:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.839910 on epoch=18
05/22/2022 23:44:16 - INFO - __main__ - Global step 450 Train loss 0.859371 Classification-F1 0.20342857142857143 on epoch=18
05/22/2022 23:44:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.723123 on epoch=19
05/22/2022 23:44:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.758222 on epoch=19
05/22/2022 23:44:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.674185 on epoch=19
05/22/2022 23:44:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.725671 on epoch=20
05/22/2022 23:44:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.548103 on epoch=20
05/22/2022 23:44:49 - INFO - __main__ - Global step 500 Train loss 0.685861 Classification-F1 0.24145520225562037 on epoch=20
05/22/2022 23:44:55 - INFO - __main__ - Step 510 Global step 510 Train loss 1.210588 on epoch=21
05/22/2022 23:45:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.780084 on epoch=21
05/22/2022 23:45:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.742383 on epoch=22
05/22/2022 23:45:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.575252 on epoch=22
05/22/2022 23:45:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.523080 on epoch=22
05/22/2022 23:45:24 - INFO - __main__ - Global step 550 Train loss 0.766277 Classification-F1 0.18751797526603395 on epoch=22
05/22/2022 23:45:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.614447 on epoch=23
05/22/2022 23:45:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.552954 on epoch=23
05/22/2022 23:45:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.481065 on epoch=24
05/22/2022 23:45:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.496138 on epoch=24
05/22/2022 23:45:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.538403 on epoch=24
05/22/2022 23:45:56 - INFO - __main__ - Global step 600 Train loss 0.536601 Classification-F1 0.26449601247226723 on epoch=24
05/22/2022 23:46:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.548542 on epoch=25
05/22/2022 23:46:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.455673 on epoch=25
05/22/2022 23:46:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.554543 on epoch=26
05/22/2022 23:46:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.491586 on epoch=26
05/22/2022 23:46:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.469080 on epoch=27
05/22/2022 23:46:29 - INFO - __main__ - Global step 650 Train loss 0.503885 Classification-F1 0.17673037202575304 on epoch=27
05/22/2022 23:46:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.459791 on epoch=27
05/22/2022 23:46:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.406522 on epoch=27
05/22/2022 23:46:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.418015 on epoch=28
05/22/2022 23:46:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.567885 on epoch=28
05/22/2022 23:46:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.659188 on epoch=29
05/22/2022 23:47:02 - INFO - __main__ - Global step 700 Train loss 0.502280 Classification-F1 0.16666666666666666 on epoch=29
05/22/2022 23:47:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.699907 on epoch=29
05/22/2022 23:47:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.593938 on epoch=29
05/22/2022 23:47:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.450081 on epoch=30
05/22/2022 23:47:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.413918 on epoch=30
05/22/2022 23:47:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.487967 on epoch=31
05/22/2022 23:47:35 - INFO - __main__ - Global step 750 Train loss 0.529162 Classification-F1 0.27105612792635697 on epoch=31
05/22/2022 23:47:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.421222 on epoch=31
05/22/2022 23:47:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.475434 on epoch=32
05/22/2022 23:47:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.448577 on epoch=32
05/22/2022 23:47:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.385436 on epoch=32
05/22/2022 23:48:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.444410 on epoch=33
05/22/2022 23:48:09 - INFO - __main__ - Global step 800 Train loss 0.435016 Classification-F1 0.27003022873403637 on epoch=33
05/22/2022 23:48:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.406262 on epoch=33
05/22/2022 23:48:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.419858 on epoch=34
05/22/2022 23:48:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.411601 on epoch=34
05/22/2022 23:48:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.409041 on epoch=34
05/22/2022 23:48:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.430986 on epoch=35
05/22/2022 23:48:41 - INFO - __main__ - Global step 850 Train loss 0.415549 Classification-F1 0.2711111111111111 on epoch=35
05/22/2022 23:48:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.360989 on epoch=35
05/22/2022 23:48:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.403233 on epoch=36
05/22/2022 23:48:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.375699 on epoch=36
05/22/2022 23:49:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.387757 on epoch=37
05/22/2022 23:49:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.434621 on epoch=37
05/22/2022 23:49:15 - INFO - __main__ - Global step 900 Train loss 0.392460 Classification-F1 0.25298415530351304 on epoch=37
05/22/2022 23:49:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.397312 on epoch=37
05/22/2022 23:49:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.423008 on epoch=38
05/22/2022 23:49:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.362001 on epoch=38
05/22/2022 23:49:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.388157 on epoch=39
05/22/2022 23:49:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.352762 on epoch=39
05/22/2022 23:49:48 - INFO - __main__ - Global step 950 Train loss 0.384648 Classification-F1 0.38413343295663277 on epoch=39
05/22/2022 23:49:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.399899 on epoch=39
05/22/2022 23:49:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.390128 on epoch=40
05/22/2022 23:50:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.348460 on epoch=40
05/22/2022 23:50:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.328534 on epoch=41
05/22/2022 23:50:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.311044 on epoch=41
05/22/2022 23:50:15 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:50:15 - INFO - __main__ - Printing 3 examples
05/22/2022 23:50:15 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/22/2022 23:50:15 - INFO - __main__ - ['entailment']
05/22/2022 23:50:15 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/22/2022 23:50:15 - INFO - __main__ - ['entailment']
05/22/2022 23:50:15 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/22/2022 23:50:15 - INFO - __main__ - ['entailment']
05/22/2022 23:50:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:50:15 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:50:16 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:50:16 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:50:16 - INFO - __main__ - Printing 3 examples
05/22/2022 23:50:16 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/22/2022 23:50:16 - INFO - __main__ - ['entailment']
05/22/2022 23:50:16 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/22/2022 23:50:16 - INFO - __main__ - ['entailment']
05/22/2022 23:50:16 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/22/2022 23:50:16 - INFO - __main__ - ['entailment']
05/22/2022 23:50:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:50:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:50:16 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:50:21 - INFO - __main__ - Global step 1000 Train loss 0.355613 Classification-F1 0.43831438894206093 on epoch=41
05/22/2022 23:50:21 - INFO - __main__ - save last model!
05/22/2022 23:50:29 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 23:50:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:50:29 - INFO - __main__ - Starting training!
05/22/2022 23:50:29 - INFO - __main__ - Start tokenizing ... 1000 instances
05/22/2022 23:50:29 - INFO - __main__ - Printing 3 examples
05/22/2022 23:50:29 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/22/2022 23:50:29 - INFO - __main__ - ['contradiction']
05/22/2022 23:50:29 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/22/2022 23:50:29 - INFO - __main__ - ['entailment']
05/22/2022 23:50:29 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/22/2022 23:50:29 - INFO - __main__ - ['contradiction']
05/22/2022 23:50:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:50:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:50:31 - INFO - __main__ - Loaded 1000 examples from test data
05/22/2022 23:50:48 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_21_0.0003_8_predictions.txt
05/22/2022 23:50:48 - INFO - __main__ - Classification-F1 on test data: 0.3617
05/22/2022 23:50:49 - INFO - __main__ - prefix=anli_128_21, lr=0.0003, bsz=8, dev_performance=0.43831438894206093, test_performance=0.3617011834657459
05/22/2022 23:50:49 - INFO - __main__ - Running ... prefix=anli_128_21, lr=0.0002, bsz=8 ...
05/22/2022 23:50:50 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:50:50 - INFO - __main__ - Printing 3 examples
05/22/2022 23:50:50 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/22/2022 23:50:50 - INFO - __main__ - ['entailment']
05/22/2022 23:50:50 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/22/2022 23:50:50 - INFO - __main__ - ['entailment']
05/22/2022 23:50:50 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/22/2022 23:50:50 - INFO - __main__ - ['entailment']
05/22/2022 23:50:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:50:50 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:50:50 - INFO - __main__ - Loaded 384 examples from train data
05/22/2022 23:50:50 - INFO - __main__ - Start tokenizing ... 384 instances
05/22/2022 23:50:50 - INFO - __main__ - Printing 3 examples
05/22/2022 23:50:50 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/22/2022 23:50:50 - INFO - __main__ - ['entailment']
05/22/2022 23:50:50 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/22/2022 23:50:50 - INFO - __main__ - ['entailment']
05/22/2022 23:50:50 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/22/2022 23:50:50 - INFO - __main__ - ['entailment']
05/22/2022 23:50:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 23:50:50 - INFO - __main__ - Tokenizing Output ...
05/22/2022 23:50:51 - INFO - __main__ - Loaded 384 examples from dev data
05/22/2022 23:51:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 23:51:04 - INFO - __main__ - Starting training!
05/22/2022 23:51:08 - INFO - __main__ - Step 10 Global step 10 Train loss 25.778133 on epoch=0
05/22/2022 23:51:12 - INFO - __main__ - Step 20 Global step 20 Train loss 20.556610 on epoch=0
05/22/2022 23:51:18 - INFO - __main__ - Step 30 Global step 30 Train loss 15.436487 on epoch=1
05/22/2022 23:51:23 - INFO - __main__ - Step 40 Global step 40 Train loss 13.078374 on epoch=1
05/22/2022 23:51:28 - INFO - __main__ - Step 50 Global step 50 Train loss 12.014143 on epoch=2
05/22/2022 23:51:35 - INFO - __main__ - Global step 50 Train loss 17.372749 Classification-F1 0.0 on epoch=2
05/22/2022 23:51:40 - INFO - __main__ - Step 60 Global step 60 Train loss 11.446535 on epoch=2
05/22/2022 23:51:45 - INFO - __main__ - Step 70 Global step 70 Train loss 10.009584 on epoch=2
05/22/2022 23:51:50 - INFO - __main__ - Step 80 Global step 80 Train loss 9.978960 on epoch=3
05/22/2022 23:51:56 - INFO - __main__ - Step 90 Global step 90 Train loss 9.700262 on epoch=3
05/22/2022 23:52:01 - INFO - __main__ - Step 100 Global step 100 Train loss 8.678344 on epoch=4
05/22/2022 23:52:07 - INFO - __main__ - Global step 100 Train loss 9.962737 Classification-F1 0.0 on epoch=4
05/22/2022 23:52:12 - INFO - __main__ - Step 110 Global step 110 Train loss 9.038271 on epoch=4
05/22/2022 23:52:18 - INFO - __main__ - Step 120 Global step 120 Train loss 8.071596 on epoch=4
05/22/2022 23:52:23 - INFO - __main__ - Step 130 Global step 130 Train loss 8.484121 on epoch=5
05/22/2022 23:52:28 - INFO - __main__ - Step 140 Global step 140 Train loss 6.943550 on epoch=5
05/22/2022 23:52:33 - INFO - __main__ - Step 150 Global step 150 Train loss 6.611027 on epoch=6
05/22/2022 23:52:40 - INFO - __main__ - Global step 150 Train loss 7.829712 Classification-F1 0.0 on epoch=6
05/22/2022 23:52:45 - INFO - __main__ - Step 160 Global step 160 Train loss 6.442945 on epoch=6
05/22/2022 23:52:50 - INFO - __main__ - Step 170 Global step 170 Train loss 5.058846 on epoch=7
05/22/2022 23:52:55 - INFO - __main__ - Step 180 Global step 180 Train loss 4.414524 on epoch=7
05/22/2022 23:53:00 - INFO - __main__ - Step 190 Global step 190 Train loss 3.357788 on epoch=7
05/22/2022 23:53:05 - INFO - __main__ - Step 200 Global step 200 Train loss 3.214586 on epoch=8
05/22/2022 23:53:11 - INFO - __main__ - Global step 200 Train loss 4.497738 Classification-F1 0.16666666666666666 on epoch=8
05/22/2022 23:53:16 - INFO - __main__ - Step 210 Global step 210 Train loss 2.704484 on epoch=8
05/22/2022 23:53:21 - INFO - __main__ - Step 220 Global step 220 Train loss 2.900792 on epoch=9
05/22/2022 23:53:27 - INFO - __main__ - Step 230 Global step 230 Train loss 2.877245 on epoch=9
05/22/2022 23:53:32 - INFO - __main__ - Step 240 Global step 240 Train loss 2.412205 on epoch=9
05/22/2022 23:53:37 - INFO - __main__ - Step 250 Global step 250 Train loss 2.630600 on epoch=10
05/22/2022 23:53:43 - INFO - __main__ - Global step 250 Train loss 2.705066 Classification-F1 0.24603985278142582 on epoch=10
05/22/2022 23:53:49 - INFO - __main__ - Step 260 Global step 260 Train loss 2.585850 on epoch=10
05/22/2022 23:53:54 - INFO - __main__ - Step 270 Global step 270 Train loss 2.528624 on epoch=11
05/22/2022 23:53:59 - INFO - __main__ - Step 280 Global step 280 Train loss 2.129241 on epoch=11
05/22/2022 23:54:04 - INFO - __main__ - Step 290 Global step 290 Train loss 2.760857 on epoch=12
05/22/2022 23:54:09 - INFO - __main__ - Step 300 Global step 300 Train loss 2.115287 on epoch=12
05/22/2022 23:54:15 - INFO - __main__ - Global step 300 Train loss 2.423972 Classification-F1 0.16666666666666666 on epoch=12
05/22/2022 23:54:20 - INFO - __main__ - Step 310 Global step 310 Train loss 1.899508 on epoch=12
05/22/2022 23:54:26 - INFO - __main__ - Step 320 Global step 320 Train loss 1.862023 on epoch=13
05/22/2022 23:54:31 - INFO - __main__ - Step 330 Global step 330 Train loss 1.765114 on epoch=13
05/22/2022 23:54:36 - INFO - __main__ - Step 340 Global step 340 Train loss 1.970179 on epoch=14
05/22/2022 23:54:41 - INFO - __main__ - Step 350 Global step 350 Train loss 1.979759 on epoch=14
05/22/2022 23:54:47 - INFO - __main__ - Global step 350 Train loss 1.895317 Classification-F1 0.16666666666666666 on epoch=14
05/22/2022 23:54:52 - INFO - __main__ - Step 360 Global step 360 Train loss 1.899258 on epoch=14
05/22/2022 23:54:57 - INFO - __main__ - Step 370 Global step 370 Train loss 1.742357 on epoch=15
05/22/2022 23:55:02 - INFO - __main__ - Step 380 Global step 380 Train loss 1.339563 on epoch=15
05/22/2022 23:55:07 - INFO - __main__ - Step 390 Global step 390 Train loss 1.551653 on epoch=16
05/22/2022 23:55:12 - INFO - __main__ - Step 400 Global step 400 Train loss 1.302286 on epoch=16
05/22/2022 23:55:19 - INFO - __main__ - Global step 400 Train loss 1.567023 Classification-F1 0.21161887694145756 on epoch=16
05/22/2022 23:55:24 - INFO - __main__ - Step 410 Global step 410 Train loss 1.502264 on epoch=17
05/22/2022 23:55:29 - INFO - __main__ - Step 420 Global step 420 Train loss 1.328419 on epoch=17
05/22/2022 23:55:34 - INFO - __main__ - Step 430 Global step 430 Train loss 1.260926 on epoch=17
05/22/2022 23:55:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.231066 on epoch=18
05/22/2022 23:55:44 - INFO - __main__ - Step 450 Global step 450 Train loss 1.236911 on epoch=18
05/22/2022 23:55:51 - INFO - __main__ - Global step 450 Train loss 1.311917 Classification-F1 0.19670546767293454 on epoch=18
05/22/2022 23:55:56 - INFO - __main__ - Step 460 Global step 460 Train loss 1.183245 on epoch=19
05/22/2022 23:56:01 - INFO - __main__ - Step 470 Global step 470 Train loss 1.240019 on epoch=19
05/22/2022 23:56:06 - INFO - __main__ - Step 480 Global step 480 Train loss 1.112102 on epoch=19
05/22/2022 23:56:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.985334 on epoch=20
05/22/2022 23:56:17 - INFO - __main__ - Step 500 Global step 500 Train loss 1.011268 on epoch=20
05/22/2022 23:56:23 - INFO - __main__ - Global step 500 Train loss 1.106394 Classification-F1 0.20153854856043893 on epoch=20
05/22/2022 23:56:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.950937 on epoch=21
05/22/2022 23:56:33 - INFO - __main__ - Step 520 Global step 520 Train loss 1.499771 on epoch=21
05/22/2022 23:56:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.851099 on epoch=22
05/22/2022 23:56:44 - INFO - __main__ - Step 540 Global step 540 Train loss 1.235846 on epoch=22
05/22/2022 23:56:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.782375 on epoch=22
05/22/2022 23:56:56 - INFO - __main__ - Global step 550 Train loss 1.064006 Classification-F1 0.3024366937410416 on epoch=22
05/22/2022 23:57:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.831295 on epoch=23
05/22/2022 23:57:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.749179 on epoch=23
05/22/2022 23:57:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.587627 on epoch=24
05/22/2022 23:57:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.605047 on epoch=24
05/22/2022 23:57:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.468046 on epoch=24
05/22/2022 23:57:29 - INFO - __main__ - Global step 600 Train loss 0.648239 Classification-F1 0.16568819308545338 on epoch=24
05/22/2022 23:57:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.475488 on epoch=25
05/22/2022 23:57:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.439291 on epoch=25
05/22/2022 23:57:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.486396 on epoch=26
05/22/2022 23:57:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.473461 on epoch=26
05/22/2022 23:57:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.424025 on epoch=27
05/22/2022 23:58:02 - INFO - __main__ - Global step 650 Train loss 0.459732 Classification-F1 0.3103304547171532 on epoch=27
05/22/2022 23:58:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.425296 on epoch=27
05/22/2022 23:58:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.417011 on epoch=27
05/22/2022 23:58:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.470986 on epoch=28
05/22/2022 23:58:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.440810 on epoch=28
05/22/2022 23:58:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.502863 on epoch=29
05/22/2022 23:58:34 - INFO - __main__ - Global step 700 Train loss 0.451393 Classification-F1 0.33753727674700323 on epoch=29
05/22/2022 23:58:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.340273 on epoch=29
05/22/2022 23:58:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.359281 on epoch=29
05/22/2022 23:58:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.326427 on epoch=30
05/22/2022 23:58:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.328537 on epoch=30
05/22/2022 23:59:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.329358 on epoch=31
05/22/2022 23:59:06 - INFO - __main__ - Global step 750 Train loss 0.336775 Classification-F1 0.3557535713564082 on epoch=31
05/22/2022 23:59:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.304957 on epoch=31
05/22/2022 23:59:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.301795 on epoch=32
05/22/2022 23:59:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.269510 on epoch=32
05/22/2022 23:59:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.263889 on epoch=32
05/22/2022 23:59:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.190231 on epoch=33
05/22/2022 23:59:39 - INFO - __main__ - Global step 800 Train loss 0.266076 Classification-F1 0.34367045063639495 on epoch=33
05/22/2022 23:59:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.237364 on epoch=33
05/22/2022 23:59:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.217770 on epoch=34
05/22/2022 23:59:54 - INFO - __main__ - Step 830 Global step 830 Train loss 0.232547 on epoch=34
05/23/2022 00:00:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.162483 on epoch=34
05/23/2022 00:00:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.207739 on epoch=35
05/23/2022 00:00:11 - INFO - __main__ - Global step 850 Train loss 0.211581 Classification-F1 0.3048557902693241 on epoch=35
05/23/2022 00:00:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.173683 on epoch=35
05/23/2022 00:00:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.116824 on epoch=36
05/23/2022 00:00:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.137470 on epoch=36
05/23/2022 00:00:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.116054 on epoch=37
05/23/2022 00:00:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.087979 on epoch=37
05/23/2022 00:00:44 - INFO - __main__ - Global step 900 Train loss 0.126402 Classification-F1 0.5303224339887214 on epoch=37
05/23/2022 00:00:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.119037 on epoch=37
05/23/2022 00:00:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.063904 on epoch=38
05/23/2022 00:01:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.092370 on epoch=38
05/23/2022 00:01:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.104442 on epoch=39
05/23/2022 00:01:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.079182 on epoch=39
05/23/2022 00:01:18 - INFO - __main__ - Global step 950 Train loss 0.091787 Classification-F1 0.5761390598953345 on epoch=39
05/23/2022 00:01:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.065269 on epoch=39
05/23/2022 00:01:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.063141 on epoch=40
05/23/2022 00:01:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.066167 on epoch=40
05/23/2022 00:01:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.038309 on epoch=41
05/23/2022 00:01:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.049866 on epoch=41
05/23/2022 00:01:45 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:01:45 - INFO - __main__ - Printing 3 examples
05/23/2022 00:01:45 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/23/2022 00:01:45 - INFO - __main__ - ['entailment']
05/23/2022 00:01:45 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/23/2022 00:01:45 - INFO - __main__ - ['entailment']
05/23/2022 00:01:45 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/23/2022 00:01:45 - INFO - __main__ - ['entailment']
05/23/2022 00:01:45 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:01:45 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:01:45 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:01:45 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:01:45 - INFO - __main__ - Printing 3 examples
05/23/2022 00:01:45 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/23/2022 00:01:45 - INFO - __main__ - ['entailment']
05/23/2022 00:01:45 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/23/2022 00:01:45 - INFO - __main__ - ['entailment']
05/23/2022 00:01:45 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/23/2022 00:01:45 - INFO - __main__ - ['entailment']
05/23/2022 00:01:45 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:01:46 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:01:46 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:01:50 - INFO - __main__ - Global step 1000 Train loss 0.056551 Classification-F1 0.5459178450228627 on epoch=41
05/23/2022 00:01:50 - INFO - __main__ - save last model!
05/23/2022 00:01:57 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 00:01:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:01:57 - INFO - __main__ - Starting training!
05/23/2022 00:01:58 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 00:01:58 - INFO - __main__ - Printing 3 examples
05/23/2022 00:01:58 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 00:01:58 - INFO - __main__ - ['contradiction']
05/23/2022 00:01:58 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 00:01:58 - INFO - __main__ - ['entailment']
05/23/2022 00:01:58 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 00:01:58 - INFO - __main__ - ['contradiction']
05/23/2022 00:01:58 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:01:58 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:01:59 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 00:02:19 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_21_0.0002_8_predictions.txt
05/23/2022 00:02:19 - INFO - __main__ - Classification-F1 on test data: 0.3755
05/23/2022 00:02:19 - INFO - __main__ - prefix=anli_128_21, lr=0.0002, bsz=8, dev_performance=0.5761390598953345, test_performance=0.3755386121686735
05/23/2022 00:02:19 - INFO - __main__ - Running ... prefix=anli_128_21, lr=0.0001, bsz=8 ...
05/23/2022 00:02:20 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:02:20 - INFO - __main__ - Printing 3 examples
05/23/2022 00:02:20 - INFO - __main__ -  [anli] premise: Bill Lowrey (born January 29, 1963) is an American musical entertainer and banjoist from California. He has been a featured performer or headliner at a variety of jazz festivals around the U.S. for over fifteen years. Lowrey has established himself in the four-string banjo community as one of its key figures as compared to the likes of Sean Moyses, Steve Peterson, and Buddy Wachter. [SEP] hypothesis: Bill Lowrey has played festivals for over a decade.
05/23/2022 00:02:20 - INFO - __main__ - ['entailment']
05/23/2022 00:02:20 - INFO - __main__ -  [anli] premise: Glassroth v. Moore, CV-01-T-1268-N, 229 F. Supp. 2d 1290 (M.D. Ala. 2002), and its companion case Maddox and Howard v. Moore, CV-01-T-1269-N, concern then-Alabama Supreme Court Chief Justice Roy S. Moore and a stone monument of the Ten Commandments in the rotunda of the Alabama Judicial Building in Montgomery, Alabama. [SEP] hypothesis: Justice Roy S. Moore was the Supreme Court Chief in Alabama. 
05/23/2022 00:02:20 - INFO - __main__ - ['entailment']
05/23/2022 00:02:20 - INFO - __main__ -  [anli] premise: 5...GO is an album by South Korean rock band F.T. Island. It was released on 13 May 2015. The album was released to celebrate the band's fifth anniversary in Japan. The title track "Primavera" is a collaboration with Japanese rock singer Takahiro Moriuchi from One Ok Rock. [SEP] hypothesis: 5 GO is a rock album.
05/23/2022 00:02:20 - INFO - __main__ - ['entailment']
05/23/2022 00:02:20 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:02:20 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:02:21 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:02:21 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:02:21 - INFO - __main__ - Printing 3 examples
05/23/2022 00:02:21 - INFO - __main__ -  [anli] premise: Terenzo is a "comune" (municipality) in the Province of Parma in the Italian region Emilia-Romagna, located about 100 km west of Bologna and about 30 km southwest of Parma. As of 31 December 2004, it had a population of 1,250 and an area of 72.4 km2 . [SEP] hypothesis: Terenzo has a small population.
05/23/2022 00:02:21 - INFO - __main__ - ['entailment']
05/23/2022 00:02:21 - INFO - __main__ -  [anli] premise: Brett McLaughlin, known professionally as Leland, is an American singer, songwriter, record producer, composer and lecturer. Based in Los Angeles, California, he has worked closely with a range of popular artists, including Troye Sivan, Daya, Capital Cities, Andy Grammer, Hilary Duff and Allie X. [SEP] hypothesis: Leland has worked with at least 6 popular artists.
05/23/2022 00:02:21 - INFO - __main__ - ['entailment']
05/23/2022 00:02:21 - INFO - __main__ -  [anli] premise: Amazon Fire TV refers to two digital media players and microconsoles developed by Amazon.com. It is a small network appliance and entertainment device designed to stream digital audio/video content to a high-definition television. The device also allows users to play video games with the included remote, via a mobile app, or with an optional game controller. [SEP] hypothesis: Amazon Fire TV refers to the digital media players and micro consoles developed by amazon.com
05/23/2022 00:02:21 - INFO - __main__ - ['entailment']
05/23/2022 00:02:21 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:02:21 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:02:22 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:02:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:02:32 - INFO - __main__ - Starting training!
05/23/2022 00:02:36 - INFO - __main__ - Step 10 Global step 10 Train loss 24.606993 on epoch=0
05/23/2022 00:02:41 - INFO - __main__ - Step 20 Global step 20 Train loss 22.698328 on epoch=0
05/23/2022 00:02:46 - INFO - __main__ - Step 30 Global step 30 Train loss 19.492285 on epoch=1
05/23/2022 00:02:51 - INFO - __main__ - Step 40 Global step 40 Train loss 15.176558 on epoch=1
05/23/2022 00:02:56 - INFO - __main__ - Step 50 Global step 50 Train loss 14.297333 on epoch=2
05/23/2022 00:03:15 - INFO - __main__ - Global step 50 Train loss 19.254299 Classification-F1 0.005451338784672118 on epoch=2
05/23/2022 00:03:20 - INFO - __main__ - Step 60 Global step 60 Train loss 14.237821 on epoch=2
05/23/2022 00:03:25 - INFO - __main__ - Step 70 Global step 70 Train loss 12.933383 on epoch=2
05/23/2022 00:03:30 - INFO - __main__ - Step 80 Global step 80 Train loss 12.433969 on epoch=3
05/23/2022 00:03:35 - INFO - __main__ - Step 90 Global step 90 Train loss 12.466246 on epoch=3
05/23/2022 00:03:40 - INFO - __main__ - Step 100 Global step 100 Train loss 11.576358 on epoch=4
05/23/2022 00:03:49 - INFO - __main__ - Global step 100 Train loss 12.729554 Classification-F1 0.03110957483581058 on epoch=4
05/23/2022 00:03:55 - INFO - __main__ - Step 110 Global step 110 Train loss 11.851460 on epoch=4
05/23/2022 00:04:00 - INFO - __main__ - Step 120 Global step 120 Train loss 11.147257 on epoch=4
05/23/2022 00:04:05 - INFO - __main__ - Step 130 Global step 130 Train loss 11.291086 on epoch=5
05/23/2022 00:04:10 - INFO - __main__ - Step 140 Global step 140 Train loss 10.564631 on epoch=5
05/23/2022 00:04:15 - INFO - __main__ - Step 150 Global step 150 Train loss 10.207637 on epoch=6
05/23/2022 00:04:23 - INFO - __main__ - Global step 150 Train loss 11.012416 Classification-F1 0.006122448979591836 on epoch=6
05/23/2022 00:04:28 - INFO - __main__ - Step 160 Global step 160 Train loss 10.988591 on epoch=6
05/23/2022 00:04:33 - INFO - __main__ - Step 170 Global step 170 Train loss 10.267196 on epoch=7
05/23/2022 00:04:38 - INFO - __main__ - Step 180 Global step 180 Train loss 10.278228 on epoch=7
05/23/2022 00:04:43 - INFO - __main__ - Step 190 Global step 190 Train loss 9.061648 on epoch=7
05/23/2022 00:04:48 - INFO - __main__ - Step 200 Global step 200 Train loss 8.951125 on epoch=8
05/23/2022 00:04:56 - INFO - __main__ - Global step 200 Train loss 9.909357 Classification-F1 0.016697588126159554 on epoch=8
05/23/2022 00:05:01 - INFO - __main__ - Step 210 Global step 210 Train loss 8.676557 on epoch=8
05/23/2022 00:05:06 - INFO - __main__ - Step 220 Global step 220 Train loss 8.977170 on epoch=9
05/23/2022 00:05:11 - INFO - __main__ - Step 230 Global step 230 Train loss 9.418662 on epoch=9
05/23/2022 00:05:16 - INFO - __main__ - Step 240 Global step 240 Train loss 8.197534 on epoch=9
05/23/2022 00:05:21 - INFO - __main__ - Step 250 Global step 250 Train loss 8.390920 on epoch=10
05/23/2022 00:05:29 - INFO - __main__ - Global step 250 Train loss 8.732168 Classification-F1 0.007407407407407408 on epoch=10
05/23/2022 00:05:34 - INFO - __main__ - Step 260 Global step 260 Train loss 7.915999 on epoch=10
05/23/2022 00:05:39 - INFO - __main__ - Step 270 Global step 270 Train loss 7.935446 on epoch=11
05/23/2022 00:05:44 - INFO - __main__ - Step 280 Global step 280 Train loss 7.734456 on epoch=11
05/23/2022 00:05:49 - INFO - __main__ - Step 290 Global step 290 Train loss 7.632155 on epoch=12
05/23/2022 00:05:54 - INFO - __main__ - Step 300 Global step 300 Train loss 7.461478 on epoch=12
05/23/2022 00:06:01 - INFO - __main__ - Global step 300 Train loss 7.735907 Classification-F1 0.005474452554744526 on epoch=12
05/23/2022 00:06:06 - INFO - __main__ - Step 310 Global step 310 Train loss 6.233027 on epoch=12
05/23/2022 00:06:11 - INFO - __main__ - Step 320 Global step 320 Train loss 6.722537 on epoch=13
05/23/2022 00:06:16 - INFO - __main__ - Step 330 Global step 330 Train loss 6.027271 on epoch=13
05/23/2022 00:06:21 - INFO - __main__ - Step 340 Global step 340 Train loss 6.115207 on epoch=14
05/23/2022 00:06:26 - INFO - __main__ - Step 350 Global step 350 Train loss 6.039529 on epoch=14
05/23/2022 00:06:33 - INFO - __main__ - Global step 350 Train loss 6.227515 Classification-F1 0.003076923076923077 on epoch=14
05/23/2022 00:06:38 - INFO - __main__ - Step 360 Global step 360 Train loss 4.943327 on epoch=14
05/23/2022 00:06:44 - INFO - __main__ - Step 370 Global step 370 Train loss 5.539787 on epoch=15
05/23/2022 00:06:49 - INFO - __main__ - Step 380 Global step 380 Train loss 4.591500 on epoch=15
05/23/2022 00:06:54 - INFO - __main__ - Step 390 Global step 390 Train loss 4.736445 on epoch=16
05/23/2022 00:06:59 - INFO - __main__ - Step 400 Global step 400 Train loss 4.784846 on epoch=16
05/23/2022 00:07:06 - INFO - __main__ - Global step 400 Train loss 4.919181 Classification-F1 0.0031007751937984496 on epoch=16
05/23/2022 00:07:11 - INFO - __main__ - Step 410 Global step 410 Train loss 3.734648 on epoch=17
05/23/2022 00:07:16 - INFO - __main__ - Step 420 Global step 420 Train loss 4.079181 on epoch=17
05/23/2022 00:07:21 - INFO - __main__ - Step 430 Global step 430 Train loss 3.427654 on epoch=17
05/23/2022 00:07:26 - INFO - __main__ - Step 440 Global step 440 Train loss 2.983587 on epoch=18
05/23/2022 00:07:31 - INFO - __main__ - Step 450 Global step 450 Train loss 2.694453 on epoch=18
05/23/2022 00:07:38 - INFO - __main__ - Global step 450 Train loss 3.383904 Classification-F1 0.08497577507816415 on epoch=18
05/23/2022 00:07:43 - INFO - __main__ - Step 460 Global step 460 Train loss 2.728428 on epoch=19
05/23/2022 00:07:48 - INFO - __main__ - Step 470 Global step 470 Train loss 2.977760 on epoch=19
05/23/2022 00:07:53 - INFO - __main__ - Step 480 Global step 480 Train loss 2.632342 on epoch=19
05/23/2022 00:07:58 - INFO - __main__ - Step 490 Global step 490 Train loss 2.880111 on epoch=20
05/23/2022 00:08:03 - INFO - __main__ - Step 500 Global step 500 Train loss 2.683308 on epoch=20
05/23/2022 00:08:10 - INFO - __main__ - Global step 500 Train loss 2.780390 Classification-F1 0.16666666666666666 on epoch=20
05/23/2022 00:08:16 - INFO - __main__ - Step 510 Global step 510 Train loss 2.579427 on epoch=21
05/23/2022 00:08:21 - INFO - __main__ - Step 520 Global step 520 Train loss 2.353331 on epoch=21
05/23/2022 00:08:26 - INFO - __main__ - Step 530 Global step 530 Train loss 2.367437 on epoch=22
05/23/2022 00:08:31 - INFO - __main__ - Step 540 Global step 540 Train loss 2.402308 on epoch=22
05/23/2022 00:08:36 - INFO - __main__ - Step 550 Global step 550 Train loss 1.924401 on epoch=22
05/23/2022 00:08:42 - INFO - __main__ - Global step 550 Train loss 2.325381 Classification-F1 0.16666666666666666 on epoch=22
05/23/2022 00:08:47 - INFO - __main__ - Step 560 Global step 560 Train loss 2.334220 on epoch=23
05/23/2022 00:08:52 - INFO - __main__ - Step 570 Global step 570 Train loss 2.154586 on epoch=23
05/23/2022 00:08:57 - INFO - __main__ - Step 580 Global step 580 Train loss 2.468390 on epoch=24
05/23/2022 00:09:02 - INFO - __main__ - Step 590 Global step 590 Train loss 2.692905 on epoch=24
05/23/2022 00:09:07 - INFO - __main__ - Step 600 Global step 600 Train loss 1.749254 on epoch=24
05/23/2022 00:09:14 - INFO - __main__ - Global step 600 Train loss 2.279871 Classification-F1 0.16666666666666666 on epoch=24
05/23/2022 00:09:19 - INFO - __main__ - Step 610 Global step 610 Train loss 2.374157 on epoch=25
05/23/2022 00:09:24 - INFO - __main__ - Step 620 Global step 620 Train loss 1.999932 on epoch=25
05/23/2022 00:09:29 - INFO - __main__ - Step 630 Global step 630 Train loss 2.181904 on epoch=26
05/23/2022 00:09:34 - INFO - __main__ - Step 640 Global step 640 Train loss 2.447376 on epoch=26
05/23/2022 00:09:39 - INFO - __main__ - Step 650 Global step 650 Train loss 2.026962 on epoch=27
05/23/2022 00:09:45 - INFO - __main__ - Global step 650 Train loss 2.206066 Classification-F1 0.16666666666666666 on epoch=27
05/23/2022 00:09:50 - INFO - __main__ - Step 660 Global step 660 Train loss 2.048675 on epoch=27
05/23/2022 00:09:55 - INFO - __main__ - Step 670 Global step 670 Train loss 2.164185 on epoch=27
05/23/2022 00:10:00 - INFO - __main__ - Step 680 Global step 680 Train loss 1.955213 on epoch=28
05/23/2022 00:10:05 - INFO - __main__ - Step 690 Global step 690 Train loss 2.198088 on epoch=28
05/23/2022 00:10:10 - INFO - __main__ - Step 700 Global step 700 Train loss 1.986204 on epoch=29
05/23/2022 00:10:17 - INFO - __main__ - Global step 700 Train loss 2.070473 Classification-F1 0.16666666666666666 on epoch=29
05/23/2022 00:10:22 - INFO - __main__ - Step 710 Global step 710 Train loss 2.109461 on epoch=29
05/23/2022 00:10:27 - INFO - __main__ - Step 720 Global step 720 Train loss 2.084379 on epoch=29
05/23/2022 00:10:32 - INFO - __main__ - Step 730 Global step 730 Train loss 2.032494 on epoch=30
05/23/2022 00:10:37 - INFO - __main__ - Step 740 Global step 740 Train loss 1.782471 on epoch=30
05/23/2022 00:10:42 - INFO - __main__ - Step 750 Global step 750 Train loss 2.105680 on epoch=31
05/23/2022 00:10:48 - INFO - __main__ - Global step 750 Train loss 2.022897 Classification-F1 0.16666666666666666 on epoch=31
05/23/2022 00:10:53 - INFO - __main__ - Step 760 Global step 760 Train loss 1.926188 on epoch=31
05/23/2022 00:10:58 - INFO - __main__ - Step 770 Global step 770 Train loss 2.237236 on epoch=32
05/23/2022 00:11:03 - INFO - __main__ - Step 780 Global step 780 Train loss 1.824332 on epoch=32
05/23/2022 00:11:08 - INFO - __main__ - Step 790 Global step 790 Train loss 1.763100 on epoch=32
05/23/2022 00:11:13 - INFO - __main__ - Step 800 Global step 800 Train loss 1.682109 on epoch=33
05/23/2022 00:11:20 - INFO - __main__ - Global step 800 Train loss 1.886593 Classification-F1 0.16666666666666666 on epoch=33
05/23/2022 00:11:25 - INFO - __main__ - Step 810 Global step 810 Train loss 1.452552 on epoch=33
05/23/2022 00:11:30 - INFO - __main__ - Step 820 Global step 820 Train loss 1.269911 on epoch=34
05/23/2022 00:11:35 - INFO - __main__ - Step 830 Global step 830 Train loss 2.023239 on epoch=34
05/23/2022 00:11:40 - INFO - __main__ - Step 840 Global step 840 Train loss 1.378965 on epoch=34
05/23/2022 00:11:45 - INFO - __main__ - Step 850 Global step 850 Train loss 1.315343 on epoch=35
05/23/2022 00:11:51 - INFO - __main__ - Global step 850 Train loss 1.488002 Classification-F1 0.1855186509475055 on epoch=35
05/23/2022 00:11:57 - INFO - __main__ - Step 860 Global step 860 Train loss 1.750651 on epoch=35
05/23/2022 00:12:02 - INFO - __main__ - Step 870 Global step 870 Train loss 1.559682 on epoch=36
05/23/2022 00:12:07 - INFO - __main__ - Step 880 Global step 880 Train loss 1.529260 on epoch=36
05/23/2022 00:12:12 - INFO - __main__ - Step 890 Global step 890 Train loss 1.561322 on epoch=37
05/23/2022 00:12:17 - INFO - __main__ - Step 900 Global step 900 Train loss 1.185714 on epoch=37
05/23/2022 00:12:23 - INFO - __main__ - Global step 900 Train loss 1.517326 Classification-F1 0.16666666666666666 on epoch=37
05/23/2022 00:12:29 - INFO - __main__ - Step 910 Global step 910 Train loss 2.057655 on epoch=37
05/23/2022 00:12:34 - INFO - __main__ - Step 920 Global step 920 Train loss 1.703995 on epoch=38
05/23/2022 00:12:39 - INFO - __main__ - Step 930 Global step 930 Train loss 1.195232 on epoch=38
05/23/2022 00:12:44 - INFO - __main__ - Step 940 Global step 940 Train loss 1.479678 on epoch=39
05/23/2022 00:12:49 - INFO - __main__ - Step 950 Global step 950 Train loss 1.272581 on epoch=39
05/23/2022 00:12:55 - INFO - __main__ - Global step 950 Train loss 1.541828 Classification-F1 0.16666666666666666 on epoch=39
05/23/2022 00:13:00 - INFO - __main__ - Step 960 Global step 960 Train loss 1.502471 on epoch=39
05/23/2022 00:13:05 - INFO - __main__ - Step 970 Global step 970 Train loss 1.479590 on epoch=40
05/23/2022 00:13:10 - INFO - __main__ - Step 980 Global step 980 Train loss 1.462741 on epoch=40
05/23/2022 00:13:15 - INFO - __main__ - Step 990 Global step 990 Train loss 1.200782 on epoch=41
05/23/2022 00:13:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.621801 on epoch=41
05/23/2022 00:13:21 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:13:21 - INFO - __main__ - Printing 3 examples
05/23/2022 00:13:21 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:13:21 - INFO - __main__ - ['neutral']
05/23/2022 00:13:21 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:13:21 - INFO - __main__ - ['neutral']
05/23/2022 00:13:21 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:13:21 - INFO - __main__ - ['neutral']
05/23/2022 00:13:21 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:13:22 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:13:22 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:13:22 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:13:22 - INFO - __main__ - Printing 3 examples
05/23/2022 00:13:22 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:13:22 - INFO - __main__ - ['neutral']
05/23/2022 00:13:22 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:13:22 - INFO - __main__ - ['neutral']
05/23/2022 00:13:22 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:13:22 - INFO - __main__ - ['neutral']
05/23/2022 00:13:22 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:13:22 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:13:23 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:13:26 - INFO - __main__ - Global step 1000 Train loss 1.453477 Classification-F1 0.1872259257074312 on epoch=41
05/23/2022 00:13:27 - INFO - __main__ - save last model!
05/23/2022 00:13:34 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 00:13:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:13:35 - INFO - __main__ - Starting training!
05/23/2022 00:13:35 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 00:13:35 - INFO - __main__ - Printing 3 examples
05/23/2022 00:13:35 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 00:13:35 - INFO - __main__ - ['contradiction']
05/23/2022 00:13:35 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 00:13:35 - INFO - __main__ - ['entailment']
05/23/2022 00:13:35 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 00:13:35 - INFO - __main__ - ['contradiction']
05/23/2022 00:13:35 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:13:36 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:13:37 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 00:13:53 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_21_0.0001_8_predictions.txt
05/23/2022 00:13:53 - INFO - __main__ - Classification-F1 on test data: 0.1667
05/23/2022 00:13:53 - INFO - __main__ - prefix=anli_128_21, lr=0.0001, bsz=8, dev_performance=0.1872259257074312, test_performance=0.16666666666666666
05/23/2022 00:13:53 - INFO - __main__ - Running ... prefix=anli_128_42, lr=0.0005, bsz=8 ...
05/23/2022 00:13:54 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:13:54 - INFO - __main__ - Printing 3 examples
05/23/2022 00:13:54 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:13:54 - INFO - __main__ - ['neutral']
05/23/2022 00:13:54 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:13:54 - INFO - __main__ - ['neutral']
05/23/2022 00:13:54 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:13:54 - INFO - __main__ - ['neutral']
05/23/2022 00:13:54 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:13:54 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:13:55 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:13:55 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:13:55 - INFO - __main__ - Printing 3 examples
05/23/2022 00:13:55 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:13:55 - INFO - __main__ - ['neutral']
05/23/2022 00:13:55 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:13:55 - INFO - __main__ - ['neutral']
05/23/2022 00:13:55 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:13:55 - INFO - __main__ - ['neutral']
05/23/2022 00:13:55 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:13:55 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:13:55 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:14:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:14:06 - INFO - __main__ - Starting training!
05/23/2022 00:14:10 - INFO - __main__ - Step 10 Global step 10 Train loss 24.284187 on epoch=0
05/23/2022 00:14:15 - INFO - __main__ - Step 20 Global step 20 Train loss 20.198017 on epoch=0
05/23/2022 00:14:20 - INFO - __main__ - Step 30 Global step 30 Train loss 14.127782 on epoch=1
05/23/2022 00:14:25 - INFO - __main__ - Step 40 Global step 40 Train loss 10.641171 on epoch=1
05/23/2022 00:14:30 - INFO - __main__ - Step 50 Global step 50 Train loss 10.550249 on epoch=2
05/23/2022 00:14:36 - INFO - __main__ - Global step 50 Train loss 15.960282 Classification-F1 0.0 on epoch=2
05/23/2022 00:14:42 - INFO - __main__ - Step 60 Global step 60 Train loss 8.763792 on epoch=2
05/23/2022 00:14:47 - INFO - __main__ - Step 70 Global step 70 Train loss 8.650223 on epoch=2
05/23/2022 00:14:52 - INFO - __main__ - Step 80 Global step 80 Train loss 7.039094 on epoch=3
05/23/2022 00:14:57 - INFO - __main__ - Step 90 Global step 90 Train loss 4.901855 on epoch=3
05/23/2022 00:15:02 - INFO - __main__ - Step 100 Global step 100 Train loss 3.310522 on epoch=4
05/23/2022 00:15:09 - INFO - __main__ - Global step 100 Train loss 6.533098 Classification-F1 0.21130770541611077 on epoch=4
05/23/2022 00:15:15 - INFO - __main__ - Step 110 Global step 110 Train loss 2.754022 on epoch=4
05/23/2022 00:15:20 - INFO - __main__ - Step 120 Global step 120 Train loss 2.266489 on epoch=4
05/23/2022 00:15:25 - INFO - __main__ - Step 130 Global step 130 Train loss 2.195480 on epoch=5
05/23/2022 00:15:30 - INFO - __main__ - Step 140 Global step 140 Train loss 1.974096 on epoch=5
05/23/2022 00:15:35 - INFO - __main__ - Step 150 Global step 150 Train loss 2.093169 on epoch=6
05/23/2022 00:15:41 - INFO - __main__ - Global step 150 Train loss 2.256651 Classification-F1 0.16666666666666666 on epoch=6
05/23/2022 00:15:46 - INFO - __main__ - Step 160 Global step 160 Train loss 1.859632 on epoch=6
05/23/2022 00:15:51 - INFO - __main__ - Step 170 Global step 170 Train loss 1.868313 on epoch=7
05/23/2022 00:15:56 - INFO - __main__ - Step 180 Global step 180 Train loss 1.473313 on epoch=7
05/23/2022 00:16:01 - INFO - __main__ - Step 190 Global step 190 Train loss 1.374373 on epoch=7
05/23/2022 00:16:06 - INFO - __main__ - Step 200 Global step 200 Train loss 1.548718 on epoch=8
05/23/2022 00:16:13 - INFO - __main__ - Global step 200 Train loss 1.624870 Classification-F1 0.2011471024116096 on epoch=8
05/23/2022 00:16:18 - INFO - __main__ - Step 210 Global step 210 Train loss 1.380542 on epoch=8
05/23/2022 00:16:23 - INFO - __main__ - Step 220 Global step 220 Train loss 1.121645 on epoch=9
05/23/2022 00:16:28 - INFO - __main__ - Step 230 Global step 230 Train loss 1.251408 on epoch=9
05/23/2022 00:16:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.860056 on epoch=9
05/23/2022 00:16:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.957134 on epoch=10
05/23/2022 00:16:44 - INFO - __main__ - Global step 250 Train loss 1.114157 Classification-F1 0.1721607831834019 on epoch=10
05/23/2022 00:16:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.907882 on epoch=10
05/23/2022 00:16:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.903471 on epoch=11
05/23/2022 00:17:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.875926 on epoch=11
05/23/2022 00:17:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.632602 on epoch=12
05/23/2022 00:17:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.754885 on epoch=12
05/23/2022 00:17:16 - INFO - __main__ - Global step 300 Train loss 0.814953 Classification-F1 0.16666666666666666 on epoch=12
05/23/2022 00:17:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.526470 on epoch=12
05/23/2022 00:17:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.700273 on epoch=13
05/23/2022 00:17:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.577596 on epoch=13
05/23/2022 00:17:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.671659 on epoch=14
05/23/2022 00:17:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.529305 on epoch=14
05/23/2022 00:17:49 - INFO - __main__ - Global step 350 Train loss 0.601061 Classification-F1 0.1721607831834019 on epoch=14
05/23/2022 00:17:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.611096 on epoch=14
05/23/2022 00:17:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.676598 on epoch=15
05/23/2022 00:18:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.501820 on epoch=15
05/23/2022 00:18:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.534000 on epoch=16
05/23/2022 00:18:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.478811 on epoch=16
05/23/2022 00:18:21 - INFO - __main__ - Global step 400 Train loss 0.560465 Classification-F1 0.3070338183120138 on epoch=16
05/23/2022 00:18:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.473867 on epoch=17
05/23/2022 00:18:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.447022 on epoch=17
05/23/2022 00:18:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.432746 on epoch=17
05/23/2022 00:18:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.534937 on epoch=18
05/23/2022 00:18:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.471539 on epoch=18
05/23/2022 00:18:54 - INFO - __main__ - Global step 450 Train loss 0.472022 Classification-F1 0.2834463572687414 on epoch=18
05/23/2022 00:18:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.575497 on epoch=19
05/23/2022 00:19:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.448857 on epoch=19
05/23/2022 00:19:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.446814 on epoch=19
05/23/2022 00:19:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.506281 on epoch=20
05/23/2022 00:19:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.464570 on epoch=20
05/23/2022 00:19:27 - INFO - __main__ - Global step 500 Train loss 0.488404 Classification-F1 0.24501889834678728 on epoch=20
05/23/2022 00:19:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.619851 on epoch=21
05/23/2022 00:19:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.460255 on epoch=21
05/23/2022 00:19:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.382445 on epoch=22
05/23/2022 00:19:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.421032 on epoch=22
05/23/2022 00:19:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.451892 on epoch=22
05/23/2022 00:19:59 - INFO - __main__ - Global step 550 Train loss 0.467095 Classification-F1 0.30915771441559564 on epoch=22
05/23/2022 00:20:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.478405 on epoch=23
05/23/2022 00:20:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.395450 on epoch=23
05/23/2022 00:20:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.505913 on epoch=24
05/23/2022 00:20:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.475199 on epoch=24
05/23/2022 00:20:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.427200 on epoch=24
05/23/2022 00:20:32 - INFO - __main__ - Global step 600 Train loss 0.456433 Classification-F1 0.1647058823529412 on epoch=24
05/23/2022 00:20:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.469398 on epoch=25
05/23/2022 00:20:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.496540 on epoch=25
05/23/2022 00:20:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.553786 on epoch=26
05/23/2022 00:20:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.489441 on epoch=26
05/23/2022 00:20:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.490933 on epoch=27
05/23/2022 00:21:04 - INFO - __main__ - Global step 650 Train loss 0.500020 Classification-F1 0.2667677150435771 on epoch=27
05/23/2022 00:21:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.444451 on epoch=27
05/23/2022 00:21:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.486936 on epoch=27
05/23/2022 00:21:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.470168 on epoch=28
05/23/2022 00:21:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.463966 on epoch=28
05/23/2022 00:21:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.446088 on epoch=29
05/23/2022 00:21:36 - INFO - __main__ - Global step 700 Train loss 0.462322 Classification-F1 0.2854749437866566 on epoch=29
05/23/2022 00:21:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.504041 on epoch=29
05/23/2022 00:21:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.465417 on epoch=29
05/23/2022 00:21:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.434833 on epoch=30
05/23/2022 00:21:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.442526 on epoch=30
05/23/2022 00:22:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.407982 on epoch=31
05/23/2022 00:22:09 - INFO - __main__ - Global step 750 Train loss 0.450960 Classification-F1 0.23031378509103362 on epoch=31
05/23/2022 00:22:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.426237 on epoch=31
05/23/2022 00:22:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.423280 on epoch=32
05/23/2022 00:22:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.463283 on epoch=32
05/23/2022 00:22:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.445952 on epoch=32
05/23/2022 00:22:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.428954 on epoch=33
05/23/2022 00:22:41 - INFO - __main__ - Global step 800 Train loss 0.437541 Classification-F1 0.2870018417649594 on epoch=33
05/23/2022 00:22:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.422753 on epoch=33
05/23/2022 00:22:51 - INFO - __main__ - Step 820 Global step 820 Train loss 0.412935 on epoch=34
05/23/2022 00:22:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.399682 on epoch=34
05/23/2022 00:23:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.382516 on epoch=34
05/23/2022 00:23:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.428809 on epoch=35
05/23/2022 00:23:14 - INFO - __main__ - Global step 850 Train loss 0.409339 Classification-F1 0.2575524751056666 on epoch=35
05/23/2022 00:23:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.356868 on epoch=35
05/23/2022 00:23:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.387036 on epoch=36
05/23/2022 00:23:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.429035 on epoch=36
05/23/2022 00:23:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.411370 on epoch=37
05/23/2022 00:23:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.412676 on epoch=37
05/23/2022 00:23:48 - INFO - __main__ - Global step 900 Train loss 0.399397 Classification-F1 0.2291731415496624 on epoch=37
05/23/2022 00:23:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.366637 on epoch=37
05/23/2022 00:23:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.472891 on epoch=38
05/23/2022 00:24:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.386918 on epoch=38
05/23/2022 00:24:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.423540 on epoch=39
05/23/2022 00:24:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.338464 on epoch=39
05/23/2022 00:24:21 - INFO - __main__ - Global step 950 Train loss 0.397690 Classification-F1 0.3407649447673864 on epoch=39
05/23/2022 00:24:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.319930 on epoch=39
05/23/2022 00:24:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.384324 on epoch=40
05/23/2022 00:24:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.281322 on epoch=40
05/23/2022 00:24:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.343368 on epoch=41
05/23/2022 00:24:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.364019 on epoch=41
05/23/2022 00:24:49 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:24:49 - INFO - __main__ - Printing 3 examples
05/23/2022 00:24:49 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:24:49 - INFO - __main__ - ['neutral']
05/23/2022 00:24:49 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:24:49 - INFO - __main__ - ['neutral']
05/23/2022 00:24:49 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:24:49 - INFO - __main__ - ['neutral']
05/23/2022 00:24:49 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:24:49 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:24:49 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:24:49 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:24:49 - INFO - __main__ - Printing 3 examples
05/23/2022 00:24:49 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:24:49 - INFO - __main__ - ['neutral']
05/23/2022 00:24:49 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:24:49 - INFO - __main__ - ['neutral']
05/23/2022 00:24:49 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:24:49 - INFO - __main__ - ['neutral']
05/23/2022 00:24:49 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:24:49 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:24:50 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:24:55 - INFO - __main__ - Global step 1000 Train loss 0.338593 Classification-F1 0.3572854120203579 on epoch=41
05/23/2022 00:24:55 - INFO - __main__ - save last model!
05/23/2022 00:25:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:25:01 - INFO - __main__ - Starting training!
05/23/2022 00:25:02 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 00:25:03 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 00:25:03 - INFO - __main__ - Printing 3 examples
05/23/2022 00:25:03 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 00:25:03 - INFO - __main__ - ['contradiction']
05/23/2022 00:25:03 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 00:25:03 - INFO - __main__ - ['entailment']
05/23/2022 00:25:03 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 00:25:03 - INFO - __main__ - ['contradiction']
05/23/2022 00:25:03 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:25:04 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:25:05 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 00:25:23 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_42_0.0005_8_predictions.txt
05/23/2022 00:25:23 - INFO - __main__ - Classification-F1 on test data: 0.3346
05/23/2022 00:25:23 - INFO - __main__ - prefix=anli_128_42, lr=0.0005, bsz=8, dev_performance=0.3572854120203579, test_performance=0.3345912811125595
05/23/2022 00:25:23 - INFO - __main__ - Running ... prefix=anli_128_42, lr=0.0003, bsz=8 ...
05/23/2022 00:25:24 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:25:24 - INFO - __main__ - Printing 3 examples
05/23/2022 00:25:24 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:25:24 - INFO - __main__ - ['neutral']
05/23/2022 00:25:24 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:25:24 - INFO - __main__ - ['neutral']
05/23/2022 00:25:24 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:25:24 - INFO - __main__ - ['neutral']
05/23/2022 00:25:24 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:25:24 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:25:25 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:25:25 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:25:25 - INFO - __main__ - Printing 3 examples
05/23/2022 00:25:25 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:25:25 - INFO - __main__ - ['neutral']
05/23/2022 00:25:25 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:25:25 - INFO - __main__ - ['neutral']
05/23/2022 00:25:25 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:25:25 - INFO - __main__ - ['neutral']
05/23/2022 00:25:25 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:25:25 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:25:25 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:25:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:25:38 - INFO - __main__ - Starting training!
05/23/2022 00:25:42 - INFO - __main__ - Step 10 Global step 10 Train loss 23.903923 on epoch=0
05/23/2022 00:25:47 - INFO - __main__ - Step 20 Global step 20 Train loss 20.618200 on epoch=0
05/23/2022 00:25:51 - INFO - __main__ - Step 30 Global step 30 Train loss 16.618923 on epoch=1
05/23/2022 00:25:57 - INFO - __main__ - Step 40 Global step 40 Train loss 12.263122 on epoch=1
05/23/2022 00:26:02 - INFO - __main__ - Step 50 Global step 50 Train loss 12.224123 on epoch=2
05/23/2022 00:27:07 - INFO - __main__ - Global step 50 Train loss 17.125660 Classification-F1 0.0033775938865550654 on epoch=2
05/23/2022 00:27:13 - INFO - __main__ - Step 60 Global step 60 Train loss 10.360946 on epoch=2
05/23/2022 00:27:18 - INFO - __main__ - Step 70 Global step 70 Train loss 10.976200 on epoch=2
05/23/2022 00:27:23 - INFO - __main__ - Step 80 Global step 80 Train loss 9.950344 on epoch=3
05/23/2022 00:27:28 - INFO - __main__ - Step 90 Global step 90 Train loss 8.724662 on epoch=3
05/23/2022 00:27:33 - INFO - __main__ - Step 100 Global step 100 Train loss 8.237250 on epoch=4
05/23/2022 00:27:49 - INFO - __main__ - Global step 100 Train loss 9.649880 Classification-F1 0.0198019801980198 on epoch=4
05/23/2022 00:27:54 - INFO - __main__ - Step 110 Global step 110 Train loss 7.364754 on epoch=4
05/23/2022 00:27:59 - INFO - __main__ - Step 120 Global step 120 Train loss 6.510680 on epoch=4
05/23/2022 00:28:04 - INFO - __main__ - Step 130 Global step 130 Train loss 4.558327 on epoch=5
05/23/2022 00:28:09 - INFO - __main__ - Step 140 Global step 140 Train loss 4.083094 on epoch=5
05/23/2022 00:28:14 - INFO - __main__ - Step 150 Global step 150 Train loss 3.706535 on epoch=6
05/23/2022 00:28:28 - INFO - __main__ - Global step 150 Train loss 5.244678 Classification-F1 0.02593262340097783 on epoch=6
05/23/2022 00:28:34 - INFO - __main__ - Step 160 Global step 160 Train loss 2.607604 on epoch=6
05/23/2022 00:28:39 - INFO - __main__ - Step 170 Global step 170 Train loss 2.839790 on epoch=7
05/23/2022 00:28:44 - INFO - __main__ - Step 180 Global step 180 Train loss 2.257677 on epoch=7
05/23/2022 00:28:49 - INFO - __main__ - Step 190 Global step 190 Train loss 2.486038 on epoch=7
05/23/2022 00:28:54 - INFO - __main__ - Step 200 Global step 200 Train loss 2.917362 on epoch=8
05/23/2022 00:29:02 - INFO - __main__ - Global step 200 Train loss 2.621694 Classification-F1 0.16666666666666666 on epoch=8
05/23/2022 00:29:08 - INFO - __main__ - Step 210 Global step 210 Train loss 2.523123 on epoch=8
05/23/2022 00:29:13 - INFO - __main__ - Step 220 Global step 220 Train loss 1.739215 on epoch=9
05/23/2022 00:29:18 - INFO - __main__ - Step 230 Global step 230 Train loss 2.612291 on epoch=9
05/23/2022 00:29:23 - INFO - __main__ - Step 240 Global step 240 Train loss 1.756038 on epoch=9
05/23/2022 00:29:28 - INFO - __main__ - Step 250 Global step 250 Train loss 1.591149 on epoch=10
05/23/2022 00:29:35 - INFO - __main__ - Global step 250 Train loss 2.044363 Classification-F1 0.16666666666666666 on epoch=10
05/23/2022 00:29:41 - INFO - __main__ - Step 260 Global step 260 Train loss 1.904255 on epoch=10
05/23/2022 00:29:46 - INFO - __main__ - Step 270 Global step 270 Train loss 1.901985 on epoch=11
05/23/2022 00:29:51 - INFO - __main__ - Step 280 Global step 280 Train loss 1.503590 on epoch=11
05/23/2022 00:29:56 - INFO - __main__ - Step 290 Global step 290 Train loss 1.613332 on epoch=12
05/23/2022 00:30:01 - INFO - __main__ - Step 300 Global step 300 Train loss 1.500173 on epoch=12
05/23/2022 00:30:07 - INFO - __main__ - Global step 300 Train loss 1.684667 Classification-F1 0.16666666666666666 on epoch=12
05/23/2022 00:30:12 - INFO - __main__ - Step 310 Global step 310 Train loss 1.647221 on epoch=12
05/23/2022 00:30:17 - INFO - __main__ - Step 320 Global step 320 Train loss 1.778171 on epoch=13
05/23/2022 00:30:23 - INFO - __main__ - Step 330 Global step 330 Train loss 1.369493 on epoch=13
05/23/2022 00:30:28 - INFO - __main__ - Step 340 Global step 340 Train loss 1.063453 on epoch=14
05/23/2022 00:30:33 - INFO - __main__ - Step 350 Global step 350 Train loss 1.364463 on epoch=14
05/23/2022 00:30:39 - INFO - __main__ - Global step 350 Train loss 1.444561 Classification-F1 0.16666666666666666 on epoch=14
05/23/2022 00:30:44 - INFO - __main__ - Step 360 Global step 360 Train loss 1.239846 on epoch=14
05/23/2022 00:30:49 - INFO - __main__ - Step 370 Global step 370 Train loss 1.161121 on epoch=15
05/23/2022 00:30:55 - INFO - __main__ - Step 380 Global step 380 Train loss 1.149436 on epoch=15
05/23/2022 00:31:00 - INFO - __main__ - Step 390 Global step 390 Train loss 1.155483 on epoch=16
05/23/2022 00:31:05 - INFO - __main__ - Step 400 Global step 400 Train loss 1.115175 on epoch=16
05/23/2022 00:31:11 - INFO - __main__ - Global step 400 Train loss 1.164212 Classification-F1 0.16666666666666666 on epoch=16
05/23/2022 00:31:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.916287 on epoch=17
05/23/2022 00:31:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.970387 on epoch=17
05/23/2022 00:31:27 - INFO - __main__ - Step 430 Global step 430 Train loss 1.046690 on epoch=17
05/23/2022 00:31:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.957053 on epoch=18
05/23/2022 00:31:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.685720 on epoch=18
05/23/2022 00:31:43 - INFO - __main__ - Global step 450 Train loss 0.915228 Classification-F1 0.16666666666666666 on epoch=18
05/23/2022 00:31:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.878410 on epoch=19
05/23/2022 00:31:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.796943 on epoch=19
05/23/2022 00:31:59 - INFO - __main__ - Step 480 Global step 480 Train loss 1.028566 on epoch=19
05/23/2022 00:32:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.798867 on epoch=20
05/23/2022 00:32:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.665332 on epoch=20
05/23/2022 00:32:16 - INFO - __main__ - Global step 500 Train loss 0.833624 Classification-F1 0.23419259387250402 on epoch=20
05/23/2022 00:32:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.804409 on epoch=21
05/23/2022 00:32:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.757099 on epoch=21
05/23/2022 00:32:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.914986 on epoch=22
05/23/2022 00:32:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.581120 on epoch=22
05/23/2022 00:32:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.680335 on epoch=22
05/23/2022 00:32:48 - INFO - __main__ - Global step 550 Train loss 0.747590 Classification-F1 0.18608972008311941 on epoch=22
05/23/2022 00:32:54 - INFO - __main__ - Step 560 Global step 560 Train loss 0.638426 on epoch=23
05/23/2022 00:32:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.736562 on epoch=23
05/23/2022 00:33:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.619988 on epoch=24
05/23/2022 00:33:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.638011 on epoch=24
05/23/2022 00:33:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.640517 on epoch=24
05/23/2022 00:33:21 - INFO - __main__ - Global step 600 Train loss 0.654701 Classification-F1 0.17947344935296747 on epoch=24
05/23/2022 00:33:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.574803 on epoch=25
05/23/2022 00:33:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.675322 on epoch=25
05/23/2022 00:33:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.544444 on epoch=26
05/23/2022 00:33:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.623486 on epoch=26
05/23/2022 00:33:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.520059 on epoch=27
05/23/2022 00:33:53 - INFO - __main__ - Global step 650 Train loss 0.587623 Classification-F1 0.16666666666666666 on epoch=27
05/23/2022 00:33:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.584017 on epoch=27
05/23/2022 00:34:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.642356 on epoch=27
05/23/2022 00:34:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.543203 on epoch=28
05/23/2022 00:34:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.618237 on epoch=28
05/23/2022 00:34:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.520626 on epoch=29
05/23/2022 00:34:25 - INFO - __main__ - Global step 700 Train loss 0.581688 Classification-F1 0.17040483575916646 on epoch=29
05/23/2022 00:34:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.490220 on epoch=29
05/23/2022 00:34:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.467546 on epoch=29
05/23/2022 00:34:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.476325 on epoch=30
05/23/2022 00:34:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.577183 on epoch=30
05/23/2022 00:34:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.519656 on epoch=31
05/23/2022 00:34:57 - INFO - __main__ - Global step 750 Train loss 0.506186 Classification-F1 0.1739502487562189 on epoch=31
05/23/2022 00:35:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.521906 on epoch=31
05/23/2022 00:35:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.487162 on epoch=32
05/23/2022 00:35:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.440098 on epoch=32
05/23/2022 00:35:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.438008 on epoch=32
05/23/2022 00:35:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.495953 on epoch=33
05/23/2022 00:35:30 - INFO - __main__ - Global step 800 Train loss 0.476625 Classification-F1 0.2511845178511845 on epoch=33
05/23/2022 00:35:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.463564 on epoch=33
05/23/2022 00:35:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.502741 on epoch=34
05/23/2022 00:35:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.456281 on epoch=34
05/23/2022 00:35:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.495735 on epoch=34
05/23/2022 00:35:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.446738 on epoch=35
05/23/2022 00:36:03 - INFO - __main__ - Global step 850 Train loss 0.473012 Classification-F1 0.2805276609873712 on epoch=35
05/23/2022 00:36:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.443845 on epoch=35
05/23/2022 00:36:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.488981 on epoch=36
05/23/2022 00:36:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.402815 on epoch=36
05/23/2022 00:36:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.406238 on epoch=37
05/23/2022 00:36:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.430297 on epoch=37
05/23/2022 00:36:35 - INFO - __main__ - Global step 900 Train loss 0.434435 Classification-F1 0.2555489692419153 on epoch=37
05/23/2022 00:36:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.518697 on epoch=37
05/23/2022 00:36:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.530642 on epoch=38
05/23/2022 00:36:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.478174 on epoch=38
05/23/2022 00:36:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.440849 on epoch=39
05/23/2022 00:37:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.459896 on epoch=39
05/23/2022 00:37:08 - INFO - __main__ - Global step 950 Train loss 0.485652 Classification-F1 0.24430832913799852 on epoch=39
05/23/2022 00:37:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.480448 on epoch=39
05/23/2022 00:37:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.443063 on epoch=40
05/23/2022 00:37:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.469169 on epoch=40
05/23/2022 00:37:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.440523 on epoch=41
05/23/2022 00:37:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.420783 on epoch=41
05/23/2022 00:37:35 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:37:35 - INFO - __main__ - Printing 3 examples
05/23/2022 00:37:35 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:37:35 - INFO - __main__ - ['neutral']
05/23/2022 00:37:35 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:37:35 - INFO - __main__ - ['neutral']
05/23/2022 00:37:35 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:37:35 - INFO - __main__ - ['neutral']
05/23/2022 00:37:35 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:37:35 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:37:35 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:37:35 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:37:35 - INFO - __main__ - Printing 3 examples
05/23/2022 00:37:35 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:37:35 - INFO - __main__ - ['neutral']
05/23/2022 00:37:35 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:37:35 - INFO - __main__ - ['neutral']
05/23/2022 00:37:35 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:37:35 - INFO - __main__ - ['neutral']
05/23/2022 00:37:35 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:37:35 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:37:36 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:37:40 - INFO - __main__ - Global step 1000 Train loss 0.450797 Classification-F1 0.20778438664617527 on epoch=41
05/23/2022 00:37:40 - INFO - __main__ - save last model!
05/23/2022 00:37:47 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 00:37:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:37:47 - INFO - __main__ - Starting training!
05/23/2022 00:37:48 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 00:37:48 - INFO - __main__ - Printing 3 examples
05/23/2022 00:37:48 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 00:37:48 - INFO - __main__ - ['contradiction']
05/23/2022 00:37:48 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 00:37:48 - INFO - __main__ - ['entailment']
05/23/2022 00:37:48 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 00:37:48 - INFO - __main__ - ['contradiction']
05/23/2022 00:37:48 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:37:48 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:37:49 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 00:38:07 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_42_0.0003_8_predictions.txt
05/23/2022 00:38:07 - INFO - __main__ - Classification-F1 on test data: 0.3177
05/23/2022 00:38:08 - INFO - __main__ - prefix=anli_128_42, lr=0.0003, bsz=8, dev_performance=0.2805276609873712, test_performance=0.31770845449529467
05/23/2022 00:38:08 - INFO - __main__ - Running ... prefix=anli_128_42, lr=0.0002, bsz=8 ...
05/23/2022 00:38:09 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:38:09 - INFO - __main__ - Printing 3 examples
05/23/2022 00:38:09 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:38:09 - INFO - __main__ - ['neutral']
05/23/2022 00:38:09 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:38:09 - INFO - __main__ - ['neutral']
05/23/2022 00:38:09 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:38:09 - INFO - __main__ - ['neutral']
05/23/2022 00:38:09 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:38:09 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:38:09 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:38:09 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:38:09 - INFO - __main__ - Printing 3 examples
05/23/2022 00:38:09 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:38:09 - INFO - __main__ - ['neutral']
05/23/2022 00:38:09 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:38:09 - INFO - __main__ - ['neutral']
05/23/2022 00:38:09 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:38:09 - INFO - __main__ - ['neutral']
05/23/2022 00:38:09 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:38:09 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:38:10 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:38:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:38:21 - INFO - __main__ - Starting training!
05/23/2022 00:38:25 - INFO - __main__ - Step 10 Global step 10 Train loss 26.361542 on epoch=0
05/23/2022 00:38:30 - INFO - __main__ - Step 20 Global step 20 Train loss 20.426226 on epoch=0
05/23/2022 00:38:35 - INFO - __main__ - Step 30 Global step 30 Train loss 16.325739 on epoch=1
05/23/2022 00:38:40 - INFO - __main__ - Step 40 Global step 40 Train loss 13.575788 on epoch=1
05/23/2022 00:38:46 - INFO - __main__ - Step 50 Global step 50 Train loss 13.279236 on epoch=2
05/23/2022 00:38:53 - INFO - __main__ - Global step 50 Train loss 17.993708 Classification-F1 0.000641025641025641 on epoch=2
05/23/2022 00:38:59 - INFO - __main__ - Step 60 Global step 60 Train loss 11.758478 on epoch=2
05/23/2022 00:39:04 - INFO - __main__ - Step 70 Global step 70 Train loss 11.946796 on epoch=2
05/23/2022 00:39:09 - INFO - __main__ - Step 80 Global step 80 Train loss 11.043296 on epoch=3
05/23/2022 00:39:14 - INFO - __main__ - Step 90 Global step 90 Train loss 9.856739 on epoch=3
05/23/2022 00:39:20 - INFO - __main__ - Step 100 Global step 100 Train loss 9.520432 on epoch=4
05/23/2022 00:39:28 - INFO - __main__ - Global step 100 Train loss 10.825149 Classification-F1 0.01499605367008682 on epoch=4
05/23/2022 00:39:34 - INFO - __main__ - Step 110 Global step 110 Train loss 8.785666 on epoch=4
05/23/2022 00:39:39 - INFO - __main__ - Step 120 Global step 120 Train loss 8.843719 on epoch=4
05/23/2022 00:39:45 - INFO - __main__ - Step 130 Global step 130 Train loss 8.911937 on epoch=5
05/23/2022 00:39:50 - INFO - __main__ - Step 140 Global step 140 Train loss 8.362629 on epoch=5
05/23/2022 00:39:55 - INFO - __main__ - Step 150 Global step 150 Train loss 7.559323 on epoch=6
05/23/2022 00:40:03 - INFO - __main__ - Global step 150 Train loss 8.492655 Classification-F1 0.03294573643410853 on epoch=6
05/23/2022 00:40:09 - INFO - __main__ - Step 160 Global step 160 Train loss 6.697289 on epoch=6
05/23/2022 00:40:14 - INFO - __main__ - Step 170 Global step 170 Train loss 6.666544 on epoch=7
05/23/2022 00:40:19 - INFO - __main__ - Step 180 Global step 180 Train loss 5.143584 on epoch=7
05/23/2022 00:40:24 - INFO - __main__ - Step 190 Global step 190 Train loss 5.214349 on epoch=7
05/23/2022 00:40:30 - INFO - __main__ - Step 200 Global step 200 Train loss 3.715298 on epoch=8
05/23/2022 00:40:37 - INFO - __main__ - Global step 200 Train loss 5.487413 Classification-F1 0.16537419063394068 on epoch=8
05/23/2022 00:40:43 - INFO - __main__ - Step 210 Global step 210 Train loss 3.748912 on epoch=8
05/23/2022 00:40:48 - INFO - __main__ - Step 220 Global step 220 Train loss 3.022902 on epoch=9
05/23/2022 00:40:53 - INFO - __main__ - Step 230 Global step 230 Train loss 3.115232 on epoch=9
05/23/2022 00:40:58 - INFO - __main__ - Step 240 Global step 240 Train loss 2.667107 on epoch=9
05/23/2022 00:41:03 - INFO - __main__ - Step 250 Global step 250 Train loss 2.541409 on epoch=10
05/23/2022 00:41:10 - INFO - __main__ - Global step 250 Train loss 3.019112 Classification-F1 0.16666666666666666 on epoch=10
05/23/2022 00:41:16 - INFO - __main__ - Step 260 Global step 260 Train loss 2.195529 on epoch=10
05/23/2022 00:41:21 - INFO - __main__ - Step 270 Global step 270 Train loss 2.243488 on epoch=11
05/23/2022 00:41:26 - INFO - __main__ - Step 280 Global step 280 Train loss 1.744907 on epoch=11
05/23/2022 00:41:31 - INFO - __main__ - Step 290 Global step 290 Train loss 1.893424 on epoch=12
05/23/2022 00:41:36 - INFO - __main__ - Step 300 Global step 300 Train loss 2.310352 on epoch=12
05/23/2022 00:41:42 - INFO - __main__ - Global step 300 Train loss 2.077540 Classification-F1 0.16666666666666666 on epoch=12
05/23/2022 00:41:48 - INFO - __main__ - Step 310 Global step 310 Train loss 2.245456 on epoch=12
05/23/2022 00:41:53 - INFO - __main__ - Step 320 Global step 320 Train loss 2.536512 on epoch=13
05/23/2022 00:41:58 - INFO - __main__ - Step 330 Global step 330 Train loss 1.877751 on epoch=13
05/23/2022 00:42:03 - INFO - __main__ - Step 340 Global step 340 Train loss 2.023543 on epoch=14
05/23/2022 00:42:08 - INFO - __main__ - Step 350 Global step 350 Train loss 1.726492 on epoch=14
05/23/2022 00:42:14 - INFO - __main__ - Global step 350 Train loss 2.081951 Classification-F1 0.16666666666666666 on epoch=14
05/23/2022 00:42:20 - INFO - __main__ - Step 360 Global step 360 Train loss 1.617026 on epoch=14
05/23/2022 00:42:25 - INFO - __main__ - Step 370 Global step 370 Train loss 1.916510 on epoch=15
05/23/2022 00:42:30 - INFO - __main__ - Step 380 Global step 380 Train loss 1.905717 on epoch=15
05/23/2022 00:42:35 - INFO - __main__ - Step 390 Global step 390 Train loss 1.538638 on epoch=16
05/23/2022 00:42:40 - INFO - __main__ - Step 400 Global step 400 Train loss 1.691550 on epoch=16
05/23/2022 00:42:47 - INFO - __main__ - Global step 400 Train loss 1.733888 Classification-F1 0.16666666666666666 on epoch=16
05/23/2022 00:42:52 - INFO - __main__ - Step 410 Global step 410 Train loss 1.661040 on epoch=17
05/23/2022 00:42:57 - INFO - __main__ - Step 420 Global step 420 Train loss 1.103548 on epoch=17
05/23/2022 00:43:02 - INFO - __main__ - Step 430 Global step 430 Train loss 1.312690 on epoch=17
05/23/2022 00:43:07 - INFO - __main__ - Step 440 Global step 440 Train loss 1.386344 on epoch=18
05/23/2022 00:43:12 - INFO - __main__ - Step 450 Global step 450 Train loss 1.346042 on epoch=18
05/23/2022 00:43:19 - INFO - __main__ - Global step 450 Train loss 1.361933 Classification-F1 0.16666666666666666 on epoch=18
05/23/2022 00:43:24 - INFO - __main__ - Step 460 Global step 460 Train loss 1.289710 on epoch=19
05/23/2022 00:43:29 - INFO - __main__ - Step 470 Global step 470 Train loss 1.171251 on epoch=19
05/23/2022 00:43:34 - INFO - __main__ - Step 480 Global step 480 Train loss 1.061839 on epoch=19
05/23/2022 00:43:39 - INFO - __main__ - Step 490 Global step 490 Train loss 1.150563 on epoch=20
05/23/2022 00:43:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.970413 on epoch=20
05/23/2022 00:43:51 - INFO - __main__ - Global step 500 Train loss 1.128755 Classification-F1 0.1721607831834019 on epoch=20
05/23/2022 00:43:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.990363 on epoch=21
05/23/2022 00:44:02 - INFO - __main__ - Step 520 Global step 520 Train loss 1.127288 on epoch=21
05/23/2022 00:44:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.949804 on epoch=22
05/23/2022 00:44:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.848592 on epoch=22
05/23/2022 00:44:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.812344 on epoch=22
05/23/2022 00:44:24 - INFO - __main__ - Global step 550 Train loss 0.945678 Classification-F1 0.16666666666666666 on epoch=22
05/23/2022 00:44:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.796776 on epoch=23
05/23/2022 00:44:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.935947 on epoch=23
05/23/2022 00:44:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.689572 on epoch=24
05/23/2022 00:44:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.712950 on epoch=24
05/23/2022 00:44:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.602516 on epoch=24
05/23/2022 00:44:56 - INFO - __main__ - Global step 600 Train loss 0.747552 Classification-F1 0.16666666666666666 on epoch=24
05/23/2022 00:45:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.651736 on epoch=25
05/23/2022 00:45:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.565642 on epoch=25
05/23/2022 00:45:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.503454 on epoch=26
05/23/2022 00:45:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.669774 on epoch=26
05/23/2022 00:45:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.531436 on epoch=27
05/23/2022 00:45:28 - INFO - __main__ - Global step 650 Train loss 0.584408 Classification-F1 0.3167542498140179 on epoch=27
05/23/2022 00:45:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.575528 on epoch=27
05/23/2022 00:45:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.613981 on epoch=27
05/23/2022 00:45:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.529623 on epoch=28
05/23/2022 00:45:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.485094 on epoch=28
05/23/2022 00:45:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.456812 on epoch=29
05/23/2022 00:46:02 - INFO - __main__ - Global step 700 Train loss 0.532208 Classification-F1 0.34819688280893324 on epoch=29
05/23/2022 00:46:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.445414 on epoch=29
05/23/2022 00:46:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.448014 on epoch=29
05/23/2022 00:46:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.465893 on epoch=30
05/23/2022 00:46:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.396100 on epoch=30
05/23/2022 00:46:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.469771 on epoch=31
05/23/2022 00:46:33 - INFO - __main__ - Global step 750 Train loss 0.445038 Classification-F1 0.23946352440131882 on epoch=31
05/23/2022 00:46:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.436893 on epoch=31
05/23/2022 00:46:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.413655 on epoch=32
05/23/2022 00:46:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.411254 on epoch=32
05/23/2022 00:46:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.408387 on epoch=32
05/23/2022 00:46:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.363356 on epoch=33
05/23/2022 00:47:06 - INFO - __main__ - Global step 800 Train loss 0.406709 Classification-F1 0.3126333375978721 on epoch=33
05/23/2022 00:47:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.415513 on epoch=33
05/23/2022 00:47:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.370491 on epoch=34
05/23/2022 00:47:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.345787 on epoch=34
05/23/2022 00:47:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.286780 on epoch=34
05/23/2022 00:47:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.358663 on epoch=35
05/23/2022 00:47:38 - INFO - __main__ - Global step 850 Train loss 0.355447 Classification-F1 0.383855061408856 on epoch=35
05/23/2022 00:47:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.299123 on epoch=35
05/23/2022 00:47:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.287220 on epoch=36
05/23/2022 00:47:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.296008 on epoch=36
05/23/2022 00:47:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.252185 on epoch=37
05/23/2022 00:48:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.227786 on epoch=37
05/23/2022 00:48:11 - INFO - __main__ - Global step 900 Train loss 0.272464 Classification-F1 0.3429509086426294 on epoch=37
05/23/2022 00:48:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.233275 on epoch=37
05/23/2022 00:48:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.280909 on epoch=38
05/23/2022 00:48:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.220690 on epoch=38
05/23/2022 00:48:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.214592 on epoch=39
05/23/2022 00:48:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.156328 on epoch=39
05/23/2022 00:48:43 - INFO - __main__ - Global step 950 Train loss 0.221159 Classification-F1 0.36116332868301376 on epoch=39
05/23/2022 00:48:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.165517 on epoch=39
05/23/2022 00:48:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.186487 on epoch=40
05/23/2022 00:48:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.130221 on epoch=40
05/23/2022 00:49:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.181007 on epoch=41
05/23/2022 00:49:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.127157 on epoch=41
05/23/2022 00:49:10 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:49:10 - INFO - __main__ - Printing 3 examples
05/23/2022 00:49:10 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:49:10 - INFO - __main__ - ['neutral']
05/23/2022 00:49:10 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:49:10 - INFO - __main__ - ['neutral']
05/23/2022 00:49:10 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:49:10 - INFO - __main__ - ['neutral']
05/23/2022 00:49:10 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:49:10 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:49:10 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:49:10 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:49:10 - INFO - __main__ - Printing 3 examples
05/23/2022 00:49:10 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:49:10 - INFO - __main__ - ['neutral']
05/23/2022 00:49:10 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:49:10 - INFO - __main__ - ['neutral']
05/23/2022 00:49:10 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:49:10 - INFO - __main__ - ['neutral']
05/23/2022 00:49:10 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:49:11 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:49:11 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:49:15 - INFO - __main__ - Global step 1000 Train loss 0.158078 Classification-F1 0.321583698632879 on epoch=41
05/23/2022 00:49:15 - INFO - __main__ - save last model!
05/23/2022 00:49:22 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 00:49:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:49:22 - INFO - __main__ - Starting training!
05/23/2022 00:49:22 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 00:49:22 - INFO - __main__ - Printing 3 examples
05/23/2022 00:49:22 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 00:49:22 - INFO - __main__ - ['contradiction']
05/23/2022 00:49:22 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 00:49:22 - INFO - __main__ - ['entailment']
05/23/2022 00:49:22 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 00:49:22 - INFO - __main__ - ['contradiction']
05/23/2022 00:49:22 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:49:23 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:49:24 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 00:49:41 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_42_0.0002_8_predictions.txt
05/23/2022 00:49:41 - INFO - __main__ - Classification-F1 on test data: 0.3451
05/23/2022 00:49:41 - INFO - __main__ - prefix=anli_128_42, lr=0.0002, bsz=8, dev_performance=0.383855061408856, test_performance=0.3450679344982021
05/23/2022 00:49:41 - INFO - __main__ - Running ... prefix=anli_128_42, lr=0.0001, bsz=8 ...
05/23/2022 00:49:42 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:49:42 - INFO - __main__ - Printing 3 examples
05/23/2022 00:49:42 - INFO - __main__ -  [anli] premise: The Other One is the third solo album by former Fleetwood Mac guitarist Bob Welch. The track "Future Games" was first released on the Fleetwood Mac album of the same name in 1971. Members of Welch's backing band also make songwriting contributions here though the majority of tracks are Welch's own. [SEP] hypothesis: The Other One is an album by the group TOOL, for which Bob Welch did most of the backing vocals.
05/23/2022 00:49:42 - INFO - __main__ - ['neutral']
05/23/2022 00:49:42 - INFO - __main__ -  [anli] premise: The Living and the Dead is a British supernatural horror television miniseries created by Ashley Pharoah and Matthew Graham. The plot revolves around Nathan Appleby (played by Colin Morgan) and his wife, Charlotte Appleby (played by Charlotte Spencer), whose farm is believed to be at the centre of numerous supernatural occurrences. [SEP] hypothesis: The Living and the Dead was renewed for 7 seasons.
05/23/2022 00:49:42 - INFO - __main__ - ['neutral']
05/23/2022 00:49:42 - INFO - __main__ -  [anli] premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play "Wild Swans". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. [SEP] hypothesis: Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London. 
05/23/2022 00:49:42 - INFO - __main__ - ['neutral']
05/23/2022 00:49:42 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:49:43 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:49:43 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 00:49:43 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 00:49:43 - INFO - __main__ - Printing 3 examples
05/23/2022 00:49:43 - INFO - __main__ -  [anli] premise: Arlette Roxburgh is a Trinidadian American singer and songwriter. She was born in Trinidad. She is best known for singing The Star-Spangled Banner before every New Jersey Devils home game started. When the Nets were in New Jersey, she also sang the national anthem before their home games at the time as well. [SEP] hypothesis: Arlette Roxburgh has only ever sung for the New Jersey Devils.
05/23/2022 00:49:43 - INFO - __main__ - ['neutral']
05/23/2022 00:49:43 - INFO - __main__ -  [anli] premise: Storm Keating (born 27 October 1981) is an Australian-born fashion designer, brand ambassador, producer-director and blogger, now based in London. Keating has worked on a number of Australian and British television programmes such as "The Apprentice Australia", "Masterchef Australia", "The X Factor", "The Voice Australia", and "The Voice UK". She is the wife of Ronan Keating. [SEP] hypothesis: Storm Keaton learned about fashion while studying abroad in the United States.
05/23/2022 00:49:43 - INFO - __main__ - ['neutral']
05/23/2022 00:49:43 - INFO - __main__ -  [anli] premise: Piton is a Pilsner beer brand from the island of Saint Lucia, brewed by Windward & Leeward Brewing Limited, which is owned by Heineken. The beer was named for the Gros Piton and Petit Piton mountains on the island. It was first brewed on October 7, 1992. [SEP] hypothesis: Heineken plans to stop production of Piton in the near future
05/23/2022 00:49:43 - INFO - __main__ - ['neutral']
05/23/2022 00:49:43 - INFO - __main__ - Tokenizing Input ...
05/23/2022 00:49:43 - INFO - __main__ - Tokenizing Output ...
05/23/2022 00:49:44 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 00:49:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 00:49:54 - INFO - __main__ - Starting training!
05/23/2022 00:49:58 - INFO - __main__ - Step 10 Global step 10 Train loss 24.864838 on epoch=0
05/23/2022 00:50:03 - INFO - __main__ - Step 20 Global step 20 Train loss 22.999531 on epoch=0
05/23/2022 00:50:08 - INFO - __main__ - Step 30 Global step 30 Train loss 17.126860 on epoch=1
05/23/2022 00:50:14 - INFO - __main__ - Step 40 Global step 40 Train loss 12.792951 on epoch=1
05/23/2022 00:50:19 - INFO - __main__ - Step 50 Global step 50 Train loss 13.363086 on epoch=2
05/23/2022 00:50:30 - INFO - __main__ - Global step 50 Train loss 18.229452 Classification-F1 0.007575757575757576 on epoch=2
05/23/2022 00:50:36 - INFO - __main__ - Step 60 Global step 60 Train loss 11.576512 on epoch=2
05/23/2022 00:50:41 - INFO - __main__ - Step 70 Global step 70 Train loss 12.210320 on epoch=2
05/23/2022 00:50:47 - INFO - __main__ - Step 80 Global step 80 Train loss 12.898027 on epoch=3
05/23/2022 00:50:52 - INFO - __main__ - Step 90 Global step 90 Train loss 10.861410 on epoch=3
05/23/2022 00:50:57 - INFO - __main__ - Step 100 Global step 100 Train loss 11.727501 on epoch=4
05/23/2022 00:51:04 - INFO - __main__ - Global step 100 Train loss 11.854753 Classification-F1 0.0 on epoch=4
05/23/2022 00:51:09 - INFO - __main__ - Step 110 Global step 110 Train loss 10.704836 on epoch=4
05/23/2022 00:51:14 - INFO - __main__ - Step 120 Global step 120 Train loss 11.315786 on epoch=4
05/23/2022 00:51:19 - INFO - __main__ - Step 130 Global step 130 Train loss 10.901088 on epoch=5
05/23/2022 00:51:24 - INFO - __main__ - Step 140 Global step 140 Train loss 11.186317 on epoch=5
05/23/2022 00:51:29 - INFO - __main__ - Step 150 Global step 150 Train loss 10.340487 on epoch=6
05/23/2022 00:51:37 - INFO - __main__ - Global step 150 Train loss 10.889702 Classification-F1 0.0 on epoch=6
05/23/2022 00:51:42 - INFO - __main__ - Step 160 Global step 160 Train loss 9.976728 on epoch=6
05/23/2022 00:51:47 - INFO - __main__ - Step 170 Global step 170 Train loss 10.661404 on epoch=7
05/23/2022 00:51:52 - INFO - __main__ - Step 180 Global step 180 Train loss 10.348417 on epoch=7
05/23/2022 00:51:57 - INFO - __main__ - Step 190 Global step 190 Train loss 9.984625 on epoch=7
05/23/2022 00:52:02 - INFO - __main__ - Step 200 Global step 200 Train loss 9.705345 on epoch=8
05/23/2022 00:52:11 - INFO - __main__ - Global step 200 Train loss 10.135303 Classification-F1 0.008278145695364239 on epoch=8
05/23/2022 00:52:17 - INFO - __main__ - Step 210 Global step 210 Train loss 9.868585 on epoch=8
05/23/2022 00:52:22 - INFO - __main__ - Step 220 Global step 220 Train loss 9.191132 on epoch=9
05/23/2022 00:52:27 - INFO - __main__ - Step 230 Global step 230 Train loss 9.171698 on epoch=9
05/23/2022 00:52:32 - INFO - __main__ - Step 240 Global step 240 Train loss 8.979034 on epoch=9
05/23/2022 00:52:37 - INFO - __main__ - Step 250 Global step 250 Train loss 8.856775 on epoch=10
05/23/2022 00:52:44 - INFO - __main__ - Global step 250 Train loss 9.213445 Classification-F1 0.0 on epoch=10
05/23/2022 00:52:49 - INFO - __main__ - Step 260 Global step 260 Train loss 8.741919 on epoch=10
05/23/2022 00:52:54 - INFO - __main__ - Step 270 Global step 270 Train loss 9.101110 on epoch=11
05/23/2022 00:53:00 - INFO - __main__ - Step 280 Global step 280 Train loss 7.038649 on epoch=11
05/23/2022 00:53:05 - INFO - __main__ - Step 290 Global step 290 Train loss 8.057371 on epoch=12
05/23/2022 00:53:10 - INFO - __main__ - Step 300 Global step 300 Train loss 6.963079 on epoch=12
05/23/2022 00:53:17 - INFO - __main__ - Global step 300 Train loss 7.980426 Classification-F1 0.0031007751937984496 on epoch=12
05/23/2022 00:53:22 - INFO - __main__ - Step 310 Global step 310 Train loss 7.577856 on epoch=12
05/23/2022 00:53:27 - INFO - __main__ - Step 320 Global step 320 Train loss 6.992085 on epoch=13
05/23/2022 00:53:33 - INFO - __main__ - Step 330 Global step 330 Train loss 6.121719 on epoch=13
05/23/2022 00:53:38 - INFO - __main__ - Step 340 Global step 340 Train loss 5.425183 on epoch=14
05/23/2022 00:53:43 - INFO - __main__ - Step 350 Global step 350 Train loss 5.369220 on epoch=14
05/23/2022 00:53:51 - INFO - __main__ - Global step 350 Train loss 6.297212 Classification-F1 0.0019083969465648854 on epoch=14
05/23/2022 00:53:56 - INFO - __main__ - Step 360 Global step 360 Train loss 4.562982 on epoch=14
05/23/2022 00:54:01 - INFO - __main__ - Step 370 Global step 370 Train loss 4.321702 on epoch=15
05/23/2022 00:54:06 - INFO - __main__ - Step 380 Global step 380 Train loss 3.720016 on epoch=15
05/23/2022 00:54:11 - INFO - __main__ - Step 390 Global step 390 Train loss 3.671366 on epoch=16
05/23/2022 00:54:17 - INFO - __main__ - Step 400 Global step 400 Train loss 3.469483 on epoch=16
05/23/2022 00:54:23 - INFO - __main__ - Global step 400 Train loss 3.949110 Classification-F1 0.06993006993006992 on epoch=16
05/23/2022 00:54:29 - INFO - __main__ - Step 410 Global step 410 Train loss 3.721568 on epoch=17
05/23/2022 00:54:35 - INFO - __main__ - Step 420 Global step 420 Train loss 2.585352 on epoch=17
05/23/2022 00:54:40 - INFO - __main__ - Step 430 Global step 430 Train loss 2.908938 on epoch=17
05/23/2022 00:54:45 - INFO - __main__ - Step 440 Global step 440 Train loss 3.288619 on epoch=18
05/23/2022 00:54:50 - INFO - __main__ - Step 450 Global step 450 Train loss 2.105839 on epoch=18
05/23/2022 00:54:56 - INFO - __main__ - Global step 450 Train loss 2.922063 Classification-F1 0.16666666666666666 on epoch=18
05/23/2022 00:55:02 - INFO - __main__ - Step 460 Global step 460 Train loss 2.576324 on epoch=19
05/23/2022 00:55:08 - INFO - __main__ - Step 470 Global step 470 Train loss 2.581667 on epoch=19
05/23/2022 00:55:13 - INFO - __main__ - Step 480 Global step 480 Train loss 3.532155 on epoch=19
05/23/2022 00:55:18 - INFO - __main__ - Step 490 Global step 490 Train loss 2.556082 on epoch=20
05/23/2022 00:55:23 - INFO - __main__ - Step 500 Global step 500 Train loss 3.128997 on epoch=20
05/23/2022 00:55:30 - INFO - __main__ - Global step 500 Train loss 2.875046 Classification-F1 0.16666666666666666 on epoch=20
05/23/2022 00:55:35 - INFO - __main__ - Step 510 Global step 510 Train loss 2.769147 on epoch=21
05/23/2022 00:55:40 - INFO - __main__ - Step 520 Global step 520 Train loss 2.504802 on epoch=21
05/23/2022 00:55:45 - INFO - __main__ - Step 530 Global step 530 Train loss 2.313884 on epoch=22
05/23/2022 00:55:51 - INFO - __main__ - Step 540 Global step 540 Train loss 2.562232 on epoch=22
05/23/2022 00:55:56 - INFO - __main__ - Step 550 Global step 550 Train loss 2.839828 on epoch=22
05/23/2022 00:56:02 - INFO - __main__ - Global step 550 Train loss 2.597978 Classification-F1 0.16666666666666666 on epoch=22
05/23/2022 00:56:07 - INFO - __main__ - Step 560 Global step 560 Train loss 2.343228 on epoch=23
05/23/2022 00:56:12 - INFO - __main__ - Step 570 Global step 570 Train loss 2.627310 on epoch=23
05/23/2022 00:56:18 - INFO - __main__ - Step 580 Global step 580 Train loss 2.579454 on epoch=24
05/23/2022 00:56:23 - INFO - __main__ - Step 590 Global step 590 Train loss 2.746131 on epoch=24
05/23/2022 00:56:28 - INFO - __main__ - Step 600 Global step 600 Train loss 2.342111 on epoch=24
05/23/2022 00:56:34 - INFO - __main__ - Global step 600 Train loss 2.527647 Classification-F1 0.16666666666666666 on epoch=24
05/23/2022 00:56:39 - INFO - __main__ - Step 610 Global step 610 Train loss 1.982489 on epoch=25
05/23/2022 00:56:44 - INFO - __main__ - Step 620 Global step 620 Train loss 2.473229 on epoch=25
05/23/2022 00:56:50 - INFO - __main__ - Step 630 Global step 630 Train loss 2.469464 on epoch=26
05/23/2022 00:56:55 - INFO - __main__ - Step 640 Global step 640 Train loss 2.943030 on epoch=26
05/23/2022 00:57:00 - INFO - __main__ - Step 650 Global step 650 Train loss 1.889614 on epoch=27
05/23/2022 00:57:06 - INFO - __main__ - Global step 650 Train loss 2.351565 Classification-F1 0.16666666666666666 on epoch=27
05/23/2022 00:57:11 - INFO - __main__ - Step 660 Global step 660 Train loss 2.058966 on epoch=27
05/23/2022 00:57:16 - INFO - __main__ - Step 670 Global step 670 Train loss 2.270162 on epoch=27
05/23/2022 00:57:21 - INFO - __main__ - Step 680 Global step 680 Train loss 2.233059 on epoch=28
05/23/2022 00:57:26 - INFO - __main__ - Step 690 Global step 690 Train loss 2.261241 on epoch=28
05/23/2022 00:57:32 - INFO - __main__ - Step 700 Global step 700 Train loss 2.087270 on epoch=29
05/23/2022 00:57:37 - INFO - __main__ - Global step 700 Train loss 2.182140 Classification-F1 0.18137254901960784 on epoch=29
05/23/2022 00:57:43 - INFO - __main__ - Step 710 Global step 710 Train loss 1.709038 on epoch=29
05/23/2022 00:57:49 - INFO - __main__ - Step 720 Global step 720 Train loss 2.005374 on epoch=29
05/23/2022 00:57:54 - INFO - __main__ - Step 730 Global step 730 Train loss 1.761015 on epoch=30
05/23/2022 00:57:59 - INFO - __main__ - Step 740 Global step 740 Train loss 1.755025 on epoch=30
05/23/2022 00:58:04 - INFO - __main__ - Step 750 Global step 750 Train loss 1.854583 on epoch=31
05/23/2022 00:58:10 - INFO - __main__ - Global step 750 Train loss 1.817007 Classification-F1 0.29046726849486176 on epoch=31
05/23/2022 00:58:16 - INFO - __main__ - Step 760 Global step 760 Train loss 1.905883 on epoch=31
05/23/2022 00:58:21 - INFO - __main__ - Step 770 Global step 770 Train loss 2.151362 on epoch=32
05/23/2022 00:58:26 - INFO - __main__ - Step 780 Global step 780 Train loss 2.070500 on epoch=32
05/23/2022 00:58:32 - INFO - __main__ - Step 790 Global step 790 Train loss 2.147643 on epoch=32
05/23/2022 00:58:37 - INFO - __main__ - Step 800 Global step 800 Train loss 1.449051 on epoch=33
05/23/2022 00:58:42 - INFO - __main__ - Global step 800 Train loss 1.944888 Classification-F1 0.16666666666666666 on epoch=33
05/23/2022 00:58:48 - INFO - __main__ - Step 810 Global step 810 Train loss 1.760597 on epoch=33
05/23/2022 00:58:53 - INFO - __main__ - Step 820 Global step 820 Train loss 1.874706 on epoch=34
05/23/2022 00:58:58 - INFO - __main__ - Step 830 Global step 830 Train loss 1.708234 on epoch=34
05/23/2022 00:59:03 - INFO - __main__ - Step 840 Global step 840 Train loss 1.397332 on epoch=34
05/23/2022 00:59:09 - INFO - __main__ - Step 850 Global step 850 Train loss 1.722985 on epoch=35
05/23/2022 00:59:14 - INFO - __main__ - Global step 850 Train loss 1.692770 Classification-F1 0.25330380214101145 on epoch=35
05/23/2022 00:59:19 - INFO - __main__ - Step 860 Global step 860 Train loss 1.579996 on epoch=35
05/23/2022 00:59:25 - INFO - __main__ - Step 870 Global step 870 Train loss 1.625842 on epoch=36
05/23/2022 00:59:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.676682 on epoch=36
05/23/2022 00:59:35 - INFO - __main__ - Step 890 Global step 890 Train loss 1.647430 on epoch=37
05/23/2022 00:59:40 - INFO - __main__ - Step 900 Global step 900 Train loss 1.844208 on epoch=37
05/23/2022 00:59:46 - INFO - __main__ - Global step 900 Train loss 1.674832 Classification-F1 0.16666666666666666 on epoch=37
05/23/2022 00:59:51 - INFO - __main__ - Step 910 Global step 910 Train loss 1.435475 on epoch=37
05/23/2022 00:59:56 - INFO - __main__ - Step 920 Global step 920 Train loss 1.123587 on epoch=38
05/23/2022 01:00:01 - INFO - __main__ - Step 930 Global step 930 Train loss 1.484154 on epoch=38
05/23/2022 01:00:07 - INFO - __main__ - Step 940 Global step 940 Train loss 1.452443 on epoch=39
05/23/2022 01:00:12 - INFO - __main__ - Step 950 Global step 950 Train loss 1.463024 on epoch=39
05/23/2022 01:00:18 - INFO - __main__ - Global step 950 Train loss 1.391736 Classification-F1 0.16666666666666666 on epoch=39
05/23/2022 01:00:23 - INFO - __main__ - Step 960 Global step 960 Train loss 1.398308 on epoch=39
05/23/2022 01:00:29 - INFO - __main__ - Step 970 Global step 970 Train loss 1.245061 on epoch=40
05/23/2022 01:00:34 - INFO - __main__ - Step 980 Global step 980 Train loss 1.348279 on epoch=40
05/23/2022 01:00:39 - INFO - __main__ - Step 990 Global step 990 Train loss 1.294900 on epoch=41
05/23/2022 01:00:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.365203 on epoch=41
05/23/2022 01:00:45 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:00:45 - INFO - __main__ - Printing 3 examples
05/23/2022 01:00:45 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:00:45 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:45 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:00:45 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:45 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:00:45 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:45 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:00:46 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:00:46 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:00:46 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:00:46 - INFO - __main__ - Printing 3 examples
05/23/2022 01:00:46 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:00:46 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:46 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:00:46 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:46 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:00:46 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:46 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:00:46 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:00:47 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:00:50 - INFO - __main__ - Global step 1000 Train loss 1.330350 Classification-F1 0.16666666666666666 on epoch=41
05/23/2022 01:00:50 - INFO - __main__ - save last model!
05/23/2022 01:00:58 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 01:00:58 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 01:00:58 - INFO - __main__ - Printing 3 examples
05/23/2022 01:00:58 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 01:00:58 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:58 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 01:00:58 - INFO - __main__ - ['entailment']
05/23/2022 01:00:58 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 01:00:58 - INFO - __main__ - ['contradiction']
05/23/2022 01:00:58 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:00:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:00:59 - INFO - __main__ - Starting training!
05/23/2022 01:00:59 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:01:00 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 01:01:15 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_42_0.0001_8_predictions.txt
05/23/2022 01:01:15 - INFO - __main__ - Classification-F1 on test data: 0.2584
05/23/2022 01:01:15 - INFO - __main__ - prefix=anli_128_42, lr=0.0001, bsz=8, dev_performance=0.29046726849486176, test_performance=0.25835346859112857
05/23/2022 01:01:15 - INFO - __main__ - Running ... prefix=anli_128_87, lr=0.0005, bsz=8 ...
05/23/2022 01:01:16 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:01:16 - INFO - __main__ - Printing 3 examples
05/23/2022 01:01:16 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:01:16 - INFO - __main__ - ['contradiction']
05/23/2022 01:01:16 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:01:16 - INFO - __main__ - ['contradiction']
05/23/2022 01:01:16 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:01:16 - INFO - __main__ - ['contradiction']
05/23/2022 01:01:16 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:01:17 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:01:17 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:01:17 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:01:17 - INFO - __main__ - Printing 3 examples
05/23/2022 01:01:17 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:01:17 - INFO - __main__ - ['contradiction']
05/23/2022 01:01:17 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:01:17 - INFO - __main__ - ['contradiction']
05/23/2022 01:01:17 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:01:17 - INFO - __main__ - ['contradiction']
05/23/2022 01:01:17 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:01:17 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:01:18 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:01:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:01:28 - INFO - __main__ - Starting training!
05/23/2022 01:01:33 - INFO - __main__ - Step 10 Global step 10 Train loss 24.134995 on epoch=0
05/23/2022 01:01:38 - INFO - __main__ - Step 20 Global step 20 Train loss 14.602297 on epoch=0
05/23/2022 01:01:43 - INFO - __main__ - Step 30 Global step 30 Train loss 12.021067 on epoch=1
05/23/2022 01:01:48 - INFO - __main__ - Step 40 Global step 40 Train loss 10.871696 on epoch=1
05/23/2022 01:01:53 - INFO - __main__ - Step 50 Global step 50 Train loss 8.849212 on epoch=2
05/23/2022 01:02:01 - INFO - __main__ - Global step 50 Train loss 14.095855 Classification-F1 0.16666666666666666 on epoch=2
05/23/2022 01:02:07 - INFO - __main__ - Step 60 Global step 60 Train loss 8.632337 on epoch=2
05/23/2022 01:02:12 - INFO - __main__ - Step 70 Global step 70 Train loss 6.607265 on epoch=2
05/23/2022 01:02:17 - INFO - __main__ - Step 80 Global step 80 Train loss 5.179209 on epoch=3
05/23/2022 01:02:22 - INFO - __main__ - Step 90 Global step 90 Train loss 3.331599 on epoch=3
05/23/2022 01:02:28 - INFO - __main__ - Step 100 Global step 100 Train loss 2.741937 on epoch=4
05/23/2022 01:02:34 - INFO - __main__ - Global step 100 Train loss 5.298469 Classification-F1 0.16666666666666666 on epoch=4
05/23/2022 01:02:39 - INFO - __main__ - Step 110 Global step 110 Train loss 2.096105 on epoch=4
05/23/2022 01:02:44 - INFO - __main__ - Step 120 Global step 120 Train loss 2.246712 on epoch=4
05/23/2022 01:02:49 - INFO - __main__ - Step 130 Global step 130 Train loss 1.928481 on epoch=5
05/23/2022 01:02:55 - INFO - __main__ - Step 140 Global step 140 Train loss 1.608472 on epoch=5
05/23/2022 01:03:00 - INFO - __main__ - Step 150 Global step 150 Train loss 2.069968 on epoch=6
05/23/2022 01:03:06 - INFO - __main__ - Global step 150 Train loss 1.989948 Classification-F1 0.16666666666666666 on epoch=6
05/23/2022 01:03:11 - INFO - __main__ - Step 160 Global step 160 Train loss 1.699289 on epoch=6
05/23/2022 01:03:16 - INFO - __main__ - Step 170 Global step 170 Train loss 1.316376 on epoch=7
05/23/2022 01:03:22 - INFO - __main__ - Step 180 Global step 180 Train loss 1.590188 on epoch=7
05/23/2022 01:03:27 - INFO - __main__ - Step 190 Global step 190 Train loss 1.226965 on epoch=7
05/23/2022 01:03:32 - INFO - __main__ - Step 200 Global step 200 Train loss 1.046612 on epoch=8
05/23/2022 01:03:38 - INFO - __main__ - Global step 200 Train loss 1.375886 Classification-F1 0.27091696808299215 on epoch=8
05/23/2022 01:03:44 - INFO - __main__ - Step 210 Global step 210 Train loss 1.159523 on epoch=8
05/23/2022 01:03:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.749220 on epoch=9
05/23/2022 01:03:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.863499 on epoch=9
05/23/2022 01:03:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.798066 on epoch=9
05/23/2022 01:04:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.676492 on epoch=10
05/23/2022 01:04:11 - INFO - __main__ - Global step 250 Train loss 0.849360 Classification-F1 0.16666666666666666 on epoch=10
05/23/2022 01:04:16 - INFO - __main__ - Step 260 Global step 260 Train loss 0.633569 on epoch=10
05/23/2022 01:04:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.635801 on epoch=11
05/23/2022 01:04:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.610947 on epoch=11
05/23/2022 01:04:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.532593 on epoch=12
05/23/2022 01:04:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.718504 on epoch=12
05/23/2022 01:04:42 - INFO - __main__ - Global step 300 Train loss 0.626283 Classification-F1 0.16666666666666666 on epoch=12
05/23/2022 01:04:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.554139 on epoch=12
05/23/2022 01:04:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.717207 on epoch=13
05/23/2022 01:04:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.561898 on epoch=13
05/23/2022 01:05:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.520937 on epoch=14
05/23/2022 01:05:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.475877 on epoch=14
05/23/2022 01:05:14 - INFO - __main__ - Global step 350 Train loss 0.566011 Classification-F1 0.20833333333333334 on epoch=14
05/23/2022 01:05:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.456936 on epoch=14
05/23/2022 01:05:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.578247 on epoch=15
05/23/2022 01:05:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.550034 on epoch=15
05/23/2022 01:05:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.457447 on epoch=16
05/23/2022 01:05:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.576625 on epoch=16
05/23/2022 01:05:47 - INFO - __main__ - Global step 400 Train loss 0.523858 Classification-F1 0.2556664002838214 on epoch=16
05/23/2022 01:05:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.429433 on epoch=17
05/23/2022 01:05:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.468705 on epoch=17
05/23/2022 01:06:03 - INFO - __main__ - Step 430 Global step 430 Train loss 0.447615 on epoch=17
05/23/2022 01:06:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.515745 on epoch=18
05/23/2022 01:06:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.490316 on epoch=18
05/23/2022 01:06:20 - INFO - __main__ - Global step 450 Train loss 0.470362 Classification-F1 0.16601307189542483 on epoch=18
05/23/2022 01:06:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.524125 on epoch=19
05/23/2022 01:06:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.473789 on epoch=19
05/23/2022 01:06:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.579120 on epoch=19
05/23/2022 01:06:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.404160 on epoch=20
05/23/2022 01:06:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.407912 on epoch=20
05/23/2022 01:06:52 - INFO - __main__ - Global step 500 Train loss 0.477821 Classification-F1 0.2310585793731861 on epoch=20
05/23/2022 01:06:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.442350 on epoch=21
05/23/2022 01:07:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.520973 on epoch=21
05/23/2022 01:07:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.408200 on epoch=22
05/23/2022 01:07:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.454403 on epoch=22
05/23/2022 01:07:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.403606 on epoch=22
05/23/2022 01:07:25 - INFO - __main__ - Global step 550 Train loss 0.445906 Classification-F1 0.32212769419737947 on epoch=22
05/23/2022 01:07:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.417680 on epoch=23
05/23/2022 01:07:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.394964 on epoch=23
05/23/2022 01:07:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.372136 on epoch=24
05/23/2022 01:07:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.413976 on epoch=24
05/23/2022 01:07:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.310259 on epoch=24
05/23/2022 01:07:58 - INFO - __main__ - Global step 600 Train loss 0.381803 Classification-F1 0.26975151000315173 on epoch=24
05/23/2022 01:08:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.353389 on epoch=25
05/23/2022 01:08:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.317184 on epoch=25
05/23/2022 01:08:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.295582 on epoch=26
05/23/2022 01:08:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.297530 on epoch=26
05/23/2022 01:08:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.290868 on epoch=27
05/23/2022 01:08:31 - INFO - __main__ - Global step 650 Train loss 0.310911 Classification-F1 0.28880230880230884 on epoch=27
05/23/2022 01:08:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.312814 on epoch=27
05/23/2022 01:08:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.247262 on epoch=27
05/23/2022 01:08:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.136656 on epoch=28
05/23/2022 01:08:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.130546 on epoch=28
05/23/2022 01:08:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.145088 on epoch=29
05/23/2022 01:09:03 - INFO - __main__ - Global step 700 Train loss 0.194473 Classification-F1 0.33849507585207356 on epoch=29
05/23/2022 01:09:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.137517 on epoch=29
05/23/2022 01:09:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.096716 on epoch=29
05/23/2022 01:09:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.131341 on epoch=30
05/23/2022 01:09:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.087769 on epoch=30
05/23/2022 01:09:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.135577 on epoch=31
05/23/2022 01:09:37 - INFO - __main__ - Global step 750 Train loss 0.117784 Classification-F1 0.42795344363971816 on epoch=31
05/23/2022 01:09:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.038218 on epoch=31
05/23/2022 01:09:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.062525 on epoch=32
05/23/2022 01:09:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.071855 on epoch=32
05/23/2022 01:09:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.047644 on epoch=32
05/23/2022 01:10:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.028506 on epoch=33
05/23/2022 01:10:11 - INFO - __main__ - Global step 800 Train loss 0.049750 Classification-F1 0.48500881834215165 on epoch=33
05/23/2022 01:10:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.040408 on epoch=33
05/23/2022 01:10:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.027624 on epoch=34
05/23/2022 01:10:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.066826 on epoch=34
05/23/2022 01:10:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.035554 on epoch=34
05/23/2022 01:10:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.213471 on epoch=35
05/23/2022 01:10:45 - INFO - __main__ - Global step 850 Train loss 0.076777 Classification-F1 0.44270406063093143 on epoch=35
05/23/2022 01:10:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.016592 on epoch=35
05/23/2022 01:10:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.009832 on epoch=36
05/23/2022 01:11:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.044115 on epoch=36
05/23/2022 01:11:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.093148 on epoch=37
05/23/2022 01:11:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.302885 on epoch=37
05/23/2022 01:11:17 - INFO - __main__ - Global step 900 Train loss 0.093314 Classification-F1 0.46797545218424846 on epoch=37
05/23/2022 01:11:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.327326 on epoch=37
05/23/2022 01:11:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.116250 on epoch=38
05/23/2022 01:11:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.035178 on epoch=38
05/23/2022 01:11:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.069622 on epoch=39
05/23/2022 01:11:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.013607 on epoch=39
05/23/2022 01:11:50 - INFO - __main__ - Global step 950 Train loss 0.112397 Classification-F1 0.49634527590232724 on epoch=39
05/23/2022 01:11:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.034013 on epoch=39
05/23/2022 01:12:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.032104 on epoch=40
05/23/2022 01:12:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.021442 on epoch=40
05/23/2022 01:12:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.017658 on epoch=41
05/23/2022 01:12:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.035308 on epoch=41
05/23/2022 01:12:18 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:12:18 - INFO - __main__ - Printing 3 examples
05/23/2022 01:12:18 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:12:18 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:18 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:12:18 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:18 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:12:18 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:18 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:12:18 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:12:18 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:12:18 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:12:18 - INFO - __main__ - Printing 3 examples
05/23/2022 01:12:18 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:12:18 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:18 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:12:18 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:18 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:12:18 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:18 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:12:19 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:12:19 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:12:24 - INFO - __main__ - Global step 1000 Train loss 0.028105 Classification-F1 0.45971440501686595 on epoch=41
05/23/2022 01:12:24 - INFO - __main__ - save last model!
05/23/2022 01:12:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:12:30 - INFO - __main__ - Starting training!
05/23/2022 01:12:32 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 01:12:32 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 01:12:32 - INFO - __main__ - Printing 3 examples
05/23/2022 01:12:32 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 01:12:32 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:32 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 01:12:32 - INFO - __main__ - ['entailment']
05/23/2022 01:12:32 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 01:12:32 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:32 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:12:33 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:12:34 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 01:12:53 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_87_0.0005_8_predictions.txt
05/23/2022 01:12:53 - INFO - __main__ - Classification-F1 on test data: 0.2459
05/23/2022 01:12:53 - INFO - __main__ - prefix=anli_128_87, lr=0.0005, bsz=8, dev_performance=0.49634527590232724, test_performance=0.24592239432970614
05/23/2022 01:12:53 - INFO - __main__ - Running ... prefix=anli_128_87, lr=0.0003, bsz=8 ...
05/23/2022 01:12:54 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:12:54 - INFO - __main__ - Printing 3 examples
05/23/2022 01:12:54 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:12:54 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:54 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:12:54 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:54 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:12:54 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:54 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:12:54 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:12:55 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:12:55 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:12:55 - INFO - __main__ - Printing 3 examples
05/23/2022 01:12:55 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:12:55 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:55 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:12:55 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:55 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:12:55 - INFO - __main__ - ['contradiction']
05/23/2022 01:12:55 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:12:55 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:12:56 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:13:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:13:06 - INFO - __main__ - Starting training!
05/23/2022 01:13:10 - INFO - __main__ - Step 10 Global step 10 Train loss 25.139442 on epoch=0
05/23/2022 01:13:15 - INFO - __main__ - Step 20 Global step 20 Train loss 21.164825 on epoch=0
05/23/2022 01:13:20 - INFO - __main__ - Step 30 Global step 30 Train loss 13.770602 on epoch=1
05/23/2022 01:13:25 - INFO - __main__ - Step 40 Global step 40 Train loss 11.785352 on epoch=1
05/23/2022 01:13:30 - INFO - __main__ - Step 50 Global step 50 Train loss 10.425165 on epoch=2
05/23/2022 01:13:38 - INFO - __main__ - Global step 50 Train loss 16.457077 Classification-F1 0.008823529411764706 on epoch=2
05/23/2022 01:13:44 - INFO - __main__ - Step 60 Global step 60 Train loss 11.216019 on epoch=2
05/23/2022 01:13:49 - INFO - __main__ - Step 70 Global step 70 Train loss 9.187836 on epoch=2
05/23/2022 01:13:54 - INFO - __main__ - Step 80 Global step 80 Train loss 8.869314 on epoch=3
05/23/2022 01:13:59 - INFO - __main__ - Step 90 Global step 90 Train loss 8.056900 on epoch=3
05/23/2022 01:14:04 - INFO - __main__ - Step 100 Global step 100 Train loss 7.553673 on epoch=4
05/23/2022 01:14:11 - INFO - __main__ - Global step 100 Train loss 8.976748 Classification-F1 0.0 on epoch=4
05/23/2022 01:14:16 - INFO - __main__ - Step 110 Global step 110 Train loss 6.648667 on epoch=4
05/23/2022 01:14:21 - INFO - __main__ - Step 120 Global step 120 Train loss 5.882450 on epoch=4
05/23/2022 01:14:27 - INFO - __main__ - Step 130 Global step 130 Train loss 4.662637 on epoch=5
05/23/2022 01:14:32 - INFO - __main__ - Step 140 Global step 140 Train loss 3.720861 on epoch=5
05/23/2022 01:14:37 - INFO - __main__ - Step 150 Global step 150 Train loss 2.879741 on epoch=6
05/23/2022 01:15:26 - INFO - __main__ - Global step 150 Train loss 4.758871 Classification-F1 0.1007936507936508 on epoch=6
05/23/2022 01:15:32 - INFO - __main__ - Step 160 Global step 160 Train loss 2.689358 on epoch=6
05/23/2022 01:15:37 - INFO - __main__ - Step 170 Global step 170 Train loss 2.607956 on epoch=7
05/23/2022 01:15:42 - INFO - __main__ - Step 180 Global step 180 Train loss 1.981382 on epoch=7
05/23/2022 01:15:47 - INFO - __main__ - Step 190 Global step 190 Train loss 1.882880 on epoch=7
05/23/2022 01:15:52 - INFO - __main__ - Step 200 Global step 200 Train loss 2.546083 on epoch=8
05/23/2022 01:15:58 - INFO - __main__ - Global step 200 Train loss 2.341532 Classification-F1 0.2423272453398607 on epoch=8
05/23/2022 01:16:03 - INFO - __main__ - Step 210 Global step 210 Train loss 1.819314 on epoch=8
05/23/2022 01:16:09 - INFO - __main__ - Step 220 Global step 220 Train loss 1.834880 on epoch=9
05/23/2022 01:16:14 - INFO - __main__ - Step 230 Global step 230 Train loss 1.900118 on epoch=9
05/23/2022 01:16:19 - INFO - __main__ - Step 240 Global step 240 Train loss 1.799455 on epoch=9
05/23/2022 01:16:24 - INFO - __main__ - Step 250 Global step 250 Train loss 1.990342 on epoch=10
05/23/2022 01:16:30 - INFO - __main__ - Global step 250 Train loss 1.868822 Classification-F1 0.16666666666666666 on epoch=10
05/23/2022 01:16:35 - INFO - __main__ - Step 260 Global step 260 Train loss 1.424533 on epoch=10
05/23/2022 01:16:40 - INFO - __main__ - Step 270 Global step 270 Train loss 1.507474 on epoch=11
05/23/2022 01:16:45 - INFO - __main__ - Step 280 Global step 280 Train loss 1.426188 on epoch=11
05/23/2022 01:16:50 - INFO - __main__ - Step 290 Global step 290 Train loss 1.314025 on epoch=12
05/23/2022 01:16:56 - INFO - __main__ - Step 300 Global step 300 Train loss 1.128048 on epoch=12
05/23/2022 01:17:00 - INFO - __main__ - Global step 300 Train loss 1.360054 Classification-F1 0.16666666666666666 on epoch=12
05/23/2022 01:17:05 - INFO - __main__ - Step 310 Global step 310 Train loss 1.143801 on epoch=12
05/23/2022 01:17:11 - INFO - __main__ - Step 320 Global step 320 Train loss 1.137896 on epoch=13
05/23/2022 01:17:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.916745 on epoch=13
05/23/2022 01:17:21 - INFO - __main__ - Step 340 Global step 340 Train loss 1.088254 on epoch=14
05/23/2022 01:17:26 - INFO - __main__ - Step 350 Global step 350 Train loss 1.072732 on epoch=14
05/23/2022 01:17:33 - INFO - __main__ - Global step 350 Train loss 1.071886 Classification-F1 0.17833538481311761 on epoch=14
05/23/2022 01:17:38 - INFO - __main__ - Step 360 Global step 360 Train loss 1.243601 on epoch=14
05/23/2022 01:17:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.769567 on epoch=15
05/23/2022 01:17:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.772733 on epoch=15
05/23/2022 01:17:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.811757 on epoch=16
05/23/2022 01:17:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.654634 on epoch=16
05/23/2022 01:18:06 - INFO - __main__ - Global step 400 Train loss 0.850458 Classification-F1 0.2713967566080242 on epoch=16
05/23/2022 01:18:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.637025 on epoch=17
05/23/2022 01:18:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.625434 on epoch=17
05/23/2022 01:18:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.736257 on epoch=17
05/23/2022 01:18:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.662449 on epoch=18
05/23/2022 01:18:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.563280 on epoch=18
05/23/2022 01:18:39 - INFO - __main__ - Global step 450 Train loss 0.644889 Classification-F1 0.1860765360790694 on epoch=18
05/23/2022 01:18:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.511989 on epoch=19
05/23/2022 01:18:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.580410 on epoch=19
05/23/2022 01:18:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.625025 on epoch=19
05/23/2022 01:19:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.564092 on epoch=20
05/23/2022 01:19:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.438104 on epoch=20
05/23/2022 01:19:12 - INFO - __main__ - Global step 500 Train loss 0.543924 Classification-F1 0.2686800166732332 on epoch=20
05/23/2022 01:19:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.497188 on epoch=21
05/23/2022 01:19:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.514707 on epoch=21
05/23/2022 01:19:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.482529 on epoch=22
05/23/2022 01:19:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.439222 on epoch=22
05/23/2022 01:19:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.554695 on epoch=22
05/23/2022 01:19:44 - INFO - __main__ - Global step 550 Train loss 0.497668 Classification-F1 0.1932427725531174 on epoch=22
05/23/2022 01:19:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.484884 on epoch=23
05/23/2022 01:19:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.964465 on epoch=23
05/23/2022 01:20:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.471623 on epoch=24
05/23/2022 01:20:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.526870 on epoch=24
05/23/2022 01:20:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.470932 on epoch=24
05/23/2022 01:20:17 - INFO - __main__ - Global step 600 Train loss 0.583755 Classification-F1 0.20489469615551406 on epoch=24
05/23/2022 01:20:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.437170 on epoch=25
05/23/2022 01:20:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.540311 on epoch=25
05/23/2022 01:20:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.374462 on epoch=26
05/23/2022 01:20:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.467346 on epoch=26
05/23/2022 01:20:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.425553 on epoch=27
05/23/2022 01:20:49 - INFO - __main__ - Global step 650 Train loss 0.448968 Classification-F1 0.262615091468779 on epoch=27
05/23/2022 01:20:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.451983 on epoch=27
05/23/2022 01:20:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.468500 on epoch=27
05/23/2022 01:21:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.476027 on epoch=28
05/23/2022 01:21:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.438239 on epoch=28
05/23/2022 01:21:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.271674 on epoch=29
05/23/2022 01:21:21 - INFO - __main__ - Global step 700 Train loss 0.421284 Classification-F1 0.4223471321983118 on epoch=29
05/23/2022 01:21:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.276501 on epoch=29
05/23/2022 01:21:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.332780 on epoch=29
05/23/2022 01:21:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.307759 on epoch=30
05/23/2022 01:21:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.226642 on epoch=30
05/23/2022 01:21:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.194696 on epoch=31
05/23/2022 01:21:53 - INFO - __main__ - Global step 750 Train loss 0.267675 Classification-F1 0.3802074455660562 on epoch=31
05/23/2022 01:21:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.140651 on epoch=31
05/23/2022 01:22:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.151002 on epoch=32
05/23/2022 01:22:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.160675 on epoch=32
05/23/2022 01:22:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.133705 on epoch=32
05/23/2022 01:22:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.154084 on epoch=33
05/23/2022 01:22:24 - INFO - __main__ - Global step 800 Train loss 0.148023 Classification-F1 0.4510209926089419 on epoch=33
05/23/2022 01:22:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.069482 on epoch=33
05/23/2022 01:22:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.107975 on epoch=34
05/23/2022 01:22:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.084461 on epoch=34
05/23/2022 01:22:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.060220 on epoch=34
05/23/2022 01:22:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.080317 on epoch=35
05/23/2022 01:22:57 - INFO - __main__ - Global step 850 Train loss 0.080491 Classification-F1 0.4928236401456488 on epoch=35
05/23/2022 01:23:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.055061 on epoch=35
05/23/2022 01:23:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.027672 on epoch=36
05/23/2022 01:23:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.022690 on epoch=36
05/23/2022 01:23:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.022476 on epoch=37
05/23/2022 01:23:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.025504 on epoch=37
05/23/2022 01:23:30 - INFO - __main__ - Global step 900 Train loss 0.030680 Classification-F1 0.5341572588631412 on epoch=37
05/23/2022 01:23:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.033406 on epoch=37
05/23/2022 01:23:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.015991 on epoch=38
05/23/2022 01:23:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.060056 on epoch=38
05/23/2022 01:23:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.023667 on epoch=39
05/23/2022 01:23:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.012445 on epoch=39
05/23/2022 01:24:03 - INFO - __main__ - Global step 950 Train loss 0.029113 Classification-F1 0.5570960905384509 on epoch=39
05/23/2022 01:24:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.046695 on epoch=39
05/23/2022 01:24:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.012952 on epoch=40
05/23/2022 01:24:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.027082 on epoch=40
05/23/2022 01:24:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.005406 on epoch=41
05/23/2022 01:24:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.007166 on epoch=41
05/23/2022 01:24:30 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:24:30 - INFO - __main__ - Printing 3 examples
05/23/2022 01:24:30 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:24:30 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:30 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:24:30 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:30 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:24:30 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:30 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:24:30 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:24:31 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:24:31 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:24:31 - INFO - __main__ - Printing 3 examples
05/23/2022 01:24:31 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:24:31 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:31 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:24:31 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:31 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:24:31 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:31 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:24:31 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:24:31 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:24:35 - INFO - __main__ - Global step 1000 Train loss 0.019860 Classification-F1 0.37474220124039614 on epoch=41
05/23/2022 01:24:35 - INFO - __main__ - save last model!
05/23/2022 01:24:42 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 01:24:43 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 01:24:43 - INFO - __main__ - Printing 3 examples
05/23/2022 01:24:43 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 01:24:43 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:43 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 01:24:43 - INFO - __main__ - ['entailment']
05/23/2022 01:24:43 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 01:24:43 - INFO - __main__ - ['contradiction']
05/23/2022 01:24:43 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:24:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:24:43 - INFO - __main__ - Starting training!
05/23/2022 01:24:44 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:24:45 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 01:25:03 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_87_0.0003_8_predictions.txt
05/23/2022 01:25:03 - INFO - __main__ - Classification-F1 on test data: 0.3526
05/23/2022 01:25:04 - INFO - __main__ - prefix=anli_128_87, lr=0.0003, bsz=8, dev_performance=0.5570960905384509, test_performance=0.35259333060018716
05/23/2022 01:25:04 - INFO - __main__ - Running ... prefix=anli_128_87, lr=0.0002, bsz=8 ...
05/23/2022 01:25:05 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:25:05 - INFO - __main__ - Printing 3 examples
05/23/2022 01:25:05 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:25:05 - INFO - __main__ - ['contradiction']
05/23/2022 01:25:05 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:25:05 - INFO - __main__ - ['contradiction']
05/23/2022 01:25:05 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:25:05 - INFO - __main__ - ['contradiction']
05/23/2022 01:25:05 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:25:05 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:25:05 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:25:05 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:25:05 - INFO - __main__ - Printing 3 examples
05/23/2022 01:25:05 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:25:05 - INFO - __main__ - ['contradiction']
05/23/2022 01:25:05 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:25:05 - INFO - __main__ - ['contradiction']
05/23/2022 01:25:05 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:25:05 - INFO - __main__ - ['contradiction']
05/23/2022 01:25:05 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:25:05 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:25:06 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:25:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:25:18 - INFO - __main__ - Starting training!
05/23/2022 01:25:23 - INFO - __main__ - Step 10 Global step 10 Train loss 23.730042 on epoch=0
05/23/2022 01:25:27 - INFO - __main__ - Step 20 Global step 20 Train loss 17.453281 on epoch=0
05/23/2022 01:25:32 - INFO - __main__ - Step 30 Global step 30 Train loss 13.256925 on epoch=1
05/23/2022 01:25:38 - INFO - __main__ - Step 40 Global step 40 Train loss 13.089818 on epoch=1
05/23/2022 01:25:43 - INFO - __main__ - Step 50 Global step 50 Train loss 11.473922 on epoch=2
05/23/2022 01:25:50 - INFO - __main__ - Global step 50 Train loss 15.800797 Classification-F1 0.0 on epoch=2
05/23/2022 01:25:56 - INFO - __main__ - Step 60 Global step 60 Train loss 12.392446 on epoch=2
05/23/2022 01:26:01 - INFO - __main__ - Step 70 Global step 70 Train loss 9.315855 on epoch=2
05/23/2022 01:26:06 - INFO - __main__ - Step 80 Global step 80 Train loss 10.532549 on epoch=3
05/23/2022 01:26:11 - INFO - __main__ - Step 90 Global step 90 Train loss 10.599394 on epoch=3
05/23/2022 01:26:16 - INFO - __main__ - Step 100 Global step 100 Train loss 9.650145 on epoch=4
05/23/2022 01:26:23 - INFO - __main__ - Global step 100 Train loss 10.498077 Classification-F1 0.0 on epoch=4
05/23/2022 01:26:28 - INFO - __main__ - Step 110 Global step 110 Train loss 8.937951 on epoch=4
05/23/2022 01:26:33 - INFO - __main__ - Step 120 Global step 120 Train loss 8.577920 on epoch=4
05/23/2022 01:26:39 - INFO - __main__ - Step 130 Global step 130 Train loss 8.172136 on epoch=5
05/23/2022 01:26:44 - INFO - __main__ - Step 140 Global step 140 Train loss 7.600161 on epoch=5
05/23/2022 01:26:49 - INFO - __main__ - Step 150 Global step 150 Train loss 6.476362 on epoch=6
05/23/2022 01:26:56 - INFO - __main__ - Global step 150 Train loss 7.952906 Classification-F1 0.026490066225165566 on epoch=6
05/23/2022 01:27:02 - INFO - __main__ - Step 160 Global step 160 Train loss 6.606774 on epoch=6
05/23/2022 01:27:07 - INFO - __main__ - Step 170 Global step 170 Train loss 5.010386 on epoch=7
05/23/2022 01:27:12 - INFO - __main__ - Step 180 Global step 180 Train loss 4.977122 on epoch=7
05/23/2022 01:27:17 - INFO - __main__ - Step 190 Global step 190 Train loss 3.628134 on epoch=7
05/23/2022 01:27:22 - INFO - __main__ - Step 200 Global step 200 Train loss 2.931161 on epoch=8
05/23/2022 01:27:29 - INFO - __main__ - Global step 200 Train loss 4.630715 Classification-F1 0.0826689650219062 on epoch=8
05/23/2022 01:27:34 - INFO - __main__ - Step 210 Global step 210 Train loss 2.694079 on epoch=8
05/23/2022 01:27:39 - INFO - __main__ - Step 220 Global step 220 Train loss 2.980109 on epoch=9
05/23/2022 01:27:44 - INFO - __main__ - Step 230 Global step 230 Train loss 2.735357 on epoch=9
05/23/2022 01:27:49 - INFO - __main__ - Step 240 Global step 240 Train loss 3.021922 on epoch=9
05/23/2022 01:27:55 - INFO - __main__ - Step 250 Global step 250 Train loss 2.369276 on epoch=10
05/23/2022 01:28:01 - INFO - __main__ - Global step 250 Train loss 2.760149 Classification-F1 0.16666666666666666 on epoch=10
05/23/2022 01:28:07 - INFO - __main__ - Step 260 Global step 260 Train loss 2.561374 on epoch=10
05/23/2022 01:28:12 - INFO - __main__ - Step 270 Global step 270 Train loss 1.977105 on epoch=11
05/23/2022 01:28:17 - INFO - __main__ - Step 280 Global step 280 Train loss 2.380542 on epoch=11
05/23/2022 01:28:22 - INFO - __main__ - Step 290 Global step 290 Train loss 2.930959 on epoch=12
05/23/2022 01:28:27 - INFO - __main__ - Step 300 Global step 300 Train loss 2.495308 on epoch=12
05/23/2022 01:28:33 - INFO - __main__ - Global step 300 Train loss 2.469058 Classification-F1 0.16666666666666666 on epoch=12
05/23/2022 01:28:39 - INFO - __main__ - Step 310 Global step 310 Train loss 2.375506 on epoch=12
05/23/2022 01:28:44 - INFO - __main__ - Step 320 Global step 320 Train loss 1.760599 on epoch=13
05/23/2022 01:28:49 - INFO - __main__ - Step 330 Global step 330 Train loss 2.181696 on epoch=13
05/23/2022 01:28:54 - INFO - __main__ - Step 340 Global step 340 Train loss 2.011207 on epoch=14
05/23/2022 01:28:59 - INFO - __main__ - Step 350 Global step 350 Train loss 1.794107 on epoch=14
05/23/2022 01:29:05 - INFO - __main__ - Global step 350 Train loss 2.024623 Classification-F1 0.16666666666666666 on epoch=14
05/23/2022 01:29:11 - INFO - __main__ - Step 360 Global step 360 Train loss 2.262408 on epoch=14
05/23/2022 01:29:16 - INFO - __main__ - Step 370 Global step 370 Train loss 1.734449 on epoch=15
05/23/2022 01:29:21 - INFO - __main__ - Step 380 Global step 380 Train loss 2.131139 on epoch=15
05/23/2022 01:29:26 - INFO - __main__ - Step 390 Global step 390 Train loss 1.794999 on epoch=16
05/23/2022 01:29:31 - INFO - __main__ - Step 400 Global step 400 Train loss 2.062007 on epoch=16
05/23/2022 01:29:38 - INFO - __main__ - Global step 400 Train loss 1.997000 Classification-F1 0.16666666666666666 on epoch=16
05/23/2022 01:29:43 - INFO - __main__ - Step 410 Global step 410 Train loss 1.697298 on epoch=17
05/23/2022 01:29:48 - INFO - __main__ - Step 420 Global step 420 Train loss 1.763203 on epoch=17
05/23/2022 01:29:53 - INFO - __main__ - Step 430 Global step 430 Train loss 1.424824 on epoch=17
05/23/2022 01:29:58 - INFO - __main__ - Step 440 Global step 440 Train loss 1.466365 on epoch=18
05/23/2022 01:30:03 - INFO - __main__ - Step 450 Global step 450 Train loss 1.646536 on epoch=18
05/23/2022 01:30:10 - INFO - __main__ - Global step 450 Train loss 1.599645 Classification-F1 0.16568819308545338 on epoch=18
05/23/2022 01:30:15 - INFO - __main__ - Step 460 Global step 460 Train loss 1.420319 on epoch=19
05/23/2022 01:30:20 - INFO - __main__ - Step 470 Global step 470 Train loss 1.052462 on epoch=19
05/23/2022 01:30:25 - INFO - __main__ - Step 480 Global step 480 Train loss 1.234751 on epoch=19
05/23/2022 01:30:30 - INFO - __main__ - Step 490 Global step 490 Train loss 1.535594 on epoch=20
05/23/2022 01:30:35 - INFO - __main__ - Step 500 Global step 500 Train loss 1.176238 on epoch=20
05/23/2022 01:30:42 - INFO - __main__ - Global step 500 Train loss 1.283873 Classification-F1 0.29988565173623666 on epoch=20
05/23/2022 01:30:47 - INFO - __main__ - Step 510 Global step 510 Train loss 1.363447 on epoch=21
05/23/2022 01:30:53 - INFO - __main__ - Step 520 Global step 520 Train loss 1.070951 on epoch=21
05/23/2022 01:30:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.987443 on epoch=22
05/23/2022 01:31:03 - INFO - __main__ - Step 540 Global step 540 Train loss 1.041404 on epoch=22
05/23/2022 01:31:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.906800 on epoch=22
05/23/2022 01:31:14 - INFO - __main__ - Global step 550 Train loss 1.074009 Classification-F1 0.28225422599377153 on epoch=22
05/23/2022 01:31:20 - INFO - __main__ - Step 560 Global step 560 Train loss 1.017933 on epoch=23
05/23/2022 01:31:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.978922 on epoch=23
05/23/2022 01:31:30 - INFO - __main__ - Step 580 Global step 580 Train loss 1.038400 on epoch=24
05/23/2022 01:31:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.991910 on epoch=24
05/23/2022 01:31:40 - INFO - __main__ - Step 600 Global step 600 Train loss 1.062434 on epoch=24
05/23/2022 01:31:46 - INFO - __main__ - Global step 600 Train loss 1.017920 Classification-F1 0.16666666666666666 on epoch=24
05/23/2022 01:31:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.758103 on epoch=25
05/23/2022 01:31:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.791344 on epoch=25
05/23/2022 01:32:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.835834 on epoch=26
05/23/2022 01:32:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.799694 on epoch=26
05/23/2022 01:32:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.831983 on epoch=27
05/23/2022 01:32:19 - INFO - __main__ - Global step 650 Train loss 0.803391 Classification-F1 0.16666666666666666 on epoch=27
05/23/2022 01:32:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.647397 on epoch=27
05/23/2022 01:32:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.836990 on epoch=27
05/23/2022 01:32:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.763976 on epoch=28
05/23/2022 01:32:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.589000 on epoch=28
05/23/2022 01:32:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.794804 on epoch=29
05/23/2022 01:32:51 - INFO - __main__ - Global step 700 Train loss 0.726433 Classification-F1 0.16666666666666666 on epoch=29
05/23/2022 01:32:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.794177 on epoch=29
05/23/2022 01:33:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.688358 on epoch=29
05/23/2022 01:33:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.689895 on epoch=30
05/23/2022 01:33:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.644410 on epoch=30
05/23/2022 01:33:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.670138 on epoch=31
05/23/2022 01:33:24 - INFO - __main__ - Global step 750 Train loss 0.697395 Classification-F1 0.22664145477953013 on epoch=31
05/23/2022 01:33:29 - INFO - __main__ - Step 760 Global step 760 Train loss 0.651744 on epoch=31
05/23/2022 01:33:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.660571 on epoch=32
05/23/2022 01:33:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.594917 on epoch=32
05/23/2022 01:33:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.631234 on epoch=32
05/23/2022 01:33:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.659431 on epoch=33
05/23/2022 01:33:56 - INFO - __main__ - Global step 800 Train loss 0.639580 Classification-F1 0.18171116853287397 on epoch=33
05/23/2022 01:34:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.646443 on epoch=33
05/23/2022 01:34:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.564771 on epoch=34
05/23/2022 01:34:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.684570 on epoch=34
05/23/2022 01:34:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.584310 on epoch=34
05/23/2022 01:34:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.535952 on epoch=35
05/23/2022 01:34:29 - INFO - __main__ - Global step 850 Train loss 0.603209 Classification-F1 0.2691865763302825 on epoch=35
05/23/2022 01:34:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.549811 on epoch=35
05/23/2022 01:34:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.646768 on epoch=36
05/23/2022 01:34:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.591811 on epoch=36
05/23/2022 01:34:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.507077 on epoch=37
05/23/2022 01:34:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.548698 on epoch=37
05/23/2022 01:35:01 - INFO - __main__ - Global step 900 Train loss 0.568833 Classification-F1 0.33899600525755064 on epoch=37
05/23/2022 01:35:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.504626 on epoch=37
05/23/2022 01:35:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.500689 on epoch=38
05/23/2022 01:35:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.483250 on epoch=38
05/23/2022 01:35:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.443386 on epoch=39
05/23/2022 01:35:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.427910 on epoch=39
05/23/2022 01:35:34 - INFO - __main__ - Global step 950 Train loss 0.471972 Classification-F1 0.2748638107508852 on epoch=39
05/23/2022 01:35:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.533614 on epoch=39
05/23/2022 01:35:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.480060 on epoch=40
05/23/2022 01:35:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.462620 on epoch=40
05/23/2022 01:35:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.387540 on epoch=41
05/23/2022 01:36:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.444867 on epoch=41
05/23/2022 01:36:01 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:36:01 - INFO - __main__ - Printing 3 examples
05/23/2022 01:36:01 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:36:01 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:01 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:36:01 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:01 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:36:01 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:01 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:36:02 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:36:02 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:36:02 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:36:02 - INFO - __main__ - Printing 3 examples
05/23/2022 01:36:02 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:36:02 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:02 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:36:02 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:02 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:36:02 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:02 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:36:02 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:36:03 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:36:07 - INFO - __main__ - Global step 1000 Train loss 0.461740 Classification-F1 0.2861978069970209 on epoch=41
05/23/2022 01:36:07 - INFO - __main__ - save last model!
05/23/2022 01:36:14 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 01:36:14 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 01:36:14 - INFO - __main__ - Printing 3 examples
05/23/2022 01:36:14 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 01:36:14 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:14 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 01:36:14 - INFO - __main__ - ['entailment']
05/23/2022 01:36:14 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 01:36:14 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:14 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:36:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:36:15 - INFO - __main__ - Starting training!
05/23/2022 01:36:15 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:36:16 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 01:36:34 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_87_0.0002_8_predictions.txt
05/23/2022 01:36:34 - INFO - __main__ - Classification-F1 on test data: 0.3129
05/23/2022 01:36:34 - INFO - __main__ - prefix=anli_128_87, lr=0.0002, bsz=8, dev_performance=0.33899600525755064, test_performance=0.3129228588235136
05/23/2022 01:36:34 - INFO - __main__ - Running ... prefix=anli_128_87, lr=0.0001, bsz=8 ...
05/23/2022 01:36:35 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:36:35 - INFO - __main__ - Printing 3 examples
05/23/2022 01:36:35 - INFO - __main__ -  [anli] premise: "I Love Rock 'n' Roll" is a rock song written in 1975 by Alan Merrill of the Arrows, who recorded the first released version. The song was later made famous by Joan Jett & the Blackhearts in 1982. Alan Merrill has played the song live in Europe, Japan and most often in his home town New York City. [SEP] hypothesis: "I Love Rock 'n' Roll" is a rock song written in 1975 Joan Jett & the Blackhearts.
05/23/2022 01:36:35 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:35 - INFO - __main__ -  [anli] premise: Binani Industries Ltd is an Indian business group based in Mumbai. It is a 143-year old business conglomerate and belongs to the legendary Braj Binani Group. The business portfolio of Binani Industries includes sectors like cement, zinc, glass-fiber, and downstream composite products. [SEP] hypothesis: Binani industries was founded in America over 143 years ago. 
05/23/2022 01:36:35 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:35 - INFO - __main__ -  [anli] premise: Konec agenta W4C prostřednictvím psa pana Foustky (English: The End of Agent W4C ) is a 1967 Czechoslovak film parodying the James Bond secret agent genre. Directed by Václav Vorlíček based on the story by Oldřich Daněk. Runtime 87 min. Mono. Produced by Filmové Studio Barrandov and distributed by Central Office of Film Distribution, Prague. [SEP] hypothesis: Konec agenta W4C prostřednictvím psa pana Foustky (magic: The End of Agent W4C ) is a 1967 Czechoslovak film 
05/23/2022 01:36:35 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:35 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:36:36 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:36:36 - INFO - __main__ - Loaded 384 examples from train data
05/23/2022 01:36:36 - INFO - __main__ - Start tokenizing ... 384 instances
05/23/2022 01:36:36 - INFO - __main__ - Printing 3 examples
05/23/2022 01:36:36 - INFO - __main__ -  [anli] premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, "What is Love?", one song that is a B-side from "The Summer EP" and one live track. [SEP] hypothesis:  The EP features two live tracks. 
05/23/2022 01:36:36 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:36 - INFO - __main__ -  [anli] premise: The Hound of the Baskervilles is a 1978 British comedy film spoofing "The Hound of the Baskervilles" by Sir Arthur Conan Doyle. It starred Peter Cook as Sherlock Holmes and Dudley Moore as Dr. Watson. A number of other well-known British comedy actors appeared in the film including Terry-Thomas (in his final screen appearance), Kenneth Williams and Denholm Elliott. [SEP] hypothesis: The Hound of the Baskervilles is a american food dish.
05/23/2022 01:36:36 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:36 - INFO - __main__ -  [anli] premise: Jake Roberts is an English film editor. He is best known for his works on films "Citadel" (2012), "Starred Up" (2013), "The Riot Club" (2014) and "Brooklyn" (2015). For "Hell or High Water" (2016), Roberts was nominated (among several honors) for an Independent Spirit Award and the Academy Award for Best Film Editing at the 89th Academy Awards. [SEP] hypothesis: Jake Roberts is most famous for his music career.
05/23/2022 01:36:36 - INFO - __main__ - ['contradiction']
05/23/2022 01:36:36 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:36:36 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:36:37 - INFO - __main__ - Loaded 384 examples from dev data
05/23/2022 01:36:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/23/2022 01:36:47 - INFO - __main__ - Starting training!
05/23/2022 01:36:51 - INFO - __main__ - Step 10 Global step 10 Train loss 24.233904 on epoch=0
05/23/2022 01:36:56 - INFO - __main__ - Step 20 Global step 20 Train loss 19.630686 on epoch=0
05/23/2022 01:37:01 - INFO - __main__ - Step 30 Global step 30 Train loss 16.084412 on epoch=1
05/23/2022 01:37:06 - INFO - __main__ - Step 40 Global step 40 Train loss 13.602125 on epoch=1
05/23/2022 01:37:11 - INFO - __main__ - Step 50 Global step 50 Train loss 12.237228 on epoch=2
05/23/2022 01:37:21 - INFO - __main__ - Global step 50 Train loss 17.157671 Classification-F1 0.004901960784313725 on epoch=2
05/23/2022 01:37:27 - INFO - __main__ - Step 60 Global step 60 Train loss 14.214121 on epoch=2
05/23/2022 01:37:32 - INFO - __main__ - Step 70 Global step 70 Train loss 11.631449 on epoch=2
05/23/2022 01:37:37 - INFO - __main__ - Step 80 Global step 80 Train loss 12.525160 on epoch=3
05/23/2022 01:37:42 - INFO - __main__ - Step 90 Global step 90 Train loss 11.607875 on epoch=3
05/23/2022 01:37:47 - INFO - __main__ - Step 100 Global step 100 Train loss 11.595133 on epoch=4
05/23/2022 01:37:55 - INFO - __main__ - Global step 100 Train loss 12.314747 Classification-F1 0.0 on epoch=4
05/23/2022 01:38:00 - INFO - __main__ - Step 110 Global step 110 Train loss 10.711555 on epoch=4
05/23/2022 01:38:05 - INFO - __main__ - Step 120 Global step 120 Train loss 11.403325 on epoch=4
05/23/2022 01:38:10 - INFO - __main__ - Step 130 Global step 130 Train loss 11.120070 on epoch=5
05/23/2022 01:38:15 - INFO - __main__ - Step 140 Global step 140 Train loss 9.989307 on epoch=5
05/23/2022 01:38:21 - INFO - __main__ - Step 150 Global step 150 Train loss 10.474322 on epoch=6
05/23/2022 01:38:28 - INFO - __main__ - Global step 150 Train loss 10.739716 Classification-F1 0.0 on epoch=6
05/23/2022 01:38:33 - INFO - __main__ - Step 160 Global step 160 Train loss 10.362710 on epoch=6
05/23/2022 01:38:38 - INFO - __main__ - Step 170 Global step 170 Train loss 9.333444 on epoch=7
05/23/2022 01:38:43 - INFO - __main__ - Step 180 Global step 180 Train loss 10.001992 on epoch=7
05/23/2022 01:38:49 - INFO - __main__ - Step 190 Global step 190 Train loss 8.369946 on epoch=7
05/23/2022 01:38:54 - INFO - __main__ - Step 200 Global step 200 Train loss 9.599283 on epoch=8
05/23/2022 01:39:01 - INFO - __main__ - Global step 200 Train loss 9.533475 Classification-F1 0.0 on epoch=8
05/23/2022 01:39:06 - INFO - __main__ - Step 210 Global step 210 Train loss 8.872972 on epoch=8
05/23/2022 01:39:11 - INFO - __main__ - Step 220 Global step 220 Train loss 9.460243 on epoch=9
05/23/2022 01:39:16 - INFO - __main__ - Step 230 Global step 230 Train loss 7.872411 on epoch=9
05/23/2022 01:39:22 - INFO - __main__ - Step 240 Global step 240 Train loss 8.051127 on epoch=9
05/23/2022 01:39:27 - INFO - __main__ - Step 250 Global step 250 Train loss 7.610820 on epoch=10
05/23/2022 01:39:34 - INFO - __main__ - Global step 250 Train loss 8.373514 Classification-F1 0.0 on epoch=10
05/23/2022 01:39:39 - INFO - __main__ - Step 260 Global step 260 Train loss 7.793391 on epoch=10
05/23/2022 01:39:44 - INFO - __main__ - Step 270 Global step 270 Train loss 6.904061 on epoch=11
05/23/2022 01:39:49 - INFO - __main__ - Step 280 Global step 280 Train loss 7.018252 on epoch=11
05/23/2022 01:39:54 - INFO - __main__ - Step 290 Global step 290 Train loss 6.034820 on epoch=12
05/23/2022 01:40:00 - INFO - __main__ - Step 300 Global step 300 Train loss 6.767726 on epoch=12
05/23/2022 01:40:07 - INFO - __main__ - Global step 300 Train loss 6.903650 Classification-F1 0.0 on epoch=12
05/23/2022 01:40:12 - INFO - __main__ - Step 310 Global step 310 Train loss 6.190404 on epoch=12
05/23/2022 01:40:17 - INFO - __main__ - Step 320 Global step 320 Train loss 5.268931 on epoch=13
05/23/2022 01:40:22 - INFO - __main__ - Step 330 Global step 330 Train loss 4.575173 on epoch=13
05/23/2022 01:40:27 - INFO - __main__ - Step 340 Global step 340 Train loss 3.800631 on epoch=14
05/23/2022 01:40:33 - INFO - __main__ - Step 350 Global step 350 Train loss 3.301289 on epoch=14
05/23/2022 01:40:38 - INFO - __main__ - Global step 350 Train loss 4.627285 Classification-F1 0.0779467680608365 on epoch=14
05/23/2022 01:40:44 - INFO - __main__ - Step 360 Global step 360 Train loss 3.332669 on epoch=14
05/23/2022 01:40:50 - INFO - __main__ - Step 370 Global step 370 Train loss 3.420909 on epoch=15
05/23/2022 01:40:55 - INFO - __main__ - Step 380 Global step 380 Train loss 2.778602 on epoch=15
05/23/2022 01:41:00 - INFO - __main__ - Step 390 Global step 390 Train loss 3.014647 on epoch=16
05/23/2022 01:41:05 - INFO - __main__ - Step 400 Global step 400 Train loss 2.911962 on epoch=16
05/23/2022 01:41:11 - INFO - __main__ - Global step 400 Train loss 3.091758 Classification-F1 0.16666666666666666 on epoch=16
05/23/2022 01:41:17 - INFO - __main__ - Step 410 Global step 410 Train loss 3.284144 on epoch=17
05/23/2022 01:41:22 - INFO - __main__ - Step 420 Global step 420 Train loss 2.716270 on epoch=17
05/23/2022 01:41:28 - INFO - __main__ - Step 430 Global step 430 Train loss 2.608400 on epoch=17
05/23/2022 01:41:33 - INFO - __main__ - Step 440 Global step 440 Train loss 2.550559 on epoch=18
05/23/2022 01:41:38 - INFO - __main__ - Step 450 Global step 450 Train loss 2.540020 on epoch=18
05/23/2022 01:41:44 - INFO - __main__ - Global step 450 Train loss 2.739879 Classification-F1 0.16666666666666666 on epoch=18
05/23/2022 01:41:49 - INFO - __main__ - Step 460 Global step 460 Train loss 2.782601 on epoch=19
05/23/2022 01:41:54 - INFO - __main__ - Step 470 Global step 470 Train loss 2.239815 on epoch=19
05/23/2022 01:41:59 - INFO - __main__ - Step 480 Global step 480 Train loss 2.084079 on epoch=19
05/23/2022 01:42:04 - INFO - __main__ - Step 490 Global step 490 Train loss 2.760488 on epoch=20
05/23/2022 01:42:10 - INFO - __main__ - Step 500 Global step 500 Train loss 1.893692 on epoch=20
05/23/2022 01:42:15 - INFO - __main__ - Global step 500 Train loss 2.352135 Classification-F1 0.16666666666666666 on epoch=20
05/23/2022 01:42:20 - INFO - __main__ - Step 510 Global step 510 Train loss 2.465185 on epoch=21
05/23/2022 01:42:25 - INFO - __main__ - Step 520 Global step 520 Train loss 1.838038 on epoch=21
05/23/2022 01:42:30 - INFO - __main__ - Step 530 Global step 530 Train loss 1.920412 on epoch=22
05/23/2022 01:42:36 - INFO - __main__ - Step 540 Global step 540 Train loss 2.062183 on epoch=22
05/23/2022 01:42:41 - INFO - __main__ - Step 550 Global step 550 Train loss 2.338120 on epoch=22
05/23/2022 01:42:47 - INFO - __main__ - Global step 550 Train loss 2.124788 Classification-F1 0.16666666666666666 on epoch=22
05/23/2022 01:42:53 - INFO - __main__ - Step 560 Global step 560 Train loss 1.927555 on epoch=23
05/23/2022 01:42:58 - INFO - __main__ - Step 570 Global step 570 Train loss 1.755230 on epoch=23
05/23/2022 01:43:03 - INFO - __main__ - Step 580 Global step 580 Train loss 2.317438 on epoch=24
05/23/2022 01:43:08 - INFO - __main__ - Step 590 Global step 590 Train loss 1.745016 on epoch=24
05/23/2022 01:43:14 - INFO - __main__ - Step 600 Global step 600 Train loss 1.903171 on epoch=24
05/23/2022 01:43:20 - INFO - __main__ - Global step 600 Train loss 1.929682 Classification-F1 0.16666666666666666 on epoch=24
05/23/2022 01:43:25 - INFO - __main__ - Step 610 Global step 610 Train loss 1.471892 on epoch=25
05/23/2022 01:43:30 - INFO - __main__ - Step 620 Global step 620 Train loss 1.689442 on epoch=25
05/23/2022 01:43:35 - INFO - __main__ - Step 630 Global step 630 Train loss 1.861105 on epoch=26
05/23/2022 01:43:40 - INFO - __main__ - Step 640 Global step 640 Train loss 1.851160 on epoch=26
05/23/2022 01:43:45 - INFO - __main__ - Step 650 Global step 650 Train loss 1.746069 on epoch=27
05/23/2022 01:43:52 - INFO - __main__ - Global step 650 Train loss 1.723934 Classification-F1 0.16666666666666666 on epoch=27
05/23/2022 01:43:57 - INFO - __main__ - Step 660 Global step 660 Train loss 1.355086 on epoch=27
05/23/2022 01:44:02 - INFO - __main__ - Step 670 Global step 670 Train loss 1.573553 on epoch=27
05/23/2022 01:44:07 - INFO - __main__ - Step 680 Global step 680 Train loss 1.529976 on epoch=28
05/23/2022 01:44:12 - INFO - __main__ - Step 690 Global step 690 Train loss 1.744130 on epoch=28
05/23/2022 01:44:17 - INFO - __main__ - Step 700 Global step 700 Train loss 1.477727 on epoch=29
05/23/2022 01:44:24 - INFO - __main__ - Global step 700 Train loss 1.536094 Classification-F1 0.16666666666666666 on epoch=29
05/23/2022 01:44:29 - INFO - __main__ - Step 710 Global step 710 Train loss 1.735350 on epoch=29
05/23/2022 01:44:34 - INFO - __main__ - Step 720 Global step 720 Train loss 1.159290 on epoch=29
05/23/2022 01:44:39 - INFO - __main__ - Step 730 Global step 730 Train loss 1.685540 on epoch=30
05/23/2022 01:44:44 - INFO - __main__ - Step 740 Global step 740 Train loss 1.501338 on epoch=30
05/23/2022 01:44:49 - INFO - __main__ - Step 750 Global step 750 Train loss 1.317091 on epoch=31
05/23/2022 01:44:56 - INFO - __main__ - Global step 750 Train loss 1.479722 Classification-F1 0.16666666666666666 on epoch=31
05/23/2022 01:45:01 - INFO - __main__ - Step 760 Global step 760 Train loss 1.285877 on epoch=31
05/23/2022 01:45:06 - INFO - __main__ - Step 770 Global step 770 Train loss 1.199276 on epoch=32
05/23/2022 01:45:11 - INFO - __main__ - Step 780 Global step 780 Train loss 1.105014 on epoch=32
05/23/2022 01:45:16 - INFO - __main__ - Step 790 Global step 790 Train loss 1.032294 on epoch=32
05/23/2022 01:45:22 - INFO - __main__ - Step 800 Global step 800 Train loss 1.085912 on epoch=33
05/23/2022 01:45:28 - INFO - __main__ - Global step 800 Train loss 1.141674 Classification-F1 0.16699282452707112 on epoch=33
05/23/2022 01:45:34 - INFO - __main__ - Step 810 Global step 810 Train loss 1.177073 on epoch=33
05/23/2022 01:45:39 - INFO - __main__ - Step 820 Global step 820 Train loss 1.204605 on epoch=34
05/23/2022 01:45:44 - INFO - __main__ - Step 830 Global step 830 Train loss 1.141467 on epoch=34
05/23/2022 01:45:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.828490 on epoch=34
05/23/2022 01:45:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.587041 on epoch=35
05/23/2022 01:45:59 - INFO - __main__ - Global step 850 Train loss 0.987735 Classification-F1 0.16666666666666666 on epoch=35
05/23/2022 01:46:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.595468 on epoch=35
05/23/2022 01:46:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.507877 on epoch=36
05/23/2022 01:46:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.526754 on epoch=36
05/23/2022 01:46:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.595094 on epoch=37
05/23/2022 01:46:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.562634 on epoch=37
05/23/2022 01:46:30 - INFO - __main__ - Global step 900 Train loss 0.557566 Classification-F1 0.1721607831834019 on epoch=37
05/23/2022 01:46:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.490326 on epoch=37
05/23/2022 01:46:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.499968 on epoch=38
05/23/2022 01:46:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.463324 on epoch=38
05/23/2022 01:46:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.512912 on epoch=39
05/23/2022 01:46:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.471543 on epoch=39
05/23/2022 01:47:01 - INFO - __main__ - Global step 950 Train loss 0.487614 Classification-F1 0.18719741796664877 on epoch=39
05/23/2022 01:47:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.457710 on epoch=39
05/23/2022 01:47:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.462342 on epoch=40
05/23/2022 01:47:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.463893 on epoch=40
05/23/2022 01:47:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.439679 on epoch=41
05/23/2022 01:47:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.512975 on epoch=41
05/23/2022 01:47:32 - INFO - __main__ - Global step 1000 Train loss 0.467320 Classification-F1 0.2108898648360551 on epoch=41
05/23/2022 01:47:33 - INFO - __main__ - save last model!
05/23/2022 01:47:40 - INFO - __main__ - Loading checkpoint on the fly
05/23/2022 01:47:40 - INFO - __main__ - Start tokenizing ... 1000 instances
05/23/2022 01:47:40 - INFO - __main__ - Printing 3 examples
05/23/2022 01:47:40 - INFO - __main__ -  [anli] premise: Linguistics is the scientific study of language, and involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who wrote a formal description of the Sanskrit language in his "Aṣṭādhyāyī ". [SEP] hypothesis: Form and meaning are the only aspects of language linguistics is concerned with.
05/23/2022 01:47:40 - INFO - __main__ - ['contradiction']
05/23/2022 01:47:40 - INFO - __main__ -  [anli] premise: Franco Zeffirelli, KBE Grande Ufficiale OMRI (] ; born 12 February 1923) is an Italian director and producer of operas, films and television. He is also a former senator (1994–2001) for the Italian centre-right "Forza Italia" party. Recently, Italian researchers have found that he is one of the few distant relatives of Leonardo da Vinci. [SEP] hypothesis: Franco Zeffirelli had a political career
05/23/2022 01:47:40 - INFO - __main__ - ['entailment']
05/23/2022 01:47:40 - INFO - __main__ -  [anli] premise: Eme 15 is the self-titled debut studio album by Mexican-Argentine pop band, Eme 15. The album was released in Mexico and Latin America on June 26, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV. [SEP] hypothesis: Eme 15 was released in Mexico and Latin America on June 27, 2012 through Warner Music México, and features songs from the Nickelodeon Latin America and Televisa musical television series, Miss XV.
05/23/2022 01:47:40 - INFO - __main__ - ['contradiction']
05/23/2022 01:47:40 - INFO - __main__ - Tokenizing Input ...
05/23/2022 01:47:41 - INFO - __main__ - Tokenizing Output ...
05/23/2022 01:47:42 - INFO - __main__ - Loaded 1000 examples from test data
05/23/2022 01:47:54 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-anli/anli_128_87_0.0001_8_predictions.txt
05/23/2022 01:47:54 - INFO - __main__ - Classification-F1 on test data: 0.1949
05/23/2022 01:47:54 - INFO - __main__ - prefix=anli_128_87, lr=0.0001, bsz=8, dev_performance=0.2108898648360551, test_performance=0.19492182231410782
