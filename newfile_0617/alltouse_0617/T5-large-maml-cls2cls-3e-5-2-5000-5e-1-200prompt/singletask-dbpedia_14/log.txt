05/25/2022 10:05:39 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='0,1')
05/25/2022 10:05:39 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14
05/25/2022 10:05:39 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='0,1')
05/25/2022 10:05:39 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14
05/25/2022 10:05:41 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/25/2022 10:05:41 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/25/2022 10:05:41 - INFO - __main__ - args.device: cuda:0
05/25/2022 10:05:41 - INFO - __main__ - Using 2 gpus
05/25/2022 10:05:41 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/25/2022 10:05:41 - INFO - __main__ - args.device: cuda:1
05/25/2022 10:05:41 - INFO - __main__ - Using 2 gpus
05/25/2022 10:05:41 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/25/2022 10:05:46 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/25/2022 10:05:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:05:46 - INFO - __main__ - Printing 3 examples
05/25/2022 10:05:46 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 10:05:46 - INFO - __main__ - ['Animal']
05/25/2022 10:05:46 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 10:05:46 - INFO - __main__ - ['Animal']
05/25/2022 10:05:46 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 10:05:46 - INFO - __main__ - ['Animal']
05/25/2022 10:05:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:05:46 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:05:46 - INFO - __main__ - Printing 3 examples
05/25/2022 10:05:46 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 10:05:46 - INFO - __main__ - ['Animal']
05/25/2022 10:05:46 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 10:05:46 - INFO - __main__ - ['Animal']
05/25/2022 10:05:46 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 10:05:46 - INFO - __main__ - ['Animal']
05/25/2022 10:05:46 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:05:47 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:05:47 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:05:47 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 10:05:47 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:05:47 - INFO - __main__ - Printing 3 examples
05/25/2022 10:05:47 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 10:05:47 - INFO - __main__ - ['Animal']
05/25/2022 10:05:47 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 10:05:47 - INFO - __main__ - ['Animal']
05/25/2022 10:05:47 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 10:05:47 - INFO - __main__ - ['Animal']
05/25/2022 10:05:47 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:05:47 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 10:05:47 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:05:47 - INFO - __main__ - Printing 3 examples
05/25/2022 10:05:47 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 10:05:47 - INFO - __main__ - ['Animal']
05/25/2022 10:05:47 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 10:05:47 - INFO - __main__ - ['Animal']
05/25/2022 10:05:47 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 10:05:47 - INFO - __main__ - ['Animal']
05/25/2022 10:05:47 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:05:47 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:05:47 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:05:47 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 10:05:47 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 10:06:05 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:06:05 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:06:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 10:06:06 - INFO - __main__ - Starting training!
05/25/2022 10:06:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 10:06:10 - INFO - __main__ - Starting training!
05/25/2022 10:06:15 - INFO - __main__ - Step 10 Global step 10 Train loss 4.94 on epoch=0
05/25/2022 10:06:18 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=1
05/25/2022 10:06:21 - INFO - __main__ - Step 30 Global step 30 Train loss 2.41 on epoch=2
05/25/2022 10:06:24 - INFO - __main__ - Step 40 Global step 40 Train loss 1.52 on epoch=2
05/25/2022 10:06:27 - INFO - __main__ - Step 50 Global step 50 Train loss 1.38 on epoch=3
05/25/2022 10:06:34 - INFO - __main__ - Global step 50 Train loss 2.73 Classification-F1 0.3361979758981863 on epoch=3
05/25/2022 10:06:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3361979758981863 on epoch=3, global_step=50
05/25/2022 10:06:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.08 on epoch=4
05/25/2022 10:06:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.84 on epoch=4
05/25/2022 10:06:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=5
05/25/2022 10:06:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.67 on epoch=6
05/25/2022 10:06:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.64 on epoch=7
05/25/2022 10:06:58 - INFO - __main__ - Global step 100 Train loss 0.81 Classification-F1 0.7390060476024785 on epoch=7
05/25/2022 10:06:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3361979758981863 -> 0.7390060476024785 on epoch=7, global_step=100
05/25/2022 10:07:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.59 on epoch=7
05/25/2022 10:07:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.55 on epoch=8
05/25/2022 10:07:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.50 on epoch=9
05/25/2022 10:07:10 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=9
05/25/2022 10:07:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.51 on epoch=10
05/25/2022 10:07:22 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.7762644098447117 on epoch=10
05/25/2022 10:07:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7390060476024785 -> 0.7762644098447117 on epoch=10, global_step=150
05/25/2022 10:07:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=11
05/25/2022 10:07:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=12
05/25/2022 10:07:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.32 on epoch=12
05/25/2022 10:07:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.33 on epoch=13
05/25/2022 10:07:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=14
05/25/2022 10:07:46 - INFO - __main__ - Global step 200 Train loss 0.40 Classification-F1 0.808979706227414 on epoch=14
05/25/2022 10:07:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7762644098447117 -> 0.808979706227414 on epoch=14, global_step=200
05/25/2022 10:07:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.27 on epoch=14
05/25/2022 10:07:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=15
05/25/2022 10:07:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=16
05/25/2022 10:07:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=17
05/25/2022 10:08:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.18 on epoch=17
05/25/2022 10:08:10 - INFO - __main__ - Global step 250 Train loss 0.26 Classification-F1 0.7440214966840933 on epoch=17
05/25/2022 10:08:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.15 on epoch=18
05/25/2022 10:08:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=19
05/25/2022 10:08:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=19
05/25/2022 10:08:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=20
05/25/2022 10:08:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=21
05/25/2022 10:08:33 - INFO - __main__ - Global step 300 Train loss 0.21 Classification-F1 0.6521190657778564 on epoch=21
05/25/2022 10:08:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=22
05/25/2022 10:08:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.16 on epoch=22
05/25/2022 10:08:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.15 on epoch=23
05/25/2022 10:08:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=24
05/25/2022 10:08:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.09 on epoch=24
05/25/2022 10:08:57 - INFO - __main__ - Global step 350 Train loss 0.16 Classification-F1 0.7655547260177772 on epoch=24
05/25/2022 10:09:00 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=25
05/25/2022 10:09:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=26
05/25/2022 10:09:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=27
05/25/2022 10:09:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.09 on epoch=27
05/25/2022 10:09:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.13 on epoch=28
05/25/2022 10:09:19 - INFO - __main__ - Global step 400 Train loss 0.15 Classification-F1 0.6454421325389067 on epoch=28
05/25/2022 10:09:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.12 on epoch=29
05/25/2022 10:09:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=29
05/25/2022 10:09:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.12 on epoch=30
05/25/2022 10:09:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=31
05/25/2022 10:09:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=32
05/25/2022 10:09:41 - INFO - __main__ - Global step 450 Train loss 0.11 Classification-F1 0.6807358083554584 on epoch=32
05/25/2022 10:09:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=32
05/25/2022 10:09:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=33
05/25/2022 10:09:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=34
05/25/2022 10:09:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
05/25/2022 10:09:56 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=35
05/25/2022 10:10:03 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.7546129084168696 on epoch=35
05/25/2022 10:10:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=36
05/25/2022 10:10:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=37
05/25/2022 10:10:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
05/25/2022 10:10:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=38
05/25/2022 10:10:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=39
05/25/2022 10:10:25 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.6410362805409244 on epoch=39
05/25/2022 10:10:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=39
05/25/2022 10:10:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=40
05/25/2022 10:10:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
05/25/2022 10:10:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=42
05/25/2022 10:10:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=42
05/25/2022 10:10:48 - INFO - __main__ - Global step 600 Train loss 0.07 Classification-F1 0.7728614777437461 on epoch=42
05/25/2022 10:10:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=43
05/25/2022 10:10:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=44
05/25/2022 10:10:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
05/25/2022 10:11:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
05/25/2022 10:11:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
05/25/2022 10:11:11 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.7439199962508632 on epoch=46
05/25/2022 10:11:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
05/25/2022 10:11:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=47
05/25/2022 10:11:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=48
05/25/2022 10:11:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=49
05/25/2022 10:11:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=49
05/25/2022 10:11:34 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.8027828595553055 on epoch=49
05/25/2022 10:11:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
05/25/2022 10:11:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
05/25/2022 10:11:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=52
05/25/2022 10:11:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
05/25/2022 10:11:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
05/25/2022 10:11:56 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.6804675134446432 on epoch=53
05/25/2022 10:11:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=54
05/25/2022 10:12:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=54
05/25/2022 10:12:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
05/25/2022 10:12:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=56
05/25/2022 10:12:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=57
05/25/2022 10:12:20 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.8386427298192004 on epoch=57
05/25/2022 10:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.808979706227414 -> 0.8386427298192004 on epoch=57, global_step=800
05/25/2022 10:12:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=57
05/25/2022 10:12:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
05/25/2022 10:12:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=59
05/25/2022 10:12:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=59
05/25/2022 10:12:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=60
05/25/2022 10:12:42 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.688091938160642 on epoch=60
05/25/2022 10:12:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=61
05/25/2022 10:12:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=62
05/25/2022 10:12:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=62
05/25/2022 10:12:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=63
05/25/2022 10:12:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
05/25/2022 10:13:04 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.6986299779403228 on epoch=64
05/25/2022 10:13:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=64
05/25/2022 10:13:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
05/25/2022 10:13:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
05/25/2022 10:13:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
05/25/2022 10:13:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
05/25/2022 10:13:26 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7030207195292584 on epoch=67
05/25/2022 10:13:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
05/25/2022 10:13:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=69
05/25/2022 10:13:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
05/25/2022 10:13:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=70
05/25/2022 10:13:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
05/25/2022 10:13:47 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.825547508635744 on epoch=71
05/25/2022 10:13:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=72
05/25/2022 10:13:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
05/25/2022 10:13:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
05/25/2022 10:14:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=74
05/25/2022 10:14:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
05/25/2022 10:14:09 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7250565645132708 on epoch=74
05/25/2022 10:14:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
05/25/2022 10:14:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
05/25/2022 10:14:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
05/25/2022 10:14:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
05/25/2022 10:14:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
05/25/2022 10:14:31 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6854801966585121 on epoch=78
05/25/2022 10:14:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
05/25/2022 10:14:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
05/25/2022 10:14:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
05/25/2022 10:14:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
05/25/2022 10:14:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
05/25/2022 10:14:52 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8023972774786716 on epoch=82
05/25/2022 10:14:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/25/2022 10:14:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
05/25/2022 10:15:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
05/25/2022 10:15:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/25/2022 10:15:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
05/25/2022 10:15:15 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.9014542467136853 on epoch=85
05/25/2022 10:15:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8386427298192004 -> 0.9014542467136853 on epoch=85, global_step=1200
05/25/2022 10:15:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
05/25/2022 10:15:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
05/25/2022 10:15:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
05/25/2022 10:15:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
05/25/2022 10:15:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
05/25/2022 10:15:37 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7319510864549372 on epoch=89
05/25/2022 10:15:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
05/25/2022 10:15:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
05/25/2022 10:15:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
05/25/2022 10:15:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
05/25/2022 10:15:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/25/2022 10:15:58 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7927861061623201 on epoch=92
05/25/2022 10:16:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
05/25/2022 10:16:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
05/25/2022 10:16:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
05/25/2022 10:16:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 10:16:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
05/25/2022 10:16:20 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8430157607903612 on epoch=96
05/25/2022 10:16:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
05/25/2022 10:16:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
05/25/2022 10:16:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
05/25/2022 10:16:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
05/25/2022 10:16:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
05/25/2022 10:16:42 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.9776165011459128 on epoch=99
05/25/2022 10:16:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9014542467136853 -> 0.9776165011459128 on epoch=99, global_step=1400
05/25/2022 10:16:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
05/25/2022 10:16:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
05/25/2022 10:16:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/25/2022 10:16:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
05/25/2022 10:16:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/25/2022 10:17:04 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9062002608034146 on epoch=103
05/25/2022 10:17:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
05/25/2022 10:17:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/25/2022 10:17:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/25/2022 10:17:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/25/2022 10:17:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
05/25/2022 10:17:26 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9102521650450721 on epoch=107
05/25/2022 10:17:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
05/25/2022 10:17:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/25/2022 10:17:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
05/25/2022 10:17:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
05/25/2022 10:17:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/25/2022 10:17:48 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9495280064487595 on epoch=110
05/25/2022 10:17:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/25/2022 10:17:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/25/2022 10:17:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/25/2022 10:18:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 10:18:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/25/2022 10:18:10 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9550315140719045 on epoch=114
05/25/2022 10:18:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/25/2022 10:18:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
05/25/2022 10:18:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 10:18:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
05/25/2022 10:18:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/25/2022 10:18:32 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9639950995060781 on epoch=117
05/25/2022 10:18:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/25/2022 10:18:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
05/25/2022 10:18:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 10:18:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/25/2022 10:18:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
05/25/2022 10:18:53 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.9821034792216007 on epoch=121
05/25/2022 10:18:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9776165011459128 -> 0.9821034792216007 on epoch=121, global_step=1700
05/25/2022 10:18:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 10:19:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=122
05/25/2022 10:19:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
05/25/2022 10:19:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=124
05/25/2022 10:19:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/25/2022 10:19:15 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7886286921377333 on epoch=124
05/25/2022 10:19:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=125
05/25/2022 10:19:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=126
05/25/2022 10:19:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/25/2022 10:19:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 10:19:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=128
05/25/2022 10:19:37 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7868910405954642 on epoch=128
05/25/2022 10:19:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=129
05/25/2022 10:19:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=129
05/25/2022 10:19:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 10:19:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
05/25/2022 10:19:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=132
05/25/2022 10:19:59 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9732751751727083 on epoch=132
05/25/2022 10:20:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/25/2022 10:20:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 10:20:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/25/2022 10:20:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/25/2022 10:20:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 10:20:21 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8371358104370274 on epoch=135
05/25/2022 10:20:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/25/2022 10:20:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 10:20:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/25/2022 10:20:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/25/2022 10:20:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/25/2022 10:20:43 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8135104162233979 on epoch=139
05/25/2022 10:20:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 10:20:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/25/2022 10:20:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/25/2022 10:20:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
05/25/2022 10:20:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 10:21:05 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.8318326935589069 on epoch=142
05/25/2022 10:21:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
05/25/2022 10:21:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/25/2022 10:21:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/25/2022 10:21:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/25/2022 10:21:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 10:21:27 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7647436687284884 on epoch=146
05/25/2022 10:21:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 10:21:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
05/25/2022 10:21:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
05/25/2022 10:21:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
05/25/2022 10:21:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/25/2022 10:21:49 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8385141739980451 on epoch=149
05/25/2022 10:21:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/25/2022 10:21:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/25/2022 10:21:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/25/2022 10:22:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
05/25/2022 10:22:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 10:22:11 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7821041187349292 on epoch=153
05/25/2022 10:22:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/25/2022 10:22:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 10:22:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/25/2022 10:22:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/25/2022 10:22:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 10:22:32 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8394794913933316 on epoch=157
05/25/2022 10:22:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 10:22:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 10:22:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/25/2022 10:22:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/25/2022 10:22:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
05/25/2022 10:22:54 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8411115765954476 on epoch=160
05/25/2022 10:22:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
05/25/2022 10:23:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
05/25/2022 10:23:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
05/25/2022 10:23:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/25/2022 10:23:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/25/2022 10:23:16 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8289865285166437 on epoch=164
05/25/2022 10:23:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/25/2022 10:23:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 10:23:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 10:23:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/25/2022 10:23:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 10:23:38 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9731478515159729 on epoch=167
05/25/2022 10:23:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/25/2022 10:23:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
05/25/2022 10:23:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/25/2022 10:23:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/25/2022 10:23:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/25/2022 10:24:00 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9684637491360181 on epoch=171
05/25/2022 10:24:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/25/2022 10:24:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/25/2022 10:24:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 10:24:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
05/25/2022 10:24:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
05/25/2022 10:24:22 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.9640213856803719 on epoch=174
05/25/2022 10:24:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 10:24:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/25/2022 10:24:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 10:24:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/25/2022 10:24:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/25/2022 10:24:44 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8123731440324152 on epoch=178
05/25/2022 10:24:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/25/2022 10:24:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 10:24:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 10:24:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/25/2022 10:24:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/25/2022 10:25:05 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.761068515297551 on epoch=182
05/25/2022 10:25:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/25/2022 10:25:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/25/2022 10:25:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/25/2022 10:25:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 10:25:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 10:25:27 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8915783539439452 on epoch=185
05/25/2022 10:25:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
05/25/2022 10:25:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 10:25:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/25/2022 10:25:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/25/2022 10:25:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
05/25/2022 10:25:49 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9640301135116803 on epoch=189
05/25/2022 10:25:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 10:25:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 10:25:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
05/25/2022 10:26:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 10:26:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 10:26:11 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8934156282258751 on epoch=192
05/25/2022 10:26:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
05/25/2022 10:26:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/25/2022 10:26:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 10:26:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/25/2022 10:26:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
05/25/2022 10:26:33 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9547760518348756 on epoch=196
05/25/2022 10:26:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/25/2022 10:26:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/25/2022 10:26:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/25/2022 10:26:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 10:26:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 10:26:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8328965969428412 on epoch=199
05/25/2022 10:26:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 10:27:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 10:27:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 10:27:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 10:27:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 10:27:16 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9593983112958445 on epoch=203
05/25/2022 10:27:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 10:27:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 10:27:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 10:27:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 10:27:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 10:27:38 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9018393613554904 on epoch=207
05/25/2022 10:27:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 10:27:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 10:27:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 10:27:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/25/2022 10:27:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 10:28:00 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8370531952289462 on epoch=210
05/25/2022 10:28:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/25/2022 10:28:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 10:28:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 10:28:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 10:28:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
05/25/2022 10:28:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:28:17 - INFO - __main__ - Printing 3 examples
05/25/2022 10:28:17 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 10:28:17 - INFO - __main__ - ['Animal']
05/25/2022 10:28:17 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 10:28:17 - INFO - __main__ - ['Animal']
05/25/2022 10:28:17 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 10:28:17 - INFO - __main__ - ['Animal']
05/25/2022 10:28:17 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:28:17 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:28:17 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 10:28:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:28:17 - INFO - __main__ - Printing 3 examples
05/25/2022 10:28:17 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 10:28:17 - INFO - __main__ - ['Animal']
05/25/2022 10:28:17 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 10:28:17 - INFO - __main__ - ['Animal']
05/25/2022 10:28:17 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 10:28:17 - INFO - __main__ - ['Animal']
05/25/2022 10:28:17 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:28:17 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:28:17 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 10:28:21 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8943756896698074 on epoch=214
05/25/2022 10:28:21 - INFO - __main__ - save last model!
05/25/2022 10:28:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 10:28:22 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 10:28:22 - INFO - __main__ - Printing 3 examples
05/25/2022 10:28:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 10:28:22 - INFO - __main__ - ['Animal']
05/25/2022 10:28:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 10:28:22 - INFO - __main__ - ['Animal']
05/25/2022 10:28:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 10:28:22 - INFO - __main__ - ['Village']
05/25/2022 10:28:22 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:28:23 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:28:27 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 10:28:36 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:28:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 10:28:37 - INFO - __main__ - Starting training!
05/25/2022 10:30:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/25/2022 10:30:47 - INFO - __main__ - Classification-F1 on test data: 0.4347
05/25/2022 10:30:48 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9821034792216007, test_performance=0.43472728406748135
05/25/2022 10:30:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/25/2022 10:30:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:30:49 - INFO - __main__ - Printing 3 examples
05/25/2022 10:30:49 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 10:30:49 - INFO - __main__ - ['Animal']
05/25/2022 10:30:49 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 10:30:49 - INFO - __main__ - ['Animal']
05/25/2022 10:30:49 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 10:30:49 - INFO - __main__ - ['Animal']
05/25/2022 10:30:49 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:30:49 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:30:49 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 10:30:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:30:49 - INFO - __main__ - Printing 3 examples
05/25/2022 10:30:49 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 10:30:49 - INFO - __main__ - ['Animal']
05/25/2022 10:30:49 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 10:30:49 - INFO - __main__ - ['Animal']
05/25/2022 10:30:49 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 10:30:49 - INFO - __main__ - ['Animal']
05/25/2022 10:30:49 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:30:49 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:30:49 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 10:31:08 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:31:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 10:31:09 - INFO - __main__ - Starting training!
05/25/2022 10:31:13 - INFO - __main__ - Step 10 Global step 10 Train loss 4.98 on epoch=0
05/25/2022 10:31:16 - INFO - __main__ - Step 20 Global step 20 Train loss 3.39 on epoch=1
05/25/2022 10:31:19 - INFO - __main__ - Step 30 Global step 30 Train loss 2.54 on epoch=2
05/25/2022 10:31:22 - INFO - __main__ - Step 40 Global step 40 Train loss 1.96 on epoch=2
05/25/2022 10:31:25 - INFO - __main__ - Step 50 Global step 50 Train loss 1.68 on epoch=3
05/25/2022 10:31:30 - INFO - __main__ - Global step 50 Train loss 2.91 Classification-F1 0.27379657239239785 on epoch=3
05/25/2022 10:31:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.27379657239239785 on epoch=3, global_step=50
05/25/2022 10:31:33 - INFO - __main__ - Step 60 Global step 60 Train loss 1.38 on epoch=4
05/25/2022 10:31:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.13 on epoch=4
05/25/2022 10:31:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=5
05/25/2022 10:31:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=6
05/25/2022 10:31:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=7
05/25/2022 10:31:52 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.6122792876881087 on epoch=7
05/25/2022 10:31:52 - INFO - __main__ - Saving model with best Classification-F1: 0.27379657239239785 -> 0.6122792876881087 on epoch=7, global_step=100
05/25/2022 10:31:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.73 on epoch=7
05/25/2022 10:31:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=8
05/25/2022 10:32:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=9
05/25/2022 10:32:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=9
05/25/2022 10:32:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=10
05/25/2022 10:32:15 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.7068560334378742 on epoch=10
05/25/2022 10:32:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6122792876881087 -> 0.7068560334378742 on epoch=10, global_step=150
05/25/2022 10:32:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=11
05/25/2022 10:32:21 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=12
05/25/2022 10:32:24 - INFO - __main__ - Step 180 Global step 180 Train loss 1.17 on epoch=12
05/25/2022 10:32:27 - INFO - __main__ - Step 190 Global step 190 Train loss 1.05 on epoch=13
05/25/2022 10:32:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=14
05/25/2022 10:32:38 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.6696720649894566 on epoch=14
05/25/2022 10:32:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=14
05/25/2022 10:32:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=15
05/25/2022 10:32:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=16
05/25/2022 10:32:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=17
05/25/2022 10:32:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=17
05/25/2022 10:33:00 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.7351643178345539 on epoch=17
05/25/2022 10:33:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7068560334378742 -> 0.7351643178345539 on epoch=17, global_step=250
05/25/2022 10:33:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
05/25/2022 10:33:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=19
05/25/2022 10:33:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
05/25/2022 10:33:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=20
05/25/2022 10:33:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=21
05/25/2022 10:33:23 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.7285133883788195 on epoch=21
05/25/2022 10:33:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=22
05/25/2022 10:33:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=22
05/25/2022 10:33:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.52 on epoch=23
05/25/2022 10:33:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=24
05/25/2022 10:33:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=24
05/25/2022 10:33:44 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.7951726089417092 on epoch=24
05/25/2022 10:33:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7351643178345539 -> 0.7951726089417092 on epoch=24, global_step=350
05/25/2022 10:33:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=25
05/25/2022 10:33:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.41 on epoch=26
05/25/2022 10:33:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
05/25/2022 10:33:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=27
05/25/2022 10:33:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
05/25/2022 10:34:06 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.787474040324753 on epoch=28
05/25/2022 10:34:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=29
05/25/2022 10:34:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=29
05/25/2022 10:34:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.41 on epoch=30
05/25/2022 10:34:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.46 on epoch=31
05/25/2022 10:34:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=32
05/25/2022 10:34:29 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.8040909037667417 on epoch=32
05/25/2022 10:34:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7951726089417092 -> 0.8040909037667417 on epoch=32, global_step=450
05/25/2022 10:34:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=32
05/25/2022 10:34:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=33
05/25/2022 10:34:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
05/25/2022 10:34:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=34
05/25/2022 10:34:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=35
05/25/2022 10:34:52 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.741731241151604 on epoch=35
05/25/2022 10:34:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=36
05/25/2022 10:34:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.46 on epoch=37
05/25/2022 10:35:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=37
05/25/2022 10:35:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=38
05/25/2022 10:35:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=39
05/25/2022 10:35:15 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.8042097391796951 on epoch=39
05/25/2022 10:35:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8040909037667417 -> 0.8042097391796951 on epoch=39, global_step=550
05/25/2022 10:35:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
05/25/2022 10:35:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=40
05/25/2022 10:35:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=41
05/25/2022 10:35:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
05/25/2022 10:35:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=42
05/25/2022 10:35:37 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.7490631114608226 on epoch=42
05/25/2022 10:35:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=43
05/25/2022 10:35:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=44
05/25/2022 10:35:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=44
05/25/2022 10:35:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=45
05/25/2022 10:35:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=46
05/25/2022 10:36:00 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.8036637851392837 on epoch=46
05/25/2022 10:36:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.38 on epoch=47
05/25/2022 10:36:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.37 on epoch=47
05/25/2022 10:36:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
05/25/2022 10:36:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
05/25/2022 10:36:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
05/25/2022 10:36:23 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.6678359252662659 on epoch=49
05/25/2022 10:36:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=50
05/25/2022 10:36:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=51
05/25/2022 10:36:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=52
05/25/2022 10:36:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=52
05/25/2022 10:36:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
05/25/2022 10:36:46 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.7552348926088845 on epoch=53
05/25/2022 10:36:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
05/25/2022 10:36:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
05/25/2022 10:36:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
05/25/2022 10:36:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=56
05/25/2022 10:37:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
05/25/2022 10:37:09 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.7584172872957287 on epoch=57
05/25/2022 10:37:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
05/25/2022 10:37:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
05/25/2022 10:37:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
05/25/2022 10:37:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
05/25/2022 10:37:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=60
05/25/2022 10:37:32 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.8714971728776829 on epoch=60
05/25/2022 10:37:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8042097391796951 -> 0.8714971728776829 on epoch=60, global_step=850
05/25/2022 10:37:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
05/25/2022 10:37:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
05/25/2022 10:37:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
05/25/2022 10:37:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=63
05/25/2022 10:37:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=64
05/25/2022 10:37:55 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.746432936350896 on epoch=64
05/25/2022 10:37:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/25/2022 10:38:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=65
05/25/2022 10:38:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=66
05/25/2022 10:38:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=67
05/25/2022 10:38:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
05/25/2022 10:38:18 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.8811600781762071 on epoch=67
05/25/2022 10:38:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8714971728776829 -> 0.8811600781762071 on epoch=67, global_step=950
05/25/2022 10:38:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=68
05/25/2022 10:38:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
05/25/2022 10:38:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
05/25/2022 10:38:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
05/25/2022 10:38:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=71
05/25/2022 10:38:41 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.6009071983159204 on epoch=71
05/25/2022 10:38:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
05/25/2022 10:38:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
05/25/2022 10:38:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=73
05/25/2022 10:38:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
05/25/2022 10:38:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=74
05/25/2022 10:39:04 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6494764795898322 on epoch=74
05/25/2022 10:39:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
05/25/2022 10:39:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
05/25/2022 10:39:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=77
05/25/2022 10:39:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
05/25/2022 10:39:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
05/25/2022 10:39:26 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6967778482142706 on epoch=78
05/25/2022 10:39:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
05/25/2022 10:39:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
05/25/2022 10:39:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=80
05/25/2022 10:39:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
05/25/2022 10:39:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
05/25/2022 10:39:47 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7646663714387608 on epoch=82
05/25/2022 10:39:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
05/25/2022 10:39:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.38 on epoch=83
05/25/2022 10:39:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.39 on epoch=84
05/25/2022 10:39:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=84
05/25/2022 10:40:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=85
05/25/2022 10:40:10 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.7045884817160514 on epoch=85
05/25/2022 10:40:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=86
05/25/2022 10:40:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
05/25/2022 10:40:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
05/25/2022 10:40:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=88
05/25/2022 10:40:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
05/25/2022 10:40:33 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7187109073177931 on epoch=89
05/25/2022 10:40:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=89
05/25/2022 10:40:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
05/25/2022 10:40:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
05/25/2022 10:40:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
05/25/2022 10:40:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
05/25/2022 10:40:54 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.8241248506571087 on epoch=92
05/25/2022 10:40:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/25/2022 10:41:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
05/25/2022 10:41:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=94
05/25/2022 10:41:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
05/25/2022 10:41:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=96
05/25/2022 10:41:17 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.8391153639893559 on epoch=96
05/25/2022 10:41:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=97
05/25/2022 10:41:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=97
05/25/2022 10:41:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/25/2022 10:41:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
05/25/2022 10:41:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
05/25/2022 10:41:39 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.708401384897565 on epoch=99
05/25/2022 10:41:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
05/25/2022 10:41:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
05/25/2022 10:41:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
05/25/2022 10:41:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
05/25/2022 10:41:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
05/25/2022 10:42:01 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.783605968963832 on epoch=103
05/25/2022 10:42:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
05/25/2022 10:42:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
05/25/2022 10:42:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
05/25/2022 10:42:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
05/25/2022 10:42:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
05/25/2022 10:42:23 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6662624452975799 on epoch=107
05/25/2022 10:42:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
05/25/2022 10:42:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
05/25/2022 10:42:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
05/25/2022 10:42:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
05/25/2022 10:42:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/25/2022 10:42:45 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6753433347915301 on epoch=110
05/25/2022 10:42:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
05/25/2022 10:42:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
05/25/2022 10:42:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
05/25/2022 10:42:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
05/25/2022 10:43:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
05/25/2022 10:43:07 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.6808411990298455 on epoch=114
05/25/2022 10:43:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/25/2022 10:43:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
05/25/2022 10:43:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/25/2022 10:43:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=117
05/25/2022 10:43:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/25/2022 10:43:29 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.6664425131904094 on epoch=117
05/25/2022 10:43:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
05/25/2022 10:43:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=119
05/25/2022 10:43:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
05/25/2022 10:43:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
05/25/2022 10:43:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
05/25/2022 10:43:51 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.7139381406086371 on epoch=121
05/25/2022 10:43:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/25/2022 10:43:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/25/2022 10:44:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
05/25/2022 10:44:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
05/25/2022 10:44:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/25/2022 10:44:13 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6926583957590632 on epoch=124
05/25/2022 10:44:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
05/25/2022 10:44:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
05/25/2022 10:44:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
05/25/2022 10:44:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
05/25/2022 10:44:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
05/25/2022 10:44:35 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6781727763806616 on epoch=128
05/25/2022 10:44:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/25/2022 10:44:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
05/25/2022 10:44:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/25/2022 10:44:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/25/2022 10:44:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/25/2022 10:44:57 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7169896947360712 on epoch=132
05/25/2022 10:45:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
05/25/2022 10:45:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
05/25/2022 10:45:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 10:45:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
05/25/2022 10:45:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
05/25/2022 10:45:19 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7158397493820217 on epoch=135
05/25/2022 10:45:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/25/2022 10:45:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
05/25/2022 10:45:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
05/25/2022 10:45:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
05/25/2022 10:45:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
05/25/2022 10:45:41 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6909627441036609 on epoch=139
05/25/2022 10:45:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/25/2022 10:45:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
05/25/2022 10:45:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
05/25/2022 10:45:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/25/2022 10:45:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/25/2022 10:46:03 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7603621130785252 on epoch=142
05/25/2022 10:46:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
05/25/2022 10:46:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/25/2022 10:46:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/25/2022 10:46:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/25/2022 10:46:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
05/25/2022 10:46:24 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7337119553438339 on epoch=146
05/25/2022 10:46:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
05/25/2022 10:46:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/25/2022 10:46:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/25/2022 10:46:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
05/25/2022 10:46:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
05/25/2022 10:46:45 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6670471538216458 on epoch=149
05/25/2022 10:46:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/25/2022 10:46:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/25/2022 10:46:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 10:46:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
05/25/2022 10:47:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/25/2022 10:47:07 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7710897279881255 on epoch=153
05/25/2022 10:47:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
05/25/2022 10:47:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/25/2022 10:47:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
05/25/2022 10:47:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
05/25/2022 10:47:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/25/2022 10:47:28 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.5610988656993056 on epoch=157
05/25/2022 10:47:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/25/2022 10:47:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/25/2022 10:47:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
05/25/2022 10:47:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/25/2022 10:47:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
05/25/2022 10:47:49 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7013310285013321 on epoch=160
05/25/2022 10:47:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
05/25/2022 10:47:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/25/2022 10:47:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/25/2022 10:48:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
05/25/2022 10:48:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
05/25/2022 10:48:11 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7790039182828558 on epoch=164
05/25/2022 10:48:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
05/25/2022 10:48:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
05/25/2022 10:48:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/25/2022 10:48:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
05/25/2022 10:48:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
05/25/2022 10:48:33 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8469819159335289 on epoch=167
05/25/2022 10:48:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
05/25/2022 10:48:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
05/25/2022 10:48:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
05/25/2022 10:48:44 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
05/25/2022 10:48:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
05/25/2022 10:48:54 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8469819159335288 on epoch=171
05/25/2022 10:48:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/25/2022 10:49:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
05/25/2022 10:49:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
05/25/2022 10:49:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/25/2022 10:49:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
05/25/2022 10:49:17 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8009811109194411 on epoch=174
05/25/2022 10:49:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
05/25/2022 10:49:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
05/25/2022 10:49:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
05/25/2022 10:49:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/25/2022 10:49:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
05/25/2022 10:49:39 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9016811608858326 on epoch=178
05/25/2022 10:49:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8811600781762071 -> 0.9016811608858326 on epoch=178, global_step=2500
05/25/2022 10:49:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
05/25/2022 10:49:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/25/2022 10:49:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 10:49:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
05/25/2022 10:49:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/25/2022 10:50:01 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9776698435972629 on epoch=182
05/25/2022 10:50:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9016811608858326 -> 0.9776698435972629 on epoch=182, global_step=2550
05/25/2022 10:50:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/25/2022 10:50:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
05/25/2022 10:50:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/25/2022 10:50:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/25/2022 10:50:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.12 on epoch=185
05/25/2022 10:50:24 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.892244364848729 on epoch=185
05/25/2022 10:50:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/25/2022 10:50:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/25/2022 10:50:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/25/2022 10:50:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/25/2022 10:50:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 10:50:45 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9012698323182192 on epoch=189
05/25/2022 10:50:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/25/2022 10:50:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/25/2022 10:50:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 10:50:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 10:51:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/25/2022 10:51:07 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7004525542159951 on epoch=192
05/25/2022 10:51:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/25/2022 10:51:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 10:51:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/25/2022 10:51:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/25/2022 10:51:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/25/2022 10:51:29 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8970819861142442 on epoch=196
05/25/2022 10:51:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
05/25/2022 10:51:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/25/2022 10:51:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
05/25/2022 10:51:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
05/25/2022 10:51:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/25/2022 10:51:51 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.9042916621411246 on epoch=199
05/25/2022 10:51:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 10:51:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
05/25/2022 10:51:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/25/2022 10:52:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
05/25/2022 10:52:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/25/2022 10:52:12 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8266094120932831 on epoch=203
05/25/2022 10:52:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
05/25/2022 10:52:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/25/2022 10:52:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/25/2022 10:52:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
05/25/2022 10:52:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/25/2022 10:52:34 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7565765178668404 on epoch=207
05/25/2022 10:52:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/25/2022 10:52:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=208
05/25/2022 10:52:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/25/2022 10:52:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/25/2022 10:52:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
05/25/2022 10:52:56 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6915824915824916 on epoch=210
05/25/2022 10:52:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
05/25/2022 10:53:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
05/25/2022 10:53:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/25/2022 10:53:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
05/25/2022 10:53:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/25/2022 10:53:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:53:12 - INFO - __main__ - Printing 3 examples
05/25/2022 10:53:12 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 10:53:12 - INFO - __main__ - ['Animal']
05/25/2022 10:53:12 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 10:53:12 - INFO - __main__ - ['Animal']
05/25/2022 10:53:12 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 10:53:12 - INFO - __main__ - ['Animal']
05/25/2022 10:53:12 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:53:12 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:53:13 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 10:53:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:53:13 - INFO - __main__ - Printing 3 examples
05/25/2022 10:53:13 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 10:53:13 - INFO - __main__ - ['Animal']
05/25/2022 10:53:13 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 10:53:13 - INFO - __main__ - ['Animal']
05/25/2022 10:53:13 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 10:53:13 - INFO - __main__ - ['Animal']
05/25/2022 10:53:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:53:13 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:53:13 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 10:53:18 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7866229659019032 on epoch=214
05/25/2022 10:53:18 - INFO - __main__ - save last model!
05/25/2022 10:53:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 10:53:18 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 10:53:18 - INFO - __main__ - Printing 3 examples
05/25/2022 10:53:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 10:53:18 - INFO - __main__ - ['Animal']
05/25/2022 10:53:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 10:53:18 - INFO - __main__ - ['Animal']
05/25/2022 10:53:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 10:53:18 - INFO - __main__ - ['Village']
05/25/2022 10:53:18 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:53:19 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:53:23 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 10:53:32 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:53:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 10:53:33 - INFO - __main__ - Starting training!
05/25/2022 10:55:39 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/25/2022 10:55:39 - INFO - __main__ - Classification-F1 on test data: 0.5290
05/25/2022 10:55:39 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9776698435972629, test_performance=0.5290461931113785
05/25/2022 10:55:39 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/25/2022 10:55:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:55:40 - INFO - __main__ - Printing 3 examples
05/25/2022 10:55:40 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 10:55:40 - INFO - __main__ - ['Animal']
05/25/2022 10:55:40 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 10:55:40 - INFO - __main__ - ['Animal']
05/25/2022 10:55:40 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 10:55:40 - INFO - __main__ - ['Animal']
05/25/2022 10:55:40 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:55:40 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:55:41 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 10:55:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 10:55:41 - INFO - __main__ - Printing 3 examples
05/25/2022 10:55:41 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 10:55:41 - INFO - __main__ - ['Animal']
05/25/2022 10:55:41 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 10:55:41 - INFO - __main__ - ['Animal']
05/25/2022 10:55:41 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 10:55:41 - INFO - __main__ - ['Animal']
05/25/2022 10:55:41 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:55:41 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:55:41 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 10:55:59 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:56:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 10:56:00 - INFO - __main__ - Starting training!
05/25/2022 10:56:05 - INFO - __main__ - Step 10 Global step 10 Train loss 5.31 on epoch=0
05/25/2022 10:56:08 - INFO - __main__ - Step 20 Global step 20 Train loss 3.99 on epoch=1
05/25/2022 10:56:11 - INFO - __main__ - Step 30 Global step 30 Train loss 3.13 on epoch=2
05/25/2022 10:56:14 - INFO - __main__ - Step 40 Global step 40 Train loss 2.37 on epoch=2
05/25/2022 10:56:17 - INFO - __main__ - Step 50 Global step 50 Train loss 2.09 on epoch=3
05/25/2022 10:56:21 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.026410564225690276 on epoch=3
05/25/2022 10:56:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.026410564225690276 on epoch=3, global_step=50
05/25/2022 10:56:24 - INFO - __main__ - Step 60 Global step 60 Train loss 1.68 on epoch=4
05/25/2022 10:56:27 - INFO - __main__ - Step 70 Global step 70 Train loss 1.42 on epoch=4
05/25/2022 10:56:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.15 on epoch=5
05/25/2022 10:56:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.09 on epoch=6
05/25/2022 10:56:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=7
05/25/2022 10:56:44 - INFO - __main__ - Global step 100 Train loss 1.25 Classification-F1 0.47870234019466157 on epoch=7
05/25/2022 10:56:44 - INFO - __main__ - Saving model with best Classification-F1: 0.026410564225690276 -> 0.47870234019466157 on epoch=7, global_step=100
05/25/2022 10:56:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.86 on epoch=7
05/25/2022 10:56:50 - INFO - __main__ - Step 120 Global step 120 Train loss 0.73 on epoch=8
05/25/2022 10:56:53 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=9
05/25/2022 10:56:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=9
05/25/2022 10:56:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.62 on epoch=10
05/25/2022 10:57:07 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.5854611430425292 on epoch=10
05/25/2022 10:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.47870234019466157 -> 0.5854611430425292 on epoch=10, global_step=150
05/25/2022 10:57:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=11
05/25/2022 10:57:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=12
05/25/2022 10:57:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=12
05/25/2022 10:57:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=13
05/25/2022 10:57:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=14
05/25/2022 10:57:30 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.7121998538681465 on epoch=14
05/25/2022 10:57:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5854611430425292 -> 0.7121998538681465 on epoch=14, global_step=200
05/25/2022 10:57:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=14
05/25/2022 10:57:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
05/25/2022 10:57:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.56 on epoch=16
05/25/2022 10:57:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=17
05/25/2022 10:57:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=17
05/25/2022 10:57:52 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.7858724257415676 on epoch=17
05/25/2022 10:57:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7121998538681465 -> 0.7858724257415676 on epoch=17, global_step=250
05/25/2022 10:57:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=18
05/25/2022 10:57:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=19
05/25/2022 10:58:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
05/25/2022 10:58:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=20
05/25/2022 10:58:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=21
05/25/2022 10:58:15 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.7382632496289636 on epoch=21
05/25/2022 10:58:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
05/25/2022 10:58:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=22
05/25/2022 10:58:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
05/25/2022 10:58:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=24
05/25/2022 10:58:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=24
05/25/2022 10:58:37 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6478082072365754 on epoch=24
05/25/2022 10:58:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=25
05/25/2022 10:58:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=26
05/25/2022 10:58:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
05/25/2022 10:58:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=27
05/25/2022 10:58:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
05/25/2022 10:59:00 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.8073063252671546 on epoch=28
05/25/2022 10:59:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7858724257415676 -> 0.8073063252671546 on epoch=28, global_step=400
05/25/2022 10:59:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
05/25/2022 10:59:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=29
05/25/2022 10:59:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
05/25/2022 10:59:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
05/25/2022 10:59:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=32
05/25/2022 10:59:23 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.6389664345441834 on epoch=32
05/25/2022 10:59:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=32
05/25/2022 10:59:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=33
05/25/2022 10:59:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
05/25/2022 10:59:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=34
05/25/2022 10:59:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
05/25/2022 10:59:46 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6367801485868108 on epoch=35
05/25/2022 10:59:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
05/25/2022 10:59:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
05/25/2022 10:59:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
05/25/2022 10:59:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=38
05/25/2022 11:00:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
05/25/2022 11:00:09 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.7747724904314339 on epoch=39
05/25/2022 11:00:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
05/25/2022 11:00:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
05/25/2022 11:00:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=41
05/25/2022 11:00:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
05/25/2022 11:00:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
05/25/2022 11:00:32 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.701389213248649 on epoch=42
05/25/2022 11:00:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
05/25/2022 11:00:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=44
05/25/2022 11:00:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
05/25/2022 11:00:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
05/25/2022 11:00:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=46
05/25/2022 11:00:55 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.6404493110375464 on epoch=46
05/25/2022 11:00:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
05/25/2022 11:01:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
05/25/2022 11:01:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
05/25/2022 11:01:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
05/25/2022 11:01:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
05/25/2022 11:01:18 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7084380216733158 on epoch=49
05/25/2022 11:01:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
05/25/2022 11:01:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=51
05/25/2022 11:01:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
05/25/2022 11:01:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
05/25/2022 11:01:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
05/25/2022 11:01:41 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.7085608864055504 on epoch=53
05/25/2022 11:01:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=54
05/25/2022 11:01:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
05/25/2022 11:01:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
05/25/2022 11:01:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
05/25/2022 11:01:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=57
05/25/2022 11:02:03 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.617330474443531 on epoch=57
05/25/2022 11:02:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
05/25/2022 11:02:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
05/25/2022 11:02:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
05/25/2022 11:02:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
05/25/2022 11:02:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
05/25/2022 11:02:27 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7303558747704888 on epoch=60
05/25/2022 11:02:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
05/25/2022 11:02:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
05/25/2022 11:02:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=62
05/25/2022 11:02:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
05/25/2022 11:02:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
05/25/2022 11:02:49 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7765584606782343 on epoch=64
05/25/2022 11:02:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
05/25/2022 11:02:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
05/25/2022 11:02:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
05/25/2022 11:03:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
05/25/2022 11:03:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
05/25/2022 11:03:11 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.8606073224336981 on epoch=67
05/25/2022 11:03:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8073063252671546 -> 0.8606073224336981 on epoch=67, global_step=950
05/25/2022 11:03:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
05/25/2022 11:03:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
05/25/2022 11:03:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
05/25/2022 11:03:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
05/25/2022 11:03:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=71
05/25/2022 11:03:34 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8589471386356815 on epoch=71
05/25/2022 11:03:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
05/25/2022 11:03:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
05/25/2022 11:03:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
05/25/2022 11:03:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=74
05/25/2022 11:03:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
05/25/2022 11:03:56 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7533119760096495 on epoch=74
05/25/2022 11:03:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
05/25/2022 11:04:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
05/25/2022 11:04:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
05/25/2022 11:04:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
05/25/2022 11:04:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
05/25/2022 11:04:18 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.770176623396618 on epoch=78
05/25/2022 11:04:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
05/25/2022 11:04:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
05/25/2022 11:04:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
05/25/2022 11:04:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
05/25/2022 11:04:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
05/25/2022 11:04:40 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6921333372011259 on epoch=82
05/25/2022 11:04:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=82
05/25/2022 11:04:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
05/25/2022 11:04:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
05/25/2022 11:04:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
05/25/2022 11:04:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
05/25/2022 11:05:02 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7971671381076655 on epoch=85
05/25/2022 11:05:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
05/25/2022 11:05:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
05/25/2022 11:05:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/25/2022 11:05:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
05/25/2022 11:05:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
05/25/2022 11:05:24 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.8863268836371303 on epoch=89
05/25/2022 11:05:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8606073224336981 -> 0.8863268836371303 on epoch=89, global_step=1250
05/25/2022 11:05:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
05/25/2022 11:05:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/25/2022 11:05:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
05/25/2022 11:05:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
05/25/2022 11:05:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/25/2022 11:05:46 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7574467749264044 on epoch=92
05/25/2022 11:05:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/25/2022 11:05:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/25/2022 11:05:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/25/2022 11:05:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 11:06:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
05/25/2022 11:06:08 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7666458893100289 on epoch=96
05/25/2022 11:06:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
05/25/2022 11:06:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/25/2022 11:06:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
05/25/2022 11:06:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
05/25/2022 11:06:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/25/2022 11:06:30 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7693026094868425 on epoch=99
05/25/2022 11:06:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
05/25/2022 11:06:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/25/2022 11:06:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/25/2022 11:06:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
05/25/2022 11:06:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
05/25/2022 11:06:53 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7569861687188446 on epoch=103
05/25/2022 11:06:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
05/25/2022 11:06:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
05/25/2022 11:07:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/25/2022 11:07:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/25/2022 11:07:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
05/25/2022 11:07:15 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7564449027570499 on epoch=107
05/25/2022 11:07:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
05/25/2022 11:07:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/25/2022 11:07:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/25/2022 11:07:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
05/25/2022 11:07:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/25/2022 11:07:37 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9058192208018812 on epoch=110
05/25/2022 11:07:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8863268836371303 -> 0.9058192208018812 on epoch=110, global_step=1550
05/25/2022 11:07:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/25/2022 11:07:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
05/25/2022 11:07:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/25/2022 11:07:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/25/2022 11:07:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/25/2022 11:07:59 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6935847640491604 on epoch=114
05/25/2022 11:08:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/25/2022 11:08:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/25/2022 11:08:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 11:08:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/25/2022 11:08:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/25/2022 11:08:22 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7867059176803569 on epoch=117
05/25/2022 11:08:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/25/2022 11:08:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
05/25/2022 11:08:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=119
05/25/2022 11:08:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/25/2022 11:08:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/25/2022 11:08:44 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7471076352355436 on epoch=121
05/25/2022 11:08:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 11:08:50 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/25/2022 11:08:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/25/2022 11:08:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/25/2022 11:08:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/25/2022 11:09:05 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7686143645444831 on epoch=124
05/25/2022 11:09:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 11:09:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
05/25/2022 11:09:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/25/2022 11:09:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 11:09:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/25/2022 11:09:28 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9731478515159729 on epoch=128
05/25/2022 11:09:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9058192208018812 -> 0.9731478515159729 on epoch=128, global_step=1800
05/25/2022 11:09:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/25/2022 11:09:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/25/2022 11:09:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 11:09:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/25/2022 11:09:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=132
05/25/2022 11:09:50 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8474759304381577 on epoch=132
05/25/2022 11:09:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/25/2022 11:09:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 11:09:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 11:10:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/25/2022 11:10:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/25/2022 11:10:12 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9038383838383837 on epoch=135
05/25/2022 11:10:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
05/25/2022 11:10:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 11:10:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/25/2022 11:10:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/25/2022 11:10:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
05/25/2022 11:10:34 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9061207904471662 on epoch=139
05/25/2022 11:10:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 11:10:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
05/25/2022 11:10:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/25/2022 11:10:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
05/25/2022 11:10:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 11:10:57 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8437523103082876 on epoch=142
05/25/2022 11:11:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/25/2022 11:11:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/25/2022 11:11:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/25/2022 11:11:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 11:11:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 11:11:19 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8363438792444877 on epoch=146
05/25/2022 11:11:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 11:11:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
05/25/2022 11:11:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/25/2022 11:11:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
05/25/2022 11:11:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
05/25/2022 11:11:41 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.784681882259737 on epoch=149
05/25/2022 11:11:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
05/25/2022 11:11:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 11:11:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
05/25/2022 11:11:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
05/25/2022 11:11:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
05/25/2022 11:12:04 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8492316428037491 on epoch=153
05/25/2022 11:12:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/25/2022 11:12:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
05/25/2022 11:12:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 11:12:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/25/2022 11:12:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 11:12:27 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8414222873900293 on epoch=157
05/25/2022 11:12:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 11:12:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/25/2022 11:12:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/25/2022 11:12:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/25/2022 11:12:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.13 on epoch=160
05/25/2022 11:12:48 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8427890657729368 on epoch=160
05/25/2022 11:12:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
05/25/2022 11:12:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/25/2022 11:12:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 11:13:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/25/2022 11:13:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 11:13:11 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8444697380418443 on epoch=164
05/25/2022 11:13:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/25/2022 11:13:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 11:13:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 11:13:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
05/25/2022 11:13:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/25/2022 11:13:33 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7271793565911213 on epoch=167
05/25/2022 11:13:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/25/2022 11:13:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 11:13:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/25/2022 11:13:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 11:13:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 11:13:56 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7176046176046176 on epoch=171
05/25/2022 11:13:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/25/2022 11:14:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 11:14:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/25/2022 11:14:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
05/25/2022 11:14:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/25/2022 11:14:18 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8273051948051948 on epoch=174
05/25/2022 11:14:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 11:14:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 11:14:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/25/2022 11:14:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 11:14:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/25/2022 11:14:40 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.840020349832723 on epoch=178
05/25/2022 11:14:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/25/2022 11:14:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/25/2022 11:14:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 11:14:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
05/25/2022 11:14:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/25/2022 11:15:03 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7712136281829376 on epoch=182
05/25/2022 11:15:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/25/2022 11:15:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/25/2022 11:15:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/25/2022 11:15:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/25/2022 11:15:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 11:15:24 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.777113572701808 on epoch=185
05/25/2022 11:15:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
05/25/2022 11:15:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 11:15:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/25/2022 11:15:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/25/2022 11:15:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 11:15:47 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.8413079160159249 on epoch=189
05/25/2022 11:15:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 11:15:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 11:15:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/25/2022 11:15:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/25/2022 11:16:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 11:16:08 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9001290684624018 on epoch=192
05/25/2022 11:16:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/25/2022 11:16:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 11:16:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 11:16:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 11:16:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 11:16:30 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8390020513760433 on epoch=196
05/25/2022 11:16:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 11:16:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/25/2022 11:16:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 11:16:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 11:16:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 11:16:52 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.9012527257688547 on epoch=199
05/25/2022 11:16:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 11:16:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 11:17:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 11:17:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 11:17:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 11:17:15 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9042916621411246 on epoch=203
05/25/2022 11:17:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 11:17:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 11:17:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 11:17:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 11:17:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 11:17:37 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9029182582123758 on epoch=207
05/25/2022 11:17:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 11:17:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 11:17:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 11:17:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/25/2022 11:17:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 11:17:59 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9121928967090257 on epoch=210
05/25/2022 11:18:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/25/2022 11:18:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 11:18:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 11:18:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/25/2022 11:18:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 11:18:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:18:16 - INFO - __main__ - Printing 3 examples
05/25/2022 11:18:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 11:18:16 - INFO - __main__ - ['Animal']
05/25/2022 11:18:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 11:18:16 - INFO - __main__ - ['Animal']
05/25/2022 11:18:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 11:18:16 - INFO - __main__ - ['Animal']
05/25/2022 11:18:16 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:18:16 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:18:16 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 11:18:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:18:16 - INFO - __main__ - Printing 3 examples
05/25/2022 11:18:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 11:18:16 - INFO - __main__ - ['Animal']
05/25/2022 11:18:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 11:18:16 - INFO - __main__ - ['Animal']
05/25/2022 11:18:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 11:18:16 - INFO - __main__ - ['Animal']
05/25/2022 11:18:16 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:18:16 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:18:16 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 11:18:21 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7482034351882023 on epoch=214
05/25/2022 11:18:21 - INFO - __main__ - save last model!
05/25/2022 11:18:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 11:18:21 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 11:18:21 - INFO - __main__ - Printing 3 examples
05/25/2022 11:18:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 11:18:21 - INFO - __main__ - ['Animal']
05/25/2022 11:18:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 11:18:21 - INFO - __main__ - ['Animal']
05/25/2022 11:18:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 11:18:21 - INFO - __main__ - ['Village']
05/25/2022 11:18:21 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:18:23 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:18:26 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 11:18:32 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 11:18:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 11:18:32 - INFO - __main__ - Starting training!
05/25/2022 11:20:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/25/2022 11:20:47 - INFO - __main__ - Classification-F1 on test data: 0.5132
05/25/2022 11:20:47 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9731478515159729, test_performance=0.5131585241948451
05/25/2022 11:20:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/25/2022 11:20:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:20:48 - INFO - __main__ - Printing 3 examples
05/25/2022 11:20:48 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 11:20:48 - INFO - __main__ - ['Animal']
05/25/2022 11:20:48 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 11:20:48 - INFO - __main__ - ['Animal']
05/25/2022 11:20:48 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 11:20:48 - INFO - __main__ - ['Animal']
05/25/2022 11:20:48 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:20:48 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:20:49 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 11:20:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:20:49 - INFO - __main__ - Printing 3 examples
05/25/2022 11:20:49 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/25/2022 11:20:49 - INFO - __main__ - ['Animal']
05/25/2022 11:20:49 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/25/2022 11:20:49 - INFO - __main__ - ['Animal']
05/25/2022 11:20:49 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/25/2022 11:20:49 - INFO - __main__ - ['Animal']
05/25/2022 11:20:49 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:20:49 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:20:49 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 11:21:04 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 11:21:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 11:21:05 - INFO - __main__ - Starting training!
05/25/2022 11:21:09 - INFO - __main__ - Step 10 Global step 10 Train loss 5.66 on epoch=0
05/25/2022 11:21:12 - INFO - __main__ - Step 20 Global step 20 Train loss 4.62 on epoch=1
05/25/2022 11:21:15 - INFO - __main__ - Step 30 Global step 30 Train loss 3.75 on epoch=2
05/25/2022 11:21:18 - INFO - __main__ - Step 40 Global step 40 Train loss 3.17 on epoch=2
05/25/2022 11:21:21 - INFO - __main__ - Step 50 Global step 50 Train loss 2.83 on epoch=3
05/25/2022 11:21:26 - INFO - __main__ - Global step 50 Train loss 4.00 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 11:21:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 11:21:29 - INFO - __main__ - Step 60 Global step 60 Train loss 2.42 on epoch=4
05/25/2022 11:21:32 - INFO - __main__ - Step 70 Global step 70 Train loss 2.13 on epoch=4
05/25/2022 11:21:35 - INFO - __main__ - Step 80 Global step 80 Train loss 1.85 on epoch=5
05/25/2022 11:21:38 - INFO - __main__ - Step 90 Global step 90 Train loss 1.70 on epoch=6
05/25/2022 11:21:41 - INFO - __main__ - Step 100 Global step 100 Train loss 1.52 on epoch=7
05/25/2022 11:21:46 - INFO - __main__ - Global step 100 Train loss 1.93 Classification-F1 0.313219110919768 on epoch=7
05/25/2022 11:21:46 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.313219110919768 on epoch=7, global_step=100
05/25/2022 11:21:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.29 on epoch=7
05/25/2022 11:21:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.19 on epoch=8
05/25/2022 11:21:55 - INFO - __main__ - Step 130 Global step 130 Train loss 1.09 on epoch=9
05/25/2022 11:21:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=9
05/25/2022 11:22:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.90 on epoch=10
05/25/2022 11:22:09 - INFO - __main__ - Global step 150 Train loss 1.09 Classification-F1 0.4647873739781415 on epoch=10
05/25/2022 11:22:09 - INFO - __main__ - Saving model with best Classification-F1: 0.313219110919768 -> 0.4647873739781415 on epoch=10, global_step=150
05/25/2022 11:22:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=11
05/25/2022 11:22:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=12
05/25/2022 11:22:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=12
05/25/2022 11:22:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.78 on epoch=13
05/25/2022 11:22:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.75 on epoch=14
05/25/2022 11:22:33 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.5721891899618872 on epoch=14
05/25/2022 11:22:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4647873739781415 -> 0.5721891899618872 on epoch=14, global_step=200
05/25/2022 11:22:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=14
05/25/2022 11:22:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.67 on epoch=15
05/25/2022 11:22:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=16
05/25/2022 11:22:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=17
05/25/2022 11:22:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=17
05/25/2022 11:22:57 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.7826167182912581 on epoch=17
05/25/2022 11:22:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5721891899618872 -> 0.7826167182912581 on epoch=17, global_step=250
05/25/2022 11:23:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=18
05/25/2022 11:23:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
05/25/2022 11:23:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=19
05/25/2022 11:23:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=20
05/25/2022 11:23:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=21
05/25/2022 11:23:20 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.6493580842133972 on epoch=21
05/25/2022 11:23:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=22
05/25/2022 11:23:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=22
05/25/2022 11:23:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=23
05/25/2022 11:23:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=24
05/25/2022 11:23:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=24
05/25/2022 11:23:43 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.5801419355098361 on epoch=24
05/25/2022 11:23:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=25
05/25/2022 11:23:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=26
05/25/2022 11:23:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=27
05/25/2022 11:23:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=27
05/25/2022 11:23:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=28
05/25/2022 11:24:07 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.746537618932412 on epoch=28
05/25/2022 11:24:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=29
05/25/2022 11:24:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
05/25/2022 11:24:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
05/25/2022 11:24:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=31
05/25/2022 11:24:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=32
05/25/2022 11:24:30 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.6265715164959079 on epoch=32
05/25/2022 11:24:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=32
05/25/2022 11:24:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=33
05/25/2022 11:24:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=34
05/25/2022 11:24:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=34
05/25/2022 11:24:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
05/25/2022 11:24:53 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.6558433938179448 on epoch=35
05/25/2022 11:24:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=36
05/25/2022 11:24:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
05/25/2022 11:25:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=37
05/25/2022 11:25:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.34 on epoch=38
05/25/2022 11:25:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=39
05/25/2022 11:25:17 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.7254670160809826 on epoch=39
05/25/2022 11:25:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=39
05/25/2022 11:25:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
05/25/2022 11:25:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=41
05/25/2022 11:25:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=42
05/25/2022 11:25:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
05/25/2022 11:25:39 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.6230113031562305 on epoch=42
05/25/2022 11:25:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=43
05/25/2022 11:25:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
05/25/2022 11:25:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
05/25/2022 11:25:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
05/25/2022 11:25:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
05/25/2022 11:26:03 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.7161549159288114 on epoch=46
05/25/2022 11:26:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
05/25/2022 11:26:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
05/25/2022 11:26:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
05/25/2022 11:26:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=49
05/25/2022 11:26:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=49
05/25/2022 11:26:26 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7240488908285644 on epoch=49
05/25/2022 11:26:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
05/25/2022 11:26:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
05/25/2022 11:26:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=52
05/25/2022 11:26:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=52
05/25/2022 11:26:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
05/25/2022 11:26:49 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.8601746106284374 on epoch=53
05/25/2022 11:26:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7826167182912581 -> 0.8601746106284374 on epoch=53, global_step=750
05/25/2022 11:26:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
05/25/2022 11:26:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
05/25/2022 11:26:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
05/25/2022 11:27:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
05/25/2022 11:27:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
05/25/2022 11:27:13 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7412567307140392 on epoch=57
05/25/2022 11:27:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
05/25/2022 11:27:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
05/25/2022 11:27:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
05/25/2022 11:27:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
05/25/2022 11:27:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
05/25/2022 11:27:36 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6765156667885731 on epoch=60
05/25/2022 11:27:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
05/25/2022 11:27:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
05/25/2022 11:27:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
05/25/2022 11:27:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
05/25/2022 11:27:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
05/25/2022 11:28:00 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.8356532703396354 on epoch=64
05/25/2022 11:28:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/25/2022 11:28:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
05/25/2022 11:28:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
05/25/2022 11:28:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=67
05/25/2022 11:28:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
05/25/2022 11:28:23 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.79850095868057 on epoch=67
05/25/2022 11:28:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
05/25/2022 11:28:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
05/25/2022 11:28:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
05/25/2022 11:28:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
05/25/2022 11:28:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
05/25/2022 11:28:46 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7483811734946113 on epoch=71
05/25/2022 11:28:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
05/25/2022 11:28:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
05/25/2022 11:28:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
05/25/2022 11:28:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
05/25/2022 11:29:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
05/25/2022 11:29:09 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7752106107235027 on epoch=74
05/25/2022 11:29:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
05/25/2022 11:29:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
05/25/2022 11:29:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
05/25/2022 11:29:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
05/25/2022 11:29:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
05/25/2022 11:29:34 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.8329999113843909 on epoch=78
05/25/2022 11:29:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
05/25/2022 11:29:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
05/25/2022 11:29:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
05/25/2022 11:29:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
05/25/2022 11:29:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=82
05/25/2022 11:29:57 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6928763370189517 on epoch=82
05/25/2022 11:30:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
05/25/2022 11:30:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
05/25/2022 11:30:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
05/25/2022 11:30:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
05/25/2022 11:30:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
05/25/2022 11:30:20 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.8949447853432673 on epoch=85
05/25/2022 11:30:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8601746106284374 -> 0.8949447853432673 on epoch=85, global_step=1200
05/25/2022 11:30:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
05/25/2022 11:30:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
05/25/2022 11:30:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
05/25/2022 11:30:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
05/25/2022 11:30:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
05/25/2022 11:30:44 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7779913207304657 on epoch=89
05/25/2022 11:30:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
05/25/2022 11:30:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
05/25/2022 11:30:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
05/25/2022 11:30:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
05/25/2022 11:30:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
05/25/2022 11:31:07 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7331046822731163 on epoch=92
05/25/2022 11:31:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
05/25/2022 11:31:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
05/25/2022 11:31:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
05/25/2022 11:31:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
05/25/2022 11:31:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
05/25/2022 11:31:30 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.766593268323372 on epoch=96
05/25/2022 11:31:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
05/25/2022 11:31:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
05/25/2022 11:31:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
05/25/2022 11:31:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
05/25/2022 11:31:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=99
05/25/2022 11:31:53 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.8931669637551991 on epoch=99
05/25/2022 11:31:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
05/25/2022 11:31:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
05/25/2022 11:32:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 11:32:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
05/25/2022 11:32:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/25/2022 11:32:17 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8400417042020458 on epoch=103
05/25/2022 11:32:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
05/25/2022 11:32:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
05/25/2022 11:32:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
05/25/2022 11:32:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
05/25/2022 11:32:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
05/25/2022 11:32:40 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6635276162351998 on epoch=107
05/25/2022 11:32:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
05/25/2022 11:32:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
05/25/2022 11:32:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/25/2022 11:32:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/25/2022 11:32:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/25/2022 11:33:03 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7912198379438027 on epoch=110
05/25/2022 11:33:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
05/25/2022 11:33:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
05/25/2022 11:33:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
05/25/2022 11:33:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
05/25/2022 11:33:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
05/25/2022 11:33:26 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.837356247484331 on epoch=114
05/25/2022 11:33:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/25/2022 11:33:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
05/25/2022 11:33:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
05/25/2022 11:33:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
05/25/2022 11:33:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
05/25/2022 11:33:49 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8954739041266555 on epoch=117
05/25/2022 11:33:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8949447853432673 -> 0.8954739041266555 on epoch=117, global_step=1650
05/25/2022 11:33:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
05/25/2022 11:33:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/25/2022 11:33:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
05/25/2022 11:34:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
05/25/2022 11:34:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/25/2022 11:34:13 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.897624441761064 on epoch=121
05/25/2022 11:34:13 - INFO - __main__ - Saving model with best Classification-F1: 0.8954739041266555 -> 0.897624441761064 on epoch=121, global_step=1700
05/25/2022 11:34:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/25/2022 11:34:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/25/2022 11:34:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/25/2022 11:34:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
05/25/2022 11:34:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/25/2022 11:34:36 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7815912302950958 on epoch=124
05/25/2022 11:34:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
05/25/2022 11:34:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
05/25/2022 11:34:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/25/2022 11:34:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 11:34:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
05/25/2022 11:34:58 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7404470449880383 on epoch=128
05/25/2022 11:35:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
05/25/2022 11:35:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/25/2022 11:35:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
05/25/2022 11:35:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
05/25/2022 11:35:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
05/25/2022 11:35:21 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8260917784041517 on epoch=132
05/25/2022 11:35:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
05/25/2022 11:35:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/25/2022 11:35:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/25/2022 11:35:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/25/2022 11:35:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=135
05/25/2022 11:35:44 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9062396258601192 on epoch=135
05/25/2022 11:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.897624441761064 -> 0.9062396258601192 on epoch=135, global_step=1900
05/25/2022 11:35:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/25/2022 11:35:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
05/25/2022 11:35:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/25/2022 11:35:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/25/2022 11:35:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/25/2022 11:36:08 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9732751751727083 on epoch=139
05/25/2022 11:36:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9062396258601192 -> 0.9732751751727083 on epoch=139, global_step=1950
05/25/2022 11:36:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/25/2022 11:36:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/25/2022 11:36:17 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
05/25/2022 11:36:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/25/2022 11:36:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/25/2022 11:36:31 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9732751751727083 on epoch=142
05/25/2022 11:36:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
05/25/2022 11:36:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
05/25/2022 11:36:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/25/2022 11:36:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/25/2022 11:36:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/25/2022 11:36:54 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9062396258601192 on epoch=146
05/25/2022 11:36:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=147
05/25/2022 11:37:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
05/25/2022 11:37:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=148
05/25/2022 11:37:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
05/25/2022 11:37:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
05/25/2022 11:37:18 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8214117774838838 on epoch=149
05/25/2022 11:37:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
05/25/2022 11:37:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/25/2022 11:37:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
05/25/2022 11:37:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
05/25/2022 11:37:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/25/2022 11:37:41 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8876784714102867 on epoch=153
05/25/2022 11:37:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
05/25/2022 11:37:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
05/25/2022 11:37:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/25/2022 11:37:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/25/2022 11:37:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
05/25/2022 11:38:04 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8931520682564326 on epoch=157
05/25/2022 11:38:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/25/2022 11:38:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/25/2022 11:38:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
05/25/2022 11:38:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/25/2022 11:38:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/25/2022 11:38:27 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8409835943680739 on epoch=160
05/25/2022 11:38:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
05/25/2022 11:38:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/25/2022 11:38:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/25/2022 11:38:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/25/2022 11:38:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/25/2022 11:38:50 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8289417877312854 on epoch=164
05/25/2022 11:38:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/25/2022 11:38:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
05/25/2022 11:38:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 11:39:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/25/2022 11:39:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 11:39:13 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8988663539707182 on epoch=167
05/25/2022 11:39:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/25/2022 11:39:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
05/25/2022 11:39:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/25/2022 11:39:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/25/2022 11:39:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 11:39:36 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8987475185577654 on epoch=171
05/25/2022 11:39:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/25/2022 11:39:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 11:39:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/25/2022 11:39:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
05/25/2022 11:39:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
05/25/2022 11:39:59 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9062396258601192 on epoch=174
05/25/2022 11:40:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
05/25/2022 11:40:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 11:40:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 11:40:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 11:40:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/25/2022 11:40:22 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9061207904471663 on epoch=178
05/25/2022 11:40:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/25/2022 11:40:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
05/25/2022 11:40:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/25/2022 11:40:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/25/2022 11:40:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/25/2022 11:40:45 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9061207904471663 on epoch=182
05/25/2022 11:40:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/25/2022 11:40:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/25/2022 11:40:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=184
05/25/2022 11:40:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/25/2022 11:41:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=185
05/25/2022 11:41:09 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.9061338240085868 on epoch=185
05/25/2022 11:41:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/25/2022 11:41:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/25/2022 11:41:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/25/2022 11:41:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/25/2022 11:41:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
05/25/2022 11:41:32 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9013878099188575 on epoch=189
05/25/2022 11:41:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 11:41:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/25/2022 11:41:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 11:41:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/25/2022 11:41:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/25/2022 11:41:55 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8996446437812662 on epoch=192
05/25/2022 11:41:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/25/2022 11:42:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 11:42:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 11:42:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
05/25/2022 11:42:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/25/2022 11:42:18 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9102915301017768 on epoch=196
05/25/2022 11:42:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/25/2022 11:42:24 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/25/2022 11:42:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.13 on epoch=198
05/25/2022 11:42:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/25/2022 11:42:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
05/25/2022 11:42:41 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.9102915301017768 on epoch=199
05/25/2022 11:42:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 11:42:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/25/2022 11:42:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/25/2022 11:42:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 11:42:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/25/2022 11:43:04 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9055455160120475 on epoch=203
05/25/2022 11:43:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/25/2022 11:43:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 11:43:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/25/2022 11:43:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 11:43:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/25/2022 11:43:27 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9055455160120475 on epoch=207
05/25/2022 11:43:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/25/2022 11:43:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/25/2022 11:43:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/25/2022 11:43:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/25/2022 11:43:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/25/2022 11:43:49 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.89705745235157 on epoch=210
05/25/2022 11:43:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/25/2022 11:43:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 11:43:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/25/2022 11:44:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/25/2022 11:44:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/25/2022 11:44:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:44:06 - INFO - __main__ - Printing 3 examples
05/25/2022 11:44:06 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 11:44:06 - INFO - __main__ - ['Animal']
05/25/2022 11:44:06 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 11:44:06 - INFO - __main__ - ['Animal']
05/25/2022 11:44:06 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 11:44:06 - INFO - __main__ - ['Animal']
05/25/2022 11:44:06 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:44:06 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:44:06 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 11:44:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:44:06 - INFO - __main__ - Printing 3 examples
05/25/2022 11:44:06 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 11:44:06 - INFO - __main__ - ['Animal']
05/25/2022 11:44:06 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 11:44:06 - INFO - __main__ - ['Animal']
05/25/2022 11:44:06 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 11:44:06 - INFO - __main__ - ['Animal']
05/25/2022 11:44:06 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:44:07 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:44:07 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 11:44:12 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9776348295916607 on epoch=214
05/25/2022 11:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9732751751727083 -> 0.9776348295916607 on epoch=214, global_step=3000
05/25/2022 11:44:12 - INFO - __main__ - save last model!
05/25/2022 11:44:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 11:44:13 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 11:44:13 - INFO - __main__ - Printing 3 examples
05/25/2022 11:44:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 11:44:13 - INFO - __main__ - ['Animal']
05/25/2022 11:44:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 11:44:13 - INFO - __main__ - ['Animal']
05/25/2022 11:44:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 11:44:13 - INFO - __main__ - ['Village']
05/25/2022 11:44:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:44:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:44:18 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 11:44:22 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 11:44:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 11:44:23 - INFO - __main__ - Starting training!
05/25/2022 11:46:52 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/25/2022 11:46:52 - INFO - __main__ - Classification-F1 on test data: 0.7165
05/25/2022 11:46:52 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9776348295916607, test_performance=0.7164586132693597
05/25/2022 11:46:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/25/2022 11:46:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:46:53 - INFO - __main__ - Printing 3 examples
05/25/2022 11:46:53 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 11:46:53 - INFO - __main__ - ['Animal']
05/25/2022 11:46:53 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 11:46:53 - INFO - __main__ - ['Animal']
05/25/2022 11:46:53 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 11:46:53 - INFO - __main__ - ['Animal']
05/25/2022 11:46:53 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:46:53 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:46:54 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 11:46:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 11:46:54 - INFO - __main__ - Printing 3 examples
05/25/2022 11:46:54 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 11:46:54 - INFO - __main__ - ['Animal']
05/25/2022 11:46:54 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 11:46:54 - INFO - __main__ - ['Animal']
05/25/2022 11:46:54 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 11:46:54 - INFO - __main__ - ['Animal']
05/25/2022 11:46:54 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:46:54 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:46:54 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 11:47:09 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 11:47:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 11:47:10 - INFO - __main__ - Starting training!
05/25/2022 11:47:14 - INFO - __main__ - Step 10 Global step 10 Train loss 5.07 on epoch=0
05/25/2022 11:47:17 - INFO - __main__ - Step 20 Global step 20 Train loss 3.39 on epoch=1
05/25/2022 11:47:20 - INFO - __main__ - Step 30 Global step 30 Train loss 2.46 on epoch=2
05/25/2022 11:47:23 - INFO - __main__ - Step 40 Global step 40 Train loss 1.76 on epoch=2
05/25/2022 11:47:26 - INFO - __main__ - Step 50 Global step 50 Train loss 1.34 on epoch=3
05/25/2022 11:47:32 - INFO - __main__ - Global step 50 Train loss 2.80 Classification-F1 0.29899667282081427 on epoch=3
05/25/2022 11:47:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.29899667282081427 on epoch=3, global_step=50
05/25/2022 11:47:35 - INFO - __main__ - Step 60 Global step 60 Train loss 1.09 on epoch=4
05/25/2022 11:47:38 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=4
05/25/2022 11:47:41 - INFO - __main__ - Step 80 Global step 80 Train loss 0.81 on epoch=5
05/25/2022 11:47:44 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=6
05/25/2022 11:47:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.69 on epoch=7
05/25/2022 11:47:55 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.41224594666201897 on epoch=7
05/25/2022 11:47:55 - INFO - __main__ - Saving model with best Classification-F1: 0.29899667282081427 -> 0.41224594666201897 on epoch=7, global_step=100
05/25/2022 11:47:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.64 on epoch=7
05/25/2022 11:48:01 - INFO - __main__ - Step 120 Global step 120 Train loss 0.54 on epoch=8
05/25/2022 11:48:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.52 on epoch=9
05/25/2022 11:48:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.49 on epoch=9
05/25/2022 11:48:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=10
05/25/2022 11:48:18 - INFO - __main__ - Global step 150 Train loss 0.55 Classification-F1 0.6985400642845915 on epoch=10
05/25/2022 11:48:18 - INFO - __main__ - Saving model with best Classification-F1: 0.41224594666201897 -> 0.6985400642845915 on epoch=10, global_step=150
05/25/2022 11:48:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.38 on epoch=11
05/25/2022 11:48:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=12
05/25/2022 11:48:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.40 on epoch=12
05/25/2022 11:48:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=13
05/25/2022 11:48:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.39 on epoch=14
05/25/2022 11:48:41 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.5831097061960302 on epoch=14
05/25/2022 11:48:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.34 on epoch=14
05/25/2022 11:48:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=15
05/25/2022 11:48:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=16
05/25/2022 11:48:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=17
05/25/2022 11:48:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=17
05/25/2022 11:49:05 - INFO - __main__ - Global step 250 Train loss 0.31 Classification-F1 0.7700511744792973 on epoch=17
05/25/2022 11:49:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6985400642845915 -> 0.7700511744792973 on epoch=17, global_step=250
05/25/2022 11:49:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=18
05/25/2022 11:49:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=19
05/25/2022 11:49:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=19
05/25/2022 11:49:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=20
05/25/2022 11:49:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=21
05/25/2022 11:49:28 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.5722274056536991 on epoch=21
05/25/2022 11:49:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=22
05/25/2022 11:49:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=22
05/25/2022 11:49:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.13 on epoch=23
05/25/2022 11:49:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=24
05/25/2022 11:49:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.13 on epoch=24
05/25/2022 11:49:51 - INFO - __main__ - Global step 350 Train loss 0.18 Classification-F1 0.798475777436998 on epoch=24
05/25/2022 11:49:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7700511744792973 -> 0.798475777436998 on epoch=24, global_step=350
05/25/2022 11:49:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=25
05/25/2022 11:49:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.12 on epoch=26
05/25/2022 11:50:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.12 on epoch=27
05/25/2022 11:50:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=27
05/25/2022 11:50:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=28
05/25/2022 11:50:15 - INFO - __main__ - Global step 400 Train loss 0.12 Classification-F1 0.8938237284949317 on epoch=28
05/25/2022 11:50:15 - INFO - __main__ - Saving model with best Classification-F1: 0.798475777436998 -> 0.8938237284949317 on epoch=28, global_step=400
05/25/2022 11:50:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=29
05/25/2022 11:50:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=29
05/25/2022 11:50:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=30
05/25/2022 11:50:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=31
05/25/2022 11:50:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=32
05/25/2022 11:50:38 - INFO - __main__ - Global step 450 Train loss 0.12 Classification-F1 0.5944490810137399 on epoch=32
05/25/2022 11:50:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=32
05/25/2022 11:50:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=33
05/25/2022 11:50:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=34
05/25/2022 11:50:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=34
05/25/2022 11:50:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=35
05/25/2022 11:51:01 - INFO - __main__ - Global step 500 Train loss 0.09 Classification-F1 0.5336088993319493 on epoch=35
05/25/2022 11:51:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=36
05/25/2022 11:51:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=37
05/25/2022 11:51:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
05/25/2022 11:51:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
05/25/2022 11:51:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=39
05/25/2022 11:51:24 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.6844296442530544 on epoch=39
05/25/2022 11:51:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=39
05/25/2022 11:51:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
05/25/2022 11:51:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
05/25/2022 11:51:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
05/25/2022 11:51:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=42
05/25/2022 11:51:48 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6524584776269392 on epoch=42
05/25/2022 11:51:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=43
05/25/2022 11:51:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=44
05/25/2022 11:51:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=44
05/25/2022 11:52:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=45
05/25/2022 11:52:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=46
05/25/2022 11:52:11 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.7889774069317663 on epoch=46
05/25/2022 11:52:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=47
05/25/2022 11:52:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=47
05/25/2022 11:52:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=48
05/25/2022 11:52:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=49
05/25/2022 11:52:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
05/25/2022 11:52:35 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.8156697606740138 on epoch=49
05/25/2022 11:52:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=50
05/25/2022 11:52:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
05/25/2022 11:52:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
05/25/2022 11:52:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
05/25/2022 11:52:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
05/25/2022 11:52:58 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.8287149115511308 on epoch=53
05/25/2022 11:53:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=54
05/25/2022 11:53:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=54
05/25/2022 11:53:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
05/25/2022 11:53:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=56
05/25/2022 11:53:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=57
05/25/2022 11:53:21 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.8330925246337286 on epoch=57
05/25/2022 11:53:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=57
05/25/2022 11:53:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
05/25/2022 11:53:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=59
05/25/2022 11:53:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=59
05/25/2022 11:53:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=60
05/25/2022 11:53:43 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.9058511586452762 on epoch=60
05/25/2022 11:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8938237284949317 -> 0.9058511586452762 on epoch=60, global_step=850
05/25/2022 11:53:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
05/25/2022 11:53:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=62
05/25/2022 11:53:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
05/25/2022 11:53:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
05/25/2022 11:53:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
05/25/2022 11:54:06 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.8888665661768127 on epoch=64
05/25/2022 11:54:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=64
05/25/2022 11:54:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
05/25/2022 11:54:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
05/25/2022 11:54:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=67
05/25/2022 11:54:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
05/25/2022 11:54:28 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8393845954804209 on epoch=67
05/25/2022 11:54:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=68
05/25/2022 11:54:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
05/25/2022 11:54:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
05/25/2022 11:54:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
05/25/2022 11:54:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=71
05/25/2022 11:54:51 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.8189027563004674 on epoch=71
05/25/2022 11:54:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
05/25/2022 11:54:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=72
05/25/2022 11:55:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
05/25/2022 11:55:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=74
05/25/2022 11:55:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
05/25/2022 11:55:13 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.9684182397299096 on epoch=74
05/25/2022 11:55:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9058511586452762 -> 0.9684182397299096 on epoch=74, global_step=1050
05/25/2022 11:55:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
05/25/2022 11:55:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=76
05/25/2022 11:55:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
05/25/2022 11:55:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
05/25/2022 11:55:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
05/25/2022 11:55:36 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8366304192131399 on epoch=78
05/25/2022 11:55:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
05/25/2022 11:55:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
05/25/2022 11:55:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
05/25/2022 11:55:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
05/25/2022 11:55:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=82
05/25/2022 11:55:57 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.8067871081717144 on epoch=82
05/25/2022 11:56:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/25/2022 11:56:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
05/25/2022 11:56:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
05/25/2022 11:56:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
05/25/2022 11:56:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=85
05/25/2022 11:56:19 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7854323722850749 on epoch=85
05/25/2022 11:56:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
05/25/2022 11:56:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
05/25/2022 11:56:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/25/2022 11:56:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=88
05/25/2022 11:56:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
05/25/2022 11:56:41 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.8847840794726222 on epoch=89
05/25/2022 11:56:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
05/25/2022 11:56:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/25/2022 11:56:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
05/25/2022 11:56:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
05/25/2022 11:56:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/25/2022 11:57:04 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8895107888925095 on epoch=92
05/25/2022 11:57:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
05/25/2022 11:57:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
05/25/2022 11:57:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
05/25/2022 11:57:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 11:57:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
05/25/2022 11:57:26 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7860917108392197 on epoch=96
05/25/2022 11:57:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=97
05/25/2022 11:57:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
05/25/2022 11:57:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
05/25/2022 11:57:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=99
05/25/2022 11:57:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
05/25/2022 11:57:47 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.9685622489464993 on epoch=99
05/25/2022 11:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9684182397299096 -> 0.9685622489464993 on epoch=99, global_step=1400
05/25/2022 11:57:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
05/25/2022 11:57:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/25/2022 11:57:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=102
05/25/2022 11:58:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
05/25/2022 11:58:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/25/2022 11:58:09 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.9019541237804993 on epoch=103
05/25/2022 11:58:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/25/2022 11:58:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
05/25/2022 11:58:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
05/25/2022 11:58:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/25/2022 11:58:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
05/25/2022 11:58:31 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.8976660820731029 on epoch=107
05/25/2022 11:58:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
05/25/2022 11:58:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=108
05/25/2022 11:58:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
05/25/2022 11:58:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=109
05/25/2022 11:58:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=110
05/25/2022 11:58:54 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.9598547190137052 on epoch=110
05/25/2022 11:58:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/25/2022 11:59:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/25/2022 11:59:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/25/2022 11:59:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 11:59:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=114
05/25/2022 11:59:16 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.964076913756705 on epoch=114
05/25/2022 11:59:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
05/25/2022 11:59:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/25/2022 11:59:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 11:59:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/25/2022 11:59:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/25/2022 11:59:39 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.9598380334538508 on epoch=117
05/25/2022 11:59:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/25/2022 11:59:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/25/2022 11:59:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 11:59:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/25/2022 11:59:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/25/2022 12:00:01 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8976440879382056 on epoch=121
05/25/2022 12:00:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 12:00:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/25/2022 12:00:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=123
05/25/2022 12:00:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/25/2022 12:00:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/25/2022 12:00:23 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.9596416352464738 on epoch=124
05/25/2022 12:00:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/25/2022 12:00:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=126
05/25/2022 12:00:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
05/25/2022 12:00:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/25/2022 12:00:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=128
05/25/2022 12:00:45 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8262026515151515 on epoch=128
05/25/2022 12:00:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
05/25/2022 12:00:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/25/2022 12:00:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 12:00:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=131
05/25/2022 12:01:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=132
05/25/2022 12:01:07 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9595926567107781 on epoch=132
05/25/2022 12:01:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/25/2022 12:01:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 12:01:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/25/2022 12:01:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/25/2022 12:01:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
05/25/2022 12:01:29 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8317673510525658 on epoch=135
05/25/2022 12:01:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
05/25/2022 12:01:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 12:01:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/25/2022 12:01:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/25/2022 12:01:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/25/2022 12:01:52 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.959698388152915 on epoch=139
05/25/2022 12:01:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
05/25/2022 12:01:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 12:02:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
05/25/2022 12:02:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/25/2022 12:02:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 12:02:13 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.708300909455034 on epoch=142
05/25/2022 12:02:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/25/2022 12:02:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/25/2022 12:02:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/25/2022 12:02:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/25/2022 12:02:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/25/2022 12:02:35 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8764585314537875 on epoch=146
05/25/2022 12:02:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 12:02:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/25/2022 12:02:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/25/2022 12:02:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 12:02:51 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
05/25/2022 12:02:57 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8976515151515152 on epoch=149
05/25/2022 12:03:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
05/25/2022 12:03:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 12:03:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/25/2022 12:03:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 12:03:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
05/25/2022 12:03:19 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8978674998836288 on epoch=153
05/25/2022 12:03:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/25/2022 12:03:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 12:03:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
05/25/2022 12:03:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/25/2022 12:03:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 12:03:40 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8978866463496442 on epoch=157
05/25/2022 12:03:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 12:03:46 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 12:03:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
05/25/2022 12:03:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 12:03:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
05/25/2022 12:04:02 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9019656239817528 on epoch=160
05/25/2022 12:04:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
05/25/2022 12:04:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/25/2022 12:04:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 12:04:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
05/25/2022 12:04:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 12:04:24 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8908998659631716 on epoch=164
05/25/2022 12:04:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/25/2022 12:04:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 12:04:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 12:04:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/25/2022 12:04:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 12:04:46 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8316719802429516 on epoch=167
05/25/2022 12:04:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/25/2022 12:04:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 12:04:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/25/2022 12:04:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/25/2022 12:05:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
05/25/2022 12:05:08 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8977948843271423 on epoch=171
05/25/2022 12:05:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/25/2022 12:05:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/25/2022 12:05:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/25/2022 12:05:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
05/25/2022 12:05:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
05/25/2022 12:05:29 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8617612662388259 on epoch=174
05/25/2022 12:05:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/25/2022 12:05:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 12:05:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/25/2022 12:05:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/25/2022 12:05:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
05/25/2022 12:05:51 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.749965668834742 on epoch=178
05/25/2022 12:05:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
05/25/2022 12:05:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 12:06:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 12:06:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 12:06:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/25/2022 12:06:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8151421712379967 on epoch=182
05/25/2022 12:06:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/25/2022 12:06:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 12:06:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/25/2022 12:06:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 12:06:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 12:06:35 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7898273071995509 on epoch=185
05/25/2022 12:06:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
05/25/2022 12:06:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 12:06:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/25/2022 12:06:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 12:06:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
05/25/2022 12:06:58 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8049245697179166 on epoch=189
05/25/2022 12:07:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 12:07:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 12:07:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/25/2022 12:07:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/25/2022 12:07:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
05/25/2022 12:07:19 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6965469693473719 on epoch=192
05/25/2022 12:07:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/25/2022 12:07:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 12:07:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 12:07:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/25/2022 12:07:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 12:07:41 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8396505376344087 on epoch=196
05/25/2022 12:07:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 12:07:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
05/25/2022 12:07:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 12:07:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 12:07:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 12:08:04 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7987548486525597 on epoch=199
05/25/2022 12:08:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 12:08:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 12:08:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/25/2022 12:08:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 12:08:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 12:08:26 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7888967803030302 on epoch=203
05/25/2022 12:08:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 12:08:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 12:08:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 12:08:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 12:08:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
05/25/2022 12:08:48 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7851784161245143 on epoch=207
05/25/2022 12:08:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 12:08:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 12:08:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 12:09:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 12:09:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 12:09:10 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7963625672043011 on epoch=210
05/25/2022 12:09:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 12:09:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 12:09:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/25/2022 12:09:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 12:09:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.11 on epoch=214
05/25/2022 12:09:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:09:27 - INFO - __main__ - Printing 3 examples
05/25/2022 12:09:27 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 12:09:27 - INFO - __main__ - ['Animal']
05/25/2022 12:09:27 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 12:09:27 - INFO - __main__ - ['Animal']
05/25/2022 12:09:27 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 12:09:27 - INFO - __main__ - ['Animal']
05/25/2022 12:09:27 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:09:27 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:09:27 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 12:09:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:09:27 - INFO - __main__ - Printing 3 examples
05/25/2022 12:09:27 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 12:09:27 - INFO - __main__ - ['Animal']
05/25/2022 12:09:27 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 12:09:27 - INFO - __main__ - ['Animal']
05/25/2022 12:09:27 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 12:09:27 - INFO - __main__ - ['Animal']
05/25/2022 12:09:27 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:09:27 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:09:27 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 12:09:32 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9642883546380426 on epoch=214
05/25/2022 12:09:32 - INFO - __main__ - save last model!
05/25/2022 12:09:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 12:09:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 12:09:32 - INFO - __main__ - Printing 3 examples
05/25/2022 12:09:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 12:09:32 - INFO - __main__ - ['Animal']
05/25/2022 12:09:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 12:09:32 - INFO - __main__ - ['Animal']
05/25/2022 12:09:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 12:09:32 - INFO - __main__ - ['Village']
05/25/2022 12:09:32 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:09:34 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:09:37 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 12:09:43 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:09:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 12:09:43 - INFO - __main__ - Starting training!
05/25/2022 12:12:01 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/25/2022 12:12:01 - INFO - __main__ - Classification-F1 on test data: 0.7593
05/25/2022 12:12:02 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9685622489464993, test_performance=0.7592764907008628
05/25/2022 12:12:02 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/25/2022 12:12:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:12:03 - INFO - __main__ - Printing 3 examples
05/25/2022 12:12:03 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 12:12:03 - INFO - __main__ - ['Animal']
05/25/2022 12:12:03 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 12:12:03 - INFO - __main__ - ['Animal']
05/25/2022 12:12:03 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 12:12:03 - INFO - __main__ - ['Animal']
05/25/2022 12:12:03 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:12:03 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:12:03 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 12:12:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:12:03 - INFO - __main__ - Printing 3 examples
05/25/2022 12:12:03 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 12:12:03 - INFO - __main__ - ['Animal']
05/25/2022 12:12:03 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 12:12:03 - INFO - __main__ - ['Animal']
05/25/2022 12:12:03 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 12:12:03 - INFO - __main__ - ['Animal']
05/25/2022 12:12:03 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:12:03 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:12:03 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 12:12:19 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:12:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 12:12:19 - INFO - __main__ - Starting training!
05/25/2022 12:12:23 - INFO - __main__ - Step 10 Global step 10 Train loss 5.00 on epoch=0
05/25/2022 12:12:26 - INFO - __main__ - Step 20 Global step 20 Train loss 3.65 on epoch=1
05/25/2022 12:12:29 - INFO - __main__ - Step 30 Global step 30 Train loss 2.75 on epoch=2
05/25/2022 12:12:32 - INFO - __main__ - Step 40 Global step 40 Train loss 1.93 on epoch=2
05/25/2022 12:12:35 - INFO - __main__ - Step 50 Global step 50 Train loss 1.56 on epoch=3
05/25/2022 12:12:41 - INFO - __main__ - Global step 50 Train loss 2.98 Classification-F1 0.2774428580695651 on epoch=3
05/25/2022 12:12:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2774428580695651 on epoch=3, global_step=50
05/25/2022 12:12:44 - INFO - __main__ - Step 60 Global step 60 Train loss 1.32 on epoch=4
05/25/2022 12:12:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=4
05/25/2022 12:12:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.88 on epoch=5
05/25/2022 12:12:53 - INFO - __main__ - Step 90 Global step 90 Train loss 0.79 on epoch=6
05/25/2022 12:12:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.76 on epoch=7
05/25/2022 12:13:03 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.49269378625124577 on epoch=7
05/25/2022 12:13:03 - INFO - __main__ - Saving model with best Classification-F1: 0.2774428580695651 -> 0.49269378625124577 on epoch=7, global_step=100
05/25/2022 12:13:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.74 on epoch=7
05/25/2022 12:13:09 - INFO - __main__ - Step 120 Global step 120 Train loss 0.61 on epoch=8
05/25/2022 12:13:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.54 on epoch=9
05/25/2022 12:13:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=9
05/25/2022 12:13:18 - INFO - __main__ - Step 150 Global step 150 Train loss 0.50 on epoch=10
05/25/2022 12:13:26 - INFO - __main__ - Global step 150 Train loss 0.60 Classification-F1 0.5153131271382965 on epoch=10
05/25/2022 12:13:26 - INFO - __main__ - Saving model with best Classification-F1: 0.49269378625124577 -> 0.5153131271382965 on epoch=10, global_step=150
05/25/2022 12:13:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.49 on epoch=11
05/25/2022 12:13:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=12
05/25/2022 12:13:35 - INFO - __main__ - Step 180 Global step 180 Train loss 0.41 on epoch=12
05/25/2022 12:13:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=13
05/25/2022 12:13:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=14
05/25/2022 12:13:48 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.7019645766308832 on epoch=14
05/25/2022 12:13:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5153131271382965 -> 0.7019645766308832 on epoch=14, global_step=200
05/25/2022 12:13:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=14
05/25/2022 12:13:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=15
05/25/2022 12:13:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.44 on epoch=16
05/25/2022 12:14:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=17
05/25/2022 12:14:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=17
05/25/2022 12:14:11 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.7010596071356656 on epoch=17
05/25/2022 12:14:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=18
05/25/2022 12:14:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=19
05/25/2022 12:14:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=19
05/25/2022 12:14:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=20
05/25/2022 12:14:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=21
05/25/2022 12:14:33 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.7260321620830883 on epoch=21
05/25/2022 12:14:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7019645766308832 -> 0.7260321620830883 on epoch=21, global_step=300
05/25/2022 12:14:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=22
05/25/2022 12:14:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
05/25/2022 12:14:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=23
05/25/2022 12:14:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=24
05/25/2022 12:14:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=24
05/25/2022 12:14:56 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.7644415070432262 on epoch=24
05/25/2022 12:14:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7260321620830883 -> 0.7644415070432262 on epoch=24, global_step=350
05/25/2022 12:14:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=25
05/25/2022 12:15:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=26
05/25/2022 12:15:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
05/25/2022 12:15:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=27
05/25/2022 12:15:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=28
05/25/2022 12:15:19 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.8730647754303668 on epoch=28
05/25/2022 12:15:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7644415070432262 -> 0.8730647754303668 on epoch=28, global_step=400
05/25/2022 12:15:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=29
05/25/2022 12:15:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=29
05/25/2022 12:15:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
05/25/2022 12:15:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=31
05/25/2022 12:15:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
05/25/2022 12:15:42 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.9470991039082569 on epoch=32
05/25/2022 12:15:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8730647754303668 -> 0.9470991039082569 on epoch=32, global_step=450
05/25/2022 12:15:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
05/25/2022 12:15:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=33
05/25/2022 12:15:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
05/25/2022 12:15:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
05/25/2022 12:15:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
05/25/2022 12:16:05 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.9640183346065699 on epoch=35
05/25/2022 12:16:05 - INFO - __main__ - Saving model with best Classification-F1: 0.9470991039082569 -> 0.9640183346065699 on epoch=35, global_step=500
05/25/2022 12:16:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
05/25/2022 12:16:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
05/25/2022 12:16:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
05/25/2022 12:16:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=38
05/25/2022 12:16:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
05/25/2022 12:16:28 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6838358149276872 on epoch=39
05/25/2022 12:16:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=39
05/25/2022 12:16:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
05/25/2022 12:16:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
05/25/2022 12:16:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
05/25/2022 12:16:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
05/25/2022 12:16:51 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.7742155425219941 on epoch=42
05/25/2022 12:16:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
05/25/2022 12:16:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=44
05/25/2022 12:17:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
05/25/2022 12:17:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=45
05/25/2022 12:17:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
05/25/2022 12:17:14 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.7415736310473153 on epoch=46
05/25/2022 12:17:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=47
05/25/2022 12:17:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
05/25/2022 12:17:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
05/25/2022 12:17:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
05/25/2022 12:17:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
05/25/2022 12:17:36 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6417557242268217 on epoch=49
05/25/2022 12:17:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
05/25/2022 12:17:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
05/25/2022 12:17:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
05/25/2022 12:17:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
05/25/2022 12:17:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
05/25/2022 12:17:59 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.7321384257802944 on epoch=53
05/25/2022 12:18:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=54
05/25/2022 12:18:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
05/25/2022 12:18:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=55
05/25/2022 12:18:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=56
05/25/2022 12:18:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
05/25/2022 12:18:22 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.733751970848745 on epoch=57
05/25/2022 12:18:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
05/25/2022 12:18:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
05/25/2022 12:18:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
05/25/2022 12:18:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
05/25/2022 12:18:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
05/25/2022 12:18:45 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6891339880689976 on epoch=60
05/25/2022 12:18:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
05/25/2022 12:18:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
05/25/2022 12:18:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
05/25/2022 12:18:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
05/25/2022 12:19:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
05/25/2022 12:19:07 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7343873256373256 on epoch=64
05/25/2022 12:19:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
05/25/2022 12:19:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
05/25/2022 12:19:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
05/25/2022 12:19:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
05/25/2022 12:19:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
05/25/2022 12:19:30 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6537830113781377 on epoch=67
05/25/2022 12:19:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
05/25/2022 12:19:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
05/25/2022 12:19:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
05/25/2022 12:19:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=70
05/25/2022 12:19:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/25/2022 12:19:52 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7976815913722934 on epoch=71
05/25/2022 12:19:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
05/25/2022 12:19:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
05/25/2022 12:20:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
05/25/2022 12:20:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=74
05/25/2022 12:20:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
05/25/2022 12:20:15 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7684996621695444 on epoch=74
05/25/2022 12:20:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
05/25/2022 12:20:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
05/25/2022 12:20:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
05/25/2022 12:20:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
05/25/2022 12:20:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
05/25/2022 12:20:37 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.9776348295916607 on epoch=78
05/25/2022 12:20:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9640183346065699 -> 0.9776348295916607 on epoch=78, global_step=1100
05/25/2022 12:20:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
05/25/2022 12:20:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/25/2022 12:20:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
05/25/2022 12:20:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
05/25/2022 12:20:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
05/25/2022 12:21:00 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7177070947759785 on epoch=82
05/25/2022 12:21:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
05/25/2022 12:21:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
05/25/2022 12:21:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/25/2022 12:21:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/25/2022 12:21:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
05/25/2022 12:21:23 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7380722548061258 on epoch=85
05/25/2022 12:21:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
05/25/2022 12:21:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
05/25/2022 12:21:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
05/25/2022 12:21:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/25/2022 12:21:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
05/25/2022 12:21:45 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.754308401965521 on epoch=89
05/25/2022 12:21:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
05/25/2022 12:21:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
05/25/2022 12:21:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
05/25/2022 12:21:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
05/25/2022 12:22:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/25/2022 12:22:07 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8047395913721254 on epoch=92
05/25/2022 12:22:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
05/25/2022 12:22:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/25/2022 12:22:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
05/25/2022 12:22:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
05/25/2022 12:22:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
05/25/2022 12:22:29 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9053134515342525 on epoch=96
05/25/2022 12:22:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
05/25/2022 12:22:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/25/2022 12:22:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
05/25/2022 12:22:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
05/25/2022 12:22:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/25/2022 12:22:52 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8285487554625957 on epoch=99
05/25/2022 12:22:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
05/25/2022 12:22:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
05/25/2022 12:23:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 12:23:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
05/25/2022 12:23:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/25/2022 12:23:14 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8191253776628591 on epoch=103
05/25/2022 12:23:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/25/2022 12:23:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/25/2022 12:23:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
05/25/2022 12:23:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/25/2022 12:23:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
05/25/2022 12:23:36 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9060075613823242 on epoch=107
05/25/2022 12:23:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/25/2022 12:23:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
05/25/2022 12:23:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/25/2022 12:23:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
05/25/2022 12:23:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
05/25/2022 12:23:58 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9818181818181818 on epoch=110
05/25/2022 12:23:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9776348295916607 -> 0.9818181818181818 on epoch=110, global_step=1550
05/25/2022 12:24:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/25/2022 12:24:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/25/2022 12:24:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
05/25/2022 12:24:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 12:24:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
05/25/2022 12:24:20 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.845199384739233 on epoch=114
05/25/2022 12:24:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
05/25/2022 12:24:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/25/2022 12:24:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 12:24:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/25/2022 12:24:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/25/2022 12:24:42 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9058887259693712 on epoch=117
05/25/2022 12:24:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/25/2022 12:24:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
05/25/2022 12:24:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 12:24:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/25/2022 12:24:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/25/2022 12:25:04 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8368667469326188 on epoch=121
05/25/2022 12:25:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
05/25/2022 12:25:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/25/2022 12:25:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
05/25/2022 12:25:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
05/25/2022 12:25:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/25/2022 12:25:27 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8126998236978076 on epoch=124
05/25/2022 12:25:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/25/2022 12:25:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=126
05/25/2022 12:25:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/25/2022 12:25:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 12:25:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/25/2022 12:25:49 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7999982929388765 on epoch=128
05/25/2022 12:25:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/25/2022 12:25:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/25/2022 12:25:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 12:26:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/25/2022 12:26:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/25/2022 12:26:11 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9016934525520864 on epoch=132
05/25/2022 12:26:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/25/2022 12:26:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 12:26:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 12:26:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 12:26:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 12:26:33 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8772893683377555 on epoch=135
05/25/2022 12:26:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/25/2022 12:26:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 12:26:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/25/2022 12:26:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/25/2022 12:26:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/25/2022 12:26:55 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8915269179247673 on epoch=139
05/25/2022 12:26:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/25/2022 12:27:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 12:27:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
05/25/2022 12:27:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/25/2022 12:27:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
05/25/2022 12:27:16 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8219071556966533 on epoch=142
05/25/2022 12:27:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
05/25/2022 12:27:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
05/25/2022 12:27:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/25/2022 12:27:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/25/2022 12:27:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 12:27:38 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8886027439775067 on epoch=146
05/25/2022 12:27:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 12:27:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
05/25/2022 12:27:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/25/2022 12:27:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 12:27:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
05/25/2022 12:28:00 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.776754700831187 on epoch=149
05/25/2022 12:28:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/25/2022 12:28:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 12:28:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/25/2022 12:28:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
05/25/2022 12:28:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
05/25/2022 12:28:21 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7854236246877376 on epoch=153
05/25/2022 12:28:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
05/25/2022 12:28:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 12:28:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 12:28:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/25/2022 12:28:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 12:28:43 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.828660163662239 on epoch=157
05/25/2022 12:28:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 12:28:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/25/2022 12:28:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/25/2022 12:28:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 12:28:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/25/2022 12:29:05 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7763525680123167 on epoch=160
05/25/2022 12:29:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/25/2022 12:29:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
05/25/2022 12:29:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 12:29:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/25/2022 12:29:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 12:29:26 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7422274628227226 on epoch=164
05/25/2022 12:29:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/25/2022 12:29:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 12:29:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
05/25/2022 12:29:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
05/25/2022 12:29:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
05/25/2022 12:29:48 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7470692791248128 on epoch=167
05/25/2022 12:29:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/25/2022 12:29:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 12:29:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/25/2022 12:30:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
05/25/2022 12:30:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/25/2022 12:30:10 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6261789037326673 on epoch=171
05/25/2022 12:30:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/25/2022 12:30:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/25/2022 12:30:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 12:30:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 12:30:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
05/25/2022 12:30:32 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6723373460458186 on epoch=174
05/25/2022 12:30:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 12:30:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/25/2022 12:30:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/25/2022 12:30:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/25/2022 12:30:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/25/2022 12:30:53 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7008009410998025 on epoch=178
05/25/2022 12:30:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/25/2022 12:30:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/25/2022 12:31:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 12:31:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/25/2022 12:31:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/25/2022 12:31:15 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6157883387959289 on epoch=182
05/25/2022 12:31:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/25/2022 12:31:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 12:31:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/25/2022 12:31:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 12:31:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 12:31:36 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6132379514458243 on epoch=185
05/25/2022 12:31:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 12:31:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/25/2022 12:31:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/25/2022 12:31:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 12:31:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
05/25/2022 12:31:58 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7441748239172616 on epoch=189
05/25/2022 12:32:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 12:32:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 12:32:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
05/25/2022 12:32:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 12:32:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 12:32:20 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7885462487781036 on epoch=192
05/25/2022 12:32:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 12:32:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 12:32:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 12:32:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 12:32:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 12:32:42 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8779004028403831 on epoch=196
05/25/2022 12:32:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 12:32:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/25/2022 12:32:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 12:32:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/25/2022 12:32:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 12:33:04 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8414914323500663 on epoch=199
05/25/2022 12:33:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 12:33:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 12:33:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 12:33:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 12:33:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/25/2022 12:33:26 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7437123495249403 on epoch=203
05/25/2022 12:33:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/25/2022 12:33:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 12:33:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 12:33:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 12:33:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/25/2022 12:33:47 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7796840911627718 on epoch=207
05/25/2022 12:33:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/25/2022 12:33:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
05/25/2022 12:33:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 12:33:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 12:34:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 12:34:09 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8976857282502444 on epoch=210
05/25/2022 12:34:12 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 12:34:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 12:34:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 12:34:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/25/2022 12:34:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/25/2022 12:34:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:34:26 - INFO - __main__ - Printing 3 examples
05/25/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 12:34:26 - INFO - __main__ - ['Animal']
05/25/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 12:34:26 - INFO - __main__ - ['Animal']
05/25/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 12:34:26 - INFO - __main__ - ['Animal']
05/25/2022 12:34:26 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:34:26 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:34:26 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 12:34:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:34:26 - INFO - __main__ - Printing 3 examples
05/25/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 12:34:26 - INFO - __main__ - ['Animal']
05/25/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 12:34:26 - INFO - __main__ - ['Animal']
05/25/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 12:34:26 - INFO - __main__ - ['Animal']
05/25/2022 12:34:26 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:34:26 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:34:27 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 12:34:32 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9100594656239819 on epoch=214
05/25/2022 12:34:32 - INFO - __main__ - save last model!
05/25/2022 12:34:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 12:34:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 12:34:32 - INFO - __main__ - Printing 3 examples
05/25/2022 12:34:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 12:34:32 - INFO - __main__ - ['Animal']
05/25/2022 12:34:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 12:34:32 - INFO - __main__ - ['Animal']
05/25/2022 12:34:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 12:34:32 - INFO - __main__ - ['Village']
05/25/2022 12:34:32 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:34:34 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:34:37 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 12:34:42 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:34:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 12:34:42 - INFO - __main__ - Starting training!
05/25/2022 12:37:00 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/25/2022 12:37:00 - INFO - __main__ - Classification-F1 on test data: 0.6832
05/25/2022 12:37:00 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9818181818181818, test_performance=0.6832308891094871
05/25/2022 12:37:00 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/25/2022 12:37:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:37:01 - INFO - __main__ - Printing 3 examples
05/25/2022 12:37:01 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 12:37:01 - INFO - __main__ - ['Animal']
05/25/2022 12:37:01 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 12:37:01 - INFO - __main__ - ['Animal']
05/25/2022 12:37:01 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 12:37:01 - INFO - __main__ - ['Animal']
05/25/2022 12:37:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:37:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:37:01 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 12:37:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:37:01 - INFO - __main__ - Printing 3 examples
05/25/2022 12:37:01 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 12:37:01 - INFO - __main__ - ['Animal']
05/25/2022 12:37:01 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 12:37:01 - INFO - __main__ - ['Animal']
05/25/2022 12:37:01 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 12:37:01 - INFO - __main__ - ['Animal']
05/25/2022 12:37:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:37:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:37:02 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 12:37:20 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:37:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 12:37:21 - INFO - __main__ - Starting training!
05/25/2022 12:37:25 - INFO - __main__ - Step 10 Global step 10 Train loss 5.29 on epoch=0
05/25/2022 12:37:28 - INFO - __main__ - Step 20 Global step 20 Train loss 3.96 on epoch=1
05/25/2022 12:37:31 - INFO - __main__ - Step 30 Global step 30 Train loss 3.02 on epoch=2
05/25/2022 12:37:34 - INFO - __main__ - Step 40 Global step 40 Train loss 2.54 on epoch=2
05/25/2022 12:37:37 - INFO - __main__ - Step 50 Global step 50 Train loss 2.10 on epoch=3
05/25/2022 12:37:41 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 12:37:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 12:37:44 - INFO - __main__ - Step 60 Global step 60 Train loss 1.82 on epoch=4
05/25/2022 12:37:48 - INFO - __main__ - Step 70 Global step 70 Train loss 1.57 on epoch=4
05/25/2022 12:37:51 - INFO - __main__ - Step 80 Global step 80 Train loss 1.45 on epoch=5
05/25/2022 12:37:54 - INFO - __main__ - Step 90 Global step 90 Train loss 1.26 on epoch=6
05/25/2022 12:37:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=7
05/25/2022 12:38:04 - INFO - __main__ - Global step 100 Train loss 1.41 Classification-F1 0.3894494239616865 on epoch=7
05/25/2022 12:38:04 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.3894494239616865 on epoch=7, global_step=100
05/25/2022 12:38:07 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=7
05/25/2022 12:38:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=8
05/25/2022 12:38:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.75 on epoch=9
05/25/2022 12:38:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=9
05/25/2022 12:38:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=10
05/25/2022 12:38:27 - INFO - __main__ - Global step 150 Train loss 0.77 Classification-F1 0.4291924042188388 on epoch=10
05/25/2022 12:38:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3894494239616865 -> 0.4291924042188388 on epoch=10, global_step=150
05/25/2022 12:38:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=11
05/25/2022 12:38:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=12
05/25/2022 12:38:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=12
05/25/2022 12:38:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.69 on epoch=13
05/25/2022 12:38:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=14
05/25/2022 12:38:50 - INFO - __main__ - Global step 200 Train loss 0.60 Classification-F1 0.6171326643243398 on epoch=14
05/25/2022 12:38:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4291924042188388 -> 0.6171326643243398 on epoch=14, global_step=200
05/25/2022 12:38:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=14
05/25/2022 12:38:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=15
05/25/2022 12:38:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=16
05/25/2022 12:39:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=17
05/25/2022 12:39:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.52 on epoch=17
05/25/2022 12:39:13 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.527456994617377 on epoch=17
05/25/2022 12:39:16 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=18
05/25/2022 12:39:19 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=19
05/25/2022 12:39:22 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
05/25/2022 12:39:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=20
05/25/2022 12:39:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=21
05/25/2022 12:39:36 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.7731873421290621 on epoch=21
05/25/2022 12:39:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6171326643243398 -> 0.7731873421290621 on epoch=21, global_step=300
05/25/2022 12:39:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=22
05/25/2022 12:39:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.78 on epoch=22
05/25/2022 12:39:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=23
05/25/2022 12:39:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
05/25/2022 12:39:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=24
05/25/2022 12:39:59 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.7083711841589413 on epoch=24
05/25/2022 12:40:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
05/25/2022 12:40:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=26
05/25/2022 12:40:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=27
05/25/2022 12:40:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
05/25/2022 12:40:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=28
05/25/2022 12:40:22 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.7767633453750382 on epoch=28
05/25/2022 12:40:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7731873421290621 -> 0.7767633453750382 on epoch=28, global_step=400
05/25/2022 12:40:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=29
05/25/2022 12:40:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
05/25/2022 12:40:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=30
05/25/2022 12:40:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
05/25/2022 12:40:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=32
05/25/2022 12:40:45 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7496464646464648 on epoch=32
05/25/2022 12:40:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
05/25/2022 12:40:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=33
05/25/2022 12:40:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
05/25/2022 12:40:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=34
05/25/2022 12:41:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=35
05/25/2022 12:41:09 - INFO - __main__ - Global step 500 Train loss 0.31 Classification-F1 0.7156627607054551 on epoch=35
05/25/2022 12:41:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
05/25/2022 12:41:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
05/25/2022 12:41:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
05/25/2022 12:41:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
05/25/2022 12:41:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
05/25/2022 12:41:32 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.7639988478761792 on epoch=39
05/25/2022 12:41:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=39
05/25/2022 12:41:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=40
05/25/2022 12:41:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=41
05/25/2022 12:41:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=42
05/25/2022 12:41:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=42
05/25/2022 12:41:56 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.8107386981364092 on epoch=42
05/25/2022 12:41:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7767633453750382 -> 0.8107386981364092 on epoch=42, global_step=600
05/25/2022 12:41:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=43
05/25/2022 12:42:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=44
05/25/2022 12:42:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=44
05/25/2022 12:42:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
05/25/2022 12:42:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=46
05/25/2022 12:42:19 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7186315763151905 on epoch=46
05/25/2022 12:42:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
05/25/2022 12:42:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=47
05/25/2022 12:42:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
05/25/2022 12:42:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
05/25/2022 12:42:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
05/25/2022 12:42:42 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.6841054206158044 on epoch=49
05/25/2022 12:42:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
05/25/2022 12:42:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
05/25/2022 12:42:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=52
05/25/2022 12:42:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
05/25/2022 12:42:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
05/25/2022 12:43:06 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.8978736127882239 on epoch=53
05/25/2022 12:43:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8107386981364092 -> 0.8978736127882239 on epoch=53, global_step=750
05/25/2022 12:43:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=54
05/25/2022 12:43:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
05/25/2022 12:43:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
05/25/2022 12:43:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=56
05/25/2022 12:43:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
05/25/2022 12:43:30 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.8313727543803444 on epoch=57
05/25/2022 12:43:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
05/25/2022 12:43:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
05/25/2022 12:43:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
05/25/2022 12:43:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
05/25/2022 12:43:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
05/25/2022 12:43:53 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7876694792589904 on epoch=60
05/25/2022 12:43:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
05/25/2022 12:44:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
05/25/2022 12:44:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
05/25/2022 12:44:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
05/25/2022 12:44:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
05/25/2022 12:44:16 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.7646235286164408 on epoch=64
05/25/2022 12:44:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/25/2022 12:44:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=65
05/25/2022 12:44:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
05/25/2022 12:44:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
05/25/2022 12:44:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
05/25/2022 12:44:39 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7018105923296234 on epoch=67
05/25/2022 12:44:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
05/25/2022 12:44:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
05/25/2022 12:44:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
05/25/2022 12:44:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
05/25/2022 12:44:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
05/25/2022 12:45:02 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7814519171470559 on epoch=71
05/25/2022 12:45:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
05/25/2022 12:45:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=72
05/25/2022 12:45:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
05/25/2022 12:45:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
05/25/2022 12:45:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
05/25/2022 12:45:25 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.6924967648919512 on epoch=74
05/25/2022 12:45:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
05/25/2022 12:45:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
05/25/2022 12:45:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
05/25/2022 12:45:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
05/25/2022 12:45:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
05/25/2022 12:45:48 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.5638932241344541 on epoch=78
05/25/2022 12:45:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
05/25/2022 12:45:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/25/2022 12:45:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
05/25/2022 12:46:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
05/25/2022 12:46:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
05/25/2022 12:46:11 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6437485555832331 on epoch=82
05/25/2022 12:46:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
05/25/2022 12:46:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
05/25/2022 12:46:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
05/25/2022 12:46:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/25/2022 12:46:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
05/25/2022 12:46:32 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5539119394906871 on epoch=85
05/25/2022 12:46:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
05/25/2022 12:46:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
05/25/2022 12:46:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
05/25/2022 12:46:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/25/2022 12:46:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
05/25/2022 12:46:54 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7274406615222028 on epoch=89
05/25/2022 12:46:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=89
05/25/2022 12:47:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
05/25/2022 12:47:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
05/25/2022 12:47:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
05/25/2022 12:47:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
05/25/2022 12:47:16 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7445835234690499 on epoch=92
05/25/2022 12:47:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
05/25/2022 12:47:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
05/25/2022 12:47:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/25/2022 12:47:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
05/25/2022 12:47:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
05/25/2022 12:47:39 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7428304852588007 on epoch=96
05/25/2022 12:47:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
05/25/2022 12:47:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/25/2022 12:47:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/25/2022 12:47:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
05/25/2022 12:47:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
05/25/2022 12:48:01 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8356807490224829 on epoch=99
05/25/2022 12:48:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
05/25/2022 12:48:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
05/25/2022 12:48:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/25/2022 12:48:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/25/2022 12:48:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
05/25/2022 12:48:23 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7807039560692313 on epoch=103
05/25/2022 12:48:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/25/2022 12:48:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/25/2022 12:48:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
05/25/2022 12:48:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/25/2022 12:48:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
05/25/2022 12:48:45 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8956764780420694 on epoch=107
05/25/2022 12:48:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/25/2022 12:48:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/25/2022 12:48:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/25/2022 12:48:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
05/25/2022 12:49:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/25/2022 12:49:07 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7009714215222486 on epoch=110
05/25/2022 12:49:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/25/2022 12:49:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/25/2022 12:49:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/25/2022 12:49:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/25/2022 12:49:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
05/25/2022 12:49:29 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7881788313239926 on epoch=114
05/25/2022 12:49:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
05/25/2022 12:49:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/25/2022 12:49:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/25/2022 12:49:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
05/25/2022 12:49:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/25/2022 12:49:51 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8527368000491733 on epoch=117
05/25/2022 12:49:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/25/2022 12:49:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/25/2022 12:50:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/25/2022 12:50:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/25/2022 12:50:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/25/2022 12:50:13 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7876140499801546 on epoch=121
05/25/2022 12:50:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
05/25/2022 12:50:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/25/2022 12:50:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/25/2022 12:50:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
05/25/2022 12:50:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/25/2022 12:50:35 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8403030713751776 on epoch=124
05/25/2022 12:50:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/25/2022 12:50:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/25/2022 12:50:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
05/25/2022 12:50:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 12:50:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/25/2022 12:50:57 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.905888725969371 on epoch=128
05/25/2022 12:50:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8978736127882239 -> 0.905888725969371 on epoch=128, global_step=1800
05/25/2022 12:51:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
05/25/2022 12:51:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/25/2022 12:51:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/25/2022 12:51:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/25/2022 12:51:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/25/2022 12:51:20 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9682586230973327 on epoch=132
05/25/2022 12:51:20 - INFO - __main__ - Saving model with best Classification-F1: 0.905888725969371 -> 0.9682586230973327 on epoch=132, global_step=1850
05/25/2022 12:51:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/25/2022 12:51:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 12:51:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 12:51:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 12:51:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 12:51:41 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9773678606339897 on epoch=135
05/25/2022 12:51:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9682586230973327 -> 0.9773678606339897 on epoch=135, global_step=1900
05/25/2022 12:51:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/25/2022 12:51:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/25/2022 12:51:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/25/2022 12:51:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/25/2022 12:51:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/25/2022 12:52:04 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.973026534660785 on epoch=139
05/25/2022 12:52:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 12:52:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
05/25/2022 12:52:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/25/2022 12:52:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
05/25/2022 12:52:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 12:52:26 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.973026534660785 on epoch=142
05/25/2022 12:52:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/25/2022 12:52:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/25/2022 12:52:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/25/2022 12:52:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 12:52:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 12:52:48 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.973026534660785 on epoch=146
05/25/2022 12:52:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 12:52:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
05/25/2022 12:52:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/25/2022 12:53:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
05/25/2022 12:53:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/25/2022 12:53:10 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9730308985764394 on epoch=149
05/25/2022 12:53:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/25/2022 12:53:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 12:53:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 12:53:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 12:53:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 12:53:32 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9142302052785924 on epoch=153
05/25/2022 12:53:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
05/25/2022 12:53:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 12:53:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/25/2022 12:53:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/25/2022 12:53:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/25/2022 12:53:54 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.973026534660785 on epoch=157
05/25/2022 12:53:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 12:54:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/25/2022 12:54:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/25/2022 12:54:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 12:54:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
05/25/2022 12:54:16 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9773678606339897 on epoch=160
05/25/2022 12:54:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 12:54:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
05/25/2022 12:54:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 12:54:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/25/2022 12:54:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 12:54:38 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.973026534660785 on epoch=164
05/25/2022 12:54:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/25/2022 12:54:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 12:54:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/25/2022 12:54:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/25/2022 12:54:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 12:55:00 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9728167834531932 on epoch=167
05/25/2022 12:55:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
05/25/2022 12:55:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 12:55:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
05/25/2022 12:55:12 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
05/25/2022 12:55:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/25/2022 12:55:22 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9185443141088302 on epoch=171
05/25/2022 12:55:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/25/2022 12:55:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 12:55:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/25/2022 12:55:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/25/2022 12:55:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/25/2022 12:55:44 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9060075613823242 on epoch=174
05/25/2022 12:55:47 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 12:55:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 12:55:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 12:55:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 12:55:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/25/2022 12:56:06 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9685578850308451 on epoch=178
05/25/2022 12:56:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/25/2022 12:56:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/25/2022 12:56:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 12:56:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 12:56:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
05/25/2022 12:56:28 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.972812419537539 on epoch=182
05/25/2022 12:56:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/25/2022 12:56:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 12:56:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/25/2022 12:56:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/25/2022 12:56:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 12:56:50 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9727272727272728 on epoch=185
05/25/2022 12:56:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
05/25/2022 12:56:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/25/2022 12:56:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/25/2022 12:57:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 12:57:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/25/2022 12:57:12 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9057282502443792 on epoch=189
05/25/2022 12:57:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 12:57:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/25/2022 12:57:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 12:57:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 12:57:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 12:57:34 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.905534015810794 on epoch=192
05/25/2022 12:57:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 12:57:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 12:57:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 12:57:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
05/25/2022 12:57:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
05/25/2022 12:57:56 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8350052589779737 on epoch=196
05/25/2022 12:57:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/25/2022 12:58:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/25/2022 12:58:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 12:58:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/25/2022 12:58:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 12:58:18 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.903513813790592 on epoch=199
05/25/2022 12:58:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 12:58:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 12:58:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/25/2022 12:58:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/25/2022 12:58:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 12:58:40 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8984344487112269 on epoch=203
05/25/2022 12:58:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 12:58:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
05/25/2022 12:58:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/25/2022 12:58:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 12:58:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/25/2022 12:59:03 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9012444407432301 on epoch=207
05/25/2022 12:59:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
05/25/2022 12:59:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/25/2022 12:59:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 12:59:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 12:59:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/25/2022 12:59:24 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8463636774357837 on epoch=210
05/25/2022 12:59:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 12:59:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 12:59:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 12:59:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/25/2022 12:59:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 12:59:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:59:41 - INFO - __main__ - Printing 3 examples
05/25/2022 12:59:41 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 12:59:41 - INFO - __main__ - ['Animal']
05/25/2022 12:59:41 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 12:59:41 - INFO - __main__ - ['Animal']
05/25/2022 12:59:41 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 12:59:41 - INFO - __main__ - ['Animal']
05/25/2022 12:59:41 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:59:41 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:59:41 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 12:59:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 12:59:41 - INFO - __main__ - Printing 3 examples
05/25/2022 12:59:41 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 12:59:41 - INFO - __main__ - ['Animal']
05/25/2022 12:59:41 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 12:59:41 - INFO - __main__ - ['Animal']
05/25/2022 12:59:41 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 12:59:41 - INFO - __main__ - ['Animal']
05/25/2022 12:59:41 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:59:41 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:59:42 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 12:59:46 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.973026534660785 on epoch=214
05/25/2022 12:59:46 - INFO - __main__ - save last model!
05/25/2022 12:59:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 12:59:46 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 12:59:46 - INFO - __main__ - Printing 3 examples
05/25/2022 12:59:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 12:59:46 - INFO - __main__ - ['Animal']
05/25/2022 12:59:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 12:59:46 - INFO - __main__ - ['Animal']
05/25/2022 12:59:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 12:59:46 - INFO - __main__ - ['Village']
05/25/2022 12:59:46 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:59:48 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:59:51 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 12:59:57 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:59:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 12:59:57 - INFO - __main__ - Starting training!
05/25/2022 13:02:13 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/25/2022 13:02:13 - INFO - __main__ - Classification-F1 on test data: 0.7182
05/25/2022 13:02:13 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9773678606339897, test_performance=0.7181633576685752
05/25/2022 13:02:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/25/2022 13:02:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:02:14 - INFO - __main__ - Printing 3 examples
05/25/2022 13:02:14 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 13:02:14 - INFO - __main__ - ['Animal']
05/25/2022 13:02:14 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 13:02:14 - INFO - __main__ - ['Animal']
05/25/2022 13:02:14 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 13:02:14 - INFO - __main__ - ['Animal']
05/25/2022 13:02:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:02:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:02:15 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 13:02:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:02:15 - INFO - __main__ - Printing 3 examples
05/25/2022 13:02:15 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/25/2022 13:02:15 - INFO - __main__ - ['Animal']
05/25/2022 13:02:15 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/25/2022 13:02:15 - INFO - __main__ - ['Animal']
05/25/2022 13:02:15 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/25/2022 13:02:15 - INFO - __main__ - ['Animal']
05/25/2022 13:02:15 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:02:15 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:02:15 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 13:02:34 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 13:02:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 13:02:35 - INFO - __main__ - Starting training!
05/25/2022 13:02:38 - INFO - __main__ - Step 10 Global step 10 Train loss 5.65 on epoch=0
05/25/2022 13:02:41 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=1
05/25/2022 13:02:44 - INFO - __main__ - Step 30 Global step 30 Train loss 3.66 on epoch=2
05/25/2022 13:02:48 - INFO - __main__ - Step 40 Global step 40 Train loss 3.06 on epoch=2
05/25/2022 13:02:51 - INFO - __main__ - Step 50 Global step 50 Train loss 2.74 on epoch=3
05/25/2022 13:02:55 - INFO - __main__ - Global step 50 Train loss 3.92 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 13:02:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 13:02:58 - INFO - __main__ - Step 60 Global step 60 Train loss 2.46 on epoch=4
05/25/2022 13:03:01 - INFO - __main__ - Step 70 Global step 70 Train loss 2.01 on epoch=4
05/25/2022 13:03:04 - INFO - __main__ - Step 80 Global step 80 Train loss 1.77 on epoch=5
05/25/2022 13:03:07 - INFO - __main__ - Step 90 Global step 90 Train loss 1.60 on epoch=6
05/25/2022 13:03:10 - INFO - __main__ - Step 100 Global step 100 Train loss 1.38 on epoch=7
05/25/2022 13:03:16 - INFO - __main__ - Global step 100 Train loss 1.84 Classification-F1 0.3506894625692579 on epoch=7
05/25/2022 13:03:16 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.3506894625692579 on epoch=7, global_step=100
05/25/2022 13:03:19 - INFO - __main__ - Step 110 Global step 110 Train loss 1.18 on epoch=7
05/25/2022 13:03:22 - INFO - __main__ - Step 120 Global step 120 Train loss 1.14 on epoch=8
05/25/2022 13:03:25 - INFO - __main__ - Step 130 Global step 130 Train loss 1.13 on epoch=9
05/25/2022 13:03:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.99 on epoch=9
05/25/2022 13:03:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=10
05/25/2022 13:03:38 - INFO - __main__ - Global step 150 Train loss 1.06 Classification-F1 0.35169796574796164 on epoch=10
05/25/2022 13:03:38 - INFO - __main__ - Saving model with best Classification-F1: 0.3506894625692579 -> 0.35169796574796164 on epoch=10, global_step=150
05/25/2022 13:03:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.76 on epoch=11
05/25/2022 13:03:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=12
05/25/2022 13:03:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=12
05/25/2022 13:03:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=13
05/25/2022 13:03:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=14
05/25/2022 13:04:01 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.42970434604155533 on epoch=14
05/25/2022 13:04:01 - INFO - __main__ - Saving model with best Classification-F1: 0.35169796574796164 -> 0.42970434604155533 on epoch=14, global_step=200
05/25/2022 13:04:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=14
05/25/2022 13:04:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.64 on epoch=15
05/25/2022 13:04:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=16
05/25/2022 13:04:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=17
05/25/2022 13:04:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=17
05/25/2022 13:04:23 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.5123850230942634 on epoch=17
05/25/2022 13:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.42970434604155533 -> 0.5123850230942634 on epoch=17, global_step=250
05/25/2022 13:04:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=18
05/25/2022 13:04:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=19
05/25/2022 13:04:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=19
05/25/2022 13:04:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=20
05/25/2022 13:04:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=21
05/25/2022 13:04:46 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6541821110956716 on epoch=21
05/25/2022 13:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5123850230942634 -> 0.6541821110956716 on epoch=21, global_step=300
05/25/2022 13:04:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
05/25/2022 13:04:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
05/25/2022 13:04:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=23
05/25/2022 13:04:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=24
05/25/2022 13:05:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.44 on epoch=24
05/25/2022 13:05:08 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.5778943102672686 on epoch=24
05/25/2022 13:05:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=25
05/25/2022 13:05:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=26
05/25/2022 13:05:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=27
05/25/2022 13:05:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=27
05/25/2022 13:05:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=28
05/25/2022 13:05:31 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.6532412991008106 on epoch=28
05/25/2022 13:05:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=29
05/25/2022 13:05:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=29
05/25/2022 13:05:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
05/25/2022 13:05:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=31
05/25/2022 13:05:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=32
05/25/2022 13:05:54 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.677743481364207 on epoch=32
05/25/2022 13:05:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6541821110956716 -> 0.677743481364207 on epoch=32, global_step=450
05/25/2022 13:05:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
05/25/2022 13:06:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=33
05/25/2022 13:06:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
05/25/2022 13:06:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=34
05/25/2022 13:06:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
05/25/2022 13:06:16 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.6926503290927815 on epoch=35
05/25/2022 13:06:16 - INFO - __main__ - Saving model with best Classification-F1: 0.677743481364207 -> 0.6926503290927815 on epoch=35, global_step=500
05/25/2022 13:06:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
05/25/2022 13:06:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
05/25/2022 13:06:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
05/25/2022 13:06:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
05/25/2022 13:06:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=39
05/25/2022 13:06:38 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.641928300854963 on epoch=39
05/25/2022 13:06:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
05/25/2022 13:06:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=40
05/25/2022 13:06:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
05/25/2022 13:06:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
05/25/2022 13:06:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
05/25/2022 13:07:01 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.6638509826390278 on epoch=42
05/25/2022 13:07:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
05/25/2022 13:07:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
05/25/2022 13:07:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
05/25/2022 13:07:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=45
05/25/2022 13:07:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
05/25/2022 13:07:23 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6391550760725572 on epoch=46
05/25/2022 13:07:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
05/25/2022 13:07:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
05/25/2022 13:07:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
05/25/2022 13:07:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
05/25/2022 13:07:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=49
05/25/2022 13:07:46 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6860197061347372 on epoch=49
05/25/2022 13:07:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
05/25/2022 13:07:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
05/25/2022 13:07:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
05/25/2022 13:07:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=52
05/25/2022 13:08:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=53
05/25/2022 13:08:09 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.7183448791795443 on epoch=53
05/25/2022 13:08:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6926503290927815 -> 0.7183448791795443 on epoch=53, global_step=750
05/25/2022 13:08:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=54
05/25/2022 13:08:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
05/25/2022 13:08:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
05/25/2022 13:08:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
05/25/2022 13:08:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=57
05/25/2022 13:08:31 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6724343777915207 on epoch=57
05/25/2022 13:08:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
05/25/2022 13:08:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
05/25/2022 13:08:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
05/25/2022 13:08:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
05/25/2022 13:08:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
05/25/2022 13:08:54 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6602217243306743 on epoch=60
05/25/2022 13:08:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
05/25/2022 13:09:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=62
05/25/2022 13:09:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
05/25/2022 13:09:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
05/25/2022 13:09:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=64
05/25/2022 13:09:16 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.668128089404685 on epoch=64
05/25/2022 13:09:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
05/25/2022 13:09:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=65
05/25/2022 13:09:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
05/25/2022 13:09:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
05/25/2022 13:09:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
05/25/2022 13:09:38 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6209685010875701 on epoch=67
05/25/2022 13:09:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
05/25/2022 13:09:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
05/25/2022 13:09:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
05/25/2022 13:09:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
05/25/2022 13:09:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
05/25/2022 13:10:01 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7672133072844649 on epoch=71
05/25/2022 13:10:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7183448791795443 -> 0.7672133072844649 on epoch=71, global_step=1000
05/25/2022 13:10:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
05/25/2022 13:10:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
05/25/2022 13:10:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
05/25/2022 13:10:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
05/25/2022 13:10:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=74
05/25/2022 13:10:24 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.7708495616183898 on epoch=74
05/25/2022 13:10:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7672133072844649 -> 0.7708495616183898 on epoch=74, global_step=1050
05/25/2022 13:10:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
05/25/2022 13:10:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
05/25/2022 13:10:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
05/25/2022 13:10:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
05/25/2022 13:10:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
05/25/2022 13:10:47 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.5960548565004024 on epoch=78
05/25/2022 13:10:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
05/25/2022 13:10:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
05/25/2022 13:10:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
05/25/2022 13:10:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
05/25/2022 13:11:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
05/25/2022 13:11:09 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7343415026569968 on epoch=82
05/25/2022 13:11:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
05/25/2022 13:11:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/25/2022 13:11:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
05/25/2022 13:11:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
05/25/2022 13:11:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
05/25/2022 13:11:31 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6939988596233475 on epoch=85
05/25/2022 13:11:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
05/25/2022 13:11:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
05/25/2022 13:11:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
05/25/2022 13:11:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
05/25/2022 13:11:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
05/25/2022 13:11:53 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.6531329954080379 on epoch=89
05/25/2022 13:11:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
05/25/2022 13:11:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
05/25/2022 13:12:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
05/25/2022 13:12:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
05/25/2022 13:12:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
05/25/2022 13:12:16 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7310049418920388 on epoch=92
05/25/2022 13:12:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/25/2022 13:12:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
05/25/2022 13:12:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
05/25/2022 13:12:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
05/25/2022 13:12:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
05/25/2022 13:12:38 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.723052508357168 on epoch=96
05/25/2022 13:12:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
05/25/2022 13:12:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
05/25/2022 13:12:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/25/2022 13:12:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
05/25/2022 13:12:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
05/25/2022 13:13:01 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.617659974434168 on epoch=99
05/25/2022 13:13:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
05/25/2022 13:13:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
05/25/2022 13:13:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 13:13:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
05/25/2022 13:13:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
05/25/2022 13:13:23 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7628251426973864 on epoch=103
05/25/2022 13:13:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
05/25/2022 13:13:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
05/25/2022 13:13:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
05/25/2022 13:13:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/25/2022 13:13:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
05/25/2022 13:13:46 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7218409060065638 on epoch=107
05/25/2022 13:13:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
05/25/2022 13:13:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/25/2022 13:13:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
05/25/2022 13:13:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
05/25/2022 13:14:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
05/25/2022 13:14:09 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7417329112406976 on epoch=110
05/25/2022 13:14:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
05/25/2022 13:14:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
05/25/2022 13:14:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/25/2022 13:14:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
05/25/2022 13:14:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
05/25/2022 13:14:32 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.6689196279684895 on epoch=114
05/25/2022 13:14:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/25/2022 13:14:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
05/25/2022 13:14:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/25/2022 13:14:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
05/25/2022 13:14:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
05/25/2022 13:14:54 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7565192423547151 on epoch=117
05/25/2022 13:14:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/25/2022 13:15:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/25/2022 13:15:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
05/25/2022 13:15:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
05/25/2022 13:15:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/25/2022 13:15:17 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.768888661433928 on epoch=121
05/25/2022 13:15:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/25/2022 13:15:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/25/2022 13:15:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/25/2022 13:15:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
05/25/2022 13:15:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=124
05/25/2022 13:15:40 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7885504315769971 on epoch=124
05/25/2022 13:15:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7708495616183898 -> 0.7885504315769971 on epoch=124, global_step=1750
05/25/2022 13:15:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
05/25/2022 13:15:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/25/2022 13:15:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
05/25/2022 13:15:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
05/25/2022 13:15:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/25/2022 13:16:03 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8183064855544695 on epoch=128
05/25/2022 13:16:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7885504315769971 -> 0.8183064855544695 on epoch=128, global_step=1800
05/25/2022 13:16:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/25/2022 13:16:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
05/25/2022 13:16:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
05/25/2022 13:16:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=131
05/25/2022 13:16:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/25/2022 13:16:26 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.824984388600723 on epoch=132
05/25/2022 13:16:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8183064855544695 -> 0.824984388600723 on epoch=132, global_step=1850
05/25/2022 13:16:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
05/25/2022 13:16:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/25/2022 13:16:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/25/2022 13:16:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
05/25/2022 13:16:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
05/25/2022 13:16:49 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8975227128974755 on epoch=135
05/25/2022 13:16:49 - INFO - __main__ - Saving model with best Classification-F1: 0.824984388600723 -> 0.8975227128974755 on epoch=135, global_step=1900
05/25/2022 13:16:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/25/2022 13:16:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/25/2022 13:16:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/25/2022 13:17:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/25/2022 13:17:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/25/2022 13:17:12 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.897750197830843 on epoch=139
05/25/2022 13:17:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8975227128974755 -> 0.897750197830843 on epoch=139, global_step=1950
05/25/2022 13:17:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/25/2022 13:17:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
05/25/2022 13:17:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
05/25/2022 13:17:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/25/2022 13:17:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/25/2022 13:17:35 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7859977016509554 on epoch=142
05/25/2022 13:17:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/25/2022 13:17:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
05/25/2022 13:17:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/25/2022 13:17:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 13:17:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/25/2022 13:17:57 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9058756924079503 on epoch=146
05/25/2022 13:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.897750197830843 -> 0.9058756924079503 on epoch=146, global_step=2050
05/25/2022 13:18:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
05/25/2022 13:18:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
05/25/2022 13:18:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
05/25/2022 13:18:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/25/2022 13:18:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
05/25/2022 13:18:20 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7784908347038607 on epoch=149
05/25/2022 13:18:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
05/25/2022 13:18:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
05/25/2022 13:18:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
05/25/2022 13:18:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/25/2022 13:18:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/25/2022 13:18:43 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7603429935023863 on epoch=153
05/25/2022 13:18:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
05/25/2022 13:18:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/25/2022 13:18:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/25/2022 13:18:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/25/2022 13:18:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/25/2022 13:19:05 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8927897323691669 on epoch=157
05/25/2022 13:19:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/25/2022 13:19:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
05/25/2022 13:19:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/25/2022 13:19:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/25/2022 13:19:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
05/25/2022 13:19:27 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9639495900999694 on epoch=160
05/25/2022 13:19:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9058756924079503 -> 0.9639495900999694 on epoch=160, global_step=2250
05/25/2022 13:19:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 13:19:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/25/2022 13:19:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
05/25/2022 13:19:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/25/2022 13:19:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
05/25/2022 13:19:49 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8433483015640274 on epoch=164
05/25/2022 13:19:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/25/2022 13:19:55 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/25/2022 13:19:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/25/2022 13:20:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/25/2022 13:20:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 13:20:11 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6861932441252256 on epoch=167
05/25/2022 13:20:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
05/25/2022 13:20:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
05/25/2022 13:20:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/25/2022 13:20:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
05/25/2022 13:20:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 13:20:34 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7452994910169549 on epoch=171
05/25/2022 13:20:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/25/2022 13:20:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/25/2022 13:20:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 13:20:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/25/2022 13:20:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/25/2022 13:20:56 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8994281524926687 on epoch=174
05/25/2022 13:20:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
05/25/2022 13:21:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/25/2022 13:21:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.12 on epoch=177
05/25/2022 13:21:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/25/2022 13:21:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
05/25/2022 13:21:19 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7850333842827906 on epoch=178
05/25/2022 13:21:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/25/2022 13:21:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
05/25/2022 13:21:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
05/25/2022 13:21:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
05/25/2022 13:21:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
05/25/2022 13:21:41 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8388989133549062 on epoch=182
05/25/2022 13:21:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/25/2022 13:21:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/25/2022 13:21:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/25/2022 13:21:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
05/25/2022 13:21:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/25/2022 13:22:03 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6924844621451962 on epoch=185
05/25/2022 13:22:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/25/2022 13:22:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
05/25/2022 13:22:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/25/2022 13:22:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/25/2022 13:22:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/25/2022 13:22:26 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7869922455785834 on epoch=189
05/25/2022 13:22:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 13:22:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/25/2022 13:22:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 13:22:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/25/2022 13:22:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/25/2022 13:22:48 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6802322984374679 on epoch=192
05/25/2022 13:22:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
05/25/2022 13:22:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
05/25/2022 13:22:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 13:23:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
05/25/2022 13:23:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
05/25/2022 13:23:10 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8325111908766439 on epoch=196
05/25/2022 13:23:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/25/2022 13:23:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/25/2022 13:23:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/25/2022 13:23:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/25/2022 13:23:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 13:23:32 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8472545515640274 on epoch=199
05/25/2022 13:23:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 13:23:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
05/25/2022 13:23:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/25/2022 13:23:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 13:23:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/25/2022 13:23:55 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7953956069231213 on epoch=203
05/25/2022 13:23:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
05/25/2022 13:24:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 13:24:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/25/2022 13:24:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/25/2022 13:24:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/25/2022 13:24:18 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8256767166886867 on epoch=207
05/25/2022 13:24:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/25/2022 13:24:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/25/2022 13:24:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 13:24:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/25/2022 13:24:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/25/2022 13:24:40 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8900436391565424 on epoch=210
05/25/2022 13:24:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/25/2022 13:24:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 13:24:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/25/2022 13:24:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/25/2022 13:24:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/25/2022 13:24:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:24:57 - INFO - __main__ - Printing 3 examples
05/25/2022 13:24:57 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 13:24:57 - INFO - __main__ - ['Plant']
05/25/2022 13:24:57 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 13:24:57 - INFO - __main__ - ['Plant']
05/25/2022 13:24:57 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 13:24:57 - INFO - __main__ - ['Plant']
05/25/2022 13:24:57 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:24:57 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:24:57 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 13:24:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:24:57 - INFO - __main__ - Printing 3 examples
05/25/2022 13:24:57 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 13:24:57 - INFO - __main__ - ['Plant']
05/25/2022 13:24:57 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 13:24:57 - INFO - __main__ - ['Plant']
05/25/2022 13:24:57 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 13:24:57 - INFO - __main__ - ['Plant']
05/25/2022 13:24:57 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:24:57 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:24:57 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 13:25:02 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8326848470749681 on epoch=214
05/25/2022 13:25:02 - INFO - __main__ - save last model!
05/25/2022 13:25:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 13:25:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 13:25:02 - INFO - __main__ - Printing 3 examples
05/25/2022 13:25:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 13:25:02 - INFO - __main__ - ['Animal']
05/25/2022 13:25:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 13:25:02 - INFO - __main__ - ['Animal']
05/25/2022 13:25:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 13:25:02 - INFO - __main__ - ['Village']
05/25/2022 13:25:02 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:25:04 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:25:08 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 13:25:13 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 13:25:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 13:25:13 - INFO - __main__ - Starting training!
05/25/2022 13:27:28 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/25/2022 13:27:28 - INFO - __main__ - Classification-F1 on test data: 0.6049
05/25/2022 13:27:28 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9639495900999694, test_performance=0.6048530172295589
05/25/2022 13:27:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/25/2022 13:27:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:27:29 - INFO - __main__ - Printing 3 examples
05/25/2022 13:27:29 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 13:27:29 - INFO - __main__ - ['Plant']
05/25/2022 13:27:29 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 13:27:29 - INFO - __main__ - ['Plant']
05/25/2022 13:27:29 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 13:27:29 - INFO - __main__ - ['Plant']
05/25/2022 13:27:29 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:27:29 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:27:29 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 13:27:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:27:29 - INFO - __main__ - Printing 3 examples
05/25/2022 13:27:29 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 13:27:29 - INFO - __main__ - ['Plant']
05/25/2022 13:27:29 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 13:27:29 - INFO - __main__ - ['Plant']
05/25/2022 13:27:29 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 13:27:29 - INFO - __main__ - ['Plant']
05/25/2022 13:27:29 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:27:30 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:27:30 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 13:27:45 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 13:27:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 13:27:46 - INFO - __main__ - Starting training!
05/25/2022 13:27:50 - INFO - __main__ - Step 10 Global step 10 Train loss 5.01 on epoch=0
05/25/2022 13:27:53 - INFO - __main__ - Step 20 Global step 20 Train loss 3.16 on epoch=1
05/25/2022 13:27:56 - INFO - __main__ - Step 30 Global step 30 Train loss 2.43 on epoch=2
05/25/2022 13:27:59 - INFO - __main__ - Step 40 Global step 40 Train loss 1.90 on epoch=2
05/25/2022 13:28:02 - INFO - __main__ - Step 50 Global step 50 Train loss 1.47 on epoch=3
05/25/2022 13:28:09 - INFO - __main__ - Global step 50 Train loss 2.80 Classification-F1 0.24161029537762765 on epoch=3
05/25/2022 13:28:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.24161029537762765 on epoch=3, global_step=50
05/25/2022 13:28:12 - INFO - __main__ - Step 60 Global step 60 Train loss 1.24 on epoch=4
05/25/2022 13:28:15 - INFO - __main__ - Step 70 Global step 70 Train loss 1.04 on epoch=4
05/25/2022 13:28:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=5
05/25/2022 13:28:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.76 on epoch=6
05/25/2022 13:28:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.66 on epoch=7
05/25/2022 13:28:32 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.4565720996477043 on epoch=7
05/25/2022 13:28:32 - INFO - __main__ - Saving model with best Classification-F1: 0.24161029537762765 -> 0.4565720996477043 on epoch=7, global_step=100
05/25/2022 13:28:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.58 on epoch=7
05/25/2022 13:28:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.62 on epoch=8
05/25/2022 13:28:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.59 on epoch=9
05/25/2022 13:28:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=9
05/25/2022 13:28:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=10
05/25/2022 13:28:55 - INFO - __main__ - Global step 150 Train loss 0.55 Classification-F1 0.5498246206730905 on epoch=10
05/25/2022 13:28:55 - INFO - __main__ - Saving model with best Classification-F1: 0.4565720996477043 -> 0.5498246206730905 on epoch=10, global_step=150
05/25/2022 13:28:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.45 on epoch=11
05/25/2022 13:29:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.44 on epoch=12
05/25/2022 13:29:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=12
05/25/2022 13:29:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=13
05/25/2022 13:29:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=14
05/25/2022 13:29:17 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.7251617565357512 on epoch=14
05/25/2022 13:29:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5498246206730905 -> 0.7251617565357512 on epoch=14, global_step=200
05/25/2022 13:29:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=14
05/25/2022 13:29:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=15
05/25/2022 13:29:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=16
05/25/2022 13:29:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=17
05/25/2022 13:29:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=17
05/25/2022 13:29:40 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.6583736098061657 on epoch=17
05/25/2022 13:29:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=18
05/25/2022 13:29:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=19
05/25/2022 13:29:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=19
05/25/2022 13:29:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=20
05/25/2022 13:29:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=21
05/25/2022 13:30:02 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.7181982651608169 on epoch=21
05/25/2022 13:30:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=22
05/25/2022 13:30:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=22
05/25/2022 13:30:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=23
05/25/2022 13:30:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=24
05/25/2022 13:30:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=24
05/25/2022 13:30:26 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.7973979949060874 on epoch=24
05/25/2022 13:30:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7251617565357512 -> 0.7973979949060874 on epoch=24, global_step=350
05/25/2022 13:30:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=25
05/25/2022 13:30:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=26
05/25/2022 13:30:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.12 on epoch=27
05/25/2022 13:30:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=27
05/25/2022 13:30:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=28
05/25/2022 13:30:49 - INFO - __main__ - Global step 400 Train loss 0.16 Classification-F1 0.6521262613332506 on epoch=28
05/25/2022 13:30:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=29
05/25/2022 13:30:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=29
05/25/2022 13:30:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=30
05/25/2022 13:31:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=31
05/25/2022 13:31:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=32
05/25/2022 13:31:12 - INFO - __main__ - Global step 450 Train loss 0.15 Classification-F1 0.6905548328298753 on epoch=32
05/25/2022 13:31:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=32
05/25/2022 13:31:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=33
05/25/2022 13:31:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=34
05/25/2022 13:31:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=34
05/25/2022 13:31:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=35
05/25/2022 13:31:34 - INFO - __main__ - Global step 500 Train loss 0.09 Classification-F1 0.662023109135613 on epoch=35
05/25/2022 13:31:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=36
05/25/2022 13:31:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=37
05/25/2022 13:31:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
05/25/2022 13:31:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=38
05/25/2022 13:31:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=39
05/25/2022 13:31:58 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.7755725457338362 on epoch=39
05/25/2022 13:32:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=39
05/25/2022 13:32:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
05/25/2022 13:32:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
05/25/2022 13:32:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=42
05/25/2022 13:32:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=42
05/25/2022 13:32:21 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.7610029228386141 on epoch=42
05/25/2022 13:32:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
05/25/2022 13:32:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=44
05/25/2022 13:32:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=44
05/25/2022 13:32:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
05/25/2022 13:32:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
05/25/2022 13:32:44 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.8101388649301362 on epoch=46
05/25/2022 13:32:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7973979949060874 -> 0.8101388649301362 on epoch=46, global_step=650
05/25/2022 13:32:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=47
05/25/2022 13:32:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=47
05/25/2022 13:32:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=48
05/25/2022 13:32:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=49
05/25/2022 13:32:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
05/25/2022 13:33:07 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.8238796737536657 on epoch=49
05/25/2022 13:33:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8101388649301362 -> 0.8238796737536657 on epoch=49, global_step=700
05/25/2022 13:33:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
05/25/2022 13:33:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
05/25/2022 13:33:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=52
05/25/2022 13:33:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
05/25/2022 13:33:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=53
05/25/2022 13:33:29 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.732174053854766 on epoch=53
05/25/2022 13:33:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
05/25/2022 13:33:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=54
05/25/2022 13:33:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
05/25/2022 13:33:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
05/25/2022 13:33:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
05/25/2022 13:33:52 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6601855298549596 on epoch=57
05/25/2022 13:33:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=57
05/25/2022 13:33:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=58
05/25/2022 13:34:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=59
05/25/2022 13:34:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=59
05/25/2022 13:34:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
05/25/2022 13:34:15 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.8383958027859237 on epoch=60
05/25/2022 13:34:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8238796737536657 -> 0.8383958027859237 on epoch=60, global_step=850
05/25/2022 13:34:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
05/25/2022 13:34:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=62
05/25/2022 13:34:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
05/25/2022 13:34:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
05/25/2022 13:34:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
05/25/2022 13:34:37 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7103870227642657 on epoch=64
05/25/2022 13:34:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=64
05/25/2022 13:34:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
05/25/2022 13:34:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
05/25/2022 13:34:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
05/25/2022 13:34:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
05/25/2022 13:34:59 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7482925390693822 on epoch=67
05/25/2022 13:35:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
05/25/2022 13:35:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
05/25/2022 13:35:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
05/25/2022 13:35:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
05/25/2022 13:35:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/25/2022 13:35:22 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7777941883213726 on epoch=71
05/25/2022 13:35:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=72
05/25/2022 13:35:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
05/25/2022 13:35:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
05/25/2022 13:35:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
05/25/2022 13:35:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
05/25/2022 13:35:44 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.8397168255131965 on epoch=74
05/25/2022 13:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8383958027859237 -> 0.8397168255131965 on epoch=74, global_step=1050
05/25/2022 13:35:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
05/25/2022 13:35:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
05/25/2022 13:35:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
05/25/2022 13:35:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=77
05/25/2022 13:35:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
05/25/2022 13:36:06 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.705143138216924 on epoch=78
05/25/2022 13:36:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
05/25/2022 13:36:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=79
05/25/2022 13:36:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=80
05/25/2022 13:36:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
05/25/2022 13:36:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=82
05/25/2022 13:36:28 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=82
05/25/2022 13:36:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8397168255131965 -> 0.9865984150258343 on epoch=82, global_step=1150
05/25/2022 13:36:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=82
05/25/2022 13:36:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
05/25/2022 13:36:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
05/25/2022 13:36:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/25/2022 13:36:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
05/25/2022 13:36:50 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.8608626588465298 on epoch=85
05/25/2022 13:36:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
05/25/2022 13:36:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
05/25/2022 13:36:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
05/25/2022 13:37:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
05/25/2022 13:37:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
05/25/2022 13:37:12 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9043049853372432 on epoch=89
05/25/2022 13:37:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
05/25/2022 13:37:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
05/25/2022 13:37:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
05/25/2022 13:37:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
05/25/2022 13:37:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
05/25/2022 13:37:34 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=92
05/25/2022 13:37:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
05/25/2022 13:37:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
05/25/2022 13:37:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
05/25/2022 13:37:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 13:37:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
05/25/2022 13:37:57 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.902064306661081 on epoch=96
05/25/2022 13:38:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
05/25/2022 13:38:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/25/2022 13:38:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/25/2022 13:38:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
05/25/2022 13:38:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
05/25/2022 13:38:20 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9092811758134338 on epoch=99
05/25/2022 13:38:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
05/25/2022 13:38:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=101
05/25/2022 13:38:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
05/25/2022 13:38:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
05/25/2022 13:38:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/25/2022 13:38:42 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8109929944607364 on epoch=103
05/25/2022 13:38:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=104
05/25/2022 13:38:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
05/25/2022 13:38:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/25/2022 13:38:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/25/2022 13:38:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/25/2022 13:39:04 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=107
05/25/2022 13:39:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/25/2022 13:39:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
05/25/2022 13:39:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
05/25/2022 13:39:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
05/25/2022 13:39:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/25/2022 13:39:26 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.838604777047665 on epoch=110
05/25/2022 13:39:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=111
05/25/2022 13:39:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/25/2022 13:39:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/25/2022 13:39:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 13:39:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=114
05/25/2022 13:39:47 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=114
05/25/2022 13:39:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9865984150258343 -> 0.9910627007401202 on epoch=114, global_step=1600
05/25/2022 13:39:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=114
05/25/2022 13:39:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
05/25/2022 13:39:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 13:39:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=117
05/25/2022 13:40:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/25/2022 13:40:09 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=117
05/25/2022 13:40:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=118
05/25/2022 13:40:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
05/25/2022 13:40:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 13:40:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/25/2022 13:40:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=121
05/25/2022 13:40:31 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=121
05/25/2022 13:40:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=122
05/25/2022 13:40:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/25/2022 13:40:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
05/25/2022 13:40:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/25/2022 13:40:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
05/25/2022 13:40:52 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8285713322316115 on epoch=124
05/25/2022 13:40:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 13:40:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/25/2022 13:41:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
05/25/2022 13:41:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
05/25/2022 13:41:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/25/2022 13:41:14 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=128
05/25/2022 13:41:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=129
05/25/2022 13:41:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/25/2022 13:41:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 13:41:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=131
05/25/2022 13:41:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/25/2022 13:41:36 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9134478424801006 on epoch=132
05/25/2022 13:41:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
05/25/2022 13:41:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 13:41:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=134
05/25/2022 13:41:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 13:41:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
05/25/2022 13:41:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=135
05/25/2022 13:42:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/25/2022 13:42:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
05/25/2022 13:42:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/25/2022 13:42:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=138
05/25/2022 13:42:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/25/2022 13:42:21 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.9185272075594656 on epoch=139
05/25/2022 13:42:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
05/25/2022 13:42:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 13:42:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
05/25/2022 13:42:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
05/25/2022 13:42:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 13:42:43 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=142
05/25/2022 13:42:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
05/25/2022 13:42:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/25/2022 13:42:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
05/25/2022 13:42:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 13:42:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 13:43:06 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9103372434017594 on epoch=146
05/25/2022 13:43:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
05/25/2022 13:43:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
05/25/2022 13:43:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/25/2022 13:43:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/25/2022 13:43:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
05/25/2022 13:43:28 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9186705767350927 on epoch=149
05/25/2022 13:43:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
05/25/2022 13:43:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 13:43:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
05/25/2022 13:43:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 13:43:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
05/25/2022 13:43:51 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=153
05/25/2022 13:43:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/25/2022 13:43:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
05/25/2022 13:44:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
05/25/2022 13:44:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/25/2022 13:44:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
05/25/2022 13:44:13 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.8507474898456198 on epoch=157
05/25/2022 13:44:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 13:44:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/25/2022 13:44:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/25/2022 13:44:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 13:44:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
05/25/2022 13:44:35 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9043090583251873 on epoch=160
05/25/2022 13:44:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/25/2022 13:44:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/25/2022 13:44:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
05/25/2022 13:44:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/25/2022 13:44:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
05/25/2022 13:44:57 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.9185353535353535 on epoch=164
05/25/2022 13:45:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/25/2022 13:45:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/25/2022 13:45:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
05/25/2022 13:45:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/25/2022 13:45:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
05/25/2022 13:45:20 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9186705767350927 on epoch=167
05/25/2022 13:45:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/25/2022 13:45:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 13:45:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/25/2022 13:45:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 13:45:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 13:45:43 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9910670646557743 on epoch=171
05/25/2022 13:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9910627007401202 -> 0.9910670646557743 on epoch=171, global_step=2400
05/25/2022 13:45:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/25/2022 13:45:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
05/25/2022 13:45:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
05/25/2022 13:45:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 13:45:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
05/25/2022 13:46:05 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=174
05/25/2022 13:46:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/25/2022 13:46:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/25/2022 13:46:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/25/2022 13:46:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/25/2022 13:46:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/25/2022 13:46:28 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9037412987239591 on epoch=178
05/25/2022 13:46:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/25/2022 13:46:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 13:46:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 13:46:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
05/25/2022 13:46:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/25/2022 13:46:50 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7957407837012627 on epoch=182
05/25/2022 13:46:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/25/2022 13:46:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/25/2022 13:46:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/25/2022 13:47:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 13:47:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/25/2022 13:47:12 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7948598313832561 on epoch=185
05/25/2022 13:47:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 13:47:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 13:47:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/25/2022 13:47:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 13:47:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
05/25/2022 13:47:35 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.909753822990753 on epoch=189
05/25/2022 13:47:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 13:47:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 13:47:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
05/25/2022 13:47:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 13:47:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 13:47:57 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.9097407894293321 on epoch=192
05/25/2022 13:48:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
05/25/2022 13:48:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/25/2022 13:48:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 13:48:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
05/25/2022 13:48:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 13:48:19 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9126461750117663 on epoch=196
05/25/2022 13:48:22 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/25/2022 13:48:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/25/2022 13:48:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 13:48:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 13:48:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 13:48:41 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9205474095796676 on epoch=199
05/25/2022 13:48:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 13:48:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 13:48:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
05/25/2022 13:48:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 13:48:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/25/2022 13:49:04 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=203
05/25/2022 13:49:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 13:49:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 13:49:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/25/2022 13:49:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 13:49:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/25/2022 13:49:27 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=207
05/25/2022 13:49:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 13:49:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 13:49:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 13:49:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 13:49:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/25/2022 13:49:49 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9819717916492109 on epoch=210
05/25/2022 13:49:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 13:49:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 13:49:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 13:50:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/25/2022 13:50:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 13:50:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:50:06 - INFO - __main__ - Printing 3 examples
05/25/2022 13:50:06 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 13:50:06 - INFO - __main__ - ['Plant']
05/25/2022 13:50:06 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 13:50:06 - INFO - __main__ - ['Plant']
05/25/2022 13:50:06 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 13:50:06 - INFO - __main__ - ['Plant']
05/25/2022 13:50:06 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:50:06 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:50:06 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 13:50:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:50:06 - INFO - __main__ - Printing 3 examples
05/25/2022 13:50:06 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 13:50:06 - INFO - __main__ - ['Plant']
05/25/2022 13:50:06 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 13:50:06 - INFO - __main__ - ['Plant']
05/25/2022 13:50:06 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 13:50:06 - INFO - __main__ - ['Plant']
05/25/2022 13:50:06 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:50:07 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:50:07 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 13:50:12 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9821297653958945 on epoch=214
05/25/2022 13:50:12 - INFO - __main__ - save last model!
05/25/2022 13:50:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 13:50:12 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 13:50:12 - INFO - __main__ - Printing 3 examples
05/25/2022 13:50:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 13:50:12 - INFO - __main__ - ['Animal']
05/25/2022 13:50:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 13:50:12 - INFO - __main__ - ['Animal']
05/25/2022 13:50:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 13:50:12 - INFO - __main__ - ['Village']
05/25/2022 13:50:12 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:50:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:50:17 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 13:50:22 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 13:50:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 13:50:23 - INFO - __main__ - Starting training!
05/25/2022 13:52:41 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/25/2022 13:52:41 - INFO - __main__ - Classification-F1 on test data: 0.7567
05/25/2022 13:52:41 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9910670646557743, test_performance=0.7567230623959815
05/25/2022 13:52:41 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/25/2022 13:52:42 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:52:42 - INFO - __main__ - Printing 3 examples
05/25/2022 13:52:42 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 13:52:42 - INFO - __main__ - ['Plant']
05/25/2022 13:52:42 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 13:52:42 - INFO - __main__ - ['Plant']
05/25/2022 13:52:42 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 13:52:42 - INFO - __main__ - ['Plant']
05/25/2022 13:52:42 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:52:42 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:52:43 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 13:52:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 13:52:43 - INFO - __main__ - Printing 3 examples
05/25/2022 13:52:43 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 13:52:43 - INFO - __main__ - ['Plant']
05/25/2022 13:52:43 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 13:52:43 - INFO - __main__ - ['Plant']
05/25/2022 13:52:43 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 13:52:43 - INFO - __main__ - ['Plant']
05/25/2022 13:52:43 - INFO - __main__ - Tokenizing Input ...
05/25/2022 13:52:43 - INFO - __main__ - Tokenizing Output ...
05/25/2022 13:52:43 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 13:53:01 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 13:53:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 13:53:02 - INFO - __main__ - Starting training!
05/25/2022 13:53:06 - INFO - __main__ - Step 10 Global step 10 Train loss 5.04 on epoch=0
05/25/2022 13:53:09 - INFO - __main__ - Step 20 Global step 20 Train loss 3.26 on epoch=1
05/25/2022 13:53:12 - INFO - __main__ - Step 30 Global step 30 Train loss 2.64 on epoch=2
05/25/2022 13:53:15 - INFO - __main__ - Step 40 Global step 40 Train loss 1.85 on epoch=2
05/25/2022 13:53:18 - INFO - __main__ - Step 50 Global step 50 Train loss 1.58 on epoch=3
05/25/2022 13:53:24 - INFO - __main__ - Global step 50 Train loss 2.88 Classification-F1 0.268403512619298 on epoch=3
05/25/2022 13:53:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.268403512619298 on epoch=3, global_step=50
05/25/2022 13:53:27 - INFO - __main__ - Step 60 Global step 60 Train loss 1.25 on epoch=4
05/25/2022 13:53:31 - INFO - __main__ - Step 70 Global step 70 Train loss 1.07 on epoch=4
05/25/2022 13:53:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=5
05/25/2022 13:53:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.73 on epoch=6
05/25/2022 13:53:40 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=7
05/25/2022 13:53:48 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.43944801397432975 on epoch=7
05/25/2022 13:53:48 - INFO - __main__ - Saving model with best Classification-F1: 0.268403512619298 -> 0.43944801397432975 on epoch=7, global_step=100
05/25/2022 13:53:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.71 on epoch=7
05/25/2022 13:53:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=8
05/25/2022 13:53:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.57 on epoch=9
05/25/2022 13:54:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.55 on epoch=9
05/25/2022 13:54:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.50 on epoch=10
05/25/2022 13:54:11 - INFO - __main__ - Global step 150 Train loss 0.58 Classification-F1 0.6808260484427758 on epoch=10
05/25/2022 13:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.43944801397432975 -> 0.6808260484427758 on epoch=10, global_step=150
05/25/2022 13:54:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.43 on epoch=11
05/25/2022 13:54:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=12
05/25/2022 13:54:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.44 on epoch=12
05/25/2022 13:54:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=13
05/25/2022 13:54:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=14
05/25/2022 13:54:35 - INFO - __main__ - Global step 200 Train loss 0.40 Classification-F1 0.5525973215053602 on epoch=14
05/25/2022 13:54:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=14
05/25/2022 13:54:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=15
05/25/2022 13:54:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=16
05/25/2022 13:54:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=17
05/25/2022 13:54:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=17
05/25/2022 13:54:58 - INFO - __main__ - Global step 250 Train loss 0.35 Classification-F1 0.7031670787640963 on epoch=17
05/25/2022 13:54:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6808260484427758 -> 0.7031670787640963 on epoch=17, global_step=250
05/25/2022 13:55:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=18
05/25/2022 13:55:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=19
05/25/2022 13:55:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=19
05/25/2022 13:55:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=20
05/25/2022 13:55:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=21
05/25/2022 13:55:21 - INFO - __main__ - Global step 300 Train loss 0.27 Classification-F1 0.7837597973284081 on epoch=21
05/25/2022 13:55:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7031670787640963 -> 0.7837597973284081 on epoch=21, global_step=300
05/25/2022 13:55:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=22
05/25/2022 13:55:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=22
05/25/2022 13:55:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=23
05/25/2022 13:55:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=24
05/25/2022 13:55:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=24
05/25/2022 13:55:45 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.8807327895462745 on epoch=24
05/25/2022 13:55:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7837597973284081 -> 0.8807327895462745 on epoch=24, global_step=350
05/25/2022 13:55:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=25
05/25/2022 13:55:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=26
05/25/2022 13:55:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=27
05/25/2022 13:55:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=27
05/25/2022 13:56:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=28
05/25/2022 13:56:09 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.8023248186448526 on epoch=28
05/25/2022 13:56:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
05/25/2022 13:56:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=29
05/25/2022 13:56:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=30
05/25/2022 13:56:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=31
05/25/2022 13:56:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=32
05/25/2022 13:56:31 - INFO - __main__ - Global step 450 Train loss 0.15 Classification-F1 0.6520801367313402 on epoch=32
05/25/2022 13:56:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=32
05/25/2022 13:56:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
05/25/2022 13:56:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=34
05/25/2022 13:56:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=34
05/25/2022 13:56:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=35
05/25/2022 13:56:54 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.5750886699095903 on epoch=35
05/25/2022 13:56:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=36
05/25/2022 13:57:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=37
05/25/2022 13:57:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=37
05/25/2022 13:57:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
05/25/2022 13:57:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
05/25/2022 13:57:16 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.7783093834956065 on epoch=39
05/25/2022 13:57:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
05/25/2022 13:57:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=40
05/25/2022 13:57:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=41
05/25/2022 13:57:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=42
05/25/2022 13:57:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
05/25/2022 13:57:39 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.7365317422466658 on epoch=42
05/25/2022 13:57:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=43
05/25/2022 13:57:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=44
05/25/2022 13:57:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=44
05/25/2022 13:57:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
05/25/2022 13:57:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
05/25/2022 13:58:02 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.693490406281625 on epoch=46
05/25/2022 13:58:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=47
05/25/2022 13:58:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
05/25/2022 13:58:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
05/25/2022 13:58:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=49
05/25/2022 13:58:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=49
05/25/2022 13:58:24 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.8046836815738025 on epoch=49
05/25/2022 13:58:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
05/25/2022 13:58:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
05/25/2022 13:58:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=52
05/25/2022 13:58:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
05/25/2022 13:58:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
05/25/2022 13:58:46 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.6835157126823793 on epoch=53
05/25/2022 13:58:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=54
05/25/2022 13:58:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
05/25/2022 13:58:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
05/25/2022 13:58:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=56
05/25/2022 13:59:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=57
05/25/2022 13:59:09 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.7463887676857874 on epoch=57
05/25/2022 13:59:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
05/25/2022 13:59:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
05/25/2022 13:59:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=59
05/25/2022 13:59:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=59
05/25/2022 13:59:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=60
05/25/2022 13:59:32 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6435694007925538 on epoch=60
05/25/2022 13:59:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
05/25/2022 13:59:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
05/25/2022 13:59:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
05/25/2022 13:59:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=63
05/25/2022 13:59:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
05/25/2022 13:59:54 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.6263873072022478 on epoch=64
05/25/2022 13:59:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
05/25/2022 14:00:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=65
05/25/2022 14:00:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
05/25/2022 14:00:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
05/25/2022 14:00:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
05/25/2022 14:00:16 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6249935689664042 on epoch=67
05/25/2022 14:00:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
05/25/2022 14:00:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
05/25/2022 14:00:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
05/25/2022 14:00:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
05/25/2022 14:00:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
05/25/2022 14:00:39 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7458524150794023 on epoch=71
05/25/2022 14:00:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
05/25/2022 14:00:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
05/25/2022 14:00:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
05/25/2022 14:00:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
05/25/2022 14:00:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
05/25/2022 14:01:01 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7573457535506871 on epoch=74
05/25/2022 14:01:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
05/25/2022 14:01:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
05/25/2022 14:01:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
05/25/2022 14:01:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
05/25/2022 14:01:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
05/25/2022 14:01:24 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.739362099621057 on epoch=78
05/25/2022 14:01:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
05/25/2022 14:01:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
05/25/2022 14:01:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/25/2022 14:01:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
05/25/2022 14:01:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
05/25/2022 14:01:46 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6126593105730226 on epoch=82
05/25/2022 14:01:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
05/25/2022 14:01:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
05/25/2022 14:01:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
05/25/2022 14:01:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=84
05/25/2022 14:02:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
05/25/2022 14:02:08 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6215737884905467 on epoch=85
05/25/2022 14:02:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
05/25/2022 14:02:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
05/25/2022 14:02:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
05/25/2022 14:02:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/25/2022 14:02:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
05/25/2022 14:02:32 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.8154913550830889 on epoch=89
05/25/2022 14:02:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
05/25/2022 14:02:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
05/25/2022 14:02:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
05/25/2022 14:02:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
05/25/2022 14:02:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/25/2022 14:02:54 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6168315237183318 on epoch=92
05/25/2022 14:02:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/25/2022 14:03:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
05/25/2022 14:03:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
05/25/2022 14:03:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 14:03:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
05/25/2022 14:03:16 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6773503403207705 on epoch=96
05/25/2022 14:03:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
05/25/2022 14:03:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/25/2022 14:03:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
05/25/2022 14:03:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
05/25/2022 14:03:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
05/25/2022 14:03:38 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.770937778520499 on epoch=99
05/25/2022 14:03:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
05/25/2022 14:03:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/25/2022 14:03:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/25/2022 14:03:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
05/25/2022 14:03:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
05/25/2022 14:04:00 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7472952998899702 on epoch=103
05/25/2022 14:04:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
05/25/2022 14:04:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/25/2022 14:04:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=105
05/25/2022 14:04:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/25/2022 14:04:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/25/2022 14:04:22 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6251532219274155 on epoch=107
05/25/2022 14:04:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/25/2022 14:04:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
05/25/2022 14:04:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/25/2022 14:04:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
05/25/2022 14:04:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/25/2022 14:04:44 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.5982002185038239 on epoch=110
05/25/2022 14:04:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
05/25/2022 14:04:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/25/2022 14:04:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/25/2022 14:04:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 14:04:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/25/2022 14:05:06 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7024053158198788 on epoch=114
05/25/2022 14:05:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/25/2022 14:05:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
05/25/2022 14:05:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 14:05:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/25/2022 14:05:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/25/2022 14:05:28 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6695402566370308 on epoch=117
05/25/2022 14:05:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/25/2022 14:05:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/25/2022 14:05:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 14:05:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/25/2022 14:05:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
05/25/2022 14:05:50 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7609269548771725 on epoch=121
05/25/2022 14:05:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 14:05:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/25/2022 14:05:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
05/25/2022 14:06:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/25/2022 14:06:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/25/2022 14:06:12 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8039795830355603 on epoch=124
05/25/2022 14:06:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 14:06:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
05/25/2022 14:06:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/25/2022 14:06:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
05/25/2022 14:06:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/25/2022 14:06:35 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9119084336131055 on epoch=128
05/25/2022 14:06:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8807327895462745 -> 0.9119084336131055 on epoch=128, global_step=1800
05/25/2022 14:06:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
05/25/2022 14:06:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/25/2022 14:06:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 14:06:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/25/2022 14:06:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/25/2022 14:06:57 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.756745643842418 on epoch=132
05/25/2022 14:07:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/25/2022 14:07:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 14:07:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/25/2022 14:07:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 14:07:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 14:07:19 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7936819663574882 on epoch=135
05/25/2022 14:07:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
05/25/2022 14:07:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
05/25/2022 14:07:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/25/2022 14:07:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/25/2022 14:07:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/25/2022 14:07:41 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6839614133207891 on epoch=139
05/25/2022 14:07:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
05/25/2022 14:07:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 14:07:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
05/25/2022 14:07:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/25/2022 14:07:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 14:08:03 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7067825205459614 on epoch=142
05/25/2022 14:08:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/25/2022 14:08:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
05/25/2022 14:08:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/25/2022 14:08:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/25/2022 14:08:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 14:08:25 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6776978253629133 on epoch=146
05/25/2022 14:08:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
05/25/2022 14:08:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
05/25/2022 14:08:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/25/2022 14:08:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 14:08:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
05/25/2022 14:08:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.644235563850772 on epoch=149
05/25/2022 14:08:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/25/2022 14:08:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 14:08:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/25/2022 14:09:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
05/25/2022 14:09:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 14:09:09 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7410279118794753 on epoch=153
05/25/2022 14:09:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=154
05/25/2022 14:09:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
05/25/2022 14:09:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
05/25/2022 14:09:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/25/2022 14:09:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
05/25/2022 14:09:31 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.793613502029389 on epoch=157
05/25/2022 14:09:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 14:09:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 14:09:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
05/25/2022 14:09:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 14:09:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
05/25/2022 14:09:53 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7064091848103069 on epoch=160
05/25/2022 14:09:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 14:09:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/25/2022 14:10:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
05/25/2022 14:10:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/25/2022 14:10:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 14:10:15 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6908948436962019 on epoch=164
05/25/2022 14:10:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/25/2022 14:10:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
05/25/2022 14:10:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 14:10:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/25/2022 14:10:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
05/25/2022 14:10:37 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7913999325987271 on epoch=167
05/25/2022 14:10:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/25/2022 14:10:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/25/2022 14:10:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/25/2022 14:10:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
05/25/2022 14:10:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 14:10:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6437587925645841 on epoch=171
05/25/2022 14:11:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/25/2022 14:11:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 14:11:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/25/2022 14:11:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 14:11:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
05/25/2022 14:11:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5867031074404346 on epoch=174
05/25/2022 14:11:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
05/25/2022 14:11:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 14:11:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/25/2022 14:11:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/25/2022 14:11:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/25/2022 14:11:44 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6518236910287245 on epoch=178
05/25/2022 14:11:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/25/2022 14:11:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 14:11:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 14:11:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
05/25/2022 14:11:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/25/2022 14:12:06 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6554454562603967 on epoch=182
05/25/2022 14:12:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/25/2022 14:12:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/25/2022 14:12:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/25/2022 14:12:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 14:12:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/25/2022 14:12:28 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.725858732399951 on epoch=185
05/25/2022 14:12:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 14:12:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 14:12:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/25/2022 14:12:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 14:12:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 14:12:50 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7931888106684402 on epoch=189
05/25/2022 14:12:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
05/25/2022 14:12:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/25/2022 14:12:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/25/2022 14:13:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/25/2022 14:13:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 14:13:12 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9119084336131053 on epoch=192
05/25/2022 14:13:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/25/2022 14:13:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/25/2022 14:13:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 14:13:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/25/2022 14:13:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/25/2022 14:13:34 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9186746497230367 on epoch=196
05/25/2022 14:13:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9119084336131055 -> 0.9186746497230367 on epoch=196, global_step=2750
05/25/2022 14:13:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 14:13:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/25/2022 14:13:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/25/2022 14:13:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/25/2022 14:13:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 14:13:56 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8549179749384839 on epoch=199
05/25/2022 14:14:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 14:14:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 14:14:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 14:14:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 14:14:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 14:14:20 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9228453893776475 on epoch=203
05/25/2022 14:14:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9186746497230367 -> 0.9228453893776475 on epoch=203, global_step=2850
05/25/2022 14:14:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 14:14:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 14:14:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 14:14:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 14:14:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 14:14:42 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9270120560443141 on epoch=207
05/25/2022 14:14:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9228453893776475 -> 0.9270120560443141 on epoch=207, global_step=2900
05/25/2022 14:14:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
05/25/2022 14:14:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/25/2022 14:14:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/25/2022 14:14:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 14:14:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/25/2022 14:15:04 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8487658846529815 on epoch=210
05/25/2022 14:15:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/25/2022 14:15:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 14:15:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/25/2022 14:15:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 14:15:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 14:15:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:15:21 - INFO - __main__ - Printing 3 examples
05/25/2022 14:15:21 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 14:15:21 - INFO - __main__ - ['Plant']
05/25/2022 14:15:21 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 14:15:21 - INFO - __main__ - ['Plant']
05/25/2022 14:15:21 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 14:15:21 - INFO - __main__ - ['Plant']
05/25/2022 14:15:21 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:15:21 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:15:21 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 14:15:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:15:21 - INFO - __main__ - Printing 3 examples
05/25/2022 14:15:21 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 14:15:21 - INFO - __main__ - ['Plant']
05/25/2022 14:15:21 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 14:15:21 - INFO - __main__ - ['Plant']
05/25/2022 14:15:21 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 14:15:21 - INFO - __main__ - ['Plant']
05/25/2022 14:15:21 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:15:21 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:15:22 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 14:15:26 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8066484692893892 on epoch=214
05/25/2022 14:15:26 - INFO - __main__ - save last model!
05/25/2022 14:15:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 14:15:26 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 14:15:26 - INFO - __main__ - Printing 3 examples
05/25/2022 14:15:26 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 14:15:26 - INFO - __main__ - ['Animal']
05/25/2022 14:15:26 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 14:15:26 - INFO - __main__ - ['Animal']
05/25/2022 14:15:26 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 14:15:26 - INFO - __main__ - ['Village']
05/25/2022 14:15:26 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:15:28 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:15:32 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 14:15:40 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 14:15:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 14:15:41 - INFO - __main__ - Starting training!
05/25/2022 14:17:53 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/25/2022 14:17:53 - INFO - __main__ - Classification-F1 on test data: 0.6469
05/25/2022 14:17:53 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9270120560443141, test_performance=0.6469497247131664
05/25/2022 14:17:53 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/25/2022 14:17:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:17:54 - INFO - __main__ - Printing 3 examples
05/25/2022 14:17:54 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 14:17:54 - INFO - __main__ - ['Plant']
05/25/2022 14:17:54 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 14:17:54 - INFO - __main__ - ['Plant']
05/25/2022 14:17:54 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 14:17:54 - INFO - __main__ - ['Plant']
05/25/2022 14:17:54 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:17:54 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:17:54 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 14:17:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:17:54 - INFO - __main__ - Printing 3 examples
05/25/2022 14:17:54 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 14:17:54 - INFO - __main__ - ['Plant']
05/25/2022 14:17:54 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 14:17:54 - INFO - __main__ - ['Plant']
05/25/2022 14:17:54 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 14:17:54 - INFO - __main__ - ['Plant']
05/25/2022 14:17:54 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:17:55 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:17:55 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 14:18:13 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 14:18:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 14:18:14 - INFO - __main__ - Starting training!
05/25/2022 14:18:18 - INFO - __main__ - Step 10 Global step 10 Train loss 5.47 on epoch=0
05/25/2022 14:18:21 - INFO - __main__ - Step 20 Global step 20 Train loss 3.85 on epoch=1
05/25/2022 14:18:24 - INFO - __main__ - Step 30 Global step 30 Train loss 3.30 on epoch=2
05/25/2022 14:18:27 - INFO - __main__ - Step 40 Global step 40 Train loss 2.59 on epoch=2
05/25/2022 14:18:30 - INFO - __main__ - Step 50 Global step 50 Train loss 2.12 on epoch=3
05/25/2022 14:18:34 - INFO - __main__ - Global step 50 Train loss 3.47 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 14:18:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 14:18:38 - INFO - __main__ - Step 60 Global step 60 Train loss 1.81 on epoch=4
05/25/2022 14:18:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.59 on epoch=4
05/25/2022 14:18:44 - INFO - __main__ - Step 80 Global step 80 Train loss 1.50 on epoch=5
05/25/2022 14:18:47 - INFO - __main__ - Step 90 Global step 90 Train loss 1.14 on epoch=6
05/25/2022 14:18:50 - INFO - __main__ - Step 100 Global step 100 Train loss 1.10 on epoch=7
05/25/2022 14:18:57 - INFO - __main__ - Global step 100 Train loss 1.43 Classification-F1 0.3483964338863255 on epoch=7
05/25/2022 14:18:57 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.3483964338863255 on epoch=7, global_step=100
05/25/2022 14:19:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.84 on epoch=7
05/25/2022 14:19:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=8
05/25/2022 14:19:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=9
05/25/2022 14:19:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=9
05/25/2022 14:19:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.66 on epoch=10
05/25/2022 14:19:19 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.545848597273982 on epoch=10
05/25/2022 14:19:19 - INFO - __main__ - Saving model with best Classification-F1: 0.3483964338863255 -> 0.545848597273982 on epoch=10, global_step=150
05/25/2022 14:19:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.57 on epoch=11
05/25/2022 14:19:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=12
05/25/2022 14:19:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.49 on epoch=12
05/25/2022 14:19:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=13
05/25/2022 14:19:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=14
05/25/2022 14:19:42 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.6490793602395579 on epoch=14
05/25/2022 14:19:42 - INFO - __main__ - Saving model with best Classification-F1: 0.545848597273982 -> 0.6490793602395579 on epoch=14, global_step=200
05/25/2022 14:19:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=14
05/25/2022 14:19:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=15
05/25/2022 14:19:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=16
05/25/2022 14:19:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=17
05/25/2022 14:19:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=17
05/25/2022 14:20:05 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.6184116435799651 on epoch=17
05/25/2022 14:20:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=18
05/25/2022 14:20:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=19
05/25/2022 14:20:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=19
05/25/2022 14:20:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=20
05/25/2022 14:20:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=21
05/25/2022 14:20:28 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.6802536078187994 on epoch=21
05/25/2022 14:20:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6490793602395579 -> 0.6802536078187994 on epoch=21, global_step=300
05/25/2022 14:20:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=22
05/25/2022 14:20:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.34 on epoch=22
05/25/2022 14:20:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=23
05/25/2022 14:20:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=24
05/25/2022 14:20:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=24
05/25/2022 14:20:51 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.9550744858060526 on epoch=24
05/25/2022 14:20:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6802536078187994 -> 0.9550744858060526 on epoch=24, global_step=350
05/25/2022 14:20:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
05/25/2022 14:20:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=26
05/25/2022 14:21:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=27
05/25/2022 14:21:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=27
05/25/2022 14:21:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=28
05/25/2022 14:21:14 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.8279381561440666 on epoch=28
05/25/2022 14:21:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=29
05/25/2022 14:21:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=29
05/25/2022 14:21:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=30
05/25/2022 14:21:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
05/25/2022 14:21:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=32
05/25/2022 14:21:37 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.87238471444802 on epoch=32
05/25/2022 14:21:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
05/25/2022 14:21:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=33
05/25/2022 14:21:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=34
05/25/2022 14:21:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.14 on epoch=34
05/25/2022 14:21:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=35
05/25/2022 14:22:00 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.7695861252391992 on epoch=35
05/25/2022 14:22:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=36
05/25/2022 14:22:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
05/25/2022 14:22:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
05/25/2022 14:22:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
05/25/2022 14:22:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
05/25/2022 14:22:23 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7317330802039398 on epoch=39
05/25/2022 14:22:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
05/25/2022 14:22:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=40
05/25/2022 14:22:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=41
05/25/2022 14:22:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=42
05/25/2022 14:22:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
05/25/2022 14:22:45 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6445003408701228 on epoch=42
05/25/2022 14:22:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
05/25/2022 14:22:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=44
05/25/2022 14:22:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
05/25/2022 14:22:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
05/25/2022 14:23:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=46
05/25/2022 14:23:07 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.6211768407096548 on epoch=46
05/25/2022 14:23:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
05/25/2022 14:23:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
05/25/2022 14:23:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
05/25/2022 14:23:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
05/25/2022 14:23:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=49
05/25/2022 14:23:29 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7501201001087178 on epoch=49
05/25/2022 14:23:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
05/25/2022 14:23:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
05/25/2022 14:23:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=52
05/25/2022 14:23:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=52
05/25/2022 14:23:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
05/25/2022 14:23:51 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.698516907723897 on epoch=53
05/25/2022 14:23:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=54
05/25/2022 14:23:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
05/25/2022 14:24:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
05/25/2022 14:24:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
05/25/2022 14:24:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=57
05/25/2022 14:24:14 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6489849734362502 on epoch=57
05/25/2022 14:24:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
05/25/2022 14:24:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
05/25/2022 14:24:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
05/25/2022 14:24:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=59
05/25/2022 14:24:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
05/25/2022 14:24:36 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7892743273869361 on epoch=60
05/25/2022 14:24:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
05/25/2022 14:24:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
05/25/2022 14:24:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
05/25/2022 14:24:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=63
05/25/2022 14:24:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
05/25/2022 14:24:59 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.6875750513603913 on epoch=64
05/25/2022 14:25:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
05/25/2022 14:25:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
05/25/2022 14:25:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
05/25/2022 14:25:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
05/25/2022 14:25:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
05/25/2022 14:25:21 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6948682696223824 on epoch=67
05/25/2022 14:25:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
05/25/2022 14:25:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
05/25/2022 14:25:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
05/25/2022 14:25:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
05/25/2022 14:25:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/25/2022 14:25:43 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7771951009142659 on epoch=71
05/25/2022 14:25:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
05/25/2022 14:25:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
05/25/2022 14:25:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
05/25/2022 14:25:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
05/25/2022 14:25:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
05/25/2022 14:26:07 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.9096423916585207 on epoch=74
05/25/2022 14:26:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
05/25/2022 14:26:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
05/25/2022 14:26:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
05/25/2022 14:26:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/25/2022 14:26:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
05/25/2022 14:26:29 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7190882978871094 on epoch=78
05/25/2022 14:26:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
05/25/2022 14:26:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
05/25/2022 14:26:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
05/25/2022 14:26:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
05/25/2022 14:26:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
05/25/2022 14:26:51 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.701282407073882 on epoch=82
05/25/2022 14:26:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
05/25/2022 14:26:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
05/25/2022 14:27:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
05/25/2022 14:27:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
05/25/2022 14:27:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
05/25/2022 14:27:14 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7603865201895597 on epoch=85
05/25/2022 14:27:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
05/25/2022 14:27:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
05/25/2022 14:27:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
05/25/2022 14:27:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
05/25/2022 14:27:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
05/25/2022 14:27:36 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6751422884663035 on epoch=89
05/25/2022 14:27:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
05/25/2022 14:27:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/25/2022 14:27:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
05/25/2022 14:27:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
05/25/2022 14:27:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/25/2022 14:27:58 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7764107871887758 on epoch=92
05/25/2022 14:28:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/25/2022 14:28:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
05/25/2022 14:28:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
05/25/2022 14:28:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
05/25/2022 14:28:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
05/25/2022 14:28:20 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.726080861094302 on epoch=96
05/25/2022 14:28:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
05/25/2022 14:28:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
05/25/2022 14:28:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
05/25/2022 14:28:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
05/25/2022 14:28:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
05/25/2022 14:28:41 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7499741245471796 on epoch=99
05/25/2022 14:28:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/25/2022 14:28:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/25/2022 14:28:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
05/25/2022 14:28:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/25/2022 14:28:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
05/25/2022 14:29:03 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7894059037960248 on epoch=103
05/25/2022 14:29:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
05/25/2022 14:29:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
05/25/2022 14:29:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
05/25/2022 14:29:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
05/25/2022 14:29:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
05/25/2022 14:29:25 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7480700379168401 on epoch=107
05/25/2022 14:29:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/25/2022 14:29:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/25/2022 14:29:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
05/25/2022 14:29:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
05/25/2022 14:29:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/25/2022 14:29:46 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7536936504231962 on epoch=110
05/25/2022 14:29:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
05/25/2022 14:29:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
05/25/2022 14:29:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
05/25/2022 14:29:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
05/25/2022 14:30:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
05/25/2022 14:30:08 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7666524427335373 on epoch=114
05/25/2022 14:30:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/25/2022 14:30:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
05/25/2022 14:30:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
05/25/2022 14:30:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
05/25/2022 14:30:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
05/25/2022 14:30:30 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7457683452168746 on epoch=117
05/25/2022 14:30:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/25/2022 14:30:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
05/25/2022 14:30:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/25/2022 14:30:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
05/25/2022 14:30:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
05/25/2022 14:30:52 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7116390737495801 on epoch=121
05/25/2022 14:30:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 14:30:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/25/2022 14:31:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/25/2022 14:31:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/25/2022 14:31:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/25/2022 14:31:14 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7959528875088647 on epoch=124
05/25/2022 14:31:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/25/2022 14:31:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
05/25/2022 14:31:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/25/2022 14:31:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/25/2022 14:31:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/25/2022 14:31:36 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7782869012707723 on epoch=128
05/25/2022 14:31:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
05/25/2022 14:31:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/25/2022 14:31:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/25/2022 14:31:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/25/2022 14:31:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
05/25/2022 14:31:57 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7639328342851264 on epoch=132
05/25/2022 14:32:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
05/25/2022 14:32:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 14:32:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/25/2022 14:32:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 14:32:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 14:32:20 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8097345931839027 on epoch=135
05/25/2022 14:32:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/25/2022 14:32:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
05/25/2022 14:32:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
05/25/2022 14:32:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/25/2022 14:32:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/25/2022 14:32:41 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8069167052528683 on epoch=139
05/25/2022 14:32:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.19 on epoch=139
05/25/2022 14:32:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/25/2022 14:32:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/25/2022 14:32:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/25/2022 14:32:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 14:33:03 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6861327503482286 on epoch=142
05/25/2022 14:33:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
05/25/2022 14:33:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
05/25/2022 14:33:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/25/2022 14:33:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/25/2022 14:33:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/25/2022 14:33:26 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7541455868443284 on epoch=146
05/25/2022 14:33:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 14:33:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/25/2022 14:33:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/25/2022 14:33:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/25/2022 14:33:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
05/25/2022 14:33:48 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7222359595627289 on epoch=149
05/25/2022 14:33:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
05/25/2022 14:33:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 14:33:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
05/25/2022 14:34:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/25/2022 14:34:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 14:34:10 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7839405358306568 on epoch=153
05/25/2022 14:34:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
05/25/2022 14:34:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 14:34:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/25/2022 14:34:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/25/2022 14:34:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/25/2022 14:34:31 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7850265842851263 on epoch=157
05/25/2022 14:34:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 14:34:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 14:34:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
05/25/2022 14:34:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/25/2022 14:34:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/25/2022 14:34:53 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7881292489926266 on epoch=160
05/25/2022 14:34:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 14:34:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/25/2022 14:35:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 14:35:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/25/2022 14:35:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 14:35:15 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8010999463323941 on epoch=164
05/25/2022 14:35:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/25/2022 14:35:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 14:35:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/25/2022 14:35:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/25/2022 14:35:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/25/2022 14:35:37 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7480700379168401 on epoch=167
05/25/2022 14:35:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/25/2022 14:35:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 14:35:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/25/2022 14:35:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
05/25/2022 14:35:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 14:35:58 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7702210989350209 on epoch=171
05/25/2022 14:36:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/25/2022 14:36:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/25/2022 14:36:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 14:36:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 14:36:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
05/25/2022 14:36:20 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8125119644020854 on epoch=174
05/25/2022 14:36:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/25/2022 14:36:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/25/2022 14:36:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/25/2022 14:36:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/25/2022 14:36:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/25/2022 14:36:42 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7872922776148582 on epoch=178
05/25/2022 14:36:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/25/2022 14:36:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 14:36:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 14:36:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
05/25/2022 14:36:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/25/2022 14:37:03 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8815994041800493 on epoch=182
05/25/2022 14:37:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/25/2022 14:37:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 14:37:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/25/2022 14:37:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/25/2022 14:37:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 14:37:25 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8382739531993534 on epoch=185
05/25/2022 14:37:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 14:37:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/25/2022 14:37:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/25/2022 14:37:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/25/2022 14:37:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 14:37:47 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8054502551582641 on epoch=189
05/25/2022 14:37:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
05/25/2022 14:37:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/25/2022 14:37:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/25/2022 14:37:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 14:38:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/25/2022 14:38:09 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8322912302751013 on epoch=192
05/25/2022 14:38:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/25/2022 14:38:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/25/2022 14:38:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/25/2022 14:38:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/25/2022 14:38:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
05/25/2022 14:38:30 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9092852488013778 on epoch=196
05/25/2022 14:38:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 14:38:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/25/2022 14:38:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 14:38:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 14:38:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 14:38:52 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.90276963180189 on epoch=199
05/25/2022 14:38:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/25/2022 14:38:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 14:39:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 14:39:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 14:39:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/25/2022 14:39:14 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8248838228676938 on epoch=203
05/25/2022 14:39:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 14:39:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 14:39:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 14:39:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 14:39:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 14:39:36 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.8458443438282148 on epoch=207
05/25/2022 14:39:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/25/2022 14:39:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/25/2022 14:39:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 14:39:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/25/2022 14:39:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 14:39:58 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7870872954350747 on epoch=210
05/25/2022 14:40:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 14:40:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 14:40:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/25/2022 14:40:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/25/2022 14:40:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 14:40:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:40:14 - INFO - __main__ - Printing 3 examples
05/25/2022 14:40:14 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 14:40:14 - INFO - __main__ - ['Plant']
05/25/2022 14:40:14 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 14:40:14 - INFO - __main__ - ['Plant']
05/25/2022 14:40:14 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 14:40:14 - INFO - __main__ - ['Plant']
05/25/2022 14:40:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:40:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:40:15 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 14:40:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:40:15 - INFO - __main__ - Printing 3 examples
05/25/2022 14:40:15 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 14:40:15 - INFO - __main__ - ['Plant']
05/25/2022 14:40:15 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 14:40:15 - INFO - __main__ - ['Plant']
05/25/2022 14:40:15 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 14:40:15 - INFO - __main__ - ['Plant']
05/25/2022 14:40:15 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:40:15 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:40:15 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 14:40:19 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7525031154956977 on epoch=214
05/25/2022 14:40:19 - INFO - __main__ - save last model!
05/25/2022 14:40:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 14:40:19 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 14:40:19 - INFO - __main__ - Printing 3 examples
05/25/2022 14:40:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 14:40:19 - INFO - __main__ - ['Animal']
05/25/2022 14:40:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 14:40:19 - INFO - __main__ - ['Animal']
05/25/2022 14:40:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 14:40:19 - INFO - __main__ - ['Village']
05/25/2022 14:40:19 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:40:21 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:40:25 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 14:40:33 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 14:40:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 14:40:34 - INFO - __main__ - Starting training!
05/25/2022 14:42:39 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/25/2022 14:42:39 - INFO - __main__ - Classification-F1 on test data: 0.6478
05/25/2022 14:42:39 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9550744858060526, test_performance=0.6477531438348674
05/25/2022 14:42:39 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/25/2022 14:42:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:42:40 - INFO - __main__ - Printing 3 examples
05/25/2022 14:42:40 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 14:42:40 - INFO - __main__ - ['Plant']
05/25/2022 14:42:40 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 14:42:40 - INFO - __main__ - ['Plant']
05/25/2022 14:42:40 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 14:42:40 - INFO - __main__ - ['Plant']
05/25/2022 14:42:40 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:42:41 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:42:41 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 14:42:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 14:42:41 - INFO - __main__ - Printing 3 examples
05/25/2022 14:42:41 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/25/2022 14:42:41 - INFO - __main__ - ['Plant']
05/25/2022 14:42:41 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
05/25/2022 14:42:41 - INFO - __main__ - ['Plant']
05/25/2022 14:42:41 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/25/2022 14:42:41 - INFO - __main__ - ['Plant']
05/25/2022 14:42:41 - INFO - __main__ - Tokenizing Input ...
05/25/2022 14:42:41 - INFO - __main__ - Tokenizing Output ...
05/25/2022 14:42:41 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 14:43:00 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 14:43:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 14:43:01 - INFO - __main__ - Starting training!
05/25/2022 14:43:05 - INFO - __main__ - Step 10 Global step 10 Train loss 5.81 on epoch=0
05/25/2022 14:43:08 - INFO - __main__ - Step 20 Global step 20 Train loss 4.60 on epoch=1
05/25/2022 14:43:11 - INFO - __main__ - Step 30 Global step 30 Train loss 3.70 on epoch=2
05/25/2022 14:43:14 - INFO - __main__ - Step 40 Global step 40 Train loss 3.17 on epoch=2
05/25/2022 14:43:17 - INFO - __main__ - Step 50 Global step 50 Train loss 2.68 on epoch=3
05/25/2022 14:43:21 - INFO - __main__ - Global step 50 Train loss 3.99 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 14:43:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 14:43:24 - INFO - __main__ - Step 60 Global step 60 Train loss 2.28 on epoch=4
05/25/2022 14:43:27 - INFO - __main__ - Step 70 Global step 70 Train loss 1.91 on epoch=4
05/25/2022 14:43:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.70 on epoch=5
05/25/2022 14:43:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.50 on epoch=6
05/25/2022 14:43:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.40 on epoch=7
05/25/2022 14:43:42 - INFO - __main__ - Global step 100 Train loss 1.76 Classification-F1 0.29425118801937605 on epoch=7
05/25/2022 14:43:42 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.29425118801937605 on epoch=7, global_step=100
05/25/2022 14:43:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.16 on epoch=7
05/25/2022 14:43:48 - INFO - __main__ - Step 120 Global step 120 Train loss 1.08 on epoch=8
05/25/2022 14:43:51 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=9
05/25/2022 14:43:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=9
05/25/2022 14:43:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=10
05/25/2022 14:44:04 - INFO - __main__ - Global step 150 Train loss 1.00 Classification-F1 0.4261995108854791 on epoch=10
05/25/2022 14:44:04 - INFO - __main__ - Saving model with best Classification-F1: 0.29425118801937605 -> 0.4261995108854791 on epoch=10, global_step=150
05/25/2022 14:44:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
05/25/2022 14:44:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=12
05/25/2022 14:44:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=12
05/25/2022 14:44:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.60 on epoch=13
05/25/2022 14:44:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
05/25/2022 14:44:27 - INFO - __main__ - Global step 200 Train loss 0.64 Classification-F1 0.5557481573489556 on epoch=14
05/25/2022 14:44:27 - INFO - __main__ - Saving model with best Classification-F1: 0.4261995108854791 -> 0.5557481573489556 on epoch=14, global_step=200
05/25/2022 14:44:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=14
05/25/2022 14:44:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=15
05/25/2022 14:44:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=16
05/25/2022 14:44:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=17
05/25/2022 14:44:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=17
05/25/2022 14:44:50 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.6577484353381778 on epoch=17
05/25/2022 14:44:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5557481573489556 -> 0.6577484353381778 on epoch=17, global_step=250
05/25/2022 14:44:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=18
05/25/2022 14:44:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=19
05/25/2022 14:44:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=19
05/25/2022 14:45:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=20
05/25/2022 14:45:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
05/25/2022 14:45:12 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.7263065697039374 on epoch=21
05/25/2022 14:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6577484353381778 -> 0.7263065697039374 on epoch=21, global_step=300
05/25/2022 14:45:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=22
05/25/2022 14:45:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=22
05/25/2022 14:45:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
05/25/2022 14:45:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=24
05/25/2022 14:45:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
05/25/2022 14:45:36 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.6815256263532125 on epoch=24
05/25/2022 14:45:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.38 on epoch=25
05/25/2022 14:45:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
05/25/2022 14:45:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=27
05/25/2022 14:45:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=27
05/25/2022 14:45:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
05/25/2022 14:45:59 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.8653710184721249 on epoch=28
05/25/2022 14:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7263065697039374 -> 0.8653710184721249 on epoch=28, global_step=400
05/25/2022 14:46:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=29
05/25/2022 14:46:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=29
05/25/2022 14:46:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=30
05/25/2022 14:46:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=31
05/25/2022 14:46:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=32
05/25/2022 14:46:23 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.7762478647273747 on epoch=32
05/25/2022 14:46:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=32
05/25/2022 14:46:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=33
05/25/2022 14:46:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
05/25/2022 14:46:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
05/25/2022 14:46:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
05/25/2022 14:46:47 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.771816898792614 on epoch=35
05/25/2022 14:46:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
05/25/2022 14:46:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
05/25/2022 14:46:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
05/25/2022 14:46:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
05/25/2022 14:47:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
05/25/2022 14:47:10 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.777030884555258 on epoch=39
05/25/2022 14:47:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
05/25/2022 14:47:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=40
05/25/2022 14:47:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=41
05/25/2022 14:47:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
05/25/2022 14:47:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
05/25/2022 14:47:34 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.6719240366311673 on epoch=42
05/25/2022 14:47:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
05/25/2022 14:47:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
05/25/2022 14:47:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=44
05/25/2022 14:47:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
05/25/2022 14:47:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=46
05/25/2022 14:47:57 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.649234641778645 on epoch=46
05/25/2022 14:48:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
05/25/2022 14:48:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
05/25/2022 14:48:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
05/25/2022 14:48:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
05/25/2022 14:48:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
05/25/2022 14:48:21 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7112444880022891 on epoch=49
05/25/2022 14:48:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
05/25/2022 14:48:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
05/25/2022 14:48:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
05/25/2022 14:48:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
05/25/2022 14:48:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
05/25/2022 14:48:45 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6675378285285406 on epoch=53
05/25/2022 14:48:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
05/25/2022 14:48:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
05/25/2022 14:48:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
05/25/2022 14:48:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
05/25/2022 14:49:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
05/25/2022 14:49:08 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.836241742038113 on epoch=57
05/25/2022 14:49:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=57
05/25/2022 14:49:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
05/25/2022 14:49:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
05/25/2022 14:49:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
05/25/2022 14:49:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
05/25/2022 14:49:32 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6986333111333112 on epoch=60
05/25/2022 14:49:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
05/25/2022 14:49:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
05/25/2022 14:49:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
05/25/2022 14:49:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
05/25/2022 14:49:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
05/25/2022 14:49:54 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6031337172656475 on epoch=64
05/25/2022 14:49:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
05/25/2022 14:50:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
05/25/2022 14:50:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
05/25/2022 14:50:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
05/25/2022 14:50:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
05/25/2022 14:50:18 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.8492598991576104 on epoch=67
05/25/2022 14:50:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
05/25/2022 14:50:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
05/25/2022 14:50:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
05/25/2022 14:50:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=70
05/25/2022 14:50:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
05/25/2022 14:50:41 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7330050013782328 on epoch=71
05/25/2022 14:50:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
05/25/2022 14:50:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
05/25/2022 14:50:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
05/25/2022 14:50:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
05/25/2022 14:50:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
05/25/2022 14:51:05 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.9144793763057522 on epoch=74
05/25/2022 14:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8653710184721249 -> 0.9144793763057522 on epoch=74, global_step=1050
05/25/2022 14:51:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=75
05/25/2022 14:51:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
05/25/2022 14:51:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=77
05/25/2022 14:51:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
05/25/2022 14:51:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
05/25/2022 14:51:28 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8511324422014594 on epoch=78
05/25/2022 14:51:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
05/25/2022 14:51:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
05/25/2022 14:51:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
05/25/2022 14:51:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
05/25/2022 14:51:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
05/25/2022 14:51:51 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6564154844910403 on epoch=82
05/25/2022 14:51:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
05/25/2022 14:51:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=83
05/25/2022 14:52:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
05/25/2022 14:52:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
05/25/2022 14:52:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
05/25/2022 14:52:14 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6567038607386155 on epoch=85
05/25/2022 14:52:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
05/25/2022 14:52:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
05/25/2022 14:52:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
05/25/2022 14:52:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
05/25/2022 14:52:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
05/25/2022 14:52:37 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7136480007447751 on epoch=89
05/25/2022 14:52:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
05/25/2022 14:52:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
05/25/2022 14:52:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
05/25/2022 14:52:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
05/25/2022 14:52:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/25/2022 14:53:00 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7290434468019856 on epoch=92
05/25/2022 14:53:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/25/2022 14:53:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
05/25/2022 14:53:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/25/2022 14:53:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
05/25/2022 14:53:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
05/25/2022 14:53:23 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8591069464809384 on epoch=96
05/25/2022 14:53:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
05/25/2022 14:53:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
05/25/2022 14:53:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
05/25/2022 14:53:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
05/25/2022 14:53:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/25/2022 14:53:45 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7334670631041598 on epoch=99
05/25/2022 14:53:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/25/2022 14:53:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
05/25/2022 14:53:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/25/2022 14:53:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
05/25/2022 14:54:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
05/25/2022 14:54:08 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7086293896198419 on epoch=103
05/25/2022 14:54:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
05/25/2022 14:54:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/25/2022 14:54:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/25/2022 14:54:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/25/2022 14:54:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
05/25/2022 14:54:30 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8007697947214076 on epoch=107
05/25/2022 14:54:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
05/25/2022 14:54:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/25/2022 14:54:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
05/25/2022 14:54:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/25/2022 14:54:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/25/2022 14:54:52 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8205348415025835 on epoch=110
05/25/2022 14:54:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
05/25/2022 14:54:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/25/2022 14:55:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/25/2022 14:55:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
05/25/2022 14:55:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
05/25/2022 14:55:15 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8669245267347734 on epoch=114
05/25/2022 14:55:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/25/2022 14:55:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/25/2022 14:55:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
05/25/2022 14:55:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/25/2022 14:55:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/25/2022 14:55:37 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8456826327794069 on epoch=117
05/25/2022 14:55:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
05/25/2022 14:55:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
05/25/2022 14:55:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/25/2022 14:55:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/25/2022 14:55:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
05/25/2022 14:56:00 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8731400021722602 on epoch=121
05/25/2022 14:56:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 14:56:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
05/25/2022 14:56:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
05/25/2022 14:56:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
05/25/2022 14:56:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/25/2022 14:56:23 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7499639773107795 on epoch=124
05/25/2022 14:56:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
05/25/2022 14:56:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
05/25/2022 14:56:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/25/2022 14:56:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
05/25/2022 14:56:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/25/2022 14:56:46 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.847655062045183 on epoch=128
05/25/2022 14:56:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/25/2022 14:56:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/25/2022 14:56:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/25/2022 14:56:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
05/25/2022 14:57:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/25/2022 14:57:09 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7646435013270627 on epoch=132
05/25/2022 14:57:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
05/25/2022 14:57:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
05/25/2022 14:57:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 14:57:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
05/25/2022 14:57:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/25/2022 14:57:31 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8766258409522166 on epoch=135
05/25/2022 14:57:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/25/2022 14:57:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/25/2022 14:57:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
05/25/2022 14:57:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
05/25/2022 14:57:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/25/2022 14:57:53 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8065980118726124 on epoch=139
05/25/2022 14:57:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 14:57:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/25/2022 14:58:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/25/2022 14:58:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
05/25/2022 14:58:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/25/2022 14:58:16 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7685180503589848 on epoch=142
05/25/2022 14:58:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
05/25/2022 14:58:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/25/2022 14:58:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/25/2022 14:58:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 14:58:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/25/2022 14:58:39 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7548891921785101 on epoch=146
05/25/2022 14:58:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
05/25/2022 14:58:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/25/2022 14:58:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/25/2022 14:58:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/25/2022 14:58:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/25/2022 14:59:02 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8830904874168631 on epoch=149
05/25/2022 14:59:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/25/2022 14:59:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 14:59:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 14:59:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/25/2022 14:59:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 14:59:25 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.821413734115347 on epoch=153
05/25/2022 14:59:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/25/2022 14:59:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/25/2022 14:59:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/25/2022 14:59:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/25/2022 14:59:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/25/2022 14:59:47 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8817207792207792 on epoch=157
05/25/2022 14:59:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 14:59:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/25/2022 14:59:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/25/2022 15:00:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/25/2022 15:00:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/25/2022 15:00:09 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.869007177033493 on epoch=160
05/25/2022 15:00:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
05/25/2022 15:00:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/25/2022 15:00:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/25/2022 15:00:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/25/2022 15:00:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/25/2022 15:00:32 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9022755331088665 on epoch=164
05/25/2022 15:00:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
05/25/2022 15:00:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/25/2022 15:00:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/25/2022 15:00:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/25/2022 15:00:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 15:00:54 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9023401266665023 on epoch=167
05/25/2022 15:00:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
05/25/2022 15:01:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
05/25/2022 15:01:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/25/2022 15:01:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 15:01:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 15:01:16 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8670678959104007 on epoch=171
05/25/2022 15:01:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/25/2022 15:01:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/25/2022 15:01:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/25/2022 15:01:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 15:01:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/25/2022 15:01:39 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8286415785155705 on epoch=174
05/25/2022 15:01:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/25/2022 15:01:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 15:01:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/25/2022 15:01:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/25/2022 15:01:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/25/2022 15:02:02 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8199466049249612 on epoch=178
05/25/2022 15:02:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/25/2022 15:02:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 15:02:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
05/25/2022 15:02:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/25/2022 15:02:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
05/25/2022 15:02:25 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8591069464809384 on epoch=182
05/25/2022 15:02:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/25/2022 15:02:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 15:02:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
05/25/2022 15:02:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/25/2022 15:02:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/25/2022 15:02:48 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7516416537289402 on epoch=185
05/25/2022 15:02:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 15:02:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 15:02:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/25/2022 15:03:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/25/2022 15:03:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 15:03:11 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7988796737536656 on epoch=189
05/25/2022 15:03:14 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 15:03:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/25/2022 15:03:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/25/2022 15:03:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 15:03:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/25/2022 15:03:34 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8086018959758879 on epoch=192
05/25/2022 15:03:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 15:03:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
05/25/2022 15:03:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 15:03:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 15:03:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 15:03:56 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8126404991692618 on epoch=196
05/25/2022 15:03:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/25/2022 15:04:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/25/2022 15:04:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/25/2022 15:04:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/25/2022 15:04:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/25/2022 15:04:19 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7989910819533093 on epoch=199
05/25/2022 15:04:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/25/2022 15:04:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 15:04:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/25/2022 15:04:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 15:04:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 15:04:41 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8433400824382123 on epoch=203
05/25/2022 15:04:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/25/2022 15:04:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 15:04:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
05/25/2022 15:04:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/25/2022 15:04:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 15:05:04 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.849545183012925 on epoch=207
05/25/2022 15:05:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/25/2022 15:05:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/25/2022 15:05:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.08 on epoch=209
05/25/2022 15:05:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/25/2022 15:05:20 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
05/25/2022 15:05:27 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9186460429724188 on epoch=210
05/25/2022 15:05:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9144793763057522 -> 0.9186460429724188 on epoch=210, global_step=2950
05/25/2022 15:05:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/25/2022 15:05:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 15:05:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
05/25/2022 15:05:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/25/2022 15:05:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 15:05:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:05:44 - INFO - __main__ - Printing 3 examples
05/25/2022 15:05:44 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 15:05:44 - INFO - __main__ - ['Company']
05/25/2022 15:05:44 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 15:05:44 - INFO - __main__ - ['Company']
05/25/2022 15:05:44 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 15:05:44 - INFO - __main__ - ['Company']
05/25/2022 15:05:44 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:05:44 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:05:44 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 15:05:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:05:44 - INFO - __main__ - Printing 3 examples
05/25/2022 15:05:44 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 15:05:44 - INFO - __main__ - ['Company']
05/25/2022 15:05:44 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 15:05:44 - INFO - __main__ - ['Company']
05/25/2022 15:05:44 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 15:05:44 - INFO - __main__ - ['Company']
05/25/2022 15:05:44 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:05:44 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:05:44 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 15:05:50 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9064306995742797 on epoch=214
05/25/2022 15:05:50 - INFO - __main__ - save last model!
05/25/2022 15:05:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 15:05:50 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 15:05:50 - INFO - __main__ - Printing 3 examples
05/25/2022 15:05:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 15:05:50 - INFO - __main__ - ['Animal']
05/25/2022 15:05:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 15:05:50 - INFO - __main__ - ['Animal']
05/25/2022 15:05:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 15:05:50 - INFO - __main__ - ['Village']
05/25/2022 15:05:50 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:05:52 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:05:55 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 15:06:03 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 15:06:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 15:06:04 - INFO - __main__ - Starting training!
05/25/2022 15:08:13 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/25/2022 15:08:13 - INFO - __main__ - Classification-F1 on test data: 0.6149
05/25/2022 15:08:13 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9186460429724188, test_performance=0.6149053217364862
05/25/2022 15:08:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/25/2022 15:08:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:08:14 - INFO - __main__ - Printing 3 examples
05/25/2022 15:08:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 15:08:14 - INFO - __main__ - ['Company']
05/25/2022 15:08:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 15:08:14 - INFO - __main__ - ['Company']
05/25/2022 15:08:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 15:08:14 - INFO - __main__ - ['Company']
05/25/2022 15:08:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:08:15 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:08:15 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 15:08:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:08:15 - INFO - __main__ - Printing 3 examples
05/25/2022 15:08:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 15:08:15 - INFO - __main__ - ['Company']
05/25/2022 15:08:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 15:08:15 - INFO - __main__ - ['Company']
05/25/2022 15:08:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 15:08:15 - INFO - __main__ - ['Company']
05/25/2022 15:08:15 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:08:15 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:08:15 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 15:08:31 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 15:08:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 15:08:31 - INFO - __main__ - Starting training!
05/25/2022 15:08:35 - INFO - __main__ - Step 10 Global step 10 Train loss 4.85 on epoch=0
05/25/2022 15:08:38 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=1
05/25/2022 15:08:41 - INFO - __main__ - Step 30 Global step 30 Train loss 2.39 on epoch=2
05/25/2022 15:08:44 - INFO - __main__ - Step 40 Global step 40 Train loss 1.72 on epoch=2
05/25/2022 15:08:47 - INFO - __main__ - Step 50 Global step 50 Train loss 1.65 on epoch=3
05/25/2022 15:08:53 - INFO - __main__ - Global step 50 Train loss 2.80 Classification-F1 0.33413621410007494 on epoch=3
05/25/2022 15:08:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.33413621410007494 on epoch=3, global_step=50
05/25/2022 15:08:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.67 on epoch=4
05/25/2022 15:08:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.48 on epoch=4
05/25/2022 15:09:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.25 on epoch=5
05/25/2022 15:09:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.16 on epoch=6
05/25/2022 15:09:08 - INFO - __main__ - Step 100 Global step 100 Train loss 1.14 on epoch=7
05/25/2022 15:09:14 - INFO - __main__ - Global step 100 Train loss 1.34 Classification-F1 0.3173942383971132 on epoch=7
05/25/2022 15:09:17 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=7
05/25/2022 15:09:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.97 on epoch=8
05/25/2022 15:09:23 - INFO - __main__ - Step 130 Global step 130 Train loss 1.02 on epoch=9
05/25/2022 15:09:26 - INFO - __main__ - Step 140 Global step 140 Train loss 1.01 on epoch=9
05/25/2022 15:09:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=10
05/25/2022 15:09:38 - INFO - __main__ - Global step 150 Train loss 0.98 Classification-F1 0.3869641811868702 on epoch=10
05/25/2022 15:09:38 - INFO - __main__ - Saving model with best Classification-F1: 0.33413621410007494 -> 0.3869641811868702 on epoch=10, global_step=150
05/25/2022 15:09:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=11
05/25/2022 15:09:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.86 on epoch=12
05/25/2022 15:09:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=12
05/25/2022 15:09:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.71 on epoch=13
05/25/2022 15:09:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=14
05/25/2022 15:10:00 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.5245043619005582 on epoch=14
05/25/2022 15:10:00 - INFO - __main__ - Saving model with best Classification-F1: 0.3869641811868702 -> 0.5245043619005582 on epoch=14, global_step=200
05/25/2022 15:10:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=14
05/25/2022 15:10:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.65 on epoch=15
05/25/2022 15:10:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=16
05/25/2022 15:10:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=17
05/25/2022 15:10:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=17
05/25/2022 15:10:24 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.5068317291228042 on epoch=17
05/25/2022 15:10:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=18
05/25/2022 15:10:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=19
05/25/2022 15:10:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=19
05/25/2022 15:10:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=20
05/25/2022 15:10:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.54 on epoch=21
05/25/2022 15:10:47 - INFO - __main__ - Global step 300 Train loss 0.56 Classification-F1 0.5429123002849829 on epoch=21
05/25/2022 15:10:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5245043619005582 -> 0.5429123002849829 on epoch=21, global_step=300
05/25/2022 15:10:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=22
05/25/2022 15:10:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=22
05/25/2022 15:10:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
05/25/2022 15:10:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=24
05/25/2022 15:11:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=24
05/25/2022 15:11:10 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.7004135679130246 on epoch=24
05/25/2022 15:11:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5429123002849829 -> 0.7004135679130246 on epoch=24, global_step=350
05/25/2022 15:11:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=25
05/25/2022 15:11:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=26
05/25/2022 15:11:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=27
05/25/2022 15:11:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.55 on epoch=27
05/25/2022 15:11:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=28
05/25/2022 15:11:35 - INFO - __main__ - Global step 400 Train loss 0.48 Classification-F1 0.6762961323434882 on epoch=28
05/25/2022 15:11:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=29
05/25/2022 15:11:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=29
05/25/2022 15:11:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.41 on epoch=30
05/25/2022 15:11:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=31
05/25/2022 15:11:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=32
05/25/2022 15:11:57 - INFO - __main__ - Global step 450 Train loss 0.41 Classification-F1 0.6268799017124723 on epoch=32
05/25/2022 15:12:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=32
05/25/2022 15:12:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=33
05/25/2022 15:12:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
05/25/2022 15:12:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=34
05/25/2022 15:12:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=35
05/25/2022 15:12:21 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.6943060724376003 on epoch=35
05/25/2022 15:12:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
05/25/2022 15:12:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
05/25/2022 15:12:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=37
05/25/2022 15:12:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=38
05/25/2022 15:12:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=39
05/25/2022 15:12:44 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.674911897499238 on epoch=39
05/25/2022 15:12:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=39
05/25/2022 15:12:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=40
05/25/2022 15:12:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
05/25/2022 15:12:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
05/25/2022 15:12:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=42
05/25/2022 15:13:08 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.7333083359746972 on epoch=42
05/25/2022 15:13:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7004135679130246 -> 0.7333083359746972 on epoch=42, global_step=600
05/25/2022 15:13:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=43
05/25/2022 15:13:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=44
05/25/2022 15:13:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
05/25/2022 15:13:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=45
05/25/2022 15:13:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
05/25/2022 15:13:33 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.7953253912546918 on epoch=46
05/25/2022 15:13:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7333083359746972 -> 0.7953253912546918 on epoch=46, global_step=650
05/25/2022 15:13:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=47
05/25/2022 15:13:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=47
05/25/2022 15:13:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=48
05/25/2022 15:13:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=49
05/25/2022 15:13:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
05/25/2022 15:13:57 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.8979830042038051 on epoch=49
05/25/2022 15:13:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7953253912546918 -> 0.8979830042038051 on epoch=49, global_step=700
05/25/2022 15:14:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=50
05/25/2022 15:14:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=51
05/25/2022 15:14:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
05/25/2022 15:14:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=52
05/25/2022 15:14:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
05/25/2022 15:14:21 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.9687942038985682 on epoch=53
05/25/2022 15:14:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8979830042038051 -> 0.9687942038985682 on epoch=53, global_step=750
05/25/2022 15:14:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=54
05/25/2022 15:14:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
05/25/2022 15:14:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
05/25/2022 15:14:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
05/25/2022 15:14:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
05/25/2022 15:14:45 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.8432470919118276 on epoch=57
05/25/2022 15:14:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
05/25/2022 15:14:51 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
05/25/2022 15:14:54 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
05/25/2022 15:14:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
05/25/2022 15:15:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
05/25/2022 15:15:09 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.8254315912582042 on epoch=60
05/25/2022 15:15:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
05/25/2022 15:15:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
05/25/2022 15:15:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
05/25/2022 15:15:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
05/25/2022 15:15:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
05/25/2022 15:15:31 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.7799566732079466 on epoch=64
05/25/2022 15:15:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
05/25/2022 15:15:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
05/25/2022 15:15:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=66
05/25/2022 15:15:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
05/25/2022 15:15:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=67
05/25/2022 15:15:54 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7239485895247199 on epoch=67
05/25/2022 15:15:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
05/25/2022 15:16:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
05/25/2022 15:16:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
05/25/2022 15:16:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
05/25/2022 15:16:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
05/25/2022 15:16:17 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6421111086845632 on epoch=71
05/25/2022 15:16:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
05/25/2022 15:16:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
05/25/2022 15:16:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
05/25/2022 15:16:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
05/25/2022 15:16:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=74
05/25/2022 15:16:40 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.5997476778264254 on epoch=74
05/25/2022 15:16:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=75
05/25/2022 15:16:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
05/25/2022 15:16:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
05/25/2022 15:16:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
05/25/2022 15:16:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
05/25/2022 15:17:04 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6913880339283565 on epoch=78
05/25/2022 15:17:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
05/25/2022 15:17:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
05/25/2022 15:17:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
05/25/2022 15:17:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
05/25/2022 15:17:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
05/25/2022 15:17:28 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.6252471584919403 on epoch=82
05/25/2022 15:17:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
05/25/2022 15:17:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
05/25/2022 15:17:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
05/25/2022 15:17:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
05/25/2022 15:17:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
05/25/2022 15:17:51 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8650741082047885 on epoch=85
05/25/2022 15:17:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
05/25/2022 15:17:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
05/25/2022 15:18:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
05/25/2022 15:18:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
05/25/2022 15:18:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
05/25/2022 15:18:15 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7971989362030585 on epoch=89
05/25/2022 15:18:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
05/25/2022 15:18:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
05/25/2022 15:18:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
05/25/2022 15:18:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
05/25/2022 15:18:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
05/25/2022 15:18:38 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.914360540892799 on epoch=92
05/25/2022 15:18:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
05/25/2022 15:18:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/25/2022 15:18:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/25/2022 15:18:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
05/25/2022 15:18:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
05/25/2022 15:19:02 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9820991153059465 on epoch=96
05/25/2022 15:19:02 - INFO - __main__ - Saving model with best Classification-F1: 0.9687942038985682 -> 0.9820991153059465 on epoch=96, global_step=1350
05/25/2022 15:19:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
05/25/2022 15:19:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
05/25/2022 15:19:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
05/25/2022 15:19:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
05/25/2022 15:19:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
05/25/2022 15:19:25 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.830014065794181 on epoch=99
05/25/2022 15:19:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
05/25/2022 15:19:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/25/2022 15:19:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/25/2022 15:19:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/25/2022 15:19:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
05/25/2022 15:19:47 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7440169419652796 on epoch=103
05/25/2022 15:19:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
05/25/2022 15:19:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/25/2022 15:19:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/25/2022 15:19:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/25/2022 15:20:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
05/25/2022 15:20:10 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9147027882511752 on epoch=107
05/25/2022 15:20:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/25/2022 15:20:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
05/25/2022 15:20:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=109
05/25/2022 15:20:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=109
05/25/2022 15:20:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/25/2022 15:20:33 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8065551147145075 on epoch=110
05/25/2022 15:20:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
05/25/2022 15:20:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/25/2022 15:20:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
05/25/2022 15:20:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
05/25/2022 15:20:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
05/25/2022 15:20:56 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8043914906441898 on epoch=114
05/25/2022 15:20:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/25/2022 15:21:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/25/2022 15:21:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/25/2022 15:21:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/25/2022 15:21:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
05/25/2022 15:21:19 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8430241613279956 on epoch=117
05/25/2022 15:21:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/25/2022 15:21:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
05/25/2022 15:21:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
05/25/2022 15:21:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
05/25/2022 15:21:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/25/2022 15:21:42 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.8027485480995916 on epoch=121
05/25/2022 15:21:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
05/25/2022 15:21:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/25/2022 15:21:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
05/25/2022 15:21:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
05/25/2022 15:21:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/25/2022 15:22:05 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8003346955123438 on epoch=124
05/25/2022 15:22:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/25/2022 15:22:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
05/25/2022 15:22:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/25/2022 15:22:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 15:22:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/25/2022 15:22:27 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8523250942605782 on epoch=128
05/25/2022 15:22:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/25/2022 15:22:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/25/2022 15:22:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/25/2022 15:22:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
05/25/2022 15:22:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/25/2022 15:22:49 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=132
05/25/2022 15:22:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
05/25/2022 15:22:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
05/25/2022 15:22:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/25/2022 15:23:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 15:23:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
05/25/2022 15:23:12 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8093625942149424 on epoch=135
05/25/2022 15:23:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/25/2022 15:23:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
05/25/2022 15:23:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/25/2022 15:23:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/25/2022 15:23:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
05/25/2022 15:23:34 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7529844713458956 on epoch=139
05/25/2022 15:23:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 15:23:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 15:23:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
05/25/2022 15:23:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/25/2022 15:23:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
05/25/2022 15:23:57 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8028419026744733 on epoch=142
05/25/2022 15:24:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
05/25/2022 15:24:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
05/25/2022 15:24:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
05/25/2022 15:24:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 15:24:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 15:24:19 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8066701167270428 on epoch=146
05/25/2022 15:24:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/25/2022 15:24:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/25/2022 15:24:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/25/2022 15:24:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 15:24:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
05/25/2022 15:24:42 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=149
05/25/2022 15:24:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9820991153059465 -> 0.9821254014802402 on epoch=149, global_step=2100
05/25/2022 15:24:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/25/2022 15:24:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/25/2022 15:24:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/25/2022 15:24:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/25/2022 15:24:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
05/25/2022 15:25:04 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=153
05/25/2022 15:25:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/25/2022 15:25:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/25/2022 15:25:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 15:25:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/25/2022 15:25:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/25/2022 15:25:27 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9029558255364705 on epoch=157
05/25/2022 15:25:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 15:25:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 15:25:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/25/2022 15:25:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/25/2022 15:25:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/25/2022 15:25:50 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8309506353861192 on epoch=160
05/25/2022 15:25:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 15:25:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
05/25/2022 15:25:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 15:26:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
05/25/2022 15:26:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/25/2022 15:26:13 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8009558696688958 on epoch=164
05/25/2022 15:26:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/25/2022 15:26:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 15:26:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/25/2022 15:26:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/25/2022 15:26:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 15:26:35 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8029684048882622 on epoch=167
05/25/2022 15:26:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
05/25/2022 15:26:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 15:26:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/25/2022 15:26:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 15:26:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/25/2022 15:26:58 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8562121622842686 on epoch=171
05/25/2022 15:27:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
05/25/2022 15:27:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 15:27:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/25/2022 15:27:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 15:27:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/25/2022 15:27:21 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8452302034059542 on epoch=174
05/25/2022 15:27:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 15:27:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/25/2022 15:27:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 15:27:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 15:27:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/25/2022 15:27:43 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9163766699250571 on epoch=178
05/25/2022 15:27:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.24 on epoch=179
05/25/2022 15:27:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
05/25/2022 15:27:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/25/2022 15:27:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 15:27:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
05/25/2022 15:28:06 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.7088103406888986 on epoch=182
05/25/2022 15:28:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/25/2022 15:28:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 15:28:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/25/2022 15:28:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 15:28:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/25/2022 15:28:28 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6848593461496688 on epoch=185
05/25/2022 15:28:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 15:28:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/25/2022 15:28:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/25/2022 15:28:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/25/2022 15:28:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 15:28:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7840400593565008 on epoch=189
05/25/2022 15:28:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
05/25/2022 15:28:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/25/2022 15:29:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/25/2022 15:29:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 15:29:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/25/2022 15:29:14 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.881848575207209 on epoch=192
05/25/2022 15:29:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 15:29:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/25/2022 15:29:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 15:29:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 15:29:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/25/2022 15:29:36 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7875737825411944 on epoch=196
05/25/2022 15:29:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 15:29:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/25/2022 15:29:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/25/2022 15:29:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 15:29:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 15:29:59 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8463465298142717 on epoch=199
05/25/2022 15:30:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 15:30:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 15:30:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 15:30:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 15:30:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 15:30:21 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7893563137354903 on epoch=203
05/25/2022 15:30:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/25/2022 15:30:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 15:30:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 15:30:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 15:30:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
05/25/2022 15:30:43 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7855284342475994 on epoch=207
05/25/2022 15:30:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/25/2022 15:30:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 15:30:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 15:30:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/25/2022 15:30:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/25/2022 15:31:06 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7950771951009143 on epoch=210
05/25/2022 15:31:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
05/25/2022 15:31:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 15:31:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 15:31:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/25/2022 15:31:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 15:31:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:31:23 - INFO - __main__ - Printing 3 examples
05/25/2022 15:31:23 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 15:31:23 - INFO - __main__ - ['Company']
05/25/2022 15:31:23 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 15:31:23 - INFO - __main__ - ['Company']
05/25/2022 15:31:23 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 15:31:23 - INFO - __main__ - ['Company']
05/25/2022 15:31:23 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:31:23 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:31:23 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 15:31:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:31:23 - INFO - __main__ - Printing 3 examples
05/25/2022 15:31:23 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 15:31:23 - INFO - __main__ - ['Company']
05/25/2022 15:31:23 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 15:31:23 - INFO - __main__ - ['Company']
05/25/2022 15:31:23 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 15:31:23 - INFO - __main__ - ['Company']
05/25/2022 15:31:23 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:31:23 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:31:23 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 15:31:28 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7170641556829097 on epoch=214
05/25/2022 15:31:28 - INFO - __main__ - save last model!
05/25/2022 15:31:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 15:31:28 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 15:31:28 - INFO - __main__ - Printing 3 examples
05/25/2022 15:31:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 15:31:28 - INFO - __main__ - ['Animal']
05/25/2022 15:31:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 15:31:28 - INFO - __main__ - ['Animal']
05/25/2022 15:31:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 15:31:28 - INFO - __main__ - ['Village']
05/25/2022 15:31:28 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:31:31 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:31:34 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 15:31:42 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 15:31:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 15:31:43 - INFO - __main__ - Starting training!
05/25/2022 15:33:59 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/25/2022 15:33:59 - INFO - __main__ - Classification-F1 on test data: 0.5406
05/25/2022 15:33:59 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9821254014802402, test_performance=0.540562220178456
05/25/2022 15:33:59 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/25/2022 15:34:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:34:00 - INFO - __main__ - Printing 3 examples
05/25/2022 15:34:00 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 15:34:00 - INFO - __main__ - ['Company']
05/25/2022 15:34:00 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 15:34:00 - INFO - __main__ - ['Company']
05/25/2022 15:34:00 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 15:34:00 - INFO - __main__ - ['Company']
05/25/2022 15:34:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:34:00 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:34:01 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 15:34:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:34:01 - INFO - __main__ - Printing 3 examples
05/25/2022 15:34:01 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 15:34:01 - INFO - __main__ - ['Company']
05/25/2022 15:34:01 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 15:34:01 - INFO - __main__ - ['Company']
05/25/2022 15:34:01 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 15:34:01 - INFO - __main__ - ['Company']
05/25/2022 15:34:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:34:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:34:01 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 15:34:21 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 15:34:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 15:34:22 - INFO - __main__ - Starting training!
05/25/2022 15:34:25 - INFO - __main__ - Step 10 Global step 10 Train loss 5.27 on epoch=0
05/25/2022 15:34:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.68 on epoch=1
05/25/2022 15:34:32 - INFO - __main__ - Step 30 Global step 30 Train loss 2.53 on epoch=2
05/25/2022 15:34:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.99 on epoch=2
05/25/2022 15:34:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.60 on epoch=3
05/25/2022 15:34:43 - INFO - __main__ - Global step 50 Train loss 3.01 Classification-F1 0.24227291000759704 on epoch=3
05/25/2022 15:34:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.24227291000759704 on epoch=3, global_step=50
05/25/2022 15:34:46 - INFO - __main__ - Step 60 Global step 60 Train loss 1.28 on epoch=4
05/25/2022 15:34:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.16 on epoch=4
05/25/2022 15:34:52 - INFO - __main__ - Step 80 Global step 80 Train loss 0.88 on epoch=5
05/25/2022 15:34:55 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=6
05/25/2022 15:34:58 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=7
05/25/2022 15:35:05 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.46056347247386187 on epoch=7
05/25/2022 15:35:06 - INFO - __main__ - Saving model with best Classification-F1: 0.24227291000759704 -> 0.46056347247386187 on epoch=7, global_step=100
05/25/2022 15:35:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=7
05/25/2022 15:35:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=8
05/25/2022 15:35:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.64 on epoch=9
05/25/2022 15:35:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=9
05/25/2022 15:35:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=10
05/25/2022 15:35:29 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.5487333124614955 on epoch=10
05/25/2022 15:35:29 - INFO - __main__ - Saving model with best Classification-F1: 0.46056347247386187 -> 0.5487333124614955 on epoch=10, global_step=150
05/25/2022 15:35:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.57 on epoch=11
05/25/2022 15:35:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=12
05/25/2022 15:35:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=12
05/25/2022 15:35:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=13
05/25/2022 15:35:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=14
05/25/2022 15:35:51 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.7405440759729287 on epoch=14
05/25/2022 15:35:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5487333124614955 -> 0.7405440759729287 on epoch=14, global_step=200
05/25/2022 15:35:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=14
05/25/2022 15:35:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.42 on epoch=15
05/25/2022 15:36:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=16
05/25/2022 15:36:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=17
05/25/2022 15:36:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=17
05/25/2022 15:36:14 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.7198808537088789 on epoch=17
05/25/2022 15:36:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=18
05/25/2022 15:36:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=19
05/25/2022 15:36:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=19
05/25/2022 15:36:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=20
05/25/2022 15:36:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=21
05/25/2022 15:36:36 - INFO - __main__ - Global step 300 Train loss 0.31 Classification-F1 0.6808826629812821 on epoch=21
05/25/2022 15:36:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=22
05/25/2022 15:36:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=22
05/25/2022 15:36:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=23
05/25/2022 15:36:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=24
05/25/2022 15:36:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=24
05/25/2022 15:37:00 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.6804118124316966 on epoch=24
05/25/2022 15:37:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=25
05/25/2022 15:37:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
05/25/2022 15:37:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=27
05/25/2022 15:37:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=27
05/25/2022 15:37:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=28
05/25/2022 15:37:22 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.7631534118349534 on epoch=28
05/25/2022 15:37:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7405440759729287 -> 0.7631534118349534 on epoch=28, global_step=400
05/25/2022 15:37:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
05/25/2022 15:37:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=29
05/25/2022 15:37:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=30
05/25/2022 15:37:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=31
05/25/2022 15:37:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
05/25/2022 15:37:45 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.799179595142992 on epoch=32
05/25/2022 15:37:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7631534118349534 -> 0.799179595142992 on epoch=32, global_step=450
05/25/2022 15:37:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=32
05/25/2022 15:37:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=33
05/25/2022 15:37:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=34
05/25/2022 15:37:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=34
05/25/2022 15:38:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=35
05/25/2022 15:38:09 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.692035142567597 on epoch=35
05/25/2022 15:38:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=36
05/25/2022 15:38:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=37
05/25/2022 15:38:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
05/25/2022 15:38:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
05/25/2022 15:38:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=39
05/25/2022 15:38:31 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.6425399169931902 on epoch=39
05/25/2022 15:38:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
05/25/2022 15:38:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
05/25/2022 15:38:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=41
05/25/2022 15:38:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=42
05/25/2022 15:38:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=42
05/25/2022 15:38:54 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.5998108905943008 on epoch=42
05/25/2022 15:38:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
05/25/2022 15:39:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
05/25/2022 15:39:03 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
05/25/2022 15:39:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=45
05/25/2022 15:39:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
05/25/2022 15:39:17 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.6338241502149112 on epoch=46
05/25/2022 15:39:20 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
05/25/2022 15:39:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
05/25/2022 15:39:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
05/25/2022 15:39:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
05/25/2022 15:39:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
05/25/2022 15:39:39 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6626209443339588 on epoch=49
05/25/2022 15:39:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
05/25/2022 15:39:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
05/25/2022 15:39:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
05/25/2022 15:39:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
05/25/2022 15:39:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
05/25/2022 15:40:02 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.7037280642328564 on epoch=53
05/25/2022 15:40:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
05/25/2022 15:40:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
05/25/2022 15:40:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
05/25/2022 15:40:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
05/25/2022 15:40:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
05/25/2022 15:40:24 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6329877893188617 on epoch=57
05/25/2022 15:40:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
05/25/2022 15:40:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
05/25/2022 15:40:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
05/25/2022 15:40:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
05/25/2022 15:40:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=60
05/25/2022 15:40:46 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.8246093204510543 on epoch=60
05/25/2022 15:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.799179595142992 -> 0.8246093204510543 on epoch=60, global_step=850
05/25/2022 15:40:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
05/25/2022 15:40:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
05/25/2022 15:40:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
05/25/2022 15:40:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
05/25/2022 15:41:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
05/25/2022 15:41:09 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.765790495083664 on epoch=64
05/25/2022 15:41:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
05/25/2022 15:41:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
05/25/2022 15:41:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
05/25/2022 15:41:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
05/25/2022 15:41:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
05/25/2022 15:41:31 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7416297619260062 on epoch=67
05/25/2022 15:41:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
05/25/2022 15:41:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
05/25/2022 15:41:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
05/25/2022 15:41:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
05/25/2022 15:41:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
05/25/2022 15:41:52 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.5999258590871493 on epoch=71
05/25/2022 15:41:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
05/25/2022 15:41:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
05/25/2022 15:42:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
05/25/2022 15:42:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
05/25/2022 15:42:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
05/25/2022 15:42:14 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6497105880976848 on epoch=74
05/25/2022 15:42:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
05/25/2022 15:42:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
05/25/2022 15:42:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
05/25/2022 15:42:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
05/25/2022 15:42:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
05/25/2022 15:42:36 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6326554528820634 on epoch=78
05/25/2022 15:42:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
05/25/2022 15:42:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/25/2022 15:42:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=80
05/25/2022 15:42:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
05/25/2022 15:42:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
05/25/2022 15:42:58 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.678669843449423 on epoch=82
05/25/2022 15:43:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/25/2022 15:43:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
05/25/2022 15:43:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/25/2022 15:43:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
05/25/2022 15:43:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
05/25/2022 15:43:20 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7093229841398768 on epoch=85
05/25/2022 15:43:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
05/25/2022 15:43:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
05/25/2022 15:43:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
05/25/2022 15:43:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
05/25/2022 15:43:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
05/25/2022 15:43:42 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6967486390236814 on epoch=89
05/25/2022 15:43:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
05/25/2022 15:43:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
05/25/2022 15:43:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
05/25/2022 15:43:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
05/25/2022 15:43:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
05/25/2022 15:44:03 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6096169540109809 on epoch=92
05/25/2022 15:44:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/25/2022 15:44:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
05/25/2022 15:44:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
05/25/2022 15:44:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
05/25/2022 15:44:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
05/25/2022 15:44:26 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7441475189417347 on epoch=96
05/25/2022 15:44:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
05/25/2022 15:44:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/25/2022 15:44:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
05/25/2022 15:44:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
05/25/2022 15:44:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
05/25/2022 15:44:47 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6854360576310086 on epoch=99
05/25/2022 15:44:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
05/25/2022 15:44:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
05/25/2022 15:44:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 15:44:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/25/2022 15:45:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
05/25/2022 15:45:09 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7448051873455099 on epoch=103
05/25/2022 15:45:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/25/2022 15:45:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
05/25/2022 15:45:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/25/2022 15:45:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
05/25/2022 15:45:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/25/2022 15:45:31 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7309991706906153 on epoch=107
05/25/2022 15:45:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/25/2022 15:45:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
05/25/2022 15:45:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/25/2022 15:45:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
05/25/2022 15:45:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/25/2022 15:45:53 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7164480115244123 on epoch=110
05/25/2022 15:45:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
05/25/2022 15:45:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/25/2022 15:46:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/25/2022 15:46:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/25/2022 15:46:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
05/25/2022 15:46:15 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8068002127537232 on epoch=114
05/25/2022 15:46:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/25/2022 15:46:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/25/2022 15:46:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/25/2022 15:46:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
05/25/2022 15:46:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
05/25/2022 15:46:37 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8523250942605782 on epoch=117
05/25/2022 15:46:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8246093204510543 -> 0.8523250942605782 on epoch=117, global_step=1650
05/25/2022 15:46:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
05/25/2022 15:46:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
05/25/2022 15:46:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
05/25/2022 15:46:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/25/2022 15:46:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
05/25/2022 15:46:59 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7636614803953514 on epoch=121
05/25/2022 15:47:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
05/25/2022 15:47:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
05/25/2022 15:47:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/25/2022 15:47:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/25/2022 15:47:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/25/2022 15:47:21 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7829974814276 on epoch=124
05/25/2022 15:47:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 15:47:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
05/25/2022 15:47:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/25/2022 15:47:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 15:47:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/25/2022 15:47:43 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8010708716814309 on epoch=128
05/25/2022 15:47:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/25/2022 15:47:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
05/25/2022 15:47:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/25/2022 15:47:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/25/2022 15:47:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/25/2022 15:48:05 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7909318320232408 on epoch=132
05/25/2022 15:48:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/25/2022 15:48:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 15:48:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 15:48:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/25/2022 15:48:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
05/25/2022 15:48:27 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8491094531654304 on epoch=135
05/25/2022 15:48:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/25/2022 15:48:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 15:48:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/25/2022 15:48:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/25/2022 15:48:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
05/25/2022 15:48:49 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9228413163897033 on epoch=139
05/25/2022 15:48:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8523250942605782 -> 0.9228413163897033 on epoch=139, global_step=1950
05/25/2022 15:48:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 15:48:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/25/2022 15:48:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/25/2022 15:49:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/25/2022 15:49:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 15:49:11 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=142
05/25/2022 15:49:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/25/2022 15:49:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/25/2022 15:49:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/25/2022 15:49:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/25/2022 15:49:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/25/2022 15:49:34 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8530425219941349 on epoch=146
05/25/2022 15:49:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/25/2022 15:49:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/25/2022 15:49:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/25/2022 15:49:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
05/25/2022 15:49:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/25/2022 15:49:56 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.855335105083089 on epoch=149
05/25/2022 15:49:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/25/2022 15:50:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 15:50:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 15:50:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 15:50:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/25/2022 15:50:19 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9139245626453634 on epoch=153
05/25/2022 15:50:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/25/2022 15:50:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/25/2022 15:50:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 15:50:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
05/25/2022 15:50:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 15:50:41 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9112973048456919 on epoch=157
05/25/2022 15:50:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/25/2022 15:50:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/25/2022 15:50:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/25/2022 15:50:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/25/2022 15:50:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/25/2022 15:51:03 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9143564679048549 on epoch=160
05/25/2022 15:51:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/25/2022 15:51:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/25/2022 15:51:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 15:51:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/25/2022 15:51:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 15:51:25 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8439980449657869 on epoch=164
05/25/2022 15:51:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/25/2022 15:51:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
05/25/2022 15:51:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/25/2022 15:51:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/25/2022 15:51:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
05/25/2022 15:51:47 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8047797711459951 on epoch=167
05/25/2022 15:51:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/25/2022 15:51:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 15:51:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/25/2022 15:51:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/25/2022 15:52:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
05/25/2022 15:52:09 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9083320661815286 on epoch=171
05/25/2022 15:52:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/25/2022 15:52:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 15:52:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 15:52:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 15:52:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/25/2022 15:52:32 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=174
05/25/2022 15:52:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/25/2022 15:52:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 15:52:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 15:52:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 15:52:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/25/2022 15:52:54 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7932104581060938 on epoch=178
05/25/2022 15:52:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/25/2022 15:53:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/25/2022 15:53:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 15:53:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 15:53:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/25/2022 15:53:16 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8372881484477702 on epoch=182
05/25/2022 15:53:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
05/25/2022 15:53:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/25/2022 15:53:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/25/2022 15:53:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/25/2022 15:53:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/25/2022 15:53:38 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7892298115217017 on epoch=185
05/25/2022 15:53:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 15:53:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/25/2022 15:53:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/25/2022 15:53:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/25/2022 15:53:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=189
05/25/2022 15:54:01 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7716246909320913 on epoch=189
05/25/2022 15:54:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 15:54:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 15:54:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/25/2022 15:54:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/25/2022 15:54:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/25/2022 15:54:23 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7345591622566039 on epoch=192
05/25/2022 15:54:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 15:54:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 15:54:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
05/25/2022 15:54:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 15:54:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/25/2022 15:54:45 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.846294283210301 on epoch=196
05/25/2022 15:54:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/25/2022 15:54:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/25/2022 15:54:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/25/2022 15:54:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/25/2022 15:55:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/25/2022 15:55:07 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8549364613880743 on epoch=199
05/25/2022 15:55:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 15:55:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 15:55:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/25/2022 15:55:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
05/25/2022 15:55:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 15:55:30 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8482806172322301 on epoch=203
05/25/2022 15:55:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 15:55:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 15:55:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 15:55:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 15:55:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 15:55:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8491094531654304 on epoch=207
05/25/2022 15:55:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/25/2022 15:55:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 15:56:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 15:56:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 15:56:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 15:56:15 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8551930596285435 on epoch=210
05/25/2022 15:56:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 15:56:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 15:56:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/25/2022 15:56:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 15:56:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/25/2022 15:56:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:56:31 - INFO - __main__ - Printing 3 examples
05/25/2022 15:56:31 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 15:56:31 - INFO - __main__ - ['Company']
05/25/2022 15:56:31 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 15:56:31 - INFO - __main__ - ['Company']
05/25/2022 15:56:31 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 15:56:31 - INFO - __main__ - ['Company']
05/25/2022 15:56:31 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:56:31 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:56:32 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 15:56:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:56:32 - INFO - __main__ - Printing 3 examples
05/25/2022 15:56:32 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 15:56:32 - INFO - __main__ - ['Company']
05/25/2022 15:56:32 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 15:56:32 - INFO - __main__ - ['Company']
05/25/2022 15:56:32 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 15:56:32 - INFO - __main__ - ['Company']
05/25/2022 15:56:32 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:56:32 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:56:32 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 15:56:37 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8526376108133616 on epoch=214
05/25/2022 15:56:37 - INFO - __main__ - save last model!
05/25/2022 15:56:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 15:56:37 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 15:56:37 - INFO - __main__ - Printing 3 examples
05/25/2022 15:56:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 15:56:37 - INFO - __main__ - ['Animal']
05/25/2022 15:56:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 15:56:37 - INFO - __main__ - ['Animal']
05/25/2022 15:56:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 15:56:37 - INFO - __main__ - ['Village']
05/25/2022 15:56:37 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:56:39 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:56:42 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 15:56:48 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 15:56:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 15:56:48 - INFO - __main__ - Starting training!
05/25/2022 15:59:11 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/25/2022 15:59:11 - INFO - __main__ - Classification-F1 on test data: 0.6815
05/25/2022 15:59:12 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9228413163897033, test_performance=0.6815127258141709
05/25/2022 15:59:12 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/25/2022 15:59:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:59:13 - INFO - __main__ - Printing 3 examples
05/25/2022 15:59:13 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 15:59:13 - INFO - __main__ - ['Company']
05/25/2022 15:59:13 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 15:59:13 - INFO - __main__ - ['Company']
05/25/2022 15:59:13 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 15:59:13 - INFO - __main__ - ['Company']
05/25/2022 15:59:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:59:13 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:59:13 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 15:59:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 15:59:13 - INFO - __main__ - Printing 3 examples
05/25/2022 15:59:13 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 15:59:13 - INFO - __main__ - ['Company']
05/25/2022 15:59:13 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 15:59:13 - INFO - __main__ - ['Company']
05/25/2022 15:59:13 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 15:59:13 - INFO - __main__ - ['Company']
05/25/2022 15:59:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 15:59:13 - INFO - __main__ - Tokenizing Output ...
05/25/2022 15:59:13 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 15:59:32 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 15:59:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 15:59:33 - INFO - __main__ - Starting training!
05/25/2022 15:59:37 - INFO - __main__ - Step 10 Global step 10 Train loss 5.30 on epoch=0
05/25/2022 15:59:40 - INFO - __main__ - Step 20 Global step 20 Train loss 4.06 on epoch=1
05/25/2022 15:59:43 - INFO - __main__ - Step 30 Global step 30 Train loss 3.08 on epoch=2
05/25/2022 15:59:46 - INFO - __main__ - Step 40 Global step 40 Train loss 2.59 on epoch=2
05/25/2022 15:59:49 - INFO - __main__ - Step 50 Global step 50 Train loss 2.27 on epoch=3
05/25/2022 15:59:54 - INFO - __main__ - Global step 50 Train loss 3.46 Classification-F1 0.01796701944376077 on epoch=3
05/25/2022 15:59:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01796701944376077 on epoch=3, global_step=50
05/25/2022 15:59:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.79 on epoch=4
05/25/2022 16:00:00 - INFO - __main__ - Step 70 Global step 70 Train loss 1.60 on epoch=4
05/25/2022 16:00:03 - INFO - __main__ - Step 80 Global step 80 Train loss 1.29 on epoch=5
05/25/2022 16:00:06 - INFO - __main__ - Step 90 Global step 90 Train loss 1.21 on epoch=6
05/25/2022 16:00:09 - INFO - __main__ - Step 100 Global step 100 Train loss 1.11 on epoch=7
05/25/2022 16:00:17 - INFO - __main__ - Global step 100 Train loss 1.40 Classification-F1 0.2516821192200467 on epoch=7
05/25/2022 16:00:17 - INFO - __main__ - Saving model with best Classification-F1: 0.01796701944376077 -> 0.2516821192200467 on epoch=7, global_step=100
05/25/2022 16:00:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=7
05/25/2022 16:00:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=8
05/25/2022 16:00:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=9
05/25/2022 16:00:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=9
05/25/2022 16:00:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=10
05/25/2022 16:00:41 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.4846519568874951 on epoch=10
05/25/2022 16:00:41 - INFO - __main__ - Saving model with best Classification-F1: 0.2516821192200467 -> 0.4846519568874951 on epoch=10, global_step=150
05/25/2022 16:00:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=11
05/25/2022 16:00:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=12
05/25/2022 16:00:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=12
05/25/2022 16:00:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=13
05/25/2022 16:00:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=14
05/25/2022 16:01:05 - INFO - __main__ - Global step 200 Train loss 0.66 Classification-F1 0.47929115775521525 on epoch=14
05/25/2022 16:01:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=14
05/25/2022 16:01:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=15
05/25/2022 16:01:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=16
05/25/2022 16:01:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=17
05/25/2022 16:01:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=17
05/25/2022 16:01:29 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.6275506932999176 on epoch=17
05/25/2022 16:01:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4846519568874951 -> 0.6275506932999176 on epoch=17, global_step=250
05/25/2022 16:01:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=18
05/25/2022 16:01:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
05/25/2022 16:01:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=19
05/25/2022 16:01:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=20
05/25/2022 16:01:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=21
05/25/2022 16:01:52 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.4685822398621587 on epoch=21
05/25/2022 16:01:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
05/25/2022 16:01:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=22
05/25/2022 16:02:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=23
05/25/2022 16:02:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=24
05/25/2022 16:02:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=24
05/25/2022 16:02:15 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.6712113406768689 on epoch=24
05/25/2022 16:02:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6275506932999176 -> 0.6712113406768689 on epoch=24, global_step=350
05/25/2022 16:02:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=25
05/25/2022 16:02:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=26
05/25/2022 16:02:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=27
05/25/2022 16:02:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
05/25/2022 16:02:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
05/25/2022 16:02:38 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.7113025819863613 on epoch=28
05/25/2022 16:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6712113406768689 -> 0.7113025819863613 on epoch=28, global_step=400
05/25/2022 16:02:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=29
05/25/2022 16:02:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=29
05/25/2022 16:02:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=30
05/25/2022 16:02:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
05/25/2022 16:02:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
05/25/2022 16:03:01 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.6661181931409108 on epoch=32
05/25/2022 16:03:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=32
05/25/2022 16:03:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=33
05/25/2022 16:03:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
05/25/2022 16:03:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=34
05/25/2022 16:03:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
05/25/2022 16:03:24 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.8321410412470654 on epoch=35
05/25/2022 16:03:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7113025819863613 -> 0.8321410412470654 on epoch=35, global_step=500
05/25/2022 16:03:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
05/25/2022 16:03:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=37
05/25/2022 16:03:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
05/25/2022 16:03:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=38
05/25/2022 16:03:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
05/25/2022 16:03:46 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.7889816144481459 on epoch=39
05/25/2022 16:03:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=39
05/25/2022 16:03:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
05/25/2022 16:03:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
05/25/2022 16:03:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=42
05/25/2022 16:04:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
05/25/2022 16:04:10 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6502921328048663 on epoch=42
05/25/2022 16:04:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=43
05/25/2022 16:04:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=44
05/25/2022 16:04:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=44
05/25/2022 16:04:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=45
05/25/2022 16:04:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
05/25/2022 16:04:34 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.6282941355134142 on epoch=46
05/25/2022 16:04:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=47
05/25/2022 16:04:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=47
05/25/2022 16:04:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
05/25/2022 16:04:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
05/25/2022 16:04:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
05/25/2022 16:04:57 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.6915654039592919 on epoch=49
05/25/2022 16:05:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
05/25/2022 16:05:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=51
05/25/2022 16:05:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
05/25/2022 16:05:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
05/25/2022 16:05:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
05/25/2022 16:05:21 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.7642379092133205 on epoch=53
05/25/2022 16:05:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=54
05/25/2022 16:05:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=54
05/25/2022 16:05:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
05/25/2022 16:05:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
05/25/2022 16:05:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
05/25/2022 16:05:44 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.8280723859471487 on epoch=57
05/25/2022 16:05:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
05/25/2022 16:05:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
05/25/2022 16:05:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
05/25/2022 16:05:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=59
05/25/2022 16:05:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
05/25/2022 16:06:07 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.6232190169512275 on epoch=60
05/25/2022 16:06:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
05/25/2022 16:06:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
05/25/2022 16:06:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
05/25/2022 16:06:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=63
05/25/2022 16:06:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
05/25/2022 16:06:31 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.8910175175750761 on epoch=64
05/25/2022 16:06:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8321410412470654 -> 0.8910175175750761 on epoch=64, global_step=900
05/25/2022 16:06:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
05/25/2022 16:06:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
05/25/2022 16:06:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
05/25/2022 16:06:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
05/25/2022 16:06:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
05/25/2022 16:06:56 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7020614760910997 on epoch=67
05/25/2022 16:06:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
05/25/2022 16:07:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
05/25/2022 16:07:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
05/25/2022 16:07:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
05/25/2022 16:07:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=71
05/25/2022 16:07:19 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7379764754402471 on epoch=71
05/25/2022 16:07:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
05/25/2022 16:07:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
05/25/2022 16:07:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
05/25/2022 16:07:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
05/25/2022 16:07:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
05/25/2022 16:07:42 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6255263427347745 on epoch=74
05/25/2022 16:07:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
05/25/2022 16:07:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
05/25/2022 16:07:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
05/25/2022 16:07:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/25/2022 16:07:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
05/25/2022 16:08:05 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7259127372030598 on epoch=78
05/25/2022 16:08:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
05/25/2022 16:08:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
05/25/2022 16:08:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
05/25/2022 16:08:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
05/25/2022 16:08:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
05/25/2022 16:08:28 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.651174634891428 on epoch=82
05/25/2022 16:08:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
05/25/2022 16:08:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
05/25/2022 16:08:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
05/25/2022 16:08:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
05/25/2022 16:08:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
05/25/2022 16:08:51 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6810017588006203 on epoch=85
05/25/2022 16:08:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
05/25/2022 16:08:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
05/25/2022 16:09:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
05/25/2022 16:09:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
05/25/2022 16:09:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
05/25/2022 16:09:14 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.63667733774724 on epoch=89
05/25/2022 16:09:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
05/25/2022 16:09:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
05/25/2022 16:09:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
05/25/2022 16:09:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
05/25/2022 16:09:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/25/2022 16:09:37 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6714245268945327 on epoch=92
05/25/2022 16:09:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
05/25/2022 16:09:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
05/25/2022 16:09:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
05/25/2022 16:09:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 16:09:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
05/25/2022 16:10:00 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7715307576476338 on epoch=96
05/25/2022 16:10:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
05/25/2022 16:10:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
05/25/2022 16:10:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/25/2022 16:10:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
05/25/2022 16:10:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
05/25/2022 16:10:22 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6835200672368603 on epoch=99
05/25/2022 16:10:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
05/25/2022 16:10:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
05/25/2022 16:10:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 16:10:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
05/25/2022 16:10:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
05/25/2022 16:10:45 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6945319955530294 on epoch=103
05/25/2022 16:10:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/25/2022 16:10:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/25/2022 16:10:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
05/25/2022 16:10:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/25/2022 16:11:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
05/25/2022 16:11:07 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.5845271067045261 on epoch=107
05/25/2022 16:11:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/25/2022 16:11:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
05/25/2022 16:11:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/25/2022 16:11:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/25/2022 16:11:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
05/25/2022 16:11:29 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5977608149809288 on epoch=110
05/25/2022 16:11:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
05/25/2022 16:11:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
05/25/2022 16:11:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/25/2022 16:11:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
05/25/2022 16:11:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
05/25/2022 16:11:51 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8225809724549644 on epoch=114
05/25/2022 16:11:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/25/2022 16:11:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
05/25/2022 16:12:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
05/25/2022 16:12:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
05/25/2022 16:12:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/25/2022 16:12:13 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8710363396271714 on epoch=117
05/25/2022 16:12:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
05/25/2022 16:12:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
05/25/2022 16:12:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 16:12:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/25/2022 16:12:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
05/25/2022 16:12:35 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8905634181931515 on epoch=121
05/25/2022 16:12:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
05/25/2022 16:12:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/25/2022 16:12:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
05/25/2022 16:12:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
05/25/2022 16:12:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/25/2022 16:12:58 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.810748615184099 on epoch=124
05/25/2022 16:13:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 16:13:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
05/25/2022 16:13:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/25/2022 16:13:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
05/25/2022 16:13:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/25/2022 16:13:21 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8937884346309394 on epoch=128
05/25/2022 16:13:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8910175175750761 -> 0.8937884346309394 on epoch=128, global_step=1800
05/25/2022 16:13:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
05/25/2022 16:13:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/25/2022 16:13:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/25/2022 16:13:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/25/2022 16:13:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/25/2022 16:13:44 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8819789108214154 on epoch=132
05/25/2022 16:13:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/25/2022 16:13:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/25/2022 16:13:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/25/2022 16:13:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
05/25/2022 16:13:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
05/25/2022 16:14:06 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.860488487020745 on epoch=135
05/25/2022 16:14:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
05/25/2022 16:14:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 16:14:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/25/2022 16:14:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/25/2022 16:14:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/25/2022 16:14:29 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8289980860379342 on epoch=139
05/25/2022 16:14:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
05/25/2022 16:14:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/25/2022 16:14:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/25/2022 16:14:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/25/2022 16:14:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
05/25/2022 16:14:51 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7548137764679791 on epoch=142
05/25/2022 16:14:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/25/2022 16:14:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/25/2022 16:15:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/25/2022 16:15:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 16:15:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/25/2022 16:15:13 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6560417585085516 on epoch=146
05/25/2022 16:15:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 16:15:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
05/25/2022 16:15:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
05/25/2022 16:15:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/25/2022 16:15:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
05/25/2022 16:15:35 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8049731892100875 on epoch=149
05/25/2022 16:15:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/25/2022 16:15:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/25/2022 16:15:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 16:15:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/25/2022 16:15:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/25/2022 16:15:58 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7909335288367547 on epoch=153
05/25/2022 16:16:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/25/2022 16:16:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 16:16:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 16:16:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/25/2022 16:16:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 16:16:21 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8430465284043913 on epoch=157
05/25/2022 16:16:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/25/2022 16:16:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 16:16:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/25/2022 16:16:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/25/2022 16:16:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
05/25/2022 16:16:43 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8862080482241772 on epoch=160
05/25/2022 16:16:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 16:16:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
05/25/2022 16:16:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
05/25/2022 16:16:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/25/2022 16:16:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/25/2022 16:17:06 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9072569008052879 on epoch=164
05/25/2022 16:17:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8937884346309394 -> 0.9072569008052879 on epoch=164, global_step=2300
05/25/2022 16:17:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/25/2022 16:17:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 16:17:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/25/2022 16:17:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/25/2022 16:17:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 16:17:28 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9819761555648652 on epoch=167
05/25/2022 16:17:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9072569008052879 -> 0.9819761555648652 on epoch=167, global_step=2350
05/25/2022 16:17:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/25/2022 16:17:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 16:17:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/25/2022 16:17:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 16:17:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/25/2022 16:17:51 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9079365721412441 on epoch=171
05/25/2022 16:17:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
05/25/2022 16:17:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
05/25/2022 16:18:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 16:18:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
05/25/2022 16:18:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/25/2022 16:18:13 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9021544477028347 on epoch=174
05/25/2022 16:18:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/25/2022 16:18:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/25/2022 16:18:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 16:18:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/25/2022 16:18:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/25/2022 16:18:36 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9101857282502444 on epoch=178
05/25/2022 16:18:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/25/2022 16:18:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/25/2022 16:18:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/25/2022 16:18:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
05/25/2022 16:18:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/25/2022 16:18:58 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9163766699250571 on epoch=182
05/25/2022 16:19:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
05/25/2022 16:19:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/25/2022 16:19:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/25/2022 16:19:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/25/2022 16:19:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/25/2022 16:19:21 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9078918214402084 on epoch=185
05/25/2022 16:19:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=186
05/25/2022 16:19:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/25/2022 16:19:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/25/2022 16:19:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/25/2022 16:19:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/25/2022 16:19:43 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9002609374367755 on epoch=189
05/25/2022 16:19:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 16:19:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/25/2022 16:19:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 16:19:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/25/2022 16:19:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/25/2022 16:20:06 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8376955226738789 on epoch=192
05/25/2022 16:20:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/25/2022 16:20:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/25/2022 16:20:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/25/2022 16:20:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 16:20:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/25/2022 16:20:28 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=196
05/25/2022 16:20:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/25/2022 16:20:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/25/2022 16:20:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/25/2022 16:20:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/25/2022 16:20:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
05/25/2022 16:20:51 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9120625610948191 on epoch=199
05/25/2022 16:20:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 16:20:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/25/2022 16:21:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/25/2022 16:21:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 16:21:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/25/2022 16:21:13 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9120625610948191 on epoch=203
05/25/2022 16:21:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/25/2022 16:21:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/25/2022 16:21:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/25/2022 16:21:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/25/2022 16:21:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/25/2022 16:21:35 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9143564679048549 on epoch=207
05/25/2022 16:21:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/25/2022 16:21:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/25/2022 16:21:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 16:21:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 16:21:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 16:21:57 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.857086999022483 on epoch=210
05/25/2022 16:22:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/25/2022 16:22:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/25/2022 16:22:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 16:22:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
05/25/2022 16:22:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/25/2022 16:22:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:22:14 - INFO - __main__ - Printing 3 examples
05/25/2022 16:22:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 16:22:14 - INFO - __main__ - ['Company']
05/25/2022 16:22:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 16:22:14 - INFO - __main__ - ['Company']
05/25/2022 16:22:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 16:22:14 - INFO - __main__ - ['Company']
05/25/2022 16:22:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:22:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:22:15 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 16:22:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:22:15 - INFO - __main__ - Printing 3 examples
05/25/2022 16:22:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 16:22:15 - INFO - __main__ - ['Company']
05/25/2022 16:22:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 16:22:15 - INFO - __main__ - ['Company']
05/25/2022 16:22:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 16:22:15 - INFO - __main__ - ['Company']
05/25/2022 16:22:15 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:22:15 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:22:15 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 16:22:20 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8104766833419584 on epoch=214
05/25/2022 16:22:20 - INFO - __main__ - save last model!
05/25/2022 16:22:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 16:22:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 16:22:20 - INFO - __main__ - Printing 3 examples
05/25/2022 16:22:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 16:22:20 - INFO - __main__ - ['Animal']
05/25/2022 16:22:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 16:22:20 - INFO - __main__ - ['Animal']
05/25/2022 16:22:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 16:22:20 - INFO - __main__ - ['Village']
05/25/2022 16:22:20 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:22:22 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:22:26 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 16:22:31 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 16:22:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 16:22:31 - INFO - __main__ - Starting training!
05/25/2022 16:24:50 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/25/2022 16:24:51 - INFO - __main__ - Classification-F1 on test data: 0.5687
05/25/2022 16:24:51 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9819761555648652, test_performance=0.5687429669619601
05/25/2022 16:24:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/25/2022 16:24:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:24:52 - INFO - __main__ - Printing 3 examples
05/25/2022 16:24:52 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 16:24:52 - INFO - __main__ - ['Company']
05/25/2022 16:24:52 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 16:24:52 - INFO - __main__ - ['Company']
05/25/2022 16:24:52 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 16:24:52 - INFO - __main__ - ['Company']
05/25/2022 16:24:52 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:24:52 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:24:52 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 16:24:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:24:52 - INFO - __main__ - Printing 3 examples
05/25/2022 16:24:52 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/25/2022 16:24:52 - INFO - __main__ - ['Company']
05/25/2022 16:24:52 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/25/2022 16:24:52 - INFO - __main__ - ['Company']
05/25/2022 16:24:52 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/25/2022 16:24:52 - INFO - __main__ - ['Company']
05/25/2022 16:24:52 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:24:52 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:24:53 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 16:25:11 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 16:25:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 16:25:12 - INFO - __main__ - Starting training!
05/25/2022 16:25:16 - INFO - __main__ - Step 10 Global step 10 Train loss 5.69 on epoch=0
05/25/2022 16:25:19 - INFO - __main__ - Step 20 Global step 20 Train loss 4.68 on epoch=1
05/25/2022 16:25:22 - INFO - __main__ - Step 30 Global step 30 Train loss 3.73 on epoch=2
05/25/2022 16:25:25 - INFO - __main__ - Step 40 Global step 40 Train loss 3.10 on epoch=2
05/25/2022 16:25:28 - INFO - __main__ - Step 50 Global step 50 Train loss 2.78 on epoch=3
05/25/2022 16:25:32 - INFO - __main__ - Global step 50 Train loss 4.00 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 16:25:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 16:25:35 - INFO - __main__ - Step 60 Global step 60 Train loss 2.42 on epoch=4
05/25/2022 16:25:38 - INFO - __main__ - Step 70 Global step 70 Train loss 1.95 on epoch=4
05/25/2022 16:25:41 - INFO - __main__ - Step 80 Global step 80 Train loss 1.83 on epoch=5
05/25/2022 16:25:44 - INFO - __main__ - Step 90 Global step 90 Train loss 1.49 on epoch=6
05/25/2022 16:25:47 - INFO - __main__ - Step 100 Global step 100 Train loss 1.44 on epoch=7
05/25/2022 16:25:52 - INFO - __main__ - Global step 100 Train loss 1.82 Classification-F1 0.27454507027450975 on epoch=7
05/25/2022 16:25:52 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.27454507027450975 on epoch=7, global_step=100
05/25/2022 16:25:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.24 on epoch=7
05/25/2022 16:25:58 - INFO - __main__ - Step 120 Global step 120 Train loss 1.14 on epoch=8
05/25/2022 16:26:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=9
05/25/2022 16:26:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.95 on epoch=9
05/25/2022 16:26:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.86 on epoch=10
05/25/2022 16:26:16 - INFO - __main__ - Global step 150 Train loss 1.04 Classification-F1 0.35459353432807733 on epoch=10
05/25/2022 16:26:16 - INFO - __main__ - Saving model with best Classification-F1: 0.27454507027450975 -> 0.35459353432807733 on epoch=10, global_step=150
05/25/2022 16:26:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.83 on epoch=11
05/25/2022 16:26:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=12
05/25/2022 16:26:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=12
05/25/2022 16:26:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=13
05/25/2022 16:26:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
05/25/2022 16:26:38 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.46664816469814535 on epoch=14
05/25/2022 16:26:38 - INFO - __main__ - Saving model with best Classification-F1: 0.35459353432807733 -> 0.46664816469814535 on epoch=14, global_step=200
05/25/2022 16:26:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=14
05/25/2022 16:26:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=15
05/25/2022 16:26:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.69 on epoch=16
05/25/2022 16:26:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=17
05/25/2022 16:26:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=17
05/25/2022 16:27:01 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.5589613028794718 on epoch=17
05/25/2022 16:27:01 - INFO - __main__ - Saving model with best Classification-F1: 0.46664816469814535 -> 0.5589613028794718 on epoch=17, global_step=250
05/25/2022 16:27:04 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=18
05/25/2022 16:27:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=19
05/25/2022 16:27:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=19
05/25/2022 16:27:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=20
05/25/2022 16:27:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.55 on epoch=21
05/25/2022 16:27:24 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.4719390492402173 on epoch=21
05/25/2022 16:27:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=22
05/25/2022 16:27:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=22
05/25/2022 16:27:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=23
05/25/2022 16:27:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=24
05/25/2022 16:27:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=24
05/25/2022 16:27:47 - INFO - __main__ - Global step 350 Train loss 0.48 Classification-F1 0.5365126777592429 on epoch=24
05/25/2022 16:27:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=25
05/25/2022 16:27:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=26
05/25/2022 16:27:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=27
05/25/2022 16:27:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=27
05/25/2022 16:28:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=28
05/25/2022 16:28:11 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.5760490866094314 on epoch=28
05/25/2022 16:28:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5589613028794718 -> 0.5760490866094314 on epoch=28, global_step=400
05/25/2022 16:28:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=29
05/25/2022 16:28:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=29
05/25/2022 16:28:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=30
05/25/2022 16:28:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
05/25/2022 16:28:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=32
05/25/2022 16:28:35 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.7546341186047069 on epoch=32
05/25/2022 16:28:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5760490866094314 -> 0.7546341186047069 on epoch=32, global_step=450
05/25/2022 16:28:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=32
05/25/2022 16:28:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
05/25/2022 16:28:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
05/25/2022 16:28:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
05/25/2022 16:28:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=35
05/25/2022 16:29:00 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.8720958891753238 on epoch=35
05/25/2022 16:29:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7546341186047069 -> 0.8720958891753238 on epoch=35, global_step=500
05/25/2022 16:29:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
05/25/2022 16:29:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=37
05/25/2022 16:29:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
05/25/2022 16:29:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=38
05/25/2022 16:29:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
05/25/2022 16:29:24 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.8760323167929659 on epoch=39
05/25/2022 16:29:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8720958891753238 -> 0.8760323167929659 on epoch=39, global_step=550
05/25/2022 16:29:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.36 on epoch=39
05/25/2022 16:29:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=40
05/25/2022 16:29:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=41
05/25/2022 16:29:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=42
05/25/2022 16:29:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=42
05/25/2022 16:29:49 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.8207617312586375 on epoch=42
05/25/2022 16:29:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=43
05/25/2022 16:29:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=44
05/25/2022 16:29:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=44
05/25/2022 16:30:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=45
05/25/2022 16:30:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=46
05/25/2022 16:30:12 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.9599856364833322 on epoch=46
05/25/2022 16:30:13 - INFO - __main__ - Saving model with best Classification-F1: 0.8760323167929659 -> 0.9599856364833322 on epoch=46, global_step=650
05/25/2022 16:30:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=47
05/25/2022 16:30:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=47
05/25/2022 16:30:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=48
05/25/2022 16:30:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
05/25/2022 16:30:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
05/25/2022 16:30:36 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.8364599358121572 on epoch=49
05/25/2022 16:30:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
05/25/2022 16:30:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=51
05/25/2022 16:30:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=52
05/25/2022 16:30:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=52
05/25/2022 16:30:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
05/25/2022 16:31:00 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.8191000291140152 on epoch=53
05/25/2022 16:31:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
05/25/2022 16:31:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=54
05/25/2022 16:31:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=55
05/25/2022 16:31:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=56
05/25/2022 16:31:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=57
05/25/2022 16:31:25 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.9687876543579309 on epoch=57
05/25/2022 16:31:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9599856364833322 -> 0.9687876543579309 on epoch=57, global_step=800
05/25/2022 16:31:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=57
05/25/2022 16:31:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
05/25/2022 16:31:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=59
05/25/2022 16:31:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.30 on epoch=59
05/25/2022 16:31:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=60
05/25/2022 16:31:49 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.8275243713499763 on epoch=60
05/25/2022 16:31:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
05/25/2022 16:31:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
05/25/2022 16:31:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
05/25/2022 16:32:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
05/25/2022 16:32:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
05/25/2022 16:32:12 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.6984243337818173 on epoch=64
05/25/2022 16:32:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=64
05/25/2022 16:32:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
05/25/2022 16:32:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
05/25/2022 16:32:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=67
05/25/2022 16:32:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
05/25/2022 16:32:37 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.901290154043213 on epoch=67
05/25/2022 16:32:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
05/25/2022 16:32:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
05/25/2022 16:32:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
05/25/2022 16:32:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=70
05/25/2022 16:32:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=71
05/25/2022 16:33:01 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.7837291661532648 on epoch=71
05/25/2022 16:33:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=72
05/25/2022 16:33:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=72
05/25/2022 16:33:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
05/25/2022 16:33:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
05/25/2022 16:33:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
05/25/2022 16:33:24 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7039965626337825 on epoch=74
05/25/2022 16:33:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=75
05/25/2022 16:33:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
05/25/2022 16:33:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
05/25/2022 16:33:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
05/25/2022 16:33:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
05/25/2022 16:33:48 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.9143564679048547 on epoch=78
05/25/2022 16:33:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
05/25/2022 16:33:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
05/25/2022 16:33:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=80
05/25/2022 16:34:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
05/25/2022 16:34:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=82
05/25/2022 16:34:13 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.9775075059349252 on epoch=82
05/25/2022 16:34:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9687876543579309 -> 0.9775075059349252 on epoch=82, global_step=1150
05/25/2022 16:34:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
05/25/2022 16:34:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/25/2022 16:34:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=84
05/25/2022 16:34:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
05/25/2022 16:34:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=85
05/25/2022 16:34:37 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.8183125532283022 on epoch=85
05/25/2022 16:34:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=86
05/25/2022 16:34:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
05/25/2022 16:34:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=87
05/25/2022 16:34:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
05/25/2022 16:34:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
05/25/2022 16:35:00 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.7702722878007509 on epoch=89
05/25/2022 16:35:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
05/25/2022 16:35:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
05/25/2022 16:35:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=91
05/25/2022 16:35:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=92
05/25/2022 16:35:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
05/25/2022 16:35:25 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.8924120234604104 on epoch=92
05/25/2022 16:35:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=93
05/25/2022 16:35:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
05/25/2022 16:35:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
05/25/2022 16:35:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
05/25/2022 16:35:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
05/25/2022 16:35:48 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7946183271569321 on epoch=96
05/25/2022 16:35:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
05/25/2022 16:35:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
05/25/2022 16:35:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/25/2022 16:36:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
05/25/2022 16:36:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=99
05/25/2022 16:36:12 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.7842147451255611 on epoch=99
05/25/2022 16:36:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
05/25/2022 16:36:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
05/25/2022 16:36:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
05/25/2022 16:36:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=102
05/25/2022 16:36:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=103
05/25/2022 16:36:36 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7843840204703583 on epoch=103
05/25/2022 16:36:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
05/25/2022 16:36:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
05/25/2022 16:36:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
05/25/2022 16:36:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
05/25/2022 16:36:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
05/25/2022 16:36:59 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6735686615256508 on epoch=107
05/25/2022 16:37:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/25/2022 16:37:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
05/25/2022 16:37:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
05/25/2022 16:37:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
05/25/2022 16:37:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
05/25/2022 16:37:22 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.853180749022483 on epoch=110
05/25/2022 16:37:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=111
05/25/2022 16:37:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
05/25/2022 16:37:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
05/25/2022 16:37:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
05/25/2022 16:37:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
05/25/2022 16:37:46 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.784184348226094 on epoch=114
05/25/2022 16:37:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/25/2022 16:37:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
05/25/2022 16:37:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/25/2022 16:37:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
05/25/2022 16:38:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/25/2022 16:38:09 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.9097816878462041 on epoch=117
05/25/2022 16:38:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
05/25/2022 16:38:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/25/2022 16:38:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
05/25/2022 16:38:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/25/2022 16:38:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
05/25/2022 16:38:33 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7464107871887757 on epoch=121
05/25/2022 16:38:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
05/25/2022 16:38:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
05/25/2022 16:38:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=123
05/25/2022 16:38:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
05/25/2022 16:38:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
05/25/2022 16:38:57 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6745020060048454 on epoch=124
05/25/2022 16:39:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
05/25/2022 16:39:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
05/25/2022 16:39:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/25/2022 16:39:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
05/25/2022 16:39:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
05/25/2022 16:39:20 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7276242766347176 on epoch=128
05/25/2022 16:39:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/25/2022 16:39:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
05/25/2022 16:39:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
05/25/2022 16:39:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
05/25/2022 16:39:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
05/25/2022 16:39:44 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7154609146632288 on epoch=132
05/25/2022 16:39:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
05/25/2022 16:39:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/25/2022 16:39:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/25/2022 16:39:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
05/25/2022 16:39:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
05/25/2022 16:40:07 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7287270314244731 on epoch=135
05/25/2022 16:40:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/25/2022 16:40:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
05/25/2022 16:40:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
05/25/2022 16:40:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
05/25/2022 16:40:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
05/25/2022 16:40:30 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7285632314526976 on epoch=139
05/25/2022 16:40:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
05/25/2022 16:40:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
05/25/2022 16:40:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
05/25/2022 16:40:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/25/2022 16:40:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/25/2022 16:40:54 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7969294462653096 on epoch=142
05/25/2022 16:40:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
05/25/2022 16:41:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/25/2022 16:41:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
05/25/2022 16:41:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/25/2022 16:41:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/25/2022 16:41:18 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7601045992161072 on epoch=146
05/25/2022 16:41:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
05/25/2022 16:41:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=147
05/25/2022 16:41:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/25/2022 16:41:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/25/2022 16:41:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
05/25/2022 16:41:41 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6677193184214057 on epoch=149
05/25/2022 16:41:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/25/2022 16:41:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/25/2022 16:41:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=152
05/25/2022 16:41:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
05/25/2022 16:41:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
05/25/2022 16:42:04 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6878612029149664 on epoch=153
05/25/2022 16:42:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
05/25/2022 16:42:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
05/25/2022 16:42:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
05/25/2022 16:42:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
05/25/2022 16:42:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/25/2022 16:42:27 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7564816442088489 on epoch=157
05/25/2022 16:42:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/25/2022 16:42:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/25/2022 16:42:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/25/2022 16:42:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/25/2022 16:42:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/25/2022 16:42:50 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.747943388544056 on epoch=160
05/25/2022 16:42:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
05/25/2022 16:42:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
05/25/2022 16:42:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/25/2022 16:43:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
05/25/2022 16:43:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
05/25/2022 16:43:12 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.671835306741928 on epoch=164
05/25/2022 16:43:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
05/25/2022 16:43:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
05/25/2022 16:43:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 16:43:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
05/25/2022 16:43:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/25/2022 16:43:35 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7911864226854739 on epoch=167
05/25/2022 16:43:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
05/25/2022 16:43:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
05/25/2022 16:43:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/25/2022 16:43:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
05/25/2022 16:43:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
05/25/2022 16:43:58 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7970234554535739 on epoch=171
05/25/2022 16:44:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
05/25/2022 16:44:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
05/25/2022 16:44:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
05/25/2022 16:44:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
05/25/2022 16:44:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
05/25/2022 16:44:21 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9078918214402084 on epoch=174
05/25/2022 16:44:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/25/2022 16:44:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/25/2022 16:44:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
05/25/2022 16:44:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
05/25/2022 16:44:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
05/25/2022 16:44:45 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9775031420192709 on epoch=178
05/25/2022 16:44:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/25/2022 16:44:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/25/2022 16:44:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/25/2022 16:44:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/25/2022 16:45:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/25/2022 16:45:08 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9122059302704464 on epoch=182
05/25/2022 16:45:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/25/2022 16:45:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
05/25/2022 16:45:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/25/2022 16:45:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
05/25/2022 16:45:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/25/2022 16:45:31 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9775031420192709 on epoch=185
05/25/2022 16:45:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/25/2022 16:45:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
05/25/2022 16:45:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/25/2022 16:45:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
05/25/2022 16:45:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/25/2022 16:45:54 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9020107888925092 on epoch=189
05/25/2022 16:45:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 16:46:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/25/2022 16:46:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 16:46:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
05/25/2022 16:46:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/25/2022 16:46:17 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9028124563608434 on epoch=192
05/25/2022 16:46:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=193
05/25/2022 16:46:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/25/2022 16:46:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/25/2022 16:46:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/25/2022 16:46:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/25/2022 16:46:40 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9775031420192709 on epoch=196
05/25/2022 16:46:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/25/2022 16:46:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/25/2022 16:46:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/25/2022 16:46:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
05/25/2022 16:46:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
05/25/2022 16:47:03 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9048326583810454 on epoch=199
05/25/2022 16:47:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/25/2022 16:47:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
05/25/2022 16:47:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/25/2022 16:47:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
05/25/2022 16:47:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/25/2022 16:47:26 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=203
05/25/2022 16:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9775075059349252 -> 0.9821254014802402 on epoch=203, global_step=2850
05/25/2022 16:47:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
05/25/2022 16:47:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
05/25/2022 16:47:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/25/2022 16:47:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 16:47:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/25/2022 16:47:49 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8512868096285435 on epoch=207
05/25/2022 16:47:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/25/2022 16:47:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/25/2022 16:47:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
05/25/2022 16:48:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/25/2022 16:48:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/25/2022 16:48:12 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9775031420192709 on epoch=210
05/25/2022 16:48:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/25/2022 16:48:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/25/2022 16:48:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
05/25/2022 16:48:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/25/2022 16:48:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 16:48:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:48:28 - INFO - __main__ - Printing 3 examples
05/25/2022 16:48:28 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 16:48:28 - INFO - __main__ - ['Film']
05/25/2022 16:48:28 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 16:48:28 - INFO - __main__ - ['Film']
05/25/2022 16:48:28 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 16:48:28 - INFO - __main__ - ['Film']
05/25/2022 16:48:28 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:48:29 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:48:29 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 16:48:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:48:29 - INFO - __main__ - Printing 3 examples
05/25/2022 16:48:29 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 16:48:29 - INFO - __main__ - ['Film']
05/25/2022 16:48:29 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 16:48:29 - INFO - __main__ - ['Film']
05/25/2022 16:48:29 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 16:48:29 - INFO - __main__ - ['Film']
05/25/2022 16:48:29 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:48:29 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:48:29 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 16:48:34 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8029900523259158 on epoch=214
05/25/2022 16:48:34 - INFO - __main__ - save last model!
05/25/2022 16:48:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 16:48:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 16:48:35 - INFO - __main__ - Printing 3 examples
05/25/2022 16:48:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 16:48:35 - INFO - __main__ - ['Animal']
05/25/2022 16:48:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 16:48:35 - INFO - __main__ - ['Animal']
05/25/2022 16:48:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 16:48:35 - INFO - __main__ - ['Village']
05/25/2022 16:48:35 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:48:36 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:48:40 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 16:48:47 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 16:48:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 16:48:47 - INFO - __main__ - Starting training!
05/25/2022 16:51:04 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/25/2022 16:51:04 - INFO - __main__ - Classification-F1 on test data: 0.6833
05/25/2022 16:51:04 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9821254014802402, test_performance=0.6832801534666181
05/25/2022 16:51:04 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/25/2022 16:51:05 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:51:05 - INFO - __main__ - Printing 3 examples
05/25/2022 16:51:05 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 16:51:05 - INFO - __main__ - ['Film']
05/25/2022 16:51:05 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 16:51:05 - INFO - __main__ - ['Film']
05/25/2022 16:51:05 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 16:51:05 - INFO - __main__ - ['Film']
05/25/2022 16:51:05 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:51:05 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:51:05 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 16:51:05 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 16:51:05 - INFO - __main__ - Printing 3 examples
05/25/2022 16:51:05 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 16:51:05 - INFO - __main__ - ['Film']
05/25/2022 16:51:05 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 16:51:05 - INFO - __main__ - ['Film']
05/25/2022 16:51:05 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 16:51:05 - INFO - __main__ - ['Film']
05/25/2022 16:51:05 - INFO - __main__ - Tokenizing Input ...
05/25/2022 16:51:05 - INFO - __main__ - Tokenizing Output ...
05/25/2022 16:51:06 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 16:51:21 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 16:51:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 16:51:22 - INFO - __main__ - Starting training!
05/25/2022 16:51:26 - INFO - __main__ - Step 10 Global step 10 Train loss 4.92 on epoch=0
05/25/2022 16:51:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=1
05/25/2022 16:51:32 - INFO - __main__ - Step 30 Global step 30 Train loss 2.37 on epoch=2
05/25/2022 16:51:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.62 on epoch=2
05/25/2022 16:51:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.25 on epoch=3
05/25/2022 16:51:46 - INFO - __main__ - Global step 50 Train loss 2.71 Classification-F1 0.3095116821613975 on epoch=3
05/25/2022 16:51:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3095116821613975 on epoch=3, global_step=50
05/25/2022 16:51:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.99 on epoch=4
05/25/2022 16:51:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.82 on epoch=4
05/25/2022 16:51:55 - INFO - __main__ - Step 80 Global step 80 Train loss 0.74 on epoch=5
05/25/2022 16:51:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.67 on epoch=6
05/25/2022 16:52:01 - INFO - __main__ - Step 100 Global step 100 Train loss 0.73 on epoch=7
05/25/2022 16:52:09 - INFO - __main__ - Global step 100 Train loss 0.79 Classification-F1 0.5081358836729752 on epoch=7
05/25/2022 16:52:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3095116821613975 -> 0.5081358836729752 on epoch=7, global_step=100
05/25/2022 16:52:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.62 on epoch=7
05/25/2022 16:52:15 - INFO - __main__ - Step 120 Global step 120 Train loss 0.53 on epoch=8
05/25/2022 16:52:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=9
05/25/2022 16:52:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.47 on epoch=9
05/25/2022 16:52:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=10
05/25/2022 16:52:33 - INFO - __main__ - Global step 150 Train loss 0.54 Classification-F1 0.7482590782558656 on epoch=10
05/25/2022 16:52:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5081358836729752 -> 0.7482590782558656 on epoch=10, global_step=150
05/25/2022 16:52:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.43 on epoch=11
05/25/2022 16:52:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=12
05/25/2022 16:52:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=12
05/25/2022 16:52:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.38 on epoch=13
05/25/2022 16:52:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=14
05/25/2022 16:52:56 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.730465114546774 on epoch=14
05/25/2022 16:53:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=14
05/25/2022 16:53:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=15
05/25/2022 16:53:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
05/25/2022 16:53:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.39 on epoch=17
05/25/2022 16:53:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=17
05/25/2022 16:53:20 - INFO - __main__ - Global step 250 Train loss 0.35 Classification-F1 0.8281908944334401 on epoch=17
05/25/2022 16:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7482590782558656 -> 0.8281908944334401 on epoch=17, global_step=250
05/25/2022 16:53:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=18
05/25/2022 16:53:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=19
05/25/2022 16:53:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=19
05/25/2022 16:53:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=20
05/25/2022 16:53:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=21
05/25/2022 16:53:43 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.8270304208184964 on epoch=21
05/25/2022 16:53:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.17 on epoch=22
05/25/2022 16:53:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=22
05/25/2022 16:53:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=23
05/25/2022 16:53:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=24
05/25/2022 16:53:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=24
05/25/2022 16:54:06 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.5316609633891461 on epoch=24
05/25/2022 16:54:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=25
05/25/2022 16:54:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=26
05/25/2022 16:54:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=27
05/25/2022 16:54:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=27
05/25/2022 16:54:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=28
05/25/2022 16:54:30 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.8066628288891691 on epoch=28
05/25/2022 16:54:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=29
05/25/2022 16:54:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=29
05/25/2022 16:54:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
05/25/2022 16:54:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=31
05/25/2022 16:54:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=32
05/25/2022 16:54:54 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.7915156407330644 on epoch=32
05/25/2022 16:54:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=32
05/25/2022 16:55:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=33
05/25/2022 16:55:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
05/25/2022 16:55:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
05/25/2022 16:55:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
05/25/2022 16:55:17 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.722392543057565 on epoch=35
05/25/2022 16:55:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
05/25/2022 16:55:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=37
05/25/2022 16:55:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
05/25/2022 16:55:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=38
05/25/2022 16:55:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=39
05/25/2022 16:55:40 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.8827957660618951 on epoch=39
05/25/2022 16:55:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8281908944334401 -> 0.8827957660618951 on epoch=39, global_step=550
05/25/2022 16:55:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=39
05/25/2022 16:55:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
05/25/2022 16:55:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=41
05/25/2022 16:55:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=42
05/25/2022 16:55:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=42
05/25/2022 16:56:04 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.8062356592702811 on epoch=42
05/25/2022 16:56:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=43
05/25/2022 16:56:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=44
05/25/2022 16:56:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
05/25/2022 16:56:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
05/25/2022 16:56:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
05/25/2022 16:56:27 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.8350170151992438 on epoch=46
05/25/2022 16:56:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=47
05/25/2022 16:56:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=47
05/25/2022 16:56:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=48
05/25/2022 16:56:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=49
05/25/2022 16:56:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=49
05/25/2022 16:56:52 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.8424103380860889 on epoch=49
05/25/2022 16:56:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
05/25/2022 16:56:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
05/25/2022 16:57:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=52
05/25/2022 16:57:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
05/25/2022 16:57:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
05/25/2022 16:57:15 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.8348205968604451 on epoch=53
05/25/2022 16:57:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
05/25/2022 16:57:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=54
05/25/2022 16:57:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=55
05/25/2022 16:57:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
05/25/2022 16:57:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
05/25/2022 16:57:39 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6612588019092898 on epoch=57
05/25/2022 16:57:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
05/25/2022 16:57:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
05/25/2022 16:57:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=59
05/25/2022 16:57:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=59
05/25/2022 16:57:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=60
05/25/2022 16:58:03 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.9027879225981692 on epoch=60
05/25/2022 16:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8827957660618951 -> 0.9027879225981692 on epoch=60, global_step=850
05/25/2022 16:58:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
05/25/2022 16:58:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
05/25/2022 16:58:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
05/25/2022 16:58:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=63
05/25/2022 16:58:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
05/25/2022 16:58:26 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7415888530675339 on epoch=64
05/25/2022 16:58:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
05/25/2022 16:58:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=65
05/25/2022 16:58:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
05/25/2022 16:58:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
05/25/2022 16:58:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
05/25/2022 16:58:49 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.8101348695852915 on epoch=67
05/25/2022 16:58:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
05/25/2022 16:58:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
05/25/2022 16:58:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
05/25/2022 16:59:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=70
05/25/2022 16:59:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/25/2022 16:59:12 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.8387893573851828 on epoch=71
05/25/2022 16:59:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
05/25/2022 16:59:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=72
05/25/2022 16:59:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
05/25/2022 16:59:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=74
05/25/2022 16:59:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
05/25/2022 16:59:35 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9775031420192712 on epoch=74
05/25/2022 16:59:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9027879225981692 -> 0.9775031420192712 on epoch=74, global_step=1050
05/25/2022 16:59:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
05/25/2022 16:59:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
05/25/2022 16:59:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
05/25/2022 16:59:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
05/25/2022 16:59:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
05/25/2022 16:59:59 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8359321734558927 on epoch=78
05/25/2022 17:00:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
05/25/2022 17:00:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
05/25/2022 17:00:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/25/2022 17:00:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
05/25/2022 17:00:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
05/25/2022 17:00:22 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.9098726584037062 on epoch=82
05/25/2022 17:00:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
05/25/2022 17:00:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=83
05/25/2022 17:00:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
05/25/2022 17:00:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/25/2022 17:00:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
05/25/2022 17:00:45 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=85
05/25/2022 17:00:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
05/25/2022 17:00:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
05/25/2022 17:00:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/25/2022 17:00:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/25/2022 17:01:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
05/25/2022 17:01:08 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.8981025434611773 on epoch=89
05/25/2022 17:01:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
05/25/2022 17:01:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/25/2022 17:01:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=91
05/25/2022 17:01:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
05/25/2022 17:01:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/25/2022 17:01:31 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.9028124563608436 on epoch=92
05/25/2022 17:01:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
05/25/2022 17:01:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/25/2022 17:01:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
05/25/2022 17:01:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
05/25/2022 17:01:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
05/25/2022 17:01:55 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9122100032583904 on epoch=96
05/25/2022 17:01:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
05/25/2022 17:02:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
05/25/2022 17:02:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/25/2022 17:02:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
05/25/2022 17:02:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
05/25/2022 17:02:18 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8945157277526579 on epoch=99
05/25/2022 17:02:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
05/25/2022 17:02:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/25/2022 17:02:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/25/2022 17:02:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/25/2022 17:02:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/25/2022 17:02:41 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7695934678856879 on epoch=103
05/25/2022 17:02:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
05/25/2022 17:02:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/25/2022 17:02:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
05/25/2022 17:02:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/25/2022 17:02:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
05/25/2022 17:03:03 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=107
05/25/2022 17:03:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/25/2022 17:03:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=108
05/25/2022 17:03:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/25/2022 17:03:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
05/25/2022 17:03:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/25/2022 17:03:26 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9143449677036014 on epoch=110
05/25/2022 17:03:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=111
05/25/2022 17:03:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/25/2022 17:03:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/25/2022 17:03:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 17:03:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
05/25/2022 17:03:49 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=114
05/25/2022 17:03:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9775031420192712 -> 0.9865940511101802 on epoch=114, global_step=1600
05/25/2022 17:03:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/25/2022 17:03:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=115
05/25/2022 17:03:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/25/2022 17:04:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
05/25/2022 17:04:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/25/2022 17:04:12 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9012698323182194 on epoch=117
05/25/2022 17:04:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/25/2022 17:04:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
05/25/2022 17:04:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 17:04:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/25/2022 17:04:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/25/2022 17:04:35 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8508550796190657 on epoch=121
05/25/2022 17:04:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/25/2022 17:04:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/25/2022 17:04:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/25/2022 17:04:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
05/25/2022 17:04:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
05/25/2022 17:04:57 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.902158520690779 on epoch=124
05/25/2022 17:05:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 17:05:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
05/25/2022 17:05:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/25/2022 17:05:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
05/25/2022 17:05:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=128
05/25/2022 17:05:19 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.911301377833636 on epoch=128
05/25/2022 17:05:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/25/2022 17:05:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/25/2022 17:05:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/25/2022 17:05:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/25/2022 17:05:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/25/2022 17:05:42 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.901396094944482 on epoch=132
05/25/2022 17:05:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/25/2022 17:05:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 17:05:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/25/2022 17:05:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/25/2022 17:05:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 17:06:05 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9103045636631976 on epoch=135
05/25/2022 17:06:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/25/2022 17:06:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 17:06:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/25/2022 17:06:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=138
05/25/2022 17:06:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=139
05/25/2022 17:06:28 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=139
05/25/2022 17:06:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/25/2022 17:06:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/25/2022 17:06:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
05/25/2022 17:06:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
05/25/2022 17:06:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 17:06:52 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.806543614513254 on epoch=142
05/25/2022 17:06:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/25/2022 17:06:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/25/2022 17:07:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/25/2022 17:07:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/25/2022 17:07:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 17:07:14 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9163766699250571 on epoch=146
05/25/2022 17:07:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 17:07:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
05/25/2022 17:07:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
05/25/2022 17:07:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 17:07:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/25/2022 17:07:36 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9186746497230369 on epoch=149
05/25/2022 17:07:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
05/25/2022 17:07:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 17:07:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/25/2022 17:07:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 17:07:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
05/25/2022 17:07:59 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8381399245915375 on epoch=153
05/25/2022 17:08:02 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/25/2022 17:08:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 17:08:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
05/25/2022 17:08:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/25/2022 17:08:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
05/25/2022 17:08:21 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9084754353571559 on epoch=157
05/25/2022 17:08:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
05/25/2022 17:08:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/25/2022 17:08:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/25/2022 17:08:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 17:08:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/25/2022 17:08:43 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7825694900899991 on epoch=160
05/25/2022 17:08:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
05/25/2022 17:08:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/25/2022 17:08:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
05/25/2022 17:08:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/25/2022 17:08:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 17:09:05 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.8499837080482242 on epoch=164
05/25/2022 17:09:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/25/2022 17:09:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
05/25/2022 17:09:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 17:09:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/25/2022 17:09:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
05/25/2022 17:09:28 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.8328870755238217 on epoch=167
05/25/2022 17:09:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/25/2022 17:09:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 17:09:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/25/2022 17:09:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 17:09:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 17:09:51 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9730388563049855 on epoch=171
05/25/2022 17:09:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/25/2022 17:09:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/25/2022 17:10:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
05/25/2022 17:10:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
05/25/2022 17:10:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/25/2022 17:10:13 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.9038399171985513 on epoch=174
05/25/2022 17:10:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 17:10:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/25/2022 17:10:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/25/2022 17:10:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 17:10:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/25/2022 17:10:36 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9865984150258343 on epoch=178
05/25/2022 17:10:36 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101802 -> 0.9865984150258343 on epoch=178, global_step=2500
05/25/2022 17:10:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/25/2022 17:10:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/25/2022 17:10:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 17:10:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 17:10:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/25/2022 17:10:59 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.910329097425872 on epoch=182
05/25/2022 17:11:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/25/2022 17:11:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/25/2022 17:11:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/25/2022 17:11:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/25/2022 17:11:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 17:11:21 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.855327468230694 on epoch=185
05/25/2022 17:11:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 17:11:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 17:11:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/25/2022 17:11:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 17:11:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
05/25/2022 17:11:44 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.9821297653958947 on epoch=189
05/25/2022 17:11:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 17:11:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/25/2022 17:11:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
05/25/2022 17:11:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/25/2022 17:12:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
05/25/2022 17:12:07 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9144998370804823 on epoch=192
05/25/2022 17:12:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 17:12:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/25/2022 17:12:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 17:12:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/25/2022 17:12:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 17:12:29 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.9144998370804823 on epoch=196
05/25/2022 17:12:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 17:12:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/25/2022 17:12:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 17:12:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/25/2022 17:12:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/25/2022 17:12:52 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8551930596285435 on epoch=199
05/25/2022 17:12:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 17:12:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 17:13:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 17:13:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 17:13:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 17:13:15 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9143564679048553 on epoch=203
05/25/2022 17:13:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/25/2022 17:13:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 17:13:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/25/2022 17:13:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 17:13:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/25/2022 17:13:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9144998370804825 on epoch=207
05/25/2022 17:13:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 17:13:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 17:13:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 17:13:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/25/2022 17:13:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 17:14:00 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9776611157659547 on epoch=210
05/25/2022 17:14:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 17:14:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/25/2022 17:14:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 17:14:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 17:14:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/25/2022 17:14:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:14:18 - INFO - __main__ - Printing 3 examples
05/25/2022 17:14:18 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 17:14:18 - INFO - __main__ - ['Film']
05/25/2022 17:14:18 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 17:14:18 - INFO - __main__ - ['Film']
05/25/2022 17:14:18 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 17:14:18 - INFO - __main__ - ['Film']
05/25/2022 17:14:18 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:14:18 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:14:18 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 17:14:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:14:18 - INFO - __main__ - Printing 3 examples
05/25/2022 17:14:18 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 17:14:18 - INFO - __main__ - ['Film']
05/25/2022 17:14:18 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 17:14:18 - INFO - __main__ - ['Film']
05/25/2022 17:14:18 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 17:14:18 - INFO - __main__ - ['Film']
05/25/2022 17:14:18 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:14:18 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:14:18 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 17:14:23 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9143564679048553 on epoch=214
05/25/2022 17:14:23 - INFO - __main__ - save last model!
05/25/2022 17:14:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 17:14:23 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 17:14:23 - INFO - __main__ - Printing 3 examples
05/25/2022 17:14:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 17:14:23 - INFO - __main__ - ['Animal']
05/25/2022 17:14:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 17:14:23 - INFO - __main__ - ['Animal']
05/25/2022 17:14:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 17:14:23 - INFO - __main__ - ['Village']
05/25/2022 17:14:23 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:14:25 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:14:29 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 17:14:34 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 17:14:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 17:14:34 - INFO - __main__ - Starting training!
05/25/2022 17:16:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/25/2022 17:16:54 - INFO - __main__ - Classification-F1 on test data: 0.7572
05/25/2022 17:16:54 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9865984150258343, test_performance=0.7572423704021335
05/25/2022 17:16:54 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/25/2022 17:16:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:16:55 - INFO - __main__ - Printing 3 examples
05/25/2022 17:16:55 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 17:16:55 - INFO - __main__ - ['Film']
05/25/2022 17:16:55 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 17:16:55 - INFO - __main__ - ['Film']
05/25/2022 17:16:55 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 17:16:55 - INFO - __main__ - ['Film']
05/25/2022 17:16:55 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:16:55 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:16:55 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 17:16:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:16:55 - INFO - __main__ - Printing 3 examples
05/25/2022 17:16:55 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 17:16:55 - INFO - __main__ - ['Film']
05/25/2022 17:16:55 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 17:16:55 - INFO - __main__ - ['Film']
05/25/2022 17:16:55 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 17:16:55 - INFO - __main__ - ['Film']
05/25/2022 17:16:55 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:16:56 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:16:56 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 17:17:11 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 17:17:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 17:17:12 - INFO - __main__ - Starting training!
05/25/2022 17:17:16 - INFO - __main__ - Step 10 Global step 10 Train loss 5.16 on epoch=0
05/25/2022 17:17:19 - INFO - __main__ - Step 20 Global step 20 Train loss 3.57 on epoch=1
05/25/2022 17:17:22 - INFO - __main__ - Step 30 Global step 30 Train loss 2.56 on epoch=2
05/25/2022 17:17:25 - INFO - __main__ - Step 40 Global step 40 Train loss 1.86 on epoch=2
05/25/2022 17:17:28 - INFO - __main__ - Step 50 Global step 50 Train loss 1.53 on epoch=3
05/25/2022 17:17:34 - INFO - __main__ - Global step 50 Train loss 2.93 Classification-F1 0.35061958393273 on epoch=3
05/25/2022 17:17:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.35061958393273 on epoch=3, global_step=50
05/25/2022 17:17:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.26 on epoch=4
05/25/2022 17:17:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=4
05/25/2022 17:17:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=5
05/25/2022 17:17:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.73 on epoch=6
05/25/2022 17:17:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.71 on epoch=7
05/25/2022 17:17:57 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.7254059335944195 on epoch=7
05/25/2022 17:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.35061958393273 -> 0.7254059335944195 on epoch=7, global_step=100
05/25/2022 17:18:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=7
05/25/2022 17:18:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=8
05/25/2022 17:18:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.57 on epoch=9
05/25/2022 17:18:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.55 on epoch=9
05/25/2022 17:18:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.52 on epoch=10
05/25/2022 17:18:21 - INFO - __main__ - Global step 150 Train loss 0.55 Classification-F1 0.6116409347279221 on epoch=10
05/25/2022 17:18:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=11
05/25/2022 17:18:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=12
05/25/2022 17:18:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=12
05/25/2022 17:18:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=13
05/25/2022 17:18:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=14
05/25/2022 17:18:44 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.6028405385294175 on epoch=14
05/25/2022 17:18:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=14
05/25/2022 17:18:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.42 on epoch=15
05/25/2022 17:18:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=16
05/25/2022 17:18:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=17
05/25/2022 17:18:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=17
05/25/2022 17:19:08 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.8488342408864479 on epoch=17
05/25/2022 17:19:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7254059335944195 -> 0.8488342408864479 on epoch=17, global_step=250
05/25/2022 17:19:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=18
05/25/2022 17:19:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=19
05/25/2022 17:19:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=19
05/25/2022 17:19:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=20
05/25/2022 17:19:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=21
05/25/2022 17:19:32 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.8635277473648306 on epoch=21
05/25/2022 17:19:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8488342408864479 -> 0.8635277473648306 on epoch=21, global_step=300
05/25/2022 17:19:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=22
05/25/2022 17:19:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=22
05/25/2022 17:19:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=23
05/25/2022 17:19:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=24
05/25/2022 17:19:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
05/25/2022 17:19:56 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.8031037000197996 on epoch=24
05/25/2022 17:19:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=25
05/25/2022 17:20:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=26
05/25/2022 17:20:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=27
05/25/2022 17:20:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=27
05/25/2022 17:20:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=28
05/25/2022 17:20:21 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.7620913644169011 on epoch=28
05/25/2022 17:20:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=29
05/25/2022 17:20:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=29
05/25/2022 17:20:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
05/25/2022 17:20:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
05/25/2022 17:20:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
05/25/2022 17:20:45 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.9637871745421801 on epoch=32
05/25/2022 17:20:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8635277473648306 -> 0.9637871745421801 on epoch=32, global_step=450
05/25/2022 17:20:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=32
05/25/2022 17:20:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=33
05/25/2022 17:20:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=34
05/25/2022 17:20:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
05/25/2022 17:21:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=35
05/25/2022 17:21:10 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.9551154770230471 on epoch=35
05/25/2022 17:21:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
05/25/2022 17:21:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=37
05/25/2022 17:21:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
05/25/2022 17:21:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
05/25/2022 17:21:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
05/25/2022 17:21:34 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7354295815752173 on epoch=39
05/25/2022 17:21:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
05/25/2022 17:21:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
05/25/2022 17:21:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
05/25/2022 17:21:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=42
05/25/2022 17:21:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
05/25/2022 17:21:58 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.9061705767350929 on epoch=42
05/25/2022 17:22:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
05/25/2022 17:22:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
05/25/2022 17:22:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
05/25/2022 17:22:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
05/25/2022 17:22:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
05/25/2022 17:22:22 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.8523604944171179 on epoch=46
05/25/2022 17:22:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
05/25/2022 17:22:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
05/25/2022 17:22:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=48
05/25/2022 17:22:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
05/25/2022 17:22:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
05/25/2022 17:22:47 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.8476295210166178 on epoch=49
05/25/2022 17:22:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
05/25/2022 17:22:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
05/25/2022 17:22:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
05/25/2022 17:22:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
05/25/2022 17:23:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=53
05/25/2022 17:23:12 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.8890795190448401 on epoch=53
05/25/2022 17:23:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
05/25/2022 17:23:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
05/25/2022 17:23:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
05/25/2022 17:23:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
05/25/2022 17:23:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
05/25/2022 17:23:36 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.8959542558198473 on epoch=57
05/25/2022 17:23:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=57
05/25/2022 17:23:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
05/25/2022 17:23:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
05/25/2022 17:23:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
05/25/2022 17:23:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
05/25/2022 17:24:00 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.9865984150258343 on epoch=60
05/25/2022 17:24:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9637871745421801 -> 0.9865984150258343 on epoch=60, global_step=850
05/25/2022 17:24:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
05/25/2022 17:24:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
05/25/2022 17:24:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
05/25/2022 17:24:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
05/25/2022 17:24:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
05/25/2022 17:24:24 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.9822527251369758 on epoch=64
05/25/2022 17:24:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
05/25/2022 17:24:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
05/25/2022 17:24:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
05/25/2022 17:24:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
05/25/2022 17:24:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
05/25/2022 17:24:48 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7993034345012804 on epoch=67
05/25/2022 17:24:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
05/25/2022 17:24:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
05/25/2022 17:24:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
05/25/2022 17:25:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
05/25/2022 17:25:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
05/25/2022 17:25:11 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.9096234873765463 on epoch=71
05/25/2022 17:25:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
05/25/2022 17:25:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
05/25/2022 17:25:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
05/25/2022 17:25:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=74
05/25/2022 17:25:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
05/25/2022 17:25:34 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.903065700375947 on epoch=74
05/25/2022 17:25:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
05/25/2022 17:25:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
05/25/2022 17:25:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
05/25/2022 17:25:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
05/25/2022 17:25:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
05/25/2022 17:25:57 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8592145362543845 on epoch=78
05/25/2022 17:26:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
05/25/2022 17:26:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
05/25/2022 17:26:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
05/25/2022 17:26:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
05/25/2022 17:26:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
05/25/2022 17:26:19 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.9080106568531616 on epoch=82
05/25/2022 17:26:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
05/25/2022 17:26:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
05/25/2022 17:26:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
05/25/2022 17:26:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/25/2022 17:26:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
05/25/2022 17:26:42 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7473578840514326 on epoch=85
05/25/2022 17:26:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
05/25/2022 17:26:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
05/25/2022 17:26:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
05/25/2022 17:26:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
05/25/2022 17:26:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
05/25/2022 17:27:04 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7875337818411824 on epoch=89
05/25/2022 17:27:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
05/25/2022 17:27:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
05/25/2022 17:27:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=91
05/25/2022 17:27:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
05/25/2022 17:27:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=92
05/25/2022 17:27:27 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9776654796816088 on epoch=92
05/25/2022 17:27:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
05/25/2022 17:27:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
05/25/2022 17:27:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
05/25/2022 17:27:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
05/25/2022 17:27:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
05/25/2022 17:27:49 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.9821297653958947 on epoch=96
05/25/2022 17:27:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
05/25/2022 17:27:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/25/2022 17:27:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
05/25/2022 17:28:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
05/25/2022 17:28:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/25/2022 17:28:13 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9103045636631976 on epoch=99
05/25/2022 17:28:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
05/25/2022 17:28:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/25/2022 17:28:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
05/25/2022 17:28:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
05/25/2022 17:28:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
05/25/2022 17:28:36 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9186705767350929 on epoch=103
05/25/2022 17:28:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
05/25/2022 17:28:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
05/25/2022 17:28:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
05/25/2022 17:28:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/25/2022 17:28:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
05/25/2022 17:28:58 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9144868035190616 on epoch=107
05/25/2022 17:29:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/25/2022 17:29:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
05/25/2022 17:29:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
05/25/2022 17:29:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
05/25/2022 17:29:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/25/2022 17:29:21 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9077131601958206 on epoch=110
05/25/2022 17:29:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/25/2022 17:29:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/25/2022 17:29:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
05/25/2022 17:29:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/25/2022 17:29:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/25/2022 17:29:44 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9686712441574871 on epoch=114
05/25/2022 17:29:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/25/2022 17:29:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
05/25/2022 17:29:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
05/25/2022 17:29:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/25/2022 17:29:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/25/2022 17:30:06 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9777840755070358 on epoch=117
05/25/2022 17:30:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
05/25/2022 17:30:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
05/25/2022 17:30:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 17:30:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/25/2022 17:30:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
05/25/2022 17:30:30 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9774346789985081 on epoch=121
05/25/2022 17:30:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
05/25/2022 17:30:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/25/2022 17:30:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/25/2022 17:30:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/25/2022 17:30:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/25/2022 17:30:52 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8609970674486804 on epoch=124
05/25/2022 17:30:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/25/2022 17:30:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
05/25/2022 17:31:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/25/2022 17:31:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 17:31:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
05/25/2022 17:31:15 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9104520058267689 on epoch=128
05/25/2022 17:31:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/25/2022 17:31:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/25/2022 17:31:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=130
05/25/2022 17:31:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/25/2022 17:31:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/25/2022 17:31:38 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9144998370804823 on epoch=132
05/25/2022 17:31:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/25/2022 17:31:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/25/2022 17:31:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/25/2022 17:31:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 17:31:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
05/25/2022 17:32:01 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9865984150258343 on epoch=135
05/25/2022 17:32:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/25/2022 17:32:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 17:32:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/25/2022 17:32:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=138
05/25/2022 17:32:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=139
05/25/2022 17:32:24 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9103045636631976 on epoch=139
05/25/2022 17:32:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
05/25/2022 17:32:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 17:32:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/25/2022 17:32:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/25/2022 17:32:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
05/25/2022 17:32:46 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=142
05/25/2022 17:32:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/25/2022 17:32:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/25/2022 17:32:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/25/2022 17:32:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/25/2022 17:33:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
05/25/2022 17:33:08 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8483920254318736 on epoch=146
05/25/2022 17:33:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 17:33:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
05/25/2022 17:33:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/25/2022 17:33:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 17:33:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
05/25/2022 17:33:31 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.986440441279151 on epoch=149
05/25/2022 17:33:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/25/2022 17:33:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/25/2022 17:33:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 17:33:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/25/2022 17:33:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 17:33:53 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=153
05/25/2022 17:33:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9865984150258343 -> 0.9867213747669157 on epoch=153, global_step=2150
05/25/2022 17:33:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
05/25/2022 17:33:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/25/2022 17:34:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 17:34:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/25/2022 17:34:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 17:34:16 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=157
05/25/2022 17:34:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/25/2022 17:34:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/25/2022 17:34:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/25/2022 17:34:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/25/2022 17:34:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/25/2022 17:34:39 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=160
05/25/2022 17:34:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/25/2022 17:34:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/25/2022 17:34:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/25/2022 17:34:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/25/2022 17:34:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 17:35:01 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=164
05/25/2022 17:35:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/25/2022 17:35:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
05/25/2022 17:35:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 17:35:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/25/2022 17:35:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
05/25/2022 17:35:23 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9865677649358864 on epoch=167
05/25/2022 17:35:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/25/2022 17:35:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
05/25/2022 17:35:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/25/2022 17:35:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 17:35:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/25/2022 17:35:46 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.9686668802418329 on epoch=171
05/25/2022 17:35:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/25/2022 17:35:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 17:35:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 17:35:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 17:36:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/25/2022 17:36:08 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9144998370804823 on epoch=174
05/25/2022 17:36:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 17:36:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/25/2022 17:36:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/25/2022 17:36:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/25/2022 17:36:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/25/2022 17:36:31 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9775031420192712 on epoch=178
05/25/2022 17:36:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/25/2022 17:36:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/25/2022 17:36:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 17:36:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
05/25/2022 17:36:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/25/2022 17:36:54 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8530195215916279 on epoch=182
05/25/2022 17:36:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/25/2022 17:37:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/25/2022 17:37:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/25/2022 17:37:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/25/2022 17:37:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/25/2022 17:37:16 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.9187894121480461 on epoch=185
05/25/2022 17:37:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/25/2022 17:37:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/25/2022 17:37:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/25/2022 17:37:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/25/2022 17:37:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 17:37:39 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9071020314284072 on epoch=189
05/25/2022 17:37:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 17:37:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/25/2022 17:37:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
05/25/2022 17:37:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/25/2022 17:37:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 17:38:01 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8081865570578519 on epoch=192
05/25/2022 17:38:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 17:38:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/25/2022 17:38:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=194
05/25/2022 17:38:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/25/2022 17:38:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/25/2022 17:38:23 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9096072386394968 on epoch=196
05/25/2022 17:38:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/25/2022 17:38:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/25/2022 17:38:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 17:38:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 17:38:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 17:38:46 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.9011223901546482 on epoch=199
05/25/2022 17:38:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/25/2022 17:38:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 17:38:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 17:38:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 17:39:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/25/2022 17:39:08 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8257736131476051 on epoch=203
05/25/2022 17:39:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
05/25/2022 17:39:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 17:39:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 17:39:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/25/2022 17:39:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/25/2022 17:39:31 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6755804090269285 on epoch=207
05/25/2022 17:39:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 17:39:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/25/2022 17:39:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 17:39:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/25/2022 17:39:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 17:39:53 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.721869542040102 on epoch=210
05/25/2022 17:39:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 17:39:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 17:40:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/25/2022 17:40:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 17:40:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 17:40:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:40:10 - INFO - __main__ - Printing 3 examples
05/25/2022 17:40:10 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 17:40:10 - INFO - __main__ - ['Film']
05/25/2022 17:40:10 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 17:40:10 - INFO - __main__ - ['Film']
05/25/2022 17:40:10 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 17:40:10 - INFO - __main__ - ['Film']
05/25/2022 17:40:10 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:40:10 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:40:10 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 17:40:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:40:10 - INFO - __main__ - Printing 3 examples
05/25/2022 17:40:10 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 17:40:10 - INFO - __main__ - ['Film']
05/25/2022 17:40:10 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 17:40:10 - INFO - __main__ - ['Film']
05/25/2022 17:40:10 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 17:40:10 - INFO - __main__ - ['Film']
05/25/2022 17:40:10 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:40:10 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:40:11 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 17:40:15 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8668410662098869 on epoch=214
05/25/2022 17:40:15 - INFO - __main__ - save last model!
05/25/2022 17:40:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 17:40:16 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 17:40:16 - INFO - __main__ - Printing 3 examples
05/25/2022 17:40:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 17:40:16 - INFO - __main__ - ['Animal']
05/25/2022 17:40:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 17:40:16 - INFO - __main__ - ['Animal']
05/25/2022 17:40:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 17:40:16 - INFO - __main__ - ['Village']
05/25/2022 17:40:16 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:40:17 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:40:21 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 17:40:26 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 17:40:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 17:40:27 - INFO - __main__ - Starting training!
05/25/2022 17:42:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/25/2022 17:42:47 - INFO - __main__ - Classification-F1 on test data: 0.5694
05/25/2022 17:42:47 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9867213747669157, test_performance=0.569355050356881
05/25/2022 17:42:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/25/2022 17:42:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:42:48 - INFO - __main__ - Printing 3 examples
05/25/2022 17:42:48 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 17:42:48 - INFO - __main__ - ['Film']
05/25/2022 17:42:48 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 17:42:48 - INFO - __main__ - ['Film']
05/25/2022 17:42:48 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 17:42:48 - INFO - __main__ - ['Film']
05/25/2022 17:42:48 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:42:48 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:42:48 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 17:42:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 17:42:48 - INFO - __main__ - Printing 3 examples
05/25/2022 17:42:48 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 17:42:48 - INFO - __main__ - ['Film']
05/25/2022 17:42:48 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 17:42:48 - INFO - __main__ - ['Film']
05/25/2022 17:42:48 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 17:42:48 - INFO - __main__ - ['Film']
05/25/2022 17:42:48 - INFO - __main__ - Tokenizing Input ...
05/25/2022 17:42:48 - INFO - __main__ - Tokenizing Output ...
05/25/2022 17:42:48 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 17:43:07 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 17:43:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 17:43:08 - INFO - __main__ - Starting training!
05/25/2022 17:43:12 - INFO - __main__ - Step 10 Global step 10 Train loss 5.53 on epoch=0
05/25/2022 17:43:15 - INFO - __main__ - Step 20 Global step 20 Train loss 3.96 on epoch=1
05/25/2022 17:43:18 - INFO - __main__ - Step 30 Global step 30 Train loss 3.09 on epoch=2
05/25/2022 17:43:21 - INFO - __main__ - Step 40 Global step 40 Train loss 2.41 on epoch=2
05/25/2022 17:43:24 - INFO - __main__ - Step 50 Global step 50 Train loss 1.91 on epoch=3
05/25/2022 17:43:29 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.14872912127814086 on epoch=3
05/25/2022 17:43:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.14872912127814086 on epoch=3, global_step=50
05/25/2022 17:43:32 - INFO - __main__ - Step 60 Global step 60 Train loss 1.60 on epoch=4
05/25/2022 17:43:35 - INFO - __main__ - Step 70 Global step 70 Train loss 1.25 on epoch=4
05/25/2022 17:43:38 - INFO - __main__ - Step 80 Global step 80 Train loss 1.10 on epoch=5
05/25/2022 17:43:41 - INFO - __main__ - Step 90 Global step 90 Train loss 1.03 on epoch=6
05/25/2022 17:43:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=7
05/25/2022 17:43:52 - INFO - __main__ - Global step 100 Train loss 1.19 Classification-F1 0.5933123281198934 on epoch=7
05/25/2022 17:43:52 - INFO - __main__ - Saving model with best Classification-F1: 0.14872912127814086 -> 0.5933123281198934 on epoch=7, global_step=100
05/25/2022 17:43:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=7
05/25/2022 17:43:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=8
05/25/2022 17:44:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=9
05/25/2022 17:44:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=9
05/25/2022 17:44:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=10
05/25/2022 17:44:15 - INFO - __main__ - Global step 150 Train loss 0.72 Classification-F1 0.6672575125665187 on epoch=10
05/25/2022 17:44:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5933123281198934 -> 0.6672575125665187 on epoch=10, global_step=150
05/25/2022 17:44:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=11
05/25/2022 17:44:21 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=12
05/25/2022 17:44:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=12
05/25/2022 17:44:27 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=13
05/25/2022 17:44:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=14
05/25/2022 17:44:38 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.6767857788674844 on epoch=14
05/25/2022 17:44:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6672575125665187 -> 0.6767857788674844 on epoch=14, global_step=200
05/25/2022 17:44:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=14
05/25/2022 17:44:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.47 on epoch=15
05/25/2022 17:44:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=16
05/25/2022 17:44:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=17
05/25/2022 17:44:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=17
05/25/2022 17:45:00 - INFO - __main__ - Global step 250 Train loss 0.43 Classification-F1 0.7885520750842464 on epoch=17
05/25/2022 17:45:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6767857788674844 -> 0.7885520750842464 on epoch=17, global_step=250
05/25/2022 17:45:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
05/25/2022 17:45:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=19
05/25/2022 17:45:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
05/25/2022 17:45:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=20
05/25/2022 17:45:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=21
05/25/2022 17:45:23 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6470130965387132 on epoch=21
05/25/2022 17:45:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
05/25/2022 17:45:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=22
05/25/2022 17:45:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=23
05/25/2022 17:45:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
05/25/2022 17:45:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
05/25/2022 17:45:45 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.7304270964250803 on epoch=24
05/25/2022 17:45:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
05/25/2022 17:45:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=26
05/25/2022 17:45:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=27
05/25/2022 17:45:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=27
05/25/2022 17:46:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
05/25/2022 17:46:09 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.7645949737857413 on epoch=28
05/25/2022 17:46:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
05/25/2022 17:46:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
05/25/2022 17:46:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=30
05/25/2022 17:46:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
05/25/2022 17:46:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=32
05/25/2022 17:46:32 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.8277136044654488 on epoch=32
05/25/2022 17:46:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7885520750842464 -> 0.8277136044654488 on epoch=32, global_step=450
05/25/2022 17:46:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
05/25/2022 17:46:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=33
05/25/2022 17:46:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=34
05/25/2022 17:46:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
05/25/2022 17:46:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=35
05/25/2022 17:46:55 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.7435026064376438 on epoch=35
05/25/2022 17:46:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
05/25/2022 17:47:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
05/25/2022 17:47:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
05/25/2022 17:47:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
05/25/2022 17:47:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
05/25/2022 17:47:18 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.7149553206594165 on epoch=39
05/25/2022 17:47:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
05/25/2022 17:47:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
05/25/2022 17:47:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
05/25/2022 17:47:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=42
05/25/2022 17:47:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=42
05/25/2022 17:47:41 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.7716807544132024 on epoch=42
05/25/2022 17:47:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
05/25/2022 17:47:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
05/25/2022 17:47:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
05/25/2022 17:47:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
05/25/2022 17:47:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=46
05/25/2022 17:48:04 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7147973670204253 on epoch=46
05/25/2022 17:48:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
05/25/2022 17:48:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
05/25/2022 17:48:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
05/25/2022 17:48:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
05/25/2022 17:48:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
05/25/2022 17:48:28 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7314044733689927 on epoch=49
05/25/2022 17:48:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
05/25/2022 17:48:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
05/25/2022 17:48:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
05/25/2022 17:48:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
05/25/2022 17:48:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
05/25/2022 17:48:52 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.8848308700903087 on epoch=53
05/25/2022 17:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8277136044654488 -> 0.8848308700903087 on epoch=53, global_step=750
05/25/2022 17:48:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
05/25/2022 17:48:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
05/25/2022 17:49:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=55
05/25/2022 17:49:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
05/25/2022 17:49:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
05/25/2022 17:49:15 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6239734337803757 on epoch=57
05/25/2022 17:49:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
05/25/2022 17:49:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
05/25/2022 17:49:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
05/25/2022 17:49:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
05/25/2022 17:49:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
05/25/2022 17:49:39 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7179490446252562 on epoch=60
05/25/2022 17:49:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
05/25/2022 17:49:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
05/25/2022 17:49:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
05/25/2022 17:49:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
05/25/2022 17:49:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
05/25/2022 17:50:02 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7107875239209875 on epoch=64
05/25/2022 17:50:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
05/25/2022 17:50:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
05/25/2022 17:50:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
05/25/2022 17:50:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
05/25/2022 17:50:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
05/25/2022 17:50:26 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6795608133668655 on epoch=67
05/25/2022 17:50:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
05/25/2022 17:50:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
05/25/2022 17:50:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
05/25/2022 17:50:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
05/25/2022 17:50:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
05/25/2022 17:50:50 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.782269395596776 on epoch=71
05/25/2022 17:50:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=72
05/25/2022 17:50:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
05/25/2022 17:50:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
05/25/2022 17:51:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=74
05/25/2022 17:51:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
05/25/2022 17:51:13 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.8120750637131686 on epoch=74
05/25/2022 17:51:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
05/25/2022 17:51:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
05/25/2022 17:51:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
05/25/2022 17:51:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
05/25/2022 17:51:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
05/25/2022 17:51:36 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.9019168644975099 on epoch=78
05/25/2022 17:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8848308700903087 -> 0.9019168644975099 on epoch=78, global_step=1100
05/25/2022 17:51:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
05/25/2022 17:51:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
05/25/2022 17:51:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/25/2022 17:51:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
05/25/2022 17:51:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
05/25/2022 17:52:01 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.899497943512862 on epoch=82
05/25/2022 17:52:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
05/25/2022 17:52:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
05/25/2022 17:52:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
05/25/2022 17:52:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
05/25/2022 17:52:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
05/25/2022 17:52:24 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9020688862055088 on epoch=85
05/25/2022 17:52:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9019168644975099 -> 0.9020688862055088 on epoch=85, global_step=1200
05/25/2022 17:52:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
05/25/2022 17:52:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=87
05/25/2022 17:52:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
05/25/2022 17:52:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
05/25/2022 17:52:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
05/25/2022 17:52:48 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.90803926360378 on epoch=89
05/25/2022 17:52:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9020688862055088 -> 0.90803926360378 on epoch=89, global_step=1250
05/25/2022 17:52:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
05/25/2022 17:52:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
05/25/2022 17:52:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
05/25/2022 17:53:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
05/25/2022 17:53:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
05/25/2022 17:53:11 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9686181538547264 on epoch=92
05/25/2022 17:53:11 - INFO - __main__ - Saving model with best Classification-F1: 0.90803926360378 -> 0.9686181538547264 on epoch=92, global_step=1300
05/25/2022 17:53:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/25/2022 17:53:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/25/2022 17:53:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/25/2022 17:53:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/25/2022 17:53:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
05/25/2022 17:53:35 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8492706805962855 on epoch=96
05/25/2022 17:53:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
05/25/2022 17:53:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/25/2022 17:53:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
05/25/2022 17:53:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
05/25/2022 17:53:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
05/25/2022 17:53:59 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9515661797980497 on epoch=99
05/25/2022 17:54:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
05/25/2022 17:54:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
05/25/2022 17:54:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 17:54:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
05/25/2022 17:54:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/25/2022 17:54:23 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8968897830552394 on epoch=103
05/25/2022 17:54:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
05/25/2022 17:54:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
05/25/2022 17:54:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
05/25/2022 17:54:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
05/25/2022 17:54:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
05/25/2022 17:54:46 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8971708504077806 on epoch=107
05/25/2022 17:54:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/25/2022 17:54:53 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
05/25/2022 17:54:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/25/2022 17:54:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/25/2022 17:55:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
05/25/2022 17:55:10 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8173026599394061 on epoch=110
05/25/2022 17:55:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/25/2022 17:55:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
05/25/2022 17:55:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/25/2022 17:55:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/25/2022 17:55:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
05/25/2022 17:55:33 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8472804679562187 on epoch=114
05/25/2022 17:55:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/25/2022 17:55:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/25/2022 17:55:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/25/2022 17:55:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/25/2022 17:55:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/25/2022 17:55:57 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9731845084074686 on epoch=117
05/25/2022 17:55:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9686181538547264 -> 0.9731845084074686 on epoch=117, global_step=1650
05/25/2022 17:56:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
05/25/2022 17:56:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
05/25/2022 17:56:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/25/2022 17:56:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/25/2022 17:56:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/25/2022 17:56:20 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8342553798051225 on epoch=121
05/25/2022 17:56:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
05/25/2022 17:56:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
05/25/2022 17:56:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/25/2022 17:56:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/25/2022 17:56:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
05/25/2022 17:56:43 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9145039100684262 on epoch=124
05/25/2022 17:56:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/25/2022 17:56:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/25/2022 17:56:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
05/25/2022 17:56:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 17:56:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
05/25/2022 17:57:06 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8491400904203323 on epoch=128
05/25/2022 17:57:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
05/25/2022 17:57:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/25/2022 17:57:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
05/25/2022 17:57:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/25/2022 17:57:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
05/25/2022 17:57:30 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8983467466319759 on epoch=132
05/25/2022 17:57:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/25/2022 17:57:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/25/2022 17:57:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/25/2022 17:57:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 17:57:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/25/2022 17:57:53 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.837123345173088 on epoch=135
05/25/2022 17:57:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/25/2022 17:57:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/25/2022 17:58:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/25/2022 17:58:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/25/2022 17:58:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/25/2022 17:58:16 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8304414863875846 on epoch=139
05/25/2022 17:58:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
05/25/2022 17:58:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/25/2022 17:58:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/25/2022 17:58:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/25/2022 17:58:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/25/2022 17:58:38 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6638843928180721 on epoch=142
05/25/2022 17:58:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/25/2022 17:58:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/25/2022 17:58:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/25/2022 17:58:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/25/2022 17:58:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 17:59:01 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7723443139171303 on epoch=146
05/25/2022 17:59:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
05/25/2022 17:59:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
05/25/2022 17:59:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/25/2022 17:59:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/25/2022 17:59:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/25/2022 17:59:24 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8026089594498939 on epoch=149
05/25/2022 17:59:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/25/2022 17:59:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/25/2022 17:59:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/25/2022 17:59:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 17:59:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 17:59:47 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8483920254318736 on epoch=153
05/25/2022 17:59:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/25/2022 17:59:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/25/2022 17:59:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 17:59:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/25/2022 18:00:02 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 18:00:10 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8376700592260364 on epoch=157
05/25/2022 18:00:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 18:00:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/25/2022 18:00:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
05/25/2022 18:00:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/25/2022 18:00:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/25/2022 18:00:33 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9077090872078768 on epoch=160
05/25/2022 18:00:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
05/25/2022 18:00:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/25/2022 18:00:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
05/25/2022 18:00:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/25/2022 18:00:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
05/25/2022 18:00:56 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9060075613823242 on epoch=164
05/25/2022 18:00:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/25/2022 18:01:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
05/25/2022 18:01:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 18:01:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/25/2022 18:01:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 18:01:19 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8966140874727214 on epoch=167
05/25/2022 18:01:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
05/25/2022 18:01:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/25/2022 18:01:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/25/2022 18:01:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/25/2022 18:01:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/25/2022 18:01:41 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.914360540892799 on epoch=171
05/25/2022 18:01:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/25/2022 18:01:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/25/2022 18:01:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/25/2022 18:01:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/25/2022 18:01:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/25/2022 18:02:04 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8330873091961801 on epoch=174
05/25/2022 18:02:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/25/2022 18:02:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 18:02:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/25/2022 18:02:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/25/2022 18:02:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/25/2022 18:02:27 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8410448688778778 on epoch=178
05/25/2022 18:02:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/25/2022 18:02:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/25/2022 18:02:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/25/2022 18:02:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 18:02:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
05/25/2022 18:02:50 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9103413163897035 on epoch=182
05/25/2022 18:02:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/25/2022 18:02:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
05/25/2022 18:02:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/25/2022 18:03:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/25/2022 18:03:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/25/2022 18:03:13 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9060272075594659 on epoch=185
05/25/2022 18:03:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 18:03:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/25/2022 18:03:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/25/2022 18:03:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/25/2022 18:03:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/25/2022 18:03:35 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9776304656760065 on epoch=189
05/25/2022 18:03:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9731845084074686 -> 0.9776304656760065 on epoch=189, global_step=2650
05/25/2022 18:03:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/25/2022 18:03:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/25/2022 18:03:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/25/2022 18:03:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/25/2022 18:03:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/25/2022 18:03:58 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9776567518503005 on epoch=192
05/25/2022 18:03:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9776304656760065 -> 0.9776567518503005 on epoch=192, global_step=2700
05/25/2022 18:04:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 18:04:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/25/2022 18:04:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/25/2022 18:04:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 18:04:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/25/2022 18:04:20 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9821341293115486 on epoch=196
05/25/2022 18:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9776567518503005 -> 0.9821341293115486 on epoch=196, global_step=2750
05/25/2022 18:04:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/25/2022 18:04:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/25/2022 18:04:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/25/2022 18:04:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/25/2022 18:04:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 18:04:43 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.9821341293115486 on epoch=199
05/25/2022 18:04:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/25/2022 18:04:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/25/2022 18:04:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/25/2022 18:04:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/25/2022 18:04:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/25/2022 18:05:06 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9016696606845793 on epoch=203
05/25/2022 18:05:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/25/2022 18:05:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 18:05:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/25/2022 18:05:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 18:05:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/25/2022 18:05:28 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9865940511101802 on epoch=207
05/25/2022 18:05:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9821341293115486 -> 0.9865940511101802 on epoch=207, global_step=2900
05/25/2022 18:05:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 18:05:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/25/2022 18:05:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/25/2022 18:05:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/25/2022 18:05:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 18:05:51 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9865940511101802 on epoch=210
05/25/2022 18:05:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/25/2022 18:05:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/25/2022 18:06:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
05/25/2022 18:06:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 18:06:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 18:06:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 18:06:08 - INFO - __main__ - Printing 3 examples
05/25/2022 18:06:08 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 18:06:08 - INFO - __main__ - ['Film']
05/25/2022 18:06:08 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 18:06:08 - INFO - __main__ - ['Film']
05/25/2022 18:06:08 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 18:06:08 - INFO - __main__ - ['Film']
05/25/2022 18:06:08 - INFO - __main__ - Tokenizing Input ...
05/25/2022 18:06:08 - INFO - __main__ - Tokenizing Output ...
05/25/2022 18:06:09 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 18:06:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 18:06:09 - INFO - __main__ - Printing 3 examples
05/25/2022 18:06:09 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 18:06:09 - INFO - __main__ - ['Film']
05/25/2022 18:06:09 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 18:06:09 - INFO - __main__ - ['Film']
05/25/2022 18:06:09 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 18:06:09 - INFO - __main__ - ['Film']
05/25/2022 18:06:09 - INFO - __main__ - Tokenizing Input ...
05/25/2022 18:06:09 - INFO - __main__ - Tokenizing Output ...
05/25/2022 18:06:09 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 18:06:14 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9058322543633021 on epoch=214
05/25/2022 18:06:14 - INFO - __main__ - save last model!
05/25/2022 18:06:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 18:06:14 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 18:06:14 - INFO - __main__ - Printing 3 examples
05/25/2022 18:06:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 18:06:14 - INFO - __main__ - ['Animal']
05/25/2022 18:06:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 18:06:14 - INFO - __main__ - ['Animal']
05/25/2022 18:06:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 18:06:14 - INFO - __main__ - ['Village']
05/25/2022 18:06:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 18:06:16 - INFO - __main__ - Tokenizing Output ...
05/25/2022 18:06:19 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 18:06:24 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 18:06:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 18:06:25 - INFO - __main__ - Starting training!
05/25/2022 18:08:42 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/25/2022 18:08:42 - INFO - __main__ - Classification-F1 on test data: 0.7583
05/25/2022 18:08:42 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9865940511101802, test_performance=0.7582732481001839
05/25/2022 18:08:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/25/2022 18:08:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 18:08:43 - INFO - __main__ - Printing 3 examples
05/25/2022 18:08:43 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 18:08:43 - INFO - __main__ - ['Film']
05/25/2022 18:08:43 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 18:08:43 - INFO - __main__ - ['Film']
05/25/2022 18:08:43 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 18:08:43 - INFO - __main__ - ['Film']
05/25/2022 18:08:43 - INFO - __main__ - Tokenizing Input ...
05/25/2022 18:08:43 - INFO - __main__ - Tokenizing Output ...
05/25/2022 18:08:43 - INFO - __main__ - Loaded 224 examples from train data
05/25/2022 18:08:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/25/2022 18:08:43 - INFO - __main__ - Printing 3 examples
05/25/2022 18:08:43 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/25/2022 18:08:43 - INFO - __main__ - ['Film']
05/25/2022 18:08:43 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
05/25/2022 18:08:43 - INFO - __main__ - ['Film']
05/25/2022 18:08:43 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/25/2022 18:08:43 - INFO - __main__ - ['Film']
05/25/2022 18:08:43 - INFO - __main__ - Tokenizing Input ...
05/25/2022 18:08:44 - INFO - __main__ - Tokenizing Output ...
05/25/2022 18:08:44 - INFO - __main__ - Loaded 224 examples from dev data
05/25/2022 18:08:59 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 18:09:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
05/25/2022 18:09:00 - INFO - __main__ - Starting training!
05/25/2022 18:09:04 - INFO - __main__ - Step 10 Global step 10 Train loss 5.76 on epoch=0
05/25/2022 18:09:07 - INFO - __main__ - Step 20 Global step 20 Train loss 4.56 on epoch=1
05/25/2022 18:09:10 - INFO - __main__ - Step 30 Global step 30 Train loss 3.72 on epoch=2
05/25/2022 18:09:13 - INFO - __main__ - Step 40 Global step 40 Train loss 3.24 on epoch=2
05/25/2022 18:09:16 - INFO - __main__ - Step 50 Global step 50 Train loss 2.79 on epoch=3
05/25/2022 18:09:20 - INFO - __main__ - Global step 50 Train loss 4.01 Classification-F1 0.009523809523809523 on epoch=3
05/25/2022 18:09:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/25/2022 18:09:24 - INFO - __main__ - Step 60 Global step 60 Train loss 2.62 on epoch=4
05/25/2022 18:09:27 - INFO - __main__ - Step 70 Global step 70 Train loss 2.01 on epoch=4
05/25/2022 18:09:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.95 on epoch=5
05/25/2022 18:09:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.64 on epoch=6
05/25/2022 18:09:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.30 on epoch=7
05/25/2022 18:09:42 - INFO - __main__ - Global step 100 Train loss 1.90 Classification-F1 0.3286626766714454 on epoch=7
05/25/2022 18:09:42 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.3286626766714454 on epoch=7, global_step=100
05/25/2022 18:09:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.25 on epoch=7
05/25/2022 18:09:48 - INFO - __main__ - Step 120 Global step 120 Train loss 1.21 on epoch=8
05/25/2022 18:09:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.04 on epoch=9
05/25/2022 18:09:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.89 on epoch=9
05/25/2022 18:09:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=10
05/25/2022 18:10:05 - INFO - __main__ - Global step 150 Train loss 1.04 Classification-F1 0.45348103790584315 on epoch=10
05/25/2022 18:10:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3286626766714454 -> 0.45348103790584315 on epoch=10, global_step=150
05/25/2022 18:10:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
05/25/2022 18:10:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=12
05/25/2022 18:10:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=12
05/25/2022 18:10:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=13
05/25/2022 18:10:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
05/25/2022 18:10:28 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.4279250310305339 on epoch=14
05/25/2022 18:10:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=14
05/25/2022 18:10:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=15
05/25/2022 18:10:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=16
05/25/2022 18:10:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=17
05/25/2022 18:10:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=17
05/25/2022 18:10:51 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.6409988576790597 on epoch=17
05/25/2022 18:10:51 - INFO - __main__ - Saving model with best Classification-F1: 0.45348103790584315 -> 0.6409988576790597 on epoch=17, global_step=250
05/25/2022 18:10:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=18
05/25/2022 18:10:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=19
05/25/2022 18:11:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=19
05/25/2022 18:11:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=20
05/25/2022 18:11:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=21
05/25/2022 18:11:14 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.6719542307392166 on epoch=21
05/25/2022 18:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6409988576790597 -> 0.6719542307392166 on epoch=21, global_step=300
05/25/2022 18:11:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=22
05/25/2022 18:11:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=22
05/25/2022 18:11:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=23
05/25/2022 18:11:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=24
05/25/2022 18:11:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=24
05/25/2022 18:11:37 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.6677419175844498 on epoch=24
05/25/2022 18:11:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=25
05/25/2022 18:11:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
05/25/2022 18:11:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=27
05/25/2022 18:11:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=27
05/25/2022 18:11:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=28
05/25/2022 18:12:01 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.8375386854502767 on epoch=28
05/25/2022 18:12:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6719542307392166 -> 0.8375386854502767 on epoch=28, global_step=400
05/25/2022 18:12:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=29
05/25/2022 18:12:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=29
05/25/2022 18:12:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
05/25/2022 18:12:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=31
05/25/2022 18:12:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=32
05/25/2022 18:12:24 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.7716330676830906 on epoch=32
05/25/2022 18:12:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=32
05/25/2022 18:12:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
05/25/2022 18:12:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
05/25/2022 18:12:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=34
05/25/2022 18:12:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=35
05/25/2022 18:12:48 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.7847675801001849 on epoch=35
05/25/2022 18:12:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=36
05/25/2022 18:12:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
05/25/2022 18:12:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
05/25/2022 18:13:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=38
05/25/2022 18:13:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=39
05/25/2022 18:13:11 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.7953166613039842 on epoch=39
05/25/2022 18:13:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
05/25/2022 18:13:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=40
05/25/2022 18:13:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=41
05/25/2022 18:13:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
05/25/2022 18:13:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
05/25/2022 18:13:35 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.8685015112764473 on epoch=42
05/25/2022 18:13:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8375386854502767 -> 0.8685015112764473 on epoch=42, global_step=600
05/25/2022 18:13:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=43
05/25/2022 18:13:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
05/25/2022 18:13:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
05/25/2022 18:13:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=45
05/25/2022 18:13:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=46
05/25/2022 18:13:58 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.8269202337290392 on epoch=46
05/25/2022 18:14:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=47
05/25/2022 18:14:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=47
05/25/2022 18:14:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=48
05/25/2022 18:14:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
05/25/2022 18:14:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
05/25/2022 18:14:21 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.7467119941443945 on epoch=49
05/25/2022 18:14:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
05/25/2022 18:14:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
05/25/2022 18:14:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
05/25/2022 18:14:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=52
05/25/2022 18:14:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
05/25/2022 18:14:44 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.7991508401992272 on epoch=53
05/25/2022 18:14:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=54
05/25/2022 18:14:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=54
05/25/2022 18:14:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=55
05/25/2022 18:14:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
05/25/2022 18:14:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
05/25/2022 18:15:07 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.8712423393938804 on epoch=57
05/25/2022 18:15:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8685015112764473 -> 0.8712423393938804 on epoch=57, global_step=800
05/25/2022 18:15:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
05/25/2022 18:15:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
05/25/2022 18:15:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
05/25/2022 18:15:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=59
05/25/2022 18:15:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
05/25/2022 18:15:30 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.8844054342710258 on epoch=60
05/25/2022 18:15:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8712423393938804 -> 0.8844054342710258 on epoch=60, global_step=850
05/25/2022 18:15:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
05/25/2022 18:15:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
05/25/2022 18:15:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
05/25/2022 18:15:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
05/25/2022 18:15:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
05/25/2022 18:15:53 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.6843769683354518 on epoch=64
05/25/2022 18:15:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
05/25/2022 18:15:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
05/25/2022 18:16:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
05/25/2022 18:16:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
05/25/2022 18:16:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
05/25/2022 18:16:16 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7831018468604451 on epoch=67
05/25/2022 18:16:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
05/25/2022 18:16:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
05/25/2022 18:16:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
05/25/2022 18:16:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
05/25/2022 18:16:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
05/25/2022 18:16:39 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7379657321322128 on epoch=71
05/25/2022 18:16:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
05/25/2022 18:16:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
05/25/2022 18:16:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
05/25/2022 18:16:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
05/25/2022 18:16:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
05/25/2022 18:17:02 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7910071687809159 on epoch=74
05/25/2022 18:17:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
05/25/2022 18:17:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
05/25/2022 18:17:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
05/25/2022 18:17:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/25/2022 18:17:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
05/25/2022 18:17:25 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7403389634749642 on epoch=78
05/25/2022 18:17:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
05/25/2022 18:17:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
05/25/2022 18:17:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
05/25/2022 18:17:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
05/25/2022 18:17:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
05/25/2022 18:17:49 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8359213098729228 on epoch=82
05/25/2022 18:17:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
05/25/2022 18:17:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
05/25/2022 18:17:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/25/2022 18:18:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
05/25/2022 18:18:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
05/25/2022 18:18:12 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7303661310804966 on epoch=85
05/25/2022 18:18:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
05/25/2022 18:18:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
05/25/2022 18:18:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
05/25/2022 18:18:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
05/25/2022 18:18:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
05/25/2022 18:18:35 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7115779207849102 on epoch=89
05/25/2022 18:18:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
05/25/2022 18:18:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
05/25/2022 18:18:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
05/25/2022 18:18:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
05/25/2022 18:18:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/25/2022 18:18:59 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.744253084477998 on epoch=92
05/25/2022 18:19:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/25/2022 18:19:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
05/25/2022 18:19:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
05/25/2022 18:19:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
05/25/2022 18:19:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
05/25/2022 18:19:22 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9038399171985511 on epoch=96
05/25/2022 18:19:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8844054342710258 -> 0.9038399171985511 on epoch=96, global_step=1350
05/25/2022 18:19:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
05/25/2022 18:19:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
05/25/2022 18:19:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
05/25/2022 18:19:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
05/25/2022 18:19:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
05/25/2022 18:19:46 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7580740103719789 on epoch=99
05/25/2022 18:19:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
05/25/2022 18:19:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
05/25/2022 18:19:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
05/25/2022 18:19:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
05/25/2022 18:20:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
05/25/2022 18:20:09 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8606073224336981 on epoch=103
05/25/2022 18:20:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
05/25/2022 18:20:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/25/2022 18:20:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/25/2022 18:20:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
05/25/2022 18:20:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
05/25/2022 18:20:33 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8863722177638109 on epoch=107
05/25/2022 18:20:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/25/2022 18:20:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
05/25/2022 18:20:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
05/25/2022 18:20:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
05/25/2022 18:20:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/25/2022 18:20:56 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8085417103058232 on epoch=110
05/25/2022 18:21:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
05/25/2022 18:21:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
05/25/2022 18:21:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/25/2022 18:21:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
05/25/2022 18:21:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
05/25/2022 18:21:20 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8724551012976062 on epoch=114
05/25/2022 18:21:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
05/25/2022 18:21:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
05/25/2022 18:21:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
05/25/2022 18:21:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
05/25/2022 18:21:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
05/25/2022 18:21:43 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.863186705767351 on epoch=117
05/25/2022 18:21:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
05/25/2022 18:21:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/25/2022 18:21:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
05/25/2022 18:21:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
05/25/2022 18:21:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/25/2022 18:22:06 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7748606538114418 on epoch=121
05/25/2022 18:22:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
05/25/2022 18:22:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/25/2022 18:22:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
05/25/2022 18:22:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/25/2022 18:22:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/25/2022 18:22:29 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8439168358523197 on epoch=124
05/25/2022 18:22:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/25/2022 18:22:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
05/25/2022 18:22:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/25/2022 18:22:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/25/2022 18:22:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/25/2022 18:22:52 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6558291659597892 on epoch=128
05/25/2022 18:22:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/25/2022 18:22:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/25/2022 18:23:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/25/2022 18:23:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/25/2022 18:23:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
05/25/2022 18:23:15 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8024339547035824 on epoch=132
05/25/2022 18:23:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/25/2022 18:23:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
05/25/2022 18:23:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/25/2022 18:23:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/25/2022 18:23:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
05/25/2022 18:23:39 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8057019285597915 on epoch=135
05/25/2022 18:23:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/25/2022 18:23:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
05/25/2022 18:23:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/25/2022 18:23:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
05/25/2022 18:23:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
05/25/2022 18:24:01 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8037895200548326 on epoch=139
05/25/2022 18:24:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
05/25/2022 18:24:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/25/2022 18:24:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
05/25/2022 18:24:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/25/2022 18:24:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
05/25/2022 18:24:24 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7512383690764297 on epoch=142
05/25/2022 18:24:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/25/2022 18:24:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/25/2022 18:24:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/25/2022 18:24:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/25/2022 18:24:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/25/2022 18:24:47 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7397448951884437 on epoch=146
05/25/2022 18:24:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/25/2022 18:24:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
05/25/2022 18:24:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/25/2022 18:24:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
05/25/2022 18:25:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
05/25/2022 18:25:10 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7724209311593988 on epoch=149
05/25/2022 18:25:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/25/2022 18:25:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
05/25/2022 18:25:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
05/25/2022 18:25:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/25/2022 18:25:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/25/2022 18:25:33 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8491484909579667 on epoch=153
05/25/2022 18:25:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/25/2022 18:25:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/25/2022 18:25:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/25/2022 18:25:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/25/2022 18:25:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/25/2022 18:25:55 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9112727710830179 on epoch=157
05/25/2022 18:25:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9038399171985511 -> 0.9112727710830179 on epoch=157, global_step=2200
05/25/2022 18:25:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/25/2022 18:26:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
05/25/2022 18:26:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/25/2022 18:26:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/25/2022 18:26:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/25/2022 18:26:19 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8521906856584276 on epoch=160
05/25/2022 18:26:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
05/25/2022 18:26:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/25/2022 18:26:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/25/2022 18:26:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/25/2022 18:26:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/25/2022 18:26:41 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8523587076971045 on epoch=164
05/25/2022 18:26:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=164
05/25/2022 18:26:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/25/2022 18:26:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/25/2022 18:26:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/25/2022 18:26:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/25/2022 18:27:05 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9001134952732045 on epoch=167
05/25/2022 18:27:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/25/2022 18:27:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/25/2022 18:27:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/25/2022 18:27:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/25/2022 18:27:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
05/25/2022 18:27:28 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8379304758927031 on epoch=171
05/25/2022 18:27:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/25/2022 18:27:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
05/25/2022 18:27:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/25/2022 18:27:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/25/2022 18:27:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
05/25/2022 18:27:51 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8511562194525905 on epoch=174
05/25/2022 18:27:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/25/2022 18:27:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/25/2022 18:28:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/25/2022 18:28:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/25/2022 18:28:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/25/2022 18:28:14 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9143605408927992 on epoch=178
05/25/2022 18:28:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9112727710830179 -> 0.9143605408927992 on epoch=178, global_step=2500
05/25/2022 18:28:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/25/2022 18:28:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/25/2022 18:28:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/25/2022 18:28:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/25/2022 18:28:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/25/2022 18:28:36 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.851290628054741 on epoch=182
05/25/2022 18:28:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/25/2022 18:28:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/25/2022 18:28:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/25/2022 18:28:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/25/2022 18:28:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
05/25/2022 18:28:59 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9821297653958947 on epoch=185
05/25/2022 18:28:59 - INFO - __main__ - Saving model with best Classification-F1: 0.9143605408927992 -> 0.9821297653958947 on epoch=185, global_step=2600
05/25/2022 18:29:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/25/2022 18:29:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
05/25/2022 18:29:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/25/2022 18:29:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/25/2022 18:29:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/25/2022 18:29:22 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9821297653958947 on epoch=189
05/25/2022 18:29:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/25/2022 18:29:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/25/2022 18:29:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/25/2022 18:29:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/25/2022 18:29:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
05/25/2022 18:29:44 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9821297653958947 on epoch=192
05/25/2022 18:29:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/25/2022 18:29:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/25/2022 18:29:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/25/2022 18:29:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/25/2022 18:29:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/25/2022 18:30:07 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.973170543877375 on epoch=196
05/25/2022 18:30:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/25/2022 18:30:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/25/2022 18:30:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/25/2022 18:30:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
05/25/2022 18:30:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/25/2022 18:30:30 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9080522971652004 on epoch=199
05/25/2022 18:30:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/25/2022 18:30:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/25/2022 18:30:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/25/2022 18:30:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/25/2022 18:30:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/25/2022 18:30:53 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9776611157659545 on epoch=203
05/25/2022 18:30:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/25/2022 18:30:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/25/2022 18:31:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/25/2022 18:31:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/25/2022 18:31:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/25/2022 18:31:15 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.859103128054741 on epoch=207
05/25/2022 18:31:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/25/2022 18:31:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/25/2022 18:31:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/25/2022 18:31:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/25/2022 18:31:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/25/2022 18:31:38 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9731749077930293 on epoch=210
05/25/2022 18:31:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/25/2022 18:31:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/25/2022 18:31:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/25/2022 18:31:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/25/2022 18:31:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/25/2022 18:32:01 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7966215078406731 on epoch=214
05/25/2022 18:32:01 - INFO - __main__ - save last model!
05/25/2022 18:32:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 18:32:01 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 18:32:01 - INFO - __main__ - Printing 3 examples
05/25/2022 18:32:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 18:32:01 - INFO - __main__ - ['Animal']
05/25/2022 18:32:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 18:32:01 - INFO - __main__ - ['Animal']
05/25/2022 18:32:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 18:32:01 - INFO - __main__ - ['Village']
05/25/2022 18:32:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 18:32:03 - INFO - __main__ - Tokenizing Output ...
05/25/2022 18:32:06 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 18:34:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/25/2022 18:34:30 - INFO - __main__ - Classification-F1 on test data: 0.6770
05/25/2022 18:34:31 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9821297653958947, test_performance=0.676997110226693
