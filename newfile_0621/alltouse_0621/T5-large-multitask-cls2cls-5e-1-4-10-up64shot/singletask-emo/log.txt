06/18/2022 05:24:24 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-10-up64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-10-64shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/18/2022 05:24:24 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo
06/18/2022 05:24:24 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-10-up64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-10-64shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/18/2022 05:24:24 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo
06/18/2022 05:24:25 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/18/2022 05:24:25 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/18/2022 05:24:25 - INFO - __main__ - args.device: cuda:0
06/18/2022 05:24:25 - INFO - __main__ - Using 2 gpus
06/18/2022 05:24:25 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/18/2022 05:24:25 - INFO - __main__ - args.device: cuda:1
06/18/2022 05:24:25 - INFO - __main__ - Using 2 gpus
06/18/2022 05:24:25 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/18/2022 05:24:29 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/18/2022 05:24:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:24:30 - INFO - __main__ - Printing 3 examples
06/18/2022 05:24:30 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:24:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:24:30 - INFO - __main__ - Printing 3 examples
06/18/2022 05:24:30 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:24:30 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 05:24:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:24:30 - INFO - __main__ - Printing 3 examples
06/18/2022 05:24:30 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:24:30 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 05:24:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:24:30 - INFO - __main__ - Printing 3 examples
06/18/2022 05:24:30 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 05:24:30 - INFO - __main__ - ['others']
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:24:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:24:30 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 05:24:30 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 05:24:48 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:24:48 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:24:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:24:49 - INFO - __main__ - Starting training!
06/18/2022 05:24:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:24:54 - INFO - __main__ - Starting training!
06/18/2022 05:24:57 - INFO - __main__ - Step 10 Global step 10 Train loss 4.25 on epoch=2
06/18/2022 05:24:59 - INFO - __main__ - Step 20 Global step 20 Train loss 2.80 on epoch=4
06/18/2022 05:25:02 - INFO - __main__ - Step 30 Global step 30 Train loss 1.98 on epoch=7
06/18/2022 05:25:04 - INFO - __main__ - Step 40 Global step 40 Train loss 1.51 on epoch=9
06/18/2022 05:25:07 - INFO - __main__ - Step 50 Global step 50 Train loss 1.25 on epoch=12
06/18/2022 05:25:08 - INFO - __main__ - Global step 50 Train loss 2.36 Classification-F1 0.2701449810693508 on epoch=12
06/18/2022 05:25:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2701449810693508 on epoch=12, global_step=50
06/18/2022 05:25:10 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/18/2022 05:25:13 - INFO - __main__ - Step 70 Global step 70 Train loss 0.93 on epoch=17
06/18/2022 05:25:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.79 on epoch=19
06/18/2022 05:25:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
06/18/2022 05:25:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=24
06/18/2022 05:25:21 - INFO - __main__ - Global step 100 Train loss 0.80 Classification-F1 0.5469294425087108 on epoch=24
06/18/2022 05:25:21 - INFO - __main__ - Saving model with best Classification-F1: 0.2701449810693508 -> 0.5469294425087108 on epoch=24, global_step=100
06/18/2022 05:25:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=27
06/18/2022 05:25:26 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=29
06/18/2022 05:25:28 - INFO - __main__ - Step 130 Global step 130 Train loss 0.63 on epoch=32
06/18/2022 05:25:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=34
06/18/2022 05:25:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=37
06/18/2022 05:25:34 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.5711805555555556 on epoch=37
06/18/2022 05:25:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5469294425087108 -> 0.5711805555555556 on epoch=37, global_step=150
06/18/2022 05:25:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=39
06/18/2022 05:25:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.52 on epoch=42
06/18/2022 05:25:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=44
06/18/2022 05:25:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=47
06/18/2022 05:25:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.49 on epoch=49
06/18/2022 05:25:47 - INFO - __main__ - Global step 200 Train loss 0.50 Classification-F1 0.6199682674428005 on epoch=49
06/18/2022 05:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5711805555555556 -> 0.6199682674428005 on epoch=49, global_step=200
06/18/2022 05:25:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=52
06/18/2022 05:25:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=54
06/18/2022 05:25:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=57
06/18/2022 05:25:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=59
06/18/2022 05:25:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=62
06/18/2022 05:26:00 - INFO - __main__ - Global step 250 Train loss 0.48 Classification-F1 0.5882976672450356 on epoch=62
06/18/2022 05:26:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/18/2022 05:26:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=67
06/18/2022 05:26:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=69
06/18/2022 05:26:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=72
06/18/2022 05:26:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=74
06/18/2022 05:26:13 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.635554818744474 on epoch=74
06/18/2022 05:26:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6199682674428005 -> 0.635554818744474 on epoch=74, global_step=300
06/18/2022 05:26:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/18/2022 05:26:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=79
06/18/2022 05:26:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=82
06/18/2022 05:26:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
06/18/2022 05:26:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=87
06/18/2022 05:26:26 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.6232909860859044 on epoch=87
06/18/2022 05:26:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=89
06/18/2022 05:26:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
06/18/2022 05:26:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=94
06/18/2022 05:26:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=97
06/18/2022 05:26:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/18/2022 05:26:39 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.6934697855750487 on epoch=99
06/18/2022 05:26:39 - INFO - __main__ - Saving model with best Classification-F1: 0.635554818744474 -> 0.6934697855750487 on epoch=99, global_step=400
06/18/2022 05:26:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=102
06/18/2022 05:26:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=104
06/18/2022 05:26:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=107
06/18/2022 05:26:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=109
06/18/2022 05:26:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=112
06/18/2022 05:26:52 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.6781258702311335 on epoch=112
06/18/2022 05:26:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=114
06/18/2022 05:26:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=117
06/18/2022 05:26:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=119
06/18/2022 05:27:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/18/2022 05:27:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/18/2022 05:27:05 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6436122357174989 on epoch=124
06/18/2022 05:27:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/18/2022 05:27:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
06/18/2022 05:27:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=132
06/18/2022 05:27:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/18/2022 05:27:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/18/2022 05:27:18 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.6203708133971292 on epoch=137
06/18/2022 05:27:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=139
06/18/2022 05:27:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/18/2022 05:27:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/18/2022 05:27:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/18/2022 05:27:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=149
06/18/2022 05:27:31 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6899554727140933 on epoch=149
06/18/2022 05:27:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=152
06/18/2022 05:27:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=154
06/18/2022 05:27:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=157
06/18/2022 05:27:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=159
06/18/2022 05:27:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=162
06/18/2022 05:27:44 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6899554727140933 on epoch=162
06/18/2022 05:27:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/18/2022 05:27:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=167
06/18/2022 05:27:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
06/18/2022 05:27:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=172
06/18/2022 05:27:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/18/2022 05:27:57 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.6303258145363408 on epoch=174
06/18/2022 05:27:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
06/18/2022 05:28:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/18/2022 05:28:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/18/2022 05:28:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/18/2022 05:28:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/18/2022 05:28:10 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6746031746031746 on epoch=187
06/18/2022 05:28:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/18/2022 05:28:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/18/2022 05:28:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/18/2022 05:28:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=197
06/18/2022 05:28:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/18/2022 05:28:23 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.682093278737641 on epoch=199
06/18/2022 05:28:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/18/2022 05:28:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
06/18/2022 05:28:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/18/2022 05:28:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
06/18/2022 05:28:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/18/2022 05:28:36 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6288882741971987 on epoch=212
06/18/2022 05:28:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=214
06/18/2022 05:28:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/18/2022 05:28:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/18/2022 05:28:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/18/2022 05:28:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/18/2022 05:28:49 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.6410716069110157 on epoch=224
06/18/2022 05:28:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/18/2022 05:28:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/18/2022 05:28:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/18/2022 05:28:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=234
06/18/2022 05:29:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/18/2022 05:29:02 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.6700142994260642 on epoch=237
06/18/2022 05:29:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/18/2022 05:29:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/18/2022 05:29:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/18/2022 05:29:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/18/2022 05:29:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/18/2022 05:29:15 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6607142857142858 on epoch=249
06/18/2022 05:29:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/18/2022 05:29:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/18/2022 05:29:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/18/2022 05:29:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/18/2022 05:29:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/18/2022 05:29:28 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7037050787050787 on epoch=262
06/18/2022 05:29:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6934697855750487 -> 0.7037050787050787 on epoch=262, global_step=1050
06/18/2022 05:29:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/18/2022 05:29:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/18/2022 05:29:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=269
06/18/2022 05:29:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/18/2022 05:29:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/18/2022 05:29:41 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6450327467845025 on epoch=274
06/18/2022 05:29:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/18/2022 05:29:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/18/2022 05:29:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/18/2022 05:29:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=284
06/18/2022 05:29:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/18/2022 05:29:54 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6868843231072334 on epoch=287
06/18/2022 05:29:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/18/2022 05:29:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/18/2022 05:30:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/18/2022 05:30:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/18/2022 05:30:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/18/2022 05:30:07 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6820921195921196 on epoch=299
06/18/2022 05:30:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/18/2022 05:30:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/18/2022 05:30:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/18/2022 05:30:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/18/2022 05:30:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/18/2022 05:30:20 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6954477889260497 on epoch=312
06/18/2022 05:30:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/18/2022 05:30:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/18/2022 05:30:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/18/2022 05:30:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/18/2022 05:30:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/18/2022 05:30:33 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6792623344347483 on epoch=324
06/18/2022 05:30:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/18/2022 05:30:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/18/2022 05:30:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/18/2022 05:30:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/18/2022 05:30:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/18/2022 05:30:46 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.669924924924925 on epoch=337
06/18/2022 05:30:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/18/2022 05:30:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/18/2022 05:30:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/18/2022 05:30:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
06/18/2022 05:30:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/18/2022 05:30:59 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6880672268907563 on epoch=349
06/18/2022 05:31:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/18/2022 05:31:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/18/2022 05:31:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
06/18/2022 05:31:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/18/2022 05:31:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/18/2022 05:31:12 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.685502061605627 on epoch=362
06/18/2022 05:31:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/18/2022 05:31:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/18/2022 05:31:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=369
06/18/2022 05:31:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/18/2022 05:31:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/18/2022 05:31:25 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.685502061605627 on epoch=374
06/18/2022 05:31:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/18/2022 05:31:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 05:31:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/18/2022 05:31:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/18/2022 05:31:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/18/2022 05:31:38 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7096453859321507 on epoch=387
06/18/2022 05:31:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7037050787050787 -> 0.7096453859321507 on epoch=387, global_step=1550
06/18/2022 05:31:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/18/2022 05:31:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 05:31:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/18/2022 05:31:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/18/2022 05:31:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/18/2022 05:31:51 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6683982683982684 on epoch=399
06/18/2022 05:31:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 05:31:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/18/2022 05:31:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/18/2022 05:32:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 05:32:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/18/2022 05:32:05 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.653758382442593 on epoch=412
06/18/2022 05:32:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/18/2022 05:32:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/18/2022 05:32:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/18/2022 05:32:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/18/2022 05:32:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/18/2022 05:32:18 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6649305555555556 on epoch=424
06/18/2022 05:32:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/18/2022 05:32:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 05:32:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 05:32:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/18/2022 05:32:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 05:32:31 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6939588189588191 on epoch=437
06/18/2022 05:32:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/18/2022 05:32:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/18/2022 05:32:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/18/2022 05:32:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/18/2022 05:32:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=449
06/18/2022 05:32:44 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6891891891891893 on epoch=449
06/18/2022 05:32:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/18/2022 05:32:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/18/2022 05:32:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/18/2022 05:32:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/18/2022 05:32:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 05:32:57 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.674689352108707 on epoch=462
06/18/2022 05:32:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 05:33:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/18/2022 05:33:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/18/2022 05:33:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/18/2022 05:33:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 05:33:10 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6757278669043375 on epoch=474
06/18/2022 05:33:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/18/2022 05:33:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/18/2022 05:33:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 05:33:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 05:33:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 05:33:23 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7080302050890286 on epoch=487
06/18/2022 05:33:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/18/2022 05:33:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/18/2022 05:33:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/18/2022 05:33:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/18/2022 05:33:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 05:33:36 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7279130042821726 on epoch=499
06/18/2022 05:33:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7096453859321507 -> 0.7279130042821726 on epoch=499, global_step=2000
06/18/2022 05:33:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/18/2022 05:33:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/18/2022 05:33:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/18/2022 05:33:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/18/2022 05:33:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/18/2022 05:33:50 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6798649006845424 on epoch=512
06/18/2022 05:33:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/18/2022 05:33:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/18/2022 05:33:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 05:33:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 05:34:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/18/2022 05:34:03 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7001220575414123 on epoch=524
06/18/2022 05:34:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/18/2022 05:34:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/18/2022 05:34:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 05:34:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/18/2022 05:34:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 05:34:16 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7025906120023767 on epoch=537
06/18/2022 05:34:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 05:34:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 05:34:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/18/2022 05:34:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 05:34:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 05:34:30 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.689655172413793 on epoch=549
06/18/2022 05:34:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/18/2022 05:34:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/18/2022 05:34:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 05:34:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 05:34:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/18/2022 05:34:43 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7162933684672814 on epoch=562
06/18/2022 05:34:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/18/2022 05:34:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 05:34:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 05:34:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 05:34:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 05:34:56 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7250213346987541 on epoch=574
06/18/2022 05:34:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 05:35:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 05:35:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/18/2022 05:35:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 05:35:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/18/2022 05:35:09 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7096453859321507 on epoch=587
06/18/2022 05:35:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 05:35:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 05:35:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 05:35:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/18/2022 05:35:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 05:35:23 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7161764705882353 on epoch=599
06/18/2022 05:35:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/18/2022 05:35:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 05:35:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 05:35:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/18/2022 05:35:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
06/18/2022 05:35:36 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6929492291334396 on epoch=612
06/18/2022 05:35:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 05:35:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 05:35:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/18/2022 05:35:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/18/2022 05:35:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 05:35:49 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6899381868131869 on epoch=624
06/18/2022 05:35:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 05:35:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/18/2022 05:35:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 05:35:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 05:36:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=637
06/18/2022 05:36:03 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7443564745141661 on epoch=637
06/18/2022 05:36:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7279130042821726 -> 0.7443564745141661 on epoch=637, global_step=2550
06/18/2022 05:36:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 05:36:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 05:36:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 05:36:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 05:36:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 05:36:16 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7314593301435407 on epoch=649
06/18/2022 05:36:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 05:36:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 05:36:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 05:36:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 05:36:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/18/2022 05:36:29 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.736969696969697 on epoch=662
06/18/2022 05:36:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 05:36:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 05:36:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/18/2022 05:36:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 05:36:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=674
06/18/2022 05:36:43 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7123200862911653 on epoch=674
06/18/2022 05:36:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/18/2022 05:36:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 05:36:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/18/2022 05:36:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 05:36:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/18/2022 05:36:56 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7073757818539602 on epoch=687
06/18/2022 05:36:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 05:37:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=692
06/18/2022 05:37:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 05:37:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/18/2022 05:37:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 05:37:09 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6885055304172951 on epoch=699
06/18/2022 05:37:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 05:37:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 05:37:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
06/18/2022 05:37:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 05:37:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 05:37:23 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6885055304172951 on epoch=712
06/18/2022 05:37:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 05:37:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/18/2022 05:37:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 05:37:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/18/2022 05:37:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/18/2022 05:37:36 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7023529411764705 on epoch=724
06/18/2022 05:37:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/18/2022 05:37:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 05:37:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/18/2022 05:37:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 05:37:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 05:37:49 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7294311480416957 on epoch=737
06/18/2022 05:37:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 05:37:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/18/2022 05:37:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/18/2022 05:37:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 05:38:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 05:38:03 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7136886102403344 on epoch=749
06/18/2022 05:38:03 - INFO - __main__ - save last model!
06/18/2022 05:38:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 05:38:03 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 05:38:03 - INFO - __main__ - Printing 3 examples
06/18/2022 05:38:03 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:38:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:38:03 - INFO - __main__ - Printing 3 examples
06/18/2022 05:38:03 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:38:03 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:38:03 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 05:38:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:38:03 - INFO - __main__ - Printing 3 examples
06/18/2022 05:38:03 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 05:38:03 - INFO - __main__ - ['others']
06/18/2022 05:38:03 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:38:03 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:38:03 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 05:38:05 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:38:10 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 05:38:22 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:38:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:38:22 - INFO - __main__ - Starting training!
06/18/2022 05:39:45 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/18/2022 05:39:45 - INFO - __main__ - Classification-F1 on test data: 0.2422
06/18/2022 05:39:45 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.7443564745141661, test_performance=0.24220414491744766
06/18/2022 05:39:45 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/18/2022 05:39:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:39:46 - INFO - __main__ - Printing 3 examples
06/18/2022 05:39:46 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 05:39:46 - INFO - __main__ - ['others']
06/18/2022 05:39:46 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 05:39:46 - INFO - __main__ - ['others']
06/18/2022 05:39:46 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 05:39:46 - INFO - __main__ - ['others']
06/18/2022 05:39:46 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:39:46 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:39:46 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 05:39:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:39:46 - INFO - __main__ - Printing 3 examples
06/18/2022 05:39:46 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 05:39:46 - INFO - __main__ - ['others']
06/18/2022 05:39:46 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 05:39:46 - INFO - __main__ - ['others']
06/18/2022 05:39:46 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 05:39:46 - INFO - __main__ - ['others']
06/18/2022 05:39:46 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:39:46 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:39:46 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 05:40:05 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:40:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:40:06 - INFO - __main__ - Starting training!
06/18/2022 05:40:09 - INFO - __main__ - Step 10 Global step 10 Train loss 4.41 on epoch=2
06/18/2022 05:40:12 - INFO - __main__ - Step 20 Global step 20 Train loss 3.04 on epoch=4
06/18/2022 05:40:14 - INFO - __main__ - Step 30 Global step 30 Train loss 2.33 on epoch=7
06/18/2022 05:40:17 - INFO - __main__ - Step 40 Global step 40 Train loss 1.64 on epoch=9
06/18/2022 05:40:19 - INFO - __main__ - Step 50 Global step 50 Train loss 1.46 on epoch=12
06/18/2022 05:40:20 - INFO - __main__ - Global step 50 Train loss 2.57 Classification-F1 0.23263764347202298 on epoch=12
06/18/2022 05:40:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.23263764347202298 on epoch=12, global_step=50
06/18/2022 05:40:23 - INFO - __main__ - Step 60 Global step 60 Train loss 1.09 on epoch=14
06/18/2022 05:40:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=17
06/18/2022 05:40:28 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=19
06/18/2022 05:40:30 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=22
06/18/2022 05:40:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.75 on epoch=24
06/18/2022 05:40:34 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.5086587436332768 on epoch=24
06/18/2022 05:40:34 - INFO - __main__ - Saving model with best Classification-F1: 0.23263764347202298 -> 0.5086587436332768 on epoch=24, global_step=100
06/18/2022 05:40:36 - INFO - __main__ - Step 110 Global step 110 Train loss 0.83 on epoch=27
06/18/2022 05:40:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.76 on epoch=29
06/18/2022 05:40:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.64 on epoch=32
06/18/2022 05:40:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=34
06/18/2022 05:40:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=37
06/18/2022 05:40:46 - INFO - __main__ - Global step 150 Train loss 0.74 Classification-F1 0.5710763039532866 on epoch=37
06/18/2022 05:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5086587436332768 -> 0.5710763039532866 on epoch=37, global_step=150
06/18/2022 05:40:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.68 on epoch=39
06/18/2022 05:40:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=42
06/18/2022 05:40:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=44
06/18/2022 05:40:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.53 on epoch=47
06/18/2022 05:40:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=49
06/18/2022 05:40:59 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.5471230158730159 on epoch=49
06/18/2022 05:41:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=52
06/18/2022 05:41:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=54
06/18/2022 05:41:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=57
06/18/2022 05:41:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=59
06/18/2022 05:41:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=62
06/18/2022 05:41:12 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.6216659298555851 on epoch=62
06/18/2022 05:41:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5710763039532866 -> 0.6216659298555851 on epoch=62, global_step=250
06/18/2022 05:41:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=64
06/18/2022 05:41:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/18/2022 05:41:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=69
06/18/2022 05:41:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=72
06/18/2022 05:41:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=74
06/18/2022 05:41:24 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.6209795321637427 on epoch=74
06/18/2022 05:41:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=77
06/18/2022 05:41:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=79
06/18/2022 05:41:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=82
06/18/2022 05:41:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=84
06/18/2022 05:41:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/18/2022 05:41:37 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.6348684210526315 on epoch=87
06/18/2022 05:41:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6216659298555851 -> 0.6348684210526315 on epoch=87, global_step=350
06/18/2022 05:41:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.38 on epoch=89
06/18/2022 05:41:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=92
06/18/2022 05:41:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=94
06/18/2022 05:41:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/18/2022 05:41:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=99
06/18/2022 05:41:50 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.6851290388132494 on epoch=99
06/18/2022 05:41:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6348684210526315 -> 0.6851290388132494 on epoch=99, global_step=400
06/18/2022 05:41:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=102
06/18/2022 05:41:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/18/2022 05:41:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=107
06/18/2022 05:42:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/18/2022 05:42:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=112
06/18/2022 05:42:03 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.6866866028708134 on epoch=112
06/18/2022 05:42:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6851290388132494 -> 0.6866866028708134 on epoch=112, global_step=450
06/18/2022 05:42:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
06/18/2022 05:42:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=117
06/18/2022 05:42:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/18/2022 05:42:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=122
06/18/2022 05:42:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/18/2022 05:42:16 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.6598197696023783 on epoch=124
06/18/2022 05:42:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=127
06/18/2022 05:42:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=129
06/18/2022 05:42:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/18/2022 05:42:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/18/2022 05:42:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
06/18/2022 05:42:28 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7020932787376412 on epoch=137
06/18/2022 05:42:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6866866028708134 -> 0.7020932787376412 on epoch=137, global_step=550
06/18/2022 05:42:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/18/2022 05:42:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=142
06/18/2022 05:42:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=144
06/18/2022 05:42:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/18/2022 05:42:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/18/2022 05:42:41 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.6656021864998022 on epoch=149
06/18/2022 05:42:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/18/2022 05:42:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/18/2022 05:42:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=157
06/18/2022 05:42:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/18/2022 05:42:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=162
06/18/2022 05:42:54 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6868174962292609 on epoch=162
06/18/2022 05:42:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
06/18/2022 05:42:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/18/2022 05:43:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=169
06/18/2022 05:43:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/18/2022 05:43:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
06/18/2022 05:43:07 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6933286227403874 on epoch=174
06/18/2022 05:43:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
06/18/2022 05:43:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/18/2022 05:43:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/18/2022 05:43:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/18/2022 05:43:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/18/2022 05:43:19 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6797619047619048 on epoch=187
06/18/2022 05:43:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=189
06/18/2022 05:43:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/18/2022 05:43:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/18/2022 05:43:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=197
06/18/2022 05:43:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/18/2022 05:43:32 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6658783783783784 on epoch=199
06/18/2022 05:43:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=202
06/18/2022 05:43:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
06/18/2022 05:43:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/18/2022 05:43:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/18/2022 05:43:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=212
06/18/2022 05:43:45 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6371798749747933 on epoch=212
06/18/2022 05:43:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/18/2022 05:43:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
06/18/2022 05:43:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/18/2022 05:43:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
06/18/2022 05:43:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/18/2022 05:43:58 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.6534534534534534 on epoch=224
06/18/2022 05:44:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/18/2022 05:44:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/18/2022 05:44:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=232
06/18/2022 05:44:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/18/2022 05:44:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/18/2022 05:44:11 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6751599079185285 on epoch=237
06/18/2022 05:44:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/18/2022 05:44:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/18/2022 05:44:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/18/2022 05:44:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/18/2022 05:44:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
06/18/2022 05:44:23 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7106209150326797 on epoch=249
06/18/2022 05:44:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7020932787376412 -> 0.7106209150326797 on epoch=249, global_step=1000
06/18/2022 05:44:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=252
06/18/2022 05:44:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/18/2022 05:44:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/18/2022 05:44:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/18/2022 05:44:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=262
06/18/2022 05:44:36 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.653078078078078 on epoch=262
06/18/2022 05:44:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/18/2022 05:44:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/18/2022 05:44:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/18/2022 05:44:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/18/2022 05:44:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/18/2022 05:44:49 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6726110147162778 on epoch=274
06/18/2022 05:44:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/18/2022 05:44:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/18/2022 05:44:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/18/2022 05:44:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/18/2022 05:45:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/18/2022 05:45:02 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7109469074986317 on epoch=287
06/18/2022 05:45:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7106209150326797 -> 0.7109469074986317 on epoch=287, global_step=1150
06/18/2022 05:45:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/18/2022 05:45:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/18/2022 05:45:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/18/2022 05:45:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/18/2022 05:45:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=299
06/18/2022 05:45:15 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6729627003820552 on epoch=299
06/18/2022 05:45:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/18/2022 05:45:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/18/2022 05:45:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/18/2022 05:45:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/18/2022 05:45:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/18/2022 05:45:27 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.664835474419653 on epoch=312
06/18/2022 05:45:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/18/2022 05:45:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/18/2022 05:45:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/18/2022 05:45:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/18/2022 05:45:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/18/2022 05:45:40 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6585249042145593 on epoch=324
06/18/2022 05:45:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/18/2022 05:45:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=329
06/18/2022 05:45:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/18/2022 05:45:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/18/2022 05:45:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/18/2022 05:45:53 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6585249042145593 on epoch=337
06/18/2022 05:45:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/18/2022 05:45:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/18/2022 05:46:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/18/2022 05:46:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/18/2022 05:46:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/18/2022 05:46:06 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6737179487179488 on epoch=349
06/18/2022 05:46:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/18/2022 05:46:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/18/2022 05:46:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
06/18/2022 05:46:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/18/2022 05:46:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/18/2022 05:46:19 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6579365079365079 on epoch=362
06/18/2022 05:46:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/18/2022 05:46:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/18/2022 05:46:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=369
06/18/2022 05:46:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/18/2022 05:46:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/18/2022 05:46:32 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6970588235294117 on epoch=374
06/18/2022 05:46:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/18/2022 05:46:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/18/2022 05:46:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 05:46:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/18/2022 05:46:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/18/2022 05:46:45 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.694047619047619 on epoch=387
06/18/2022 05:46:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/18/2022 05:46:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/18/2022 05:46:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/18/2022 05:46:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/18/2022 05:46:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/18/2022 05:46:58 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6698744198744199 on epoch=399
06/18/2022 05:47:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/18/2022 05:47:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 05:47:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 05:47:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/18/2022 05:47:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/18/2022 05:47:10 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6935958254269449 on epoch=412
06/18/2022 05:47:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 05:47:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/18/2022 05:47:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/18/2022 05:47:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/18/2022 05:47:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 05:47:23 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.709469696969697 on epoch=424
06/18/2022 05:47:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/18/2022 05:47:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/18/2022 05:47:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/18/2022 05:47:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/18/2022 05:47:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/18/2022 05:47:36 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7090996168582375 on epoch=437
06/18/2022 05:47:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/18/2022 05:47:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/18/2022 05:47:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/18/2022 05:47:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/18/2022 05:47:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=449
06/18/2022 05:47:49 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7081263922118638 on epoch=449
06/18/2022 05:47:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/18/2022 05:47:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/18/2022 05:47:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/18/2022 05:47:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/18/2022 05:48:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=462
06/18/2022 05:48:02 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7219875047461255 on epoch=462
06/18/2022 05:48:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7109469074986317 -> 0.7219875047461255 on epoch=462, global_step=1850
06/18/2022 05:48:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/18/2022 05:48:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/18/2022 05:48:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 05:48:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/18/2022 05:48:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/18/2022 05:48:15 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7221153846153846 on epoch=474
06/18/2022 05:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7219875047461255 -> 0.7221153846153846 on epoch=474, global_step=1900
06/18/2022 05:48:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/18/2022 05:48:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/18/2022 05:48:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 05:48:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 05:48:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 05:48:28 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7226082161566032 on epoch=487
06/18/2022 05:48:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7221153846153846 -> 0.7226082161566032 on epoch=487, global_step=1950
06/18/2022 05:48:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/18/2022 05:48:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/18/2022 05:48:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/18/2022 05:48:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/18/2022 05:48:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/18/2022 05:48:41 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6888249005896065 on epoch=499
06/18/2022 05:48:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 05:48:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/18/2022 05:48:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/18/2022 05:48:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 05:48:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 05:48:54 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7026839826839827 on epoch=512
06/18/2022 05:48:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 05:48:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/18/2022 05:49:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
06/18/2022 05:49:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 05:49:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 05:49:07 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7026839826839827 on epoch=524
06/18/2022 05:49:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/18/2022 05:49:12 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/18/2022 05:49:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=532
06/18/2022 05:49:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 05:49:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/18/2022 05:49:20 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7226082161566032 on epoch=537
06/18/2022 05:49:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 05:49:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/18/2022 05:49:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/18/2022 05:49:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 05:49:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/18/2022 05:49:33 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7219875047461255 on epoch=549
06/18/2022 05:49:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 05:49:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/18/2022 05:49:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 05:49:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 05:49:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/18/2022 05:49:46 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.707843137254902 on epoch=562
06/18/2022 05:49:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/18/2022 05:49:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/18/2022 05:49:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/18/2022 05:49:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/18/2022 05:49:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/18/2022 05:49:59 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.680461951187594 on epoch=574
06/18/2022 05:50:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/18/2022 05:50:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 05:50:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/18/2022 05:50:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 05:50:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 05:50:12 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6959657426188866 on epoch=587
06/18/2022 05:50:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=589
06/18/2022 05:50:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=592
06/18/2022 05:50:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/18/2022 05:50:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/18/2022 05:50:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 05:50:25 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7219628647214855 on epoch=599
06/18/2022 05:50:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=602
06/18/2022 05:50:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/18/2022 05:50:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 05:50:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 05:50:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 05:50:38 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7055694792536898 on epoch=612
06/18/2022 05:50:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 05:50:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/18/2022 05:50:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 05:50:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 05:50:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/18/2022 05:50:51 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7620689655172412 on epoch=624
06/18/2022 05:50:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7226082161566032 -> 0.7620689655172412 on epoch=624, global_step=2500
06/18/2022 05:50:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/18/2022 05:50:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/18/2022 05:50:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=632
06/18/2022 05:51:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/18/2022 05:51:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/18/2022 05:51:04 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7364971050454922 on epoch=637
06/18/2022 05:51:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 05:51:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 05:51:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=644
06/18/2022 05:51:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 05:51:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/18/2022 05:51:17 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.707843137254902 on epoch=649
06/18/2022 05:51:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 05:51:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/18/2022 05:51:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 05:51:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 05:51:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 05:51:30 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6787243633085418 on epoch=662
06/18/2022 05:51:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/18/2022 05:51:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.15 on epoch=667
06/18/2022 05:51:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/18/2022 05:51:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 05:51:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 05:51:43 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.7226878206479725 on epoch=674
06/18/2022 05:51:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=677
06/18/2022 05:51:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 05:51:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 05:51:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 05:51:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/18/2022 05:51:56 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7238514173998045 on epoch=687
06/18/2022 05:51:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 05:52:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
06/18/2022 05:52:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=694
06/18/2022 05:52:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/18/2022 05:52:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/18/2022 05:52:09 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7226878206479725 on epoch=699
06/18/2022 05:52:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/18/2022 05:52:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 05:52:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/18/2022 05:52:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 05:52:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 05:52:23 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7270960108181204 on epoch=712
06/18/2022 05:52:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 05:52:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/18/2022 05:52:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 05:52:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/18/2022 05:52:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=724
06/18/2022 05:52:36 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.706842136253901 on epoch=724
06/18/2022 05:52:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 05:52:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 05:52:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/18/2022 05:52:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 05:52:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 05:52:49 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6874390968508615 on epoch=737
06/18/2022 05:52:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 05:52:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 05:52:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/18/2022 05:52:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 05:53:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/18/2022 05:53:02 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7216251885369532 on epoch=749
06/18/2022 05:53:02 - INFO - __main__ - save last model!
06/18/2022 05:53:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 05:53:02 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 05:53:02 - INFO - __main__ - Printing 3 examples
06/18/2022 05:53:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:53:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:53:02 - INFO - __main__ - Printing 3 examples
06/18/2022 05:53:02 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:53:02 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:53:02 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 05:53:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:53:02 - INFO - __main__ - Printing 3 examples
06/18/2022 05:53:02 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 05:53:02 - INFO - __main__ - ['others']
06/18/2022 05:53:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:53:02 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:53:02 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 05:53:04 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:53:10 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 05:53:21 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:53:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:53:22 - INFO - __main__ - Starting training!
06/18/2022 05:54:38 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/18/2022 05:54:38 - INFO - __main__ - Classification-F1 on test data: 0.1977
06/18/2022 05:54:38 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.7620689655172412, test_performance=0.19774780740908857
06/18/2022 05:54:38 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/18/2022 05:54:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:54:39 - INFO - __main__ - Printing 3 examples
06/18/2022 05:54:39 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 05:54:39 - INFO - __main__ - ['others']
06/18/2022 05:54:39 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 05:54:39 - INFO - __main__ - ['others']
06/18/2022 05:54:39 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 05:54:39 - INFO - __main__ - ['others']
06/18/2022 05:54:39 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:54:39 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:54:39 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 05:54:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 05:54:39 - INFO - __main__ - Printing 3 examples
06/18/2022 05:54:39 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 05:54:39 - INFO - __main__ - ['others']
06/18/2022 05:54:39 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 05:54:39 - INFO - __main__ - ['others']
06/18/2022 05:54:39 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 05:54:39 - INFO - __main__ - ['others']
06/18/2022 05:54:39 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:54:39 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:54:39 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 05:54:58 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:54:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:54:58 - INFO - __main__ - Starting training!
06/18/2022 05:55:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.43 on epoch=2
06/18/2022 05:55:04 - INFO - __main__ - Step 20 Global step 20 Train loss 3.20 on epoch=4
06/18/2022 05:55:06 - INFO - __main__ - Step 30 Global step 30 Train loss 2.67 on epoch=7
06/18/2022 05:55:09 - INFO - __main__ - Step 40 Global step 40 Train loss 1.92 on epoch=9
06/18/2022 05:55:11 - INFO - __main__ - Step 50 Global step 50 Train loss 1.61 on epoch=12
06/18/2022 05:55:13 - INFO - __main__ - Global step 50 Train loss 2.77 Classification-F1 0.0993655303030303 on epoch=12
06/18/2022 05:55:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0993655303030303 on epoch=12, global_step=50
06/18/2022 05:55:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.36 on epoch=14
06/18/2022 05:55:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.24 on epoch=17
06/18/2022 05:55:20 - INFO - __main__ - Step 80 Global step 80 Train loss 1.05 on epoch=19
06/18/2022 05:55:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=22
06/18/2022 05:55:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=24
06/18/2022 05:55:26 - INFO - __main__ - Global step 100 Train loss 1.08 Classification-F1 0.3341430499325237 on epoch=24
06/18/2022 05:55:26 - INFO - __main__ - Saving model with best Classification-F1: 0.0993655303030303 -> 0.3341430499325237 on epoch=24, global_step=100
06/18/2022 05:55:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=27
06/18/2022 05:55:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.87 on epoch=29
06/18/2022 05:55:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=32
06/18/2022 05:55:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=34
06/18/2022 05:55:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=37
06/18/2022 05:55:39 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.532354862676778 on epoch=37
06/18/2022 05:55:40 - INFO - __main__ - Saving model with best Classification-F1: 0.3341430499325237 -> 0.532354862676778 on epoch=37, global_step=150
06/18/2022 05:55:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.76 on epoch=39
06/18/2022 05:55:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=42
06/18/2022 05:55:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
06/18/2022 05:55:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.67 on epoch=47
06/18/2022 05:55:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.62 on epoch=49
06/18/2022 05:55:53 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.5222275493685451 on epoch=49
06/18/2022 05:55:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/18/2022 05:55:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=54
06/18/2022 05:56:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=57
06/18/2022 05:56:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=59
06/18/2022 05:56:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=62
06/18/2022 05:56:06 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.5731177606177607 on epoch=62
06/18/2022 05:56:06 - INFO - __main__ - Saving model with best Classification-F1: 0.532354862676778 -> 0.5731177606177607 on epoch=62, global_step=250
06/18/2022 05:56:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=64
06/18/2022 05:56:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=67
06/18/2022 05:56:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/18/2022 05:56:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=72
06/18/2022 05:56:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=74
06/18/2022 05:56:20 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6410785027083838 on epoch=74
06/18/2022 05:56:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5731177606177607 -> 0.6410785027083838 on epoch=74, global_step=300
06/18/2022 05:56:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=77
06/18/2022 05:56:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=79
06/18/2022 05:56:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=82
06/18/2022 05:56:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=84
06/18/2022 05:56:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=87
06/18/2022 05:56:33 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.6246294273677641 on epoch=87
06/18/2022 05:56:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.53 on epoch=89
06/18/2022 05:56:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=92
06/18/2022 05:56:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=94
06/18/2022 05:56:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=97
06/18/2022 05:56:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=99
06/18/2022 05:56:46 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.5876012145748988 on epoch=99
06/18/2022 05:56:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/18/2022 05:56:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=104
06/18/2022 05:56:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=107
06/18/2022 05:56:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=109
06/18/2022 05:56:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=112
06/18/2022 05:57:00 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.6575457875457875 on epoch=112
06/18/2022 05:57:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6410785027083838 -> 0.6575457875457875 on epoch=112, global_step=450
06/18/2022 05:57:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=114
06/18/2022 05:57:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=117
06/18/2022 05:57:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=119
06/18/2022 05:57:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=122
06/18/2022 05:57:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=124
06/18/2022 05:57:13 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.6506274046319813 on epoch=124
06/18/2022 05:57:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=127
06/18/2022 05:57:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=129
06/18/2022 05:57:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/18/2022 05:57:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/18/2022 05:57:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=137
06/18/2022 05:57:26 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.640739064856712 on epoch=137
06/18/2022 05:57:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=139
06/18/2022 05:57:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=142
06/18/2022 05:57:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=144
06/18/2022 05:57:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=147
06/18/2022 05:57:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=149
06/18/2022 05:57:39 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.6273579717318375 on epoch=149
06/18/2022 05:57:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=152
06/18/2022 05:57:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=154
06/18/2022 05:57:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/18/2022 05:57:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/18/2022 05:57:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=162
06/18/2022 05:57:53 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6277913674741578 on epoch=162
06/18/2022 05:57:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/18/2022 05:57:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=167
06/18/2022 05:58:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/18/2022 05:58:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=172
06/18/2022 05:58:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=174
06/18/2022 05:58:06 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.6445766418592505 on epoch=174
06/18/2022 05:58:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/18/2022 05:58:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/18/2022 05:58:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=182
06/18/2022 05:58:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/18/2022 05:58:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=187
06/18/2022 05:58:19 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.6607118560207805 on epoch=187
06/18/2022 05:58:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6575457875457875 -> 0.6607118560207805 on epoch=187, global_step=750
06/18/2022 05:58:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/18/2022 05:58:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=192
06/18/2022 05:58:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=194
06/18/2022 05:58:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=197
06/18/2022 05:58:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=199
06/18/2022 05:58:33 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.634009009009009 on epoch=199
06/18/2022 05:58:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=202
06/18/2022 05:58:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/18/2022 05:58:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/18/2022 05:58:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=209
06/18/2022 05:58:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/18/2022 05:58:46 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.6371798749747933 on epoch=212
06/18/2022 05:58:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=214
06/18/2022 05:58:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/18/2022 05:58:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=219
06/18/2022 05:58:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
06/18/2022 05:58:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/18/2022 05:58:59 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6347520566259033 on epoch=224
06/18/2022 05:59:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=227
06/18/2022 05:59:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=229
06/18/2022 05:59:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/18/2022 05:59:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=234
06/18/2022 05:59:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/18/2022 05:59:13 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6364114114114113 on epoch=237
06/18/2022 05:59:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=239
06/18/2022 05:59:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/18/2022 05:59:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/18/2022 05:59:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/18/2022 05:59:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
06/18/2022 05:59:26 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6303325901151988 on epoch=249
06/18/2022 05:59:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/18/2022 05:59:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=254
06/18/2022 05:59:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=257
06/18/2022 05:59:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
06/18/2022 05:59:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=262
06/18/2022 05:59:39 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7035307829425477 on epoch=262
06/18/2022 05:59:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6607118560207805 -> 0.7035307829425477 on epoch=262, global_step=1050
06/18/2022 05:59:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/18/2022 05:59:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/18/2022 05:59:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/18/2022 05:59:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=272
06/18/2022 05:59:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/18/2022 05:59:53 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6567821067821068 on epoch=274
06/18/2022 05:59:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/18/2022 05:59:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/18/2022 06:00:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
06/18/2022 06:00:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/18/2022 06:00:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=287
06/18/2022 06:00:06 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6844272844272844 on epoch=287
06/18/2022 06:00:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/18/2022 06:00:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=292
06/18/2022 06:00:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/18/2022 06:00:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/18/2022 06:00:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/18/2022 06:00:19 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6844272844272844 on epoch=299
06/18/2022 06:00:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/18/2022 06:00:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/18/2022 06:00:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=307
06/18/2022 06:00:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/18/2022 06:00:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=312
06/18/2022 06:00:33 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.6943165672065927 on epoch=312
06/18/2022 06:00:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/18/2022 06:00:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/18/2022 06:00:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/18/2022 06:00:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/18/2022 06:00:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/18/2022 06:00:46 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7099943693693693 on epoch=324
06/18/2022 06:00:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7035307829425477 -> 0.7099943693693693 on epoch=324, global_step=1300
06/18/2022 06:00:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/18/2022 06:00:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/18/2022 06:00:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=332
06/18/2022 06:00:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/18/2022 06:00:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=337
06/18/2022 06:00:59 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6836538461538462 on epoch=337
06/18/2022 06:01:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/18/2022 06:01:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/18/2022 06:01:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/18/2022 06:01:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/18/2022 06:01:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/18/2022 06:01:12 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6808990100309211 on epoch=349
06/18/2022 06:01:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/18/2022 06:01:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=354
06/18/2022 06:01:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/18/2022 06:01:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/18/2022 06:01:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=362
06/18/2022 06:01:25 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6719272844272843 on epoch=362
06/18/2022 06:01:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/18/2022 06:01:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/18/2022 06:01:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/18/2022 06:01:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/18/2022 06:01:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/18/2022 06:01:39 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.695580808080808 on epoch=374
06/18/2022 06:01:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/18/2022 06:01:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/18/2022 06:01:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/18/2022 06:01:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=384
06/18/2022 06:01:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/18/2022 06:01:52 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.695580808080808 on epoch=387
06/18/2022 06:01:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/18/2022 06:01:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=392
06/18/2022 06:01:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/18/2022 06:02:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=397
06/18/2022 06:02:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/18/2022 06:02:05 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6816919191919192 on epoch=399
06/18/2022 06:02:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/18/2022 06:02:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/18/2022 06:02:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 06:02:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=409
06/18/2022 06:02:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/18/2022 06:02:19 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6980546123372948 on epoch=412
06/18/2022 06:02:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=414
06/18/2022 06:02:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=417
06/18/2022 06:02:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/18/2022 06:02:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/18/2022 06:02:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/18/2022 06:02:32 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6802952690321505 on epoch=424
06/18/2022 06:02:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/18/2022 06:02:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/18/2022 06:02:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/18/2022 06:02:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=434
06/18/2022 06:02:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/18/2022 06:02:45 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6975694444444444 on epoch=437
06/18/2022 06:02:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/18/2022 06:02:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/18/2022 06:02:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/18/2022 06:02:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=447
06/18/2022 06:02:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/18/2022 06:02:58 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6816919191919192 on epoch=449
06/18/2022 06:03:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/18/2022 06:03:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/18/2022 06:03:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/18/2022 06:03:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/18/2022 06:03:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/18/2022 06:03:12 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6836538461538462 on epoch=462
06/18/2022 06:03:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 06:03:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 06:03:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 06:03:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/18/2022 06:03:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 06:03:25 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6836538461538462 on epoch=474
06/18/2022 06:03:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/18/2022 06:03:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/18/2022 06:03:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/18/2022 06:03:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 06:03:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/18/2022 06:03:38 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6880555555555555 on epoch=487
06/18/2022 06:03:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 06:03:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/18/2022 06:03:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/18/2022 06:03:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/18/2022 06:03:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 06:03:51 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6598026598026597 on epoch=499
06/18/2022 06:03:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=502
06/18/2022 06:03:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/18/2022 06:03:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/18/2022 06:04:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 06:04:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/18/2022 06:04:05 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.682627276105537 on epoch=512
06/18/2022 06:04:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/18/2022 06:04:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/18/2022 06:04:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/18/2022 06:04:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/18/2022 06:04:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/18/2022 06:04:18 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7037684537684538 on epoch=524
06/18/2022 06:04:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/18/2022 06:04:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/18/2022 06:04:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/18/2022 06:04:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 06:04:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/18/2022 06:04:31 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7026839826839828 on epoch=537
06/18/2022 06:04:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/18/2022 06:04:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/18/2022 06:04:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/18/2022 06:04:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=547
06/18/2022 06:04:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/18/2022 06:04:45 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6654173088955697 on epoch=549
06/18/2022 06:04:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/18/2022 06:04:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/18/2022 06:04:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/18/2022 06:04:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=559
06/18/2022 06:04:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/18/2022 06:04:58 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6722477972477973 on epoch=562
06/18/2022 06:05:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/18/2022 06:05:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 06:05:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=569
06/18/2022 06:05:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/18/2022 06:05:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/18/2022 06:05:11 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7024372759856631 on epoch=574
06/18/2022 06:05:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 06:05:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/18/2022 06:05:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/18/2022 06:05:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/18/2022 06:05:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/18/2022 06:05:25 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7033783783783782 on epoch=587
06/18/2022 06:05:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/18/2022 06:05:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/18/2022 06:05:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/18/2022 06:05:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/18/2022 06:05:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/18/2022 06:05:38 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.68066534914361 on epoch=599
06/18/2022 06:05:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 06:05:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/18/2022 06:05:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/18/2022 06:05:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 06:05:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/18/2022 06:05:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6970280422889856 on epoch=612
06/18/2022 06:05:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/18/2022 06:05:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/18/2022 06:05:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/18/2022 06:06:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/18/2022 06:06:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/18/2022 06:06:04 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.718866608544028 on epoch=624
06/18/2022 06:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7099943693693693 -> 0.718866608544028 on epoch=624, global_step=2500
06/18/2022 06:06:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/18/2022 06:06:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/18/2022 06:06:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 06:06:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/18/2022 06:06:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 06:06:18 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6808990100309211 on epoch=637
06/18/2022 06:06:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 06:06:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 06:06:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/18/2022 06:06:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=647
06/18/2022 06:06:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/18/2022 06:06:31 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6808990100309211 on epoch=649
06/18/2022 06:06:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/18/2022 06:06:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/18/2022 06:06:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=657
06/18/2022 06:06:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 06:06:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=662
06/18/2022 06:06:44 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7175694444444444 on epoch=662
06/18/2022 06:06:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=664
06/18/2022 06:06:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/18/2022 06:06:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/18/2022 06:06:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/18/2022 06:06:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/18/2022 06:06:58 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.703377446925834 on epoch=674
06/18/2022 06:07:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/18/2022 06:07:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 06:07:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 06:07:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 06:07:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 06:07:11 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6964808558558558 on epoch=687
06/18/2022 06:07:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 06:07:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 06:07:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 06:07:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=697
06/18/2022 06:07:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/18/2022 06:07:24 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.718866608544028 on epoch=699
06/18/2022 06:07:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/18/2022 06:07:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=704
06/18/2022 06:07:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 06:07:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/18/2022 06:07:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/18/2022 06:07:38 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6980546123372948 on epoch=712
06/18/2022 06:07:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 06:07:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/18/2022 06:07:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 06:07:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=722
06/18/2022 06:07:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 06:07:51 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.716969696969697 on epoch=724
06/18/2022 06:07:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 06:07:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/18/2022 06:07:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/18/2022 06:08:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/18/2022 06:08:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=737
06/18/2022 06:08:05 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7164141414141414 on epoch=737
06/18/2022 06:08:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 06:08:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/18/2022 06:08:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 06:08:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/18/2022 06:08:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/18/2022 06:08:18 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7055555555555555 on epoch=749
06/18/2022 06:08:18 - INFO - __main__ - save last model!
06/18/2022 06:08:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 06:08:18 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 06:08:18 - INFO - __main__ - Printing 3 examples
06/18/2022 06:08:18 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:08:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:08:18 - INFO - __main__ - Printing 3 examples
06/18/2022 06:08:18 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:08:18 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:08:18 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:08:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:08:18 - INFO - __main__ - Printing 3 examples
06/18/2022 06:08:18 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 06:08:18 - INFO - __main__ - ['others']
06/18/2022 06:08:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:08:18 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:08:19 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:08:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:08:26 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 06:08:34 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:08:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:08:35 - INFO - __main__ - Starting training!
06/18/2022 06:09:51 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/18/2022 06:09:51 - INFO - __main__ - Classification-F1 on test data: 0.3218
06/18/2022 06:09:51 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.718866608544028, test_performance=0.32182164142374137
06/18/2022 06:09:51 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/18/2022 06:09:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:09:52 - INFO - __main__ - Printing 3 examples
06/18/2022 06:09:52 - INFO - __main__ -  [emo] how cause yes am listening
06/18/2022 06:09:52 - INFO - __main__ - ['others']
06/18/2022 06:09:52 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/18/2022 06:09:52 - INFO - __main__ - ['others']
06/18/2022 06:09:52 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/18/2022 06:09:52 - INFO - __main__ - ['others']
06/18/2022 06:09:52 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:09:52 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:09:52 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:09:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:09:52 - INFO - __main__ - Printing 3 examples
06/18/2022 06:09:52 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/18/2022 06:09:52 - INFO - __main__ - ['others']
06/18/2022 06:09:52 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/18/2022 06:09:52 - INFO - __main__ - ['others']
06/18/2022 06:09:52 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/18/2022 06:09:52 - INFO - __main__ - ['others']
06/18/2022 06:09:52 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:09:52 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:09:52 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:10:08 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:10:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:10:09 - INFO - __main__ - Starting training!
06/18/2022 06:10:12 - INFO - __main__ - Step 10 Global step 10 Train loss 4.52 on epoch=2
06/18/2022 06:10:14 - INFO - __main__ - Step 20 Global step 20 Train loss 3.53 on epoch=4
06/18/2022 06:10:17 - INFO - __main__ - Step 30 Global step 30 Train loss 3.18 on epoch=7
06/18/2022 06:10:19 - INFO - __main__ - Step 40 Global step 40 Train loss 2.61 on epoch=9
06/18/2022 06:10:21 - INFO - __main__ - Step 50 Global step 50 Train loss 2.28 on epoch=12
06/18/2022 06:10:23 - INFO - __main__ - Global step 50 Train loss 3.22 Classification-F1 0.028956356736242885 on epoch=12
06/18/2022 06:10:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.028956356736242885 on epoch=12, global_step=50
06/18/2022 06:10:25 - INFO - __main__ - Step 60 Global step 60 Train loss 2.01 on epoch=14
06/18/2022 06:10:28 - INFO - __main__ - Step 70 Global step 70 Train loss 1.80 on epoch=17
06/18/2022 06:10:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.51 on epoch=19
06/18/2022 06:10:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.29 on epoch=22
06/18/2022 06:10:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.09 on epoch=24
06/18/2022 06:10:36 - INFO - __main__ - Global step 100 Train loss 1.54 Classification-F1 0.2073794382617912 on epoch=24
06/18/2022 06:10:36 - INFO - __main__ - Saving model with best Classification-F1: 0.028956356736242885 -> 0.2073794382617912 on epoch=24, global_step=100
06/18/2022 06:10:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.14 on epoch=27
06/18/2022 06:10:41 - INFO - __main__ - Step 120 Global step 120 Train loss 1.06 on epoch=29
06/18/2022 06:10:43 - INFO - __main__ - Step 130 Global step 130 Train loss 1.02 on epoch=32
06/18/2022 06:10:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=34
06/18/2022 06:10:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.96 on epoch=37
06/18/2022 06:10:49 - INFO - __main__ - Global step 150 Train loss 1.00 Classification-F1 0.3623475472224273 on epoch=37
06/18/2022 06:10:49 - INFO - __main__ - Saving model with best Classification-F1: 0.2073794382617912 -> 0.3623475472224273 on epoch=37, global_step=150
06/18/2022 06:10:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=39
06/18/2022 06:10:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=42
06/18/2022 06:10:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=44
06/18/2022 06:10:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=47
06/18/2022 06:11:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=49
06/18/2022 06:11:02 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.5723837031603398 on epoch=49
06/18/2022 06:11:02 - INFO - __main__ - Saving model with best Classification-F1: 0.3623475472224273 -> 0.5723837031603398 on epoch=49, global_step=200
06/18/2022 06:11:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.80 on epoch=52
06/18/2022 06:11:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=54
06/18/2022 06:11:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.69 on epoch=57
06/18/2022 06:11:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=59
06/18/2022 06:11:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/18/2022 06:11:15 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.5972950525276106 on epoch=62
06/18/2022 06:11:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5723837031603398 -> 0.5972950525276106 on epoch=62, global_step=250
06/18/2022 06:11:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=64
06/18/2022 06:11:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=67
06/18/2022 06:11:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=69
06/18/2022 06:11:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.74 on epoch=72
06/18/2022 06:11:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=74
06/18/2022 06:11:28 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.6229716877914121 on epoch=74
06/18/2022 06:11:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5972950525276106 -> 0.6229716877914121 on epoch=74, global_step=300
06/18/2022 06:11:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=77
06/18/2022 06:11:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=79
06/18/2022 06:11:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=82
06/18/2022 06:11:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=84
06/18/2022 06:11:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=87
06/18/2022 06:11:42 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.6438492063492064 on epoch=87
06/18/2022 06:11:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6229716877914121 -> 0.6438492063492064 on epoch=87, global_step=350
06/18/2022 06:11:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.66 on epoch=89
06/18/2022 06:11:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=92
06/18/2022 06:11:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=94
06/18/2022 06:11:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.67 on epoch=97
06/18/2022 06:11:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.59 on epoch=99
06/18/2022 06:11:55 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.6357123189019741 on epoch=99
06/18/2022 06:11:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=102
06/18/2022 06:11:59 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=104
06/18/2022 06:12:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=107
06/18/2022 06:12:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=109
06/18/2022 06:12:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.53 on epoch=112
06/18/2022 06:12:08 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.6092836257309941 on epoch=112
06/18/2022 06:12:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.45 on epoch=114
06/18/2022 06:12:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/18/2022 06:12:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.51 on epoch=119
06/18/2022 06:12:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=122
06/18/2022 06:12:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=124
06/18/2022 06:12:21 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.6376025290498974 on epoch=124
06/18/2022 06:12:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.40 on epoch=127
06/18/2022 06:12:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=129
06/18/2022 06:12:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.47 on epoch=132
06/18/2022 06:12:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=134
06/18/2022 06:12:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=137
06/18/2022 06:12:34 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.6357123189019741 on epoch=137
06/18/2022 06:12:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=139
06/18/2022 06:12:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.43 on epoch=142
06/18/2022 06:12:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=144
06/18/2022 06:12:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=147
06/18/2022 06:12:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=149
06/18/2022 06:12:47 - INFO - __main__ - Global step 600 Train loss 0.40 Classification-F1 0.6217547637858825 on epoch=149
06/18/2022 06:12:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=152
06/18/2022 06:12:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.41 on epoch=154
06/18/2022 06:12:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.47 on epoch=157
06/18/2022 06:12:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=159
06/18/2022 06:12:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.41 on epoch=162
06/18/2022 06:13:00 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.6201321735849675 on epoch=162
06/18/2022 06:13:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=164
06/18/2022 06:13:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=167
06/18/2022 06:13:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=169
06/18/2022 06:13:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=172
06/18/2022 06:13:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=174
06/18/2022 06:13:13 - INFO - __main__ - Global step 700 Train loss 0.35 Classification-F1 0.6199682674428005 on epoch=174
06/18/2022 06:13:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.39 on epoch=177
06/18/2022 06:13:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=179
06/18/2022 06:13:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=182
06/18/2022 06:13:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=184
06/18/2022 06:13:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.44 on epoch=187
06/18/2022 06:13:26 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.6348684210526315 on epoch=187
06/18/2022 06:13:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=189
06/18/2022 06:13:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=192
06/18/2022 06:13:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=194
06/18/2022 06:13:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=197
06/18/2022 06:13:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=199
06/18/2022 06:13:39 - INFO - __main__ - Global step 800 Train loss 0.30 Classification-F1 0.6225225225225224 on epoch=199
06/18/2022 06:13:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/18/2022 06:13:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=204
06/18/2022 06:13:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=207
06/18/2022 06:13:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=209
06/18/2022 06:13:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=212
06/18/2022 06:13:52 - INFO - __main__ - Global step 850 Train loss 0.30 Classification-F1 0.6348684210526315 on epoch=212
06/18/2022 06:13:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=214
06/18/2022 06:13:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=217
06/18/2022 06:13:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.27 on epoch=219
06/18/2022 06:14:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=222
06/18/2022 06:14:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.31 on epoch=224
06/18/2022 06:14:05 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.6217872284048755 on epoch=224
06/18/2022 06:14:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.35 on epoch=227
06/18/2022 06:14:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=229
06/18/2022 06:14:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=232
06/18/2022 06:14:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=234
06/18/2022 06:14:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=237
06/18/2022 06:14:18 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.6159889472049183 on epoch=237
06/18/2022 06:14:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=239
06/18/2022 06:14:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=242
06/18/2022 06:14:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/18/2022 06:14:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=247
06/18/2022 06:14:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=249
06/18/2022 06:14:31 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.6415701415701416 on epoch=249
06/18/2022 06:14:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.31 on epoch=252
06/18/2022 06:14:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=254
06/18/2022 06:14:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.22 on epoch=257
06/18/2022 06:14:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/18/2022 06:14:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=262
06/18/2022 06:14:45 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.6864160401002507 on epoch=262
06/18/2022 06:14:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6438492063492064 -> 0.6864160401002507 on epoch=262, global_step=1050
06/18/2022 06:14:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=264
06/18/2022 06:14:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=267
06/18/2022 06:14:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/18/2022 06:14:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=272
06/18/2022 06:14:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=274
06/18/2022 06:14:58 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.6596910209442179 on epoch=274
06/18/2022 06:15:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=277
06/18/2022 06:15:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=279
06/18/2022 06:15:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=282
06/18/2022 06:15:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=284
06/18/2022 06:15:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=287
06/18/2022 06:15:11 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.6453697737007694 on epoch=287
06/18/2022 06:15:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=289
06/18/2022 06:15:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=292
06/18/2022 06:15:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=294
06/18/2022 06:15:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.26 on epoch=297
06/18/2022 06:15:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=299
06/18/2022 06:15:24 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.6554972804972805 on epoch=299
06/18/2022 06:15:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=302
06/18/2022 06:15:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=304
06/18/2022 06:15:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/18/2022 06:15:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/18/2022 06:15:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=312
06/18/2022 06:15:38 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.688673421432042 on epoch=312
06/18/2022 06:15:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6864160401002507 -> 0.688673421432042 on epoch=312, global_step=1250
06/18/2022 06:15:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/18/2022 06:15:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=317
06/18/2022 06:15:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=319
06/18/2022 06:15:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=322
06/18/2022 06:15:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=324
06/18/2022 06:15:51 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.6452709907072497 on epoch=324
06/18/2022 06:15:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/18/2022 06:15:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=329
06/18/2022 06:15:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=332
06/18/2022 06:16:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/18/2022 06:16:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/18/2022 06:16:04 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.6325208181744684 on epoch=337
06/18/2022 06:16:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=339
06/18/2022 06:16:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/18/2022 06:16:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=344
06/18/2022 06:16:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/18/2022 06:16:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/18/2022 06:16:17 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6032732732732733 on epoch=349
06/18/2022 06:16:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=352
06/18/2022 06:16:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=354
06/18/2022 06:16:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=357
06/18/2022 06:16:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=359
06/18/2022 06:16:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=362
06/18/2022 06:16:30 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.6452709907072497 on epoch=362
06/18/2022 06:16:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=364
06/18/2022 06:16:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/18/2022 06:16:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=369
06/18/2022 06:16:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=372
06/18/2022 06:16:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
06/18/2022 06:16:44 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.6154970760233918 on epoch=374
06/18/2022 06:16:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/18/2022 06:16:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=379
06/18/2022 06:16:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=382
06/18/2022 06:16:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=384
06/18/2022 06:16:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/18/2022 06:16:57 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.6146334727373155 on epoch=387
06/18/2022 06:16:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/18/2022 06:17:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=392
06/18/2022 06:17:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=394
06/18/2022 06:17:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=397
06/18/2022 06:17:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/18/2022 06:17:10 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6138650091739337 on epoch=399
06/18/2022 06:17:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/18/2022 06:17:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=404
06/18/2022 06:17:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=407
06/18/2022 06:17:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/18/2022 06:17:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/18/2022 06:17:23 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6514144639144639 on epoch=412
06/18/2022 06:17:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=414
06/18/2022 06:17:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
06/18/2022 06:17:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/18/2022 06:17:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=422
06/18/2022 06:17:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=424
06/18/2022 06:17:36 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6138650091739337 on epoch=424
06/18/2022 06:17:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/18/2022 06:17:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/18/2022 06:17:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=432
06/18/2022 06:17:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=434
06/18/2022 06:17:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/18/2022 06:17:49 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6588209088209087 on epoch=437
06/18/2022 06:17:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/18/2022 06:17:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=442
06/18/2022 06:17:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/18/2022 06:17:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/18/2022 06:18:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=449
06/18/2022 06:18:02 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6275120732017284 on epoch=449
06/18/2022 06:18:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=452
06/18/2022 06:18:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=454
06/18/2022 06:18:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=457
06/18/2022 06:18:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=459
06/18/2022 06:18:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/18/2022 06:18:15 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.6280466835189473 on epoch=462
06/18/2022 06:18:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 06:18:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
06/18/2022 06:18:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/18/2022 06:18:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/18/2022 06:18:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/18/2022 06:18:29 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6521825396825397 on epoch=474
06/18/2022 06:18:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/18/2022 06:18:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/18/2022 06:18:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/18/2022 06:18:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/18/2022 06:18:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=487
06/18/2022 06:18:42 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6677534630120837 on epoch=487
06/18/2022 06:18:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/18/2022 06:18:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/18/2022 06:18:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/18/2022 06:18:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/18/2022 06:18:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/18/2022 06:18:55 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6128337147215865 on epoch=499
06/18/2022 06:18:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 06:19:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=504
06/18/2022 06:19:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/18/2022 06:19:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/18/2022 06:19:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/18/2022 06:19:08 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6598026598026597 on epoch=512
06/18/2022 06:19:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/18/2022 06:19:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=517
06/18/2022 06:19:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/18/2022 06:19:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/18/2022 06:19:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/18/2022 06:19:21 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6436895705774424 on epoch=524
06/18/2022 06:19:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/18/2022 06:19:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/18/2022 06:19:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/18/2022 06:19:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/18/2022 06:19:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/18/2022 06:19:35 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6292407414427049 on epoch=537
06/18/2022 06:19:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=539
06/18/2022 06:19:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/18/2022 06:19:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/18/2022 06:19:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/18/2022 06:19:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/18/2022 06:19:48 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6179108691268401 on epoch=549
06/18/2022 06:19:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/18/2022 06:19:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/18/2022 06:19:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/18/2022 06:19:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=559
06/18/2022 06:20:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/18/2022 06:20:01 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6179108691268401 on epoch=562
06/18/2022 06:20:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/18/2022 06:20:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=567
06/18/2022 06:20:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/18/2022 06:20:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/18/2022 06:20:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/18/2022 06:20:14 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6585249042145593 on epoch=574
06/18/2022 06:20:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/18/2022 06:20:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/18/2022 06:20:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=582
06/18/2022 06:20:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/18/2022 06:20:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/18/2022 06:20:28 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6024014336917562 on epoch=587
06/18/2022 06:20:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/18/2022 06:20:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/18/2022 06:20:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/18/2022 06:20:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/18/2022 06:20:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=599
06/18/2022 06:20:41 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6568616501465867 on epoch=599
06/18/2022 06:20:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=602
06/18/2022 06:20:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/18/2022 06:20:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/18/2022 06:20:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=609
06/18/2022 06:20:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/18/2022 06:20:54 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6032732732732733 on epoch=612
06/18/2022 06:20:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/18/2022 06:20:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/18/2022 06:21:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/18/2022 06:21:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/18/2022 06:21:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=624
06/18/2022 06:21:07 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.660824838244193 on epoch=624
06/18/2022 06:21:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=627
06/18/2022 06:21:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/18/2022 06:21:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 06:21:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/18/2022 06:21:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=637
06/18/2022 06:21:21 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6177480158730159 on epoch=637
06/18/2022 06:21:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 06:21:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=642
06/18/2022 06:21:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/18/2022 06:21:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 06:21:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/18/2022 06:21:34 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6585249042145593 on epoch=649
06/18/2022 06:21:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/18/2022 06:21:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/18/2022 06:21:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/18/2022 06:21:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/18/2022 06:21:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/18/2022 06:21:47 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6585249042145593 on epoch=662
06/18/2022 06:21:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.12 on epoch=664
06/18/2022 06:21:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/18/2022 06:21:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
06/18/2022 06:21:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/18/2022 06:22:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/18/2022 06:22:00 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6510687638636822 on epoch=674
06/18/2022 06:22:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/18/2022 06:22:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/18/2022 06:22:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=682
06/18/2022 06:22:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=684
06/18/2022 06:22:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/18/2022 06:22:14 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6813486873970744 on epoch=687
06/18/2022 06:22:16 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/18/2022 06:22:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/18/2022 06:22:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 06:22:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/18/2022 06:22:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/18/2022 06:22:27 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6277913674741576 on epoch=699
06/18/2022 06:22:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/18/2022 06:22:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/18/2022 06:22:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/18/2022 06:22:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/18/2022 06:22:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=712
06/18/2022 06:22:40 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6355231026283658 on epoch=712
06/18/2022 06:22:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/18/2022 06:22:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/18/2022 06:22:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/18/2022 06:22:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/18/2022 06:22:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=724
06/18/2022 06:22:53 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6675324675324675 on epoch=724
06/18/2022 06:22:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=727
06/18/2022 06:22:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/18/2022 06:23:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/18/2022 06:23:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=734
06/18/2022 06:23:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.14 on epoch=737
06/18/2022 06:23:07 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.6304974329167877 on epoch=737
06/18/2022 06:23:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.10 on epoch=739
06/18/2022 06:23:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
06/18/2022 06:23:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/18/2022 06:23:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/18/2022 06:23:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=749
06/18/2022 06:23:20 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6604617604617604 on epoch=749
06/18/2022 06:23:20 - INFO - __main__ - save last model!
06/18/2022 06:23:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 06:23:20 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 06:23:20 - INFO - __main__ - Printing 3 examples
06/18/2022 06:23:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:23:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:23:20 - INFO - __main__ - Printing 3 examples
06/18/2022 06:23:20 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:23:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:23:20 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:23:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:23:20 - INFO - __main__ - Printing 3 examples
06/18/2022 06:23:20 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 06:23:20 - INFO - __main__ - ['others']
06/18/2022 06:23:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:23:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:23:20 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:23:22 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:23:27 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 06:23:39 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:23:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:23:40 - INFO - __main__ - Starting training!
06/18/2022 06:24:41 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/18/2022 06:24:42 - INFO - __main__ - Classification-F1 on test data: 0.1642
06/18/2022 06:24:42 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.688673421432042, test_performance=0.16420468744698097
06/18/2022 06:24:42 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/18/2022 06:24:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:24:43 - INFO - __main__ - Printing 3 examples
06/18/2022 06:24:43 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 06:24:43 - INFO - __main__ - ['others']
06/18/2022 06:24:43 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 06:24:43 - INFO - __main__ - ['others']
06/18/2022 06:24:43 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 06:24:43 - INFO - __main__ - ['others']
06/18/2022 06:24:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:24:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:24:43 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:24:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:24:43 - INFO - __main__ - Printing 3 examples
06/18/2022 06:24:43 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 06:24:43 - INFO - __main__ - ['others']
06/18/2022 06:24:43 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 06:24:43 - INFO - __main__ - ['others']
06/18/2022 06:24:43 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 06:24:43 - INFO - __main__ - ['others']
06/18/2022 06:24:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:24:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:24:43 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:24:58 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:24:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:24:59 - INFO - __main__ - Starting training!
06/18/2022 06:25:02 - INFO - __main__ - Step 10 Global step 10 Train loss 3.90 on epoch=2
06/18/2022 06:25:04 - INFO - __main__ - Step 20 Global step 20 Train loss 2.62 on epoch=4
06/18/2022 06:25:07 - INFO - __main__ - Step 30 Global step 30 Train loss 1.79 on epoch=7
06/18/2022 06:25:09 - INFO - __main__ - Step 40 Global step 40 Train loss 1.32 on epoch=9
06/18/2022 06:25:12 - INFO - __main__ - Step 50 Global step 50 Train loss 0.91 on epoch=12
06/18/2022 06:25:13 - INFO - __main__ - Global step 50 Train loss 2.11 Classification-F1 0.25686685899117057 on epoch=12
06/18/2022 06:25:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.25686685899117057 on epoch=12, global_step=50
06/18/2022 06:25:15 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/18/2022 06:25:18 - INFO - __main__ - Step 70 Global step 70 Train loss 0.74 on epoch=17
06/18/2022 06:25:20 - INFO - __main__ - Step 80 Global step 80 Train loss 0.81 on epoch=19
06/18/2022 06:25:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.60 on epoch=22
06/18/2022 06:25:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.55 on epoch=24
06/18/2022 06:25:26 - INFO - __main__ - Global step 100 Train loss 0.74 Classification-F1 0.5455867121384363 on epoch=24
06/18/2022 06:25:26 - INFO - __main__ - Saving model with best Classification-F1: 0.25686685899117057 -> 0.5455867121384363 on epoch=24, global_step=100
06/18/2022 06:25:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=27
06/18/2022 06:25:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.56 on epoch=29
06/18/2022 06:25:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.43 on epoch=32
06/18/2022 06:25:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.45 on epoch=34
06/18/2022 06:25:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.46 on epoch=37
06/18/2022 06:25:39 - INFO - __main__ - Global step 150 Train loss 0.48 Classification-F1 0.6845081453634085 on epoch=37
06/18/2022 06:25:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5455867121384363 -> 0.6845081453634085 on epoch=37, global_step=150
06/18/2022 06:25:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.41 on epoch=39
06/18/2022 06:25:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=42
06/18/2022 06:25:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.41 on epoch=44
06/18/2022 06:25:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=47
06/18/2022 06:25:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=49
06/18/2022 06:25:52 - INFO - __main__ - Global step 200 Train loss 0.41 Classification-F1 0.5382702615300239 on epoch=49
06/18/2022 06:25:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.32 on epoch=52
06/18/2022 06:25:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=54
06/18/2022 06:26:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=57
06/18/2022 06:26:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=59
06/18/2022 06:26:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=62
06/18/2022 06:26:05 - INFO - __main__ - Global step 250 Train loss 0.32 Classification-F1 0.7029411764705883 on epoch=62
06/18/2022 06:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6845081453634085 -> 0.7029411764705883 on epoch=62, global_step=250
06/18/2022 06:26:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=64
06/18/2022 06:26:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=67
06/18/2022 06:26:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/18/2022 06:26:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/18/2022 06:26:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=74
06/18/2022 06:26:18 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.6951032059727711 on epoch=74
06/18/2022 06:26:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=77
06/18/2022 06:26:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.20 on epoch=79
06/18/2022 06:26:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=82
06/18/2022 06:26:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/18/2022 06:26:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=87
06/18/2022 06:26:32 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.7163515406162465 on epoch=87
06/18/2022 06:26:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7029411764705883 -> 0.7163515406162465 on epoch=87, global_step=350
06/18/2022 06:26:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=89
06/18/2022 06:26:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/18/2022 06:26:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.17 on epoch=94
06/18/2022 06:26:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/18/2022 06:26:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=99
06/18/2022 06:26:45 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6947232947232947 on epoch=99
06/18/2022 06:26:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=102
06/18/2022 06:26:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=104
06/18/2022 06:26:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=107
06/18/2022 06:26:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.09 on epoch=109
06/18/2022 06:26:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=112
06/18/2022 06:26:58 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.6988400113400113 on epoch=112
06/18/2022 06:27:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/18/2022 06:27:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=117
06/18/2022 06:27:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=119
06/18/2022 06:27:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=122
06/18/2022 06:27:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=124
06/18/2022 06:27:11 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.695109126984127 on epoch=124
06/18/2022 06:27:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/18/2022 06:27:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=129
06/18/2022 06:27:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=132
06/18/2022 06:27:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=134
06/18/2022 06:27:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=137
06/18/2022 06:27:24 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.6764705882352942 on epoch=137
06/18/2022 06:27:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=139
06/18/2022 06:27:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/18/2022 06:27:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=144
06/18/2022 06:27:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
06/18/2022 06:27:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/18/2022 06:27:37 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7311688311688312 on epoch=149
06/18/2022 06:27:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7163515406162465 -> 0.7311688311688312 on epoch=149, global_step=600
06/18/2022 06:27:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/18/2022 06:27:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/18/2022 06:27:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=157
06/18/2022 06:27:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=159
06/18/2022 06:27:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/18/2022 06:27:50 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.7109827806602 on epoch=162
06/18/2022 06:27:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/18/2022 06:27:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/18/2022 06:27:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=169
06/18/2022 06:28:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/18/2022 06:28:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
06/18/2022 06:28:03 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7034845946387709 on epoch=174
06/18/2022 06:28:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/18/2022 06:28:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/18/2022 06:28:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/18/2022 06:28:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/18/2022 06:28:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
06/18/2022 06:28:17 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.6815274455077087 on epoch=187
06/18/2022 06:28:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/18/2022 06:28:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/18/2022 06:28:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/18/2022 06:28:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/18/2022 06:28:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/18/2022 06:28:30 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.6987240829346092 on epoch=199
06/18/2022 06:28:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/18/2022 06:28:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/18/2022 06:28:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/18/2022 06:28:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/18/2022 06:28:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/18/2022 06:28:43 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.704602231384914 on epoch=212
06/18/2022 06:28:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/18/2022 06:28:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/18/2022 06:28:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/18/2022 06:28:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/18/2022 06:28:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/18/2022 06:28:56 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.667227485775873 on epoch=224
06/18/2022 06:28:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/18/2022 06:29:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/18/2022 06:29:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/18/2022 06:29:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/18/2022 06:29:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/18/2022 06:29:09 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7154168694915725 on epoch=237
06/18/2022 06:29:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/18/2022 06:29:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/18/2022 06:29:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/18/2022 06:29:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/18/2022 06:29:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/18/2022 06:29:22 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.6889705882352941 on epoch=249
06/18/2022 06:29:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/18/2022 06:29:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/18/2022 06:29:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/18/2022 06:29:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/18/2022 06:29:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/18/2022 06:29:35 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7654875366568914 on epoch=262
06/18/2022 06:29:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7311688311688312 -> 0.7654875366568914 on epoch=262, global_step=1050
06/18/2022 06:29:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/18/2022 06:29:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/18/2022 06:29:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/18/2022 06:29:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/18/2022 06:29:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/18/2022 06:29:49 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6804233870967743 on epoch=274
06/18/2022 06:29:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/18/2022 06:29:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/18/2022 06:29:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/18/2022 06:29:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/18/2022 06:30:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/18/2022 06:30:02 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.709977146263911 on epoch=287
06/18/2022 06:30:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/18/2022 06:30:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/18/2022 06:30:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/18/2022 06:30:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/18/2022 06:30:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/18/2022 06:30:15 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7597902097902098 on epoch=299
06/18/2022 06:30:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/18/2022 06:30:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/18/2022 06:30:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/18/2022 06:30:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/18/2022 06:30:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/18/2022 06:30:29 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7636796123372949 on epoch=312
06/18/2022 06:30:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/18/2022 06:30:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
06/18/2022 06:30:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/18/2022 06:30:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/18/2022 06:30:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/18/2022 06:30:42 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7250644162588635 on epoch=324
06/18/2022 06:30:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/18/2022 06:30:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/18/2022 06:30:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/18/2022 06:30:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/18/2022 06:30:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/18/2022 06:30:55 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7740350877192983 on epoch=337
06/18/2022 06:30:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7654875366568914 -> 0.7740350877192983 on epoch=337, global_step=1350
06/18/2022 06:30:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/18/2022 06:31:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/18/2022 06:31:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/18/2022 06:31:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/18/2022 06:31:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/18/2022 06:31:09 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7295360938187764 on epoch=349
06/18/2022 06:31:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/18/2022 06:31:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/18/2022 06:31:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/18/2022 06:31:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/18/2022 06:31:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/18/2022 06:31:22 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.733853586027499 on epoch=362
06/18/2022 06:31:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/18/2022 06:31:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 06:31:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/18/2022 06:31:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/18/2022 06:31:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/18/2022 06:31:36 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7181341799855124 on epoch=374
06/18/2022 06:31:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/18/2022 06:31:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/18/2022 06:31:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 06:31:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/18/2022 06:31:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/18/2022 06:31:49 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.733853586027499 on epoch=387
06/18/2022 06:31:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/18/2022 06:31:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/18/2022 06:31:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/18/2022 06:31:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/18/2022 06:32:01 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/18/2022 06:32:02 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6874842690699468 on epoch=399
06/18/2022 06:32:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/18/2022 06:32:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 06:32:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 06:32:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/18/2022 06:32:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/18/2022 06:32:16 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6803508053508054 on epoch=412
06/18/2022 06:32:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 06:32:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/18/2022 06:32:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/18/2022 06:32:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/18/2022 06:32:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/18/2022 06:32:29 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7036799027288156 on epoch=424
06/18/2022 06:32:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/18/2022 06:32:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/18/2022 06:32:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 06:32:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/18/2022 06:32:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 06:32:43 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7426854395604396 on epoch=437
06/18/2022 06:32:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/18/2022 06:32:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/18/2022 06:32:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/18/2022 06:32:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/18/2022 06:32:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/18/2022 06:32:56 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7278861865258924 on epoch=449
06/18/2022 06:32:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/18/2022 06:33:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/18/2022 06:33:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/18/2022 06:33:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/18/2022 06:33:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/18/2022 06:33:09 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7187671727237683 on epoch=462
06/18/2022 06:33:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 06:33:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 06:33:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/18/2022 06:33:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/18/2022 06:33:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/18/2022 06:33:23 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7434464825356666 on epoch=474
06/18/2022 06:33:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/18/2022 06:33:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/18/2022 06:33:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 06:33:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 06:33:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 06:33:36 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7187886725517696 on epoch=487
06/18/2022 06:33:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/18/2022 06:33:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/18/2022 06:33:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 06:33:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/18/2022 06:33:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/18/2022 06:33:50 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7732905982905983 on epoch=499
06/18/2022 06:33:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/18/2022 06:33:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 06:33:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/18/2022 06:34:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=509
06/18/2022 06:34:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 06:34:03 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7327654424428618 on epoch=512
06/18/2022 06:34:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 06:34:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/18/2022 06:34:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 06:34:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/18/2022 06:34:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 06:34:17 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7239583333333334 on epoch=524
06/18/2022 06:34:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/18/2022 06:34:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 06:34:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 06:34:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 06:34:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/18/2022 06:34:30 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7187671727237683 on epoch=537
06/18/2022 06:34:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/18/2022 06:34:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 06:34:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 06:34:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 06:34:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 06:34:44 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7771987868762062 on epoch=549
06/18/2022 06:34:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7740350877192983 -> 0.7771987868762062 on epoch=549, global_step=2200
06/18/2022 06:34:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/18/2022 06:34:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 06:34:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/18/2022 06:34:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 06:34:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/18/2022 06:34:57 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.733853586027499 on epoch=562
06/18/2022 06:35:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/18/2022 06:35:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 06:35:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 06:35:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/18/2022 06:35:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 06:35:11 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6884633994608418 on epoch=574
06/18/2022 06:35:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 06:35:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 06:35:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/18/2022 06:35:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 06:35:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 06:35:24 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7231686900804548 on epoch=587
06/18/2022 06:35:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 06:35:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 06:35:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 06:35:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 06:35:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 06:35:38 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6884633994608418 on epoch=599
06/18/2022 06:35:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 06:35:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 06:35:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 06:35:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 06:35:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 06:35:51 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7276470588235294 on epoch=612
06/18/2022 06:35:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 06:35:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=617
06/18/2022 06:35:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 06:36:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 06:36:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=624
06/18/2022 06:36:05 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7170439455046231 on epoch=624
06/18/2022 06:36:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 06:36:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 06:36:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 06:36:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 06:36:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=637
06/18/2022 06:36:18 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7399804496578691 on epoch=637
06/18/2022 06:36:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 06:36:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 06:36:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 06:36:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 06:36:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 06:36:32 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6941526610644257 on epoch=649
06/18/2022 06:36:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 06:36:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=654
06/18/2022 06:36:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 06:36:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 06:36:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 06:36:45 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7136292016806723 on epoch=662
06/18/2022 06:36:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 06:36:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 06:36:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 06:36:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/18/2022 06:36:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/18/2022 06:36:59 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7391443863218057 on epoch=674
06/18/2022 06:37:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 06:37:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 06:37:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 06:37:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 06:37:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 06:37:12 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7312920661995205 on epoch=687
06/18/2022 06:37:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 06:37:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 06:37:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 06:37:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/18/2022 06:37:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 06:37:26 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7089980158730158 on epoch=699
06/18/2022 06:37:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 06:37:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 06:37:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 06:37:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 06:37:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 06:37:39 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6941526610644257 on epoch=712
06/18/2022 06:37:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 06:37:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 06:37:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 06:37:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 06:37:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 06:37:53 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7375032249742002 on epoch=724
06/18/2022 06:37:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 06:37:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 06:38:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 06:38:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 06:38:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 06:38:06 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6941526610644257 on epoch=737
06/18/2022 06:38:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/18/2022 06:38:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 06:38:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.18 on epoch=744
06/18/2022 06:38:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 06:38:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 06:38:20 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7825440742466605 on epoch=749
06/18/2022 06:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7771987868762062 -> 0.7825440742466605 on epoch=749, global_step=3000
06/18/2022 06:38:20 - INFO - __main__ - save last model!
06/18/2022 06:38:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 06:38:20 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 06:38:20 - INFO - __main__ - Printing 3 examples
06/18/2022 06:38:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:38:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:38:20 - INFO - __main__ - Printing 3 examples
06/18/2022 06:38:20 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:38:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:38:20 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:38:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:38:20 - INFO - __main__ - Printing 3 examples
06/18/2022 06:38:20 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 06:38:20 - INFO - __main__ - ['others']
06/18/2022 06:38:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:38:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:38:20 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:38:22 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:38:27 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 06:38:35 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:38:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:38:36 - INFO - __main__ - Starting training!
06/18/2022 06:40:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/18/2022 06:40:01 - INFO - __main__ - Classification-F1 on test data: 0.3344
06/18/2022 06:40:01 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.7825440742466605, test_performance=0.3343839129365355
06/18/2022 06:40:01 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/18/2022 06:40:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:40:02 - INFO - __main__ - Printing 3 examples
06/18/2022 06:40:02 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 06:40:02 - INFO - __main__ - ['others']
06/18/2022 06:40:02 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 06:40:02 - INFO - __main__ - ['others']
06/18/2022 06:40:02 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 06:40:02 - INFO - __main__ - ['others']
06/18/2022 06:40:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:40:02 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:40:02 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:40:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:40:02 - INFO - __main__ - Printing 3 examples
06/18/2022 06:40:02 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 06:40:02 - INFO - __main__ - ['others']
06/18/2022 06:40:02 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 06:40:02 - INFO - __main__ - ['others']
06/18/2022 06:40:02 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 06:40:02 - INFO - __main__ - ['others']
06/18/2022 06:40:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:40:02 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:40:02 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:40:20 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:40:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:40:21 - INFO - __main__ - Starting training!
06/18/2022 06:40:24 - INFO - __main__ - Step 10 Global step 10 Train loss 3.97 on epoch=2
06/18/2022 06:40:27 - INFO - __main__ - Step 20 Global step 20 Train loss 3.06 on epoch=4
06/18/2022 06:40:29 - INFO - __main__ - Step 30 Global step 30 Train loss 2.29 on epoch=7
06/18/2022 06:40:31 - INFO - __main__ - Step 40 Global step 40 Train loss 1.66 on epoch=9
06/18/2022 06:40:34 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=12
06/18/2022 06:40:35 - INFO - __main__ - Global step 50 Train loss 2.45 Classification-F1 0.22037037037037038 on epoch=12
06/18/2022 06:40:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.22037037037037038 on epoch=12, global_step=50
06/18/2022 06:40:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=14
06/18/2022 06:40:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=17
06/18/2022 06:40:42 - INFO - __main__ - Step 80 Global step 80 Train loss 0.78 on epoch=19
06/18/2022 06:40:45 - INFO - __main__ - Step 90 Global step 90 Train loss 0.63 on epoch=22
06/18/2022 06:40:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.63 on epoch=24
06/18/2022 06:40:48 - INFO - __main__ - Global step 100 Train loss 0.80 Classification-F1 0.5461666666666667 on epoch=24
06/18/2022 06:40:48 - INFO - __main__ - Saving model with best Classification-F1: 0.22037037037037038 -> 0.5461666666666667 on epoch=24, global_step=100
06/18/2022 06:40:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.61 on epoch=27
06/18/2022 06:40:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.51 on epoch=29
06/18/2022 06:40:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.63 on epoch=32
06/18/2022 06:40:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=34
06/18/2022 06:41:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.45 on epoch=37
06/18/2022 06:41:01 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.6730550284629981 on epoch=37
06/18/2022 06:41:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5461666666666667 -> 0.6730550284629981 on epoch=37, global_step=150
06/18/2022 06:41:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=39
06/18/2022 06:41:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=42
06/18/2022 06:41:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.42 on epoch=44
06/18/2022 06:41:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.43 on epoch=47
06/18/2022 06:41:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=49
06/18/2022 06:41:14 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.6805323653962492 on epoch=49
06/18/2022 06:41:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6730550284629981 -> 0.6805323653962492 on epoch=49, global_step=200
06/18/2022 06:41:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.31 on epoch=52
06/18/2022 06:41:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.33 on epoch=54
06/18/2022 06:41:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=57
06/18/2022 06:41:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=59
06/18/2022 06:41:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=62
06/18/2022 06:41:28 - INFO - __main__ - Global step 250 Train loss 0.34 Classification-F1 0.6851532567049808 on epoch=62
06/18/2022 06:41:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6805323653962492 -> 0.6851532567049808 on epoch=62, global_step=250
06/18/2022 06:41:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=64
06/18/2022 06:41:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=67
06/18/2022 06:41:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=69
06/18/2022 06:41:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/18/2022 06:41:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=74
06/18/2022 06:41:41 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.6597222222222222 on epoch=74
06/18/2022 06:41:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/18/2022 06:41:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=79
06/18/2022 06:41:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=82
06/18/2022 06:41:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=84
06/18/2022 06:41:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/18/2022 06:41:54 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.6831271397447869 on epoch=87
06/18/2022 06:41:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=89
06/18/2022 06:41:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=92
06/18/2022 06:42:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/18/2022 06:42:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=97
06/18/2022 06:42:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/18/2022 06:42:07 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6800606460532931 on epoch=99
06/18/2022 06:42:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.13 on epoch=102
06/18/2022 06:42:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=104
06/18/2022 06:42:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=107
06/18/2022 06:42:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
06/18/2022 06:42:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=112
06/18/2022 06:42:20 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.6955723345525977 on epoch=112
06/18/2022 06:42:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6851532567049808 -> 0.6955723345525977 on epoch=112, global_step=450
06/18/2022 06:42:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=114
06/18/2022 06:42:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=117
06/18/2022 06:42:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=119
06/18/2022 06:42:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/18/2022 06:42:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/18/2022 06:42:33 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.6741159608806668 on epoch=124
06/18/2022 06:42:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/18/2022 06:42:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=129
06/18/2022 06:42:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/18/2022 06:42:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=134
06/18/2022 06:42:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/18/2022 06:42:46 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.704602231384914 on epoch=137
06/18/2022 06:42:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6955723345525977 -> 0.704602231384914 on epoch=137, global_step=550
06/18/2022 06:42:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/18/2022 06:42:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
06/18/2022 06:42:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/18/2022 06:42:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=147
06/18/2022 06:42:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/18/2022 06:42:58 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.704602231384914 on epoch=149
06/18/2022 06:43:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/18/2022 06:43:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/18/2022 06:43:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=157
06/18/2022 06:43:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/18/2022 06:43:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/18/2022 06:43:11 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.7111449502341343 on epoch=162
06/18/2022 06:43:11 - INFO - __main__ - Saving model with best Classification-F1: 0.704602231384914 -> 0.7111449502341343 on epoch=162, global_step=650
06/18/2022 06:43:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/18/2022 06:43:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=167
06/18/2022 06:43:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/18/2022 06:43:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/18/2022 06:43:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/18/2022 06:43:24 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.6741159608806668 on epoch=174
06/18/2022 06:43:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/18/2022 06:43:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/18/2022 06:43:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/18/2022 06:43:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/18/2022 06:43:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
06/18/2022 06:43:37 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.6944871794871795 on epoch=187
06/18/2022 06:43:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/18/2022 06:43:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/18/2022 06:43:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/18/2022 06:43:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=197
06/18/2022 06:43:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/18/2022 06:43:49 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6751091269841271 on epoch=199
06/18/2022 06:43:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
06/18/2022 06:43:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/18/2022 06:43:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/18/2022 06:43:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/18/2022 06:44:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/18/2022 06:44:02 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6739958407605467 on epoch=212
06/18/2022 06:44:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/18/2022 06:44:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/18/2022 06:44:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
06/18/2022 06:44:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/18/2022 06:44:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/18/2022 06:44:15 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7184905803419127 on epoch=224
06/18/2022 06:44:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7111449502341343 -> 0.7184905803419127 on epoch=224, global_step=900
06/18/2022 06:44:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/18/2022 06:44:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/18/2022 06:44:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/18/2022 06:44:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/18/2022 06:44:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/18/2022 06:44:28 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7238618082368082 on epoch=237
06/18/2022 06:44:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7184905803419127 -> 0.7238618082368082 on epoch=237, global_step=950
06/18/2022 06:44:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/18/2022 06:44:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/18/2022 06:44:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/18/2022 06:44:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/18/2022 06:44:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
06/18/2022 06:44:40 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6878810944667721 on epoch=249
06/18/2022 06:44:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/18/2022 06:44:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/18/2022 06:44:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/18/2022 06:44:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/18/2022 06:44:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/18/2022 06:44:53 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6878810944667721 on epoch=262
06/18/2022 06:44:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/18/2022 06:44:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/18/2022 06:45:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/18/2022 06:45:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/18/2022 06:45:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/18/2022 06:45:06 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6976133887898593 on epoch=274
06/18/2022 06:45:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/18/2022 06:45:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/18/2022 06:45:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/18/2022 06:45:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/18/2022 06:45:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/18/2022 06:45:19 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7126503126503128 on epoch=287
06/18/2022 06:45:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=289
06/18/2022 06:45:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/18/2022 06:45:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/18/2022 06:45:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/18/2022 06:45:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/18/2022 06:45:32 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7231686900804548 on epoch=299
06/18/2022 06:45:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/18/2022 06:45:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/18/2022 06:45:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/18/2022 06:45:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/18/2022 06:45:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/18/2022 06:45:45 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7136292016806723 on epoch=312
06/18/2022 06:45:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/18/2022 06:45:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/18/2022 06:45:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=319
06/18/2022 06:45:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/18/2022 06:45:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/18/2022 06:45:58 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7086554172951232 on epoch=324
06/18/2022 06:46:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/18/2022 06:46:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/18/2022 06:46:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/18/2022 06:46:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/18/2022 06:46:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/18/2022 06:46:12 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7238618082368082 on epoch=337
06/18/2022 06:46:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/18/2022 06:46:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/18/2022 06:46:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/18/2022 06:46:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/18/2022 06:46:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/18/2022 06:46:25 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7086554172951232 on epoch=349
06/18/2022 06:46:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/18/2022 06:46:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/18/2022 06:46:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/18/2022 06:46:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/18/2022 06:46:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/18/2022 06:46:39 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6933243227360875 on epoch=362
06/18/2022 06:46:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/18/2022 06:46:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 06:46:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/18/2022 06:46:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/18/2022 06:46:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/18/2022 06:46:52 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7087847774244833 on epoch=374
06/18/2022 06:46:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/18/2022 06:46:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 06:47:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 06:47:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/18/2022 06:47:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/18/2022 06:47:05 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7241004962779156 on epoch=387
06/18/2022 06:47:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7238618082368082 -> 0.7241004962779156 on epoch=387, global_step=1550
06/18/2022 06:47:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/18/2022 06:47:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 06:47:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/18/2022 06:47:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/18/2022 06:47:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/18/2022 06:47:19 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6937699555346615 on epoch=399
06/18/2022 06:47:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/18/2022 06:47:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 06:47:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/18/2022 06:47:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 06:47:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/18/2022 06:47:33 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6741125541125542 on epoch=412
06/18/2022 06:47:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/18/2022 06:47:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/18/2022 06:47:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/18/2022 06:47:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/18/2022 06:47:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 06:47:46 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7270784770784771 on epoch=424
06/18/2022 06:47:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7241004962779156 -> 0.7270784770784771 on epoch=424, global_step=1700
06/18/2022 06:47:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/18/2022 06:47:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 06:47:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/18/2022 06:47:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/18/2022 06:47:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/18/2022 06:48:00 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6941526610644259 on epoch=437
06/18/2022 06:48:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/18/2022 06:48:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/18/2022 06:48:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/18/2022 06:48:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/18/2022 06:48:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 06:48:13 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7024044795783926 on epoch=449
06/18/2022 06:48:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/18/2022 06:48:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/18/2022 06:48:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/18/2022 06:48:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/18/2022 06:48:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 06:48:27 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7239583333333334 on epoch=462
06/18/2022 06:48:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/18/2022 06:48:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/18/2022 06:48:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
06/18/2022 06:48:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/18/2022 06:48:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/18/2022 06:48:41 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7078847296494356 on epoch=474
06/18/2022 06:48:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/18/2022 06:48:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/18/2022 06:48:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 06:48:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/18/2022 06:48:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 06:48:54 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7100052635536507 on epoch=487
06/18/2022 06:48:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/18/2022 06:48:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/18/2022 06:49:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/18/2022 06:49:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/18/2022 06:49:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/18/2022 06:49:08 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7094509109311741 on epoch=499
06/18/2022 06:49:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/18/2022 06:49:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 06:49:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/18/2022 06:49:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 06:49:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 06:49:22 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7254152097902098 on epoch=512
06/18/2022 06:49:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/18/2022 06:49:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/18/2022 06:49:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 06:49:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 06:49:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 06:49:35 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7135146103896104 on epoch=524
06/18/2022 06:49:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/18/2022 06:49:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 06:49:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 06:49:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/18/2022 06:49:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/18/2022 06:49:49 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6961416630534277 on epoch=537
06/18/2022 06:49:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 06:49:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 06:49:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 06:49:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 06:50:02 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 06:50:03 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.695128367003367 on epoch=549
06/18/2022 06:50:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 06:50:08 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
06/18/2022 06:50:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/18/2022 06:50:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 06:50:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/18/2022 06:50:16 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7096551765669413 on epoch=562
06/18/2022 06:50:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/18/2022 06:50:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 06:50:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/18/2022 06:50:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 06:50:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/18/2022 06:50:30 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6981156098803158 on epoch=574
06/18/2022 06:50:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 06:50:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 06:50:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/18/2022 06:50:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/18/2022 06:50:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/18/2022 06:50:44 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7136292016806723 on epoch=587
06/18/2022 06:50:46 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/18/2022 06:50:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/18/2022 06:50:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/18/2022 06:50:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 06:50:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 06:50:57 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7087477556227556 on epoch=599
06/18/2022 06:51:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 06:51:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 06:51:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 06:51:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 06:51:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 06:51:11 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7312920661995205 on epoch=612
06/18/2022 06:51:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7270784770784771 -> 0.7312920661995205 on epoch=612, global_step=2450
06/18/2022 06:51:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/18/2022 06:51:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 06:51:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 06:51:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/18/2022 06:51:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 06:51:25 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7277066071183719 on epoch=624
06/18/2022 06:51:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 06:51:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 06:51:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 06:51:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 06:51:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 06:51:38 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7275357744107743 on epoch=637
06/18/2022 06:51:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=639
06/18/2022 06:51:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 06:51:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 06:51:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 06:51:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 06:51:52 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7136292016806723 on epoch=649
06/18/2022 06:51:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 06:51:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 06:52:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 06:52:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 06:52:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 06:52:06 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7277066071183719 on epoch=662
06/18/2022 06:52:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 06:52:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 06:52:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/18/2022 06:52:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/18/2022 06:52:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 06:52:19 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7277437363834423 on epoch=674
06/18/2022 06:52:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/18/2022 06:52:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 06:52:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 06:52:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 06:52:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/18/2022 06:52:33 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.651917081328846 on epoch=687
06/18/2022 06:52:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 06:52:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 06:52:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 06:52:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 06:52:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=699
06/18/2022 06:52:47 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6882395382395383 on epoch=699
06/18/2022 06:52:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 06:52:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/18/2022 06:52:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 06:52:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 06:52:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 06:53:00 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7277437363834423 on epoch=712
06/18/2022 06:53:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 06:53:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 06:53:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 06:53:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 06:53:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/18/2022 06:53:14 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7034845946387709 on epoch=724
06/18/2022 06:53:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 06:53:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/18/2022 06:53:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 06:53:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 06:53:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/18/2022 06:53:28 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6989441452856088 on epoch=737
06/18/2022 06:53:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 06:53:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 06:53:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 06:53:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/18/2022 06:53:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 06:53:42 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7295360938187764 on epoch=749
06/18/2022 06:53:42 - INFO - __main__ - save last model!
06/18/2022 06:53:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 06:53:42 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 06:53:42 - INFO - __main__ - Printing 3 examples
06/18/2022 06:53:42 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:53:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:53:42 - INFO - __main__ - Printing 3 examples
06/18/2022 06:53:42 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:53:42 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:53:42 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:53:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:53:42 - INFO - __main__ - Printing 3 examples
06/18/2022 06:53:42 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 06:53:42 - INFO - __main__ - ['others']
06/18/2022 06:53:42 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:53:42 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:53:42 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:53:44 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:53:50 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 06:53:57 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:53:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:53:58 - INFO - __main__ - Starting training!
06/18/2022 06:55:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/18/2022 06:55:23 - INFO - __main__ - Classification-F1 on test data: 0.1801
06/18/2022 06:55:23 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.7312920661995205, test_performance=0.18010580204004317
06/18/2022 06:55:23 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/18/2022 06:55:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:55:24 - INFO - __main__ - Printing 3 examples
06/18/2022 06:55:24 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 06:55:24 - INFO - __main__ - ['others']
06/18/2022 06:55:24 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 06:55:24 - INFO - __main__ - ['others']
06/18/2022 06:55:24 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 06:55:24 - INFO - __main__ - ['others']
06/18/2022 06:55:24 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:55:24 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:55:24 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 06:55:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 06:55:24 - INFO - __main__ - Printing 3 examples
06/18/2022 06:55:24 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 06:55:24 - INFO - __main__ - ['others']
06/18/2022 06:55:24 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 06:55:24 - INFO - __main__ - ['others']
06/18/2022 06:55:24 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 06:55:24 - INFO - __main__ - ['others']
06/18/2022 06:55:24 - INFO - __main__ - Tokenizing Input ...
06/18/2022 06:55:24 - INFO - __main__ - Tokenizing Output ...
06/18/2022 06:55:24 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 06:55:39 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 06:55:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 06:55:40 - INFO - __main__ - Starting training!
06/18/2022 06:55:43 - INFO - __main__ - Step 10 Global step 10 Train loss 4.12 on epoch=2
06/18/2022 06:55:46 - INFO - __main__ - Step 20 Global step 20 Train loss 3.19 on epoch=4
06/18/2022 06:55:48 - INFO - __main__ - Step 30 Global step 30 Train loss 2.54 on epoch=7
06/18/2022 06:55:51 - INFO - __main__ - Step 40 Global step 40 Train loss 2.05 on epoch=9
06/18/2022 06:55:53 - INFO - __main__ - Step 50 Global step 50 Train loss 1.67 on epoch=12
06/18/2022 06:55:54 - INFO - __main__ - Global step 50 Train loss 2.71 Classification-F1 0.1528799019607843 on epoch=12
06/18/2022 06:55:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1528799019607843 on epoch=12, global_step=50
06/18/2022 06:55:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.17 on epoch=14
06/18/2022 06:55:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.04 on epoch=17
06/18/2022 06:56:02 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=19
06/18/2022 06:56:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=22
06/18/2022 06:56:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=24
06/18/2022 06:56:08 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.4063178201109236 on epoch=24
06/18/2022 06:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1528799019607843 -> 0.4063178201109236 on epoch=24, global_step=100
06/18/2022 06:56:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.62 on epoch=27
06/18/2022 06:56:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/18/2022 06:56:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=32
06/18/2022 06:56:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.56 on epoch=34
06/18/2022 06:56:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.57 on epoch=37
06/18/2022 06:56:21 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.5419172113289761 on epoch=37
06/18/2022 06:56:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4063178201109236 -> 0.5419172113289761 on epoch=37, global_step=150
06/18/2022 06:56:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=39
06/18/2022 06:56:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.45 on epoch=42
06/18/2022 06:56:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=44
06/18/2022 06:56:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=47
06/18/2022 06:56:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=49
06/18/2022 06:56:34 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.47504690431519697 on epoch=49
06/18/2022 06:56:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=52
06/18/2022 06:56:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=54
06/18/2022 06:56:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=57
06/18/2022 06:56:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=59
06/18/2022 06:56:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/18/2022 06:56:48 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.5408776493444686 on epoch=62
06/18/2022 06:56:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=64
06/18/2022 06:56:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/18/2022 06:56:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/18/2022 06:56:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=72
06/18/2022 06:57:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=74
06/18/2022 06:57:01 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.6997354497354497 on epoch=74
06/18/2022 06:57:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5419172113289761 -> 0.6997354497354497 on epoch=74, global_step=300
06/18/2022 06:57:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/18/2022 06:57:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=79
06/18/2022 06:57:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=82
06/18/2022 06:57:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=84
06/18/2022 06:57:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=87
06/18/2022 06:57:14 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.6514550264550265 on epoch=87
06/18/2022 06:57:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/18/2022 06:57:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=92
06/18/2022 06:57:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=94
06/18/2022 06:57:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=97
06/18/2022 06:57:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=99
06/18/2022 06:57:27 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.63816261914088 on epoch=99
06/18/2022 06:57:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
06/18/2022 06:57:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=104
06/18/2022 06:57:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=107
06/18/2022 06:57:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/18/2022 06:57:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/18/2022 06:57:40 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.6838845215505558 on epoch=112
06/18/2022 06:57:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=114
06/18/2022 06:57:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/18/2022 06:57:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=119
06/18/2022 06:57:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/18/2022 06:57:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/18/2022 06:57:53 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6459920634920635 on epoch=124
06/18/2022 06:57:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=127
06/18/2022 06:57:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/18/2022 06:58:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/18/2022 06:58:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/18/2022 06:58:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=137
06/18/2022 06:58:07 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.6468817204301076 on epoch=137
06/18/2022 06:58:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/18/2022 06:58:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/18/2022 06:58:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/18/2022 06:58:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/18/2022 06:58:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/18/2022 06:58:20 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.6317533891547049 on epoch=149
06/18/2022 06:58:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
06/18/2022 06:58:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/18/2022 06:58:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/18/2022 06:58:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/18/2022 06:58:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=162
06/18/2022 06:58:33 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6460283773951007 on epoch=162
06/18/2022 06:58:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
06/18/2022 06:58:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/18/2022 06:58:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=169
06/18/2022 06:58:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/18/2022 06:58:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
06/18/2022 06:58:46 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6743506493506494 on epoch=174
06/18/2022 06:58:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/18/2022 06:58:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=179
06/18/2022 06:58:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/18/2022 06:58:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/18/2022 06:58:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/18/2022 06:58:59 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6593137254901961 on epoch=187
06/18/2022 06:59:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/18/2022 06:59:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/18/2022 06:59:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=194
06/18/2022 06:59:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/18/2022 06:59:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/18/2022 06:59:12 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6888061145510835 on epoch=199
06/18/2022 06:59:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/18/2022 06:59:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
06/18/2022 06:59:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/18/2022 06:59:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=209
06/18/2022 06:59:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
06/18/2022 06:59:25 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6888061145510835 on epoch=212
06/18/2022 06:59:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
06/18/2022 06:59:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/18/2022 06:59:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/18/2022 06:59:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
06/18/2022 06:59:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/18/2022 06:59:39 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6739958407605467 on epoch=224
06/18/2022 06:59:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/18/2022 06:59:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=229
06/18/2022 06:59:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=232
06/18/2022 06:59:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/18/2022 06:59:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=237
06/18/2022 06:59:52 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.6741159608806668 on epoch=237
06/18/2022 06:59:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=239
06/18/2022 06:59:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=242
06/18/2022 06:59:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/18/2022 07:00:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/18/2022 07:00:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=249
06/18/2022 07:00:05 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.688794440968354 on epoch=249
06/18/2022 07:00:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/18/2022 07:00:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/18/2022 07:00:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/18/2022 07:00:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/18/2022 07:00:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/18/2022 07:00:18 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7087477556227556 on epoch=262
06/18/2022 07:00:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6997354497354497 -> 0.7087477556227556 on epoch=262, global_step=1050
06/18/2022 07:00:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/18/2022 07:00:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=267
06/18/2022 07:00:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=269
06/18/2022 07:00:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
06/18/2022 07:00:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/18/2022 07:00:32 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7034845946387709 on epoch=274
06/18/2022 07:00:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/18/2022 07:00:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/18/2022 07:00:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/18/2022 07:00:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/18/2022 07:00:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/18/2022 07:00:45 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7091537081339713 on epoch=287
06/18/2022 07:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7087477556227556 -> 0.7091537081339713 on epoch=287, global_step=1150
06/18/2022 07:00:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/18/2022 07:00:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/18/2022 07:00:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/18/2022 07:00:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/18/2022 07:00:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/18/2022 07:00:58 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.693958818958819 on epoch=299
06/18/2022 07:01:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/18/2022 07:01:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/18/2022 07:01:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/18/2022 07:01:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/18/2022 07:01:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/18/2022 07:01:11 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6367301993261073 on epoch=312
06/18/2022 07:01:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/18/2022 07:01:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/18/2022 07:01:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/18/2022 07:01:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/18/2022 07:01:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/18/2022 07:01:25 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7234906597774244 on epoch=324
06/18/2022 07:01:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7091537081339713 -> 0.7234906597774244 on epoch=324, global_step=1300
06/18/2022 07:01:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/18/2022 07:01:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/18/2022 07:01:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/18/2022 07:01:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/18/2022 07:01:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/18/2022 07:01:38 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7087477556227556 on epoch=337
06/18/2022 07:01:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=339
06/18/2022 07:01:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/18/2022 07:01:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/18/2022 07:01:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/18/2022 07:01:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/18/2022 07:01:51 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6786554621848739 on epoch=349
06/18/2022 07:01:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/18/2022 07:01:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/18/2022 07:01:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/18/2022 07:02:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/18/2022 07:02:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/18/2022 07:02:05 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6971677559912854 on epoch=362
06/18/2022 07:02:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/18/2022 07:02:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 07:02:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/18/2022 07:02:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/18/2022 07:02:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/18/2022 07:02:18 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7382223109957056 on epoch=374
06/18/2022 07:02:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7234906597774244 -> 0.7382223109957056 on epoch=374, global_step=1500
06/18/2022 07:02:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/18/2022 07:02:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 07:02:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 07:02:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/18/2022 07:02:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/18/2022 07:02:31 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7096551765669413 on epoch=387
06/18/2022 07:02:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/18/2022 07:02:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/18/2022 07:02:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/18/2022 07:02:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/18/2022 07:02:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/18/2022 07:02:44 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6882395382395383 on epoch=399
06/18/2022 07:02:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 07:02:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/18/2022 07:02:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 07:02:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 07:02:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/18/2022 07:02:58 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7234906597774244 on epoch=412
06/18/2022 07:03:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 07:03:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/18/2022 07:03:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/18/2022 07:03:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/18/2022 07:03:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 07:03:11 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7044221640995835 on epoch=424
06/18/2022 07:03:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/18/2022 07:03:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 07:03:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 07:03:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/18/2022 07:03:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/18/2022 07:03:24 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7426854395604396 on epoch=437
06/18/2022 07:03:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7382223109957056 -> 0.7426854395604396 on epoch=437, global_step=1750
06/18/2022 07:03:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/18/2022 07:03:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/18/2022 07:03:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/18/2022 07:03:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/18/2022 07:03:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 07:03:37 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7277066071183719 on epoch=449
06/18/2022 07:03:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/18/2022 07:03:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/18/2022 07:03:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/18/2022 07:03:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/18/2022 07:03:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 07:03:50 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7119269619269619 on epoch=462
06/18/2022 07:03:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 07:03:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 07:03:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=469
06/18/2022 07:04:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/18/2022 07:04:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 07:04:04 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7436823033597227 on epoch=474
06/18/2022 07:04:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7426854395604396 -> 0.7436823033597227 on epoch=474, global_step=1900
06/18/2022 07:04:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/18/2022 07:04:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/18/2022 07:04:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/18/2022 07:04:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 07:04:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 07:04:17 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.688794440968354 on epoch=487
06/18/2022 07:04:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/18/2022 07:04:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/18/2022 07:04:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/18/2022 07:04:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/18/2022 07:04:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/18/2022 07:04:30 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6879084967320261 on epoch=499
06/18/2022 07:04:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 07:04:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/18/2022 07:04:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/18/2022 07:04:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 07:04:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 07:04:44 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7425920688788336 on epoch=512
06/18/2022 07:04:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/18/2022 07:04:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/18/2022 07:04:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/18/2022 07:04:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/18/2022 07:04:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/18/2022 07:04:57 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7130007247654306 on epoch=524
06/18/2022 07:04:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/18/2022 07:05:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/18/2022 07:05:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/18/2022 07:05:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 07:05:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 07:05:10 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7609681372549019 on epoch=537
06/18/2022 07:05:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7436823033597227 -> 0.7609681372549019 on epoch=537, global_step=2150
06/18/2022 07:05:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=539
06/18/2022 07:05:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/18/2022 07:05:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/18/2022 07:05:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 07:05:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=549
06/18/2022 07:05:24 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7426854395604396 on epoch=549
06/18/2022 07:05:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 07:05:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/18/2022 07:05:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 07:05:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 07:05:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/18/2022 07:05:37 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7246774193548388 on epoch=562
06/18/2022 07:05:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/18/2022 07:05:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 07:05:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/18/2022 07:05:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=572
06/18/2022 07:05:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 07:05:51 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6879084967320261 on epoch=574
06/18/2022 07:05:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 07:05:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/18/2022 07:05:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/18/2022 07:06:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/18/2022 07:06:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/18/2022 07:06:04 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7234906597774244 on epoch=587
06/18/2022 07:06:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/18/2022 07:06:09 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 07:06:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/18/2022 07:06:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 07:06:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 07:06:18 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6892361111111112 on epoch=599
06/18/2022 07:06:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 07:06:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 07:06:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/18/2022 07:06:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 07:06:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 07:06:31 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7044221640995835 on epoch=612
06/18/2022 07:06:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 07:06:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=617
06/18/2022 07:06:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/18/2022 07:06:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/18/2022 07:06:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/18/2022 07:06:45 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.744973544973545 on epoch=624
06/18/2022 07:06:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 07:06:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 07:06:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 07:06:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/18/2022 07:06:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 07:06:58 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7436823033597227 on epoch=637
06/18/2022 07:07:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/18/2022 07:07:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/18/2022 07:07:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 07:07:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 07:07:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 07:07:12 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7426854395604396 on epoch=649
06/18/2022 07:07:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=652
06/18/2022 07:07:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/18/2022 07:07:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=657
06/18/2022 07:07:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 07:07:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/18/2022 07:07:25 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.703125 on epoch=662
06/18/2022 07:07:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 07:07:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/18/2022 07:07:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 07:07:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 07:07:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/18/2022 07:07:39 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7234076054664291 on epoch=674
06/18/2022 07:07:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/18/2022 07:07:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=679
06/18/2022 07:07:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 07:07:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/18/2022 07:07:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 07:07:52 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7025252525252526 on epoch=687
06/18/2022 07:07:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.15 on epoch=689
06/18/2022 07:07:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/18/2022 07:08:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 07:08:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/18/2022 07:08:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=699
06/18/2022 07:08:06 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7087017231134879 on epoch=699
06/18/2022 07:08:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 07:08:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 07:08:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 07:08:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 07:08:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 07:08:19 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7277066071183719 on epoch=712
06/18/2022 07:08:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/18/2022 07:08:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 07:08:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 07:08:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/18/2022 07:08:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/18/2022 07:08:33 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6972248576850095 on epoch=724
06/18/2022 07:08:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 07:08:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=729
06/18/2022 07:08:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 07:08:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 07:08:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/18/2022 07:08:46 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7425920688788336 on epoch=737
06/18/2022 07:08:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 07:08:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 07:08:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 07:08:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 07:08:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/18/2022 07:09:00 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6882395382395383 on epoch=749
06/18/2022 07:09:00 - INFO - __main__ - save last model!
06/18/2022 07:09:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 07:09:00 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 07:09:00 - INFO - __main__ - Printing 3 examples
06/18/2022 07:09:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:09:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:09:00 - INFO - __main__ - Printing 3 examples
06/18/2022 07:09:00 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:09:00 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:09:00 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:09:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:09:00 - INFO - __main__ - Printing 3 examples
06/18/2022 07:09:00 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 07:09:00 - INFO - __main__ - ['others']
06/18/2022 07:09:00 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:09:00 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:09:00 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:09:02 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:09:07 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 07:09:15 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:09:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:09:16 - INFO - __main__ - Starting training!
06/18/2022 07:10:35 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/18/2022 07:10:35 - INFO - __main__ - Classification-F1 on test data: 0.1989
06/18/2022 07:10:35 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.7609681372549019, test_performance=0.19890556375037938
06/18/2022 07:10:35 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/18/2022 07:10:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:10:36 - INFO - __main__ - Printing 3 examples
06/18/2022 07:10:36 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/18/2022 07:10:36 - INFO - __main__ - ['others']
06/18/2022 07:10:36 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/18/2022 07:10:36 - INFO - __main__ - ['others']
06/18/2022 07:10:36 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/18/2022 07:10:36 - INFO - __main__ - ['others']
06/18/2022 07:10:36 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:10:36 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:10:36 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:10:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:10:36 - INFO - __main__ - Printing 3 examples
06/18/2022 07:10:36 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/18/2022 07:10:36 - INFO - __main__ - ['others']
06/18/2022 07:10:36 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/18/2022 07:10:36 - INFO - __main__ - ['others']
06/18/2022 07:10:36 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/18/2022 07:10:36 - INFO - __main__ - ['others']
06/18/2022 07:10:36 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:10:36 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:10:36 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:10:51 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:10:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:10:52 - INFO - __main__ - Starting training!
06/18/2022 07:10:55 - INFO - __main__ - Step 10 Global step 10 Train loss 4.17 on epoch=2
06/18/2022 07:10:58 - INFO - __main__ - Step 20 Global step 20 Train loss 3.58 on epoch=4
06/18/2022 07:11:00 - INFO - __main__ - Step 30 Global step 30 Train loss 3.06 on epoch=7
06/18/2022 07:11:02 - INFO - __main__ - Step 40 Global step 40 Train loss 2.53 on epoch=9
06/18/2022 07:11:05 - INFO - __main__ - Step 50 Global step 50 Train loss 2.19 on epoch=12
06/18/2022 07:11:06 - INFO - __main__ - Global step 50 Train loss 3.11 Classification-F1 0.0385667463466325 on epoch=12
06/18/2022 07:11:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0385667463466325 on epoch=12, global_step=50
06/18/2022 07:11:09 - INFO - __main__ - Step 60 Global step 60 Train loss 1.95 on epoch=14
06/18/2022 07:11:11 - INFO - __main__ - Step 70 Global step 70 Train loss 1.64 on epoch=17
06/18/2022 07:11:14 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=19
06/18/2022 07:11:16 - INFO - __main__ - Step 90 Global step 90 Train loss 1.33 on epoch=22
06/18/2022 07:11:19 - INFO - __main__ - Step 100 Global step 100 Train loss 1.08 on epoch=24
06/18/2022 07:11:20 - INFO - __main__ - Global step 100 Train loss 1.48 Classification-F1 0.23031417112299468 on epoch=24
06/18/2022 07:11:20 - INFO - __main__ - Saving model with best Classification-F1: 0.0385667463466325 -> 0.23031417112299468 on epoch=24, global_step=100
06/18/2022 07:11:22 - INFO - __main__ - Step 110 Global step 110 Train loss 1.04 on epoch=27
06/18/2022 07:11:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=29
06/18/2022 07:11:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=32
06/18/2022 07:11:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=34
06/18/2022 07:11:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
06/18/2022 07:11:33 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.3883717965064389 on epoch=37
06/18/2022 07:11:33 - INFO - __main__ - Saving model with best Classification-F1: 0.23031417112299468 -> 0.3883717965064389 on epoch=37, global_step=150
06/18/2022 07:11:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=39
06/18/2022 07:11:38 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=42
06/18/2022 07:11:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
06/18/2022 07:11:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=47
06/18/2022 07:11:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=49
06/18/2022 07:11:47 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.49658902691511386 on epoch=49
06/18/2022 07:11:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3883717965064389 -> 0.49658902691511386 on epoch=49, global_step=200
06/18/2022 07:11:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=52
06/18/2022 07:11:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=54
06/18/2022 07:11:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=57
06/18/2022 07:11:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=59
06/18/2022 07:11:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/18/2022 07:12:00 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.5427741935483871 on epoch=62
06/18/2022 07:12:00 - INFO - __main__ - Saving model with best Classification-F1: 0.49658902691511386 -> 0.5427741935483871 on epoch=62, global_step=250
06/18/2022 07:12:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=64
06/18/2022 07:12:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
06/18/2022 07:12:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=69
06/18/2022 07:12:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=72
06/18/2022 07:12:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=74
06/18/2022 07:12:13 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.4946520146520147 on epoch=74
06/18/2022 07:12:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
06/18/2022 07:12:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=79
06/18/2022 07:12:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=82
06/18/2022 07:12:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=84
06/18/2022 07:12:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
06/18/2022 07:12:26 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.4838512404029645 on epoch=87
06/18/2022 07:12:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=89
06/18/2022 07:12:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=92
06/18/2022 07:12:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/18/2022 07:12:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=97
06/18/2022 07:12:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=99
06/18/2022 07:12:39 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.6745413892153023 on epoch=99
06/18/2022 07:12:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5427741935483871 -> 0.6745413892153023 on epoch=99, global_step=400
06/18/2022 07:12:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=102
06/18/2022 07:12:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=104
06/18/2022 07:12:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
06/18/2022 07:12:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=109
06/18/2022 07:12:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=112
06/18/2022 07:12:53 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.693951093951094 on epoch=112
06/18/2022 07:12:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6745413892153023 -> 0.693951093951094 on epoch=112, global_step=450
06/18/2022 07:12:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=114
06/18/2022 07:12:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
06/18/2022 07:13:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/18/2022 07:13:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=122
06/18/2022 07:13:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=124
06/18/2022 07:13:06 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.6381396445063677 on epoch=124
06/18/2022 07:13:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=127
06/18/2022 07:13:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=129
06/18/2022 07:13:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/18/2022 07:13:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=134
06/18/2022 07:13:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/18/2022 07:13:19 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.6449538388700387 on epoch=137
06/18/2022 07:13:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=139
06/18/2022 07:13:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=142
06/18/2022 07:13:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=144
06/18/2022 07:13:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/18/2022 07:13:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=149
06/18/2022 07:13:32 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.6745413892153023 on epoch=149
06/18/2022 07:13:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=152
06/18/2022 07:13:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=154
06/18/2022 07:13:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=157
06/18/2022 07:13:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=159
06/18/2022 07:13:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=162
06/18/2022 07:13:46 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.6753345210568211 on epoch=162
06/18/2022 07:13:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/18/2022 07:13:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
06/18/2022 07:13:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/18/2022 07:13:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=172
06/18/2022 07:13:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/18/2022 07:13:59 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6944444444444444 on epoch=174
06/18/2022 07:13:59 - INFO - __main__ - Saving model with best Classification-F1: 0.693951093951094 -> 0.6944444444444444 on epoch=174, global_step=700
06/18/2022 07:14:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=177
06/18/2022 07:14:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=179
06/18/2022 07:14:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/18/2022 07:14:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=184
06/18/2022 07:14:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/18/2022 07:14:13 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6753345210568211 on epoch=187
06/18/2022 07:14:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=189
06/18/2022 07:14:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/18/2022 07:14:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=194
06/18/2022 07:14:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/18/2022 07:14:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/18/2022 07:14:26 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6460283773951007 on epoch=199
06/18/2022 07:14:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/18/2022 07:14:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/18/2022 07:14:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=207
06/18/2022 07:14:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
06/18/2022 07:14:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=212
06/18/2022 07:14:39 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.6603764478764479 on epoch=212
06/18/2022 07:14:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/18/2022 07:14:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=217
06/18/2022 07:14:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/18/2022 07:14:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
06/18/2022 07:14:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/18/2022 07:14:52 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6798809523809524 on epoch=224
06/18/2022 07:14:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/18/2022 07:14:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/18/2022 07:14:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/18/2022 07:15:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/18/2022 07:15:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/18/2022 07:15:05 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.6798809523809524 on epoch=237
06/18/2022 07:15:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=239
06/18/2022 07:15:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=242
06/18/2022 07:15:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/18/2022 07:15:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=247
06/18/2022 07:15:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=249
06/18/2022 07:15:18 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6783424908424908 on epoch=249
06/18/2022 07:15:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/18/2022 07:15:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/18/2022 07:15:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=257
06/18/2022 07:15:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/18/2022 07:15:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=262
06/18/2022 07:15:32 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6798809523809524 on epoch=262
06/18/2022 07:15:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/18/2022 07:15:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=267
06/18/2022 07:15:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=269
06/18/2022 07:15:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=272
06/18/2022 07:15:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/18/2022 07:15:45 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.652487714987715 on epoch=274
06/18/2022 07:15:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/18/2022 07:15:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=279
06/18/2022 07:15:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/18/2022 07:15:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=284
06/18/2022 07:15:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=287
06/18/2022 07:15:58 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6745413892153023 on epoch=287
06/18/2022 07:16:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=289
06/18/2022 07:16:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
06/18/2022 07:16:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/18/2022 07:16:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/18/2022 07:16:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=299
06/18/2022 07:16:11 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.6603764478764479 on epoch=299
06/18/2022 07:16:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=302
06/18/2022 07:16:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/18/2022 07:16:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/18/2022 07:16:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/18/2022 07:16:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/18/2022 07:16:24 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6941125541125542 on epoch=312
06/18/2022 07:16:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=314
06/18/2022 07:16:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/18/2022 07:16:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/18/2022 07:16:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/18/2022 07:16:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=324
06/18/2022 07:16:38 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6885155906895036 on epoch=324
06/18/2022 07:16:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=327
06/18/2022 07:16:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/18/2022 07:16:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=332
06/18/2022 07:16:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/18/2022 07:16:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=337
06/18/2022 07:16:51 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7086760461760462 on epoch=337
06/18/2022 07:16:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6944444444444444 -> 0.7086760461760462 on epoch=337, global_step=1350
06/18/2022 07:16:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/18/2022 07:16:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/18/2022 07:16:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=344
06/18/2022 07:17:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/18/2022 07:17:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/18/2022 07:17:04 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6745413892153023 on epoch=349
06/18/2022 07:17:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/18/2022 07:17:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/18/2022 07:17:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
06/18/2022 07:17:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/18/2022 07:17:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/18/2022 07:17:17 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7283982683982685 on epoch=362
06/18/2022 07:17:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7086760461760462 -> 0.7283982683982685 on epoch=362, global_step=1450
06/18/2022 07:17:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=364
06/18/2022 07:17:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/18/2022 07:17:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/18/2022 07:17:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/18/2022 07:17:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/18/2022 07:17:30 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7086760461760462 on epoch=374
06/18/2022 07:17:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/18/2022 07:17:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/18/2022 07:17:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/18/2022 07:17:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/18/2022 07:17:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/18/2022 07:17:43 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6745413892153023 on epoch=387
06/18/2022 07:17:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/18/2022 07:17:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/18/2022 07:17:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/18/2022 07:17:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/18/2022 07:17:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/18/2022 07:17:57 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6856643356643357 on epoch=399
06/18/2022 07:17:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/18/2022 07:18:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/18/2022 07:18:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/18/2022 07:18:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/18/2022 07:18:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/18/2022 07:18:10 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7086760461760462 on epoch=412
06/18/2022 07:18:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/18/2022 07:18:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/18/2022 07:18:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/18/2022 07:18:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/18/2022 07:18:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/18/2022 07:18:23 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6745413892153023 on epoch=424
06/18/2022 07:18:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/18/2022 07:18:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/18/2022 07:18:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 07:18:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/18/2022 07:18:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/18/2022 07:18:36 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6601933187339549 on epoch=437
06/18/2022 07:18:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/18/2022 07:18:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/18/2022 07:18:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/18/2022 07:18:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/18/2022 07:18:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/18/2022 07:18:50 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7134208928326575 on epoch=449
06/18/2022 07:18:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/18/2022 07:18:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/18/2022 07:18:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/18/2022 07:18:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/18/2022 07:19:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=462
06/18/2022 07:19:03 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6994085893466699 on epoch=462
06/18/2022 07:19:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 07:19:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 07:19:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/18/2022 07:19:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=472
06/18/2022 07:19:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/18/2022 07:19:16 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7086760461760462 on epoch=474
06/18/2022 07:19:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
06/18/2022 07:19:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/18/2022 07:19:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 07:19:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 07:19:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 07:19:29 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7281639044506691 on epoch=487
06/18/2022 07:19:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 07:19:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/18/2022 07:19:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 07:19:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/18/2022 07:19:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/18/2022 07:19:43 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7232837301587302 on epoch=499
06/18/2022 07:19:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 07:19:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/18/2022 07:19:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/18/2022 07:19:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=509
06/18/2022 07:19:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 07:19:56 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6888480345703346 on epoch=512
06/18/2022 07:19:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 07:20:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/18/2022 07:20:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
06/18/2022 07:20:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/18/2022 07:20:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/18/2022 07:20:10 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7426854395604396 on epoch=524
06/18/2022 07:20:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7283982683982685 -> 0.7426854395604396 on epoch=524, global_step=2100
06/18/2022 07:20:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=527
06/18/2022 07:20:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/18/2022 07:20:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/18/2022 07:20:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/18/2022 07:20:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 07:20:23 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7426854395604396 on epoch=537
06/18/2022 07:20:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/18/2022 07:20:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/18/2022 07:20:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/18/2022 07:20:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 07:20:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/18/2022 07:20:37 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7232837301587302 on epoch=549
06/18/2022 07:20:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/18/2022 07:20:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/18/2022 07:20:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 07:20:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 07:20:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/18/2022 07:20:50 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7239583333333334 on epoch=562
06/18/2022 07:20:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/18/2022 07:20:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/18/2022 07:20:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/18/2022 07:21:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/18/2022 07:21:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/18/2022 07:21:03 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7033045273534404 on epoch=574
06/18/2022 07:21:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/18/2022 07:21:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=579
06/18/2022 07:21:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/18/2022 07:21:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/18/2022 07:21:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 07:21:17 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7426854395604396 on epoch=587
06/18/2022 07:21:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=589
06/18/2022 07:21:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/18/2022 07:21:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/18/2022 07:21:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/18/2022 07:21:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/18/2022 07:21:30 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7033045273534404 on epoch=599
06/18/2022 07:21:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/18/2022 07:21:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/18/2022 07:21:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=607
06/18/2022 07:21:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 07:21:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/18/2022 07:21:43 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6894802457288617 on epoch=612
06/18/2022 07:21:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/18/2022 07:21:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/18/2022 07:21:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=619
06/18/2022 07:21:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=622
06/18/2022 07:21:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=624
06/18/2022 07:21:56 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7036799027288156 on epoch=624
06/18/2022 07:21:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/18/2022 07:22:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/18/2022 07:22:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 07:22:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/18/2022 07:22:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 07:22:10 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7043664065403195 on epoch=637
06/18/2022 07:22:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=639
06/18/2022 07:22:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=642
06/18/2022 07:22:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/18/2022 07:22:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 07:22:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/18/2022 07:22:23 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7391443863218057 on epoch=649
06/18/2022 07:22:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/18/2022 07:22:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 07:22:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/18/2022 07:22:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/18/2022 07:22:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/18/2022 07:22:36 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7239583333333334 on epoch=662
06/18/2022 07:22:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/18/2022 07:22:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/18/2022 07:22:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/18/2022 07:22:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/18/2022 07:22:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/18/2022 07:22:50 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7442105263157894 on epoch=674
06/18/2022 07:22:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7426854395604396 -> 0.7442105263157894 on epoch=674, global_step=2700
06/18/2022 07:22:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/18/2022 07:22:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/18/2022 07:22:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/18/2022 07:23:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 07:23:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/18/2022 07:23:03 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7442105263157894 on epoch=687
06/18/2022 07:23:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 07:23:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
06/18/2022 07:23:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/18/2022 07:23:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=697
06/18/2022 07:23:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/18/2022 07:23:17 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7588666085440279 on epoch=699
06/18/2022 07:23:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7442105263157894 -> 0.7588666085440279 on epoch=699, global_step=2800
06/18/2022 07:23:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/18/2022 07:23:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/18/2022 07:23:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/18/2022 07:23:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/18/2022 07:23:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/18/2022 07:23:30 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7618058464832659 on epoch=712
06/18/2022 07:23:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7588666085440279 -> 0.7618058464832659 on epoch=712, global_step=2850
06/18/2022 07:23:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 07:23:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/18/2022 07:23:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/18/2022 07:23:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/18/2022 07:23:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/18/2022 07:23:43 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7618058464832659 on epoch=724
06/18/2022 07:23:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 07:23:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/18/2022 07:23:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/18/2022 07:23:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 07:23:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.12 on epoch=737
06/18/2022 07:23:57 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.757968017645437 on epoch=737
06/18/2022 07:23:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 07:24:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/18/2022 07:24:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/18/2022 07:24:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 07:24:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=749
06/18/2022 07:24:10 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7618058464832659 on epoch=749
06/18/2022 07:24:10 - INFO - __main__ - save last model!
06/18/2022 07:24:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 07:24:10 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 07:24:10 - INFO - __main__ - Printing 3 examples
06/18/2022 07:24:10 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 07:24:10 - INFO - __main__ - ['others']
06/18/2022 07:24:10 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 07:24:10 - INFO - __main__ - ['others']
06/18/2022 07:24:10 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 07:24:10 - INFO - __main__ - ['others']
06/18/2022 07:24:10 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:24:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:24:11 - INFO - __main__ - Printing 3 examples
06/18/2022 07:24:11 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 07:24:11 - INFO - __main__ - ['sad']
06/18/2022 07:24:11 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 07:24:11 - INFO - __main__ - ['sad']
06/18/2022 07:24:11 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 07:24:11 - INFO - __main__ - ['sad']
06/18/2022 07:24:11 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:24:11 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:24:11 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:24:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:24:11 - INFO - __main__ - Printing 3 examples
06/18/2022 07:24:11 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 07:24:11 - INFO - __main__ - ['sad']
06/18/2022 07:24:11 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 07:24:11 - INFO - __main__ - ['sad']
06/18/2022 07:24:11 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 07:24:11 - INFO - __main__ - ['sad']
06/18/2022 07:24:11 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:24:11 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:24:11 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:24:12 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:24:18 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 07:24:30 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:24:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:24:30 - INFO - __main__ - Starting training!
06/18/2022 07:25:39 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/18/2022 07:25:39 - INFO - __main__ - Classification-F1 on test data: 0.1415
06/18/2022 07:25:39 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.7618058464832659, test_performance=0.14149451258735582
06/18/2022 07:25:39 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/18/2022 07:25:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:25:40 - INFO - __main__ - Printing 3 examples
06/18/2022 07:25:40 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 07:25:40 - INFO - __main__ - ['sad']
06/18/2022 07:25:40 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 07:25:40 - INFO - __main__ - ['sad']
06/18/2022 07:25:40 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 07:25:40 - INFO - __main__ - ['sad']
06/18/2022 07:25:40 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:25:40 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:25:41 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:25:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:25:41 - INFO - __main__ - Printing 3 examples
06/18/2022 07:25:41 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 07:25:41 - INFO - __main__ - ['sad']
06/18/2022 07:25:41 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 07:25:41 - INFO - __main__ - ['sad']
06/18/2022 07:25:41 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 07:25:41 - INFO - __main__ - ['sad']
06/18/2022 07:25:41 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:25:41 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:25:41 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:25:56 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:25:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:25:56 - INFO - __main__ - Starting training!
06/18/2022 07:25:59 - INFO - __main__ - Step 10 Global step 10 Train loss 4.12 on epoch=2
06/18/2022 07:26:02 - INFO - __main__ - Step 20 Global step 20 Train loss 3.05 on epoch=4
06/18/2022 07:26:04 - INFO - __main__ - Step 30 Global step 30 Train loss 2.09 on epoch=7
06/18/2022 07:26:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.49 on epoch=9
06/18/2022 07:26:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.11 on epoch=12
06/18/2022 07:26:10 - INFO - __main__ - Global step 50 Train loss 2.37 Classification-F1 0.3832894736842105 on epoch=12
06/18/2022 07:26:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3832894736842105 on epoch=12, global_step=50
06/18/2022 07:26:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/18/2022 07:26:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.70 on epoch=17
06/18/2022 07:26:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.63 on epoch=19
06/18/2022 07:26:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.59 on epoch=22
06/18/2022 07:26:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.47 on epoch=24
06/18/2022 07:26:22 - INFO - __main__ - Global step 100 Train loss 0.65 Classification-F1 0.5640350877192982 on epoch=24
06/18/2022 07:26:22 - INFO - __main__ - Saving model with best Classification-F1: 0.3832894736842105 -> 0.5640350877192982 on epoch=24, global_step=100
06/18/2022 07:26:25 - INFO - __main__ - Step 110 Global step 110 Train loss 0.53 on epoch=27
06/18/2022 07:26:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=29
06/18/2022 07:26:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.54 on epoch=32
06/18/2022 07:26:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.44 on epoch=34
06/18/2022 07:26:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.49 on epoch=37
06/18/2022 07:26:35 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.5773310023310022 on epoch=37
06/18/2022 07:26:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5640350877192982 -> 0.5773310023310022 on epoch=37, global_step=150
06/18/2022 07:26:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=39
06/18/2022 07:26:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=42
06/18/2022 07:26:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.36 on epoch=44
06/18/2022 07:26:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.29 on epoch=47
06/18/2022 07:26:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=49
06/18/2022 07:26:48 - INFO - __main__ - Global step 200 Train loss 0.37 Classification-F1 0.6374458874458874 on epoch=49
06/18/2022 07:26:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5773310023310022 -> 0.6374458874458874 on epoch=49, global_step=200
06/18/2022 07:26:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=52
06/18/2022 07:26:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=54
06/18/2022 07:26:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=57
06/18/2022 07:26:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=59
06/18/2022 07:27:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.30 on epoch=62
06/18/2022 07:27:00 - INFO - __main__ - Global step 250 Train loss 0.34 Classification-F1 0.6530872636135794 on epoch=62
06/18/2022 07:27:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6374458874458874 -> 0.6530872636135794 on epoch=62, global_step=250
06/18/2022 07:27:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=64
06/18/2022 07:27:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/18/2022 07:27:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/18/2022 07:27:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=72
06/18/2022 07:27:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/18/2022 07:27:13 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.6791125541125541 on epoch=74
06/18/2022 07:27:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6530872636135794 -> 0.6791125541125541 on epoch=74, global_step=300
06/18/2022 07:27:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/18/2022 07:27:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.16 on epoch=79
06/18/2022 07:27:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=82
06/18/2022 07:27:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/18/2022 07:27:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=87
06/18/2022 07:27:26 - INFO - __main__ - Global step 350 Train loss 0.18 Classification-F1 0.6544806618819776 on epoch=87
06/18/2022 07:27:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.14 on epoch=89
06/18/2022 07:27:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=92
06/18/2022 07:27:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/18/2022 07:27:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=97
06/18/2022 07:27:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=99
06/18/2022 07:27:38 - INFO - __main__ - Global step 400 Train loss 0.14 Classification-F1 0.6680999180999181 on epoch=99
06/18/2022 07:27:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=102
06/18/2022 07:27:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/18/2022 07:27:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=107
06/18/2022 07:27:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=109
06/18/2022 07:27:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=112
06/18/2022 07:27:51 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.6680999180999181 on epoch=112
06/18/2022 07:27:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=114
06/18/2022 07:27:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=117
06/18/2022 07:27:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=119
06/18/2022 07:28:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=122
06/18/2022 07:28:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
06/18/2022 07:28:04 - INFO - __main__ - Global step 500 Train loss 0.10 Classification-F1 0.6680999180999181 on epoch=124
06/18/2022 07:28:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/18/2022 07:28:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=129
06/18/2022 07:28:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.06 on epoch=132
06/18/2022 07:28:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/18/2022 07:28:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=137
06/18/2022 07:28:16 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.6544806618819776 on epoch=137
06/18/2022 07:28:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=139
06/18/2022 07:28:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/18/2022 07:28:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=144
06/18/2022 07:28:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/18/2022 07:28:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/18/2022 07:28:29 - INFO - __main__ - Global step 600 Train loss 0.06 Classification-F1 0.6741159608806668 on epoch=149
06/18/2022 07:28:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=152
06/18/2022 07:28:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=154
06/18/2022 07:28:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=157
06/18/2022 07:28:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=159
06/18/2022 07:28:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/18/2022 07:28:42 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.6543018551814319 on epoch=162
06/18/2022 07:28:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/18/2022 07:28:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/18/2022 07:28:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/18/2022 07:28:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/18/2022 07:28:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/18/2022 07:28:55 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.6543018551814319 on epoch=174
06/18/2022 07:28:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/18/2022 07:28:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/18/2022 07:29:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/18/2022 07:29:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/18/2022 07:29:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/18/2022 07:29:07 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.6252574002574003 on epoch=187
06/18/2022 07:29:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/18/2022 07:29:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
06/18/2022 07:29:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=194
06/18/2022 07:29:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/18/2022 07:29:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=199
06/18/2022 07:29:20 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.6526383526383527 on epoch=199
06/18/2022 07:29:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/18/2022 07:29:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/18/2022 07:29:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/18/2022 07:29:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
06/18/2022 07:29:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=212
06/18/2022 07:29:33 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6392560827343435 on epoch=212
06/18/2022 07:29:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/18/2022 07:29:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/18/2022 07:29:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/18/2022 07:29:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/18/2022 07:29:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/18/2022 07:29:46 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6736652236652236 on epoch=224
06/18/2022 07:29:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/18/2022 07:29:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/18/2022 07:29:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/18/2022 07:29:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/18/2022 07:29:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/18/2022 07:29:58 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.6744123736451102 on epoch=237
06/18/2022 07:30:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/18/2022 07:30:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/18/2022 07:30:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/18/2022 07:30:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/18/2022 07:30:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/18/2022 07:30:11 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.6753472222222222 on epoch=249
06/18/2022 07:30:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/18/2022 07:30:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/18/2022 07:30:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/18/2022 07:30:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/18/2022 07:30:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/18/2022 07:30:24 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6682387787650945 on epoch=262
06/18/2022 07:30:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/18/2022 07:30:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/18/2022 07:30:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/18/2022 07:30:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/18/2022 07:30:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/18/2022 07:30:37 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6896602418341549 on epoch=274
06/18/2022 07:30:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6791125541125541 -> 0.6896602418341549 on epoch=274, global_step=1100
06/18/2022 07:30:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/18/2022 07:30:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/18/2022 07:30:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/18/2022 07:30:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/18/2022 07:30:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/18/2022 07:30:50 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.668112714987715 on epoch=287
06/18/2022 07:30:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/18/2022 07:30:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/18/2022 07:30:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/18/2022 07:30:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/18/2022 07:31:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/18/2022 07:31:02 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.6667409387997624 on epoch=299
06/18/2022 07:31:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/18/2022 07:31:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/18/2022 07:31:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/18/2022 07:31:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/18/2022 07:31:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/18/2022 07:31:15 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6670553105335715 on epoch=312
06/18/2022 07:31:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/18/2022 07:31:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/18/2022 07:31:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/18/2022 07:31:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/18/2022 07:31:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/18/2022 07:31:28 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6809086779675015 on epoch=324
06/18/2022 07:31:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/18/2022 07:31:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/18/2022 07:31:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/18/2022 07:31:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/18/2022 07:31:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/18/2022 07:31:41 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6535953906220386 on epoch=337
06/18/2022 07:31:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/18/2022 07:31:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=342
06/18/2022 07:31:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/18/2022 07:31:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=347
06/18/2022 07:31:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/18/2022 07:31:54 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6593137254901961 on epoch=349
06/18/2022 07:31:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/18/2022 07:31:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/18/2022 07:32:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/18/2022 07:32:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/18/2022 07:32:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/18/2022 07:32:07 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6379673608573864 on epoch=362
06/18/2022 07:32:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/18/2022 07:32:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/18/2022 07:32:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/18/2022 07:32:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/18/2022 07:32:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/18/2022 07:32:20 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6517316017316017 on epoch=374
06/18/2022 07:32:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/18/2022 07:32:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 07:32:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/18/2022 07:32:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/18/2022 07:32:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/18/2022 07:32:32 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7035119969040248 on epoch=387
06/18/2022 07:32:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6896602418341549 -> 0.7035119969040248 on epoch=387, global_step=1550
06/18/2022 07:32:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/18/2022 07:32:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 07:32:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/18/2022 07:32:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/18/2022 07:32:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/18/2022 07:32:45 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.681988806988807 on epoch=399
06/18/2022 07:32:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 07:32:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 07:32:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/18/2022 07:32:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/18/2022 07:32:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/18/2022 07:32:58 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6895149613899614 on epoch=412
06/18/2022 07:33:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/18/2022 07:33:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=417
06/18/2022 07:33:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/18/2022 07:33:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/18/2022 07:33:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 07:33:11 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7039459561198691 on epoch=424
06/18/2022 07:33:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7035119969040248 -> 0.7039459561198691 on epoch=424, global_step=1700
06/18/2022 07:33:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/18/2022 07:33:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/18/2022 07:33:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 07:33:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/18/2022 07:33:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 07:33:24 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.681988806988807 on epoch=437
06/18/2022 07:33:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/18/2022 07:33:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/18/2022 07:33:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/18/2022 07:33:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/18/2022 07:33:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 07:33:37 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.688463399460842 on epoch=449
06/18/2022 07:33:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/18/2022 07:33:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/18/2022 07:33:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/18/2022 07:33:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/18/2022 07:33:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/18/2022 07:33:50 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.681988806988807 on epoch=462
06/18/2022 07:33:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/18/2022 07:33:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/18/2022 07:33:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/18/2022 07:33:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/18/2022 07:34:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=474
06/18/2022 07:34:03 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.681988806988807 on epoch=474
06/18/2022 07:34:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/18/2022 07:34:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/18/2022 07:34:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/18/2022 07:34:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/18/2022 07:34:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 07:34:15 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7035119969040248 on epoch=487
06/18/2022 07:34:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/18/2022 07:34:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/18/2022 07:34:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/18/2022 07:34:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/18/2022 07:34:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 07:34:28 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6956823877876509 on epoch=499
06/18/2022 07:34:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 07:34:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 07:34:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/18/2022 07:34:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/18/2022 07:34:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 07:34:41 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6815274455077087 on epoch=512
06/18/2022 07:34:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 07:34:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/18/2022 07:34:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 07:34:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 07:34:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 07:34:54 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.688463399460842 on epoch=524
06/18/2022 07:34:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/18/2022 07:34:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 07:35:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 07:35:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/18/2022 07:35:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 07:35:07 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7036671058410189 on epoch=537
06/18/2022 07:35:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 07:35:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 07:35:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 07:35:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 07:35:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/18/2022 07:35:20 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6956823877876509 on epoch=549
06/18/2022 07:35:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/18/2022 07:35:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 07:35:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/18/2022 07:35:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 07:35:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/18/2022 07:35:33 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7179429916339325 on epoch=562
06/18/2022 07:35:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7039459561198691 -> 0.7179429916339325 on epoch=562, global_step=2250
06/18/2022 07:35:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/18/2022 07:35:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 07:35:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 07:35:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 07:35:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 07:35:46 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7023458436838433 on epoch=574
06/18/2022 07:35:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 07:35:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 07:35:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/18/2022 07:35:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 07:35:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 07:35:58 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6815274455077087 on epoch=587
06/18/2022 07:36:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/18/2022 07:36:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/18/2022 07:36:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 07:36:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 07:36:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 07:36:11 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6956823877876509 on epoch=599
06/18/2022 07:36:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 07:36:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=604
06/18/2022 07:36:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/18/2022 07:36:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 07:36:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 07:36:24 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7023458436838433 on epoch=612
06/18/2022 07:36:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 07:36:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 07:36:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 07:36:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/18/2022 07:36:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 07:36:37 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7031692818137831 on epoch=624
06/18/2022 07:36:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 07:36:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 07:36:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 07:36:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 07:36:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 07:36:50 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7035119969040248 on epoch=637
06/18/2022 07:36:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/18/2022 07:36:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/18/2022 07:36:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 07:37:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 07:37:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 07:37:03 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6809086779675015 on epoch=649
06/18/2022 07:37:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 07:37:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 07:37:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 07:37:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/18/2022 07:37:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/18/2022 07:37:16 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7035119969040248 on epoch=662
06/18/2022 07:37:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 07:37:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 07:37:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 07:37:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 07:37:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 07:37:29 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6956823877876509 on epoch=674
06/18/2022 07:37:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 07:37:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 07:37:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 07:37:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 07:37:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 07:37:42 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7179429916339325 on epoch=687
06/18/2022 07:37:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 07:37:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 07:37:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 07:37:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 07:37:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 07:37:55 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.688821843233608 on epoch=699
06/18/2022 07:37:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 07:38:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/18/2022 07:38:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 07:38:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 07:38:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 07:38:08 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6956823877876509 on epoch=712
06/18/2022 07:38:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 07:38:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/18/2022 07:38:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 07:38:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 07:38:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 07:38:21 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7035119969040248 on epoch=724
06/18/2022 07:38:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/18/2022 07:38:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 07:38:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 07:38:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 07:38:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 07:38:34 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.731833384007297 on epoch=737
06/18/2022 07:38:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7179429916339325 -> 0.731833384007297 on epoch=737, global_step=2950
06/18/2022 07:38:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 07:38:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 07:38:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 07:38:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 07:38:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 07:38:47 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.731833384007297 on epoch=749
06/18/2022 07:38:47 - INFO - __main__ - save last model!
06/18/2022 07:38:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 07:38:47 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 07:38:47 - INFO - __main__ - Printing 3 examples
06/18/2022 07:38:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 07:38:47 - INFO - __main__ - ['others']
06/18/2022 07:38:47 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 07:38:47 - INFO - __main__ - ['others']
06/18/2022 07:38:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 07:38:47 - INFO - __main__ - ['others']
06/18/2022 07:38:47 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:38:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:38:47 - INFO - __main__ - Printing 3 examples
06/18/2022 07:38:47 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 07:38:47 - INFO - __main__ - ['sad']
06/18/2022 07:38:47 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 07:38:47 - INFO - __main__ - ['sad']
06/18/2022 07:38:47 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 07:38:47 - INFO - __main__ - ['sad']
06/18/2022 07:38:47 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:38:47 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:38:47 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:38:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:38:47 - INFO - __main__ - Printing 3 examples
06/18/2022 07:38:47 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 07:38:47 - INFO - __main__ - ['sad']
06/18/2022 07:38:47 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 07:38:47 - INFO - __main__ - ['sad']
06/18/2022 07:38:47 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 07:38:47 - INFO - __main__ - ['sad']
06/18/2022 07:38:47 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:38:47 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:38:47 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:38:49 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:38:54 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 07:39:06 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:39:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:39:06 - INFO - __main__ - Starting training!
06/18/2022 07:40:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/18/2022 07:40:29 - INFO - __main__ - Classification-F1 on test data: 0.2193
06/18/2022 07:40:29 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.731833384007297, test_performance=0.21930686845568279
06/18/2022 07:40:29 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/18/2022 07:40:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:40:30 - INFO - __main__ - Printing 3 examples
06/18/2022 07:40:30 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 07:40:30 - INFO - __main__ - ['sad']
06/18/2022 07:40:30 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 07:40:30 - INFO - __main__ - ['sad']
06/18/2022 07:40:30 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 07:40:30 - INFO - __main__ - ['sad']
06/18/2022 07:40:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:40:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:40:30 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:40:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:40:30 - INFO - __main__ - Printing 3 examples
06/18/2022 07:40:30 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 07:40:30 - INFO - __main__ - ['sad']
06/18/2022 07:40:30 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 07:40:30 - INFO - __main__ - ['sad']
06/18/2022 07:40:30 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 07:40:30 - INFO - __main__ - ['sad']
06/18/2022 07:40:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:40:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:40:30 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:40:49 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:40:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:40:49 - INFO - __main__ - Starting training!
06/18/2022 07:40:52 - INFO - __main__ - Step 10 Global step 10 Train loss 4.37 on epoch=2
06/18/2022 07:40:55 - INFO - __main__ - Step 20 Global step 20 Train loss 3.28 on epoch=4
06/18/2022 07:40:57 - INFO - __main__ - Step 30 Global step 30 Train loss 2.42 on epoch=7
06/18/2022 07:41:00 - INFO - __main__ - Step 40 Global step 40 Train loss 1.79 on epoch=9
06/18/2022 07:41:02 - INFO - __main__ - Step 50 Global step 50 Train loss 1.38 on epoch=12
06/18/2022 07:41:04 - INFO - __main__ - Global step 50 Train loss 2.65 Classification-F1 0.28949938949938947 on epoch=12
06/18/2022 07:41:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.28949938949938947 on epoch=12, global_step=50
06/18/2022 07:41:06 - INFO - __main__ - Step 60 Global step 60 Train loss 1.15 on epoch=14
06/18/2022 07:41:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/18/2022 07:41:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=19
06/18/2022 07:41:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=22
06/18/2022 07:41:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
06/18/2022 07:41:17 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.5752543122512164 on epoch=24
06/18/2022 07:41:17 - INFO - __main__ - Saving model with best Classification-F1: 0.28949938949938947 -> 0.5752543122512164 on epoch=24, global_step=100
06/18/2022 07:41:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.64 on epoch=27
06/18/2022 07:41:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=29
06/18/2022 07:41:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/18/2022 07:41:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.53 on epoch=34
06/18/2022 07:41:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=37
06/18/2022 07:41:31 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.6042471042471041 on epoch=37
06/18/2022 07:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5752543122512164 -> 0.6042471042471041 on epoch=37, global_step=150
06/18/2022 07:41:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=39
06/18/2022 07:41:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=42
06/18/2022 07:41:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=44
06/18/2022 07:41:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=47
06/18/2022 07:41:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=49
06/18/2022 07:41:44 - INFO - __main__ - Global step 200 Train loss 0.44 Classification-F1 0.6515527950310559 on epoch=49
06/18/2022 07:41:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6042471042471041 -> 0.6515527950310559 on epoch=49, global_step=200
06/18/2022 07:41:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=52
06/18/2022 07:41:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=54
06/18/2022 07:41:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=57
06/18/2022 07:41:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.32 on epoch=59
06/18/2022 07:41:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=62
06/18/2022 07:41:57 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.6382002801120448 on epoch=62
06/18/2022 07:42:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=64
06/18/2022 07:42:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/18/2022 07:42:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=69
06/18/2022 07:42:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=72
06/18/2022 07:42:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=74
06/18/2022 07:42:11 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.6032509157509157 on epoch=74
06/18/2022 07:42:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=77
06/18/2022 07:42:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.34 on epoch=79
06/18/2022 07:42:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/18/2022 07:42:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=84
06/18/2022 07:42:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/18/2022 07:42:24 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.6392316017316018 on epoch=87
06/18/2022 07:42:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/18/2022 07:42:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/18/2022 07:42:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/18/2022 07:42:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/18/2022 07:42:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=99
06/18/2022 07:42:38 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.6665708388618605 on epoch=99
06/18/2022 07:42:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6515527950310559 -> 0.6665708388618605 on epoch=99, global_step=400
06/18/2022 07:42:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=102
06/18/2022 07:42:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/18/2022 07:42:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/18/2022 07:42:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=109
06/18/2022 07:42:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/18/2022 07:42:51 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.6421919243342856 on epoch=112
06/18/2022 07:42:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/18/2022 07:42:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=117
06/18/2022 07:42:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/18/2022 07:43:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/18/2022 07:43:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/18/2022 07:43:04 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.6548566017316018 on epoch=124
06/18/2022 07:43:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/18/2022 07:43:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=129
06/18/2022 07:43:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/18/2022 07:43:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=134
06/18/2022 07:43:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=137
06/18/2022 07:43:18 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.6548566017316018 on epoch=137
06/18/2022 07:43:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=139
06/18/2022 07:43:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=142
06/18/2022 07:43:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=144
06/18/2022 07:43:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=147
06/18/2022 07:43:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=149
06/18/2022 07:43:31 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6674111749963143 on epoch=149
06/18/2022 07:43:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6665708388618605 -> 0.6674111749963143 on epoch=149, global_step=600
06/18/2022 07:43:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=152
06/18/2022 07:43:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/18/2022 07:43:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=157
06/18/2022 07:43:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/18/2022 07:43:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=162
06/18/2022 07:43:45 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.6441421003580714 on epoch=162
06/18/2022 07:43:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/18/2022 07:43:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
06/18/2022 07:43:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/18/2022 07:43:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=172
06/18/2022 07:43:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/18/2022 07:43:58 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.668112714987715 on epoch=174
06/18/2022 07:43:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6674111749963143 -> 0.668112714987715 on epoch=174, global_step=700
06/18/2022 07:44:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=177
06/18/2022 07:44:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/18/2022 07:44:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/18/2022 07:44:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=184
06/18/2022 07:44:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/18/2022 07:44:12 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.6609952131691261 on epoch=187
06/18/2022 07:44:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/18/2022 07:44:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=192
06/18/2022 07:44:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/18/2022 07:44:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/18/2022 07:44:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/18/2022 07:44:25 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.660277124951038 on epoch=199
06/18/2022 07:44:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/18/2022 07:44:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/18/2022 07:44:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/18/2022 07:44:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/18/2022 07:44:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/18/2022 07:44:39 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.6525664319781966 on epoch=212
06/18/2022 07:44:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
06/18/2022 07:44:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/18/2022 07:44:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/18/2022 07:44:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/18/2022 07:44:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/18/2022 07:44:52 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.6738053613053613 on epoch=224
06/18/2022 07:44:52 - INFO - __main__ - Saving model with best Classification-F1: 0.668112714987715 -> 0.6738053613053613 on epoch=224, global_step=900
06/18/2022 07:44:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/18/2022 07:44:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/18/2022 07:45:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/18/2022 07:45:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/18/2022 07:45:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/18/2022 07:45:05 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.6741159608806668 on epoch=237
06/18/2022 07:45:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6738053613053613 -> 0.6741159608806668 on epoch=237, global_step=950
06/18/2022 07:45:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/18/2022 07:45:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/18/2022 07:45:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/18/2022 07:45:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/18/2022 07:45:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/18/2022 07:45:19 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6582752106945655 on epoch=249
06/18/2022 07:45:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/18/2022 07:45:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/18/2022 07:45:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=257
06/18/2022 07:45:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/18/2022 07:45:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/18/2022 07:45:32 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.6255189604445897 on epoch=262
06/18/2022 07:45:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/18/2022 07:45:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/18/2022 07:45:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/18/2022 07:45:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/18/2022 07:45:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/18/2022 07:45:45 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6245652994102835 on epoch=274
06/18/2022 07:45:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/18/2022 07:45:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/18/2022 07:45:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/18/2022 07:45:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/18/2022 07:45:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=287
06/18/2022 07:45:59 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6245652994102835 on epoch=287
06/18/2022 07:46:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/18/2022 07:46:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=292
06/18/2022 07:46:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/18/2022 07:46:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/18/2022 07:46:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/18/2022 07:46:12 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6520515080297689 on epoch=299
06/18/2022 07:46:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/18/2022 07:46:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/18/2022 07:46:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/18/2022 07:46:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/18/2022 07:46:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/18/2022 07:46:25 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.637466358363974 on epoch=312
06/18/2022 07:46:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/18/2022 07:46:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/18/2022 07:46:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/18/2022 07:46:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/18/2022 07:46:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/18/2022 07:46:39 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.637466358363974 on epoch=324
06/18/2022 07:46:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/18/2022 07:46:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/18/2022 07:46:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/18/2022 07:46:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/18/2022 07:46:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/18/2022 07:46:52 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6876294743941803 on epoch=337
06/18/2022 07:46:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6741159608806668 -> 0.6876294743941803 on epoch=337, global_step=1350
06/18/2022 07:46:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=339
06/18/2022 07:46:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/18/2022 07:47:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/18/2022 07:47:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/18/2022 07:47:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/18/2022 07:47:06 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6664619164619164 on epoch=349
06/18/2022 07:47:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/18/2022 07:47:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/18/2022 07:47:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/18/2022 07:47:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/18/2022 07:47:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/18/2022 07:47:19 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6520515080297689 on epoch=362
06/18/2022 07:47:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/18/2022 07:47:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 07:47:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/18/2022 07:47:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=372
06/18/2022 07:47:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/18/2022 07:47:33 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6662831097613706 on epoch=374
06/18/2022 07:47:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/18/2022 07:47:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/18/2022 07:47:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/18/2022 07:47:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/18/2022 07:47:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/18/2022 07:47:46 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.651834749918274 on epoch=387
06/18/2022 07:47:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/18/2022 07:47:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/18/2022 07:47:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/18/2022 07:47:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/18/2022 07:47:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/18/2022 07:48:00 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6522708062753829 on epoch=399
06/18/2022 07:48:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 07:48:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/18/2022 07:48:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 07:48:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/18/2022 07:48:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/18/2022 07:48:13 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6670101211420323 on epoch=412
06/18/2022 07:48:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/18/2022 07:48:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/18/2022 07:48:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/18/2022 07:48:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/18/2022 07:48:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/18/2022 07:48:26 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6674455044721525 on epoch=424
06/18/2022 07:48:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/18/2022 07:48:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/18/2022 07:48:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/18/2022 07:48:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/18/2022 07:48:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/18/2022 07:48:40 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.664992644655116 on epoch=437
06/18/2022 07:48:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/18/2022 07:48:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/18/2022 07:48:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/18/2022 07:48:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/18/2022 07:48:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 07:48:53 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6649739327168994 on epoch=449
06/18/2022 07:48:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/18/2022 07:48:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/18/2022 07:49:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/18/2022 07:49:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/18/2022 07:49:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/18/2022 07:49:07 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6655138339920948 on epoch=462
06/18/2022 07:49:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/18/2022 07:49:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/18/2022 07:49:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/18/2022 07:49:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/18/2022 07:49:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 07:49:20 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.6801680158788743 on epoch=474
06/18/2022 07:49:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/18/2022 07:49:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/18/2022 07:49:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 07:49:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/18/2022 07:49:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 07:49:34 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6802660172926653 on epoch=487
06/18/2022 07:49:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/18/2022 07:49:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/18/2022 07:49:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/18/2022 07:49:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/18/2022 07:49:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/18/2022 07:49:48 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.651834749918274 on epoch=499
06/18/2022 07:49:50 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/18/2022 07:49:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 07:49:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/18/2022 07:49:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/18/2022 07:50:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 07:50:01 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.651834749918274 on epoch=512
06/18/2022 07:50:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 07:50:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/18/2022 07:50:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/18/2022 07:50:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 07:50:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 07:50:15 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.651834749918274 on epoch=524
06/18/2022 07:50:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/18/2022 07:50:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 07:50:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 07:50:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/18/2022 07:50:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/18/2022 07:50:29 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.651834749918274 on epoch=537
06/18/2022 07:50:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 07:50:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 07:50:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/18/2022 07:50:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/18/2022 07:50:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
06/18/2022 07:50:42 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6802660172926653 on epoch=549
06/18/2022 07:50:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 07:50:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 07:50:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
06/18/2022 07:50:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 07:50:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/18/2022 07:50:56 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6649739327168994 on epoch=562
06/18/2022 07:50:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/18/2022 07:51:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 07:51:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 07:51:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 07:51:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 07:51:09 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6800479985963858 on epoch=574
06/18/2022 07:51:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 07:51:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 07:51:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/18/2022 07:51:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 07:51:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/18/2022 07:51:23 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6793843411490471 on epoch=587
06/18/2022 07:51:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 07:51:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 07:51:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/18/2022 07:51:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 07:51:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 07:51:37 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6649739327168994 on epoch=599
06/18/2022 07:51:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/18/2022 07:51:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 07:51:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 07:51:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 07:51:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/18/2022 07:51:50 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6538522264051903 on epoch=612
06/18/2022 07:51:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 07:51:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=617
06/18/2022 07:51:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 07:52:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=622
06/18/2022 07:52:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 07:52:04 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6670101211420323 on epoch=624
06/18/2022 07:52:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=627
06/18/2022 07:52:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 07:52:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=632
06/18/2022 07:52:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 07:52:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 07:52:17 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6387572927618694 on epoch=637
06/18/2022 07:52:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 07:52:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/18/2022 07:52:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 07:52:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/18/2022 07:52:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 07:52:31 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6790023701788408 on epoch=649
06/18/2022 07:52:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 07:52:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 07:52:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 07:52:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 07:52:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 07:52:44 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.680783397888661 on epoch=662
06/18/2022 07:52:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 07:52:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/18/2022 07:52:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/18/2022 07:52:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 07:52:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 07:52:58 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6793843411490471 on epoch=674
06/18/2022 07:53:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 07:53:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 07:53:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/18/2022 07:53:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 07:53:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 07:53:12 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6790023701788408 on epoch=687
06/18/2022 07:53:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 07:53:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 07:53:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 07:53:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/18/2022 07:53:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/18/2022 07:53:25 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6802660172926653 on epoch=699
06/18/2022 07:53:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 07:53:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=704
06/18/2022 07:53:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/18/2022 07:53:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 07:53:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 07:53:39 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6802660172926653 on epoch=712
06/18/2022 07:53:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 07:53:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 07:53:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 07:53:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 07:53:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 07:53:53 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6802660172926653 on epoch=724
06/18/2022 07:53:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 07:53:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 07:54:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 07:54:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 07:54:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 07:54:06 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6802660172926653 on epoch=737
06/18/2022 07:54:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 07:54:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 07:54:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 07:54:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 07:54:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/18/2022 07:54:20 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6802660172926653 on epoch=749
06/18/2022 07:54:20 - INFO - __main__ - save last model!
06/18/2022 07:54:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 07:54:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:54:20 - INFO - __main__ - Printing 3 examples
06/18/2022 07:54:20 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 07:54:20 - INFO - __main__ - ['sad']
06/18/2022 07:54:20 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 07:54:20 - INFO - __main__ - ['sad']
06/18/2022 07:54:20 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 07:54:20 - INFO - __main__ - ['sad']
06/18/2022 07:54:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:54:20 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 07:54:20 - INFO - __main__ - Printing 3 examples
06/18/2022 07:54:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 07:54:20 - INFO - __main__ - ['others']
06/18/2022 07:54:20 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 07:54:20 - INFO - __main__ - ['others']
06/18/2022 07:54:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 07:54:20 - INFO - __main__ - ['others']
06/18/2022 07:54:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:54:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:54:20 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:54:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:54:20 - INFO - __main__ - Printing 3 examples
06/18/2022 07:54:20 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 07:54:20 - INFO - __main__ - ['sad']
06/18/2022 07:54:20 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 07:54:20 - INFO - __main__ - ['sad']
06/18/2022 07:54:20 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 07:54:20 - INFO - __main__ - ['sad']
06/18/2022 07:54:20 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:54:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:54:20 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:54:22 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:54:28 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 07:54:39 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:54:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:54:40 - INFO - __main__ - Starting training!
06/18/2022 07:56:05 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/18/2022 07:56:05 - INFO - __main__ - Classification-F1 on test data: 0.1696
06/18/2022 07:56:05 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.6876294743941803, test_performance=0.16955701723527034
06/18/2022 07:56:05 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/18/2022 07:56:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:56:06 - INFO - __main__ - Printing 3 examples
06/18/2022 07:56:06 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 07:56:06 - INFO - __main__ - ['sad']
06/18/2022 07:56:06 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 07:56:06 - INFO - __main__ - ['sad']
06/18/2022 07:56:06 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 07:56:06 - INFO - __main__ - ['sad']
06/18/2022 07:56:06 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:56:06 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:56:06 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 07:56:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 07:56:06 - INFO - __main__ - Printing 3 examples
06/18/2022 07:56:06 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 07:56:06 - INFO - __main__ - ['sad']
06/18/2022 07:56:06 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 07:56:06 - INFO - __main__ - ['sad']
06/18/2022 07:56:06 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 07:56:06 - INFO - __main__ - ['sad']
06/18/2022 07:56:06 - INFO - __main__ - Tokenizing Input ...
06/18/2022 07:56:06 - INFO - __main__ - Tokenizing Output ...
06/18/2022 07:56:06 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 07:56:25 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 07:56:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 07:56:25 - INFO - __main__ - Starting training!
06/18/2022 07:56:28 - INFO - __main__ - Step 10 Global step 10 Train loss 4.19 on epoch=2
06/18/2022 07:56:31 - INFO - __main__ - Step 20 Global step 20 Train loss 3.42 on epoch=4
06/18/2022 07:56:33 - INFO - __main__ - Step 30 Global step 30 Train loss 2.62 on epoch=7
06/18/2022 07:56:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.20 on epoch=9
06/18/2022 07:56:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.65 on epoch=12
06/18/2022 07:56:40 - INFO - __main__ - Global step 50 Train loss 2.82 Classification-F1 0.1276128762541806 on epoch=12
06/18/2022 07:56:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1276128762541806 on epoch=12, global_step=50
06/18/2022 07:56:43 - INFO - __main__ - Step 60 Global step 60 Train loss 1.42 on epoch=14
06/18/2022 07:56:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.33 on epoch=17
06/18/2022 07:56:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
06/18/2022 07:56:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=22
06/18/2022 07:56:52 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=24
06/18/2022 07:56:53 - INFO - __main__ - Global step 100 Train loss 1.08 Classification-F1 0.4652218782249742 on epoch=24
06/18/2022 07:56:53 - INFO - __main__ - Saving model with best Classification-F1: 0.1276128762541806 -> 0.4652218782249742 on epoch=24, global_step=100
06/18/2022 07:56:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.84 on epoch=27
06/18/2022 07:56:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
06/18/2022 07:57:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=32
06/18/2022 07:57:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=34
06/18/2022 07:57:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.61 on epoch=37
06/18/2022 07:57:07 - INFO - __main__ - Global step 150 Train loss 0.70 Classification-F1 0.5666125541125542 on epoch=37
06/18/2022 07:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4652218782249742 -> 0.5666125541125542 on epoch=37, global_step=150
06/18/2022 07:57:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=39
06/18/2022 07:57:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=42
06/18/2022 07:57:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=44
06/18/2022 07:57:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=47
06/18/2022 07:57:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/18/2022 07:57:20 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.6067669172932331 on epoch=49
06/18/2022 07:57:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5666125541125542 -> 0.6067669172932331 on epoch=49, global_step=200
06/18/2022 07:57:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=52
06/18/2022 07:57:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=54
06/18/2022 07:57:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=57
06/18/2022 07:57:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=59
06/18/2022 07:57:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=62
06/18/2022 07:57:34 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.5633971291866029 on epoch=62
06/18/2022 07:57:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=64
06/18/2022 07:57:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=67
06/18/2022 07:57:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=69
06/18/2022 07:57:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=72
06/18/2022 07:57:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=74
06/18/2022 07:57:47 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.6800075102504771 on epoch=74
06/18/2022 07:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6067669172932331 -> 0.6800075102504771 on epoch=74, global_step=300
06/18/2022 07:57:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=77
06/18/2022 07:57:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=79
06/18/2022 07:57:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/18/2022 07:57:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=84
06/18/2022 07:57:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=87
06/18/2022 07:58:00 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6394348894348895 on epoch=87
06/18/2022 07:58:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
06/18/2022 07:58:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=92
06/18/2022 07:58:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/18/2022 07:58:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=97
06/18/2022 07:58:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
06/18/2022 07:58:14 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.6527052926433732 on epoch=99
06/18/2022 07:58:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=102
06/18/2022 07:58:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=104
06/18/2022 07:58:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/18/2022 07:58:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/18/2022 07:58:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
06/18/2022 07:58:27 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.6666229636817872 on epoch=112
06/18/2022 07:58:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/18/2022 07:58:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/18/2022 07:58:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=119
06/18/2022 07:58:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/18/2022 07:58:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/18/2022 07:58:40 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6666229636817872 on epoch=124
06/18/2022 07:58:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=127
06/18/2022 07:58:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/18/2022 07:58:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
06/18/2022 07:58:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/18/2022 07:58:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/18/2022 07:58:54 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6548566017316018 on epoch=137
06/18/2022 07:58:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/18/2022 07:58:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=142
06/18/2022 07:59:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=144
06/18/2022 07:59:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/18/2022 07:59:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/18/2022 07:59:07 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6548566017316018 on epoch=149
06/18/2022 07:59:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/18/2022 07:59:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=154
06/18/2022 07:59:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/18/2022 07:59:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=159
06/18/2022 07:59:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
06/18/2022 07:59:21 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6411133221617092 on epoch=162
06/18/2022 07:59:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/18/2022 07:59:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
06/18/2022 07:59:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=169
06/18/2022 07:59:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=172
06/18/2022 07:59:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/18/2022 07:59:34 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6752292471042471 on epoch=174
06/18/2022 07:59:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/18/2022 07:59:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/18/2022 07:59:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=182
06/18/2022 07:59:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=184
06/18/2022 07:59:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/18/2022 07:59:47 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6610295901042931 on epoch=187
06/18/2022 07:59:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/18/2022 07:59:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/18/2022 07:59:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/18/2022 07:59:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/18/2022 08:00:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=199
06/18/2022 08:00:01 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6403392773659253 on epoch=199
06/18/2022 08:00:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=202
06/18/2022 08:00:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=204
06/18/2022 08:00:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/18/2022 08:00:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=209
06/18/2022 08:00:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/18/2022 08:00:14 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6249842899036447 on epoch=212
06/18/2022 08:00:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/18/2022 08:00:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/18/2022 08:00:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/18/2022 08:00:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/18/2022 08:00:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/18/2022 08:00:27 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.652948402948403 on epoch=224
06/18/2022 08:00:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/18/2022 08:00:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/18/2022 08:00:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/18/2022 08:00:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/18/2022 08:00:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/18/2022 08:00:41 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6243890518084065 on epoch=237
06/18/2022 08:00:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=239
06/18/2022 08:00:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/18/2022 08:00:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/18/2022 08:00:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/18/2022 08:00:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/18/2022 08:00:54 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6619588744588745 on epoch=249
06/18/2022 08:00:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/18/2022 08:00:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/18/2022 08:01:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/18/2022 08:01:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/18/2022 08:01:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/18/2022 08:01:07 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6537366142629302 on epoch=262
06/18/2022 08:01:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/18/2022 08:01:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/18/2022 08:01:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/18/2022 08:01:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/18/2022 08:01:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/18/2022 08:01:21 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6243890518084065 on epoch=274
06/18/2022 08:01:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
06/18/2022 08:01:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/18/2022 08:01:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/18/2022 08:01:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/18/2022 08:01:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/18/2022 08:01:34 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6386363636363637 on epoch=287
06/18/2022 08:01:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/18/2022 08:01:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/18/2022 08:01:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/18/2022 08:01:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/18/2022 08:01:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/18/2022 08:01:47 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6243890518084065 on epoch=299
06/18/2022 08:01:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/18/2022 08:01:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/18/2022 08:01:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/18/2022 08:01:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/18/2022 08:02:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/18/2022 08:02:01 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6398809523809523 on epoch=312
06/18/2022 08:02:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/18/2022 08:02:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/18/2022 08:02:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/18/2022 08:02:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/18/2022 08:02:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/18/2022 08:02:14 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6093208874458875 on epoch=324
06/18/2022 08:02:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/18/2022 08:02:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/18/2022 08:02:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/18/2022 08:02:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/18/2022 08:02:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/18/2022 08:02:28 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6377968877968877 on epoch=337
06/18/2022 08:02:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/18/2022 08:02:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/18/2022 08:02:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/18/2022 08:02:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/18/2022 08:02:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/18/2022 08:02:41 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6596846846846847 on epoch=349
06/18/2022 08:02:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=352
06/18/2022 08:02:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=354
06/18/2022 08:02:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/18/2022 08:02:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/18/2022 08:02:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/18/2022 08:02:55 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6525664319781966 on epoch=362
06/18/2022 08:02:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/18/2022 08:03:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 08:03:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/18/2022 08:03:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/18/2022 08:03:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/18/2022 08:03:08 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.644652124951038 on epoch=374
06/18/2022 08:03:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/18/2022 08:03:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/18/2022 08:03:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/18/2022 08:03:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/18/2022 08:03:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/18/2022 08:03:22 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6234402852049911 on epoch=387
06/18/2022 08:03:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/18/2022 08:03:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 08:03:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/18/2022 08:03:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/18/2022 08:03:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/18/2022 08:03:36 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6233492014742015 on epoch=399
06/18/2022 08:03:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/18/2022 08:03:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/18/2022 08:03:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/18/2022 08:03:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 08:03:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/18/2022 08:03:49 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6532759263022421 on epoch=412
06/18/2022 08:03:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/18/2022 08:03:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/18/2022 08:03:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/18/2022 08:03:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/18/2022 08:04:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 08:04:03 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6254272043745728 on epoch=424
06/18/2022 08:04:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/18/2022 08:04:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 08:04:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 08:04:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/18/2022 08:04:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/18/2022 08:04:16 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6394348894348895 on epoch=437
06/18/2022 08:04:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/18/2022 08:04:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/18/2022 08:04:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/18/2022 08:04:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/18/2022 08:04:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/18/2022 08:04:29 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6525664319781966 on epoch=449
06/18/2022 08:04:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/18/2022 08:04:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/18/2022 08:04:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/18/2022 08:04:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/18/2022 08:04:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 08:04:43 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6532759263022421 on epoch=462
06/18/2022 08:04:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/18/2022 08:04:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 08:04:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 08:04:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/18/2022 08:04:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/18/2022 08:04:56 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6745087266826397 on epoch=474
06/18/2022 08:04:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/18/2022 08:05:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/18/2022 08:05:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 08:05:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/18/2022 08:05:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 08:05:10 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.652948402948403 on epoch=487
06/18/2022 08:05:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 08:05:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/18/2022 08:05:17 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 08:05:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/18/2022 08:05:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 08:05:23 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6731811145510836 on epoch=499
06/18/2022 08:05:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 08:05:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 08:05:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/18/2022 08:05:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 08:05:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 08:05:36 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6661518661518662 on epoch=512
06/18/2022 08:05:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 08:05:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/18/2022 08:05:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/18/2022 08:05:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 08:05:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/18/2022 08:05:50 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6250244810027418 on epoch=524
06/18/2022 08:05:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/18/2022 08:05:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/18/2022 08:05:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/18/2022 08:06:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 08:06:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 08:06:04 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6525664319781966 on epoch=537
06/18/2022 08:06:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 08:06:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 08:06:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 08:06:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/18/2022 08:06:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/18/2022 08:06:17 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6515873015873015 on epoch=549
06/18/2022 08:06:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 08:06:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 08:06:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/18/2022 08:06:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 08:06:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/18/2022 08:06:31 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.652948402948403 on epoch=562
06/18/2022 08:06:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/18/2022 08:06:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 08:06:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 08:06:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 08:06:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 08:06:43 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.652948402948403 on epoch=574
06/18/2022 08:06:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 08:06:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 08:06:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/18/2022 08:06:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/18/2022 08:06:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/18/2022 08:06:56 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6535953906220386 on epoch=587
06/18/2022 08:06:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/18/2022 08:07:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=592
06/18/2022 08:07:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 08:07:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 08:07:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 08:07:10 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.652948402948403 on epoch=599
06/18/2022 08:07:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/18/2022 08:07:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/18/2022 08:07:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/18/2022 08:07:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 08:07:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 08:07:23 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6385379945162553 on epoch=612
06/18/2022 08:07:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 08:07:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 08:07:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 08:07:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 08:07:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 08:07:36 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6517316017316017 on epoch=624
06/18/2022 08:07:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 08:07:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 08:07:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 08:07:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 08:07:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 08:07:49 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6517316017316017 on epoch=637
06/18/2022 08:07:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/18/2022 08:07:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/18/2022 08:07:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 08:07:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 08:08:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 08:08:02 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6535953906220386 on epoch=649
06/18/2022 08:08:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 08:08:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/18/2022 08:08:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 08:08:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 08:08:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 08:08:15 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6596846846846847 on epoch=662
06/18/2022 08:08:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/18/2022 08:08:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 08:08:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/18/2022 08:08:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 08:08:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/18/2022 08:08:28 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6735720375106563 on epoch=674
06/18/2022 08:08:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.13 on epoch=677
06/18/2022 08:08:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 08:08:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 08:08:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 08:08:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 08:08:42 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6596042471042471 on epoch=687
06/18/2022 08:08:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 08:08:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/18/2022 08:08:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=694
06/18/2022 08:08:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 08:08:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/18/2022 08:08:55 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6389133698916307 on epoch=699
06/18/2022 08:08:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 08:09:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 08:09:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 08:09:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 08:09:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 08:09:08 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6389133698916307 on epoch=712
06/18/2022 08:09:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 08:09:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/18/2022 08:09:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 08:09:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 08:09:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/18/2022 08:09:21 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6538522264051903 on epoch=724
06/18/2022 08:09:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=727
06/18/2022 08:09:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 08:09:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 08:09:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/18/2022 08:09:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/18/2022 08:09:34 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6683695507708667 on epoch=737
06/18/2022 08:09:37 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=739
06/18/2022 08:09:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/18/2022 08:09:42 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 08:09:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/18/2022 08:09:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 08:09:48 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6527695962478571 on epoch=749
06/18/2022 08:09:48 - INFO - __main__ - save last model!
06/18/2022 08:09:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 08:09:48 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 08:09:48 - INFO - __main__ - Printing 3 examples
06/18/2022 08:09:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 08:09:48 - INFO - __main__ - ['others']
06/18/2022 08:09:48 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 08:09:48 - INFO - __main__ - ['others']
06/18/2022 08:09:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 08:09:48 - INFO - __main__ - ['others']
06/18/2022 08:09:48 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:09:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:09:48 - INFO - __main__ - Printing 3 examples
06/18/2022 08:09:48 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 08:09:48 - INFO - __main__ - ['sad']
06/18/2022 08:09:48 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 08:09:48 - INFO - __main__ - ['sad']
06/18/2022 08:09:48 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 08:09:48 - INFO - __main__ - ['sad']
06/18/2022 08:09:48 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:09:48 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:09:48 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:09:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:09:48 - INFO - __main__ - Printing 3 examples
06/18/2022 08:09:48 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 08:09:48 - INFO - __main__ - ['sad']
06/18/2022 08:09:48 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 08:09:48 - INFO - __main__ - ['sad']
06/18/2022 08:09:48 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 08:09:48 - INFO - __main__ - ['sad']
06/18/2022 08:09:48 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:09:48 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:09:48 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:09:50 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:09:55 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 08:10:05 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:10:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:10:06 - INFO - __main__ - Starting training!
06/18/2022 08:11:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/18/2022 08:11:34 - INFO - __main__ - Classification-F1 on test data: 0.1234
06/18/2022 08:11:34 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.6800075102504771, test_performance=0.12342620742718995
06/18/2022 08:11:34 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/18/2022 08:11:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:11:35 - INFO - __main__ - Printing 3 examples
06/18/2022 08:11:35 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/18/2022 08:11:35 - INFO - __main__ - ['sad']
06/18/2022 08:11:35 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/18/2022 08:11:35 - INFO - __main__ - ['sad']
06/18/2022 08:11:35 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/18/2022 08:11:35 - INFO - __main__ - ['sad']
06/18/2022 08:11:35 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:11:35 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:11:35 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:11:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:11:35 - INFO - __main__ - Printing 3 examples
06/18/2022 08:11:35 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/18/2022 08:11:35 - INFO - __main__ - ['sad']
06/18/2022 08:11:35 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/18/2022 08:11:35 - INFO - __main__ - ['sad']
06/18/2022 08:11:35 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/18/2022 08:11:35 - INFO - __main__ - ['sad']
06/18/2022 08:11:35 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:11:35 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:11:35 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:11:54 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:11:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:11:54 - INFO - __main__ - Starting training!
06/18/2022 08:11:57 - INFO - __main__ - Step 10 Global step 10 Train loss 4.78 on epoch=2
06/18/2022 08:12:00 - INFO - __main__ - Step 20 Global step 20 Train loss 3.77 on epoch=4
06/18/2022 08:12:02 - INFO - __main__ - Step 30 Global step 30 Train loss 3.26 on epoch=7
06/18/2022 08:12:05 - INFO - __main__ - Step 40 Global step 40 Train loss 2.75 on epoch=9
06/18/2022 08:12:07 - INFO - __main__ - Step 50 Global step 50 Train loss 2.46 on epoch=12
06/18/2022 08:12:09 - INFO - __main__ - Global step 50 Train loss 3.40 Classification-F1 0.034782608695652174 on epoch=12
06/18/2022 08:12:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.034782608695652174 on epoch=12, global_step=50
06/18/2022 08:12:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.03 on epoch=14
06/18/2022 08:12:14 - INFO - __main__ - Step 70 Global step 70 Train loss 1.90 on epoch=17
06/18/2022 08:12:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.63 on epoch=19
06/18/2022 08:12:19 - INFO - __main__ - Step 90 Global step 90 Train loss 1.34 on epoch=22
06/18/2022 08:12:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.15 on epoch=24
06/18/2022 08:12:23 - INFO - __main__ - Global step 100 Train loss 1.61 Classification-F1 0.28142325510746563 on epoch=24
06/18/2022 08:12:23 - INFO - __main__ - Saving model with best Classification-F1: 0.034782608695652174 -> 0.28142325510746563 on epoch=24, global_step=100
06/18/2022 08:12:25 - INFO - __main__ - Step 110 Global step 110 Train loss 1.12 on epoch=27
06/18/2022 08:12:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.95 on epoch=29
06/18/2022 08:12:30 - INFO - __main__ - Step 130 Global step 130 Train loss 0.88 on epoch=32
06/18/2022 08:12:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.95 on epoch=34
06/18/2022 08:12:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=37
06/18/2022 08:12:36 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.5249644381223328 on epoch=37
06/18/2022 08:12:36 - INFO - __main__ - Saving model with best Classification-F1: 0.28142325510746563 -> 0.5249644381223328 on epoch=37, global_step=150
06/18/2022 08:12:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.76 on epoch=39
06/18/2022 08:12:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
06/18/2022 08:12:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=44
06/18/2022 08:12:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=47
06/18/2022 08:12:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=49
06/18/2022 08:12:49 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.5649859943977591 on epoch=49
06/18/2022 08:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5249644381223328 -> 0.5649859943977591 on epoch=49, global_step=200
06/18/2022 08:12:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=52
06/18/2022 08:12:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=54
06/18/2022 08:12:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/18/2022 08:12:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=59
06/18/2022 08:13:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=62
06/18/2022 08:13:03 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.5923423423423422 on epoch=62
06/18/2022 08:13:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5649859943977591 -> 0.5923423423423422 on epoch=62, global_step=250
06/18/2022 08:13:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=64
06/18/2022 08:13:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.52 on epoch=67
06/18/2022 08:13:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=69
06/18/2022 08:13:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=72
06/18/2022 08:13:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=74
06/18/2022 08:13:16 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.5856054006968641 on epoch=74
06/18/2022 08:13:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
06/18/2022 08:13:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=79
06/18/2022 08:13:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=82
06/18/2022 08:13:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=84
06/18/2022 08:13:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=87
06/18/2022 08:13:30 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.629004329004329 on epoch=87
06/18/2022 08:13:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5923423423423422 -> 0.629004329004329 on epoch=87, global_step=350
06/18/2022 08:13:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/18/2022 08:13:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=92
06/18/2022 08:13:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=94
06/18/2022 08:13:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=97
06/18/2022 08:13:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=99
06/18/2022 08:13:43 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.6423423423423423 on epoch=99
06/18/2022 08:13:43 - INFO - __main__ - Saving model with best Classification-F1: 0.629004329004329 -> 0.6423423423423423 on epoch=99, global_step=400
06/18/2022 08:13:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=102
06/18/2022 08:13:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=104
06/18/2022 08:13:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=107
06/18/2022 08:13:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=109
06/18/2022 08:13:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=112
06/18/2022 08:13:57 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.6530872636135794 on epoch=112
06/18/2022 08:13:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6423423423423423 -> 0.6530872636135794 on epoch=112, global_step=450
06/18/2022 08:13:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=114
06/18/2022 08:14:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=117
06/18/2022 08:14:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/18/2022 08:14:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=122
06/18/2022 08:14:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=124
06/18/2022 08:14:10 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.6405056759545924 on epoch=124
06/18/2022 08:14:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=127
06/18/2022 08:14:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
06/18/2022 08:14:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=132
06/18/2022 08:14:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=134
06/18/2022 08:14:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=137
06/18/2022 08:14:24 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.588095238095238 on epoch=137
06/18/2022 08:14:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=139
06/18/2022 08:14:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=142
06/18/2022 08:14:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=144
06/18/2022 08:14:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=147
06/18/2022 08:14:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=149
06/18/2022 08:14:37 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.588095238095238 on epoch=149
06/18/2022 08:14:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=152
06/18/2022 08:14:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=154
06/18/2022 08:14:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/18/2022 08:14:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=159
06/18/2022 08:14:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/18/2022 08:14:51 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6139097744360902 on epoch=162
06/18/2022 08:14:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
06/18/2022 08:14:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/18/2022 08:14:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=169
06/18/2022 08:15:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/18/2022 08:15:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=174
06/18/2022 08:15:04 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.651917081328846 on epoch=174
06/18/2022 08:15:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=177
06/18/2022 08:15:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/18/2022 08:15:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=182
06/18/2022 08:15:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
06/18/2022 08:15:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=187
06/18/2022 08:15:17 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.6379357484620642 on epoch=187
06/18/2022 08:15:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/18/2022 08:15:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/18/2022 08:15:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/18/2022 08:15:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/18/2022 08:15:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/18/2022 08:15:31 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.6518661518661519 on epoch=199
06/18/2022 08:15:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=202
06/18/2022 08:15:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=204
06/18/2022 08:15:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/18/2022 08:15:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/18/2022 08:15:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/18/2022 08:15:44 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6656204906204907 on epoch=212
06/18/2022 08:15:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6530872636135794 -> 0.6656204906204907 on epoch=212, global_step=850
06/18/2022 08:15:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=214
06/18/2022 08:15:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=217
06/18/2022 08:15:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=219
06/18/2022 08:15:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
06/18/2022 08:15:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/18/2022 08:15:58 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.6654761904761904 on epoch=224
06/18/2022 08:16:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/18/2022 08:16:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/18/2022 08:16:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/18/2022 08:16:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=234
06/18/2022 08:16:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/18/2022 08:16:11 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6735953801810579 on epoch=237
06/18/2022 08:16:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6656204906204907 -> 0.6735953801810579 on epoch=237, global_step=950
06/18/2022 08:16:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/18/2022 08:16:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/18/2022 08:16:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/18/2022 08:16:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/18/2022 08:16:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=249
06/18/2022 08:16:24 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.6548566017316018 on epoch=249
06/18/2022 08:16:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/18/2022 08:16:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=254
06/18/2022 08:16:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=257
06/18/2022 08:16:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
06/18/2022 08:16:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=262
06/18/2022 08:16:38 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6596042471042471 on epoch=262
06/18/2022 08:16:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/18/2022 08:16:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/18/2022 08:16:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=269
06/18/2022 08:16:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=272
06/18/2022 08:16:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/18/2022 08:16:51 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6548566017316018 on epoch=274
06/18/2022 08:16:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/18/2022 08:16:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/18/2022 08:16:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/18/2022 08:17:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/18/2022 08:17:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=287
06/18/2022 08:17:05 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6403392773659253 on epoch=287
06/18/2022 08:17:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/18/2022 08:17:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=292
06/18/2022 08:17:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=294
06/18/2022 08:17:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/18/2022 08:17:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/18/2022 08:17:18 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6548566017316018 on epoch=299
06/18/2022 08:17:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/18/2022 08:17:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/18/2022 08:17:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=307
06/18/2022 08:17:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=309
06/18/2022 08:17:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/18/2022 08:17:32 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6760409856162144 on epoch=312
06/18/2022 08:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6735953801810579 -> 0.6760409856162144 on epoch=312, global_step=1250
06/18/2022 08:17:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/18/2022 08:17:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=317
06/18/2022 08:17:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/18/2022 08:17:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/18/2022 08:17:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/18/2022 08:17:45 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6537366142629302 on epoch=324
06/18/2022 08:17:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=327
06/18/2022 08:17:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=329
06/18/2022 08:17:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=332
06/18/2022 08:17:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/18/2022 08:17:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/18/2022 08:17:58 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6231601731601731 on epoch=337
06/18/2022 08:18:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/18/2022 08:18:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/18/2022 08:18:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/18/2022 08:18:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/18/2022 08:18:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/18/2022 08:18:12 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6593096658953437 on epoch=349
06/18/2022 08:18:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=352
06/18/2022 08:18:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/18/2022 08:18:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/18/2022 08:18:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=359
06/18/2022 08:18:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/18/2022 08:18:25 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.675902124951038 on epoch=362
06/18/2022 08:18:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/18/2022 08:18:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/18/2022 08:18:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/18/2022 08:18:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=372
06/18/2022 08:18:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/18/2022 08:18:39 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6608907294391165 on epoch=374
06/18/2022 08:18:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/18/2022 08:18:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=379
06/18/2022 08:18:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
06/18/2022 08:18:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/18/2022 08:18:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=387
06/18/2022 08:18:52 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6596846846846847 on epoch=387
06/18/2022 08:18:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=389
06/18/2022 08:18:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/18/2022 08:19:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/18/2022 08:19:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/18/2022 08:19:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/18/2022 08:19:06 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6399633375163013 on epoch=399
06/18/2022 08:19:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=402
06/18/2022 08:19:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/18/2022 08:19:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/18/2022 08:19:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/18/2022 08:19:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/18/2022 08:19:19 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6591991341991341 on epoch=412
06/18/2022 08:19:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/18/2022 08:19:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/18/2022 08:19:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
06/18/2022 08:19:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/18/2022 08:19:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/18/2022 08:19:33 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6238343052582367 on epoch=424
06/18/2022 08:19:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/18/2022 08:19:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/18/2022 08:19:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/18/2022 08:19:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/18/2022 08:19:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/18/2022 08:19:47 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6243911408957176 on epoch=437
06/18/2022 08:19:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/18/2022 08:19:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=442
06/18/2022 08:19:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/18/2022 08:19:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/18/2022 08:19:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/18/2022 08:20:00 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6597222222222222 on epoch=449
06/18/2022 08:20:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/18/2022 08:20:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/18/2022 08:20:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/18/2022 08:20:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/18/2022 08:20:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/18/2022 08:20:14 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6385379945162553 on epoch=462
06/18/2022 08:20:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/18/2022 08:20:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/18/2022 08:20:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/18/2022 08:20:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/18/2022 08:20:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=474
06/18/2022 08:20:27 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.623847167325428 on epoch=474
06/18/2022 08:20:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/18/2022 08:20:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/18/2022 08:20:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 08:20:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=484
06/18/2022 08:20:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/18/2022 08:20:41 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6449134199134199 on epoch=487
06/18/2022 08:20:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 08:20:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/18/2022 08:20:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 08:20:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/18/2022 08:20:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/18/2022 08:20:54 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6449134199134199 on epoch=499
06/18/2022 08:20:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/18/2022 08:20:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/18/2022 08:21:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/18/2022 08:21:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 08:21:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 08:21:08 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.623847167325428 on epoch=512
06/18/2022 08:21:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 08:21:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/18/2022 08:21:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/18/2022 08:21:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/18/2022 08:21:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 08:21:22 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6597222222222222 on epoch=524
06/18/2022 08:21:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/18/2022 08:21:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/18/2022 08:21:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/18/2022 08:21:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=534
06/18/2022 08:21:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 08:21:35 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6603764478764479 on epoch=537
06/18/2022 08:21:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/18/2022 08:21:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/18/2022 08:21:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/18/2022 08:21:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/18/2022 08:21:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/18/2022 08:21:49 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6446078431372549 on epoch=549
06/18/2022 08:21:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/18/2022 08:21:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/18/2022 08:21:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/18/2022 08:21:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.16 on epoch=559
06/18/2022 08:22:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/18/2022 08:22:02 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6597222222222222 on epoch=562
06/18/2022 08:22:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/18/2022 08:22:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 08:22:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/18/2022 08:22:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 08:22:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/18/2022 08:22:16 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6747623291740938 on epoch=574
06/18/2022 08:22:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/18/2022 08:22:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/18/2022 08:22:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/18/2022 08:22:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/18/2022 08:22:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 08:22:29 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6597222222222222 on epoch=587
06/18/2022 08:22:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/18/2022 08:22:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 08:22:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=594
06/18/2022 08:22:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/18/2022 08:22:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 08:22:43 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6446078431372549 on epoch=599
06/18/2022 08:22:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/18/2022 08:22:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/18/2022 08:22:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/18/2022 08:22:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/18/2022 08:22:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/18/2022 08:22:56 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6597222222222222 on epoch=612
06/18/2022 08:22:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/18/2022 08:23:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=617
06/18/2022 08:23:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/18/2022 08:23:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/18/2022 08:23:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/18/2022 08:23:10 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6449134199134199 on epoch=624
06/18/2022 08:23:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/18/2022 08:23:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/18/2022 08:23:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/18/2022 08:23:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/18/2022 08:23:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/18/2022 08:23:23 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6385379945162553 on epoch=637
06/18/2022 08:23:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/18/2022 08:23:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/18/2022 08:23:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/18/2022 08:23:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 08:23:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 08:23:37 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6385379945162553 on epoch=649
06/18/2022 08:23:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/18/2022 08:23:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/18/2022 08:23:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/18/2022 08:23:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 08:23:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/18/2022 08:23:50 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6597222222222222 on epoch=662
06/18/2022 08:23:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/18/2022 08:23:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/18/2022 08:23:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/18/2022 08:24:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/18/2022 08:24:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/18/2022 08:24:04 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6597222222222222 on epoch=674
06/18/2022 08:24:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 08:24:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 08:24:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/18/2022 08:24:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 08:24:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/18/2022 08:24:17 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.623847167325428 on epoch=687
06/18/2022 08:24:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/18/2022 08:24:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/18/2022 08:24:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 08:24:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/18/2022 08:24:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/18/2022 08:24:31 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.623847167325428 on epoch=699
06/18/2022 08:24:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/18/2022 08:24:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/18/2022 08:24:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=707
06/18/2022 08:24:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 08:24:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/18/2022 08:24:44 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6449134199134199 on epoch=712
06/18/2022 08:24:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/18/2022 08:24:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=717
06/18/2022 08:24:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 08:24:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 08:24:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 08:24:58 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6449134199134199 on epoch=724
06/18/2022 08:25:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/18/2022 08:25:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/18/2022 08:25:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/18/2022 08:25:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=734
06/18/2022 08:25:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/18/2022 08:25:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6601731601731602 on epoch=737
06/18/2022 08:25:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 08:25:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/18/2022 08:25:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=744
06/18/2022 08:25:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/18/2022 08:25:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/18/2022 08:25:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.659706491292169 on epoch=749
06/18/2022 08:25:25 - INFO - __main__ - save last model!
06/18/2022 08:25:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 08:25:25 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 08:25:25 - INFO - __main__ - Printing 3 examples
06/18/2022 08:25:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 08:25:25 - INFO - __main__ - ['others']
06/18/2022 08:25:25 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 08:25:25 - INFO - __main__ - ['others']
06/18/2022 08:25:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 08:25:25 - INFO - __main__ - ['others']
06/18/2022 08:25:25 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:25:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:25:25 - INFO - __main__ - Printing 3 examples
06/18/2022 08:25:25 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 08:25:25 - INFO - __main__ - ['happy']
06/18/2022 08:25:25 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 08:25:25 - INFO - __main__ - ['happy']
06/18/2022 08:25:25 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 08:25:25 - INFO - __main__ - ['happy']
06/18/2022 08:25:25 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:25:25 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:25:25 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:25:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:25:25 - INFO - __main__ - Printing 3 examples
06/18/2022 08:25:25 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 08:25:25 - INFO - __main__ - ['happy']
06/18/2022 08:25:25 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 08:25:25 - INFO - __main__ - ['happy']
06/18/2022 08:25:25 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 08:25:25 - INFO - __main__ - ['happy']
06/18/2022 08:25:25 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:25:25 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:25:25 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:25:27 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:25:32 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 08:25:44 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:25:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:25:45 - INFO - __main__ - Starting training!
06/18/2022 08:27:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/18/2022 08:27:09 - INFO - __main__ - Classification-F1 on test data: 0.1701
06/18/2022 08:27:09 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.6760409856162144, test_performance=0.1701023865515359
06/18/2022 08:27:09 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/18/2022 08:27:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:27:10 - INFO - __main__ - Printing 3 examples
06/18/2022 08:27:10 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 08:27:10 - INFO - __main__ - ['happy']
06/18/2022 08:27:10 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 08:27:10 - INFO - __main__ - ['happy']
06/18/2022 08:27:10 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 08:27:10 - INFO - __main__ - ['happy']
06/18/2022 08:27:10 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:27:10 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:27:10 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:27:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:27:10 - INFO - __main__ - Printing 3 examples
06/18/2022 08:27:10 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 08:27:10 - INFO - __main__ - ['happy']
06/18/2022 08:27:10 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 08:27:10 - INFO - __main__ - ['happy']
06/18/2022 08:27:10 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 08:27:10 - INFO - __main__ - ['happy']
06/18/2022 08:27:10 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:27:10 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:27:10 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:27:29 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:27:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:27:29 - INFO - __main__ - Starting training!
06/18/2022 08:27:32 - INFO - __main__ - Step 10 Global step 10 Train loss 3.87 on epoch=2
06/18/2022 08:27:35 - INFO - __main__ - Step 20 Global step 20 Train loss 2.65 on epoch=4
06/18/2022 08:27:37 - INFO - __main__ - Step 30 Global step 30 Train loss 1.86 on epoch=7
06/18/2022 08:27:40 - INFO - __main__ - Step 40 Global step 40 Train loss 1.43 on epoch=9
06/18/2022 08:27:42 - INFO - __main__ - Step 50 Global step 50 Train loss 0.97 on epoch=12
06/18/2022 08:27:43 - INFO - __main__ - Global step 50 Train loss 2.16 Classification-F1 0.34847689075630256 on epoch=12
06/18/2022 08:27:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.34847689075630256 on epoch=12, global_step=50
06/18/2022 08:27:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.78 on epoch=14
06/18/2022 08:27:49 - INFO - __main__ - Step 70 Global step 70 Train loss 0.63 on epoch=17
06/18/2022 08:27:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.74 on epoch=19
06/18/2022 08:27:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.64 on epoch=22
06/18/2022 08:27:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.55 on epoch=24
06/18/2022 08:27:57 - INFO - __main__ - Global step 100 Train loss 0.67 Classification-F1 0.7115015360983103 on epoch=24
06/18/2022 08:27:57 - INFO - __main__ - Saving model with best Classification-F1: 0.34847689075630256 -> 0.7115015360983103 on epoch=24, global_step=100
06/18/2022 08:28:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.57 on epoch=27
06/18/2022 08:28:02 - INFO - __main__ - Step 120 Global step 120 Train loss 0.51 on epoch=29
06/18/2022 08:28:05 - INFO - __main__ - Step 130 Global step 130 Train loss 0.39 on epoch=32
06/18/2022 08:28:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.43 on epoch=34
06/18/2022 08:28:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.37 on epoch=37
06/18/2022 08:28:11 - INFO - __main__ - Global step 150 Train loss 0.45 Classification-F1 0.7191484985602632 on epoch=37
06/18/2022 08:28:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7115015360983103 -> 0.7191484985602632 on epoch=37, global_step=150
06/18/2022 08:28:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.41 on epoch=39
06/18/2022 08:28:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.45 on epoch=42
06/18/2022 08:28:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.34 on epoch=44
06/18/2022 08:28:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=47
06/18/2022 08:28:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=49
06/18/2022 08:28:24 - INFO - __main__ - Global step 200 Train loss 0.40 Classification-F1 0.7902462121212122 on epoch=49
06/18/2022 08:28:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7191484985602632 -> 0.7902462121212122 on epoch=49, global_step=200
06/18/2022 08:28:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=52
06/18/2022 08:28:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=54
06/18/2022 08:28:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=57
06/18/2022 08:28:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=59
06/18/2022 08:28:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/18/2022 08:28:38 - INFO - __main__ - Global step 250 Train loss 0.31 Classification-F1 0.7857349327937564 on epoch=62
06/18/2022 08:28:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.21 on epoch=64
06/18/2022 08:28:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/18/2022 08:28:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/18/2022 08:28:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/18/2022 08:28:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
06/18/2022 08:28:51 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.7519213877909531 on epoch=74
06/18/2022 08:28:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=77
06/18/2022 08:28:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/18/2022 08:28:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=82
06/18/2022 08:29:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.15 on epoch=84
06/18/2022 08:29:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=87
06/18/2022 08:29:05 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.7620429139825692 on epoch=87
06/18/2022 08:29:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=89
06/18/2022 08:29:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=92
06/18/2022 08:29:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.17 on epoch=94
06/18/2022 08:29:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=97
06/18/2022 08:29:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=99
06/18/2022 08:29:19 - INFO - __main__ - Global step 400 Train loss 0.15 Classification-F1 0.777917358165837 on epoch=99
06/18/2022 08:29:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=102
06/18/2022 08:29:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.09 on epoch=104
06/18/2022 08:29:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.12 on epoch=107
06/18/2022 08:29:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=109
06/18/2022 08:29:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
06/18/2022 08:29:32 - INFO - __main__ - Global step 450 Train loss 0.11 Classification-F1 0.7567873303167421 on epoch=112
06/18/2022 08:29:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=114
06/18/2022 08:29:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=117
06/18/2022 08:29:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=119
06/18/2022 08:29:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=122
06/18/2022 08:29:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=124
06/18/2022 08:29:46 - INFO - __main__ - Global step 500 Train loss 0.07 Classification-F1 0.7620895865677649 on epoch=124
06/18/2022 08:29:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=127
06/18/2022 08:29:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=129
06/18/2022 08:29:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/18/2022 08:29:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/18/2022 08:29:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=137
06/18/2022 08:29:59 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.7726670520788168 on epoch=137
06/18/2022 08:30:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=139
06/18/2022 08:30:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=142
06/18/2022 08:30:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=144
06/18/2022 08:30:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=147
06/18/2022 08:30:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/18/2022 08:30:13 - INFO - __main__ - Global step 600 Train loss 0.04 Classification-F1 0.7758467023172906 on epoch=149
06/18/2022 08:30:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/18/2022 08:30:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/18/2022 08:30:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=157
06/18/2022 08:30:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=159
06/18/2022 08:30:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=162
06/18/2022 08:30:26 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.7307908809456797 on epoch=162
06/18/2022 08:30:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/18/2022 08:30:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=167
06/18/2022 08:30:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=169
06/18/2022 08:30:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/18/2022 08:30:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/18/2022 08:30:39 - INFO - __main__ - Global step 700 Train loss 0.04 Classification-F1 0.7757575757575758 on epoch=174
06/18/2022 08:30:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/18/2022 08:30:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/18/2022 08:30:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/18/2022 08:30:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/18/2022 08:30:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
06/18/2022 08:30:53 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.7567873303167421 on epoch=187
06/18/2022 08:30:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/18/2022 08:30:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/18/2022 08:31:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/18/2022 08:31:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=197
06/18/2022 08:31:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/18/2022 08:31:06 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7942911255411256 on epoch=199
06/18/2022 08:31:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7902462121212122 -> 0.7942911255411256 on epoch=199, global_step=800
06/18/2022 08:31:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/18/2022 08:31:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/18/2022 08:31:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/18/2022 08:31:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=209
06/18/2022 08:31:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/18/2022 08:31:20 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.7758467023172906 on epoch=212
06/18/2022 08:31:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/18/2022 08:31:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/18/2022 08:31:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=219
06/18/2022 08:31:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/18/2022 08:31:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/18/2022 08:31:34 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7768308080808081 on epoch=224
06/18/2022 08:31:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/18/2022 08:31:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/18/2022 08:31:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/18/2022 08:31:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/18/2022 08:31:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/18/2022 08:31:47 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7470196489593041 on epoch=237
06/18/2022 08:31:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/18/2022 08:31:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/18/2022 08:31:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/18/2022 08:31:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/18/2022 08:32:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/18/2022 08:32:01 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7786637931034482 on epoch=249
06/18/2022 08:32:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/18/2022 08:32:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/18/2022 08:32:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/18/2022 08:32:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/18/2022 08:32:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/18/2022 08:32:14 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7571438365556012 on epoch=262
06/18/2022 08:32:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/18/2022 08:32:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/18/2022 08:32:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/18/2022 08:32:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/18/2022 08:32:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/18/2022 08:32:28 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7724480095068331 on epoch=274
06/18/2022 08:32:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/18/2022 08:32:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/18/2022 08:32:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/18/2022 08:32:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/18/2022 08:32:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/18/2022 08:32:41 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7573815073815074 on epoch=287
06/18/2022 08:32:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/18/2022 08:32:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/18/2022 08:32:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/18/2022 08:32:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/18/2022 08:32:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/18/2022 08:32:55 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.737296494355318 on epoch=299
06/18/2022 08:32:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/18/2022 08:33:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/18/2022 08:33:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/18/2022 08:33:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/18/2022 08:33:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/18/2022 08:33:09 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7573815073815074 on epoch=312
06/18/2022 08:33:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/18/2022 08:33:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/18/2022 08:33:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/18/2022 08:33:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/18/2022 08:33:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/18/2022 08:33:22 - INFO - __main__ - Global step 1300 Train loss 0.00 Classification-F1 0.7768308080808081 on epoch=324
06/18/2022 08:33:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/18/2022 08:33:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/18/2022 08:33:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/18/2022 08:33:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/18/2022 08:33:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/18/2022 08:33:36 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7942911255411256 on epoch=337
06/18/2022 08:33:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/18/2022 08:33:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/18/2022 08:33:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/18/2022 08:33:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/18/2022 08:33:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/18/2022 08:33:50 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.7768308080808081 on epoch=349
06/18/2022 08:33:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/18/2022 08:33:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/18/2022 08:33:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/18/2022 08:34:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/18/2022 08:34:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/18/2022 08:34:03 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7942911255411256 on epoch=362
06/18/2022 08:34:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/18/2022 08:34:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 08:34:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/18/2022 08:34:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/18/2022 08:34:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/18/2022 08:34:16 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7582170688788336 on epoch=374
06/18/2022 08:34:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/18/2022 08:34:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 08:34:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/18/2022 08:34:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/18/2022 08:34:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/18/2022 08:34:30 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7768308080808081 on epoch=387
06/18/2022 08:34:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/18/2022 08:34:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/18/2022 08:34:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/18/2022 08:34:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=397
06/18/2022 08:34:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/18/2022 08:34:43 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7768308080808081 on epoch=399
06/18/2022 08:34:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/18/2022 08:34:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/18/2022 08:34:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/18/2022 08:34:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/18/2022 08:34:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/18/2022 08:34:57 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7614087301587301 on epoch=412
06/18/2022 08:35:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 08:35:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/18/2022 08:35:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/18/2022 08:35:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/18/2022 08:35:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 08:35:11 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.75875504000504 on epoch=424
06/18/2022 08:35:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/18/2022 08:35:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 08:35:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/18/2022 08:35:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/18/2022 08:35:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 08:35:24 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7614087301587301 on epoch=437
06/18/2022 08:35:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/18/2022 08:35:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/18/2022 08:35:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/18/2022 08:35:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/18/2022 08:35:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 08:35:38 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7614087301587301 on epoch=449
06/18/2022 08:35:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/18/2022 08:35:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/18/2022 08:35:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/18/2022 08:35:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/18/2022 08:35:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/18/2022 08:35:51 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7614087301587301 on epoch=462
06/18/2022 08:35:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/18/2022 08:35:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/18/2022 08:35:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 08:36:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/18/2022 08:36:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 08:36:05 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7765931372549019 on epoch=474
06/18/2022 08:36:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/18/2022 08:36:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/18/2022 08:36:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/18/2022 08:36:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 08:36:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 08:36:19 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7768308080808081 on epoch=487
06/18/2022 08:36:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/18/2022 08:36:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/18/2022 08:36:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/18/2022 08:36:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/18/2022 08:36:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/18/2022 08:36:33 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7460728297421845 on epoch=499
06/18/2022 08:36:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/18/2022 08:36:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 08:36:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/18/2022 08:36:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 08:36:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 08:36:47 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7954656862745099 on epoch=512
06/18/2022 08:36:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7942911255411256 -> 0.7954656862745099 on epoch=512, global_step=2050
06/18/2022 08:36:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/18/2022 08:36:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/18/2022 08:36:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 08:36:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/18/2022 08:36:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/18/2022 08:37:01 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7460728297421845 on epoch=524
06/18/2022 08:37:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/18/2022 08:37:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 08:37:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 08:37:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 08:37:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/18/2022 08:37:14 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7573815073815074 on epoch=537
06/18/2022 08:37:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 08:37:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 08:37:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 08:37:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 08:37:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 08:37:28 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7954656862745099 on epoch=549
06/18/2022 08:37:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 08:37:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 08:37:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/18/2022 08:37:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 08:37:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/18/2022 08:37:42 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.8112572223246666 on epoch=562
06/18/2022 08:37:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7954656862745099 -> 0.8112572223246666 on epoch=562, global_step=2250
06/18/2022 08:37:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/18/2022 08:37:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 08:37:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=569
06/18/2022 08:37:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 08:37:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 08:37:55 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8112572223246666 on epoch=574
06/18/2022 08:37:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 08:38:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 08:38:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/18/2022 08:38:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 08:38:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/18/2022 08:38:09 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.8112572223246666 on epoch=587
06/18/2022 08:38:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 08:38:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=592
06/18/2022 08:38:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 08:38:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/18/2022 08:38:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 08:38:23 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=599
06/18/2022 08:38:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/18/2022 08:38:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/18/2022 08:38:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 08:38:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 08:38:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 08:38:36 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7768308080808081 on epoch=612
06/18/2022 08:38:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 08:38:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 08:38:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 08:38:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 08:38:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 08:38:50 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7768308080808081 on epoch=624
06/18/2022 08:38:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 08:38:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 08:38:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 08:39:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/18/2022 08:39:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 08:39:04 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7957905669599218 on epoch=637
06/18/2022 08:39:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 08:39:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 08:39:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.17 on epoch=644
06/18/2022 08:39:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 08:39:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 08:39:18 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8112572223246666 on epoch=649
06/18/2022 08:39:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/18/2022 08:39:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 08:39:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/18/2022 08:39:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/18/2022 08:39:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/18/2022 08:39:31 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7621058558558558 on epoch=662
06/18/2022 08:39:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 08:39:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 08:39:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 08:39:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/18/2022 08:39:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/18/2022 08:39:45 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.779265873015873 on epoch=674
06/18/2022 08:39:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 08:39:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 08:39:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=682
06/18/2022 08:39:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 08:39:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 08:39:59 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=687
06/18/2022 08:40:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 08:40:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 08:40:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 08:40:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 08:40:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 08:40:13 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7768308080808081 on epoch=699
06/18/2022 08:40:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 08:40:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 08:40:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 08:40:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 08:40:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=712
06/18/2022 08:40:26 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8112572223246666 on epoch=712
06/18/2022 08:40:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 08:40:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/18/2022 08:40:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 08:40:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/18/2022 08:40:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 08:40:40 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7768308080808081 on epoch=724
06/18/2022 08:40:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 08:40:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/18/2022 08:40:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 08:40:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 08:40:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 08:40:54 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7954656862745099 on epoch=737
06/18/2022 08:40:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 08:40:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 08:41:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 08:41:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 08:41:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 08:41:07 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7954656862745099 on epoch=749
06/18/2022 08:41:07 - INFO - __main__ - save last model!
06/18/2022 08:41:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 08:41:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 08:41:08 - INFO - __main__ - Printing 3 examples
06/18/2022 08:41:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 08:41:08 - INFO - __main__ - ['others']
06/18/2022 08:41:08 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 08:41:08 - INFO - __main__ - ['others']
06/18/2022 08:41:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 08:41:08 - INFO - __main__ - ['others']
06/18/2022 08:41:08 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:41:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:41:08 - INFO - __main__ - Printing 3 examples
06/18/2022 08:41:08 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 08:41:08 - INFO - __main__ - ['happy']
06/18/2022 08:41:08 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 08:41:08 - INFO - __main__ - ['happy']
06/18/2022 08:41:08 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 08:41:08 - INFO - __main__ - ['happy']
06/18/2022 08:41:08 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:41:08 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:41:08 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:41:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:41:08 - INFO - __main__ - Printing 3 examples
06/18/2022 08:41:08 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 08:41:08 - INFO - __main__ - ['happy']
06/18/2022 08:41:08 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 08:41:08 - INFO - __main__ - ['happy']
06/18/2022 08:41:08 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 08:41:08 - INFO - __main__ - ['happy']
06/18/2022 08:41:08 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:41:08 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:41:08 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:41:10 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:41:15 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 08:41:23 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:41:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:41:24 - INFO - __main__ - Starting training!
06/18/2022 08:42:52 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/18/2022 08:42:52 - INFO - __main__ - Classification-F1 on test data: 0.2138
06/18/2022 08:42:52 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.8112572223246666, test_performance=0.21383150813465687
06/18/2022 08:42:52 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/18/2022 08:42:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:42:53 - INFO - __main__ - Printing 3 examples
06/18/2022 08:42:53 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 08:42:53 - INFO - __main__ - ['happy']
06/18/2022 08:42:53 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 08:42:53 - INFO - __main__ - ['happy']
06/18/2022 08:42:53 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 08:42:53 - INFO - __main__ - ['happy']
06/18/2022 08:42:53 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:42:53 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:42:53 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:42:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:42:53 - INFO - __main__ - Printing 3 examples
06/18/2022 08:42:53 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 08:42:53 - INFO - __main__ - ['happy']
06/18/2022 08:42:53 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 08:42:53 - INFO - __main__ - ['happy']
06/18/2022 08:42:53 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 08:42:53 - INFO - __main__ - ['happy']
06/18/2022 08:42:53 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:42:53 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:42:53 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:43:12 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:43:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:43:13 - INFO - __main__ - Starting training!
06/18/2022 08:43:16 - INFO - __main__ - Step 10 Global step 10 Train loss 3.87 on epoch=2
06/18/2022 08:43:18 - INFO - __main__ - Step 20 Global step 20 Train loss 2.92 on epoch=4
06/18/2022 08:43:21 - INFO - __main__ - Step 30 Global step 30 Train loss 2.14 on epoch=7
06/18/2022 08:43:23 - INFO - __main__ - Step 40 Global step 40 Train loss 1.66 on epoch=9
06/18/2022 08:43:26 - INFO - __main__ - Step 50 Global step 50 Train loss 1.22 on epoch=12
06/18/2022 08:43:27 - INFO - __main__ - Global step 50 Train loss 2.36 Classification-F1 0.2742094253722161 on epoch=12
06/18/2022 08:43:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2742094253722161 on epoch=12, global_step=50
06/18/2022 08:43:29 - INFO - __main__ - Step 60 Global step 60 Train loss 1.17 on epoch=14
06/18/2022 08:43:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/18/2022 08:43:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.83 on epoch=19
06/18/2022 08:43:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=22
06/18/2022 08:43:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=24
06/18/2022 08:43:40 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.40947324034310945 on epoch=24
06/18/2022 08:43:40 - INFO - __main__ - Saving model with best Classification-F1: 0.2742094253722161 -> 0.40947324034310945 on epoch=24, global_step=100
06/18/2022 08:43:43 - INFO - __main__ - Step 110 Global step 110 Train loss 0.62 on epoch=27
06/18/2022 08:43:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.58 on epoch=29
06/18/2022 08:43:48 - INFO - __main__ - Step 130 Global step 130 Train loss 0.52 on epoch=32
06/18/2022 08:43:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=34
06/18/2022 08:43:53 - INFO - __main__ - Step 150 Global step 150 Train loss 0.47 on epoch=37
06/18/2022 08:43:54 - INFO - __main__ - Global step 150 Train loss 0.58 Classification-F1 0.6162229583282215 on epoch=37
06/18/2022 08:43:54 - INFO - __main__ - Saving model with best Classification-F1: 0.40947324034310945 -> 0.6162229583282215 on epoch=37, global_step=150
06/18/2022 08:43:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=39
06/18/2022 08:43:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.50 on epoch=42
06/18/2022 08:44:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.55 on epoch=44
06/18/2022 08:44:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.37 on epoch=47
06/18/2022 08:44:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/18/2022 08:44:07 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.7369510366767835 on epoch=49
06/18/2022 08:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6162229583282215 -> 0.7369510366767835 on epoch=49, global_step=200
06/18/2022 08:44:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=52
06/18/2022 08:44:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=54
06/18/2022 08:44:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=57
06/18/2022 08:44:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=59
06/18/2022 08:44:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=62
06/18/2022 08:44:21 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.7314855875831485 on epoch=62
06/18/2022 08:44:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=64
06/18/2022 08:44:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/18/2022 08:44:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/18/2022 08:44:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=72
06/18/2022 08:44:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=74
06/18/2022 08:44:34 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.7573684210526316 on epoch=74
06/18/2022 08:44:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7369510366767835 -> 0.7573684210526316 on epoch=74, global_step=300
06/18/2022 08:44:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=77
06/18/2022 08:44:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/18/2022 08:44:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/18/2022 08:44:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=84
06/18/2022 08:44:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=87
06/18/2022 08:44:48 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.7717948717948717 on epoch=87
06/18/2022 08:44:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7573684210526316 -> 0.7717948717948717 on epoch=87, global_step=350
06/18/2022 08:44:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/18/2022 08:44:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/18/2022 08:44:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
06/18/2022 08:44:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/18/2022 08:45:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=99
06/18/2022 08:45:01 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.7521739130434782 on epoch=99
06/18/2022 08:45:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/18/2022 08:45:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/18/2022 08:45:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/18/2022 08:45:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=109
06/18/2022 08:45:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=112
06/18/2022 08:45:15 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.7857349327937564 on epoch=112
06/18/2022 08:45:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7717948717948717 -> 0.7857349327937564 on epoch=112, global_step=450
06/18/2022 08:45:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
06/18/2022 08:45:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=117
06/18/2022 08:45:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=119
06/18/2022 08:45:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=122
06/18/2022 08:45:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=124
06/18/2022 08:45:28 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.7720588235294118 on epoch=124
06/18/2022 08:45:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.09 on epoch=127
06/18/2022 08:45:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/18/2022 08:45:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=132
06/18/2022 08:45:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=134
06/18/2022 08:45:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=137
06/18/2022 08:45:41 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.7720588235294118 on epoch=137
06/18/2022 08:45:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/18/2022 08:45:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/18/2022 08:45:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/18/2022 08:45:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/18/2022 08:45:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/18/2022 08:45:55 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.7218996689584926 on epoch=149
06/18/2022 08:45:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/18/2022 08:46:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=154
06/18/2022 08:46:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/18/2022 08:46:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/18/2022 08:46:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/18/2022 08:46:08 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.7075519232083077 on epoch=162
06/18/2022 08:46:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/18/2022 08:46:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/18/2022 08:46:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/18/2022 08:46:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/18/2022 08:46:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/18/2022 08:46:22 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.7853472222222222 on epoch=174
06/18/2022 08:46:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
06/18/2022 08:46:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/18/2022 08:46:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=182
06/18/2022 08:46:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/18/2022 08:46:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/18/2022 08:46:35 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.7373366013071896 on epoch=187
06/18/2022 08:46:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/18/2022 08:46:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/18/2022 08:46:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/18/2022 08:46:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=197
06/18/2022 08:46:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/18/2022 08:46:48 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.777917358165837 on epoch=199
06/18/2022 08:46:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/18/2022 08:46:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/18/2022 08:46:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/18/2022 08:46:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/18/2022 08:47:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/18/2022 08:47:02 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.76195436006337 on epoch=212
06/18/2022 08:47:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/18/2022 08:47:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/18/2022 08:47:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/18/2022 08:47:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/18/2022 08:47:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/18/2022 08:47:15 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7319690113807761 on epoch=224
06/18/2022 08:47:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/18/2022 08:47:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/18/2022 08:47:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/18/2022 08:47:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/18/2022 08:47:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/18/2022 08:47:28 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.737296494355318 on epoch=237
06/18/2022 08:47:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/18/2022 08:47:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/18/2022 08:47:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/18/2022 08:47:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/18/2022 08:47:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/18/2022 08:47:42 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7943802521008404 on epoch=249
06/18/2022 08:47:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7857349327937564 -> 0.7943802521008404 on epoch=249, global_step=1000
06/18/2022 08:47:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/18/2022 08:47:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/18/2022 08:47:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/18/2022 08:47:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/18/2022 08:47:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=262
06/18/2022 08:47:55 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7639299725993274 on epoch=262
06/18/2022 08:47:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/18/2022 08:48:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/18/2022 08:48:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/18/2022 08:48:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/18/2022 08:48:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/18/2022 08:48:09 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7940158430143218 on epoch=274
06/18/2022 08:48:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/18/2022 08:48:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/18/2022 08:48:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/18/2022 08:48:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/18/2022 08:48:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/18/2022 08:48:22 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7757575757575758 on epoch=287
06/18/2022 08:48:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/18/2022 08:48:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/18/2022 08:48:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=294
06/18/2022 08:48:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/18/2022 08:48:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/18/2022 08:48:36 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7942911255411256 on epoch=299
06/18/2022 08:48:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/18/2022 08:48:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/18/2022 08:48:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/18/2022 08:48:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/18/2022 08:48:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/18/2022 08:48:49 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7940158430143218 on epoch=312
06/18/2022 08:48:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/18/2022 08:48:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/18/2022 08:48:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/18/2022 08:48:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/18/2022 08:49:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/18/2022 08:49:02 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.779265873015873 on epoch=324
06/18/2022 08:49:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/18/2022 08:49:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/18/2022 08:49:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/18/2022 08:49:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/18/2022 08:49:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/18/2022 08:49:16 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7566982037570273 on epoch=337
06/18/2022 08:49:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/18/2022 08:49:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/18/2022 08:49:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/18/2022 08:49:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/18/2022 08:49:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/18/2022 08:49:29 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=349
06/18/2022 08:49:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/18/2022 08:49:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/18/2022 08:49:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/18/2022 08:49:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/18/2022 08:49:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/18/2022 08:49:43 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7942911255411256 on epoch=362
06/18/2022 08:49:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/18/2022 08:49:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/18/2022 08:49:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/18/2022 08:49:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/18/2022 08:49:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/18/2022 08:49:56 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=374
06/18/2022 08:49:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/18/2022 08:50:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/18/2022 08:50:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 08:50:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/18/2022 08:50:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/18/2022 08:50:09 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7942911255411256 on epoch=387
06/18/2022 08:50:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/18/2022 08:50:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/18/2022 08:50:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/18/2022 08:50:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/18/2022 08:50:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/18/2022 08:50:23 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.779265873015873 on epoch=399
06/18/2022 08:50:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 08:50:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 08:50:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 08:50:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/18/2022 08:50:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/18/2022 08:50:36 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=412
06/18/2022 08:50:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 08:50:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/18/2022 08:50:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/18/2022 08:50:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/18/2022 08:50:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/18/2022 08:50:49 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.779265873015873 on epoch=424
06/18/2022 08:50:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/18/2022 08:50:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/18/2022 08:50:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 08:50:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/18/2022 08:51:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 08:51:03 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.779265873015873 on epoch=437
06/18/2022 08:51:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/18/2022 08:51:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/18/2022 08:51:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/18/2022 08:51:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/18/2022 08:51:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 08:51:16 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7639299725993274 on epoch=449
06/18/2022 08:51:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/18/2022 08:51:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/18/2022 08:51:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/18/2022 08:51:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/18/2022 08:51:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 08:51:30 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7942911255411256 on epoch=462
06/18/2022 08:51:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=464
06/18/2022 08:51:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/18/2022 08:51:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/18/2022 08:51:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/18/2022 08:51:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/18/2022 08:51:43 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7231812840508492 on epoch=474
06/18/2022 08:51:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/18/2022 08:51:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=479
06/18/2022 08:51:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 08:51:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 08:51:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/18/2022 08:51:57 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7392951251646904 on epoch=487
06/18/2022 08:51:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/18/2022 08:52:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/18/2022 08:52:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=494
06/18/2022 08:52:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/18/2022 08:52:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/18/2022 08:52:10 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.779265873015873 on epoch=499
06/18/2022 08:52:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 08:52:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/18/2022 08:52:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/18/2022 08:52:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/18/2022 08:52:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 08:52:23 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7225715421303657 on epoch=512
06/18/2022 08:52:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 08:52:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/18/2022 08:52:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 08:52:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/18/2022 08:52:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/18/2022 08:52:37 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7757575757575758 on epoch=524
06/18/2022 08:52:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/18/2022 08:52:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/18/2022 08:52:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 08:52:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/18/2022 08:52:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/18/2022 08:52:50 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7571438365556012 on epoch=537
06/18/2022 08:52:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/18/2022 08:52:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 08:52:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 08:53:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 08:53:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/18/2022 08:53:04 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7566982037570273 on epoch=549
06/18/2022 08:53:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/18/2022 08:53:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/18/2022 08:53:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 08:53:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 08:53:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/18/2022 08:53:17 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7616792929292928 on epoch=562
06/18/2022 08:53:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/18/2022 08:53:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 08:53:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 08:53:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 08:53:30 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 08:53:31 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7285280293026473 on epoch=574
06/18/2022 08:53:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 08:53:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 08:53:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/18/2022 08:53:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=584
06/18/2022 08:53:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/18/2022 08:53:44 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7443066801619433 on epoch=587
06/18/2022 08:53:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/18/2022 08:53:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 08:53:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 08:53:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/18/2022 08:53:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 08:53:58 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7582170688788336 on epoch=599
06/18/2022 08:54:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 08:54:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/18/2022 08:54:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 08:54:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 08:54:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 08:54:11 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7765931372549019 on epoch=612
06/18/2022 08:54:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/18/2022 08:54:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/18/2022 08:54:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/18/2022 08:54:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 08:54:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 08:54:25 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7422299922299922 on epoch=624
06/18/2022 08:54:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 08:54:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 08:54:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 08:54:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 08:54:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/18/2022 08:54:38 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7765931372549019 on epoch=637
06/18/2022 08:54:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 08:54:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 08:54:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 08:54:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 08:54:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 08:54:52 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7582170688788336 on epoch=649
06/18/2022 08:54:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.15 on epoch=652
06/18/2022 08:54:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 08:54:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=657
06/18/2022 08:55:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 08:55:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 08:55:05 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.75875504000504 on epoch=662
06/18/2022 08:55:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 08:55:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 08:55:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 08:55:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 08:55:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 08:55:19 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7765931372549019 on epoch=674
06/18/2022 08:55:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 08:55:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 08:55:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 08:55:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=684
06/18/2022 08:55:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/18/2022 08:55:33 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7765931372549019 on epoch=687
06/18/2022 08:55:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 08:55:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 08:55:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 08:55:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 08:55:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 08:55:46 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7718497189085425 on epoch=699
06/18/2022 08:55:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 08:55:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/18/2022 08:55:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 08:55:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/18/2022 08:55:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/18/2022 08:56:00 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7571438365556012 on epoch=712
06/18/2022 08:56:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=714
06/18/2022 08:56:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 08:56:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 08:56:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/18/2022 08:56:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 08:56:14 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7517156862745098 on epoch=724
06/18/2022 08:56:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=727
06/18/2022 08:56:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 08:56:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 08:56:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 08:56:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 08:56:27 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7757575757575758 on epoch=737
06/18/2022 08:56:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 08:56:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 08:56:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 08:56:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 08:56:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/18/2022 08:56:41 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7287878787878788 on epoch=749
06/18/2022 08:56:41 - INFO - __main__ - save last model!
06/18/2022 08:56:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 08:56:41 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 08:56:41 - INFO - __main__ - Printing 3 examples
06/18/2022 08:56:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 08:56:41 - INFO - __main__ - ['others']
06/18/2022 08:56:41 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 08:56:41 - INFO - __main__ - ['others']
06/18/2022 08:56:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 08:56:41 - INFO - __main__ - ['others']
06/18/2022 08:56:41 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:56:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:56:41 - INFO - __main__ - Printing 3 examples
06/18/2022 08:56:41 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 08:56:41 - INFO - __main__ - ['happy']
06/18/2022 08:56:41 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 08:56:41 - INFO - __main__ - ['happy']
06/18/2022 08:56:41 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 08:56:41 - INFO - __main__ - ['happy']
06/18/2022 08:56:41 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:56:41 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:56:41 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:56:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:56:41 - INFO - __main__ - Printing 3 examples
06/18/2022 08:56:41 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 08:56:41 - INFO - __main__ - ['happy']
06/18/2022 08:56:41 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 08:56:41 - INFO - __main__ - ['happy']
06/18/2022 08:56:41 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 08:56:41 - INFO - __main__ - ['happy']
06/18/2022 08:56:41 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:56:41 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:56:41 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:56:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:56:49 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 08:56:57 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:56:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:56:58 - INFO - __main__ - Starting training!
06/18/2022 08:58:21 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/18/2022 08:58:22 - INFO - __main__ - Classification-F1 on test data: 0.1447
06/18/2022 08:58:22 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.7943802521008404, test_performance=0.14469284191799037
06/18/2022 08:58:22 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/18/2022 08:58:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:58:23 - INFO - __main__ - Printing 3 examples
06/18/2022 08:58:23 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 08:58:23 - INFO - __main__ - ['happy']
06/18/2022 08:58:23 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 08:58:23 - INFO - __main__ - ['happy']
06/18/2022 08:58:23 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 08:58:23 - INFO - __main__ - ['happy']
06/18/2022 08:58:23 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:58:23 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:58:23 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 08:58:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 08:58:23 - INFO - __main__ - Printing 3 examples
06/18/2022 08:58:23 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 08:58:23 - INFO - __main__ - ['happy']
06/18/2022 08:58:23 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 08:58:23 - INFO - __main__ - ['happy']
06/18/2022 08:58:23 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 08:58:23 - INFO - __main__ - ['happy']
06/18/2022 08:58:23 - INFO - __main__ - Tokenizing Input ...
06/18/2022 08:58:23 - INFO - __main__ - Tokenizing Output ...
06/18/2022 08:58:23 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 08:58:42 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 08:58:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 08:58:42 - INFO - __main__ - Starting training!
06/18/2022 08:58:45 - INFO - __main__ - Step 10 Global step 10 Train loss 4.17 on epoch=2
06/18/2022 08:58:48 - INFO - __main__ - Step 20 Global step 20 Train loss 3.18 on epoch=4
06/18/2022 08:58:50 - INFO - __main__ - Step 30 Global step 30 Train loss 2.55 on epoch=7
06/18/2022 08:58:53 - INFO - __main__ - Step 40 Global step 40 Train loss 2.07 on epoch=9
06/18/2022 08:58:55 - INFO - __main__ - Step 50 Global step 50 Train loss 1.79 on epoch=12
06/18/2022 08:58:57 - INFO - __main__ - Global step 50 Train loss 2.75 Classification-F1 0.08567012789901346 on epoch=12
06/18/2022 08:58:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08567012789901346 on epoch=12, global_step=50
06/18/2022 08:58:59 - INFO - __main__ - Step 60 Global step 60 Train loss 1.50 on epoch=14
06/18/2022 08:59:02 - INFO - __main__ - Step 70 Global step 70 Train loss 1.15 on epoch=17
06/18/2022 08:59:04 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=19
06/18/2022 08:59:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=22
06/18/2022 08:59:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=24
06/18/2022 08:59:10 - INFO - __main__ - Global step 100 Train loss 1.07 Classification-F1 0.356890973443641 on epoch=24
06/18/2022 08:59:10 - INFO - __main__ - Saving model with best Classification-F1: 0.08567012789901346 -> 0.356890973443641 on epoch=24, global_step=100
06/18/2022 08:59:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=27
06/18/2022 08:59:15 - INFO - __main__ - Step 120 Global step 120 Train loss 0.61 on epoch=29
06/18/2022 08:59:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=32
06/18/2022 08:59:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=34
06/18/2022 08:59:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.57 on epoch=37
06/18/2022 08:59:24 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.5195265423242468 on epoch=37
06/18/2022 08:59:24 - INFO - __main__ - Saving model with best Classification-F1: 0.356890973443641 -> 0.5195265423242468 on epoch=37, global_step=150
06/18/2022 08:59:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=39
06/18/2022 08:59:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=42
06/18/2022 08:59:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/18/2022 08:59:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=47
06/18/2022 08:59:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=49
06/18/2022 08:59:37 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.7641733870967742 on epoch=49
06/18/2022 08:59:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5195265423242468 -> 0.7641733870967742 on epoch=49, global_step=200
06/18/2022 08:59:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=52
06/18/2022 08:59:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=54
06/18/2022 08:59:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=57
06/18/2022 08:59:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
06/18/2022 08:59:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.41 on epoch=62
06/18/2022 08:59:51 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.6820887445887446 on epoch=62
06/18/2022 08:59:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=64
06/18/2022 08:59:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
06/18/2022 08:59:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=69
06/18/2022 09:00:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=72
06/18/2022 09:00:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/18/2022 09:00:04 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.7634906597774245 on epoch=74
06/18/2022 09:00:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=77
06/18/2022 09:00:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=79
06/18/2022 09:00:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=82
06/18/2022 09:00:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=84
06/18/2022 09:00:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=87
06/18/2022 09:00:18 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.7668220926322351 on epoch=87
06/18/2022 09:00:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7641733870967742 -> 0.7668220926322351 on epoch=87, global_step=350
06/18/2022 09:00:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=89
06/18/2022 09:00:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
06/18/2022 09:00:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=94
06/18/2022 09:00:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=97
06/18/2022 09:00:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
06/18/2022 09:00:31 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.8057725279106858 on epoch=99
06/18/2022 09:00:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7668220926322351 -> 0.8057725279106858 on epoch=99, global_step=400
06/18/2022 09:00:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/18/2022 09:00:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=104
06/18/2022 09:00:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/18/2022 09:00:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
06/18/2022 09:00:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=112
06/18/2022 09:00:45 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.8052235691573927 on epoch=112
06/18/2022 09:00:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=114
06/18/2022 09:00:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/18/2022 09:00:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/18/2022 09:00:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/18/2022 09:00:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
06/18/2022 09:00:58 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.8052235691573927 on epoch=124
06/18/2022 09:01:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/18/2022 09:01:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=129
06/18/2022 09:01:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/18/2022 09:01:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/18/2022 09:01:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/18/2022 09:01:11 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7904176093514329 on epoch=137
06/18/2022 09:01:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/18/2022 09:01:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
06/18/2022 09:01:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/18/2022 09:01:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/18/2022 09:01:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=149
06/18/2022 09:01:25 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7901475279106858 on epoch=149
06/18/2022 09:01:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=152
06/18/2022 09:01:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/18/2022 09:01:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/18/2022 09:01:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/18/2022 09:01:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=162
06/18/2022 09:01:38 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7519354392755928 on epoch=162
06/18/2022 09:01:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/18/2022 09:01:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
06/18/2022 09:01:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
06/18/2022 09:01:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/18/2022 09:01:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=174
06/18/2022 09:01:52 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7907978043461914 on epoch=174
06/18/2022 09:01:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/18/2022 09:01:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/18/2022 09:01:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/18/2022 09:02:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/18/2022 09:02:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=187
06/18/2022 09:02:05 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.8053071253071253 on epoch=187
06/18/2022 09:02:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/18/2022 09:02:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/18/2022 09:02:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/18/2022 09:02:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=197
06/18/2022 09:02:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=199
06/18/2022 09:02:19 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7763746057863705 on epoch=199
06/18/2022 09:02:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/18/2022 09:02:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/18/2022 09:02:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
06/18/2022 09:02:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/18/2022 09:02:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
06/18/2022 09:02:32 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7763746057863705 on epoch=212
06/18/2022 09:02:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/18/2022 09:02:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/18/2022 09:02:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=219
06/18/2022 09:02:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/18/2022 09:02:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/18/2022 09:02:45 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7577421271538919 on epoch=224
06/18/2022 09:02:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
06/18/2022 09:02:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/18/2022 09:02:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/18/2022 09:02:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/18/2022 09:02:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/18/2022 09:02:59 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7577421271538919 on epoch=237
06/18/2022 09:03:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/18/2022 09:03:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/18/2022 09:03:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=244
06/18/2022 09:03:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/18/2022 09:03:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=249
06/18/2022 09:03:13 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7943802521008404 on epoch=249
06/18/2022 09:03:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/18/2022 09:03:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=254
06/18/2022 09:03:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/18/2022 09:03:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=259
06/18/2022 09:03:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=262
06/18/2022 09:03:26 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8112572223246666 on epoch=262
06/18/2022 09:03:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8057725279106858 -> 0.8112572223246666 on epoch=262, global_step=1050
06/18/2022 09:03:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/18/2022 09:03:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=267
06/18/2022 09:03:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/18/2022 09:03:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/18/2022 09:03:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/18/2022 09:03:40 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7763746057863705 on epoch=274
06/18/2022 09:03:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/18/2022 09:03:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/18/2022 09:03:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/18/2022 09:03:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/18/2022 09:03:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/18/2022 09:03:53 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7910804881393116 on epoch=287
06/18/2022 09:03:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/18/2022 09:03:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/18/2022 09:04:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/18/2022 09:04:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/18/2022 09:04:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/18/2022 09:04:06 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7910804881393116 on epoch=299
06/18/2022 09:04:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/18/2022 09:04:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/18/2022 09:04:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/18/2022 09:04:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/18/2022 09:04:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/18/2022 09:04:20 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7910804881393116 on epoch=312
06/18/2022 09:04:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/18/2022 09:04:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/18/2022 09:04:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/18/2022 09:04:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/18/2022 09:04:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/18/2022 09:04:33 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7910804881393116 on epoch=324
06/18/2022 09:04:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/18/2022 09:04:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/18/2022 09:04:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/18/2022 09:04:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/18/2022 09:04:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/18/2022 09:04:47 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7910804881393116 on epoch=337
06/18/2022 09:04:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/18/2022 09:04:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/18/2022 09:04:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/18/2022 09:04:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/18/2022 09:04:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/18/2022 09:05:00 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7943802521008404 on epoch=349
06/18/2022 09:05:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/18/2022 09:05:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/18/2022 09:05:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/18/2022 09:05:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=359
06/18/2022 09:05:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/18/2022 09:05:13 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7942911255411256 on epoch=362
06/18/2022 09:05:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/18/2022 09:05:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/18/2022 09:05:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/18/2022 09:05:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/18/2022 09:05:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/18/2022 09:05:27 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=374
06/18/2022 09:05:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/18/2022 09:05:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 09:05:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 09:05:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/18/2022 09:05:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/18/2022 09:05:40 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8098175381263616 on epoch=387
06/18/2022 09:05:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/18/2022 09:05:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 09:05:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/18/2022 09:05:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/18/2022 09:05:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/18/2022 09:05:53 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7648624896608769 on epoch=399
06/18/2022 09:05:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 09:05:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 09:06:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/18/2022 09:06:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 09:06:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/18/2022 09:06:07 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7724480095068331 on epoch=412
06/18/2022 09:06:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/18/2022 09:06:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/18/2022 09:06:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/18/2022 09:06:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/18/2022 09:06:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 09:06:20 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7768308080808081 on epoch=424
06/18/2022 09:06:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/18/2022 09:06:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 09:06:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
06/18/2022 09:06:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/18/2022 09:06:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/18/2022 09:06:34 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7774478381096028 on epoch=437
06/18/2022 09:06:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/18/2022 09:06:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
06/18/2022 09:06:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/18/2022 09:06:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/18/2022 09:06:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=449
06/18/2022 09:06:48 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.787372934431758 on epoch=449
06/18/2022 09:06:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/18/2022 09:06:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/18/2022 09:06:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/18/2022 09:06:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/18/2022 09:07:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/18/2022 09:07:01 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.791826923076923 on epoch=462
06/18/2022 09:07:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/18/2022 09:07:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 09:07:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 09:07:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/18/2022 09:07:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/18/2022 09:07:15 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8269432773109244 on epoch=474
06/18/2022 09:07:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8112572223246666 -> 0.8269432773109244 on epoch=474, global_step=1900
06/18/2022 09:07:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/18/2022 09:07:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/18/2022 09:07:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/18/2022 09:07:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/18/2022 09:07:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 09:07:28 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8098175381263616 on epoch=487
06/18/2022 09:07:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 09:07:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/18/2022 09:07:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 09:07:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/18/2022 09:07:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/18/2022 09:07:42 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7921537204625441 on epoch=499
06/18/2022 09:07:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/18/2022 09:07:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/18/2022 09:07:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/18/2022 09:07:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=509
06/18/2022 09:07:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 09:07:56 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8112572223246666 on epoch=512
06/18/2022 09:07:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 09:08:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/18/2022 09:08:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/18/2022 09:08:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/18/2022 09:08:08 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/18/2022 09:08:09 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8112572223246666 on epoch=524
06/18/2022 09:08:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/18/2022 09:08:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/18/2022 09:08:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/18/2022 09:08:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 09:08:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/18/2022 09:08:23 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7931373243873243 on epoch=537
06/18/2022 09:08:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/18/2022 09:08:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/18/2022 09:08:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 09:08:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 09:08:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 09:08:36 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8098175381263616 on epoch=549
06/18/2022 09:08:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/18/2022 09:08:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/18/2022 09:08:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/18/2022 09:08:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=559
06/18/2022 09:08:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/18/2022 09:08:50 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8269432773109244 on epoch=562
06/18/2022 09:08:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/18/2022 09:08:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 09:08:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 09:09:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 09:09:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 09:09:03 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.8098175381263616 on epoch=574
06/18/2022 09:09:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 09:09:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 09:09:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/18/2022 09:09:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/18/2022 09:09:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 09:09:17 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7795026881720429 on epoch=587
06/18/2022 09:09:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/18/2022 09:09:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/18/2022 09:09:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 09:09:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/18/2022 09:09:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 09:09:31 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=599
06/18/2022 09:09:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/18/2022 09:09:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/18/2022 09:09:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 09:09:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/18/2022 09:09:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/18/2022 09:09:44 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8112572223246666 on epoch=612
06/18/2022 09:09:47 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/18/2022 09:09:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/18/2022 09:09:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/18/2022 09:09:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 09:09:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/18/2022 09:09:58 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8098175381263616 on epoch=624
06/18/2022 09:10:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 09:10:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/18/2022 09:10:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 09:10:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/18/2022 09:10:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 09:10:12 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8112572223246666 on epoch=637
06/18/2022 09:10:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 09:10:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 09:10:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 09:10:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 09:10:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 09:10:25 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.8112572223246666 on epoch=649
06/18/2022 09:10:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/18/2022 09:10:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/18/2022 09:10:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/18/2022 09:10:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/18/2022 09:10:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/18/2022 09:10:39 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8243897306397306 on epoch=662
06/18/2022 09:10:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/18/2022 09:10:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 09:10:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 09:10:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/18/2022 09:10:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 09:10:52 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8415854978354979 on epoch=674
06/18/2022 09:10:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8269432773109244 -> 0.8415854978354979 on epoch=674, global_step=2700
06/18/2022 09:10:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 09:10:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/18/2022 09:11:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/18/2022 09:11:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/18/2022 09:11:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 09:11:06 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.791826923076923 on epoch=687
06/18/2022 09:11:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/18/2022 09:11:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/18/2022 09:11:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/18/2022 09:11:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/18/2022 09:11:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 09:11:20 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.791826923076923 on epoch=699
06/18/2022 09:11:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/18/2022 09:11:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 09:11:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 09:11:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/18/2022 09:11:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=712
06/18/2022 09:11:33 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.791826923076923 on epoch=712
06/18/2022 09:11:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 09:11:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 09:11:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.10 on epoch=719
06/18/2022 09:11:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 09:11:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 09:11:47 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7942911255411256 on epoch=724
06/18/2022 09:11:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/18/2022 09:11:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 09:11:55 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 09:11:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/18/2022 09:12:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 09:12:01 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7942911255411256 on epoch=737
06/18/2022 09:12:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/18/2022 09:12:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 09:12:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 09:12:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 09:12:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 09:12:14 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7765931372549019 on epoch=749
06/18/2022 09:12:14 - INFO - __main__ - save last model!
06/18/2022 09:12:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 09:12:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:12:14 - INFO - __main__ - Printing 3 examples
06/18/2022 09:12:14 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 09:12:14 - INFO - __main__ - ['happy']
06/18/2022 09:12:14 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 09:12:14 - INFO - __main__ - ['happy']
06/18/2022 09:12:14 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 09:12:14 - INFO - __main__ - ['happy']
06/18/2022 09:12:14 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:12:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 09:12:14 - INFO - __main__ - Printing 3 examples
06/18/2022 09:12:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 09:12:14 - INFO - __main__ - ['others']
06/18/2022 09:12:14 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 09:12:14 - INFO - __main__ - ['others']
06/18/2022 09:12:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 09:12:14 - INFO - __main__ - ['others']
06/18/2022 09:12:14 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:12:14 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:12:15 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:12:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:12:15 - INFO - __main__ - Printing 3 examples
06/18/2022 09:12:15 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 09:12:15 - INFO - __main__ - ['happy']
06/18/2022 09:12:15 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 09:12:15 - INFO - __main__ - ['happy']
06/18/2022 09:12:15 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 09:12:15 - INFO - __main__ - ['happy']
06/18/2022 09:12:15 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:12:15 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:12:15 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:12:17 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:12:22 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 09:12:31 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:12:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:12:32 - INFO - __main__ - Starting training!
06/18/2022 09:13:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/18/2022 09:13:57 - INFO - __main__ - Classification-F1 on test data: 0.1254
06/18/2022 09:13:57 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.8415854978354979, test_performance=0.12539920362286308
06/18/2022 09:13:57 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/18/2022 09:13:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:13:58 - INFO - __main__ - Printing 3 examples
06/18/2022 09:13:58 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/18/2022 09:13:58 - INFO - __main__ - ['happy']
06/18/2022 09:13:58 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/18/2022 09:13:58 - INFO - __main__ - ['happy']
06/18/2022 09:13:58 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/18/2022 09:13:58 - INFO - __main__ - ['happy']
06/18/2022 09:13:58 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:13:58 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:13:58 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:13:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:13:58 - INFO - __main__ - Printing 3 examples
06/18/2022 09:13:58 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/18/2022 09:13:58 - INFO - __main__ - ['happy']
06/18/2022 09:13:58 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/18/2022 09:13:58 - INFO - __main__ - ['happy']
06/18/2022 09:13:58 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/18/2022 09:13:58 - INFO - __main__ - ['happy']
06/18/2022 09:13:58 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:13:58 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:13:59 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:14:17 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:14:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:14:18 - INFO - __main__ - Starting training!
06/18/2022 09:14:21 - INFO - __main__ - Step 10 Global step 10 Train loss 4.30 on epoch=2
06/18/2022 09:14:23 - INFO - __main__ - Step 20 Global step 20 Train loss 3.43 on epoch=4
06/18/2022 09:14:26 - INFO - __main__ - Step 30 Global step 30 Train loss 2.84 on epoch=7
06/18/2022 09:14:28 - INFO - __main__ - Step 40 Global step 40 Train loss 2.59 on epoch=9
06/18/2022 09:14:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.09 on epoch=12
06/18/2022 09:14:33 - INFO - __main__ - Global step 50 Train loss 3.05 Classification-F1 0.029333955804544037 on epoch=12
06/18/2022 09:14:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.029333955804544037 on epoch=12, global_step=50
06/18/2022 09:14:35 - INFO - __main__ - Step 60 Global step 60 Train loss 1.88 on epoch=14
06/18/2022 09:14:38 - INFO - __main__ - Step 70 Global step 70 Train loss 1.58 on epoch=17
06/18/2022 09:14:40 - INFO - __main__ - Step 80 Global step 80 Train loss 1.50 on epoch=19
06/18/2022 09:14:43 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=22
06/18/2022 09:14:45 - INFO - __main__ - Step 100 Global step 100 Train loss 1.14 on epoch=24
06/18/2022 09:14:46 - INFO - __main__ - Global step 100 Train loss 1.47 Classification-F1 0.3002256130935694 on epoch=24
06/18/2022 09:14:46 - INFO - __main__ - Saving model with best Classification-F1: 0.029333955804544037 -> 0.3002256130935694 on epoch=24, global_step=100
06/18/2022 09:14:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/18/2022 09:14:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=29
06/18/2022 09:14:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=32
06/18/2022 09:14:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=34
06/18/2022 09:14:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.77 on epoch=37
06/18/2022 09:15:00 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.38494163936089437 on epoch=37
06/18/2022 09:15:00 - INFO - __main__ - Saving model with best Classification-F1: 0.3002256130935694 -> 0.38494163936089437 on epoch=37, global_step=150
06/18/2022 09:15:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/18/2022 09:15:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
06/18/2022 09:15:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.78 on epoch=44
06/18/2022 09:15:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=47
06/18/2022 09:15:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.62 on epoch=49
06/18/2022 09:15:14 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.6724639445156331 on epoch=49
06/18/2022 09:15:14 - INFO - __main__ - Saving model with best Classification-F1: 0.38494163936089437 -> 0.6724639445156331 on epoch=49, global_step=200
06/18/2022 09:15:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=52
06/18/2022 09:15:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=54
06/18/2022 09:15:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=57
06/18/2022 09:15:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=59
06/18/2022 09:15:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=62
06/18/2022 09:15:27 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.6227692075015123 on epoch=62
06/18/2022 09:15:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=64
06/18/2022 09:15:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=67
06/18/2022 09:15:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=69
06/18/2022 09:15:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=72
06/18/2022 09:15:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=74
06/18/2022 09:15:41 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.7069215865552072 on epoch=74
06/18/2022 09:15:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6724639445156331 -> 0.7069215865552072 on epoch=74, global_step=300
06/18/2022 09:15:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
06/18/2022 09:15:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=79
06/18/2022 09:15:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/18/2022 09:15:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=84
06/18/2022 09:15:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
06/18/2022 09:15:54 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.7199582027168234 on epoch=87
06/18/2022 09:15:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7069215865552072 -> 0.7199582027168234 on epoch=87, global_step=350
06/18/2022 09:15:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.51 on epoch=89
06/18/2022 09:15:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=92
06/18/2022 09:16:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=94
06/18/2022 09:16:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=97
06/18/2022 09:16:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=99
06/18/2022 09:16:08 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.7179476733465129 on epoch=99
06/18/2022 09:16:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=102
06/18/2022 09:16:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=104
06/18/2022 09:16:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=107
06/18/2022 09:16:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=109
06/18/2022 09:16:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=112
06/18/2022 09:16:21 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.7179476733465129 on epoch=112
06/18/2022 09:16:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
06/18/2022 09:16:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=117
06/18/2022 09:16:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/18/2022 09:16:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=122
06/18/2022 09:16:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=124
06/18/2022 09:16:35 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.7365115505375003 on epoch=124
06/18/2022 09:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7199582027168234 -> 0.7365115505375003 on epoch=124, global_step=500
06/18/2022 09:16:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=127
06/18/2022 09:16:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=129
06/18/2022 09:16:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=132
06/18/2022 09:16:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/18/2022 09:16:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=137
06/18/2022 09:16:48 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7922983870967742 on epoch=137
06/18/2022 09:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7365115505375003 -> 0.7922983870967742 on epoch=137, global_step=550
06/18/2022 09:16:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=139
06/18/2022 09:16:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=142
06/18/2022 09:16:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=144
06/18/2022 09:16:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/18/2022 09:17:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=149
06/18/2022 09:17:02 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.7362735299017158 on epoch=149
06/18/2022 09:17:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/18/2022 09:17:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=154
06/18/2022 09:17:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/18/2022 09:17:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/18/2022 09:17:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=162
06/18/2022 09:17:15 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.7517465626161277 on epoch=162
06/18/2022 09:17:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/18/2022 09:17:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=167
06/18/2022 09:17:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/18/2022 09:17:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=172
06/18/2022 09:17:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=174
06/18/2022 09:17:29 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.7739098300073909 on epoch=174
06/18/2022 09:17:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
06/18/2022 09:17:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/18/2022 09:17:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/18/2022 09:17:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/18/2022 09:17:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=187
06/18/2022 09:17:42 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.7910105580693816 on epoch=187
06/18/2022 09:17:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=189
06/18/2022 09:17:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/18/2022 09:17:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/18/2022 09:17:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/18/2022 09:17:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/18/2022 09:17:56 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.8057725279106858 on epoch=199
06/18/2022 09:17:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7922983870967742 -> 0.8057725279106858 on epoch=199, global_step=800
06/18/2022 09:17:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=202
06/18/2022 09:18:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/18/2022 09:18:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/18/2022 09:18:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/18/2022 09:18:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/18/2022 09:18:09 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7521739130434782 on epoch=212
06/18/2022 09:18:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/18/2022 09:18:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=217
06/18/2022 09:18:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=219
06/18/2022 09:18:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
06/18/2022 09:18:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/18/2022 09:18:23 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7669795375265221 on epoch=224
06/18/2022 09:18:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=227
06/18/2022 09:18:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/18/2022 09:18:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=232
06/18/2022 09:18:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/18/2022 09:18:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/18/2022 09:18:36 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.771969696969697 on epoch=237
06/18/2022 09:18:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/18/2022 09:18:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/18/2022 09:18:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/18/2022 09:18:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=247
06/18/2022 09:18:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=249
06/18/2022 09:18:50 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7575834748160725 on epoch=249
06/18/2022 09:18:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=252
06/18/2022 09:18:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/18/2022 09:18:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/18/2022 09:19:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/18/2022 09:19:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=262
06/18/2022 09:19:03 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7380299924479448 on epoch=262
06/18/2022 09:19:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=264
06/18/2022 09:19:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=267
06/18/2022 09:19:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/18/2022 09:19:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/18/2022 09:19:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=274
06/18/2022 09:19:17 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.756969696969697 on epoch=274
06/18/2022 09:19:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/18/2022 09:19:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/18/2022 09:19:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/18/2022 09:19:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/18/2022 09:19:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=287
06/18/2022 09:19:30 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.771969696969697 on epoch=287
06/18/2022 09:19:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/18/2022 09:19:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
06/18/2022 09:19:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/18/2022 09:19:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/18/2022 09:19:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/18/2022 09:19:44 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7381475225225225 on epoch=299
06/18/2022 09:19:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/18/2022 09:19:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/18/2022 09:19:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=307
06/18/2022 09:19:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/18/2022 09:19:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/18/2022 09:19:57 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7373366013071896 on epoch=312
06/18/2022 09:20:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/18/2022 09:20:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/18/2022 09:20:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
06/18/2022 09:20:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/18/2022 09:20:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/18/2022 09:20:11 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7759289729877965 on epoch=324
06/18/2022 09:20:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=327
06/18/2022 09:20:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=329
06/18/2022 09:20:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=332
06/18/2022 09:20:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/18/2022 09:20:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/18/2022 09:20:24 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7935446906035142 on epoch=337
06/18/2022 09:20:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/18/2022 09:20:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/18/2022 09:20:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/18/2022 09:20:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=347
06/18/2022 09:20:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/18/2022 09:20:38 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7567873303167421 on epoch=349
06/18/2022 09:20:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/18/2022 09:20:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=354
06/18/2022 09:20:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/18/2022 09:20:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/18/2022 09:20:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/18/2022 09:20:52 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7935446906035142 on epoch=362
06/18/2022 09:20:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/18/2022 09:20:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=367
06/18/2022 09:20:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/18/2022 09:21:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/18/2022 09:21:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=374
06/18/2022 09:21:05 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7754010695187167 on epoch=374
06/18/2022 09:21:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/18/2022 09:21:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=379
06/18/2022 09:21:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/18/2022 09:21:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/18/2022 09:21:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/18/2022 09:21:19 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7566982037570273 on epoch=387
06/18/2022 09:21:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/18/2022 09:21:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=392
06/18/2022 09:21:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/18/2022 09:21:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/18/2022 09:21:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/18/2022 09:21:32 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7754010695187167 on epoch=399
06/18/2022 09:21:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/18/2022 09:21:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/18/2022 09:21:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/18/2022 09:21:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=409
06/18/2022 09:21:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=412
06/18/2022 09:21:46 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7754010695187167 on epoch=412
06/18/2022 09:21:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/18/2022 09:21:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=417
06/18/2022 09:21:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
06/18/2022 09:21:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/18/2022 09:21:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/18/2022 09:21:59 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8112572223246666 on epoch=424
06/18/2022 09:21:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8057725279106858 -> 0.8112572223246666 on epoch=424, global_step=1700
06/18/2022 09:22:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/18/2022 09:22:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/18/2022 09:22:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=432
06/18/2022 09:22:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/18/2022 09:22:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/18/2022 09:22:13 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7759289729877965 on epoch=437
06/18/2022 09:22:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/18/2022 09:22:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/18/2022 09:22:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/18/2022 09:22:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/18/2022 09:22:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/18/2022 09:22:27 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7759289729877965 on epoch=449
06/18/2022 09:22:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/18/2022 09:22:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/18/2022 09:22:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/18/2022 09:22:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/18/2022 09:22:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/18/2022 09:22:40 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7942760942760942 on epoch=462
06/18/2022 09:22:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/18/2022 09:22:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/18/2022 09:22:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/18/2022 09:22:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/18/2022 09:22:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 09:22:54 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7942760942760942 on epoch=474
06/18/2022 09:22:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/18/2022 09:22:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/18/2022 09:23:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/18/2022 09:23:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/18/2022 09:23:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/18/2022 09:23:07 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7759289729877965 on epoch=487
06/18/2022 09:23:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 09:23:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/18/2022 09:23:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 09:23:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/18/2022 09:23:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 09:23:21 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7759289729877965 on epoch=499
06/18/2022 09:23:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/18/2022 09:23:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/18/2022 09:23:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=507
06/18/2022 09:23:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/18/2022 09:23:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/18/2022 09:23:34 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8121482683982684 on epoch=512
06/18/2022 09:23:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8112572223246666 -> 0.8121482683982684 on epoch=512, global_step=2050
06/18/2022 09:23:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/18/2022 09:23:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=517
06/18/2022 09:23:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/18/2022 09:23:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/18/2022 09:23:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/18/2022 09:23:48 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8121482683982684 on epoch=524
06/18/2022 09:23:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/18/2022 09:23:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/18/2022 09:23:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/18/2022 09:23:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/18/2022 09:24:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/18/2022 09:24:01 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8121482683982684 on epoch=537
06/18/2022 09:24:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/18/2022 09:24:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/18/2022 09:24:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/18/2022 09:24:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 09:24:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=549
06/18/2022 09:24:14 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8112572223246666 on epoch=549
06/18/2022 09:24:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/18/2022 09:24:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/18/2022 09:24:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/18/2022 09:24:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 09:24:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=562
06/18/2022 09:24:28 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7971230158730158 on epoch=562
06/18/2022 09:24:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
06/18/2022 09:24:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/18/2022 09:24:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/18/2022 09:24:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=572
06/18/2022 09:24:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/18/2022 09:24:41 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7971230158730158 on epoch=574
06/18/2022 09:24:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 09:24:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/18/2022 09:24:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/18/2022 09:24:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=584
06/18/2022 09:24:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/18/2022 09:24:55 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7965513399717254 on epoch=587
06/18/2022 09:24:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/18/2022 09:25:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/18/2022 09:25:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/18/2022 09:25:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/18/2022 09:25:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/18/2022 09:25:08 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7763746057863705 on epoch=599
06/18/2022 09:25:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/18/2022 09:25:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/18/2022 09:25:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=607
06/18/2022 09:25:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 09:25:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 09:25:22 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7796593384828678 on epoch=612
06/18/2022 09:25:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/18/2022 09:25:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.13 on epoch=617
06/18/2022 09:25:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 09:25:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=622
06/18/2022 09:25:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/18/2022 09:25:35 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7227230572818808 on epoch=624
06/18/2022 09:25:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/18/2022 09:25:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/18/2022 09:25:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 09:25:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/18/2022 09:25:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/18/2022 09:25:48 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7570588235294118 on epoch=637
06/18/2022 09:25:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/18/2022 09:25:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/18/2022 09:25:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/18/2022 09:25:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 09:26:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/18/2022 09:26:02 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7759289729877965 on epoch=649
06/18/2022 09:26:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/18/2022 09:26:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 09:26:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/18/2022 09:26:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/18/2022 09:26:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=662
06/18/2022 09:26:15 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8112572223246666 on epoch=662
06/18/2022 09:26:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=664
06/18/2022 09:26:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/18/2022 09:26:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/18/2022 09:26:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/18/2022 09:26:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=674
06/18/2022 09:26:29 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8121482683982684 on epoch=674
06/18/2022 09:26:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/18/2022 09:26:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/18/2022 09:26:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/18/2022 09:26:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=684
06/18/2022 09:26:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/18/2022 09:26:43 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8121482683982684 on epoch=687
06/18/2022 09:26:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/18/2022 09:26:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 09:26:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=694
06/18/2022 09:26:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.13 on epoch=697
06/18/2022 09:26:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/18/2022 09:26:56 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8121482683982684 on epoch=699
06/18/2022 09:26:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/18/2022 09:27:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=704
06/18/2022 09:27:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/18/2022 09:27:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 09:27:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/18/2022 09:27:09 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8121482683982684 on epoch=712
06/18/2022 09:27:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/18/2022 09:27:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/18/2022 09:27:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 09:27:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/18/2022 09:27:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/18/2022 09:27:23 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8121482683982684 on epoch=724
06/18/2022 09:27:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 09:27:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/18/2022 09:27:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=732
06/18/2022 09:27:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 09:27:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 09:27:36 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8121482683982684 on epoch=737
06/18/2022 09:27:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/18/2022 09:27:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
06/18/2022 09:27:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/18/2022 09:27:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/18/2022 09:27:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 09:27:50 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8112572223246666 on epoch=749
06/18/2022 09:27:50 - INFO - __main__ - save last model!
06/18/2022 09:27:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 09:27:50 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 09:27:50 - INFO - __main__ - Printing 3 examples
06/18/2022 09:27:50 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:27:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:27:50 - INFO - __main__ - Printing 3 examples
06/18/2022 09:27:50 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:27:50 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:27:50 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:27:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:27:50 - INFO - __main__ - Printing 3 examples
06/18/2022 09:27:50 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 09:27:50 - INFO - __main__ - ['others']
06/18/2022 09:27:50 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:27:50 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:27:50 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:27:52 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:27:57 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 09:28:06 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:28:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:28:07 - INFO - __main__ - Starting training!
06/18/2022 09:29:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/18/2022 09:29:16 - INFO - __main__ - Classification-F1 on test data: 0.1167
06/18/2022 09:29:16 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.8121482683982684, test_performance=0.11669952447364929
06/18/2022 09:29:16 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/18/2022 09:29:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:29:17 - INFO - __main__ - Printing 3 examples
06/18/2022 09:29:17 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 09:29:17 - INFO - __main__ - ['others']
06/18/2022 09:29:17 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 09:29:17 - INFO - __main__ - ['others']
06/18/2022 09:29:17 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 09:29:17 - INFO - __main__ - ['others']
06/18/2022 09:29:17 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:29:17 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:29:17 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:29:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:29:17 - INFO - __main__ - Printing 3 examples
06/18/2022 09:29:17 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 09:29:17 - INFO - __main__ - ['others']
06/18/2022 09:29:17 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 09:29:17 - INFO - __main__ - ['others']
06/18/2022 09:29:17 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 09:29:17 - INFO - __main__ - ['others']
06/18/2022 09:29:17 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:29:17 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:29:17 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:29:32 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:29:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:29:33 - INFO - __main__ - Starting training!
06/18/2022 09:29:36 - INFO - __main__ - Step 10 Global step 10 Train loss 4.12 on epoch=2
06/18/2022 09:29:39 - INFO - __main__ - Step 20 Global step 20 Train loss 2.73 on epoch=4
06/18/2022 09:29:41 - INFO - __main__ - Step 30 Global step 30 Train loss 2.05 on epoch=7
06/18/2022 09:29:43 - INFO - __main__ - Step 40 Global step 40 Train loss 1.25 on epoch=9
06/18/2022 09:29:46 - INFO - __main__ - Step 50 Global step 50 Train loss 1.06 on epoch=12
06/18/2022 09:29:47 - INFO - __main__ - Global step 50 Train loss 2.24 Classification-F1 0.41918276845106117 on epoch=12
06/18/2022 09:29:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.41918276845106117 on epoch=12, global_step=50
06/18/2022 09:29:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.83 on epoch=14
06/18/2022 09:29:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.67 on epoch=17
06/18/2022 09:29:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=19
06/18/2022 09:29:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.62 on epoch=22
06/18/2022 09:29:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.58 on epoch=24
06/18/2022 09:30:00 - INFO - __main__ - Global step 100 Train loss 0.70 Classification-F1 0.5449628127112914 on epoch=24
06/18/2022 09:30:00 - INFO - __main__ - Saving model with best Classification-F1: 0.41918276845106117 -> 0.5449628127112914 on epoch=24, global_step=100
06/18/2022 09:30:02 - INFO - __main__ - Step 110 Global step 110 Train loss 0.59 on epoch=27
06/18/2022 09:30:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=29
06/18/2022 09:30:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.46 on epoch=32
06/18/2022 09:30:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=34
06/18/2022 09:30:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.51 on epoch=37
06/18/2022 09:30:12 - INFO - __main__ - Global step 150 Train loss 0.52 Classification-F1 0.5791021671826626 on epoch=37
06/18/2022 09:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5449628127112914 -> 0.5791021671826626 on epoch=37, global_step=150
06/18/2022 09:30:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=39
06/18/2022 09:30:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=42
06/18/2022 09:30:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=44
06/18/2022 09:30:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.31 on epoch=47
06/18/2022 09:30:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.30 on epoch=49
06/18/2022 09:30:25 - INFO - __main__ - Global step 200 Train loss 0.39 Classification-F1 0.6030908757481287 on epoch=49
06/18/2022 09:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5791021671826626 -> 0.6030908757481287 on epoch=49, global_step=200
06/18/2022 09:30:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=52
06/18/2022 09:30:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.37 on epoch=54
06/18/2022 09:30:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.28 on epoch=57
06/18/2022 09:30:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=59
06/18/2022 09:30:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=62
06/18/2022 09:30:37 - INFO - __main__ - Global step 250 Train loss 0.30 Classification-F1 0.6569235588972431 on epoch=62
06/18/2022 09:30:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6030908757481287 -> 0.6569235588972431 on epoch=62, global_step=250
06/18/2022 09:30:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/18/2022 09:30:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=67
06/18/2022 09:30:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/18/2022 09:30:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=72
06/18/2022 09:30:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/18/2022 09:30:50 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.6126402900596448 on epoch=74
06/18/2022 09:30:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=77
06/18/2022 09:30:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=79
06/18/2022 09:30:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.17 on epoch=82
06/18/2022 09:30:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=84
06/18/2022 09:31:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.13 on epoch=87
06/18/2022 09:31:03 - INFO - __main__ - Global step 350 Train loss 0.17 Classification-F1 0.6596153846153846 on epoch=87
06/18/2022 09:31:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6569235588972431 -> 0.6596153846153846 on epoch=87, global_step=350
06/18/2022 09:31:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/18/2022 09:31:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=92
06/18/2022 09:31:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=94
06/18/2022 09:31:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=97
06/18/2022 09:31:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=99
06/18/2022 09:31:15 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6617042440318303 on epoch=99
06/18/2022 09:31:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6596153846153846 -> 0.6617042440318303 on epoch=99, global_step=400
06/18/2022 09:31:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=102
06/18/2022 09:31:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/18/2022 09:31:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.11 on epoch=107
06/18/2022 09:31:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=109
06/18/2022 09:31:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=112
06/18/2022 09:31:28 - INFO - __main__ - Global step 450 Train loss 0.14 Classification-F1 0.6610518292682928 on epoch=112
06/18/2022 09:31:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=114
06/18/2022 09:31:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
06/18/2022 09:31:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=119
06/18/2022 09:31:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=122
06/18/2022 09:31:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=124
06/18/2022 09:31:41 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.6881044073598631 on epoch=124
06/18/2022 09:31:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6617042440318303 -> 0.6881044073598631 on epoch=124, global_step=500
06/18/2022 09:31:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/18/2022 09:31:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=129
06/18/2022 09:31:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/18/2022 09:31:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/18/2022 09:31:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/18/2022 09:31:53 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.691009154315606 on epoch=137
06/18/2022 09:31:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6881044073598631 -> 0.691009154315606 on epoch=137, global_step=550
06/18/2022 09:31:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/18/2022 09:31:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=142
06/18/2022 09:32:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
06/18/2022 09:32:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=147
06/18/2022 09:32:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/18/2022 09:32:06 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.6617042440318303 on epoch=149
06/18/2022 09:32:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/18/2022 09:32:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/18/2022 09:32:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/18/2022 09:32:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/18/2022 09:32:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/18/2022 09:32:18 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.6596153846153846 on epoch=162
06/18/2022 09:32:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/18/2022 09:32:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/18/2022 09:32:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/18/2022 09:32:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
06/18/2022 09:32:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/18/2022 09:32:31 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.677296198637662 on epoch=174
06/18/2022 09:32:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/18/2022 09:32:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/18/2022 09:32:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/18/2022 09:32:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/18/2022 09:32:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
06/18/2022 09:32:44 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.6867500315776178 on epoch=187
06/18/2022 09:32:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/18/2022 09:32:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/18/2022 09:32:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/18/2022 09:32:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/18/2022 09:32:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/18/2022 09:32:56 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.6765350877192983 on epoch=199
06/18/2022 09:32:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/18/2022 09:33:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/18/2022 09:33:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/18/2022 09:33:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/18/2022 09:33:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/18/2022 09:33:09 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7250398724082935 on epoch=212
06/18/2022 09:33:09 - INFO - __main__ - Saving model with best Classification-F1: 0.691009154315606 -> 0.7250398724082935 on epoch=212, global_step=850
06/18/2022 09:33:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/18/2022 09:33:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/18/2022 09:33:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/18/2022 09:33:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/18/2022 09:33:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/18/2022 09:33:21 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6867500315776178 on epoch=224
06/18/2022 09:33:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/18/2022 09:33:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/18/2022 09:33:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/18/2022 09:33:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/18/2022 09:33:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/18/2022 09:33:34 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.6466630930045565 on epoch=237
06/18/2022 09:33:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/18/2022 09:33:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/18/2022 09:33:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/18/2022 09:33:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/18/2022 09:33:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/18/2022 09:33:47 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6617042440318303 on epoch=249
06/18/2022 09:33:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/18/2022 09:33:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/18/2022 09:33:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/18/2022 09:33:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/18/2022 09:33:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/18/2022 09:33:59 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7533709106984969 on epoch=262
06/18/2022 09:33:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7250398724082935 -> 0.7533709106984969 on epoch=262, global_step=1050
06/18/2022 09:34:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/18/2022 09:34:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/18/2022 09:34:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/18/2022 09:34:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/18/2022 09:34:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/18/2022 09:34:12 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6867500315776178 on epoch=274
06/18/2022 09:34:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/18/2022 09:34:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/18/2022 09:34:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/18/2022 09:34:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/18/2022 09:34:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/18/2022 09:34:25 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.6617042440318303 on epoch=287
06/18/2022 09:34:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/18/2022 09:34:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/18/2022 09:34:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/18/2022 09:34:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/18/2022 09:34:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/18/2022 09:34:38 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.6867500315776178 on epoch=299
06/18/2022 09:34:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/18/2022 09:34:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/18/2022 09:34:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/18/2022 09:34:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/18/2022 09:34:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/18/2022 09:34:50 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6467948717948718 on epoch=312
06/18/2022 09:34:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/18/2022 09:34:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/18/2022 09:34:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/18/2022 09:35:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/18/2022 09:35:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/18/2022 09:35:03 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6617042440318303 on epoch=324
06/18/2022 09:35:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/18/2022 09:35:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/18/2022 09:35:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/18/2022 09:35:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/18/2022 09:35:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/18/2022 09:35:16 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6867500315776178 on epoch=337
06/18/2022 09:35:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/18/2022 09:35:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/18/2022 09:35:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/18/2022 09:35:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/18/2022 09:35:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/18/2022 09:35:29 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7098304396122112 on epoch=349
06/18/2022 09:35:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/18/2022 09:35:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/18/2022 09:35:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/18/2022 09:35:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/18/2022 09:35:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/18/2022 09:35:42 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6867500315776178 on epoch=362
06/18/2022 09:35:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/18/2022 09:35:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/18/2022 09:35:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/18/2022 09:35:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/18/2022 09:35:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/18/2022 09:35:55 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.6617042440318303 on epoch=374
06/18/2022 09:35:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/18/2022 09:35:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/18/2022 09:36:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 09:36:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/18/2022 09:36:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/18/2022 09:36:07 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=387
06/18/2022 09:36:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/18/2022 09:36:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 09:36:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/18/2022 09:36:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/18/2022 09:36:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/18/2022 09:36:20 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7323417293432286 on epoch=399
06/18/2022 09:36:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 09:36:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/18/2022 09:36:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/18/2022 09:36:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/18/2022 09:36:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/18/2022 09:36:33 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7323417293432286 on epoch=412
06/18/2022 09:36:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/18/2022 09:36:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/18/2022 09:36:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/18/2022 09:36:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/18/2022 09:36:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 09:36:46 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6617042440318303 on epoch=424
06/18/2022 09:36:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/18/2022 09:36:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/18/2022 09:36:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/18/2022 09:36:55 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/18/2022 09:36:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 09:36:59 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6867500315776178 on epoch=437
06/18/2022 09:37:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/18/2022 09:37:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/18/2022 09:37:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/18/2022 09:37:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/18/2022 09:37:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/18/2022 09:37:12 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6767857142857143 on epoch=449
06/18/2022 09:37:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/18/2022 09:37:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/18/2022 09:37:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/18/2022 09:37:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/18/2022 09:37:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 09:37:25 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6867500315776178 on epoch=462
06/18/2022 09:37:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 09:37:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/18/2022 09:37:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=469
06/18/2022 09:37:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/18/2022 09:37:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/18/2022 09:37:37 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6596153846153846 on epoch=474
06/18/2022 09:37:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/18/2022 09:37:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/18/2022 09:37:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/18/2022 09:37:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 09:37:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/18/2022 09:37:50 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6617042440318303 on epoch=487
06/18/2022 09:37:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/18/2022 09:37:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/18/2022 09:37:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/18/2022 09:38:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/18/2022 09:38:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/18/2022 09:38:03 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6867500315776178 on epoch=499
06/18/2022 09:38:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 09:38:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/18/2022 09:38:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/18/2022 09:38:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/18/2022 09:38:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 09:38:16 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7102090287208255 on epoch=512
06/18/2022 09:38:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/18/2022 09:38:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/18/2022 09:38:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/18/2022 09:38:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/18/2022 09:38:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 09:38:29 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6767857142857143 on epoch=524
06/18/2022 09:38:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/18/2022 09:38:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 09:38:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 09:38:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/18/2022 09:38:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/18/2022 09:38:42 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7310758082497213 on epoch=537
06/18/2022 09:38:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 09:38:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/18/2022 09:38:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 09:38:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/18/2022 09:38:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 09:38:55 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7670155993431855 on epoch=549
06/18/2022 09:38:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7533709106984969 -> 0.7670155993431855 on epoch=549, global_step=2200
06/18/2022 09:38:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 09:39:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 09:39:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 09:39:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 09:39:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/18/2022 09:39:08 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7224631180223285 on epoch=562
06/18/2022 09:39:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/18/2022 09:39:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 09:39:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 09:39:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 09:39:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 09:39:21 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7657898665158194 on epoch=574
06/18/2022 09:39:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 09:39:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 09:39:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/18/2022 09:39:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 09:39:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/18/2022 09:39:33 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7528959276018099 on epoch=587
06/18/2022 09:39:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 09:39:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 09:39:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 09:39:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 09:39:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/18/2022 09:39:46 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7093366778149387 on epoch=599
06/18/2022 09:39:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/18/2022 09:39:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 09:39:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/18/2022 09:39:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/18/2022 09:39:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 09:39:59 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7528959276018099 on epoch=612
06/18/2022 09:40:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=614
06/18/2022 09:40:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 09:40:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/18/2022 09:40:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 09:40:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/18/2022 09:40:12 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.727570425313659 on epoch=624
06/18/2022 09:40:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/18/2022 09:40:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/18/2022 09:40:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 09:40:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 09:40:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 09:40:25 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7342961092961093 on epoch=637
06/18/2022 09:40:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 09:40:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 09:40:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/18/2022 09:40:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 09:40:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/18/2022 09:40:38 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7325375773651636 on epoch=649
06/18/2022 09:40:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/18/2022 09:40:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
06/18/2022 09:40:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 09:40:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 09:40:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 09:40:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7528959276018099 on epoch=662
06/18/2022 09:40:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 09:40:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/18/2022 09:40:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 09:41:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 09:41:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/18/2022 09:41:04 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7047231353038976 on epoch=674
06/18/2022 09:41:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 09:41:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/18/2022 09:41:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/18/2022 09:41:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 09:41:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 09:41:17 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.710602598908446 on epoch=687
06/18/2022 09:41:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 09:41:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 09:41:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 09:41:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 09:41:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 09:41:30 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7126574798199512 on epoch=699
06/18/2022 09:41:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 09:41:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 09:41:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 09:41:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 09:41:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 09:41:43 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6767857142857143 on epoch=712
06/18/2022 09:41:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 09:41:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 09:41:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 09:41:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 09:41:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 09:41:56 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7018315018315019 on epoch=724
06/18/2022 09:41:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 09:42:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/18/2022 09:42:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 09:42:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 09:42:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 09:42:08 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7102090287208255 on epoch=737
06/18/2022 09:42:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 09:42:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 09:42:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 09:42:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 09:42:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/18/2022 09:42:21 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7342961092961093 on epoch=749
06/18/2022 09:42:21 - INFO - __main__ - save last model!
06/18/2022 09:42:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 09:42:21 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 09:42:21 - INFO - __main__ - Printing 3 examples
06/18/2022 09:42:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 09:42:21 - INFO - __main__ - ['others']
06/18/2022 09:42:21 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 09:42:21 - INFO - __main__ - ['others']
06/18/2022 09:42:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 09:42:21 - INFO - __main__ - ['others']
06/18/2022 09:42:21 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:42:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:42:21 - INFO - __main__ - Printing 3 examples
06/18/2022 09:42:21 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 09:42:21 - INFO - __main__ - ['others']
06/18/2022 09:42:21 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 09:42:21 - INFO - __main__ - ['others']
06/18/2022 09:42:21 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 09:42:21 - INFO - __main__ - ['others']
06/18/2022 09:42:21 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:42:22 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:42:22 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:42:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:42:22 - INFO - __main__ - Printing 3 examples
06/18/2022 09:42:22 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 09:42:22 - INFO - __main__ - ['others']
06/18/2022 09:42:22 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 09:42:22 - INFO - __main__ - ['others']
06/18/2022 09:42:22 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 09:42:22 - INFO - __main__ - ['others']
06/18/2022 09:42:22 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:42:22 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:42:22 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:42:23 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:42:29 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 09:42:40 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:42:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:42:41 - INFO - __main__ - Starting training!
06/18/2022 09:44:02 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/18/2022 09:44:02 - INFO - __main__ - Classification-F1 on test data: 0.2130
06/18/2022 09:44:02 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.7670155993431855, test_performance=0.21302472011341828
06/18/2022 09:44:02 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/18/2022 09:44:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:44:03 - INFO - __main__ - Printing 3 examples
06/18/2022 09:44:03 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 09:44:03 - INFO - __main__ - ['others']
06/18/2022 09:44:03 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 09:44:03 - INFO - __main__ - ['others']
06/18/2022 09:44:03 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 09:44:03 - INFO - __main__ - ['others']
06/18/2022 09:44:03 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:44:03 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:44:04 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:44:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:44:04 - INFO - __main__ - Printing 3 examples
06/18/2022 09:44:04 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 09:44:04 - INFO - __main__ - ['others']
06/18/2022 09:44:04 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 09:44:04 - INFO - __main__ - ['others']
06/18/2022 09:44:04 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 09:44:04 - INFO - __main__ - ['others']
06/18/2022 09:44:04 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:44:04 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:44:04 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:44:22 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:44:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:44:23 - INFO - __main__ - Starting training!
06/18/2022 09:44:26 - INFO - __main__ - Step 10 Global step 10 Train loss 4.10 on epoch=2
06/18/2022 09:44:28 - INFO - __main__ - Step 20 Global step 20 Train loss 2.94 on epoch=4
06/18/2022 09:44:31 - INFO - __main__ - Step 30 Global step 30 Train loss 2.22 on epoch=7
06/18/2022 09:44:33 - INFO - __main__ - Step 40 Global step 40 Train loss 1.71 on epoch=9
06/18/2022 09:44:35 - INFO - __main__ - Step 50 Global step 50 Train loss 1.29 on epoch=12
06/18/2022 09:44:37 - INFO - __main__ - Global step 50 Train loss 2.45 Classification-F1 0.19115479115479114 on epoch=12
06/18/2022 09:44:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19115479115479114 on epoch=12, global_step=50
06/18/2022 09:44:39 - INFO - __main__ - Step 60 Global step 60 Train loss 1.02 on epoch=14
06/18/2022 09:44:42 - INFO - __main__ - Step 70 Global step 70 Train loss 0.83 on epoch=17
06/18/2022 09:44:44 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=19
06/18/2022 09:44:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.65 on epoch=22
06/18/2022 09:44:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.58 on epoch=24
06/18/2022 09:44:50 - INFO - __main__ - Global step 100 Train loss 0.78 Classification-F1 0.4625704045058884 on epoch=24
06/18/2022 09:44:50 - INFO - __main__ - Saving model with best Classification-F1: 0.19115479115479114 -> 0.4625704045058884 on epoch=24, global_step=100
06/18/2022 09:44:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.58 on epoch=27
06/18/2022 09:44:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=29
06/18/2022 09:44:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.48 on epoch=32
06/18/2022 09:45:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=34
06/18/2022 09:45:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
06/18/2022 09:45:03 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.4625704045058884 on epoch=37
06/18/2022 09:45:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=39
06/18/2022 09:45:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=42
06/18/2022 09:45:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=44
06/18/2022 09:45:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.48 on epoch=47
06/18/2022 09:45:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/18/2022 09:45:16 - INFO - __main__ - Global step 200 Train loss 0.45 Classification-F1 0.5081135791662108 on epoch=49
06/18/2022 09:45:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4625704045058884 -> 0.5081135791662108 on epoch=49, global_step=200
06/18/2022 09:45:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=52
06/18/2022 09:45:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.37 on epoch=54
06/18/2022 09:45:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=57
06/18/2022 09:45:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=59
06/18/2022 09:45:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=62
06/18/2022 09:45:29 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.4750777426153096 on epoch=62
06/18/2022 09:45:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=64
06/18/2022 09:45:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/18/2022 09:45:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/18/2022 09:45:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/18/2022 09:45:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/18/2022 09:45:43 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.5096810207336523 on epoch=74
06/18/2022 09:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5081135791662108 -> 0.5096810207336523 on epoch=74, global_step=300
06/18/2022 09:45:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/18/2022 09:45:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=79
06/18/2022 09:45:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/18/2022 09:45:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=84
06/18/2022 09:45:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=87
06/18/2022 09:45:56 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.5082769472856019 on epoch=87
06/18/2022 09:45:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/18/2022 09:46:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=92
06/18/2022 09:46:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=94
06/18/2022 09:46:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=97
06/18/2022 09:46:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
06/18/2022 09:46:09 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.6743535327151626 on epoch=99
06/18/2022 09:46:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5096810207336523 -> 0.6743535327151626 on epoch=99, global_step=400
06/18/2022 09:46:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/18/2022 09:46:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/18/2022 09:46:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/18/2022 09:46:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=109
06/18/2022 09:46:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
06/18/2022 09:46:22 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.6439628653043288 on epoch=112
06/18/2022 09:46:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=114
06/18/2022 09:46:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=117
06/18/2022 09:46:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=119
06/18/2022 09:46:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=122
06/18/2022 09:46:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=124
06/18/2022 09:46:35 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.6743535327151626 on epoch=124
06/18/2022 09:46:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=127
06/18/2022 09:46:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=129
06/18/2022 09:46:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
06/18/2022 09:46:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=134
06/18/2022 09:46:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=137
06/18/2022 09:46:48 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6765350877192983 on epoch=137
06/18/2022 09:46:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6743535327151626 -> 0.6765350877192983 on epoch=137, global_step=550
06/18/2022 09:46:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=139
06/18/2022 09:46:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/18/2022 09:46:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=144
06/18/2022 09:46:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=147
06/18/2022 09:47:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=149
06/18/2022 09:47:02 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.6736885316740127 on epoch=149
06/18/2022 09:47:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/18/2022 09:47:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/18/2022 09:47:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/18/2022 09:47:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/18/2022 09:47:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/18/2022 09:47:15 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.6743535327151626 on epoch=162
06/18/2022 09:47:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=164
06/18/2022 09:47:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/18/2022 09:47:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
06/18/2022 09:47:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=172
06/18/2022 09:47:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/18/2022 09:47:28 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.685993208828523 on epoch=174
06/18/2022 09:47:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6765350877192983 -> 0.685993208828523 on epoch=174, global_step=700
06/18/2022 09:47:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/18/2022 09:47:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/18/2022 09:47:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/18/2022 09:47:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/18/2022 09:47:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/18/2022 09:47:41 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.6600668337510444 on epoch=187
06/18/2022 09:47:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/18/2022 09:47:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/18/2022 09:47:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/18/2022 09:47:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/18/2022 09:47:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/18/2022 09:47:54 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7121740455356754 on epoch=199
06/18/2022 09:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.685993208828523 -> 0.7121740455356754 on epoch=199, global_step=800
06/18/2022 09:47:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/18/2022 09:47:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/18/2022 09:48:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/18/2022 09:48:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/18/2022 09:48:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/18/2022 09:48:08 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7121740455356754 on epoch=212
06/18/2022 09:48:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/18/2022 09:48:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/18/2022 09:48:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/18/2022 09:48:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/18/2022 09:48:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/18/2022 09:48:21 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7121740455356754 on epoch=224
06/18/2022 09:48:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=227
06/18/2022 09:48:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/18/2022 09:48:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/18/2022 09:48:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/18/2022 09:48:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/18/2022 09:48:34 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7121740455356754 on epoch=237
06/18/2022 09:48:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=239
06/18/2022 09:48:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/18/2022 09:48:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/18/2022 09:48:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/18/2022 09:48:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/18/2022 09:48:47 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.6996523566981971 on epoch=249
06/18/2022 09:48:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/18/2022 09:48:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/18/2022 09:48:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/18/2022 09:48:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/18/2022 09:48:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/18/2022 09:49:00 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7015808752650858 on epoch=262
06/18/2022 09:49:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/18/2022 09:49:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/18/2022 09:49:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/18/2022 09:49:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/18/2022 09:49:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/18/2022 09:49:13 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6996523566981971 on epoch=274
06/18/2022 09:49:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/18/2022 09:49:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/18/2022 09:49:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/18/2022 09:49:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/18/2022 09:49:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/18/2022 09:49:26 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7015808752650858 on epoch=287
06/18/2022 09:49:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/18/2022 09:49:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/18/2022 09:49:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/18/2022 09:49:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/18/2022 09:49:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/18/2022 09:49:40 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=299
06/18/2022 09:49:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/18/2022 09:49:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/18/2022 09:49:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/18/2022 09:49:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/18/2022 09:49:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/18/2022 09:49:53 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6765350877192983 on epoch=312
06/18/2022 09:49:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/18/2022 09:49:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/18/2022 09:50:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/18/2022 09:50:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/18/2022 09:50:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/18/2022 09:50:06 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=324
06/18/2022 09:50:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/18/2022 09:50:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/18/2022 09:50:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/18/2022 09:50:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/18/2022 09:50:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/18/2022 09:50:19 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7015808752650858 on epoch=337
06/18/2022 09:50:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/18/2022 09:50:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/18/2022 09:50:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/18/2022 09:50:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/18/2022 09:50:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/18/2022 09:50:33 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=349
06/18/2022 09:50:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/18/2022 09:50:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/18/2022 09:50:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/18/2022 09:50:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/18/2022 09:50:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/18/2022 09:50:46 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=362
06/18/2022 09:50:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/18/2022 09:50:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/18/2022 09:50:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/18/2022 09:50:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/18/2022 09:50:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/18/2022 09:50:59 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7015808752650858 on epoch=374
06/18/2022 09:51:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/18/2022 09:51:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/18/2022 09:51:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/18/2022 09:51:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/18/2022 09:51:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/18/2022 09:51:13 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=387
06/18/2022 09:51:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/18/2022 09:51:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 09:51:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/18/2022 09:51:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/18/2022 09:51:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/18/2022 09:51:26 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=399
06/18/2022 09:51:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/18/2022 09:51:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/18/2022 09:51:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/18/2022 09:51:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 09:51:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/18/2022 09:51:39 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=412
06/18/2022 09:51:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 09:51:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/18/2022 09:51:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/18/2022 09:51:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/18/2022 09:51:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 09:51:53 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7015808752650858 on epoch=424
06/18/2022 09:51:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=427
06/18/2022 09:51:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/18/2022 09:52:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/18/2022 09:52:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/18/2022 09:52:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/18/2022 09:52:06 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6996523566981971 on epoch=437
06/18/2022 09:52:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/18/2022 09:52:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/18/2022 09:52:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/18/2022 09:52:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/18/2022 09:52:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/18/2022 09:52:20 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=449
06/18/2022 09:52:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/18/2022 09:52:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/18/2022 09:52:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/18/2022 09:52:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/18/2022 09:52:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/18/2022 09:52:33 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=462
06/18/2022 09:52:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 09:52:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/18/2022 09:52:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/18/2022 09:52:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/18/2022 09:52:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/18/2022 09:52:46 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6996523566981971 on epoch=474
06/18/2022 09:52:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/18/2022 09:52:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/18/2022 09:52:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/18/2022 09:52:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/18/2022 09:52:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 09:53:00 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=487
06/18/2022 09:53:02 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 09:53:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/18/2022 09:53:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/18/2022 09:53:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/18/2022 09:53:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 09:53:13 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=499
06/18/2022 09:53:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/18/2022 09:53:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/18/2022 09:53:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/18/2022 09:53:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/18/2022 09:53:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/18/2022 09:53:27 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=512
06/18/2022 09:53:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/18/2022 09:53:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/18/2022 09:53:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/18/2022 09:53:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/18/2022 09:53:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 09:53:40 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=524
06/18/2022 09:53:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/18/2022 09:53:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/18/2022 09:53:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 09:53:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/18/2022 09:53:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 09:53:54 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6867500315776178 on epoch=537
06/18/2022 09:53:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 09:53:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/18/2022 09:54:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/18/2022 09:54:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 09:54:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 09:54:07 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=549
06/18/2022 09:54:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/18/2022 09:54:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/18/2022 09:54:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 09:54:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/18/2022 09:54:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/18/2022 09:54:20 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7015808752650858 on epoch=562
06/18/2022 09:54:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/18/2022 09:54:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 09:54:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 09:54:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/18/2022 09:54:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 09:54:34 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6867500315776178 on epoch=574
06/18/2022 09:54:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/18/2022 09:54:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/18/2022 09:54:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/18/2022 09:54:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 09:54:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/18/2022 09:54:47 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7015808752650858 on epoch=587
06/18/2022 09:54:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 09:54:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 09:54:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 09:54:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/18/2022 09:55:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/18/2022 09:55:01 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6867500315776178 on epoch=599
06/18/2022 09:55:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/18/2022 09:55:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 09:55:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 09:55:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=609
06/18/2022 09:55:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 09:55:14 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.684920705479916 on epoch=612
06/18/2022 09:55:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 09:55:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 09:55:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/18/2022 09:55:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/18/2022 09:55:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/18/2022 09:55:28 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6996523566981971 on epoch=624
06/18/2022 09:55:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/18/2022 09:55:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=629
06/18/2022 09:55:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/18/2022 09:55:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/18/2022 09:55:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/18/2022 09:55:41 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.684920705479916 on epoch=637
06/18/2022 09:55:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 09:55:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/18/2022 09:55:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/18/2022 09:55:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 09:55:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.15 on epoch=649
06/18/2022 09:55:55 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6996523566981971 on epoch=649
06/18/2022 09:55:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/18/2022 09:56:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 09:56:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 09:56:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 09:56:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/18/2022 09:56:08 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6849142085984191 on epoch=662
06/18/2022 09:56:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 09:56:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/18/2022 09:56:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/18/2022 09:56:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 09:56:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 09:56:22 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6849142085984191 on epoch=674
06/18/2022 09:56:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 09:56:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/18/2022 09:56:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/18/2022 09:56:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 09:56:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=687
06/18/2022 09:56:35 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6996523566981971 on epoch=687
06/18/2022 09:56:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 09:56:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/18/2022 09:56:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 09:56:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 09:56:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/18/2022 09:56:49 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.684920705479916 on epoch=699
06/18/2022 09:56:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 09:56:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 09:56:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 09:56:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 09:57:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 09:57:02 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.684920705479916 on epoch=712
06/18/2022 09:57:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 09:57:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=717
06/18/2022 09:57:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/18/2022 09:57:12 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/18/2022 09:57:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 09:57:16 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=724
06/18/2022 09:57:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 09:57:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 09:57:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 09:57:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 09:57:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/18/2022 09:57:29 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.684920705479916 on epoch=737
06/18/2022 09:57:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 09:57:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/18/2022 09:57:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/18/2022 09:57:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 09:57:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/18/2022 09:57:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6996523566981971 on epoch=749
06/18/2022 09:57:43 - INFO - __main__ - save last model!
06/18/2022 09:57:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 09:57:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 09:57:43 - INFO - __main__ - Printing 3 examples
06/18/2022 09:57:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:57:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:57:43 - INFO - __main__ - Printing 3 examples
06/18/2022 09:57:43 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:57:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:57:43 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:57:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:57:43 - INFO - __main__ - Printing 3 examples
06/18/2022 09:57:43 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 09:57:43 - INFO - __main__ - ['others']
06/18/2022 09:57:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:57:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:57:43 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:57:45 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:57:51 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 09:57:59 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:58:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:58:00 - INFO - __main__ - Starting training!
06/18/2022 09:59:25 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/18/2022 09:59:25 - INFO - __main__ - Classification-F1 on test data: 0.1777
06/18/2022 09:59:25 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.7121740455356754, test_performance=0.17772940375738178
06/18/2022 09:59:25 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/18/2022 09:59:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:59:26 - INFO - __main__ - Printing 3 examples
06/18/2022 09:59:26 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 09:59:26 - INFO - __main__ - ['others']
06/18/2022 09:59:26 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 09:59:26 - INFO - __main__ - ['others']
06/18/2022 09:59:26 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 09:59:26 - INFO - __main__ - ['others']
06/18/2022 09:59:26 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:59:26 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:59:26 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 09:59:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 09:59:26 - INFO - __main__ - Printing 3 examples
06/18/2022 09:59:26 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 09:59:26 - INFO - __main__ - ['others']
06/18/2022 09:59:26 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 09:59:26 - INFO - __main__ - ['others']
06/18/2022 09:59:26 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 09:59:26 - INFO - __main__ - ['others']
06/18/2022 09:59:26 - INFO - __main__ - Tokenizing Input ...
06/18/2022 09:59:26 - INFO - __main__ - Tokenizing Output ...
06/18/2022 09:59:26 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 09:59:41 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 09:59:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 09:59:42 - INFO - __main__ - Starting training!
06/18/2022 09:59:45 - INFO - __main__ - Step 10 Global step 10 Train loss 4.07 on epoch=2
06/18/2022 09:59:48 - INFO - __main__ - Step 20 Global step 20 Train loss 3.13 on epoch=4
06/18/2022 09:59:50 - INFO - __main__ - Step 30 Global step 30 Train loss 2.47 on epoch=7
06/18/2022 09:59:52 - INFO - __main__ - Step 40 Global step 40 Train loss 1.98 on epoch=9
06/18/2022 09:59:55 - INFO - __main__ - Step 50 Global step 50 Train loss 1.68 on epoch=12
06/18/2022 09:59:56 - INFO - __main__ - Global step 50 Train loss 2.67 Classification-F1 0.13470463470463473 on epoch=12
06/18/2022 09:59:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13470463470463473 on epoch=12, global_step=50
06/18/2022 09:59:58 - INFO - __main__ - Step 60 Global step 60 Train loss 1.37 on epoch=14
06/18/2022 10:00:01 - INFO - __main__ - Step 70 Global step 70 Train loss 1.15 on epoch=17
06/18/2022 10:00:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=19
06/18/2022 10:00:05 - INFO - __main__ - Step 90 Global step 90 Train loss 0.84 on epoch=22
06/18/2022 10:00:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.66 on epoch=24
06/18/2022 10:00:08 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.4247619047619048 on epoch=24
06/18/2022 10:00:08 - INFO - __main__ - Saving model with best Classification-F1: 0.13470463470463473 -> 0.4247619047619048 on epoch=24, global_step=100
06/18/2022 10:00:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=27
06/18/2022 10:00:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=29
06/18/2022 10:00:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=32
06/18/2022 10:00:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.65 on epoch=34
06/18/2022 10:00:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
06/18/2022 10:00:21 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.5433006535947713 on epoch=37
06/18/2022 10:00:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4247619047619048 -> 0.5433006535947713 on epoch=37, global_step=150
06/18/2022 10:00:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=39
06/18/2022 10:00:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=42
06/18/2022 10:00:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.61 on epoch=44
06/18/2022 10:00:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=47
06/18/2022 10:00:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=49
06/18/2022 10:00:34 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.5860339040866424 on epoch=49
06/18/2022 10:00:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5433006535947713 -> 0.5860339040866424 on epoch=49, global_step=200
06/18/2022 10:00:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.45 on epoch=52
06/18/2022 10:00:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=54
06/18/2022 10:00:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=57
06/18/2022 10:00:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=59
06/18/2022 10:00:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=62
06/18/2022 10:00:46 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.6454268292682928 on epoch=62
06/18/2022 10:00:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5860339040866424 -> 0.6454268292682928 on epoch=62, global_step=250
06/18/2022 10:00:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=64
06/18/2022 10:00:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=67
06/18/2022 10:00:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=69
06/18/2022 10:00:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=72
06/18/2022 10:00:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/18/2022 10:00:58 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.6307560903149139 on epoch=74
06/18/2022 10:01:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=77
06/18/2022 10:01:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=79
06/18/2022 10:01:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=82
06/18/2022 10:01:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=84
06/18/2022 10:01:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=87
06/18/2022 10:01:11 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.6323593073593073 on epoch=87
06/18/2022 10:01:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=89
06/18/2022 10:01:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/18/2022 10:01:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
06/18/2022 10:01:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
06/18/2022 10:01:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=99
06/18/2022 10:01:23 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6287693223177094 on epoch=99
06/18/2022 10:01:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=102
06/18/2022 10:01:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/18/2022 10:01:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=107
06/18/2022 10:01:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=109
06/18/2022 10:01:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/18/2022 10:01:36 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.6414116349600222 on epoch=112
06/18/2022 10:01:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=114
06/18/2022 10:01:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/18/2022 10:01:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/18/2022 10:01:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/18/2022 10:01:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/18/2022 10:01:49 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.6714377406931964 on epoch=124
06/18/2022 10:01:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6454268292682928 -> 0.6714377406931964 on epoch=124, global_step=500
06/18/2022 10:01:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/18/2022 10:01:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/18/2022 10:01:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/18/2022 10:01:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
06/18/2022 10:02:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/18/2022 10:02:01 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6714377406931964 on epoch=137
06/18/2022 10:02:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/18/2022 10:02:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/18/2022 10:02:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=144
06/18/2022 10:02:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/18/2022 10:02:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/18/2022 10:02:14 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.684250398724083 on epoch=149
06/18/2022 10:02:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6714377406931964 -> 0.684250398724083 on epoch=149, global_step=600
06/18/2022 10:02:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=152
06/18/2022 10:02:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/18/2022 10:02:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/18/2022 10:02:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/18/2022 10:02:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=162
06/18/2022 10:02:26 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6731353950103951 on epoch=162
06/18/2022 10:02:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/18/2022 10:02:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=167
06/18/2022 10:02:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
06/18/2022 10:02:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/18/2022 10:02:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=174
06/18/2022 10:02:39 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.685993208828523 on epoch=174
06/18/2022 10:02:39 - INFO - __main__ - Saving model with best Classification-F1: 0.684250398724083 -> 0.685993208828523 on epoch=174, global_step=700
06/18/2022 10:02:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/18/2022 10:02:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=179
06/18/2022 10:02:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/18/2022 10:02:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/18/2022 10:02:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
06/18/2022 10:02:51 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6855276529738982 on epoch=187
06/18/2022 10:02:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
06/18/2022 10:02:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/18/2022 10:02:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=194
06/18/2022 10:03:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/18/2022 10:03:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=199
06/18/2022 10:03:04 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6855276529738982 on epoch=199
06/18/2022 10:03:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/18/2022 10:03:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=204
06/18/2022 10:03:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/18/2022 10:03:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/18/2022 10:03:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/18/2022 10:03:17 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6864494416981063 on epoch=212
06/18/2022 10:03:17 - INFO - __main__ - Saving model with best Classification-F1: 0.685993208828523 -> 0.6864494416981063 on epoch=212, global_step=850
06/18/2022 10:03:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/18/2022 10:03:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
06/18/2022 10:03:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/18/2022 10:03:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/18/2022 10:03:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/18/2022 10:03:29 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.6864494416981063 on epoch=224
06/18/2022 10:03:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=227
06/18/2022 10:03:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=229
06/18/2022 10:03:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/18/2022 10:03:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/18/2022 10:03:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/18/2022 10:03:42 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.6765350877192983 on epoch=237
06/18/2022 10:03:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/18/2022 10:03:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=242
06/18/2022 10:03:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/18/2022 10:03:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/18/2022 10:03:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/18/2022 10:03:54 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6743535327151626 on epoch=249
06/18/2022 10:03:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/18/2022 10:03:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/18/2022 10:04:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/18/2022 10:04:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/18/2022 10:04:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/18/2022 10:04:07 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.6765350877192983 on epoch=262
06/18/2022 10:04:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=264
06/18/2022 10:04:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/18/2022 10:04:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/18/2022 10:04:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/18/2022 10:04:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/18/2022 10:04:19 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6765350877192983 on epoch=274
06/18/2022 10:04:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/18/2022 10:04:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/18/2022 10:04:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/18/2022 10:04:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/18/2022 10:04:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/18/2022 10:04:32 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7015808752650858 on epoch=287
06/18/2022 10:04:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6864494416981063 -> 0.7015808752650858 on epoch=287, global_step=1150
06/18/2022 10:04:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/18/2022 10:04:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/18/2022 10:04:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/18/2022 10:04:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/18/2022 10:04:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/18/2022 10:04:45 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6765350877192983 on epoch=299
06/18/2022 10:04:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/18/2022 10:04:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/18/2022 10:04:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/18/2022 10:04:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/18/2022 10:04:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/18/2022 10:04:58 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=312
06/18/2022 10:05:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=314
06/18/2022 10:05:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/18/2022 10:05:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/18/2022 10:05:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/18/2022 10:05:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/18/2022 10:05:10 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6495934959349593 on epoch=324
06/18/2022 10:05:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/18/2022 10:05:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/18/2022 10:05:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/18/2022 10:05:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/18/2022 10:05:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/18/2022 10:05:23 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.6765350877192983 on epoch=337
06/18/2022 10:05:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/18/2022 10:05:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/18/2022 10:05:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/18/2022 10:05:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=347
06/18/2022 10:05:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/18/2022 10:05:35 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6765350877192983 on epoch=349
06/18/2022 10:05:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=352
06/18/2022 10:05:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/18/2022 10:05:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/18/2022 10:05:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/18/2022 10:05:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/18/2022 10:05:48 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6765350877192983 on epoch=362
06/18/2022 10:05:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/18/2022 10:05:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/18/2022 10:05:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/18/2022 10:05:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/18/2022 10:06:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/18/2022 10:06:00 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=374
06/18/2022 10:06:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/18/2022 10:06:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/18/2022 10:06:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/18/2022 10:06:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/18/2022 10:06:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/18/2022 10:06:13 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=387
06/18/2022 10:06:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/18/2022 10:06:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/18/2022 10:06:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/18/2022 10:06:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/18/2022 10:06:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/18/2022 10:06:26 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6765350877192983 on epoch=399
06/18/2022 10:06:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/18/2022 10:06:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/18/2022 10:06:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/18/2022 10:06:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/18/2022 10:06:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=412
06/18/2022 10:06:38 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7015808752650858 on epoch=412
06/18/2022 10:06:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/18/2022 10:06:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/18/2022 10:06:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=419
06/18/2022 10:06:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/18/2022 10:06:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/18/2022 10:06:51 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=424
06/18/2022 10:06:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/18/2022 10:06:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 10:06:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/18/2022 10:07:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/18/2022 10:07:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/18/2022 10:07:04 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7250398724082935 on epoch=437
06/18/2022 10:07:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7015808752650858 -> 0.7250398724082935 on epoch=437, global_step=1750
06/18/2022 10:07:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/18/2022 10:07:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/18/2022 10:07:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/18/2022 10:07:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/18/2022 10:07:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/18/2022 10:07:17 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6495934959349593 on epoch=449
06/18/2022 10:07:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/18/2022 10:07:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/18/2022 10:07:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/18/2022 10:07:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/18/2022 10:07:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/18/2022 10:07:29 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6347626522474914 on epoch=462
06/18/2022 10:07:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/18/2022 10:07:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/18/2022 10:07:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 10:07:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/18/2022 10:07:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/18/2022 10:07:42 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6765350877192983 on epoch=474
06/18/2022 10:07:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/18/2022 10:07:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/18/2022 10:07:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 10:07:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=484
06/18/2022 10:07:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/18/2022 10:07:55 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6867500315776178 on epoch=487
06/18/2022 10:07:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/18/2022 10:07:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/18/2022 10:08:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/18/2022 10:08:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/18/2022 10:08:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 10:08:07 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6765350877192983 on epoch=499
06/18/2022 10:08:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/18/2022 10:08:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/18/2022 10:08:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.21 on epoch=507
06/18/2022 10:08:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/18/2022 10:08:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/18/2022 10:08:20 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6615330198946497 on epoch=512
06/18/2022 10:08:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/18/2022 10:08:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/18/2022 10:08:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/18/2022 10:08:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/18/2022 10:08:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/18/2022 10:08:33 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6495934959349593 on epoch=524
06/18/2022 10:08:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/18/2022 10:08:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=529
06/18/2022 10:08:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 10:08:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/18/2022 10:08:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/18/2022 10:08:45 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6495934959349593 on epoch=537
06/18/2022 10:08:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/18/2022 10:08:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/18/2022 10:08:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/18/2022 10:08:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/18/2022 10:08:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/18/2022 10:08:58 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6495934959349593 on epoch=549
06/18/2022 10:09:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/18/2022 10:09:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/18/2022 10:09:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/18/2022 10:09:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/18/2022 10:09:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/18/2022 10:09:11 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6495934959349593 on epoch=562
06/18/2022 10:09:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/18/2022 10:09:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/18/2022 10:09:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/18/2022 10:09:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/18/2022 10:09:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/18/2022 10:09:25 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6495934959349593 on epoch=574
06/18/2022 10:09:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 10:09:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=579
06/18/2022 10:09:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/18/2022 10:09:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/18/2022 10:09:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/18/2022 10:09:38 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=587
06/18/2022 10:09:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/18/2022 10:09:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 10:09:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/18/2022 10:09:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/18/2022 10:09:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/18/2022 10:09:51 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6765350877192983 on epoch=599
06/18/2022 10:09:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/18/2022 10:09:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/18/2022 10:09:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/18/2022 10:10:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 10:10:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/18/2022 10:10:04 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6495934959349593 on epoch=612
06/18/2022 10:10:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/18/2022 10:10:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/18/2022 10:10:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/18/2022 10:10:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/18/2022 10:10:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/18/2022 10:10:18 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6765350877192983 on epoch=624
06/18/2022 10:10:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/18/2022 10:10:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/18/2022 10:10:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 10:10:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/18/2022 10:10:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/18/2022 10:10:31 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6743535327151626 on epoch=637
06/18/2022 10:10:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/18/2022 10:10:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/18/2022 10:10:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/18/2022 10:10:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/18/2022 10:10:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 10:10:45 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6495934959349593 on epoch=649
06/18/2022 10:10:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/18/2022 10:10:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/18/2022 10:10:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/18/2022 10:10:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 10:10:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/18/2022 10:10:58 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6743535327151626 on epoch=662
06/18/2022 10:11:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/18/2022 10:11:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/18/2022 10:11:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/18/2022 10:11:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/18/2022 10:11:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/18/2022 10:11:12 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6495934959349593 on epoch=674
06/18/2022 10:11:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/18/2022 10:11:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/18/2022 10:11:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/18/2022 10:11:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 10:11:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/18/2022 10:11:25 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6471774193548387 on epoch=687
06/18/2022 10:11:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/18/2022 10:11:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/18/2022 10:11:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/18/2022 10:11:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/18/2022 10:11:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/18/2022 10:11:39 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=699
06/18/2022 10:11:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/18/2022 10:11:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/18/2022 10:11:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 10:11:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/18/2022 10:11:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 10:11:52 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7015808752650858 on epoch=712
06/18/2022 10:11:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/18/2022 10:11:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/18/2022 10:11:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/18/2022 10:12:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/18/2022 10:12:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/18/2022 10:12:05 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7015808752650858 on epoch=724
06/18/2022 10:12:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/18/2022 10:12:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=729
06/18/2022 10:12:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/18/2022 10:12:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 10:12:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/18/2022 10:12:19 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6743535327151626 on epoch=737
06/18/2022 10:12:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/18/2022 10:12:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 10:12:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/18/2022 10:12:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/18/2022 10:12:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/18/2022 10:12:32 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7015808752650858 on epoch=749
06/18/2022 10:12:32 - INFO - __main__ - save last model!
06/18/2022 10:12:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 10:12:32 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 10:12:32 - INFO - __main__ - Printing 3 examples
06/18/2022 10:12:32 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ - Tokenizing Input ...
06/18/2022 10:12:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 10:12:32 - INFO - __main__ - Printing 3 examples
06/18/2022 10:12:32 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ - Tokenizing Input ...
06/18/2022 10:12:32 - INFO - __main__ - Tokenizing Output ...
06/18/2022 10:12:32 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 10:12:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 10:12:32 - INFO - __main__ - Printing 3 examples
06/18/2022 10:12:32 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 10:12:32 - INFO - __main__ - ['others']
06/18/2022 10:12:32 - INFO - __main__ - Tokenizing Input ...
06/18/2022 10:12:32 - INFO - __main__ - Tokenizing Output ...
06/18/2022 10:12:33 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 10:12:34 - INFO - __main__ - Tokenizing Output ...
06/18/2022 10:12:40 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 10:12:51 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 10:12:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 10:12:52 - INFO - __main__ - Starting training!
06/18/2022 10:14:13 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/18/2022 10:14:13 - INFO - __main__ - Classification-F1 on test data: 0.1283
06/18/2022 10:14:13 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.7250398724082935, test_performance=0.12834319711019185
06/18/2022 10:14:13 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/18/2022 10:14:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 10:14:14 - INFO - __main__ - Printing 3 examples
06/18/2022 10:14:14 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/18/2022 10:14:14 - INFO - __main__ - ['others']
06/18/2022 10:14:14 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/18/2022 10:14:14 - INFO - __main__ - ['others']
06/18/2022 10:14:14 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/18/2022 10:14:14 - INFO - __main__ - ['others']
06/18/2022 10:14:14 - INFO - __main__ - Tokenizing Input ...
06/18/2022 10:14:14 - INFO - __main__ - Tokenizing Output ...
06/18/2022 10:14:14 - INFO - __main__ - Loaded 64 examples from train data
06/18/2022 10:14:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/18/2022 10:14:14 - INFO - __main__ - Printing 3 examples
06/18/2022 10:14:14 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/18/2022 10:14:14 - INFO - __main__ - ['others']
06/18/2022 10:14:14 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/18/2022 10:14:14 - INFO - __main__ - ['others']
06/18/2022 10:14:14 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/18/2022 10:14:14 - INFO - __main__ - ['others']
06/18/2022 10:14:14 - INFO - __main__ - Tokenizing Input ...
06/18/2022 10:14:14 - INFO - __main__ - Tokenizing Output ...
06/18/2022 10:14:14 - INFO - __main__ - Loaded 64 examples from dev data
06/18/2022 10:14:33 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 10:14:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 10:14:33 - INFO - __main__ - Starting training!
06/18/2022 10:14:37 - INFO - __main__ - Step 10 Global step 10 Train loss 4.35 on epoch=2
06/18/2022 10:14:39 - INFO - __main__ - Step 20 Global step 20 Train loss 3.53 on epoch=4
06/18/2022 10:14:42 - INFO - __main__ - Step 30 Global step 30 Train loss 2.96 on epoch=7
06/18/2022 10:14:44 - INFO - __main__ - Step 40 Global step 40 Train loss 2.53 on epoch=9
06/18/2022 10:14:47 - INFO - __main__ - Step 50 Global step 50 Train loss 2.20 on epoch=12
06/18/2022 10:14:48 - INFO - __main__ - Global step 50 Train loss 3.12 Classification-F1 0.022162619988706944 on epoch=12
06/18/2022 10:14:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.022162619988706944 on epoch=12, global_step=50
06/18/2022 10:14:50 - INFO - __main__ - Step 60 Global step 60 Train loss 1.79 on epoch=14
06/18/2022 10:14:53 - INFO - __main__ - Step 70 Global step 70 Train loss 1.70 on epoch=17
06/18/2022 10:14:55 - INFO - __main__ - Step 80 Global step 80 Train loss 1.51 on epoch=19
06/18/2022 10:14:58 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=22
06/18/2022 10:15:00 - INFO - __main__ - Step 100 Global step 100 Train loss 1.18 on epoch=24
06/18/2022 10:15:01 - INFO - __main__ - Global step 100 Train loss 1.49 Classification-F1 0.26274413371187566 on epoch=24
06/18/2022 10:15:02 - INFO - __main__ - Saving model with best Classification-F1: 0.022162619988706944 -> 0.26274413371187566 on epoch=24, global_step=100
06/18/2022 10:15:04 - INFO - __main__ - Step 110 Global step 110 Train loss 1.04 on epoch=27
06/18/2022 10:15:06 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/18/2022 10:15:09 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/18/2022 10:15:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=34
06/18/2022 10:15:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.76 on epoch=37
06/18/2022 10:15:15 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.5714151317092494 on epoch=37
06/18/2022 10:15:15 - INFO - __main__ - Saving model with best Classification-F1: 0.26274413371187566 -> 0.5714151317092494 on epoch=37, global_step=150
06/18/2022 10:15:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=39
06/18/2022 10:15:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=42
06/18/2022 10:15:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=44
06/18/2022 10:15:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=47
06/18/2022 10:15:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=49
06/18/2022 10:15:28 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.5902495306633292 on epoch=49
06/18/2022 10:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5714151317092494 -> 0.5902495306633292 on epoch=49, global_step=200
06/18/2022 10:15:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=52
06/18/2022 10:15:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.48 on epoch=54
06/18/2022 10:15:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=57
06/18/2022 10:15:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=59
06/18/2022 10:15:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=62
06/18/2022 10:15:42 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.5908010012515644 on epoch=62
06/18/2022 10:15:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5902495306633292 -> 0.5908010012515644 on epoch=62, global_step=250
06/18/2022 10:15:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=64
06/18/2022 10:15:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=67
06/18/2022 10:15:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=69
06/18/2022 10:15:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=72
06/18/2022 10:15:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/18/2022 10:15:55 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.6038576508422231 on epoch=74
06/18/2022 10:15:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5908010012515644 -> 0.6038576508422231 on epoch=74, global_step=300
06/18/2022 10:15:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.42 on epoch=77
06/18/2022 10:16:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=79
06/18/2022 10:16:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=82
06/18/2022 10:16:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=84
06/18/2022 10:16:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.52 on epoch=87
06/18/2022 10:16:08 - INFO - __main__ - Global step 350 Train loss 0.48 Classification-F1 0.6161616161616161 on epoch=87
06/18/2022 10:16:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6038576508422231 -> 0.6161616161616161 on epoch=87, global_step=350
06/18/2022 10:16:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=89
06/18/2022 10:16:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=92
06/18/2022 10:16:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/18/2022 10:16:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=97
06/18/2022 10:16:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=99
06/18/2022 10:16:22 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.6307560903149139 on epoch=99
06/18/2022 10:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6161616161616161 -> 0.6307560903149139 on epoch=99, global_step=400
06/18/2022 10:16:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/18/2022 10:16:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=104
06/18/2022 10:16:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/18/2022 10:16:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/18/2022 10:16:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=112
06/18/2022 10:16:35 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.6437817588368384 on epoch=112
06/18/2022 10:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6307560903149139 -> 0.6437817588368384 on epoch=112, global_step=450
06/18/2022 10:16:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=114
06/18/2022 10:16:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=117
06/18/2022 10:16:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=119
06/18/2022 10:16:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=122
06/18/2022 10:16:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/18/2022 10:16:48 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.6434837876135702 on epoch=124
06/18/2022 10:16:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=127
06/18/2022 10:16:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.36 on epoch=129
06/18/2022 10:16:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=132
06/18/2022 10:16:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=134
06/18/2022 10:17:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=137
06/18/2022 10:17:02 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.6434001670843776 on epoch=137
06/18/2022 10:17:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=139
06/18/2022 10:17:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=142
06/18/2022 10:17:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=144
06/18/2022 10:17:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/18/2022 10:17:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=149
06/18/2022 10:17:15 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.642282835831223 on epoch=149
06/18/2022 10:17:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=152
06/18/2022 10:17:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/18/2022 10:17:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/18/2022 10:17:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=159
06/18/2022 10:17:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/18/2022 10:17:28 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.6587510897994769 on epoch=162
06/18/2022 10:17:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6437817588368384 -> 0.6587510897994769 on epoch=162, global_step=650
06/18/2022 10:17:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/18/2022 10:17:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/18/2022 10:17:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=169
06/18/2022 10:17:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=172
06/18/2022 10:17:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/18/2022 10:17:42 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6560321843620502 on epoch=174
06/18/2022 10:17:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=177
06/18/2022 10:17:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/18/2022 10:17:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
06/18/2022 10:17:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=184
06/18/2022 10:17:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=187
06/18/2022 10:17:55 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.6713052793273507 on epoch=187
06/18/2022 10:17:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6587510897994769 -> 0.6713052793273507 on epoch=187, global_step=750
06/18/2022 10:17:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=189
06/18/2022 10:18:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/18/2022 10:18:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=194
06/18/2022 10:18:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/18/2022 10:18:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/18/2022 10:18:09 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.671255060728745 on epoch=199
06/18/2022 10:18:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/18/2022 10:18:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=204
06/18/2022 10:18:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=207
06/18/2022 10:18:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/18/2022 10:18:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=212
06/18/2022 10:18:22 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.6713052793273507 on epoch=212
06/18/2022 10:18:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/18/2022 10:18:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/18/2022 10:18:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=219
06/18/2022 10:18:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/18/2022 10:18:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/18/2022 10:18:35 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.6598085496984002 on epoch=224
06/18/2022 10:18:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=227
06/18/2022 10:18:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=229
06/18/2022 10:18:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/18/2022 10:18:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/18/2022 10:18:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=237
06/18/2022 10:18:49 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6739583333333334 on epoch=237
06/18/2022 10:18:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6713052793273507 -> 0.6739583333333334 on epoch=237, global_step=950
06/18/2022 10:18:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=239
06/18/2022 10:18:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/18/2022 10:18:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/18/2022 10:18:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/18/2022 10:19:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=249
06/18/2022 10:19:02 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6587510897994769 on epoch=249
06/18/2022 10:19:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=252
06/18/2022 10:19:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=254
06/18/2022 10:19:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=257
06/18/2022 10:19:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=259
06/18/2022 10:19:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=262
06/18/2022 10:19:16 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.644078947368421 on epoch=262
06/18/2022 10:19:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/18/2022 10:19:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=267
06/18/2022 10:19:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=269
06/18/2022 10:19:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
06/18/2022 10:19:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/18/2022 10:19:29 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6582245004570981 on epoch=274
06/18/2022 10:19:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/18/2022 10:19:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/18/2022 10:19:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=282
06/18/2022 10:19:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=284
06/18/2022 10:19:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=287
06/18/2022 10:19:42 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6582245004570981 on epoch=287
06/18/2022 10:19:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/18/2022 10:19:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=292
06/18/2022 10:19:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/18/2022 10:19:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/18/2022 10:19:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=299
06/18/2022 10:19:56 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6582245004570981 on epoch=299
06/18/2022 10:19:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/18/2022 10:20:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/18/2022 10:20:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=307
06/18/2022 10:20:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/18/2022 10:20:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/18/2022 10:20:09 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.6596153846153846 on epoch=312
06/18/2022 10:20:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/18/2022 10:20:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/18/2022 10:20:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
06/18/2022 10:20:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/18/2022 10:20:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
06/18/2022 10:20:23 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6596153846153846 on epoch=324
06/18/2022 10:20:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/18/2022 10:20:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/18/2022 10:20:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=332
06/18/2022 10:20:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/18/2022 10:20:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/18/2022 10:20:36 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6596153846153846 on epoch=337
06/18/2022 10:20:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/18/2022 10:20:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/18/2022 10:20:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/18/2022 10:20:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/18/2022 10:20:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/18/2022 10:20:50 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6731353950103951 on epoch=349
06/18/2022 10:20:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/18/2022 10:20:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=354
06/18/2022 10:20:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
06/18/2022 10:21:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/18/2022 10:21:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/18/2022 10:21:03 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6582245004570981 on epoch=362
06/18/2022 10:21:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
06/18/2022 10:21:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/18/2022 10:21:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/18/2022 10:21:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/18/2022 10:21:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/18/2022 10:21:16 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6596153846153846 on epoch=374
06/18/2022 10:21:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/18/2022 10:21:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=379
06/18/2022 10:21:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/18/2022 10:21:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/18/2022 10:21:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/18/2022 10:21:30 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6731353950103951 on epoch=387
06/18/2022 10:21:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=389
06/18/2022 10:21:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/18/2022 10:21:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/18/2022 10:21:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/18/2022 10:21:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/18/2022 10:21:43 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6731353950103951 on epoch=399
06/18/2022 10:21:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/18/2022 10:21:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/18/2022 10:21:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/18/2022 10:21:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/18/2022 10:21:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/18/2022 10:21:57 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6587510897994769 on epoch=412
06/18/2022 10:21:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/18/2022 10:22:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/18/2022 10:22:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/18/2022 10:22:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/18/2022 10:22:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=424
06/18/2022 10:22:10 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6587510897994769 on epoch=424
06/18/2022 10:22:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/18/2022 10:22:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/18/2022 10:22:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=432
06/18/2022 10:22:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/18/2022 10:22:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/18/2022 10:22:23 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6444380181222287 on epoch=437
06/18/2022 10:22:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/18/2022 10:22:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/18/2022 10:22:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=444
06/18/2022 10:22:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/18/2022 10:22:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/18/2022 10:22:37 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6743535327151626 on epoch=449
06/18/2022 10:22:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6739583333333334 -> 0.6743535327151626 on epoch=449, global_step=1800
06/18/2022 10:22:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/18/2022 10:22:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=454
06/18/2022 10:22:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/18/2022 10:22:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/18/2022 10:22:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/18/2022 10:22:50 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6731353950103951 on epoch=462
06/18/2022 10:22:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/18/2022 10:22:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/18/2022 10:22:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/18/2022 10:23:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/18/2022 10:23:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=474
06/18/2022 10:23:03 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6743535327151626 on epoch=474
06/18/2022 10:23:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/18/2022 10:23:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
06/18/2022 10:23:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/18/2022 10:23:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/18/2022 10:23:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/18/2022 10:23:17 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6743535327151626 on epoch=487
06/18/2022 10:23:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
06/18/2022 10:23:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/18/2022 10:23:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/18/2022 10:23:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/18/2022 10:23:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/18/2022 10:23:30 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6743535327151626 on epoch=499
06/18/2022 10:23:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=502
06/18/2022 10:23:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=504
06/18/2022 10:23:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/18/2022 10:23:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/18/2022 10:23:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/18/2022 10:23:44 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6743535327151626 on epoch=512
06/18/2022 10:23:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/18/2022 10:23:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/18/2022 10:23:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/18/2022 10:23:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/18/2022 10:23:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/18/2022 10:23:57 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6731353950103951 on epoch=524
06/18/2022 10:24:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/18/2022 10:24:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/18/2022 10:24:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/18/2022 10:24:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
06/18/2022 10:24:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/18/2022 10:24:11 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6731353950103951 on epoch=537
06/18/2022 10:24:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/18/2022 10:24:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/18/2022 10:24:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/18/2022 10:24:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/18/2022 10:24:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/18/2022 10:24:25 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6596153846153846 on epoch=549
06/18/2022 10:24:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/18/2022 10:24:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/18/2022 10:24:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/18/2022 10:24:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/18/2022 10:24:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/18/2022 10:24:38 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6743535327151626 on epoch=562
06/18/2022 10:24:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/18/2022 10:24:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/18/2022 10:24:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/18/2022 10:24:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/18/2022 10:24:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/18/2022 10:24:52 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6743535327151626 on epoch=574
06/18/2022 10:24:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/18/2022 10:24:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/18/2022 10:24:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/18/2022 10:25:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/18/2022 10:25:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=587
06/18/2022 10:25:05 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6849142085984191 on epoch=587
06/18/2022 10:25:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6743535327151626 -> 0.6849142085984191 on epoch=587, global_step=2350
06/18/2022 10:25:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/18/2022 10:25:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/18/2022 10:25:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=594
06/18/2022 10:25:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/18/2022 10:25:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/18/2022 10:25:19 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6731353950103951 on epoch=599
06/18/2022 10:25:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=602
06/18/2022 10:25:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/18/2022 10:25:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/18/2022 10:25:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/18/2022 10:25:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/18/2022 10:25:32 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6743535327151626 on epoch=612
06/18/2022 10:25:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/18/2022 10:25:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/18/2022 10:25:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/18/2022 10:25:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=622
06/18/2022 10:25:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/18/2022 10:25:46 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6743535327151626 on epoch=624
06/18/2022 10:25:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/18/2022 10:25:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/18/2022 10:25:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/18/2022 10:25:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/18/2022 10:25:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/18/2022 10:26:00 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6743535327151626 on epoch=637
06/18/2022 10:26:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/18/2022 10:26:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/18/2022 10:26:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/18/2022 10:26:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/18/2022 10:26:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/18/2022 10:26:13 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6596153846153846 on epoch=649
06/18/2022 10:26:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/18/2022 10:26:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=654
06/18/2022 10:26:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/18/2022 10:26:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/18/2022 10:26:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/18/2022 10:26:26 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6743535327151626 on epoch=662
06/18/2022 10:26:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/18/2022 10:26:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/18/2022 10:26:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/18/2022 10:26:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/18/2022 10:26:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=674
06/18/2022 10:26:40 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6743535327151626 on epoch=674
06/18/2022 10:26:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/18/2022 10:26:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/18/2022 10:26:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/18/2022 10:26:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/18/2022 10:26:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/18/2022 10:26:53 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6743535327151626 on epoch=687
06/18/2022 10:26:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/18/2022 10:26:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/18/2022 10:27:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/18/2022 10:27:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/18/2022 10:27:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/18/2022 10:27:07 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6743535327151626 on epoch=699
06/18/2022 10:27:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/18/2022 10:27:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=704
06/18/2022 10:27:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/18/2022 10:27:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/18/2022 10:27:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/18/2022 10:27:20 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6743535327151626 on epoch=712
06/18/2022 10:27:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/18/2022 10:27:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/18/2022 10:27:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/18/2022 10:27:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=722
06/18/2022 10:27:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/18/2022 10:27:34 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6743535327151626 on epoch=724
06/18/2022 10:27:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/18/2022 10:27:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/18/2022 10:27:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/18/2022 10:27:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/18/2022 10:27:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/18/2022 10:27:47 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6743535327151626 on epoch=737
06/18/2022 10:27:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/18/2022 10:27:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/18/2022 10:27:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/18/2022 10:27:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/18/2022 10:28:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/18/2022 10:28:02 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6743535327151626 on epoch=749
06/18/2022 10:28:02 - INFO - __main__ - save last model!
06/18/2022 10:28:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 10:28:02 - INFO - __main__ - Start tokenizing ... 5509 instances
06/18/2022 10:28:02 - INFO - __main__ - Printing 3 examples
06/18/2022 10:28:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/18/2022 10:28:02 - INFO - __main__ - ['others']
06/18/2022 10:28:02 - INFO - __main__ -  [emo] what you like very little things ok
06/18/2022 10:28:02 - INFO - __main__ - ['others']
06/18/2022 10:28:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/18/2022 10:28:02 - INFO - __main__ - ['others']
06/18/2022 10:28:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 10:28:04 - INFO - __main__ - Tokenizing Output ...
06/18/2022 10:28:09 - INFO - __main__ - Loaded 5509 examples from test data
06/18/2022 10:29:37 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/18/2022 10:29:37 - INFO - __main__ - Classification-F1 on test data: 0.1582
06/18/2022 10:29:38 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.6849142085984191, test_performance=0.15817563815643582
