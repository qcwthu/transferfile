06/17/2022 15:53:31 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-10-up64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-10-64shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/17/2022 15:53:31 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14
06/17/2022 15:53:32 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-10-up64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-10-64shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/17/2022 15:53:32 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14
06/17/2022 15:53:32 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/17/2022 15:53:32 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/17/2022 15:53:32 - INFO - __main__ - args.device: cuda:0
06/17/2022 15:53:32 - INFO - __main__ - Using 2 gpus
06/17/2022 15:53:32 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/17/2022 15:53:32 - INFO - __main__ - args.device: cuda:1
06/17/2022 15:53:32 - INFO - __main__ - Using 2 gpus
06/17/2022 15:53:32 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/17/2022 15:53:37 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/17/2022 15:53:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 15:53:37 - INFO - __main__ - Printing 3 examples
06/17/2022 15:53:37 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 15:53:37 - INFO - __main__ - ['Animal']
06/17/2022 15:53:37 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 15:53:37 - INFO - __main__ - ['Animal']
06/17/2022 15:53:37 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 15:53:37 - INFO - __main__ - ['Animal']
06/17/2022 15:53:37 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:53:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 15:53:37 - INFO - __main__ - Printing 3 examples
06/17/2022 15:53:37 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 15:53:37 - INFO - __main__ - ['Animal']
06/17/2022 15:53:37 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 15:53:37 - INFO - __main__ - ['Animal']
06/17/2022 15:53:37 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 15:53:37 - INFO - __main__ - ['Animal']
06/17/2022 15:53:37 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:53:38 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:53:38 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:53:38 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 15:53:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 15:53:38 - INFO - __main__ - Printing 3 examples
06/17/2022 15:53:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 15:53:38 - INFO - __main__ - ['Animal']
06/17/2022 15:53:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 15:53:38 - INFO - __main__ - ['Animal']
06/17/2022 15:53:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 15:53:38 - INFO - __main__ - ['Animal']
06/17/2022 15:53:38 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:53:38 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 15:53:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 15:53:38 - INFO - __main__ - Printing 3 examples
06/17/2022 15:53:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 15:53:38 - INFO - __main__ - ['Animal']
06/17/2022 15:53:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 15:53:38 - INFO - __main__ - ['Animal']
06/17/2022 15:53:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 15:53:38 - INFO - __main__ - ['Animal']
06/17/2022 15:53:38 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:53:38 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:53:38 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:53:38 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 15:53:38 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 15:53:56 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:53:56 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:53:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 15:53:57 - INFO - __main__ - Starting training!
06/17/2022 15:54:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 15:54:01 - INFO - __main__ - Starting training!
06/17/2022 15:54:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.48 on epoch=0
06/17/2022 15:54:08 - INFO - __main__ - Step 20 Global step 20 Train loss 4.64 on epoch=1
06/17/2022 15:54:11 - INFO - __main__ - Step 30 Global step 30 Train loss 3.91 on epoch=2
06/17/2022 15:54:13 - INFO - __main__ - Step 40 Global step 40 Train loss 3.55 on epoch=2
06/17/2022 15:54:16 - INFO - __main__ - Step 50 Global step 50 Train loss 3.06 on epoch=3
06/17/2022 15:54:21 - INFO - __main__ - Global step 50 Train loss 4.33 Classification-F1 0.09449715410666175 on epoch=3
06/17/2022 15:54:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09449715410666175 on epoch=3, global_step=50
06/17/2022 15:54:23 - INFO - __main__ - Step 60 Global step 60 Train loss 2.91 on epoch=4
06/17/2022 15:54:26 - INFO - __main__ - Step 70 Global step 70 Train loss 2.21 on epoch=4
06/17/2022 15:54:29 - INFO - __main__ - Step 80 Global step 80 Train loss 2.37 on epoch=5
06/17/2022 15:54:31 - INFO - __main__ - Step 90 Global step 90 Train loss 1.99 on epoch=6
06/17/2022 15:54:34 - INFO - __main__ - Step 100 Global step 100 Train loss 1.79 on epoch=7
06/17/2022 15:54:39 - INFO - __main__ - Global step 100 Train loss 2.26 Classification-F1 0.12245518216089807 on epoch=7
06/17/2022 15:54:39 - INFO - __main__ - Saving model with best Classification-F1: 0.09449715410666175 -> 0.12245518216089807 on epoch=7, global_step=100
06/17/2022 15:54:42 - INFO - __main__ - Step 110 Global step 110 Train loss 1.59 on epoch=7
06/17/2022 15:54:44 - INFO - __main__ - Step 120 Global step 120 Train loss 1.50 on epoch=8
06/17/2022 15:54:47 - INFO - __main__ - Step 130 Global step 130 Train loss 1.53 on epoch=9
06/17/2022 15:54:49 - INFO - __main__ - Step 140 Global step 140 Train loss 1.24 on epoch=9
06/17/2022 15:54:52 - INFO - __main__ - Step 150 Global step 150 Train loss 1.10 on epoch=10
06/17/2022 15:54:58 - INFO - __main__ - Global step 150 Train loss 1.39 Classification-F1 0.35281495838727894 on epoch=10
06/17/2022 15:54:58 - INFO - __main__ - Saving model with best Classification-F1: 0.12245518216089807 -> 0.35281495838727894 on epoch=10, global_step=150
06/17/2022 15:55:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.99 on epoch=11
06/17/2022 15:55:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.97 on epoch=12
06/17/2022 15:55:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=12
06/17/2022 15:55:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=13
06/17/2022 15:55:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
06/17/2022 15:55:17 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.546381314268775 on epoch=14
06/17/2022 15:55:17 - INFO - __main__ - Saving model with best Classification-F1: 0.35281495838727894 -> 0.546381314268775 on epoch=14, global_step=200
06/17/2022 15:55:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=14
06/17/2022 15:55:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=15
06/17/2022 15:55:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=16
06/17/2022 15:55:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=17
06/17/2022 15:55:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=17
06/17/2022 15:55:36 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.5899627675718758 on epoch=17
06/17/2022 15:55:36 - INFO - __main__ - Saving model with best Classification-F1: 0.546381314268775 -> 0.5899627675718758 on epoch=17, global_step=250
06/17/2022 15:55:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
06/17/2022 15:55:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=19
06/17/2022 15:55:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=19
06/17/2022 15:55:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
06/17/2022 15:55:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=21
06/17/2022 15:55:56 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.7283117917526519 on epoch=21
06/17/2022 15:55:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5899627675718758 -> 0.7283117917526519 on epoch=21, global_step=300
06/17/2022 15:55:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
06/17/2022 15:56:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=22
06/17/2022 15:56:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=23
06/17/2022 15:56:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=24
06/17/2022 15:56:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=24
06/17/2022 15:56:15 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6562202470122175 on epoch=24
06/17/2022 15:56:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/17/2022 15:56:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=26
06/17/2022 15:56:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=27
06/17/2022 15:56:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=27
06/17/2022 15:56:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
06/17/2022 15:56:35 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.7081702845143705 on epoch=28
06/17/2022 15:56:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/17/2022 15:56:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
06/17/2022 15:56:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
06/17/2022 15:56:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
06/17/2022 15:56:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=32
06/17/2022 15:56:55 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.7097366545184383 on epoch=32
06/17/2022 15:56:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
06/17/2022 15:57:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
06/17/2022 15:57:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
06/17/2022 15:57:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
06/17/2022 15:57:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/17/2022 15:57:14 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7686420036836301 on epoch=35
06/17/2022 15:57:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7283117917526519 -> 0.7686420036836301 on epoch=35, global_step=500
06/17/2022 15:57:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
06/17/2022 15:57:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
06/17/2022 15:57:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
06/17/2022 15:57:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=38
06/17/2022 15:57:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=39
06/17/2022 15:57:33 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.8109388819066239 on epoch=39
06/17/2022 15:57:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7686420036836301 -> 0.8109388819066239 on epoch=39, global_step=550
06/17/2022 15:57:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/17/2022 15:57:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
06/17/2022 15:57:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
06/17/2022 15:57:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
06/17/2022 15:57:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=42
06/17/2022 15:57:52 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.7722198931050953 on epoch=42
06/17/2022 15:57:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
06/17/2022 15:57:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=44
06/17/2022 15:58:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=44
06/17/2022 15:58:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
06/17/2022 15:58:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/17/2022 15:58:11 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7736941110755152 on epoch=46
06/17/2022 15:58:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/17/2022 15:58:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
06/17/2022 15:58:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/17/2022 15:58:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/17/2022 15:58:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
06/17/2022 15:58:30 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6683720686916532 on epoch=49
06/17/2022 15:58:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
06/17/2022 15:58:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
06/17/2022 15:58:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/17/2022 15:58:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/17/2022 15:58:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=53
06/17/2022 15:58:49 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6532420984033888 on epoch=53
06/17/2022 15:58:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=54
06/17/2022 15:58:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=54
06/17/2022 15:58:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
06/17/2022 15:58:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/17/2022 15:59:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/17/2022 15:59:08 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6503905399171555 on epoch=57
06/17/2022 15:59:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/17/2022 15:59:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/17/2022 15:59:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
06/17/2022 15:59:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
06/17/2022 15:59:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/17/2022 15:59:27 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.740393718794841 on epoch=60
06/17/2022 15:59:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
06/17/2022 15:59:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/17/2022 15:59:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/17/2022 15:59:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/17/2022 15:59:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
06/17/2022 15:59:46 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7399929315341502 on epoch=64
06/17/2022 15:59:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=64
06/17/2022 15:59:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/17/2022 15:59:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 15:59:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/17/2022 15:59:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/17/2022 16:00:05 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.79288137542407 on epoch=67
06/17/2022 16:00:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/17/2022 16:00:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/17/2022 16:00:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
06/17/2022 16:00:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/17/2022 16:00:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/17/2022 16:00:23 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7857512506468864 on epoch=71
06/17/2022 16:00:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/17/2022 16:00:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/17/2022 16:00:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/17/2022 16:00:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/17/2022 16:00:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/17/2022 16:00:42 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.79338953266847 on epoch=74
06/17/2022 16:00:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
06/17/2022 16:00:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
06/17/2022 16:00:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/17/2022 16:00:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
06/17/2022 16:00:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
06/17/2022 16:01:01 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7479393908550489 on epoch=78
06/17/2022 16:01:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
06/17/2022 16:01:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/17/2022 16:01:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
06/17/2022 16:01:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/17/2022 16:01:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
06/17/2022 16:01:19 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8006970891221366 on epoch=82
06/17/2022 16:01:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/17/2022 16:01:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 16:01:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/17/2022 16:01:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/17/2022 16:01:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/17/2022 16:01:38 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7860009608991687 on epoch=85
06/17/2022 16:01:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/17/2022 16:01:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
06/17/2022 16:01:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
06/17/2022 16:01:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/17/2022 16:01:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/17/2022 16:01:57 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7743999721675802 on epoch=89
06/17/2022 16:02:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/17/2022 16:02:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 16:02:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/17/2022 16:02:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/17/2022 16:02:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/17/2022 16:02:16 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7420503033406258 on epoch=92
06/17/2022 16:02:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/17/2022 16:02:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/17/2022 16:02:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 16:02:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/17/2022 16:02:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/17/2022 16:02:35 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7685201157686926 on epoch=96
06/17/2022 16:02:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/17/2022 16:02:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 16:02:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/17/2022 16:02:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 16:02:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/17/2022 16:02:53 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8258812029210512 on epoch=99
06/17/2022 16:02:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8109388819066239 -> 0.8258812029210512 on epoch=99, global_step=1400
06/17/2022 16:02:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
06/17/2022 16:02:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/17/2022 16:03:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/17/2022 16:03:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/17/2022 16:03:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/17/2022 16:03:12 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.801595972373961 on epoch=103
06/17/2022 16:03:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=104
06/17/2022 16:03:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/17/2022 16:03:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/17/2022 16:03:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 16:03:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/17/2022 16:03:31 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.849679863147605 on epoch=107
06/17/2022 16:03:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8258812029210512 -> 0.849679863147605 on epoch=107, global_step=1500
06/17/2022 16:03:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/17/2022 16:03:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/17/2022 16:03:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/17/2022 16:03:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/17/2022 16:03:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/17/2022 16:03:50 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8457697947214076 on epoch=110
06/17/2022 16:03:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/17/2022 16:03:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/17/2022 16:03:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/17/2022 16:04:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/17/2022 16:04:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/17/2022 16:04:09 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.855605789073531 on epoch=114
06/17/2022 16:04:09 - INFO - __main__ - Saving model with best Classification-F1: 0.849679863147605 -> 0.855605789073531 on epoch=114, global_step=1600
06/17/2022 16:04:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/17/2022 16:04:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/17/2022 16:04:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/17/2022 16:04:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 16:04:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/17/2022 16:04:28 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8544526314924797 on epoch=117
06/17/2022 16:04:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/17/2022 16:04:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/17/2022 16:04:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/17/2022 16:04:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 16:04:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/17/2022 16:04:47 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.849679863147605 on epoch=121
06/17/2022 16:04:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 16:04:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/17/2022 16:04:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/17/2022 16:04:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/17/2022 16:05:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 16:05:05 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8488467177983308 on epoch=124
06/17/2022 16:05:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/17/2022 16:05:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/17/2022 16:05:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/17/2022 16:05:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 16:05:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/17/2022 16:05:24 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.805276036775088 on epoch=128
06/17/2022 16:05:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/17/2022 16:05:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 16:05:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 16:05:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/17/2022 16:05:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/17/2022 16:05:43 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.855605789073531 on epoch=132
06/17/2022 16:05:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 16:05:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 16:05:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 16:05:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/17/2022 16:05:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 16:06:02 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8489581259979742 on epoch=135
06/17/2022 16:06:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 16:06:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/17/2022 16:06:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 16:06:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 16:06:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 16:06:21 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8527567862245282 on epoch=139
06/17/2022 16:06:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 16:06:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/17/2022 16:06:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/17/2022 16:06:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/17/2022 16:06:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 16:06:40 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8607143459062259 on epoch=142
06/17/2022 16:06:40 - INFO - __main__ - Saving model with best Classification-F1: 0.855605789073531 -> 0.8607143459062259 on epoch=142, global_step=2000
06/17/2022 16:06:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
06/17/2022 16:06:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/17/2022 16:06:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 16:06:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
06/17/2022 16:06:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 16:07:00 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8607143459062259 on epoch=146
06/17/2022 16:07:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/17/2022 16:07:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/17/2022 16:07:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
06/17/2022 16:07:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/17/2022 16:07:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/17/2022 16:07:19 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8569156856796718 on epoch=149
06/17/2022 16:07:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/17/2022 16:07:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/17/2022 16:07:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/17/2022 16:07:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/17/2022 16:07:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 16:07:38 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=153
06/17/2022 16:07:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8607143459062259 -> 0.8630131964809384 on epoch=153, global_step=2150
06/17/2022 16:07:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/17/2022 16:07:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 16:07:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/17/2022 16:07:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 16:07:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 16:07:57 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8609970674486804 on epoch=157
06/17/2022 16:08:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/17/2022 16:08:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/17/2022 16:08:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 16:08:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 16:08:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 16:08:16 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=160
06/17/2022 16:08:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8630131964809384 -> 0.9910627007401202 on epoch=160, global_step=2250
06/17/2022 16:08:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/17/2022 16:08:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 16:08:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 16:08:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 16:08:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 16:08:36 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=164
06/17/2022 16:08:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 16:08:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 16:08:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/17/2022 16:08:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/17/2022 16:08:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 16:08:55 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.855605789073531 on epoch=167
06/17/2022 16:08:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/17/2022 16:09:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 16:09:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 16:09:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 16:09:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
06/17/2022 16:09:14 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=171
06/17/2022 16:09:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 16:09:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 16:09:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/17/2022 16:09:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 16:09:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 16:09:34 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=174
06/17/2022 16:09:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 16:09:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/17/2022 16:09:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 16:09:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/17/2022 16:09:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 16:09:53 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=178
06/17/2022 16:09:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/17/2022 16:09:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 16:10:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/17/2022 16:10:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 16:10:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 16:10:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=182
06/17/2022 16:10:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/17/2022 16:10:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 16:10:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 16:10:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 16:10:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/17/2022 16:10:32 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=185
06/17/2022 16:10:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 16:10:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/17/2022 16:10:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 16:10:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 16:10:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 16:10:52 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=189
06/17/2022 16:10:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 16:10:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 16:10:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 16:11:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 16:11:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 16:11:11 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=192
06/17/2022 16:11:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/17/2022 16:11:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/17/2022 16:11:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/17/2022 16:11:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 16:11:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/17/2022 16:11:31 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=196
06/17/2022 16:11:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 16:11:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 16:11:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/17/2022 16:11:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/17/2022 16:11:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/17/2022 16:11:51 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=199
06/17/2022 16:11:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 16:11:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/17/2022 16:11:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/17/2022 16:12:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 16:12:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 16:12:11 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=203
06/17/2022 16:12:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/17/2022 16:12:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/17/2022 16:12:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 16:12:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/17/2022 16:12:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 16:12:30 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=207
06/17/2022 16:12:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/17/2022 16:12:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 16:12:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 16:12:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 16:12:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/17/2022 16:12:50 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=210
06/17/2022 16:12:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 16:12:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 16:12:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 16:13:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 16:13:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 16:13:05 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:13:05 - INFO - __main__ - Printing 3 examples
06/17/2022 16:13:05 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 16:13:05 - INFO - __main__ - ['Animal']
06/17/2022 16:13:05 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 16:13:05 - INFO - __main__ - ['Animal']
06/17/2022 16:13:05 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 16:13:05 - INFO - __main__ - ['Animal']
06/17/2022 16:13:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:13:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:13:05 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 16:13:05 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:13:05 - INFO - __main__ - Printing 3 examples
06/17/2022 16:13:05 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 16:13:05 - INFO - __main__ - ['Animal']
06/17/2022 16:13:05 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 16:13:05 - INFO - __main__ - ['Animal']
06/17/2022 16:13:05 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 16:13:05 - INFO - __main__ - ['Animal']
06/17/2022 16:13:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:13:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:13:05 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 16:13:10 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=214
06/17/2022 16:13:10 - INFO - __main__ - save last model!
06/17/2022 16:13:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 16:13:10 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 16:13:10 - INFO - __main__ - Printing 3 examples
06/17/2022 16:13:10 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 16:13:10 - INFO - __main__ - ['Animal']
06/17/2022 16:13:10 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 16:13:10 - INFO - __main__ - ['Animal']
06/17/2022 16:13:10 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 16:13:10 - INFO - __main__ - ['Village']
06/17/2022 16:13:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:13:12 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:13:16 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 16:13:21 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 16:13:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 16:13:21 - INFO - __main__ - Starting training!
06/17/2022 16:15:47 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/17/2022 16:15:47 - INFO - __main__ - Classification-F1 on test data: 0.6503
06/17/2022 16:15:48 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6503113726227004
06/17/2022 16:15:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/17/2022 16:15:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:15:49 - INFO - __main__ - Printing 3 examples
06/17/2022 16:15:49 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 16:15:49 - INFO - __main__ - ['Animal']
06/17/2022 16:15:49 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 16:15:49 - INFO - __main__ - ['Animal']
06/17/2022 16:15:49 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 16:15:49 - INFO - __main__ - ['Animal']
06/17/2022 16:15:49 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:15:49 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:15:49 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 16:15:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:15:49 - INFO - __main__ - Printing 3 examples
06/17/2022 16:15:49 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 16:15:49 - INFO - __main__ - ['Animal']
06/17/2022 16:15:49 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 16:15:49 - INFO - __main__ - ['Animal']
06/17/2022 16:15:49 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 16:15:49 - INFO - __main__ - ['Animal']
06/17/2022 16:15:49 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:15:49 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:15:50 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 16:16:05 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 16:16:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 16:16:06 - INFO - __main__ - Starting training!
06/17/2022 16:16:09 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=0
06/17/2022 16:16:12 - INFO - __main__ - Step 20 Global step 20 Train loss 4.79 on epoch=1
06/17/2022 16:16:14 - INFO - __main__ - Step 30 Global step 30 Train loss 4.03 on epoch=2
06/17/2022 16:16:17 - INFO - __main__ - Step 40 Global step 40 Train loss 3.63 on epoch=2
06/17/2022 16:16:20 - INFO - __main__ - Step 50 Global step 50 Train loss 3.29 on epoch=3
06/17/2022 16:16:25 - INFO - __main__ - Global step 50 Train loss 4.47 Classification-F1 0.07886064255828339 on epoch=3
06/17/2022 16:16:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07886064255828339 on epoch=3, global_step=50
06/17/2022 16:16:28 - INFO - __main__ - Step 60 Global step 60 Train loss 3.29 on epoch=4
06/17/2022 16:16:31 - INFO - __main__ - Step 70 Global step 70 Train loss 2.50 on epoch=4
06/17/2022 16:16:33 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=5
06/17/2022 16:16:36 - INFO - __main__ - Step 90 Global step 90 Train loss 2.16 on epoch=6
06/17/2022 16:16:38 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=7
06/17/2022 16:16:44 - INFO - __main__ - Global step 100 Train loss 2.48 Classification-F1 0.10455398842495615 on epoch=7
06/17/2022 16:16:44 - INFO - __main__ - Saving model with best Classification-F1: 0.07886064255828339 -> 0.10455398842495615 on epoch=7, global_step=100
06/17/2022 16:16:47 - INFO - __main__ - Step 110 Global step 110 Train loss 1.85 on epoch=7
06/17/2022 16:16:49 - INFO - __main__ - Step 120 Global step 120 Train loss 1.77 on epoch=8
06/17/2022 16:16:52 - INFO - __main__ - Step 130 Global step 130 Train loss 1.81 on epoch=9
06/17/2022 16:16:54 - INFO - __main__ - Step 140 Global step 140 Train loss 1.37 on epoch=9
06/17/2022 16:16:57 - INFO - __main__ - Step 150 Global step 150 Train loss 1.47 on epoch=10
06/17/2022 16:17:03 - INFO - __main__ - Global step 150 Train loss 1.65 Classification-F1 0.17848438152564527 on epoch=10
06/17/2022 16:17:03 - INFO - __main__ - Saving model with best Classification-F1: 0.10455398842495615 -> 0.17848438152564527 on epoch=10, global_step=150
06/17/2022 16:17:06 - INFO - __main__ - Step 160 Global step 160 Train loss 1.23 on epoch=11
06/17/2022 16:17:08 - INFO - __main__ - Step 170 Global step 170 Train loss 1.19 on epoch=12
06/17/2022 16:17:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.99 on epoch=12
06/17/2022 16:17:13 - INFO - __main__ - Step 190 Global step 190 Train loss 1.07 on epoch=13
06/17/2022 16:17:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=14
06/17/2022 16:17:22 - INFO - __main__ - Global step 200 Train loss 1.09 Classification-F1 0.36594944133290835 on epoch=14
06/17/2022 16:17:22 - INFO - __main__ - Saving model with best Classification-F1: 0.17848438152564527 -> 0.36594944133290835 on epoch=14, global_step=200
06/17/2022 16:17:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=14
06/17/2022 16:17:28 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=15
06/17/2022 16:17:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=16
06/17/2022 16:17:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=17
06/17/2022 16:17:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.63 on epoch=17
06/17/2022 16:17:42 - INFO - __main__ - Global step 250 Train loss 0.76 Classification-F1 0.48846904958767806 on epoch=17
06/17/2022 16:17:42 - INFO - __main__ - Saving model with best Classification-F1: 0.36594944133290835 -> 0.48846904958767806 on epoch=17, global_step=250
06/17/2022 16:17:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=18
06/17/2022 16:17:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.64 on epoch=19
06/17/2022 16:17:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
06/17/2022 16:17:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=20
06/17/2022 16:17:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=21
06/17/2022 16:18:01 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.5596950777852538 on epoch=21
06/17/2022 16:18:01 - INFO - __main__ - Saving model with best Classification-F1: 0.48846904958767806 -> 0.5596950777852538 on epoch=21, global_step=300
06/17/2022 16:18:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=22
06/17/2022 16:18:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=22
06/17/2022 16:18:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=23
06/17/2022 16:18:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=24
06/17/2022 16:18:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=24
06/17/2022 16:18:21 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.5460094837373939 on epoch=24
06/17/2022 16:18:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=25
06/17/2022 16:18:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
06/17/2022 16:18:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=27
06/17/2022 16:18:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
06/17/2022 16:18:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=28
06/17/2022 16:18:40 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6050891275376231 on epoch=28
06/17/2022 16:18:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5596950777852538 -> 0.6050891275376231 on epoch=28, global_step=400
06/17/2022 16:18:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/17/2022 16:18:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=29
06/17/2022 16:18:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=30
06/17/2022 16:18:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=31
06/17/2022 16:18:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/17/2022 16:18:59 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.6471412570404507 on epoch=32
06/17/2022 16:18:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6050891275376231 -> 0.6471412570404507 on epoch=32, global_step=450
06/17/2022 16:19:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=32
06/17/2022 16:19:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/17/2022 16:19:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=34
06/17/2022 16:19:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
06/17/2022 16:19:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=35
06/17/2022 16:19:18 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6560433557587257 on epoch=35
06/17/2022 16:19:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6471412570404507 -> 0.6560433557587257 on epoch=35, global_step=500
06/17/2022 16:19:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/17/2022 16:19:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=37
06/17/2022 16:19:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
06/17/2022 16:19:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/17/2022 16:19:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
06/17/2022 16:19:37 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6893386922359784 on epoch=39
06/17/2022 16:19:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6560433557587257 -> 0.6893386922359784 on epoch=39, global_step=550
06/17/2022 16:19:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/17/2022 16:19:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/17/2022 16:19:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
06/17/2022 16:19:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
06/17/2022 16:19:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/17/2022 16:19:56 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.742334240849215 on epoch=42
06/17/2022 16:19:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6893386922359784 -> 0.742334240849215 on epoch=42, global_step=600
06/17/2022 16:19:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
06/17/2022 16:20:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/17/2022 16:20:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/17/2022 16:20:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/17/2022 16:20:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/17/2022 16:20:15 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.8292795123914669 on epoch=46
06/17/2022 16:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.742334240849215 -> 0.8292795123914669 on epoch=46, global_step=650
06/17/2022 16:20:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/17/2022 16:20:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
06/17/2022 16:20:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
06/17/2022 16:20:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/17/2022 16:20:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/17/2022 16:20:34 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.8273885610520506 on epoch=49
06/17/2022 16:20:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=50
06/17/2022 16:20:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
06/17/2022 16:20:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
06/17/2022 16:20:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/17/2022 16:20:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/17/2022 16:20:54 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.839312126835846 on epoch=53
06/17/2022 16:20:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8292795123914669 -> 0.839312126835846 on epoch=53, global_step=750
06/17/2022 16:20:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=54
06/17/2022 16:20:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/17/2022 16:21:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/17/2022 16:21:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
06/17/2022 16:21:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/17/2022 16:21:13 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8905791994217043 on epoch=57
06/17/2022 16:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.839312126835846 -> 0.8905791994217043 on epoch=57, global_step=800
06/17/2022 16:21:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/17/2022 16:21:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/17/2022 16:21:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/17/2022 16:21:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/17/2022 16:21:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
06/17/2022 16:21:32 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8312948110520506 on epoch=60
06/17/2022 16:21:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/17/2022 16:21:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/17/2022 16:21:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
06/17/2022 16:21:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/17/2022 16:21:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/17/2022 16:21:50 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.838251332791181 on epoch=64
06/17/2022 16:21:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/17/2022 16:21:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/17/2022 16:21:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/17/2022 16:22:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/17/2022 16:22:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/17/2022 16:22:09 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7404226518408517 on epoch=67
06/17/2022 16:22:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/17/2022 16:22:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/17/2022 16:22:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/17/2022 16:22:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/17/2022 16:22:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/17/2022 16:22:28 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7255424033412647 on epoch=71
06/17/2022 16:22:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
06/17/2022 16:22:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/17/2022 16:22:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/17/2022 16:22:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
06/17/2022 16:22:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/17/2022 16:22:46 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.6988595322796293 on epoch=74
06/17/2022 16:22:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/17/2022 16:22:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/17/2022 16:22:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/17/2022 16:22:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
06/17/2022 16:22:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/17/2022 16:23:05 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8488237173958237 on epoch=78
06/17/2022 16:23:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/17/2022 16:23:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
06/17/2022 16:23:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/17/2022 16:23:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/17/2022 16:23:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/17/2022 16:23:24 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7512170212294533 on epoch=82
06/17/2022 16:23:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/17/2022 16:23:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/17/2022 16:23:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/17/2022 16:23:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/17/2022 16:23:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/17/2022 16:23:44 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8517190747266649 on epoch=85
06/17/2022 16:23:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/17/2022 16:23:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/17/2022 16:23:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/17/2022 16:23:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/17/2022 16:23:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/17/2022 16:24:03 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9063408481672239 on epoch=89
06/17/2022 16:24:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8905791994217043 -> 0.9063408481672239 on epoch=89, global_step=1250
06/17/2022 16:24:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/17/2022 16:24:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 16:24:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/17/2022 16:24:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
06/17/2022 16:24:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/17/2022 16:24:23 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.9187894121480459 on epoch=92
06/17/2022 16:24:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9063408481672239 -> 0.9187894121480459 on epoch=92, global_step=1300
06/17/2022 16:24:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/17/2022 16:24:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/17/2022 16:24:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/17/2022 16:24:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/17/2022 16:24:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/17/2022 16:24:43 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9187894121480459 on epoch=96
06/17/2022 16:24:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/17/2022 16:24:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/17/2022 16:24:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/17/2022 16:24:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 16:24:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/17/2022 16:25:01 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9682345730732829 on epoch=99
06/17/2022 16:25:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9187894121480459 -> 0.9682345730732829 on epoch=99, global_step=1400
06/17/2022 16:25:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/17/2022 16:25:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/17/2022 16:25:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/17/2022 16:25:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/17/2022 16:25:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/17/2022 16:25:21 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=103
06/17/2022 16:25:21 - INFO - __main__ - Saving model with best Classification-F1: 0.9682345730732829 -> 0.9867213747669157 on epoch=103, global_step=1450
06/17/2022 16:25:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 16:25:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/17/2022 16:25:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/17/2022 16:25:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/17/2022 16:25:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/17/2022 16:25:40 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9779157630794254 on epoch=107
06/17/2022 16:25:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/17/2022 16:25:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/17/2022 16:25:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 16:25:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/17/2022 16:25:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/17/2022 16:26:00 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9106508840095179 on epoch=110
06/17/2022 16:26:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/17/2022 16:26:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/17/2022 16:26:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/17/2022 16:26:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/17/2022 16:26:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/17/2022 16:26:19 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9106508840095179 on epoch=114
06/17/2022 16:26:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/17/2022 16:26:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/17/2022 16:26:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/17/2022 16:26:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/17/2022 16:26:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/17/2022 16:26:39 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9780015231899212 on epoch=117
06/17/2022 16:26:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/17/2022 16:26:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/17/2022 16:26:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/17/2022 16:26:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 16:26:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/17/2022 16:26:58 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9099914938166591 on epoch=121
06/17/2022 16:27:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/17/2022 16:27:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/17/2022 16:27:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 16:27:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/17/2022 16:27:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/17/2022 16:27:18 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7981256175251041 on epoch=124
06/17/2022 16:27:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/17/2022 16:27:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 16:27:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 16:27:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
06/17/2022 16:27:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/17/2022 16:27:37 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9147375079063884 on epoch=128
06/17/2022 16:27:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/17/2022 16:27:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 16:27:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/17/2022 16:27:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/17/2022 16:27:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/17/2022 16:27:57 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9187894121480459 on epoch=132
06/17/2022 16:27:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/17/2022 16:28:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/17/2022 16:28:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 16:28:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/17/2022 16:28:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/17/2022 16:28:17 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=135
06/17/2022 16:28:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 16:28:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/17/2022 16:28:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 16:28:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 16:28:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 16:28:37 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=139
06/17/2022 16:28:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/17/2022 16:28:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 16:28:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/17/2022 16:28:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/17/2022 16:28:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 16:28:56 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8592145362543845 on epoch=142
06/17/2022 16:28:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/17/2022 16:29:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/17/2022 16:29:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 16:29:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/17/2022 16:29:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 16:29:16 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9187894121480461 on epoch=146
06/17/2022 16:29:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/17/2022 16:29:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 16:29:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/17/2022 16:29:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/17/2022 16:29:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/17/2022 16:29:35 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.863147605083089 on epoch=149
06/17/2022 16:29:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/17/2022 16:29:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 16:29:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/17/2022 16:29:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/17/2022 16:29:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/17/2022 16:29:55 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=153
06/17/2022 16:29:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/17/2022 16:30:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 16:30:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 16:30:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/17/2022 16:30:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 16:30:15 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9186746497230369 on epoch=157
06/17/2022 16:30:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/17/2022 16:30:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/17/2022 16:30:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/17/2022 16:30:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/17/2022 16:30:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 16:30:35 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9144753033178079 on epoch=160
06/17/2022 16:30:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/17/2022 16:30:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 16:30:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/17/2022 16:30:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/17/2022 16:30:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 16:30:55 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=164
06/17/2022 16:30:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 16:31:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 16:31:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/17/2022 16:31:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 16:31:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/17/2022 16:31:15 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=167
06/17/2022 16:31:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 16:31:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 16:31:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/17/2022 16:31:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/17/2022 16:31:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 16:31:35 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=171
06/17/2022 16:31:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/17/2022 16:31:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 16:31:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 16:31:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/17/2022 16:31:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 16:31:55 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=174
06/17/2022 16:31:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 16:32:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/17/2022 16:32:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 16:32:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 16:32:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 16:32:15 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=178
06/17/2022 16:32:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 16:32:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 16:32:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/17/2022 16:32:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/17/2022 16:32:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 16:32:35 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=182
06/17/2022 16:32:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/17/2022 16:32:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 16:32:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 16:32:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/17/2022 16:32:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 16:32:56 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=185
06/17/2022 16:32:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9867213747669157 -> 0.9910627007401202 on epoch=185, global_step=2600
06/17/2022 16:32:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 16:33:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/17/2022 16:33:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 16:33:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 16:33:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 16:33:15 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=189
06/17/2022 16:33:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=189
06/17/2022 16:33:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 16:33:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 16:33:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 16:33:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/17/2022 16:33:36 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=192
06/17/2022 16:33:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/17/2022 16:33:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 16:33:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 16:33:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/17/2022 16:33:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/17/2022 16:33:57 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=196
06/17/2022 16:33:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/17/2022 16:34:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/17/2022 16:34:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 16:34:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 16:34:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 16:34:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9187894121480459 on epoch=199
06/17/2022 16:34:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 16:34:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 16:34:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/17/2022 16:34:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 16:34:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 16:34:38 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=203
06/17/2022 16:34:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 16:34:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 16:34:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 16:34:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 16:34:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/17/2022 16:34:58 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=207
06/17/2022 16:35:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/17/2022 16:35:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 16:35:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 16:35:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/17/2022 16:35:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/17/2022 16:35:19 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9164955053380103 on epoch=210
06/17/2022 16:35:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 16:35:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 16:35:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/17/2022 16:35:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/17/2022 16:35:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/17/2022 16:35:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:35:33 - INFO - __main__ - Printing 3 examples
06/17/2022 16:35:33 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 16:35:33 - INFO - __main__ - ['Animal']
06/17/2022 16:35:33 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 16:35:33 - INFO - __main__ - ['Animal']
06/17/2022 16:35:33 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 16:35:33 - INFO - __main__ - ['Animal']
06/17/2022 16:35:33 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:35:33 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:35:33 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 16:35:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:35:33 - INFO - __main__ - Printing 3 examples
06/17/2022 16:35:33 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 16:35:33 - INFO - __main__ - ['Animal']
06/17/2022 16:35:33 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 16:35:33 - INFO - __main__ - ['Animal']
06/17/2022 16:35:33 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 16:35:33 - INFO - __main__ - ['Animal']
06/17/2022 16:35:33 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:35:33 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:35:33 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 16:35:39 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=214
06/17/2022 16:35:39 - INFO - __main__ - save last model!
06/17/2022 16:35:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 16:35:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 16:35:39 - INFO - __main__ - Printing 3 examples
06/17/2022 16:35:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 16:35:39 - INFO - __main__ - ['Animal']
06/17/2022 16:35:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 16:35:39 - INFO - __main__ - ['Animal']
06/17/2022 16:35:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 16:35:39 - INFO - __main__ - ['Village']
06/17/2022 16:35:39 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:35:41 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:35:44 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 16:35:49 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 16:35:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 16:35:50 - INFO - __main__ - Starting training!
06/17/2022 16:38:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/17/2022 16:38:08 - INFO - __main__ - Classification-F1 on test data: 0.5692
06/17/2022 16:38:09 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.5692329043286738
06/17/2022 16:38:09 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/17/2022 16:38:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:38:10 - INFO - __main__ - Printing 3 examples
06/17/2022 16:38:10 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 16:38:10 - INFO - __main__ - ['Animal']
06/17/2022 16:38:10 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 16:38:10 - INFO - __main__ - ['Animal']
06/17/2022 16:38:10 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 16:38:10 - INFO - __main__ - ['Animal']
06/17/2022 16:38:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:38:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:38:10 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 16:38:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 16:38:10 - INFO - __main__ - Printing 3 examples
06/17/2022 16:38:10 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 16:38:10 - INFO - __main__ - ['Animal']
06/17/2022 16:38:10 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 16:38:10 - INFO - __main__ - ['Animal']
06/17/2022 16:38:10 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 16:38:10 - INFO - __main__ - ['Animal']
06/17/2022 16:38:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 16:38:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 16:38:11 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 16:38:25 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 16:38:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 16:38:26 - INFO - __main__ - Starting training!
06/17/2022 16:38:30 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=0
06/17/2022 16:38:32 - INFO - __main__ - Step 20 Global step 20 Train loss 5.02 on epoch=1
06/17/2022 16:38:35 - INFO - __main__ - Step 30 Global step 30 Train loss 4.31 on epoch=2
06/17/2022 16:38:37 - INFO - __main__ - Step 40 Global step 40 Train loss 3.93 on epoch=2
06/17/2022 16:38:40 - INFO - __main__ - Step 50 Global step 50 Train loss 3.77 on epoch=3
06/17/2022 16:38:46 - INFO - __main__ - Global step 50 Train loss 4.76 Classification-F1 0.04731945823268483 on epoch=3
06/17/2022 16:38:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04731945823268483 on epoch=3, global_step=50
06/17/2022 16:38:48 - INFO - __main__ - Step 60 Global step 60 Train loss 3.80 on epoch=4
06/17/2022 16:38:51 - INFO - __main__ - Step 70 Global step 70 Train loss 3.10 on epoch=4
06/17/2022 16:38:54 - INFO - __main__ - Step 80 Global step 80 Train loss 3.07 on epoch=5
06/17/2022 16:38:56 - INFO - __main__ - Step 90 Global step 90 Train loss 2.65 on epoch=6
06/17/2022 16:38:59 - INFO - __main__ - Step 100 Global step 100 Train loss 2.54 on epoch=7
06/17/2022 16:39:04 - INFO - __main__ - Global step 100 Train loss 3.03 Classification-F1 0.1071993012765091 on epoch=7
06/17/2022 16:39:04 - INFO - __main__ - Saving model with best Classification-F1: 0.04731945823268483 -> 0.1071993012765091 on epoch=7, global_step=100
06/17/2022 16:39:07 - INFO - __main__ - Step 110 Global step 110 Train loss 2.36 on epoch=7
06/17/2022 16:39:09 - INFO - __main__ - Step 120 Global step 120 Train loss 2.22 on epoch=8
06/17/2022 16:39:12 - INFO - __main__ - Step 130 Global step 130 Train loss 2.29 on epoch=9
06/17/2022 16:39:14 - INFO - __main__ - Step 140 Global step 140 Train loss 1.80 on epoch=9
06/17/2022 16:39:17 - INFO - __main__ - Step 150 Global step 150 Train loss 1.86 on epoch=10
06/17/2022 16:39:22 - INFO - __main__ - Global step 150 Train loss 2.11 Classification-F1 0.1345794404107059 on epoch=10
06/17/2022 16:39:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1071993012765091 -> 0.1345794404107059 on epoch=10, global_step=150
06/17/2022 16:39:25 - INFO - __main__ - Step 160 Global step 160 Train loss 1.70 on epoch=11
06/17/2022 16:39:27 - INFO - __main__ - Step 170 Global step 170 Train loss 1.64 on epoch=12
06/17/2022 16:39:30 - INFO - __main__ - Step 180 Global step 180 Train loss 1.55 on epoch=12
06/17/2022 16:39:33 - INFO - __main__ - Step 190 Global step 190 Train loss 1.52 on epoch=13
06/17/2022 16:39:35 - INFO - __main__ - Step 200 Global step 200 Train loss 1.52 on epoch=14
06/17/2022 16:39:41 - INFO - __main__ - Global step 200 Train loss 1.59 Classification-F1 0.17545108646544172 on epoch=14
06/17/2022 16:39:41 - INFO - __main__ - Saving model with best Classification-F1: 0.1345794404107059 -> 0.17545108646544172 on epoch=14, global_step=200
06/17/2022 16:39:44 - INFO - __main__ - Step 210 Global step 210 Train loss 1.20 on epoch=14
06/17/2022 16:39:46 - INFO - __main__ - Step 220 Global step 220 Train loss 1.20 on epoch=15
06/17/2022 16:39:49 - INFO - __main__ - Step 230 Global step 230 Train loss 1.11 on epoch=16
06/17/2022 16:39:51 - INFO - __main__ - Step 240 Global step 240 Train loss 1.20 on epoch=17
06/17/2022 16:39:54 - INFO - __main__ - Step 250 Global step 250 Train loss 1.02 on epoch=17
06/17/2022 16:40:00 - INFO - __main__ - Global step 250 Train loss 1.15 Classification-F1 0.3111342663984835 on epoch=17
06/17/2022 16:40:00 - INFO - __main__ - Saving model with best Classification-F1: 0.17545108646544172 -> 0.3111342663984835 on epoch=17, global_step=250
06/17/2022 16:40:02 - INFO - __main__ - Step 260 Global step 260 Train loss 1.00 on epoch=18
06/17/2022 16:40:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.97 on epoch=19
06/17/2022 16:40:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=19
06/17/2022 16:40:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.77 on epoch=20
06/17/2022 16:40:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=21
06/17/2022 16:40:19 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.4600535721642507 on epoch=21
06/17/2022 16:40:19 - INFO - __main__ - Saving model with best Classification-F1: 0.3111342663984835 -> 0.4600535721642507 on epoch=21, global_step=300
06/17/2022 16:40:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.76 on epoch=22
06/17/2022 16:40:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.66 on epoch=22
06/17/2022 16:40:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=23
06/17/2022 16:40:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.75 on epoch=24
06/17/2022 16:40:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=24
06/17/2022 16:40:39 - INFO - __main__ - Global step 350 Train loss 0.69 Classification-F1 0.5719964201937635 on epoch=24
06/17/2022 16:40:39 - INFO - __main__ - Saving model with best Classification-F1: 0.4600535721642507 -> 0.5719964201937635 on epoch=24, global_step=350
06/17/2022 16:40:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=25
06/17/2022 16:40:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=26
06/17/2022 16:40:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=27
06/17/2022 16:40:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=27
06/17/2022 16:40:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=28
06/17/2022 16:40:58 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6349174521398046 on epoch=28
06/17/2022 16:40:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5719964201937635 -> 0.6349174521398046 on epoch=28, global_step=400
06/17/2022 16:41:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=29
06/17/2022 16:41:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=29
06/17/2022 16:41:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=30
06/17/2022 16:41:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=31
06/17/2022 16:41:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=32
06/17/2022 16:41:18 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.6656978892297298 on epoch=32
06/17/2022 16:41:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6349174521398046 -> 0.6656978892297298 on epoch=32, global_step=450
06/17/2022 16:41:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=32
06/17/2022 16:41:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=33
06/17/2022 16:41:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
06/17/2022 16:41:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/17/2022 16:41:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=35
06/17/2022 16:41:37 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.6688625121582717 on epoch=35
06/17/2022 16:41:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6656978892297298 -> 0.6688625121582717 on epoch=35, global_step=500
06/17/2022 16:41:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=36
06/17/2022 16:41:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=37
06/17/2022 16:41:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
06/17/2022 16:41:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=38
06/17/2022 16:41:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=39
06/17/2022 16:41:57 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7444768894274978 on epoch=39
06/17/2022 16:41:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6688625121582717 -> 0.7444768894274978 on epoch=39, global_step=550
06/17/2022 16:41:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=39
06/17/2022 16:42:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=40
06/17/2022 16:42:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/17/2022 16:42:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=42
06/17/2022 16:42:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=42
06/17/2022 16:42:16 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.679397418276875 on epoch=42
06/17/2022 16:42:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=43
06/17/2022 16:42:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=44
06/17/2022 16:42:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/17/2022 16:42:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/17/2022 16:42:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=46
06/17/2022 16:42:36 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7149342891278375 on epoch=46
06/17/2022 16:42:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/17/2022 16:42:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
06/17/2022 16:42:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
06/17/2022 16:42:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/17/2022 16:42:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
06/17/2022 16:42:56 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.8071402216800699 on epoch=49
06/17/2022 16:42:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7444768894274978 -> 0.8071402216800699 on epoch=49, global_step=700
06/17/2022 16:42:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
06/17/2022 16:43:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/17/2022 16:43:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/17/2022 16:43:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/17/2022 16:43:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=53
06/17/2022 16:43:16 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.7535099049107309 on epoch=53
06/17/2022 16:43:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
06/17/2022 16:43:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/17/2022 16:43:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/17/2022 16:43:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/17/2022 16:43:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/17/2022 16:43:35 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.8267100388542514 on epoch=57
06/17/2022 16:43:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8071402216800699 -> 0.8267100388542514 on epoch=57, global_step=800
06/17/2022 16:43:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/17/2022 16:43:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
06/17/2022 16:43:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
06/17/2022 16:43:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/17/2022 16:43:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
06/17/2022 16:43:55 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.8273422418820902 on epoch=60
06/17/2022 16:43:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8267100388542514 -> 0.8273422418820902 on epoch=60, global_step=850
06/17/2022 16:43:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/17/2022 16:44:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
06/17/2022 16:44:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/17/2022 16:44:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/17/2022 16:44:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
06/17/2022 16:44:14 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.7746006941676101 on epoch=64
06/17/2022 16:44:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/17/2022 16:44:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
06/17/2022 16:44:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=66
06/17/2022 16:44:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=67
06/17/2022 16:44:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/17/2022 16:44:33 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.8129881748964443 on epoch=67
06/17/2022 16:44:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/17/2022 16:44:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/17/2022 16:44:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/17/2022 16:44:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/17/2022 16:44:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/17/2022 16:44:53 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7651653410790062 on epoch=71
06/17/2022 16:44:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/17/2022 16:44:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/17/2022 16:45:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/17/2022 16:45:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/17/2022 16:45:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/17/2022 16:45:12 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8273422418820902 on epoch=74
06/17/2022 16:45:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/17/2022 16:45:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/17/2022 16:45:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/17/2022 16:45:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/17/2022 16:45:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=78
06/17/2022 16:45:31 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7663123348356076 on epoch=78
06/17/2022 16:45:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/17/2022 16:45:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/17/2022 16:45:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
06/17/2022 16:45:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=81
06/17/2022 16:45:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/17/2022 16:45:51 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8071402216800699 on epoch=82
06/17/2022 16:45:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/17/2022 16:45:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 16:45:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/17/2022 16:46:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/17/2022 16:46:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/17/2022 16:46:10 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7061415638265733 on epoch=85
06/17/2022 16:46:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/17/2022 16:46:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/17/2022 16:46:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/17/2022 16:46:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/17/2022 16:46:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/17/2022 16:46:29 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7237394273447405 on epoch=89
06/17/2022 16:46:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/17/2022 16:46:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
06/17/2022 16:46:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/17/2022 16:46:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/17/2022 16:46:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/17/2022 16:46:49 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8427782843342616 on epoch=92
06/17/2022 16:46:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8273422418820902 -> 0.8427782843342616 on epoch=92, global_step=1300
06/17/2022 16:46:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/17/2022 16:46:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/17/2022 16:46:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/17/2022 16:46:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/17/2022 16:47:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/17/2022 16:47:08 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.844177258717107 on epoch=96
06/17/2022 16:47:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8427782843342616 -> 0.844177258717107 on epoch=96, global_step=1350
06/17/2022 16:47:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/17/2022 16:47:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/17/2022 16:47:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/17/2022 16:47:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/17/2022 16:47:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/17/2022 16:47:27 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7880317918491823 on epoch=99
06/17/2022 16:47:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/17/2022 16:47:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/17/2022 16:47:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/17/2022 16:47:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/17/2022 16:47:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/17/2022 16:47:47 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7526323139226365 on epoch=103
06/17/2022 16:47:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/17/2022 16:47:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/17/2022 16:47:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/17/2022 16:47:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/17/2022 16:48:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/17/2022 16:48:06 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8440658505174634 on epoch=107
06/17/2022 16:48:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/17/2022 16:48:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/17/2022 16:48:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/17/2022 16:48:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/17/2022 16:48:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/17/2022 16:48:26 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8312948110520506 on epoch=110
06/17/2022 16:48:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/17/2022 16:48:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/17/2022 22:02:23 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-10-up64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-10-64shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/17/2022 22:02:23 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14
06/17/2022 22:02:23 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-10-up64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-10-64shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/17/2022 22:02:23 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14
06/17/2022 22:02:23 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/17/2022 22:02:23 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/17/2022 22:02:23 - INFO - __main__ - args.device: cuda:0
06/17/2022 22:02:23 - INFO - __main__ - Using 2 gpus
06/17/2022 22:02:23 - INFO - __main__ - args.device: cuda:1
06/17/2022 22:02:23 - INFO - __main__ - Using 2 gpus
06/17/2022 22:02:23 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/17/2022 22:02:23 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/17/2022 22:02:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/17/2022 22:02:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:02:29 - INFO - __main__ - Printing 3 examples
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:02:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:02:29 - INFO - __main__ - Printing 3 examples
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:02:29 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 22:02:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:02:29 - INFO - __main__ - Printing 3 examples
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:02:29 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 22:02:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:02:29 - INFO - __main__ - Printing 3 examples
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 22:02:29 - INFO - __main__ - ['Animal']
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:02:29 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:02:29 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 22:02:30 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 22:02:47 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 22:02:47 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 22:02:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 22:02:48 - INFO - __main__ - Starting training!
06/17/2022 22:02:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 22:02:52 - INFO - __main__ - Starting training!
06/17/2022 22:02:56 - INFO - __main__ - Step 10 Global step 10 Train loss 6.48 on epoch=0
06/17/2022 22:02:59 - INFO - __main__ - Step 20 Global step 20 Train loss 4.64 on epoch=1
06/17/2022 22:03:02 - INFO - __main__ - Step 30 Global step 30 Train loss 3.91 on epoch=2
06/17/2022 22:03:04 - INFO - __main__ - Step 40 Global step 40 Train loss 3.55 on epoch=2
06/17/2022 22:03:07 - INFO - __main__ - Step 50 Global step 50 Train loss 3.06 on epoch=3
06/17/2022 22:03:12 - INFO - __main__ - Global step 50 Train loss 4.33 Classification-F1 0.09449715410666175 on epoch=3
06/17/2022 22:03:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09449715410666175 on epoch=3, global_step=50
06/17/2022 22:03:14 - INFO - __main__ - Step 60 Global step 60 Train loss 2.91 on epoch=4
06/17/2022 22:03:17 - INFO - __main__ - Step 70 Global step 70 Train loss 2.21 on epoch=4
06/17/2022 22:03:19 - INFO - __main__ - Step 80 Global step 80 Train loss 2.37 on epoch=5
06/17/2022 22:03:22 - INFO - __main__ - Step 90 Global step 90 Train loss 1.99 on epoch=6
06/17/2022 22:03:24 - INFO - __main__ - Step 100 Global step 100 Train loss 1.79 on epoch=7
06/17/2022 22:03:30 - INFO - __main__ - Global step 100 Train loss 2.26 Classification-F1 0.12245518216089807 on epoch=7
06/17/2022 22:03:30 - INFO - __main__ - Saving model with best Classification-F1: 0.09449715410666175 -> 0.12245518216089807 on epoch=7, global_step=100
06/17/2022 22:03:32 - INFO - __main__ - Step 110 Global step 110 Train loss 1.59 on epoch=7
06/17/2022 22:03:35 - INFO - __main__ - Step 120 Global step 120 Train loss 1.50 on epoch=8
06/17/2022 22:03:37 - INFO - __main__ - Step 130 Global step 130 Train loss 1.53 on epoch=9
06/17/2022 22:03:40 - INFO - __main__ - Step 140 Global step 140 Train loss 1.24 on epoch=9
06/17/2022 22:03:42 - INFO - __main__ - Step 150 Global step 150 Train loss 1.10 on epoch=10
06/17/2022 22:03:48 - INFO - __main__ - Global step 150 Train loss 1.39 Classification-F1 0.35281495838727894 on epoch=10
06/17/2022 22:03:48 - INFO - __main__ - Saving model with best Classification-F1: 0.12245518216089807 -> 0.35281495838727894 on epoch=10, global_step=150
06/17/2022 22:03:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.99 on epoch=11
06/17/2022 22:03:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.97 on epoch=12
06/17/2022 22:03:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=12
06/17/2022 22:03:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=13
06/17/2022 22:04:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
06/17/2022 22:04:07 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.546381314268775 on epoch=14
06/17/2022 22:04:07 - INFO - __main__ - Saving model with best Classification-F1: 0.35281495838727894 -> 0.546381314268775 on epoch=14, global_step=200
06/17/2022 22:04:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=14
06/17/2022 22:04:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=15
06/17/2022 22:04:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=16
06/17/2022 22:04:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=17
06/17/2022 22:04:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=17
06/17/2022 22:04:26 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.5899627675718758 on epoch=17
06/17/2022 22:04:26 - INFO - __main__ - Saving model with best Classification-F1: 0.546381314268775 -> 0.5899627675718758 on epoch=17, global_step=250
06/17/2022 22:04:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
06/17/2022 22:04:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=19
06/17/2022 22:04:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=19
06/17/2022 22:04:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
06/17/2022 22:04:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=21
06/17/2022 22:04:46 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.7283117917526519 on epoch=21
06/17/2022 22:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5899627675718758 -> 0.7283117917526519 on epoch=21, global_step=300
06/17/2022 22:04:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
06/17/2022 22:04:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=22
06/17/2022 22:04:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=23
06/17/2022 22:04:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=24
06/17/2022 22:04:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=24
06/17/2022 22:05:05 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6562202470122175 on epoch=24
06/17/2022 22:05:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/17/2022 22:05:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=26
06/17/2022 22:05:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=27
06/17/2022 22:05:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=27
06/17/2022 22:05:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
06/17/2022 22:05:25 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.7081702845143705 on epoch=28
06/17/2022 22:05:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/17/2022 22:05:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
06/17/2022 22:05:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
06/17/2022 22:05:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
06/17/2022 22:05:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=32
06/17/2022 22:05:44 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.7097366545184383 on epoch=32
06/17/2022 22:05:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
06/17/2022 22:05:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
06/17/2022 22:05:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
06/17/2022 22:05:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
06/17/2022 22:05:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/17/2022 22:06:04 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7686420036836301 on epoch=35
06/17/2022 22:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7283117917526519 -> 0.7686420036836301 on epoch=35, global_step=500
06/17/2022 22:06:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
06/17/2022 22:06:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
06/17/2022 22:06:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
06/17/2022 22:06:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=38
06/17/2022 22:06:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=39
06/17/2022 22:06:23 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.8109388819066239 on epoch=39
06/17/2022 22:06:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7686420036836301 -> 0.8109388819066239 on epoch=39, global_step=550
06/17/2022 22:06:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/17/2022 22:06:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
06/17/2022 22:06:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
06/17/2022 22:06:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
06/17/2022 22:06:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=42
06/17/2022 22:06:42 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.7722198931050953 on epoch=42
06/17/2022 22:06:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
06/17/2022 22:06:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=44
06/17/2022 22:06:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=44
06/17/2022 22:06:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
06/17/2022 22:06:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/17/2022 22:07:01 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7736941110755152 on epoch=46
06/17/2022 22:07:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/17/2022 22:07:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
06/17/2022 22:07:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/17/2022 22:07:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/17/2022 22:07:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
06/17/2022 22:07:20 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6683720686916532 on epoch=49
06/17/2022 22:07:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
06/17/2022 22:07:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
06/17/2022 22:07:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/17/2022 22:07:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/17/2022 22:07:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=53
06/17/2022 22:07:39 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6532420984033888 on epoch=53
06/17/2022 22:07:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=54
06/17/2022 22:07:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=54
06/17/2022 22:07:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
06/17/2022 22:07:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/17/2022 22:07:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/17/2022 22:07:57 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6503905399171555 on epoch=57
06/17/2022 22:08:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/17/2022 22:08:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/17/2022 22:08:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
06/17/2022 22:08:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
06/17/2022 22:08:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/17/2022 22:08:16 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.740393718794841 on epoch=60
06/17/2022 22:08:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
06/17/2022 22:08:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/17/2022 22:08:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/17/2022 22:08:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/17/2022 22:08:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
06/17/2022 22:08:35 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7399929315341502 on epoch=64
06/17/2022 22:08:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=64
06/17/2022 22:08:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/17/2022 22:08:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 22:08:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/17/2022 22:08:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/17/2022 22:08:54 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.79288137542407 on epoch=67
06/17/2022 22:08:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/17/2022 22:08:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/17/2022 22:09:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
06/17/2022 22:09:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/17/2022 22:09:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/17/2022 22:09:13 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7857512506468864 on epoch=71
06/17/2022 22:09:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/17/2022 22:09:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/17/2022 22:09:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/17/2022 22:09:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/17/2022 22:09:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/17/2022 22:09:32 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.79338953266847 on epoch=74
06/17/2022 22:09:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
06/17/2022 22:09:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
06/17/2022 22:09:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/17/2022 22:09:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
06/17/2022 22:09:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
06/17/2022 22:09:50 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7479393908550489 on epoch=78
06/17/2022 22:09:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
06/17/2022 22:09:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/17/2022 22:09:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
06/17/2022 22:10:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/17/2022 22:10:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
06/17/2022 22:10:09 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8006970891221366 on epoch=82
06/17/2022 22:10:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/17/2022 22:10:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 22:10:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/17/2022 22:10:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/17/2022 22:10:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/17/2022 22:10:28 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7860009608991687 on epoch=85
06/17/2022 22:10:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/17/2022 22:10:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
06/17/2022 22:10:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
06/17/2022 22:10:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/17/2022 22:10:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/17/2022 22:10:47 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7743999721675802 on epoch=89
06/17/2022 22:10:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/17/2022 22:10:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 22:10:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/17/2022 22:10:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/17/2022 22:10:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/17/2022 22:11:06 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7420503033406258 on epoch=92
06/17/2022 22:11:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/17/2022 22:11:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/17/2022 22:11:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 22:11:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/17/2022 22:11:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/17/2022 22:11:24 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7685201157686926 on epoch=96
06/17/2022 22:11:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/17/2022 22:11:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 22:11:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/17/2022 22:11:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 22:11:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/17/2022 22:11:43 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8258812029210512 on epoch=99
06/17/2022 22:11:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8109388819066239 -> 0.8258812029210512 on epoch=99, global_step=1400
06/17/2022 22:11:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
06/17/2022 22:11:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/17/2022 22:11:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/17/2022 22:11:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/17/2022 22:11:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/17/2022 22:12:02 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.801595972373961 on epoch=103
06/17/2022 22:12:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=104
06/17/2022 22:12:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/17/2022 22:12:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/17/2022 22:12:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 22:12:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/17/2022 22:12:21 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.849679863147605 on epoch=107
06/17/2022 22:12:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8258812029210512 -> 0.849679863147605 on epoch=107, global_step=1500
06/17/2022 22:12:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/17/2022 22:12:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/17/2022 22:12:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/17/2022 22:12:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/17/2022 22:12:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/17/2022 22:12:40 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8457697947214076 on epoch=110
06/17/2022 22:12:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/17/2022 22:12:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/17/2022 22:12:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/17/2022 22:12:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/17/2022 22:12:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/17/2022 22:12:59 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.855605789073531 on epoch=114
06/17/2022 22:12:59 - INFO - __main__ - Saving model with best Classification-F1: 0.849679863147605 -> 0.855605789073531 on epoch=114, global_step=1600
06/17/2022 22:13:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/17/2022 22:13:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/17/2022 22:13:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/17/2022 22:13:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 22:13:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/17/2022 22:13:18 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8544526314924797 on epoch=117
06/17/2022 22:13:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/17/2022 22:13:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/17/2022 22:13:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/17/2022 22:13:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 22:13:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/17/2022 22:13:37 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.849679863147605 on epoch=121
06/17/2022 22:13:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 22:13:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/17/2022 22:13:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/17/2022 22:13:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/17/2022 22:13:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 22:13:56 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8488467177983308 on epoch=124
06/17/2022 22:13:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/17/2022 22:14:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/17/2022 22:14:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/17/2022 22:14:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 22:14:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/17/2022 22:14:15 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.805276036775088 on epoch=128
06/17/2022 22:14:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/17/2022 22:14:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 22:14:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 22:14:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/17/2022 22:14:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/17/2022 22:14:34 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.855605789073531 on epoch=132
06/17/2022 22:14:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 22:14:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 22:14:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 22:14:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/17/2022 22:14:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 22:14:53 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8489581259979742 on epoch=135
06/17/2022 22:14:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 22:14:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/17/2022 22:15:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 22:15:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 22:15:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 22:15:12 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8527567862245282 on epoch=139
06/17/2022 22:15:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 22:15:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/17/2022 22:15:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/17/2022 22:15:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/17/2022 22:15:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 22:15:31 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8607143459062259 on epoch=142
06/17/2022 22:15:31 - INFO - __main__ - Saving model with best Classification-F1: 0.855605789073531 -> 0.8607143459062259 on epoch=142, global_step=2000
06/17/2022 22:15:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
06/17/2022 22:15:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/17/2022 22:15:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 22:15:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
06/17/2022 22:15:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 22:15:50 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8607143459062259 on epoch=146
06/17/2022 22:15:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/17/2022 22:15:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/17/2022 22:15:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
06/17/2022 22:16:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/17/2022 22:16:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/17/2022 22:16:10 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8569156856796718 on epoch=149
06/17/2022 22:16:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/17/2022 22:16:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/17/2022 22:16:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/17/2022 22:16:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/17/2022 22:16:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 22:16:29 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=153
06/17/2022 22:16:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8607143459062259 -> 0.8630131964809384 on epoch=153, global_step=2150
06/17/2022 22:16:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/17/2022 22:16:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 22:16:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/17/2022 22:16:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 22:16:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 22:16:48 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8609970674486804 on epoch=157
06/17/2022 22:16:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/17/2022 22:16:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/17/2022 22:16:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 22:16:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 22:17:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 22:17:07 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=160
06/17/2022 22:17:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8630131964809384 -> 0.9910627007401202 on epoch=160, global_step=2250
06/17/2022 22:17:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/17/2022 22:17:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 22:17:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 22:17:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 22:17:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 22:17:26 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=164
06/17/2022 22:17:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 22:17:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 22:17:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/17/2022 22:17:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/17/2022 22:17:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 22:17:45 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.855605789073531 on epoch=167
06/17/2022 22:17:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/17/2022 22:17:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 22:17:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 22:17:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 22:17:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
06/17/2022 22:18:05 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=171
06/17/2022 22:18:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 22:18:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 22:18:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/17/2022 22:18:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 22:18:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 22:18:24 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=174
06/17/2022 22:18:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 22:18:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/17/2022 22:18:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 22:18:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/17/2022 22:18:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 22:18:43 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=178
06/17/2022 22:18:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/17/2022 22:18:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 22:18:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/17/2022 22:18:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 22:18:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 22:19:03 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=182
06/17/2022 22:19:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/17/2022 22:19:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 22:19:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 22:19:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 22:19:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/17/2022 22:19:22 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=185
06/17/2022 22:19:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 22:19:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/17/2022 22:19:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 22:19:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 22:19:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 22:19:41 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=189
06/17/2022 22:19:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 22:19:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 22:19:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 22:19:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 22:19:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 22:20:01 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=192
06/17/2022 22:20:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/17/2022 22:20:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/17/2022 22:20:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/17/2022 22:20:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 22:20:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/17/2022 22:20:20 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=196
06/17/2022 22:20:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 22:20:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 22:20:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/17/2022 22:20:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/17/2022 22:20:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/17/2022 22:20:40 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=199
06/17/2022 22:20:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 22:20:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/17/2022 22:20:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/17/2022 22:20:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 22:20:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 22:20:59 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=203
06/17/2022 22:21:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/17/2022 22:21:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/17/2022 22:21:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 22:21:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/17/2022 22:21:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 22:21:18 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=207
06/17/2022 22:21:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/17/2022 22:21:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 22:21:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 22:21:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 22:21:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/17/2022 22:21:38 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=210
06/17/2022 22:21:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 22:21:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 22:21:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 22:21:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 22:21:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 22:21:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:21:52 - INFO - __main__ - Printing 3 examples
06/17/2022 22:21:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 22:21:52 - INFO - __main__ - ['Animal']
06/17/2022 22:21:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 22:21:52 - INFO - __main__ - ['Animal']
06/17/2022 22:21:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 22:21:52 - INFO - __main__ - ['Animal']
06/17/2022 22:21:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:21:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:21:52 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 22:21:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:21:52 - INFO - __main__ - Printing 3 examples
06/17/2022 22:21:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 22:21:52 - INFO - __main__ - ['Animal']
06/17/2022 22:21:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 22:21:52 - INFO - __main__ - ['Animal']
06/17/2022 22:21:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 22:21:52 - INFO - __main__ - ['Animal']
06/17/2022 22:21:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:21:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:21:53 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 22:21:57 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=214
06/17/2022 22:21:57 - INFO - __main__ - save last model!
06/17/2022 22:21:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 22:21:58 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 22:21:58 - INFO - __main__ - Printing 3 examples
06/17/2022 22:21:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 22:21:58 - INFO - __main__ - ['Animal']
06/17/2022 22:21:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 22:21:58 - INFO - __main__ - ['Animal']
06/17/2022 22:21:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 22:21:58 - INFO - __main__ - ['Village']
06/17/2022 22:21:58 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:21:59 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:22:03 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 22:22:08 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 22:22:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 22:22:08 - INFO - __main__ - Starting training!
06/17/2022 22:24:35 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/17/2022 22:24:35 - INFO - __main__ - Classification-F1 on test data: 0.6503
06/17/2022 22:24:35 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6503113726227004
06/17/2022 22:24:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/17/2022 22:24:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:24:36 - INFO - __main__ - Printing 3 examples
06/17/2022 22:24:36 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 22:24:36 - INFO - __main__ - ['Animal']
06/17/2022 22:24:36 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 22:24:36 - INFO - __main__ - ['Animal']
06/17/2022 22:24:36 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 22:24:36 - INFO - __main__ - ['Animal']
06/17/2022 22:24:36 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:24:36 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:24:36 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 22:24:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:24:36 - INFO - __main__ - Printing 3 examples
06/17/2022 22:24:36 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 22:24:36 - INFO - __main__ - ['Animal']
06/17/2022 22:24:36 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 22:24:36 - INFO - __main__ - ['Animal']
06/17/2022 22:24:36 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 22:24:36 - INFO - __main__ - ['Animal']
06/17/2022 22:24:36 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:24:37 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:24:37 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 22:24:55 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 22:24:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 22:24:56 - INFO - __main__ - Starting training!
06/17/2022 22:25:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=0
06/17/2022 22:25:02 - INFO - __main__ - Step 20 Global step 20 Train loss 4.79 on epoch=1
06/17/2022 22:25:05 - INFO - __main__ - Step 30 Global step 30 Train loss 4.03 on epoch=2
06/17/2022 22:25:07 - INFO - __main__ - Step 40 Global step 40 Train loss 3.63 on epoch=2
06/17/2022 22:25:10 - INFO - __main__ - Step 50 Global step 50 Train loss 3.29 on epoch=3
06/17/2022 22:25:16 - INFO - __main__ - Global step 50 Train loss 4.47 Classification-F1 0.07886064255828339 on epoch=3
06/17/2022 22:25:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07886064255828339 on epoch=3, global_step=50
06/17/2022 22:25:18 - INFO - __main__ - Step 60 Global step 60 Train loss 3.29 on epoch=4
06/17/2022 22:25:21 - INFO - __main__ - Step 70 Global step 70 Train loss 2.50 on epoch=4
06/17/2022 22:25:24 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=5
06/17/2022 22:25:26 - INFO - __main__ - Step 90 Global step 90 Train loss 2.16 on epoch=6
06/17/2022 22:25:29 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=7
06/17/2022 22:25:35 - INFO - __main__ - Global step 100 Train loss 2.48 Classification-F1 0.10455398842495615 on epoch=7
06/17/2022 22:25:35 - INFO - __main__ - Saving model with best Classification-F1: 0.07886064255828339 -> 0.10455398842495615 on epoch=7, global_step=100
06/17/2022 22:25:37 - INFO - __main__ - Step 110 Global step 110 Train loss 1.85 on epoch=7
06/17/2022 22:25:40 - INFO - __main__ - Step 120 Global step 120 Train loss 1.77 on epoch=8
06/17/2022 22:25:42 - INFO - __main__ - Step 130 Global step 130 Train loss 1.81 on epoch=9
06/17/2022 22:25:45 - INFO - __main__ - Step 140 Global step 140 Train loss 1.37 on epoch=9
06/17/2022 22:25:48 - INFO - __main__ - Step 150 Global step 150 Train loss 1.47 on epoch=10
06/17/2022 22:25:54 - INFO - __main__ - Global step 150 Train loss 1.65 Classification-F1 0.17848438152564527 on epoch=10
06/17/2022 22:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.10455398842495615 -> 0.17848438152564527 on epoch=10, global_step=150
06/17/2022 22:25:56 - INFO - __main__ - Step 160 Global step 160 Train loss 1.23 on epoch=11
06/17/2022 22:25:59 - INFO - __main__ - Step 170 Global step 170 Train loss 1.19 on epoch=12
06/17/2022 22:26:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.99 on epoch=12
06/17/2022 22:26:04 - INFO - __main__ - Step 190 Global step 190 Train loss 1.07 on epoch=13
06/17/2022 22:26:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=14
06/17/2022 22:26:13 - INFO - __main__ - Global step 200 Train loss 1.09 Classification-F1 0.36594944133290835 on epoch=14
06/17/2022 22:26:13 - INFO - __main__ - Saving model with best Classification-F1: 0.17848438152564527 -> 0.36594944133290835 on epoch=14, global_step=200
06/17/2022 22:26:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=14
06/17/2022 22:26:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=15
06/17/2022 22:26:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=16
06/17/2022 22:26:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=17
06/17/2022 22:26:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.63 on epoch=17
06/17/2022 22:26:33 - INFO - __main__ - Global step 250 Train loss 0.76 Classification-F1 0.48846904958767806 on epoch=17
06/17/2022 22:26:33 - INFO - __main__ - Saving model with best Classification-F1: 0.36594944133290835 -> 0.48846904958767806 on epoch=17, global_step=250
06/17/2022 22:26:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=18
06/17/2022 22:26:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.64 on epoch=19
06/17/2022 22:26:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
06/17/2022 22:26:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=20
06/17/2022 22:26:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=21
06/17/2022 22:26:53 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.5596950777852538 on epoch=21
06/17/2022 22:26:53 - INFO - __main__ - Saving model with best Classification-F1: 0.48846904958767806 -> 0.5596950777852538 on epoch=21, global_step=300
06/17/2022 22:26:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=22
06/17/2022 22:26:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=22
06/17/2022 22:27:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=23
06/17/2022 22:27:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=24
06/17/2022 22:27:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=24
06/17/2022 22:27:12 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.5460094837373939 on epoch=24
06/17/2022 22:27:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=25
06/17/2022 22:27:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
06/17/2022 22:27:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=27
06/17/2022 22:27:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
06/17/2022 22:27:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=28
06/17/2022 22:27:31 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6050891275376231 on epoch=28
06/17/2022 22:27:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5596950777852538 -> 0.6050891275376231 on epoch=28, global_step=400
06/17/2022 22:27:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/17/2022 22:27:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=29
06/17/2022 22:27:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=30
06/17/2022 22:27:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=31
06/17/2022 22:27:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/17/2022 22:27:51 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.6471412570404507 on epoch=32
06/17/2022 22:27:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6050891275376231 -> 0.6471412570404507 on epoch=32, global_step=450
06/17/2022 22:27:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=32
06/17/2022 22:27:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/17/2022 22:27:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=34
06/17/2022 22:28:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
06/17/2022 22:28:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=35
06/17/2022 22:28:10 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6560433557587257 on epoch=35
06/17/2022 22:28:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6471412570404507 -> 0.6560433557587257 on epoch=35, global_step=500
06/17/2022 22:28:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/17/2022 22:28:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=37
06/17/2022 22:28:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
06/17/2022 22:28:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/17/2022 22:28:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
06/17/2022 22:28:29 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6893386922359784 on epoch=39
06/17/2022 22:28:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6560433557587257 -> 0.6893386922359784 on epoch=39, global_step=550
06/17/2022 22:28:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/17/2022 22:28:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/17/2022 22:28:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
06/17/2022 22:28:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
06/17/2022 22:28:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/17/2022 22:28:48 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.742334240849215 on epoch=42
06/17/2022 22:28:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6893386922359784 -> 0.742334240849215 on epoch=42, global_step=600
06/17/2022 22:28:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
06/17/2022 22:28:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/17/2022 22:28:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/17/2022 22:28:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/17/2022 22:29:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/17/2022 22:29:08 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.8292795123914669 on epoch=46
06/17/2022 22:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.742334240849215 -> 0.8292795123914669 on epoch=46, global_step=650
06/17/2022 22:29:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/17/2022 22:29:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
06/17/2022 22:29:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
06/17/2022 22:29:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/17/2022 22:29:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/17/2022 22:29:27 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.8273885610520506 on epoch=49
06/17/2022 22:29:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=50
06/17/2022 22:29:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
06/17/2022 22:29:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
06/17/2022 22:29:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/17/2022 22:29:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/17/2022 22:29:46 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.839312126835846 on epoch=53
06/17/2022 22:29:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8292795123914669 -> 0.839312126835846 on epoch=53, global_step=750
06/17/2022 22:29:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=54
06/17/2022 22:29:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/17/2022 22:29:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/17/2022 22:29:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
06/17/2022 22:29:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/17/2022 22:30:05 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8905791994217043 on epoch=57
06/17/2022 22:30:05 - INFO - __main__ - Saving model with best Classification-F1: 0.839312126835846 -> 0.8905791994217043 on epoch=57, global_step=800
06/17/2022 22:30:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/17/2022 22:30:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/17/2022 22:30:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/17/2022 22:30:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/17/2022 22:30:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
06/17/2022 22:30:24 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8312948110520506 on epoch=60
06/17/2022 22:30:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/17/2022 22:30:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/17/2022 22:30:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
06/17/2022 22:30:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/17/2022 22:30:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/17/2022 22:30:43 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.838251332791181 on epoch=64
06/17/2022 22:30:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/17/2022 22:30:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/17/2022 22:30:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/17/2022 22:30:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/17/2022 22:30:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/17/2022 22:31:02 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7404226518408517 on epoch=67
06/17/2022 22:31:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/17/2022 22:31:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/17/2022 22:31:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/17/2022 22:31:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/17/2022 22:31:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/17/2022 22:31:21 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7255424033412647 on epoch=71
06/17/2022 22:31:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
06/17/2022 22:31:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/17/2022 22:31:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/17/2022 22:31:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
06/17/2022 22:31:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/17/2022 22:31:40 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.6988595322796293 on epoch=74
06/17/2022 22:31:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/17/2022 22:31:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/17/2022 22:31:48 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/17/2022 22:31:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
06/17/2022 22:31:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/17/2022 22:31:59 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8488237173958237 on epoch=78
06/17/2022 22:32:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/17/2022 22:32:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
06/17/2022 22:32:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/17/2022 22:32:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/17/2022 22:32:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/17/2022 22:32:19 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7512170212294533 on epoch=82
06/17/2022 22:32:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/17/2022 22:32:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/17/2022 22:32:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/17/2022 22:32:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/17/2022 22:32:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/17/2022 22:32:39 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8517190747266649 on epoch=85
06/17/2022 22:32:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/17/2022 22:32:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/17/2022 22:32:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/17/2022 22:32:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/17/2022 22:32:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/17/2022 22:32:58 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9063408481672239 on epoch=89
06/17/2022 22:32:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8905791994217043 -> 0.9063408481672239 on epoch=89, global_step=1250
06/17/2022 22:33:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/17/2022 22:33:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 22:33:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/17/2022 22:33:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
06/17/2022 22:33:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/17/2022 22:33:18 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.9187894121480459 on epoch=92
06/17/2022 22:33:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9063408481672239 -> 0.9187894121480459 on epoch=92, global_step=1300
06/17/2022 22:33:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/17/2022 22:33:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/17/2022 22:33:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/17/2022 22:33:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/17/2022 22:33:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/17/2022 22:33:38 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9187894121480459 on epoch=96
06/17/2022 22:33:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/17/2022 22:33:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/17/2022 22:33:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/17/2022 22:33:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 22:33:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/17/2022 22:33:57 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9682345730732829 on epoch=99
06/17/2022 22:33:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9187894121480459 -> 0.9682345730732829 on epoch=99, global_step=1400
06/17/2022 22:33:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/17/2022 22:34:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/17/2022 22:34:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/17/2022 22:34:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/17/2022 22:34:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/17/2022 22:34:16 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=103
06/17/2022 22:34:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9682345730732829 -> 0.9867213747669157 on epoch=103, global_step=1450
06/17/2022 22:34:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 22:34:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/17/2022 22:34:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/17/2022 22:34:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/17/2022 22:34:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/17/2022 22:34:36 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9779157630794254 on epoch=107
06/17/2022 22:34:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/17/2022 22:34:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/17/2022 22:34:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 22:34:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/17/2022 22:34:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/17/2022 22:34:55 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9106508840095179 on epoch=110
06/17/2022 22:34:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/17/2022 22:35:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/17/2022 22:35:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/17/2022 22:35:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/17/2022 22:35:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/17/2022 22:35:15 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9106508840095179 on epoch=114
06/17/2022 22:35:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/17/2022 22:35:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/17/2022 22:35:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/17/2022 22:35:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/17/2022 22:35:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/17/2022 22:35:35 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9780015231899212 on epoch=117
06/17/2022 22:35:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/17/2022 22:35:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/17/2022 22:35:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/17/2022 22:35:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 22:35:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/17/2022 22:35:54 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9099914938166591 on epoch=121
06/17/2022 22:35:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/17/2022 22:36:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/17/2022 22:36:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 22:36:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/17/2022 22:36:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/17/2022 22:36:14 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7981256175251041 on epoch=124
06/17/2022 22:36:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/17/2022 22:36:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 22:36:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 22:36:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
06/17/2022 22:36:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/17/2022 22:36:34 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9147375079063884 on epoch=128
06/17/2022 22:36:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/17/2022 22:36:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 22:36:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/17/2022 22:36:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/17/2022 22:36:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/17/2022 22:36:53 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9187894121480459 on epoch=132
06/17/2022 22:36:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/17/2022 22:36:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/17/2022 22:37:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 22:37:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/17/2022 22:37:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/17/2022 22:37:13 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=135
06/17/2022 22:37:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 22:37:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/17/2022 22:37:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 22:37:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 22:37:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 22:37:33 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=139
06/17/2022 22:37:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/17/2022 22:37:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 22:37:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/17/2022 22:37:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/17/2022 22:37:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 22:37:53 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8592145362543845 on epoch=142
06/17/2022 22:37:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/17/2022 22:37:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/17/2022 22:38:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 22:38:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/17/2022 22:38:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 22:38:13 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9187894121480461 on epoch=146
06/17/2022 22:38:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/17/2022 22:38:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 22:38:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/17/2022 22:38:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/17/2022 22:38:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/17/2022 22:38:32 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.863147605083089 on epoch=149
06/17/2022 22:38:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/17/2022 22:38:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 22:38:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/17/2022 22:38:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/17/2022 22:38:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/17/2022 22:38:52 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=153
06/17/2022 22:38:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/17/2022 22:38:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 22:39:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 22:39:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/17/2022 22:39:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 22:39:12 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9186746497230369 on epoch=157
06/17/2022 22:39:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/17/2022 22:39:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/17/2022 22:39:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/17/2022 22:39:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/17/2022 22:39:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 22:39:32 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9144753033178079 on epoch=160
06/17/2022 22:39:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/17/2022 22:39:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 22:39:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/17/2022 22:39:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/17/2022 22:39:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 22:39:52 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=164
06/17/2022 22:39:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 22:39:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 22:40:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/17/2022 22:40:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 22:40:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/17/2022 22:40:13 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=167
06/17/2022 22:40:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 22:40:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 22:40:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/17/2022 22:40:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/17/2022 22:40:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 22:40:33 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=171
06/17/2022 22:40:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/17/2022 22:40:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 22:40:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 22:40:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/17/2022 22:40:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 22:40:52 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=174
06/17/2022 22:40:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 22:40:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/17/2022 22:41:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 22:41:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 22:41:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 22:41:13 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=178
06/17/2022 22:41:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 22:41:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 22:41:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/17/2022 22:41:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/17/2022 22:41:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 22:41:33 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=182
06/17/2022 22:41:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/17/2022 22:41:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 22:41:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 22:41:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/17/2022 22:41:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 22:41:53 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=185
06/17/2022 22:41:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9867213747669157 -> 0.9910627007401202 on epoch=185, global_step=2600
06/17/2022 22:41:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 22:41:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/17/2022 22:42:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 22:42:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 22:42:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 22:42:13 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=189
06/17/2022 22:42:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=189
06/17/2022 22:42:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 22:42:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 22:42:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 22:42:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/17/2022 22:42:34 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=192
06/17/2022 22:42:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/17/2022 22:42:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 22:42:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 22:42:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/17/2022 22:42:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/17/2022 22:42:55 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=196
06/17/2022 22:42:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/17/2022 22:43:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/17/2022 22:43:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 22:43:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 22:43:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 22:43:15 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9187894121480459 on epoch=199
06/17/2022 22:43:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 22:43:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 22:43:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/17/2022 22:43:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 22:43:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 22:43:36 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=203
06/17/2022 22:43:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 22:43:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 22:43:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 22:43:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 22:43:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/17/2022 22:43:57 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=207
06/17/2022 22:43:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/17/2022 22:44:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 22:44:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 22:44:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/17/2022 22:44:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/17/2022 22:44:17 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9164955053380103 on epoch=210
06/17/2022 22:44:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 22:44:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 22:44:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/17/2022 22:44:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/17/2022 22:44:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/17/2022 22:44:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:44:32 - INFO - __main__ - Printing 3 examples
06/17/2022 22:44:32 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 22:44:32 - INFO - __main__ - ['Animal']
06/17/2022 22:44:32 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 22:44:32 - INFO - __main__ - ['Animal']
06/17/2022 22:44:32 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 22:44:32 - INFO - __main__ - ['Animal']
06/17/2022 22:44:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:44:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:44:32 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 22:44:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:44:32 - INFO - __main__ - Printing 3 examples
06/17/2022 22:44:32 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 22:44:32 - INFO - __main__ - ['Animal']
06/17/2022 22:44:32 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 22:44:32 - INFO - __main__ - ['Animal']
06/17/2022 22:44:32 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 22:44:32 - INFO - __main__ - ['Animal']
06/17/2022 22:44:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:44:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:44:32 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 22:44:38 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=214
06/17/2022 22:44:38 - INFO - __main__ - save last model!
06/17/2022 22:44:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 22:44:38 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 22:44:38 - INFO - __main__ - Printing 3 examples
06/17/2022 22:44:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 22:44:38 - INFO - __main__ - ['Animal']
06/17/2022 22:44:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 22:44:38 - INFO - __main__ - ['Animal']
06/17/2022 22:44:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 22:44:38 - INFO - __main__ - ['Village']
06/17/2022 22:44:38 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:44:39 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:44:43 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 22:44:49 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 22:44:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 22:44:50 - INFO - __main__ - Starting training!
06/17/2022 22:47:05 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/17/2022 22:47:05 - INFO - __main__ - Classification-F1 on test data: 0.5692
06/17/2022 22:47:06 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.5692329043286738
06/17/2022 22:47:06 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/17/2022 22:47:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:47:07 - INFO - __main__ - Printing 3 examples
06/17/2022 22:47:07 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 22:47:07 - INFO - __main__ - ['Animal']
06/17/2022 22:47:07 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 22:47:07 - INFO - __main__ - ['Animal']
06/17/2022 22:47:07 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 22:47:07 - INFO - __main__ - ['Animal']
06/17/2022 22:47:07 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:47:07 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:47:07 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 22:47:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 22:47:07 - INFO - __main__ - Printing 3 examples
06/17/2022 22:47:07 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 22:47:07 - INFO - __main__ - ['Animal']
06/17/2022 22:47:07 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 22:47:07 - INFO - __main__ - ['Animal']
06/17/2022 22:47:07 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 22:47:07 - INFO - __main__ - ['Animal']
06/17/2022 22:47:07 - INFO - __main__ - Tokenizing Input ...
06/17/2022 22:47:07 - INFO - __main__ - Tokenizing Output ...
06/17/2022 22:47:07 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 22:47:26 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 22:47:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 22:47:27 - INFO - __main__ - Starting training!
06/17/2022 22:47:30 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=0
06/17/2022 22:47:33 - INFO - __main__ - Step 20 Global step 20 Train loss 5.02 on epoch=1
06/17/2022 22:47:35 - INFO - __main__ - Step 30 Global step 30 Train loss 4.31 on epoch=2
06/17/2022 22:47:38 - INFO - __main__ - Step 40 Global step 40 Train loss 3.93 on epoch=2
06/17/2022 22:47:41 - INFO - __main__ - Step 50 Global step 50 Train loss 3.77 on epoch=3
06/17/2022 22:47:46 - INFO - __main__ - Global step 50 Train loss 4.76 Classification-F1 0.04731945823268483 on epoch=3
06/17/2022 22:47:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04731945823268483 on epoch=3, global_step=50
06/17/2022 22:47:49 - INFO - __main__ - Step 60 Global step 60 Train loss 3.80 on epoch=4
06/17/2022 22:47:52 - INFO - __main__ - Step 70 Global step 70 Train loss 3.10 on epoch=4
06/17/2022 22:47:54 - INFO - __main__ - Step 80 Global step 80 Train loss 3.07 on epoch=5
06/17/2022 22:47:57 - INFO - __main__ - Step 90 Global step 90 Train loss 2.65 on epoch=6
06/17/2022 22:47:59 - INFO - __main__ - Step 100 Global step 100 Train loss 2.54 on epoch=7
06/17/2022 22:48:05 - INFO - __main__ - Global step 100 Train loss 3.03 Classification-F1 0.1071993012765091 on epoch=7
06/17/2022 22:48:05 - INFO - __main__ - Saving model with best Classification-F1: 0.04731945823268483 -> 0.1071993012765091 on epoch=7, global_step=100
06/17/2022 22:48:08 - INFO - __main__ - Step 110 Global step 110 Train loss 2.36 on epoch=7
06/17/2022 22:48:10 - INFO - __main__ - Step 120 Global step 120 Train loss 2.22 on epoch=8
06/17/2022 22:48:13 - INFO - __main__ - Step 130 Global step 130 Train loss 2.29 on epoch=9
06/17/2022 22:48:15 - INFO - __main__ - Step 140 Global step 140 Train loss 1.80 on epoch=9
06/17/2022 22:48:18 - INFO - __main__ - Step 150 Global step 150 Train loss 1.86 on epoch=10
06/17/2022 22:48:23 - INFO - __main__ - Global step 150 Train loss 2.11 Classification-F1 0.1345794404107059 on epoch=10
06/17/2022 22:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1071993012765091 -> 0.1345794404107059 on epoch=10, global_step=150
06/17/2022 22:48:26 - INFO - __main__ - Step 160 Global step 160 Train loss 1.70 on epoch=11
06/17/2022 22:48:29 - INFO - __main__ - Step 170 Global step 170 Train loss 1.64 on epoch=12
06/17/2022 22:48:31 - INFO - __main__ - Step 180 Global step 180 Train loss 1.55 on epoch=12
06/17/2022 22:48:34 - INFO - __main__ - Step 190 Global step 190 Train loss 1.52 on epoch=13
06/17/2022 22:48:36 - INFO - __main__ - Step 200 Global step 200 Train loss 1.52 on epoch=14
06/17/2022 22:48:42 - INFO - __main__ - Global step 200 Train loss 1.59 Classification-F1 0.17545108646544172 on epoch=14
06/17/2022 22:48:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1345794404107059 -> 0.17545108646544172 on epoch=14, global_step=200
06/17/2022 22:48:45 - INFO - __main__ - Step 210 Global step 210 Train loss 1.20 on epoch=14
06/17/2022 22:48:47 - INFO - __main__ - Step 220 Global step 220 Train loss 1.20 on epoch=15
06/17/2022 22:48:50 - INFO - __main__ - Step 230 Global step 230 Train loss 1.11 on epoch=16
06/17/2022 22:48:53 - INFO - __main__ - Step 240 Global step 240 Train loss 1.20 on epoch=17
06/17/2022 22:48:55 - INFO - __main__ - Step 250 Global step 250 Train loss 1.02 on epoch=17
06/17/2022 22:49:01 - INFO - __main__ - Global step 250 Train loss 1.15 Classification-F1 0.3111342663984835 on epoch=17
06/17/2022 22:49:01 - INFO - __main__ - Saving model with best Classification-F1: 0.17545108646544172 -> 0.3111342663984835 on epoch=17, global_step=250
06/17/2022 22:49:04 - INFO - __main__ - Step 260 Global step 260 Train loss 1.00 on epoch=18
06/17/2022 22:49:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.97 on epoch=19
06/17/2022 22:49:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=19
06/17/2022 22:49:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.77 on epoch=20
06/17/2022 22:49:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=21
06/17/2022 22:49:21 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.4600535721642507 on epoch=21
06/17/2022 22:49:21 - INFO - __main__ - Saving model with best Classification-F1: 0.3111342663984835 -> 0.4600535721642507 on epoch=21, global_step=300
06/17/2022 22:49:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.76 on epoch=22
06/17/2022 22:49:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.66 on epoch=22
06/17/2022 22:49:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=23
06/17/2022 22:49:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.75 on epoch=24
06/17/2022 22:49:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=24
06/17/2022 22:49:41 - INFO - __main__ - Global step 350 Train loss 0.69 Classification-F1 0.5719964201937635 on epoch=24
06/17/2022 22:49:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4600535721642507 -> 0.5719964201937635 on epoch=24, global_step=350
06/17/2022 22:49:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=25
06/17/2022 22:49:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=26
06/17/2022 22:49:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=27
06/17/2022 22:49:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=27
06/17/2022 22:49:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=28
06/17/2022 22:50:01 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6349174521398046 on epoch=28
06/17/2022 22:50:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5719964201937635 -> 0.6349174521398046 on epoch=28, global_step=400
06/17/2022 22:50:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=29
06/17/2022 22:50:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=29
06/17/2022 22:50:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=30
06/17/2022 22:50:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=31
06/17/2022 22:50:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=32
06/17/2022 22:50:21 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.6656978892297298 on epoch=32
06/17/2022 22:50:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6349174521398046 -> 0.6656978892297298 on epoch=32, global_step=450
06/17/2022 22:50:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=32
06/17/2022 22:50:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=33
06/17/2022 22:50:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
06/17/2022 22:50:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/17/2022 22:50:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=35
06/17/2022 22:50:40 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.6688625121582717 on epoch=35
06/17/2022 22:50:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6656978892297298 -> 0.6688625121582717 on epoch=35, global_step=500
06/17/2022 22:50:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=36
06/17/2022 22:50:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=37
06/17/2022 22:50:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
06/17/2022 22:50:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=38
06/17/2022 22:50:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=39
06/17/2022 22:51:00 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7444768894274978 on epoch=39
06/17/2022 22:51:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6688625121582717 -> 0.7444768894274978 on epoch=39, global_step=550
06/17/2022 22:51:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=39
06/17/2022 22:51:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=40
06/17/2022 22:51:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/17/2022 22:51:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=42
06/17/2022 22:51:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=42
06/17/2022 22:51:20 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.679397418276875 on epoch=42
06/17/2022 22:51:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=43
06/17/2022 22:51:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=44
06/17/2022 22:51:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/17/2022 22:51:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/17/2022 22:51:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=46
06/17/2022 22:51:39 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7149342891278375 on epoch=46
06/17/2022 22:51:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/17/2022 22:51:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
06/17/2022 22:51:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
06/17/2022 22:51:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/17/2022 22:51:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
06/17/2022 22:51:59 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.8071402216800699 on epoch=49
06/17/2022 22:51:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7444768894274978 -> 0.8071402216800699 on epoch=49, global_step=700
06/17/2022 22:52:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
06/17/2022 22:52:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/17/2022 22:52:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/17/2022 22:52:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/17/2022 22:52:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=53
06/17/2022 22:52:19 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.7535099049107309 on epoch=53
06/17/2022 22:52:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
06/17/2022 22:52:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/17/2022 22:52:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/17/2022 22:52:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/17/2022 22:52:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/17/2022 22:52:39 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.8267100388542514 on epoch=57
06/17/2022 22:52:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8071402216800699 -> 0.8267100388542514 on epoch=57, global_step=800
06/17/2022 22:52:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/17/2022 22:52:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
06/17/2022 22:52:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
06/17/2022 22:52:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/17/2022 22:52:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
06/17/2022 22:52:58 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.8273422418820902 on epoch=60
06/17/2022 22:52:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8267100388542514 -> 0.8273422418820902 on epoch=60, global_step=850
06/17/2022 22:53:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/17/2022 22:53:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
06/17/2022 22:53:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/17/2022 22:53:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/17/2022 22:53:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
06/17/2022 22:53:18 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.7746006941676101 on epoch=64
06/17/2022 22:53:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/17/2022 22:53:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
06/17/2022 22:53:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=66
06/17/2022 22:53:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=67
06/17/2022 22:53:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/17/2022 22:53:37 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.8129881748964443 on epoch=67
06/17/2022 22:53:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/17/2022 22:53:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/17/2022 22:53:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/17/2022 22:53:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/17/2022 22:53:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/17/2022 22:53:56 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7651653410790062 on epoch=71
06/17/2022 22:53:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/17/2022 22:54:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/17/2022 22:54:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/17/2022 22:54:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/17/2022 22:54:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/17/2022 22:54:15 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8273422418820902 on epoch=74
06/17/2022 22:54:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/17/2022 22:54:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/17/2022 22:54:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/17/2022 22:54:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/17/2022 22:54:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=78
06/17/2022 22:54:34 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7663123348356076 on epoch=78
06/17/2022 22:54:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/17/2022 22:54:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/17/2022 22:54:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
06/17/2022 22:54:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=81
06/17/2022 22:54:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/17/2022 22:54:54 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8071402216800699 on epoch=82
06/17/2022 22:54:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/17/2022 22:54:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 22:55:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/17/2022 22:55:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/17/2022 22:55:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/17/2022 22:55:13 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7061415638265733 on epoch=85
06/17/2022 22:55:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/17/2022 22:55:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/17/2022 22:55:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/17/2022 22:55:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/17/2022 22:55:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/17/2022 22:55:32 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7237394273447405 on epoch=89
06/17/2022 22:55:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/17/2022 22:55:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
06/17/2022 22:55:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/17/2022 22:55:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/17/2022 22:55:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/17/2022 22:55:51 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8427782843342616 on epoch=92
06/17/2022 22:55:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8273422418820902 -> 0.8427782843342616 on epoch=92, global_step=1300
06/17/2022 22:55:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/17/2022 22:55:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/17/2022 22:55:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/17/2022 22:56:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/17/2022 22:56:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/17/2022 22:56:11 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.844177258717107 on epoch=96
06/17/2022 22:56:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8427782843342616 -> 0.844177258717107 on epoch=96, global_step=1350
06/17/2022 22:56:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/17/2022 22:56:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/17/2022 22:56:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/17/2022 22:56:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/17/2022 22:56:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/17/2022 22:56:30 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7880317918491823 on epoch=99
06/17/2022 22:56:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/17/2022 22:56:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/17/2022 22:56:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/17/2022 22:56:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/17/2022 22:56:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/17/2022 22:56:49 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7526323139226365 on epoch=103
06/17/2022 22:56:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/17/2022 22:56:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/17/2022 22:56:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/17/2022 22:57:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/17/2022 22:57:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/17/2022 22:57:08 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8440658505174634 on epoch=107
06/17/2022 22:57:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/17/2022 22:57:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/17/2022 22:57:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/17/2022 22:57:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/17/2022 22:57:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/17/2022 22:57:28 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8312948110520506 on epoch=110
06/17/2022 22:57:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/17/2022 22:57:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/17/2022 22:57:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/17/2022 22:57:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/17/2022 22:57:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
06/17/2022 22:57:47 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7954135680890899 on epoch=114
06/17/2022 22:57:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/17/2022 22:57:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/17/2022 22:57:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/17/2022 22:57:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/17/2022 22:58:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/17/2022 22:58:07 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.842049993017735 on epoch=117
06/17/2022 22:58:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/17/2022 22:58:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/17/2022 22:58:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/17/2022 22:58:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/17/2022 22:58:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
06/17/2022 22:58:26 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8015743249363073 on epoch=121
06/17/2022 22:58:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/17/2022 22:58:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/17/2022 22:58:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 22:58:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/17/2022 22:58:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/17/2022 22:58:45 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8543182228903292 on epoch=124
06/17/2022 22:58:45 - INFO - __main__ - Saving model with best Classification-F1: 0.844177258717107 -> 0.8543182228903292 on epoch=124, global_step=1750
06/17/2022 22:58:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/17/2022 22:58:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 22:58:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/17/2022 22:58:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/17/2022 22:58:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/17/2022 22:59:05 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8479759189436609 on epoch=128
06/17/2022 22:59:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/17/2022 22:59:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 22:59:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/17/2022 22:59:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/17/2022 22:59:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/17/2022 22:59:25 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8530844757763557 on epoch=132
06/17/2022 22:59:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/17/2022 22:59:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/17/2022 22:59:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/17/2022 22:59:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/17/2022 22:59:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/17/2022 22:59:44 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8029030360248053 on epoch=135
06/17/2022 22:59:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/17/2022 22:59:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/17/2022 22:59:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 22:59:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/17/2022 22:59:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/17/2022 23:00:04 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7988929104901871 on epoch=139
06/17/2022 23:00:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 23:00:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/17/2022 23:00:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/17/2022 23:00:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/17/2022 23:00:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/17/2022 23:00:23 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8530844757763557 on epoch=142
06/17/2022 23:00:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/17/2022 23:00:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/17/2022 23:00:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/17/2022 23:00:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/17/2022 23:00:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 23:00:43 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9867213747669157 on epoch=146
06/17/2022 23:00:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8543182228903292 -> 0.9867213747669157 on epoch=146, global_step=2050
06/17/2022 23:00:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/17/2022 23:00:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/17/2022 23:00:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/17/2022 23:00:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/17/2022 23:00:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/17/2022 23:01:03 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8569156856796718 on epoch=149
06/17/2022 23:01:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/17/2022 23:01:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 23:01:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/17/2022 23:01:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/17/2022 23:01:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/17/2022 23:01:22 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8492858155498018 on epoch=153
06/17/2022 23:01:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/17/2022 23:01:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/17/2022 23:01:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/17/2022 23:01:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/17/2022 23:01:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/17/2022 23:01:42 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8041907119929221 on epoch=157
06/17/2022 23:01:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/17/2022 23:01:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/17/2022 23:01:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/17/2022 23:01:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/17/2022 23:01:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/17/2022 23:02:02 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8607143459062259 on epoch=160
06/17/2022 23:02:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/17/2022 23:02:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/17/2022 23:02:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/17/2022 23:02:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/17/2022 23:02:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/17/2022 23:02:21 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8544526314924797 on epoch=164
06/17/2022 23:02:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/17/2022 23:02:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/17/2022 23:02:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/17/2022 23:02:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 23:02:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/17/2022 23:02:41 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8607143459062259 on epoch=167
06/17/2022 23:02:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 23:02:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/17/2022 23:02:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/17/2022 23:02:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/17/2022 23:02:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/17/2022 23:03:01 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=171
06/17/2022 23:03:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/17/2022 23:03:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/17/2022 23:03:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/17/2022 23:03:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/17/2022 23:03:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 23:03:20 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8569156856796718 on epoch=174
06/17/2022 23:03:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/17/2022 23:03:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/17/2022 23:03:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 23:03:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 23:03:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
06/17/2022 23:03:40 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.91649550533801 on epoch=178
06/17/2022 23:03:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/17/2022 23:03:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/17/2022 23:03:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.11 on epoch=180
06/17/2022 23:03:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/17/2022 23:03:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/17/2022 23:03:59 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9124088814411396 on epoch=182
06/17/2022 23:04:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/17/2022 23:04:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/17/2022 23:04:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 23:04:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/17/2022 23:04:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/17/2022 23:04:19 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=185
06/17/2022 23:04:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/17/2022 23:04:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/17/2022 23:04:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 23:04:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/17/2022 23:04:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/17/2022 23:04:39 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9084509015944815 on epoch=189
06/17/2022 23:04:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/17/2022 23:04:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/17/2022 23:04:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/17/2022 23:04:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 23:04:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/17/2022 23:04:58 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8553833263510684 on epoch=192
06/17/2022 23:05:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/17/2022 23:05:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 23:05:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=194
06/17/2022 23:05:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/17/2022 23:05:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/17/2022 23:05:17 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.79251764048728 on epoch=196
06/17/2022 23:05:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/17/2022 23:05:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 23:05:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/17/2022 23:05:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/17/2022 23:05:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/17/2022 23:05:36 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9140433980583166 on epoch=199
06/17/2022 23:05:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/17/2022 23:05:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/17/2022 23:05:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/17/2022 23:05:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/17/2022 23:05:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/17/2022 23:05:55 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=203
06/17/2022 23:05:55 - INFO - __main__ - Saving model with best Classification-F1: 0.9867213747669157 -> 0.9910627007401202 on epoch=203, global_step=2850
06/17/2022 23:05:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 23:06:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 23:06:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/17/2022 23:06:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/17/2022 23:06:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/17/2022 23:06:15 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9154680445003026 on epoch=207
06/17/2022 23:06:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/17/2022 23:06:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 23:06:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 23:06:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/17/2022 23:06:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/17/2022 23:06:34 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8516727202448265 on epoch=210
06/17/2022 23:06:37 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/17/2022 23:06:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 23:06:42 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/17/2022 23:06:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/17/2022 23:06:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/17/2022 23:06:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:06:49 - INFO - __main__ - Printing 3 examples
06/17/2022 23:06:49 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 23:06:49 - INFO - __main__ - ['Animal']
06/17/2022 23:06:49 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 23:06:49 - INFO - __main__ - ['Animal']
06/17/2022 23:06:49 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 23:06:49 - INFO - __main__ - ['Animal']
06/17/2022 23:06:49 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:06:49 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:06:49 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 23:06:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:06:49 - INFO - __main__ - Printing 3 examples
06/17/2022 23:06:49 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 23:06:49 - INFO - __main__ - ['Animal']
06/17/2022 23:06:49 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 23:06:49 - INFO - __main__ - ['Animal']
06/17/2022 23:06:49 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 23:06:49 - INFO - __main__ - ['Animal']
06/17/2022 23:06:49 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:06:49 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:06:49 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 23:06:53 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=214
06/17/2022 23:06:53 - INFO - __main__ - save last model!
06/17/2022 23:06:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 23:06:54 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 23:06:54 - INFO - __main__ - Printing 3 examples
06/17/2022 23:06:54 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 23:06:54 - INFO - __main__ - ['Animal']
06/17/2022 23:06:54 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 23:06:54 - INFO - __main__ - ['Animal']
06/17/2022 23:06:54 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 23:06:54 - INFO - __main__ - ['Village']
06/17/2022 23:06:54 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:06:55 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:06:59 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 23:07:05 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 23:07:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 23:07:05 - INFO - __main__ - Starting training!
06/17/2022 23:09:03 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/17/2022 23:09:03 - INFO - __main__ - Classification-F1 on test data: 0.5399
06/17/2022 23:09:03 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9910627007401202, test_performance=0.5399280866628731
06/17/2022 23:09:03 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/17/2022 23:09:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:09:04 - INFO - __main__ - Printing 3 examples
06/17/2022 23:09:04 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/17/2022 23:09:04 - INFO - __main__ - ['Animal']
06/17/2022 23:09:04 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/17/2022 23:09:04 - INFO - __main__ - ['Animal']
06/17/2022 23:09:04 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/17/2022 23:09:04 - INFO - __main__ - ['Animal']
06/17/2022 23:09:04 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:09:04 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:09:04 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 23:09:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:09:04 - INFO - __main__ - Printing 3 examples
06/17/2022 23:09:04 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/17/2022 23:09:04 - INFO - __main__ - ['Animal']
06/17/2022 23:09:04 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/17/2022 23:09:04 - INFO - __main__ - ['Animal']
06/17/2022 23:09:04 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/17/2022 23:09:04 - INFO - __main__ - ['Animal']
06/17/2022 23:09:04 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:09:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:09:05 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 23:09:20 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 23:09:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 23:09:21 - INFO - __main__ - Starting training!
06/17/2022 23:09:25 - INFO - __main__ - Step 10 Global step 10 Train loss 7.22 on epoch=0
06/17/2022 23:09:27 - INFO - __main__ - Step 20 Global step 20 Train loss 5.52 on epoch=1
06/17/2022 23:09:30 - INFO - __main__ - Step 30 Global step 30 Train loss 4.79 on epoch=2
06/17/2022 23:09:32 - INFO - __main__ - Step 40 Global step 40 Train loss 4.42 on epoch=2
06/17/2022 23:09:35 - INFO - __main__ - Step 50 Global step 50 Train loss 4.42 on epoch=3
06/17/2022 23:09:42 - INFO - __main__ - Global step 50 Train loss 5.27 Classification-F1 0.020703089439517076 on epoch=3
06/17/2022 23:09:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.020703089439517076 on epoch=3, global_step=50
06/17/2022 23:09:44 - INFO - __main__ - Step 60 Global step 60 Train loss 4.21 on epoch=4
06/17/2022 23:09:47 - INFO - __main__ - Step 70 Global step 70 Train loss 3.61 on epoch=4
06/17/2022 23:09:50 - INFO - __main__ - Step 80 Global step 80 Train loss 3.72 on epoch=5
06/17/2022 23:09:52 - INFO - __main__ - Step 90 Global step 90 Train loss 3.36 on epoch=6
06/17/2022 23:09:55 - INFO - __main__ - Step 100 Global step 100 Train loss 3.29 on epoch=7
06/17/2022 23:10:00 - INFO - __main__ - Global step 100 Train loss 3.64 Classification-F1 0.08391136916820646 on epoch=7
06/17/2022 23:10:00 - INFO - __main__ - Saving model with best Classification-F1: 0.020703089439517076 -> 0.08391136916820646 on epoch=7, global_step=100
06/17/2022 23:10:03 - INFO - __main__ - Step 110 Global step 110 Train loss 3.03 on epoch=7
06/17/2022 23:10:05 - INFO - __main__ - Step 120 Global step 120 Train loss 2.90 on epoch=8
06/17/2022 23:10:08 - INFO - __main__ - Step 130 Global step 130 Train loss 2.93 on epoch=9
06/17/2022 23:10:10 - INFO - __main__ - Step 140 Global step 140 Train loss 2.52 on epoch=9
06/17/2022 23:10:13 - INFO - __main__ - Step 150 Global step 150 Train loss 2.63 on epoch=10
06/17/2022 23:10:18 - INFO - __main__ - Global step 150 Train loss 2.80 Classification-F1 0.09663524552527883 on epoch=10
06/17/2022 23:10:18 - INFO - __main__ - Saving model with best Classification-F1: 0.08391136916820646 -> 0.09663524552527883 on epoch=10, global_step=150
06/17/2022 23:10:21 - INFO - __main__ - Step 160 Global step 160 Train loss 2.40 on epoch=11
06/17/2022 23:10:23 - INFO - __main__ - Step 170 Global step 170 Train loss 2.22 on epoch=12
06/17/2022 23:10:26 - INFO - __main__ - Step 180 Global step 180 Train loss 2.13 on epoch=12
06/17/2022 23:10:29 - INFO - __main__ - Step 190 Global step 190 Train loss 2.11 on epoch=13
06/17/2022 23:10:31 - INFO - __main__ - Step 200 Global step 200 Train loss 2.21 on epoch=14
06/17/2022 23:10:36 - INFO - __main__ - Global step 200 Train loss 2.21 Classification-F1 0.12235946763596535 on epoch=14
06/17/2022 23:10:36 - INFO - __main__ - Saving model with best Classification-F1: 0.09663524552527883 -> 0.12235946763596535 on epoch=14, global_step=200
06/17/2022 23:10:39 - INFO - __main__ - Step 210 Global step 210 Train loss 1.83 on epoch=14
06/17/2022 23:10:41 - INFO - __main__ - Step 220 Global step 220 Train loss 1.90 on epoch=15
06/17/2022 23:10:44 - INFO - __main__ - Step 230 Global step 230 Train loss 1.75 on epoch=16
06/17/2022 23:10:47 - INFO - __main__ - Step 240 Global step 240 Train loss 1.78 on epoch=17
06/17/2022 23:10:49 - INFO - __main__ - Step 250 Global step 250 Train loss 1.65 on epoch=17
06/17/2022 23:10:55 - INFO - __main__ - Global step 250 Train loss 1.78 Classification-F1 0.12223669271355106 on epoch=17
06/17/2022 23:10:57 - INFO - __main__ - Step 260 Global step 260 Train loss 1.60 on epoch=18
06/17/2022 23:11:00 - INFO - __main__ - Step 270 Global step 270 Train loss 1.69 on epoch=19
06/17/2022 23:11:02 - INFO - __main__ - Step 280 Global step 280 Train loss 1.36 on epoch=19
06/17/2022 23:11:05 - INFO - __main__ - Step 290 Global step 290 Train loss 1.46 on epoch=20
06/17/2022 23:11:08 - INFO - __main__ - Step 300 Global step 300 Train loss 1.38 on epoch=21
06/17/2022 23:11:13 - INFO - __main__ - Global step 300 Train loss 1.50 Classification-F1 0.1881363916872976 on epoch=21
06/17/2022 23:11:13 - INFO - __main__ - Saving model with best Classification-F1: 0.12235946763596535 -> 0.1881363916872976 on epoch=21, global_step=300
06/17/2022 23:11:16 - INFO - __main__ - Step 310 Global step 310 Train loss 1.34 on epoch=22
06/17/2022 23:11:19 - INFO - __main__ - Step 320 Global step 320 Train loss 1.17 on epoch=22
06/17/2022 23:11:21 - INFO - __main__ - Step 330 Global step 330 Train loss 1.24 on epoch=23
06/17/2022 23:11:24 - INFO - __main__ - Step 340 Global step 340 Train loss 1.28 on epoch=24
06/17/2022 23:11:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.99 on epoch=24
06/17/2022 23:11:33 - INFO - __main__ - Global step 350 Train loss 1.21 Classification-F1 0.35375775160721395 on epoch=24
06/17/2022 23:11:33 - INFO - __main__ - Saving model with best Classification-F1: 0.1881363916872976 -> 0.35375775160721395 on epoch=24, global_step=350
06/17/2022 23:11:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.98 on epoch=25
06/17/2022 23:11:38 - INFO - __main__ - Step 370 Global step 370 Train loss 1.04 on epoch=26
06/17/2022 23:11:40 - INFO - __main__ - Step 380 Global step 380 Train loss 1.04 on epoch=27
06/17/2022 23:11:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.97 on epoch=27
06/17/2022 23:11:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.99 on epoch=28
06/17/2022 23:11:52 - INFO - __main__ - Global step 400 Train loss 1.00 Classification-F1 0.3512949439578156 on epoch=28
06/17/2022 23:11:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.88 on epoch=29
06/17/2022 23:11:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.87 on epoch=29
06/17/2022 23:12:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.77 on epoch=30
06/17/2022 23:12:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.89 on epoch=31
06/17/2022 23:12:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.82 on epoch=32
06/17/2022 23:12:11 - INFO - __main__ - Global step 450 Train loss 0.85 Classification-F1 0.41338003277413077 on epoch=32
06/17/2022 23:12:11 - INFO - __main__ - Saving model with best Classification-F1: 0.35375775160721395 -> 0.41338003277413077 on epoch=32, global_step=450
06/17/2022 23:12:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.67 on epoch=32
06/17/2022 23:12:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.77 on epoch=33
06/17/2022 23:12:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.74 on epoch=34
06/17/2022 23:12:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.67 on epoch=34
06/17/2022 23:12:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.67 on epoch=35
06/17/2022 23:12:31 - INFO - __main__ - Global step 500 Train loss 0.70 Classification-F1 0.5157597568463443 on epoch=35
06/17/2022 23:12:31 - INFO - __main__ - Saving model with best Classification-F1: 0.41338003277413077 -> 0.5157597568463443 on epoch=35, global_step=500
06/17/2022 23:12:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.70 on epoch=36
06/17/2022 23:12:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.61 on epoch=37
06/17/2022 23:12:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.55 on epoch=37
06/17/2022 23:12:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.63 on epoch=38
06/17/2022 23:12:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=39
06/17/2022 23:12:50 - INFO - __main__ - Global step 550 Train loss 0.60 Classification-F1 0.5365721709347722 on epoch=39
06/17/2022 23:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5157597568463443 -> 0.5365721709347722 on epoch=39, global_step=550
06/17/2022 23:12:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=39
06/17/2022 23:12:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.48 on epoch=40
06/17/2022 23:12:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=41
06/17/2022 23:13:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.51 on epoch=42
06/17/2022 23:13:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=42
06/17/2022 23:13:10 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.617591642228739 on epoch=42
06/17/2022 23:13:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5365721709347722 -> 0.617591642228739 on epoch=42, global_step=600
06/17/2022 23:13:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.41 on epoch=43
06/17/2022 23:13:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.45 on epoch=44
06/17/2022 23:13:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=44
06/17/2022 23:13:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=45
06/17/2022 23:13:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=46
06/17/2022 23:13:30 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.6529817903392257 on epoch=46
06/17/2022 23:13:30 - INFO - __main__ - Saving model with best Classification-F1: 0.617591642228739 -> 0.6529817903392257 on epoch=46, global_step=650
06/17/2022 23:13:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=47
06/17/2022 23:13:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=47
06/17/2022 23:13:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=48
06/17/2022 23:13:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=49
06/17/2022 23:13:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=49
06/17/2022 23:13:49 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.5661089521426764 on epoch=49
06/17/2022 23:13:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=50
06/17/2022 23:13:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=51
06/17/2022 23:13:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=52
06/17/2022 23:14:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=52
06/17/2022 23:14:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=53
06/17/2022 23:14:09 - INFO - __main__ - Global step 750 Train loss 0.33 Classification-F1 0.6649760003138111 on epoch=53
06/17/2022 23:14:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6529817903392257 -> 0.6649760003138111 on epoch=53, global_step=750
06/17/2022 23:14:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=54
06/17/2022 23:14:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=54
06/17/2022 23:14:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.41 on epoch=55
06/17/2022 23:14:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=56
06/17/2022 23:14:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=57
06/17/2022 23:14:29 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.6985836669304413 on epoch=57
06/17/2022 23:14:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6649760003138111 -> 0.6985836669304413 on epoch=57, global_step=800
06/17/2022 23:14:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=57
06/17/2022 23:14:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.38 on epoch=58
06/17/2022 23:14:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=59
06/17/2022 23:14:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=59
06/17/2022 23:14:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
06/17/2022 23:14:49 - INFO - __main__ - Global step 850 Train loss 0.25 Classification-F1 0.7167939126626166 on epoch=60
06/17/2022 23:14:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6985836669304413 -> 0.7167939126626166 on epoch=60, global_step=850
06/17/2022 23:14:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=61
06/17/2022 23:14:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=62
06/17/2022 23:14:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=62
06/17/2022 23:14:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=63
06/17/2022 23:15:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=64
06/17/2022 23:15:09 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.6793271524795544 on epoch=64
06/17/2022 23:15:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
06/17/2022 23:15:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=65
06/17/2022 23:15:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=66
06/17/2022 23:15:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/17/2022 23:15:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/17/2022 23:15:28 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.7140134078503781 on epoch=67
06/17/2022 23:15:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=68
06/17/2022 23:15:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
06/17/2022 23:15:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=69
06/17/2022 23:15:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=70
06/17/2022 23:15:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=71
06/17/2022 23:15:48 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.6795265145210215 on epoch=71
06/17/2022 23:15:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.38 on epoch=72
06/17/2022 23:15:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=72
06/17/2022 23:15:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.25 on epoch=73
06/17/2022 23:15:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=74
06/17/2022 23:16:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=74
06/17/2022 23:16:08 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.6709094627201089 on epoch=74
06/17/2022 23:16:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=75
06/17/2022 23:16:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=76
06/17/2022 23:16:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=77
06/17/2022 23:16:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
06/17/2022 23:16:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=78
06/17/2022 23:16:27 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.7633828098847104 on epoch=78
06/17/2022 23:16:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7167939126626166 -> 0.7633828098847104 on epoch=78, global_step=1100
06/17/2022 23:16:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
06/17/2022 23:16:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=79
06/17/2022 23:16:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=80
06/17/2022 23:16:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=81
06/17/2022 23:16:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=82
06/17/2022 23:16:46 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.6530859147177932 on epoch=82
06/17/2022 23:16:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/17/2022 23:16:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.29 on epoch=83
06/17/2022 23:16:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=84
06/17/2022 23:16:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=84
06/17/2022 23:16:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/17/2022 23:17:05 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.613520976979909 on epoch=85
06/17/2022 23:17:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/17/2022 23:17:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=87
06/17/2022 23:17:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=87
06/17/2022 23:17:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.27 on epoch=88
06/17/2022 23:17:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
06/17/2022 23:17:24 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.6648312345466045 on epoch=89
06/17/2022 23:17:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
06/17/2022 23:17:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=90
06/17/2022 23:17:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=91
06/17/2022 23:17:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.26 on epoch=92
06/17/2022 23:17:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=92
06/17/2022 23:17:44 - INFO - __main__ - Global step 1300 Train loss 0.19 Classification-F1 0.8478740600182726 on epoch=92
06/17/2022 23:17:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7633828098847104 -> 0.8478740600182726 on epoch=92, global_step=1300
06/17/2022 23:17:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=93
06/17/2022 23:17:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=94
06/17/2022 23:17:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/17/2022 23:17:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/17/2022 23:17:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=96
06/17/2022 23:18:03 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.723970908826222 on epoch=96
06/17/2022 23:18:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=97
06/17/2022 23:18:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=97
06/17/2022 23:18:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
06/17/2022 23:18:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=99
06/17/2022 23:18:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=99
06/17/2022 23:18:22 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.672598176483126 on epoch=99
06/17/2022 23:18:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=100
06/17/2022 23:18:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/17/2022 23:18:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=102
06/17/2022 23:18:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
06/17/2022 23:18:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=103
06/17/2022 23:18:41 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.7752148435706869 on epoch=103
06/17/2022 23:18:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/17/2022 23:18:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/17/2022 23:18:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/17/2022 23:18:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/17/2022 23:18:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
06/17/2022 23:18:59 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.7695586773608875 on epoch=107
06/17/2022 23:19:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=107
06/17/2022 23:19:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=108
06/17/2022 23:19:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/17/2022 23:19:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/17/2022 23:19:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=110
06/17/2022 23:19:18 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.8254483024881507 on epoch=110
06/17/2022 23:19:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/17/2022 23:19:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.18 on epoch=112
06/17/2022 23:19:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/17/2022 23:19:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=113
06/17/2022 23:19:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/17/2022 23:19:37 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.7840226447660313 on epoch=114
06/17/2022 23:19:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
06/17/2022 23:19:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=115
06/17/2022 23:19:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.17 on epoch=116
06/17/2022 23:19:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
06/17/2022 23:19:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/17/2022 23:19:56 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.8254483024881507 on epoch=117
06/17/2022 23:19:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/17/2022 23:20:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/17/2022 23:20:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/17/2022 23:20:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=120
06/17/2022 23:20:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/17/2022 23:20:15 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.8236657712938549 on epoch=121
06/17/2022 23:20:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=122
06/17/2022 23:20:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/17/2022 23:20:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
06/17/2022 23:20:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=124
06/17/2022 23:20:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/17/2022 23:20:35 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.7578788539163582 on epoch=124
06/17/2022 23:20:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/17/2022 23:20:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
06/17/2022 23:20:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=127
06/17/2022 23:20:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=127
06/17/2022 23:20:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/17/2022 23:20:54 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7633828098847104 on epoch=128
06/17/2022 23:20:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/17/2022 23:20:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/17/2022 23:21:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/17/2022 23:21:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/17/2022 23:21:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/17/2022 23:21:13 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.6796208492413951 on epoch=132
06/17/2022 23:21:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/17/2022 23:21:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/17/2022 23:21:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/17/2022 23:21:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/17/2022 23:21:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
06/17/2022 23:21:32 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6441970258289045 on epoch=135
06/17/2022 23:21:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/17/2022 23:21:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/17/2022 23:21:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/17/2022 23:21:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/17/2022 23:21:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/17/2022 23:21:50 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.694695164684179 on epoch=139
06/17/2022 23:21:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=139
06/17/2022 23:21:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=140
06/17/2022 23:21:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/17/2022 23:22:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/17/2022 23:22:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/17/2022 23:22:09 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7016691213148862 on epoch=142
06/17/2022 23:22:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
06/17/2022 23:22:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
06/17/2022 23:22:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=144
06/17/2022 23:22:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/17/2022 23:22:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/17/2022 23:22:28 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.8008120911346718 on epoch=146
06/17/2022 23:22:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=147
06/17/2022 23:22:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/17/2022 23:22:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/17/2022 23:22:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
06/17/2022 23:22:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/17/2022 23:22:47 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7926323869397872 on epoch=149
06/17/2022 23:22:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/17/2022 23:22:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/17/2022 23:22:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.13 on epoch=152
06/17/2022 23:22:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/17/2022 23:23:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
06/17/2022 23:23:06 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.7972368815096798 on epoch=153
06/17/2022 23:23:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/17/2022 23:23:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/17/2022 23:23:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=155
06/17/2022 23:23:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/17/2022 23:23:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/17/2022 23:23:25 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7871598996679922 on epoch=157
06/17/2022 23:23:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=157
06/17/2022 23:23:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/17/2022 23:23:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
06/17/2022 23:23:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/17/2022 23:23:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/17/2022 23:23:44 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.6894518784272631 on epoch=160
06/17/2022 23:23:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/17/2022 23:23:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
06/17/2022 23:23:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=162
06/17/2022 23:23:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/17/2022 23:23:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/17/2022 23:24:02 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.6861591892262546 on epoch=164
06/17/2022 23:24:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/17/2022 23:24:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 23:24:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/17/2022 23:24:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/17/2022 23:24:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/17/2022 23:24:21 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.743928296522967 on epoch=167
06/17/2022 23:24:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.15 on epoch=168
06/17/2022 23:24:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/17/2022 23:24:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/17/2022 23:24:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/17/2022 23:24:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/17/2022 23:24:40 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.743928296522967 on epoch=171
06/17/2022 23:24:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/17/2022 23:24:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/17/2022 23:24:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/17/2022 23:24:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/17/2022 23:24:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/17/2022 23:24:59 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7869591776679622 on epoch=174
06/17/2022 23:25:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/17/2022 23:25:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
06/17/2022 23:25:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 23:25:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/17/2022 23:25:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=178
06/17/2022 23:25:18 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7423233795480311 on epoch=178
06/17/2022 23:25:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/17/2022 23:25:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/17/2022 23:25:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=180
06/17/2022 23:25:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/17/2022 23:25:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=182
06/17/2022 23:25:37 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.71111797088028 on epoch=182
06/17/2022 23:25:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/17/2022 23:25:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/17/2022 23:25:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 23:25:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/17/2022 23:25:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/17/2022 23:25:56 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7472479379500252 on epoch=185
06/17/2022 23:25:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/17/2022 23:26:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=187
06/17/2022 23:26:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/17/2022 23:26:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/17/2022 23:26:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/17/2022 23:26:15 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7563225305160789 on epoch=189
06/17/2022 23:26:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/17/2022 23:26:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/17/2022 23:26:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/17/2022 23:26:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/17/2022 23:26:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
06/17/2022 23:26:34 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7107261166544099 on epoch=192
06/17/2022 23:26:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/17/2022 23:26:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/17/2022 23:26:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/17/2022 23:26:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/17/2022 23:26:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/17/2022 23:26:52 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7474039129018091 on epoch=196
06/17/2022 23:26:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
06/17/2022 23:26:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/17/2022 23:27:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
06/17/2022 23:27:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/17/2022 23:27:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/17/2022 23:27:11 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7486264287402808 on epoch=199
06/17/2022 23:27:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/17/2022 23:27:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/17/2022 23:27:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/17/2022 23:27:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/17/2022 23:27:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/17/2022 23:27:30 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7529459436480308 on epoch=203
06/17/2022 23:27:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/17/2022 23:27:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/17/2022 23:27:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/17/2022 23:27:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/17/2022 23:27:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/17/2022 23:27:49 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.749569356779983 on epoch=207
06/17/2022 23:27:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/17/2022 23:27:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/17/2022 23:27:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/17/2022 23:27:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/17/2022 23:28:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/17/2022 23:28:08 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.760538479176472 on epoch=210
06/17/2022 23:28:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/17/2022 23:28:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/17/2022 23:28:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/17/2022 23:28:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/17/2022 23:28:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/17/2022 23:28:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:28:22 - INFO - __main__ - Printing 3 examples
06/17/2022 23:28:22 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 23:28:22 - INFO - __main__ - ['Animal']
06/17/2022 23:28:22 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 23:28:22 - INFO - __main__ - ['Animal']
06/17/2022 23:28:22 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/17/2022 23:28:22 - INFO - __main__ - ['Animal']
06/17/2022 23:28:22 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:28:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:28:23 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 23:28:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:28:23 - INFO - __main__ - Printing 3 examples
06/17/2022 23:28:23 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 23:28:23 - INFO - __main__ - ['Animal']
06/17/2022 23:28:23 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 23:28:23 - INFO - __main__ - ['Animal']
06/17/2022 23:28:23 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 23:28:23 - INFO - __main__ - ['Animal']
06/17/2022 23:28:23 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:28:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:28:23 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 23:28:27 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7489314396335269 on epoch=214
06/17/2022 23:28:27 - INFO - __main__ - save last model!
06/17/2022 23:28:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 23:28:27 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 23:28:27 - INFO - __main__ - Printing 3 examples
06/17/2022 23:28:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 23:28:27 - INFO - __main__ - ['Animal']
06/17/2022 23:28:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 23:28:27 - INFO - __main__ - ['Animal']
06/17/2022 23:28:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 23:28:27 - INFO - __main__ - ['Village']
06/17/2022 23:28:27 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:28:29 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:28:33 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 23:28:42 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 23:28:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 23:28:43 - INFO - __main__ - Starting training!
06/17/2022 23:30:31 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/17/2022 23:30:31 - INFO - __main__ - Classification-F1 on test data: 0.4477
06/17/2022 23:30:32 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.8478740600182726, test_performance=0.44766498049286685
06/17/2022 23:30:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/17/2022 23:30:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:30:33 - INFO - __main__ - Printing 3 examples
06/17/2022 23:30:33 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 23:30:33 - INFO - __main__ - ['Animal']
06/17/2022 23:30:33 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 23:30:33 - INFO - __main__ - ['Animal']
06/17/2022 23:30:33 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/17/2022 23:30:33 - INFO - __main__ - ['Animal']
06/17/2022 23:30:33 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:30:33 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:30:33 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 23:30:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:30:33 - INFO - __main__ - Printing 3 examples
06/17/2022 23:30:33 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 23:30:33 - INFO - __main__ - ['Animal']
06/17/2022 23:30:33 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 23:30:33 - INFO - __main__ - ['Animal']
06/17/2022 23:30:33 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 23:30:33 - INFO - __main__ - ['Animal']
06/17/2022 23:30:33 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:30:33 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:30:33 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 23:30:48 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 23:30:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 23:30:49 - INFO - __main__ - Starting training!
06/17/2022 23:30:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.08 on epoch=0
06/17/2022 23:30:55 - INFO - __main__ - Step 20 Global step 20 Train loss 4.76 on epoch=1
06/17/2022 23:30:58 - INFO - __main__ - Step 30 Global step 30 Train loss 3.92 on epoch=2
06/17/2022 23:31:00 - INFO - __main__ - Step 40 Global step 40 Train loss 3.28 on epoch=2
06/17/2022 23:31:03 - INFO - __main__ - Step 50 Global step 50 Train loss 2.99 on epoch=3
06/17/2022 23:31:09 - INFO - __main__ - Global step 50 Train loss 4.21 Classification-F1 0.07866356120454877 on epoch=3
06/17/2022 23:31:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07866356120454877 on epoch=3, global_step=50
06/17/2022 23:31:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.55 on epoch=4
06/17/2022 23:31:14 - INFO - __main__ - Step 70 Global step 70 Train loss 2.17 on epoch=4
06/17/2022 23:31:16 - INFO - __main__ - Step 80 Global step 80 Train loss 2.05 on epoch=5
06/17/2022 23:31:19 - INFO - __main__ - Step 90 Global step 90 Train loss 1.83 on epoch=6
06/17/2022 23:31:22 - INFO - __main__ - Step 100 Global step 100 Train loss 1.84 on epoch=7
06/17/2022 23:31:27 - INFO - __main__ - Global step 100 Train loss 2.09 Classification-F1 0.11231891081831913 on epoch=7
06/17/2022 23:31:27 - INFO - __main__ - Saving model with best Classification-F1: 0.07866356120454877 -> 0.11231891081831913 on epoch=7, global_step=100
06/17/2022 23:31:30 - INFO - __main__ - Step 110 Global step 110 Train loss 1.57 on epoch=7
06/17/2022 23:31:32 - INFO - __main__ - Step 120 Global step 120 Train loss 1.50 on epoch=8
06/17/2022 23:31:35 - INFO - __main__ - Step 130 Global step 130 Train loss 1.24 on epoch=9
06/17/2022 23:31:37 - INFO - __main__ - Step 140 Global step 140 Train loss 1.12 on epoch=9
06/17/2022 23:31:40 - INFO - __main__ - Step 150 Global step 150 Train loss 1.12 on epoch=10
06/17/2022 23:31:46 - INFO - __main__ - Global step 150 Train loss 1.31 Classification-F1 0.3149716021008731 on epoch=10
06/17/2022 23:31:46 - INFO - __main__ - Saving model with best Classification-F1: 0.11231891081831913 -> 0.3149716021008731 on epoch=10, global_step=150
06/17/2022 23:31:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.99 on epoch=11
06/17/2022 23:31:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=12
06/17/2022 23:31:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=12
06/17/2022 23:31:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=13
06/17/2022 23:32:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=14
06/17/2022 23:32:06 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.5270462468280661 on epoch=14
06/17/2022 23:32:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3149716021008731 -> 0.5270462468280661 on epoch=14, global_step=200
06/17/2022 23:32:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=14
06/17/2022 23:32:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=15
06/17/2022 23:32:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=16
06/17/2022 23:32:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=17
06/17/2022 23:32:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=17
06/17/2022 23:32:26 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.4808251693724932 on epoch=17
06/17/2022 23:32:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=18
06/17/2022 23:32:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=19
06/17/2022 23:32:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=19
06/17/2022 23:32:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=20
06/17/2022 23:32:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=21
06/17/2022 23:32:45 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.6022483577986425 on epoch=21
06/17/2022 23:32:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5270462468280661 -> 0.6022483577986425 on epoch=21, global_step=300
06/17/2022 23:32:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=22
06/17/2022 23:32:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=22
06/17/2022 23:32:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=23
06/17/2022 23:32:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=24
06/17/2022 23:32:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=24
06/17/2022 23:33:05 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.635591194200065 on epoch=24
06/17/2022 23:33:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6022483577986425 -> 0.635591194200065 on epoch=24, global_step=350
06/17/2022 23:33:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=25
06/17/2022 23:33:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=26
06/17/2022 23:33:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=27
06/17/2022 23:33:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=27
06/17/2022 23:33:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
06/17/2022 23:33:25 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.6818985697381283 on epoch=28
06/17/2022 23:33:25 - INFO - __main__ - Saving model with best Classification-F1: 0.635591194200065 -> 0.6818985697381283 on epoch=28, global_step=400
06/17/2022 23:33:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=29
06/17/2022 23:33:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=29
06/17/2022 23:33:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=30
06/17/2022 23:33:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=31
06/17/2022 23:33:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
06/17/2022 23:33:44 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.6868787621546535 on epoch=32
06/17/2022 23:33:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6818985697381283 -> 0.6868787621546535 on epoch=32, global_step=450
06/17/2022 23:33:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=32
06/17/2022 23:33:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=33
06/17/2022 23:33:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=34
06/17/2022 23:33:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=34
06/17/2022 23:33:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=35
06/17/2022 23:34:03 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.6292014907135874 on epoch=35
06/17/2022 23:34:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=36
06/17/2022 23:34:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=37
06/17/2022 23:34:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=37
06/17/2022 23:34:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=38
06/17/2022 23:34:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
06/17/2022 23:34:22 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.6740850839398158 on epoch=39
06/17/2022 23:34:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=39
06/17/2022 23:34:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=40
06/17/2022 23:34:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=41
06/17/2022 23:34:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/17/2022 23:34:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
06/17/2022 23:34:41 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7196186837843417 on epoch=42
06/17/2022 23:34:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6868787621546535 -> 0.7196186837843417 on epoch=42, global_step=600
06/17/2022 23:34:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
06/17/2022 23:34:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=44
06/17/2022 23:34:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
06/17/2022 23:34:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=45
06/17/2022 23:34:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
06/17/2022 23:35:00 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7754971093622652 on epoch=46
06/17/2022 23:35:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7196186837843417 -> 0.7754971093622652 on epoch=46, global_step=650
06/17/2022 23:35:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=47
06/17/2022 23:35:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
06/17/2022 23:35:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=48
06/17/2022 23:35:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
06/17/2022 23:35:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/17/2022 23:35:19 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7486105998730319 on epoch=49
06/17/2022 23:35:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
06/17/2022 23:35:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
06/17/2022 23:35:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/17/2022 23:35:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=52
06/17/2022 23:35:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=53
06/17/2022 23:35:38 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.7855697786284828 on epoch=53
06/17/2022 23:35:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7754971093622652 -> 0.7855697786284828 on epoch=53, global_step=750
06/17/2022 23:35:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
06/17/2022 23:35:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
06/17/2022 23:35:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=55
06/17/2022 23:35:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=56
06/17/2022 23:35:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
06/17/2022 23:35:57 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.7945440507194532 on epoch=57
06/17/2022 23:35:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7855697786284828 -> 0.7945440507194532 on epoch=57, global_step=800
06/17/2022 23:36:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/17/2022 23:36:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=58
06/17/2022 23:36:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
06/17/2022 23:36:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
06/17/2022 23:36:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=60
06/17/2022 23:36:17 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7991906733367834 on epoch=60
06/17/2022 23:36:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7945440507194532 -> 0.7991906733367834 on epoch=60, global_step=850
06/17/2022 23:36:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/17/2022 23:36:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=62
06/17/2022 23:36:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
06/17/2022 23:36:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
06/17/2022 23:36:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/17/2022 23:36:36 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7529990767893994 on epoch=64
06/17/2022 23:36:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/17/2022 23:36:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/17/2022 23:36:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 23:36:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/17/2022 23:36:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
06/17/2022 23:36:55 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7042924488134078 on epoch=67
06/17/2022 23:36:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
06/17/2022 23:37:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
06/17/2022 23:37:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
06/17/2022 23:37:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/17/2022 23:37:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/17/2022 23:37:14 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7877326458055814 on epoch=71
06/17/2022 23:37:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/17/2022 23:37:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=72
06/17/2022 23:37:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
06/17/2022 23:37:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/17/2022 23:37:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/17/2022 23:37:34 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7968622193662224 on epoch=74
06/17/2022 23:37:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
06/17/2022 23:37:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/17/2022 23:37:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
06/17/2022 23:37:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/17/2022 23:37:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/17/2022 23:37:53 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.9016525541352145 on epoch=78
06/17/2022 23:37:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7991906733367834 -> 0.9016525541352145 on epoch=78, global_step=1100
06/17/2022 23:37:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/17/2022 23:37:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/17/2022 23:38:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/17/2022 23:38:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/17/2022 23:38:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/17/2022 23:38:12 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.901526291508952 on epoch=82
06/17/2022 23:38:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/17/2022 23:38:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
06/17/2022 23:38:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/17/2022 23:38:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/17/2022 23:38:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=85
06/17/2022 23:38:31 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.8451662984247699 on epoch=85
06/17/2022 23:38:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
06/17/2022 23:38:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
06/17/2022 23:38:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/17/2022 23:38:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
06/17/2022 23:38:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/17/2022 23:38:50 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.8472092462857324 on epoch=89
06/17/2022 23:38:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
06/17/2022 23:38:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 23:38:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=91
06/17/2022 23:39:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/17/2022 23:39:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/17/2022 23:39:09 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8975382860866731 on epoch=92
06/17/2022 23:39:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/17/2022 23:39:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/17/2022 23:39:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/17/2022 23:39:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/17/2022 23:39:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
06/17/2022 23:39:28 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.8473697781898684 on epoch=96
06/17/2022 23:39:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/17/2022 23:39:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
06/17/2022 23:39:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/17/2022 23:39:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/17/2022 23:39:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/17/2022 23:39:47 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.793185748777987 on epoch=99
06/17/2022 23:39:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/17/2022 23:39:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/17/2022 23:39:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/17/2022 23:39:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/17/2022 23:40:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/17/2022 23:40:06 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9058404003391897 on epoch=103
06/17/2022 23:40:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9016525541352145 -> 0.9058404003391897 on epoch=103, global_step=1450
06/17/2022 23:40:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 23:40:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/17/2022 23:40:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/17/2022 23:40:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 23:40:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/17/2022 23:40:26 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7894905903627147 on epoch=107
06/17/2022 23:40:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/17/2022 23:40:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/17/2022 23:40:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/17/2022 23:40:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/17/2022 23:40:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/17/2022 23:40:45 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7420226485032969 on epoch=110
06/17/2022 23:40:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/17/2022 23:40:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/17/2022 23:40:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/17/2022 23:40:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/17/2022 23:40:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/17/2022 23:41:04 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7871724217159457 on epoch=114
06/17/2022 23:41:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/17/2022 23:41:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/17/2022 23:41:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/17/2022 23:41:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/17/2022 23:41:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/17/2022 23:41:23 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8392386634411577 on epoch=117
06/17/2022 23:41:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=118
06/17/2022 23:41:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/17/2022 23:41:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/17/2022 23:41:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 23:41:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/17/2022 23:41:43 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8392386634411576 on epoch=121
06/17/2022 23:41:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/17/2022 23:41:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/17/2022 23:41:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/17/2022 23:41:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/17/2022 23:41:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/17/2022 23:42:02 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8973384453049765 on epoch=124
06/17/2022 23:42:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 23:42:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/17/2022 23:42:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 23:42:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 23:42:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 23:42:22 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7920541658766272 on epoch=128
06/17/2022 23:42:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/17/2022 23:42:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 23:42:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/17/2022 23:42:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/17/2022 23:42:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/17/2022 23:42:41 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8432831404695056 on epoch=132
06/17/2022 23:42:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 23:42:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 23:42:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/17/2022 23:42:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/17/2022 23:42:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/17/2022 23:43:01 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7873487518174426 on epoch=135
06/17/2022 23:43:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/17/2022 23:43:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/17/2022 23:43:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 23:43:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 23:43:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 23:43:21 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7992021735380369 on epoch=139
06/17/2022 23:43:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/17/2022 23:43:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/17/2022 23:43:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/17/2022 23:43:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
06/17/2022 23:43:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 23:43:41 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7412555965871379 on epoch=142
06/17/2022 23:43:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/17/2022 23:43:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/17/2022 23:43:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/17/2022 23:43:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/17/2022 23:43:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/17/2022 23:44:01 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9101938742261323 on epoch=146
06/17/2022 23:44:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9058404003391897 -> 0.9101938742261323 on epoch=146, global_step=2050
06/17/2022 23:44:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 23:44:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 23:44:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/17/2022 23:44:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/17/2022 23:44:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/17/2022 23:44:20 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7920251600726542 on epoch=149
06/17/2022 23:44:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/17/2022 23:44:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/17/2022 23:44:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 23:44:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/17/2022 23:44:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/17/2022 23:44:40 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7955004616992563 on epoch=153
06/17/2022 23:44:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/17/2022 23:44:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
06/17/2022 23:44:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 23:44:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/17/2022 23:44:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 23:45:00 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7455009441951632 on epoch=157
06/17/2022 23:45:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/17/2022 23:45:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/17/2022 23:45:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 23:45:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 23:45:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/17/2022 23:45:20 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8511154962857325 on epoch=160
06/17/2022 23:45:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/17/2022 23:45:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/17/2022 23:45:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 23:45:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 23:45:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/17/2022 23:45:39 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9728474335431413 on epoch=164
06/17/2022 23:45:39 - INFO - __main__ - Saving model with best Classification-F1: 0.9101938742261323 -> 0.9728474335431413 on epoch=164, global_step=2300
06/17/2022 23:45:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 23:45:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 23:45:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/17/2022 23:45:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/17/2022 23:45:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/17/2022 23:45:59 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.914360540892799 on epoch=167
06/17/2022 23:46:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/17/2022 23:46:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/17/2022 23:46:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 23:46:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 23:46:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/17/2022 23:46:20 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9101938742261323 on epoch=171
06/17/2022 23:46:22 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/17/2022 23:46:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 23:46:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/17/2022 23:46:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/17/2022 23:46:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 23:46:40 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9101938742261323 on epoch=174
06/17/2022 23:46:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/17/2022 23:46:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/17/2022 23:46:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 23:46:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 23:46:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/17/2022 23:47:00 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9101938742261323 on epoch=178
06/17/2022 23:47:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/17/2022 23:47:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 23:47:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/17/2022 23:47:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 23:47:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/17/2022 23:47:19 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9683831478288555 on epoch=182
06/17/2022 23:47:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/17/2022 23:47:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/17/2022 23:47:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/17/2022 23:47:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/17/2022 23:47:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/17/2022 23:47:39 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9058404003391897 on epoch=185
06/17/2022 23:47:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 23:47:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 23:47:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/17/2022 23:47:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 23:47:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/17/2022 23:47:58 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9058404003391897 on epoch=189
06/17/2022 23:48:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 23:48:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/17/2022 23:48:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 23:48:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 23:48:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/17/2022 23:48:18 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9730475841362937 on epoch=192
06/17/2022 23:48:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9728474335431413 -> 0.9730475841362937 on epoch=192, global_step=2700
06/17/2022 23:48:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/17/2022 23:48:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 23:48:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 23:48:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/17/2022 23:48:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 23:48:37 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9730475841362937 on epoch=196
06/17/2022 23:48:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/17/2022 23:48:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 23:48:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 23:48:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 23:48:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 23:48:57 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9683831478288555 on epoch=199
06/17/2022 23:49:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/17/2022 23:49:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 23:49:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/17/2022 23:49:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 23:49:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/17/2022 23:49:17 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9730475841362937 on epoch=203
06/17/2022 23:49:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 23:49:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 23:49:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 23:49:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/17/2022 23:49:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 23:49:37 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9101938742261323 on epoch=207
06/17/2022 23:49:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/17/2022 23:49:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 23:49:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 23:49:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/17/2022 23:49:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/17/2022 23:49:57 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9058797653958943 on epoch=210
06/17/2022 23:49:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 23:50:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/17/2022 23:50:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 23:50:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 23:50:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 23:50:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:50:11 - INFO - __main__ - Printing 3 examples
06/17/2022 23:50:11 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 23:50:11 - INFO - __main__ - ['Animal']
06/17/2022 23:50:11 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 23:50:11 - INFO - __main__ - ['Animal']
06/17/2022 23:50:11 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/17/2022 23:50:11 - INFO - __main__ - ['Animal']
06/17/2022 23:50:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:50:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:50:12 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 23:50:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:50:12 - INFO - __main__ - Printing 3 examples
06/17/2022 23:50:12 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 23:50:12 - INFO - __main__ - ['Animal']
06/17/2022 23:50:12 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 23:50:12 - INFO - __main__ - ['Animal']
06/17/2022 23:50:12 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 23:50:12 - INFO - __main__ - ['Animal']
06/17/2022 23:50:12 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:50:12 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:50:12 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 23:50:17 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9060402411208862 on epoch=214
06/17/2022 23:50:17 - INFO - __main__ - save last model!
06/17/2022 23:50:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 23:50:17 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 23:50:17 - INFO - __main__ - Printing 3 examples
06/17/2022 23:50:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/17/2022 23:50:17 - INFO - __main__ - ['Animal']
06/17/2022 23:50:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 23:50:17 - INFO - __main__ - ['Animal']
06/17/2022 23:50:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/17/2022 23:50:17 - INFO - __main__ - ['Village']
06/17/2022 23:50:17 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:50:19 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:50:22 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 23:50:27 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 23:50:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 23:50:28 - INFO - __main__ - Starting training!
06/17/2022 23:52:47 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/17/2022 23:52:47 - INFO - __main__ - Classification-F1 on test data: 0.7223
06/17/2022 23:52:47 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9730475841362937, test_performance=0.7222666295004864
06/17/2022 23:52:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/17/2022 23:52:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:52:48 - INFO - __main__ - Printing 3 examples
06/17/2022 23:52:48 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 23:52:48 - INFO - __main__ - ['Animal']
06/17/2022 23:52:48 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 23:52:48 - INFO - __main__ - ['Animal']
06/17/2022 23:52:48 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/17/2022 23:52:48 - INFO - __main__ - ['Animal']
06/17/2022 23:52:48 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:52:48 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:52:49 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 23:52:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 23:52:49 - INFO - __main__ - Printing 3 examples
06/17/2022 23:52:49 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 23:52:49 - INFO - __main__ - ['Animal']
06/17/2022 23:52:49 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 23:52:49 - INFO - __main__ - ['Animal']
06/17/2022 23:52:49 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 23:52:49 - INFO - __main__ - ['Animal']
06/17/2022 23:52:49 - INFO - __main__ - Tokenizing Input ...
06/17/2022 23:52:49 - INFO - __main__ - Tokenizing Output ...
06/17/2022 23:52:49 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 23:53:04 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 23:53:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/17/2022 23:53:05 - INFO - __main__ - Starting training!
06/17/2022 23:53:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.26 on epoch=0
06/17/2022 23:53:11 - INFO - __main__ - Step 20 Global step 20 Train loss 4.89 on epoch=1
06/17/2022 23:53:14 - INFO - __main__ - Step 30 Global step 30 Train loss 4.29 on epoch=2
06/17/2022 23:53:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.63 on epoch=2
06/17/2022 23:53:19 - INFO - __main__ - Step 50 Global step 50 Train loss 3.46 on epoch=3
06/17/2022 23:53:24 - INFO - __main__ - Global step 50 Train loss 4.51 Classification-F1 0.07280573767968727 on epoch=3
06/17/2022 23:53:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07280573767968727 on epoch=3, global_step=50
06/17/2022 23:53:27 - INFO - __main__ - Step 60 Global step 60 Train loss 3.12 on epoch=4
06/17/2022 23:53:30 - INFO - __main__ - Step 70 Global step 70 Train loss 2.61 on epoch=4
06/17/2022 23:53:32 - INFO - __main__ - Step 80 Global step 80 Train loss 2.43 on epoch=5
06/17/2022 23:53:35 - INFO - __main__ - Step 90 Global step 90 Train loss 2.12 on epoch=6
06/17/2022 23:53:37 - INFO - __main__ - Step 100 Global step 100 Train loss 2.13 on epoch=7
06/17/2022 23:53:43 - INFO - __main__ - Global step 100 Train loss 2.48 Classification-F1 0.10469265007640982 on epoch=7
06/17/2022 23:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.07280573767968727 -> 0.10469265007640982 on epoch=7, global_step=100
06/17/2022 23:53:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.85 on epoch=7
06/17/2022 23:53:48 - INFO - __main__ - Step 120 Global step 120 Train loss 1.83 on epoch=8
06/17/2022 23:53:50 - INFO - __main__ - Step 130 Global step 130 Train loss 1.63 on epoch=9
06/17/2022 23:53:53 - INFO - __main__ - Step 140 Global step 140 Train loss 1.44 on epoch=9
06/17/2022 23:53:56 - INFO - __main__ - Step 150 Global step 150 Train loss 1.44 on epoch=10
06/17/2022 23:54:02 - INFO - __main__ - Global step 150 Train loss 1.64 Classification-F1 0.18684687078994708 on epoch=10
06/17/2022 23:54:02 - INFO - __main__ - Saving model with best Classification-F1: 0.10469265007640982 -> 0.18684687078994708 on epoch=10, global_step=150
06/17/2022 23:54:04 - INFO - __main__ - Step 160 Global step 160 Train loss 1.32 on epoch=11
06/17/2022 23:54:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.17 on epoch=12
06/17/2022 23:54:09 - INFO - __main__ - Step 180 Global step 180 Train loss 1.03 on epoch=12
06/17/2022 23:54:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.99 on epoch=13
06/17/2022 23:54:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.87 on epoch=14
06/17/2022 23:54:21 - INFO - __main__ - Global step 200 Train loss 1.07 Classification-F1 0.3857627074781197 on epoch=14
06/17/2022 23:54:21 - INFO - __main__ - Saving model with best Classification-F1: 0.18684687078994708 -> 0.3857627074781197 on epoch=14, global_step=200
06/17/2022 23:54:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=14
06/17/2022 23:54:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=15
06/17/2022 23:54:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=16
06/17/2022 23:54:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=17
06/17/2022 23:54:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=17
06/17/2022 23:54:41 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.5262595862738749 on epoch=17
06/17/2022 23:54:41 - INFO - __main__ - Saving model with best Classification-F1: 0.3857627074781197 -> 0.5262595862738749 on epoch=17, global_step=250
06/17/2022 23:54:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=18
06/17/2022 23:54:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
06/17/2022 23:54:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=19
06/17/2022 23:54:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=20
06/17/2022 23:54:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=21
06/17/2022 23:55:00 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.48024946305112587 on epoch=21
06/17/2022 23:55:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
06/17/2022 23:55:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
06/17/2022 23:55:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=23
06/17/2022 23:55:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
06/17/2022 23:55:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=24
06/17/2022 23:55:19 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.5798843351286426 on epoch=24
06/17/2022 23:55:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5262595862738749 -> 0.5798843351286426 on epoch=24, global_step=350
06/17/2022 23:55:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
06/17/2022 23:55:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=26
06/17/2022 23:55:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=27
06/17/2022 23:55:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=27
06/17/2022 23:55:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=28
06/17/2022 23:55:39 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.6160414138605184 on epoch=28
06/17/2022 23:55:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5798843351286426 -> 0.6160414138605184 on epoch=28, global_step=400
06/17/2022 23:55:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=29
06/17/2022 23:55:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=29
06/17/2022 23:55:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=30
06/17/2022 23:55:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=31
06/17/2022 23:55:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
06/17/2022 23:55:58 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.6955019231993648 on epoch=32
06/17/2022 23:55:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6160414138605184 -> 0.6955019231993648 on epoch=32, global_step=450
06/17/2022 23:56:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=32
06/17/2022 23:56:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=33
06/17/2022 23:56:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=34
06/17/2022 23:56:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
06/17/2022 23:56:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=35
06/17/2022 23:56:17 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6856957275887666 on epoch=35
06/17/2022 23:56:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
06/17/2022 23:56:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/17/2022 23:56:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
06/17/2022 23:56:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=38
06/17/2022 23:56:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
06/17/2022 23:56:37 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.62216582868864 on epoch=39
06/17/2022 23:56:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
06/17/2022 23:56:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
06/17/2022 23:56:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
06/17/2022 23:56:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
06/17/2022 23:56:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
06/17/2022 23:56:56 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7392464972303682 on epoch=42
06/17/2022 23:56:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6955019231993648 -> 0.7392464972303682 on epoch=42, global_step=600
06/17/2022 23:56:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=43
06/17/2022 23:57:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/17/2022 23:57:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/17/2022 23:57:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
06/17/2022 23:57:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=46
06/17/2022 23:57:16 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.7200664044170719 on epoch=46
06/17/2022 23:57:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
06/17/2022 23:57:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=47
06/17/2022 23:57:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
06/17/2022 23:57:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=49
06/17/2022 23:57:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
06/17/2022 23:57:35 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7492694730597955 on epoch=49
06/17/2022 23:57:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7392464972303682 -> 0.7492694730597955 on epoch=49, global_step=700
06/17/2022 23:57:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
06/17/2022 23:57:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/17/2022 23:57:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
06/17/2022 23:57:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/17/2022 23:57:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
06/17/2022 23:57:54 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6945835598175599 on epoch=53
06/17/2022 23:57:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
06/17/2022 23:57:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/17/2022 23:58:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
06/17/2022 23:58:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=56
06/17/2022 23:58:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/17/2022 23:58:13 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7795330023118204 on epoch=57
06/17/2022 23:58:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7492694730597955 -> 0.7795330023118204 on epoch=57, global_step=800
06/17/2022 23:58:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
06/17/2022 23:58:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
06/17/2022 23:58:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/17/2022 23:58:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/17/2022 23:58:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/17/2022 23:58:32 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7180765993265992 on epoch=60
06/17/2022 23:58:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/17/2022 23:58:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
06/17/2022 23:58:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
06/17/2022 23:58:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
06/17/2022 23:58:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
06/17/2022 23:58:51 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7871724217159457 on epoch=64
06/17/2022 23:58:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7795330023118204 -> 0.7871724217159457 on epoch=64, global_step=900
06/17/2022 23:58:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
06/17/2022 23:58:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/17/2022 23:58:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
06/17/2022 23:59:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/17/2022 23:59:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
06/17/2022 23:59:10 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8404841546222594 on epoch=67
06/17/2022 23:59:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7871724217159457 -> 0.8404841546222594 on epoch=67, global_step=950
06/17/2022 23:59:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
06/17/2022 23:59:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/17/2022 23:59:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/17/2022 23:59:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/17/2022 23:59:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
06/17/2022 23:59:30 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7934734870791272 on epoch=71
06/17/2022 23:59:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
06/17/2022 23:59:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/17/2022 23:59:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/17/2022 23:59:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/17/2022 23:59:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
06/17/2022 23:59:49 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.9058927989573149 on epoch=74
06/17/2022 23:59:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8404841546222594 -> 0.9058927989573149 on epoch=74, global_step=1050
06/17/2022 23:59:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/17/2022 23:59:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/17/2022 23:59:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/17/2022 23:59:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=77
06/18/2022 00:00:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/18/2022 00:00:08 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7917807166468213 on epoch=78
06/18/2022 00:00:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/18/2022 00:00:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/18/2022 00:00:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
06/18/2022 00:00:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/18/2022 00:00:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/18/2022 00:00:27 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8433521199902249 on epoch=82
06/18/2022 00:00:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/18/2022 00:00:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/18/2022 00:00:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/18/2022 00:00:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/18/2022 00:00:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/18/2022 00:00:47 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8472092462857325 on epoch=85
06/18/2022 00:00:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/18/2022 00:00:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/18/2022 00:00:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/18/2022 00:00:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/18/2022 00:01:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/18/2022 00:01:06 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8452460593841642 on epoch=89
06/18/2022 00:01:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/18/2022 00:01:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/18/2022 00:01:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/18/2022 00:01:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/18/2022 00:01:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/18/2022 00:01:25 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7992021735380369 on epoch=92
06/18/2022 00:01:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/18/2022 00:01:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/18/2022 00:01:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/18/2022 00:01:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/18/2022 00:01:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/18/2022 00:01:44 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.8410142316229758 on epoch=96
06/18/2022 00:01:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/18/2022 00:01:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/18/2022 00:01:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/18/2022 00:01:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/18/2022 00:01:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/18/2022 00:02:03 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7955257029498016 on epoch=99
06/18/2022 00:02:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/18/2022 00:02:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/18/2022 00:02:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/18/2022 00:02:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/18/2022 00:02:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/18/2022 00:02:22 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8374982929388765 on epoch=103
06/18/2022 00:02:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/18/2022 00:02:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/18/2022 00:02:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/18/2022 00:02:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/18/2022 00:02:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/18/2022 00:02:42 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8392916055718476 on epoch=107
06/18/2022 00:02:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/18/2022 00:02:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/18/2022 00:02:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/18/2022 00:02:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/18/2022 00:02:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/18/2022 00:03:02 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8973384453049765 on epoch=110
06/18/2022 00:03:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/18/2022 00:03:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/18/2022 00:03:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/18/2022 00:03:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/18/2022 00:03:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/18/2022 00:03:22 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8513028470185728 on epoch=114
06/18/2022 00:03:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/18/2022 00:03:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/18/2022 00:03:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/18/2022 00:03:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/18/2022 00:03:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/18/2022 00:03:41 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8513028470185728 on epoch=117
06/18/2022 00:03:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/18/2022 00:03:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/18/2022 00:03:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/18/2022 00:03:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/18/2022 00:03:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/18/2022 00:04:01 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9017959233108418 on epoch=121
06/18/2022 00:04:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/18/2022 00:04:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/18/2022 00:04:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/18/2022 00:04:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/18/2022 00:04:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/18/2022 00:04:21 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9014976847583339 on epoch=124
06/18/2022 00:04:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/18/2022 00:04:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/18/2022 00:04:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/18/2022 00:04:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/18/2022 00:04:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/18/2022 00:04:42 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9100070670058564 on epoch=128
06/18/2022 00:04:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9058927989573149 -> 0.9100070670058564 on epoch=128, global_step=1800
06/18/2022 00:04:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/18/2022 00:04:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/18/2022 00:04:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/18/2022 00:04:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/18/2022 00:04:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/18/2022 00:05:02 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9100070670058564 on epoch=132
06/18/2022 00:05:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/18/2022 00:05:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/18/2022 00:05:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/18/2022 00:05:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/18/2022 00:05:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/18/2022 00:05:22 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9056970311635626 on epoch=135
06/18/2022 00:05:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/18/2022 00:05:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/18/2022 00:05:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/18/2022 00:05:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/18/2022 00:05:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/18/2022 00:05:43 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9101938742261323 on epoch=139
06/18/2022 00:05:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9100070670058564 -> 0.9101938742261323 on epoch=139, global_step=1950
06/18/2022 00:05:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/18/2022 00:05:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/18/2022 00:05:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/18/2022 00:05:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/18/2022 00:05:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/18/2022 00:06:03 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8513028470185728 on epoch=142
06/18/2022 00:06:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/18/2022 00:06:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/18/2022 00:06:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/18/2022 00:06:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/18/2022 00:06:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/18/2022 00:06:23 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8513028470185728 on epoch=146
06/18/2022 00:06:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/18/2022 00:06:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/18/2022 00:06:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 00:06:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/18/2022 00:06:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/18/2022 00:06:44 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9103216702125622 on epoch=149
06/18/2022 00:06:44 - INFO - __main__ - Saving model with best Classification-F1: 0.9101938742261323 -> 0.9103216702125622 on epoch=149, global_step=2100
06/18/2022 00:06:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/18/2022 00:06:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/18/2022 00:06:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/18/2022 00:06:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/18/2022 00:06:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/18/2022 00:07:04 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9100070670058564 on epoch=153
06/18/2022 00:07:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/18/2022 00:07:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/18/2022 00:07:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/18/2022 00:07:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/18/2022 00:07:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/18/2022 00:07:24 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9100070670058564 on epoch=157
06/18/2022 00:07:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/18/2022 00:07:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/18/2022 00:07:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/18/2022 00:07:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/18/2022 00:07:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/18/2022 00:07:44 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9100070670058564 on epoch=160
06/18/2022 00:07:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/18/2022 00:07:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 00:07:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/18/2022 00:07:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/18/2022 00:07:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/18/2022 00:08:05 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9100070670058564 on epoch=164
06/18/2022 00:08:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/18/2022 00:08:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/18/2022 00:08:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/18/2022 00:08:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/18/2022 00:08:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/18/2022 00:08:25 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.901852394916911 on epoch=167
06/18/2022 00:08:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/18/2022 00:08:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/18/2022 00:08:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/18/2022 00:08:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/18/2022 00:08:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/18/2022 00:08:45 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9017261322906482 on epoch=171
06/18/2022 00:08:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/18/2022 00:08:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/18/2022 00:08:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 00:08:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/18/2022 00:08:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/18/2022 00:09:05 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8511154962857325 on epoch=174
06/18/2022 00:09:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/18/2022 00:09:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/18/2022 00:09:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/18/2022 00:09:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/18/2022 00:09:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/18/2022 00:09:25 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.847246151026393 on epoch=178
06/18/2022 00:09:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 00:09:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/18/2022 00:09:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/18/2022 00:09:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/18/2022 00:09:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/18/2022 00:09:45 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8511154962857325 on epoch=182
06/18/2022 00:09:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/18/2022 00:09:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/18/2022 00:09:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 00:09:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/18/2022 00:09:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/18/2022 00:10:05 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8432831404695057 on epoch=185
06/18/2022 00:10:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/18/2022 00:10:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/18/2022 00:10:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/18/2022 00:10:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/18/2022 00:10:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/18/2022 00:10:25 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9101938742261323 on epoch=189
06/18/2022 00:10:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/18/2022 00:10:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/18/2022 00:10:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/18/2022 00:10:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 00:10:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/18/2022 00:10:45 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9102069077875529 on epoch=192
06/18/2022 00:10:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/18/2022 00:10:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 00:10:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/18/2022 00:10:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/18/2022 00:10:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/18/2022 00:11:05 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.89771948530651 on epoch=196
06/18/2022 00:11:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/18/2022 00:11:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/18/2022 00:11:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/18/2022 00:11:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/18/2022 00:11:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/18/2022 00:11:25 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9056970311635626 on epoch=199
06/18/2022 00:11:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/18/2022 00:11:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/18/2022 00:11:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 00:11:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/18/2022 00:11:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/18/2022 00:11:45 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8472092462857325 on epoch=203
06/18/2022 00:11:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/18/2022 00:11:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 00:11:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/18/2022 00:11:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/18/2022 00:11:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/18/2022 00:12:05 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.851152401026393 on epoch=207
06/18/2022 00:12:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/18/2022 00:12:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/18/2022 00:12:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/18/2022 00:12:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 00:12:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/18/2022 00:12:25 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8434704912023461 on epoch=210
06/18/2022 00:12:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 00:12:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/18/2022 00:12:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/18/2022 00:12:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/18/2022 00:12:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/18/2022 00:12:40 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:12:40 - INFO - __main__ - Printing 3 examples
06/18/2022 00:12:40 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/18/2022 00:12:40 - INFO - __main__ - ['Animal']
06/18/2022 00:12:40 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/18/2022 00:12:40 - INFO - __main__ - ['Animal']
06/18/2022 00:12:40 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/18/2022 00:12:40 - INFO - __main__ - ['Animal']
06/18/2022 00:12:40 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:12:40 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:12:40 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 00:12:40 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:12:40 - INFO - __main__ - Printing 3 examples
06/18/2022 00:12:40 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/18/2022 00:12:40 - INFO - __main__ - ['Animal']
06/18/2022 00:12:40 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/18/2022 00:12:40 - INFO - __main__ - ['Animal']
06/18/2022 00:12:40 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/18/2022 00:12:40 - INFO - __main__ - ['Animal']
06/18/2022 00:12:40 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:12:40 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:12:40 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 00:12:45 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7916889483065955 on epoch=214
06/18/2022 00:12:45 - INFO - __main__ - save last model!
06/18/2022 00:12:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 00:12:46 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 00:12:46 - INFO - __main__ - Printing 3 examples
06/18/2022 00:12:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 00:12:46 - INFO - __main__ - ['Animal']
06/18/2022 00:12:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 00:12:46 - INFO - __main__ - ['Animal']
06/18/2022 00:12:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 00:12:46 - INFO - __main__ - ['Village']
06/18/2022 00:12:46 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:12:47 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:12:51 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 00:12:56 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 00:12:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 00:12:56 - INFO - __main__ - Starting training!
06/18/2022 00:15:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/18/2022 00:15:16 - INFO - __main__ - Classification-F1 on test data: 0.6239
06/18/2022 00:15:17 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9103216702125622, test_performance=0.6239309435130773
06/18/2022 00:15:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/18/2022 00:15:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:15:18 - INFO - __main__ - Printing 3 examples
06/18/2022 00:15:18 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/18/2022 00:15:18 - INFO - __main__ - ['Animal']
06/18/2022 00:15:18 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/18/2022 00:15:18 - INFO - __main__ - ['Animal']
06/18/2022 00:15:18 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/18/2022 00:15:18 - INFO - __main__ - ['Animal']
06/18/2022 00:15:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:15:18 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:15:18 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 00:15:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:15:18 - INFO - __main__ - Printing 3 examples
06/18/2022 00:15:18 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/18/2022 00:15:18 - INFO - __main__ - ['Animal']
06/18/2022 00:15:18 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/18/2022 00:15:18 - INFO - __main__ - ['Animal']
06/18/2022 00:15:18 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/18/2022 00:15:18 - INFO - __main__ - ['Animal']
06/18/2022 00:15:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:15:18 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:15:18 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 00:15:37 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 00:15:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 00:15:37 - INFO - __main__ - Starting training!
06/18/2022 00:15:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.56 on epoch=0
06/18/2022 00:15:43 - INFO - __main__ - Step 20 Global step 20 Train loss 5.09 on epoch=1
06/18/2022 00:15:46 - INFO - __main__ - Step 30 Global step 30 Train loss 4.53 on epoch=2
06/18/2022 00:15:49 - INFO - __main__ - Step 40 Global step 40 Train loss 3.93 on epoch=2
06/18/2022 00:15:51 - INFO - __main__ - Step 50 Global step 50 Train loss 3.77 on epoch=3
06/18/2022 00:15:57 - INFO - __main__ - Global step 50 Train loss 4.78 Classification-F1 0.043547577965961294 on epoch=3
06/18/2022 00:15:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.043547577965961294 on epoch=3, global_step=50
06/18/2022 00:16:00 - INFO - __main__ - Step 60 Global step 60 Train loss 3.42 on epoch=4
06/18/2022 00:16:03 - INFO - __main__ - Step 70 Global step 70 Train loss 3.21 on epoch=4
06/18/2022 00:16:05 - INFO - __main__ - Step 80 Global step 80 Train loss 2.99 on epoch=5
06/18/2022 00:16:08 - INFO - __main__ - Step 90 Global step 90 Train loss 2.44 on epoch=6
06/18/2022 00:16:11 - INFO - __main__ - Step 100 Global step 100 Train loss 2.65 on epoch=7
06/18/2022 00:16:16 - INFO - __main__ - Global step 100 Train loss 2.94 Classification-F1 0.09582374769431698 on epoch=7
06/18/2022 00:16:16 - INFO - __main__ - Saving model with best Classification-F1: 0.043547577965961294 -> 0.09582374769431698 on epoch=7, global_step=100
06/18/2022 00:16:19 - INFO - __main__ - Step 110 Global step 110 Train loss 2.33 on epoch=7
06/18/2022 00:16:21 - INFO - __main__ - Step 120 Global step 120 Train loss 2.12 on epoch=8
06/18/2022 00:16:24 - INFO - __main__ - Step 130 Global step 130 Train loss 2.09 on epoch=9
06/18/2022 00:16:27 - INFO - __main__ - Step 140 Global step 140 Train loss 1.92 on epoch=9
06/18/2022 00:16:29 - INFO - __main__ - Step 150 Global step 150 Train loss 1.89 on epoch=10
06/18/2022 00:16:35 - INFO - __main__ - Global step 150 Train loss 2.07 Classification-F1 0.11002376392891822 on epoch=10
06/18/2022 00:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.09582374769431698 -> 0.11002376392891822 on epoch=10, global_step=150
06/18/2022 00:16:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.67 on epoch=11
06/18/2022 00:16:40 - INFO - __main__ - Step 170 Global step 170 Train loss 1.62 on epoch=12
06/18/2022 00:16:43 - INFO - __main__ - Step 180 Global step 180 Train loss 1.46 on epoch=12
06/18/2022 00:16:45 - INFO - __main__ - Step 190 Global step 190 Train loss 1.52 on epoch=13
06/18/2022 00:16:48 - INFO - __main__ - Step 200 Global step 200 Train loss 1.28 on epoch=14
06/18/2022 00:16:54 - INFO - __main__ - Global step 200 Train loss 1.51 Classification-F1 0.16569364641731624 on epoch=14
06/18/2022 00:16:54 - INFO - __main__ - Saving model with best Classification-F1: 0.11002376392891822 -> 0.16569364641731624 on epoch=14, global_step=200
06/18/2022 00:16:57 - INFO - __main__ - Step 210 Global step 210 Train loss 1.28 on epoch=14
06/18/2022 00:16:59 - INFO - __main__ - Step 220 Global step 220 Train loss 1.21 on epoch=15
06/18/2022 00:17:02 - INFO - __main__ - Step 230 Global step 230 Train loss 1.06 on epoch=16
06/18/2022 00:17:04 - INFO - __main__ - Step 240 Global step 240 Train loss 1.05 on epoch=17
06/18/2022 00:17:07 - INFO - __main__ - Step 250 Global step 250 Train loss 1.00 on epoch=17
06/18/2022 00:17:14 - INFO - __main__ - Global step 250 Train loss 1.12 Classification-F1 0.3058358746492188 on epoch=17
06/18/2022 00:17:14 - INFO - __main__ - Saving model with best Classification-F1: 0.16569364641731624 -> 0.3058358746492188 on epoch=17, global_step=250
06/18/2022 00:17:16 - INFO - __main__ - Step 260 Global step 260 Train loss 0.89 on epoch=18
06/18/2022 00:17:19 - INFO - __main__ - Step 270 Global step 270 Train loss 0.88 on epoch=19
06/18/2022 00:17:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=19
06/18/2022 00:17:24 - INFO - __main__ - Step 290 Global step 290 Train loss 0.76 on epoch=20
06/18/2022 00:17:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.71 on epoch=21
06/18/2022 00:17:33 - INFO - __main__ - Global step 300 Train loss 0.81 Classification-F1 0.5136045658836836 on epoch=21
06/18/2022 00:17:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3058358746492188 -> 0.5136045658836836 on epoch=21, global_step=300
06/18/2022 00:17:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.75 on epoch=22
06/18/2022 00:17:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.58 on epoch=22
06/18/2022 00:17:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=23
06/18/2022 00:17:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.62 on epoch=24
06/18/2022 00:17:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=24
06/18/2022 00:17:53 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.5494058474197281 on epoch=24
06/18/2022 00:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5136045658836836 -> 0.5494058474197281 on epoch=24, global_step=350
06/18/2022 00:17:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=25
06/18/2022 00:17:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=26
06/18/2022 00:18:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=27
06/18/2022 00:18:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=27
06/18/2022 00:18:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=28
06/18/2022 00:18:12 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.5605345449812786 on epoch=28
06/18/2022 00:18:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5494058474197281 -> 0.5605345449812786 on epoch=28, global_step=400
06/18/2022 00:18:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=29
06/18/2022 00:18:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.43 on epoch=29
06/18/2022 00:18:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=30
06/18/2022 00:18:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
06/18/2022 00:18:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=32
06/18/2022 00:18:32 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.609164385687197 on epoch=32
06/18/2022 00:18:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5605345449812786 -> 0.609164385687197 on epoch=32, global_step=450
06/18/2022 00:18:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=32
06/18/2022 00:18:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=33
06/18/2022 00:18:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=34
06/18/2022 00:18:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/18/2022 00:18:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=35
06/18/2022 00:18:51 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.6788960734557864 on epoch=35
06/18/2022 00:18:51 - INFO - __main__ - Saving model with best Classification-F1: 0.609164385687197 -> 0.6788960734557864 on epoch=35, global_step=500
06/18/2022 00:18:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=36
06/18/2022 00:18:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
06/18/2022 00:18:59 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
06/18/2022 00:19:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/18/2022 00:19:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=39
06/18/2022 00:19:11 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.6466136427946699 on epoch=39
06/18/2022 00:19:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/18/2022 00:19:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=40
06/18/2022 00:19:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/18/2022 00:19:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=42
06/18/2022 00:19:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=42
06/18/2022 00:19:30 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.7256906623842109 on epoch=42
06/18/2022 00:19:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6788960734557864 -> 0.7256906623842109 on epoch=42, global_step=600
06/18/2022 00:19:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=43
06/18/2022 00:19:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=44
06/18/2022 00:19:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=44
06/18/2022 00:19:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
06/18/2022 00:19:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
06/18/2022 00:19:49 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.7294191919191919 on epoch=46
06/18/2022 00:19:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7256906623842109 -> 0.7294191919191919 on epoch=46, global_step=650
06/18/2022 00:19:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
06/18/2022 00:19:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=47
06/18/2022 00:19:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/18/2022 00:20:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=49
06/18/2022 00:20:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=49
06/18/2022 00:20:09 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.776299272737273 on epoch=49
06/18/2022 00:20:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7294191919191919 -> 0.776299272737273 on epoch=49, global_step=700
06/18/2022 00:20:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/18/2022 00:20:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
06/18/2022 00:20:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=52
06/18/2022 00:20:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
06/18/2022 00:20:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/18/2022 00:20:28 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.6908887872173102 on epoch=53
06/18/2022 00:20:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
06/18/2022 00:20:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/18/2022 00:20:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
06/18/2022 00:20:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/18/2022 00:20:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
06/18/2022 00:20:47 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.7724212307969953 on epoch=57
06/18/2022 00:20:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
06/18/2022 00:20:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
06/18/2022 00:20:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
06/18/2022 00:20:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/18/2022 00:21:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/18/2022 00:21:06 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7409600047883234 on epoch=60
06/18/2022 00:21:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=61
06/18/2022 00:21:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=62
06/18/2022 00:21:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/18/2022 00:21:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
06/18/2022 00:21:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
06/18/2022 00:21:26 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7009138498739517 on epoch=64
06/18/2022 00:21:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=64
06/18/2022 00:21:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/18/2022 00:21:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
06/18/2022 00:21:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/18/2022 00:21:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/18/2022 00:21:45 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7480839608751795 on epoch=67
06/18/2022 00:21:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/18/2022 00:21:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
06/18/2022 00:21:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=69
06/18/2022 00:21:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/18/2022 00:21:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=71
06/18/2022 00:22:04 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7907374841045375 on epoch=71
06/18/2022 00:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.776299272737273 -> 0.7907374841045375 on epoch=71, global_step=1000
06/18/2022 00:22:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/18/2022 00:22:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/18/2022 00:22:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/18/2022 00:22:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/18/2022 00:22:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
06/18/2022 00:22:23 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7789685453750004 on epoch=74
06/18/2022 00:22:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/18/2022 00:22:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/18/2022 00:22:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=77
06/18/2022 00:22:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/18/2022 00:22:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/18/2022 00:22:42 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7826702572137813 on epoch=78
06/18/2022 00:22:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
06/18/2022 00:22:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/18/2022 00:22:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/18/2022 00:22:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/18/2022 00:22:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/18/2022 00:23:02 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7826702572137813 on epoch=82
06/18/2022 00:23:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/18/2022 00:23:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/18/2022 00:23:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/18/2022 00:23:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/18/2022 00:23:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/18/2022 00:23:21 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.8449204816229758 on epoch=85
06/18/2022 00:23:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7907374841045375 -> 0.8449204816229758 on epoch=85, global_step=1200
06/18/2022 00:23:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/18/2022 00:23:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
06/18/2022 00:23:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/18/2022 00:23:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/18/2022 00:23:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/18/2022 00:23:40 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7883776952883919 on epoch=89
06/18/2022 00:23:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/18/2022 00:23:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/18/2022 00:23:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/18/2022 00:23:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/18/2022 00:23:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/18/2022 00:24:00 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.8432831404695056 on epoch=92
06/18/2022 00:24:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/18/2022 00:24:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/18/2022 00:24:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/18/2022 00:24:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/18/2022 00:24:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/18/2022 00:24:19 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8472092462857325 on epoch=96
06/18/2022 00:24:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8449204816229758 -> 0.8472092462857325 on epoch=96, global_step=1350
06/18/2022 00:24:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/18/2022 00:24:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/18/2022 00:24:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/18/2022 00:24:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/18/2022 00:24:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/18/2022 00:24:38 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.851290628054741 on epoch=99
06/18/2022 00:24:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8472092462857325 -> 0.851290628054741 on epoch=99, global_step=1400
06/18/2022 00:24:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/18/2022 00:24:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/18/2022 00:24:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/18/2022 00:24:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
06/18/2022 00:24:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/18/2022 00:24:58 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7897914150997642 on epoch=103
06/18/2022 00:25:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/18/2022 00:25:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/18/2022 00:25:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/18/2022 00:25:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/18/2022 00:25:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/18/2022 00:25:17 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8472583699902249 on epoch=107
06/18/2022 00:25:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/18/2022 00:25:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/18/2022 00:25:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/18/2022 00:25:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/18/2022 00:25:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/18/2022 00:25:37 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8433437194525905 on epoch=110
06/18/2022 00:25:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/18/2022 00:25:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/18/2022 00:25:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/18/2022 00:25:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/18/2022 00:25:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/18/2022 00:25:56 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7916693084471776 on epoch=114
06/18/2022 00:25:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/18/2022 00:26:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/18/2022 00:26:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/18/2022 00:26:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/18/2022 00:26:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/18/2022 00:26:16 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.787885742234769 on epoch=117
06/18/2022 00:26:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/18/2022 00:26:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/18/2022 00:26:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/18/2022 00:26:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/18/2022 00:26:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/18/2022 00:26:35 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7438753634845698 on epoch=121
06/18/2022 00:26:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/18/2022 00:26:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/18/2022 00:26:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/18/2022 00:26:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/18/2022 00:26:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/18/2022 00:26:55 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8393076429618769 on epoch=124
06/18/2022 00:26:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/18/2022 00:27:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/18/2022 00:27:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/18/2022 00:27:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/18/2022 00:27:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/18/2022 00:27:15 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8933601192187529 on epoch=128
06/18/2022 00:27:15 - INFO - __main__ - Saving model with best Classification-F1: 0.851290628054741 -> 0.8933601192187529 on epoch=128, global_step=1800
06/18/2022 00:27:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/18/2022 00:27:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/18/2022 00:27:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/18/2022 00:27:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/18/2022 00:27:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 00:27:35 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9015876507005537 on epoch=132
06/18/2022 00:27:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8933601192187529 -> 0.9015876507005537 on epoch=132, global_step=1850
06/18/2022 00:27:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/18/2022 00:27:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/18/2022 00:27:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/18/2022 00:27:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/18/2022 00:27:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/18/2022 00:27:55 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.847246151026393 on epoch=135
06/18/2022 00:27:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/18/2022 00:28:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/18/2022 00:28:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/18/2022 00:28:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/18/2022 00:28:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/18/2022 00:28:14 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9101938742261323 on epoch=139
06/18/2022 00:28:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9015876507005537 -> 0.9101938742261323 on epoch=139, global_step=1950
06/18/2022 00:28:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/18/2022 00:28:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/18/2022 00:28:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/18/2022 00:28:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/18/2022 00:28:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/18/2022 00:28:34 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9017049527533397 on epoch=142
06/18/2022 00:28:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/18/2022 00:28:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/18/2022 00:28:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/18/2022 00:28:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/18/2022 00:28:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/18/2022 00:28:54 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9058797653958943 on epoch=146
06/18/2022 00:28:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
06/18/2022 00:28:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/18/2022 00:29:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 00:29:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/18/2022 00:29:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/18/2022 00:29:13 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.9015393250703726 on epoch=149
06/18/2022 00:29:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/18/2022 00:29:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/18/2022 00:29:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/18/2022 00:29:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/18/2022 00:29:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/18/2022 00:29:33 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8431685876835818 on epoch=153
06/18/2022 00:29:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/18/2022 00:29:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/18/2022 00:29:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/18/2022 00:29:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/18/2022 00:29:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/18/2022 00:29:53 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8432261119257087 on epoch=157
06/18/2022 00:29:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/18/2022 00:29:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/18/2022 00:30:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/18/2022 00:30:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/18/2022 00:30:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/18/2022 00:30:12 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9058797653958943 on epoch=160
06/18/2022 00:30:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/18/2022 00:30:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/18/2022 00:30:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/18/2022 00:30:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/18/2022 00:30:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/18/2022 00:30:32 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.847246151026393 on epoch=164
06/18/2022 00:30:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/18/2022 00:30:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/18/2022 00:30:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/18/2022 00:30:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/18/2022 00:30:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/18/2022 00:30:52 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.901526291508952 on epoch=167
06/18/2022 00:30:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/18/2022 00:30:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/18/2022 00:31:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/18/2022 00:31:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/18/2022 00:31:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/18/2022 00:31:11 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.847246151026393 on epoch=171
06/18/2022 00:31:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/18/2022 00:31:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/18/2022 00:31:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 00:31:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/18/2022 00:31:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/18/2022 00:31:31 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8472583699902249 on epoch=174
06/18/2022 00:31:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/18/2022 00:31:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/18/2022 00:31:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/18/2022 00:31:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/18/2022 00:31:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/18/2022 00:31:50 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8433200452101662 on epoch=178
06/18/2022 00:31:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 00:31:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/18/2022 00:31:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/18/2022 00:32:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/18/2022 00:32:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/18/2022 00:32:09 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8472193321976884 on epoch=182
06/18/2022 00:32:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/18/2022 00:32:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/18/2022 00:32:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 00:32:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 00:32:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/18/2022 00:32:28 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7880382225817466 on epoch=185
06/18/2022 00:32:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/18/2022 00:32:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/18/2022 00:32:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/18/2022 00:32:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/18/2022 00:32:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/18/2022 00:32:47 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8512638092260365 on epoch=189
06/18/2022 00:32:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/18/2022 00:32:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/18/2022 00:32:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/18/2022 00:32:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 00:33:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/18/2022 00:33:07 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8393869763814618 on epoch=192
06/18/2022 00:33:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/18/2022 00:33:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 00:33:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 00:33:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/18/2022 00:33:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/18/2022 00:33:26 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8393335593540683 on epoch=196
06/18/2022 00:33:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/18/2022 00:33:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/18/2022 00:33:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/18/2022 00:33:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/18/2022 00:33:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/18/2022 00:33:46 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8393869763814618 on epoch=199
06/18/2022 00:33:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/18/2022 00:33:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/18/2022 00:33:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 00:33:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 00:33:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/18/2022 00:34:06 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8473645222385142 on epoch=203
06/18/2022 00:34:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/18/2022 00:34:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/18/2022 00:34:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/18/2022 00:34:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/18/2022 00:34:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 00:34:25 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8434314534098097 on epoch=207
06/18/2022 00:34:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/18/2022 00:34:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/18/2022 00:34:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/18/2022 00:34:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 00:34:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/18/2022 00:34:44 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7991906733367834 on epoch=210
06/18/2022 00:34:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/18/2022 00:34:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/18/2022 00:34:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/18/2022 00:34:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/18/2022 00:34:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/18/2022 00:34:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:34:59 - INFO - __main__ - Printing 3 examples
06/18/2022 00:34:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/18/2022 00:34:59 - INFO - __main__ - ['Animal']
06/18/2022 00:34:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/18/2022 00:34:59 - INFO - __main__ - ['Animal']
06/18/2022 00:34:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/18/2022 00:34:59 - INFO - __main__ - ['Animal']
06/18/2022 00:34:59 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:34:59 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:34:59 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 00:34:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:34:59 - INFO - __main__ - Printing 3 examples
06/18/2022 00:34:59 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/18/2022 00:34:59 - INFO - __main__ - ['Animal']
06/18/2022 00:34:59 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/18/2022 00:34:59 - INFO - __main__ - ['Animal']
06/18/2022 00:34:59 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/18/2022 00:34:59 - INFO - __main__ - ['Animal']
06/18/2022 00:34:59 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:34:59 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:35:00 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 00:35:04 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7953493728483048 on epoch=214
06/18/2022 00:35:04 - INFO - __main__ - save last model!
06/18/2022 00:35:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 00:35:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 00:35:04 - INFO - __main__ - Printing 3 examples
06/18/2022 00:35:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 00:35:04 - INFO - __main__ - ['Animal']
06/18/2022 00:35:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 00:35:04 - INFO - __main__ - ['Animal']
06/18/2022 00:35:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 00:35:04 - INFO - __main__ - ['Village']
06/18/2022 00:35:04 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:35:06 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:35:09 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 00:35:18 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 00:35:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 00:35:19 - INFO - __main__ - Starting training!
06/18/2022 00:37:28 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/18/2022 00:37:28 - INFO - __main__ - Classification-F1 on test data: 0.5946
06/18/2022 00:37:28 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9101938742261323, test_performance=0.5945963422921524
06/18/2022 00:37:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/18/2022 00:37:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:37:29 - INFO - __main__ - Printing 3 examples
06/18/2022 00:37:29 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/18/2022 00:37:29 - INFO - __main__ - ['Animal']
06/18/2022 00:37:29 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/18/2022 00:37:29 - INFO - __main__ - ['Animal']
06/18/2022 00:37:29 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/18/2022 00:37:29 - INFO - __main__ - ['Animal']
06/18/2022 00:37:29 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:37:29 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:37:29 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 00:37:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:37:29 - INFO - __main__ - Printing 3 examples
06/18/2022 00:37:29 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/18/2022 00:37:29 - INFO - __main__ - ['Animal']
06/18/2022 00:37:29 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/18/2022 00:37:29 - INFO - __main__ - ['Animal']
06/18/2022 00:37:29 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/18/2022 00:37:29 - INFO - __main__ - ['Animal']
06/18/2022 00:37:29 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:37:29 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:37:30 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 00:37:45 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 00:37:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 00:37:46 - INFO - __main__ - Starting training!
06/18/2022 00:37:49 - INFO - __main__ - Step 10 Global step 10 Train loss 6.87 on epoch=0
06/18/2022 00:37:52 - INFO - __main__ - Step 20 Global step 20 Train loss 5.50 on epoch=1
06/18/2022 00:37:54 - INFO - __main__ - Step 30 Global step 30 Train loss 4.96 on epoch=2
06/18/2022 00:37:57 - INFO - __main__ - Step 40 Global step 40 Train loss 4.32 on epoch=2
06/18/2022 00:38:00 - INFO - __main__ - Step 50 Global step 50 Train loss 4.23 on epoch=3
06/18/2022 00:38:07 - INFO - __main__ - Global step 50 Train loss 5.18 Classification-F1 0.01925277471343448 on epoch=3
06/18/2022 00:38:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01925277471343448 on epoch=3, global_step=50
06/18/2022 00:38:10 - INFO - __main__ - Step 60 Global step 60 Train loss 4.12 on epoch=4
06/18/2022 00:38:12 - INFO - __main__ - Step 70 Global step 70 Train loss 3.74 on epoch=4
06/18/2022 00:38:15 - INFO - __main__ - Step 80 Global step 80 Train loss 3.46 on epoch=5
06/18/2022 00:38:17 - INFO - __main__ - Step 90 Global step 90 Train loss 3.25 on epoch=6
06/18/2022 00:38:20 - INFO - __main__ - Step 100 Global step 100 Train loss 3.29 on epoch=7
06/18/2022 00:38:25 - INFO - __main__ - Global step 100 Train loss 3.57 Classification-F1 0.08264550264550265 on epoch=7
06/18/2022 00:38:25 - INFO - __main__ - Saving model with best Classification-F1: 0.01925277471343448 -> 0.08264550264550265 on epoch=7, global_step=100
06/18/2022 00:38:27 - INFO - __main__ - Step 110 Global step 110 Train loss 3.00 on epoch=7
06/18/2022 00:38:30 - INFO - __main__ - Step 120 Global step 120 Train loss 2.82 on epoch=8
06/18/2022 00:38:33 - INFO - __main__ - Step 130 Global step 130 Train loss 2.74 on epoch=9
06/18/2022 00:38:35 - INFO - __main__ - Step 140 Global step 140 Train loss 2.48 on epoch=9
06/18/2022 00:38:38 - INFO - __main__ - Step 150 Global step 150 Train loss 2.40 on epoch=10
06/18/2022 00:38:43 - INFO - __main__ - Global step 150 Train loss 2.69 Classification-F1 0.09987331892366472 on epoch=10
06/18/2022 00:38:43 - INFO - __main__ - Saving model with best Classification-F1: 0.08264550264550265 -> 0.09987331892366472 on epoch=10, global_step=150
06/18/2022 00:38:46 - INFO - __main__ - Step 160 Global step 160 Train loss 2.28 on epoch=11
06/18/2022 00:38:48 - INFO - __main__ - Step 170 Global step 170 Train loss 2.30 on epoch=12
06/18/2022 00:38:51 - INFO - __main__ - Step 180 Global step 180 Train loss 2.08 on epoch=12
06/18/2022 00:38:53 - INFO - __main__ - Step 190 Global step 190 Train loss 2.01 on epoch=13
06/18/2022 00:38:56 - INFO - __main__ - Step 200 Global step 200 Train loss 1.96 on epoch=14
06/18/2022 00:39:01 - INFO - __main__ - Global step 200 Train loss 2.13 Classification-F1 0.10846438507728831 on epoch=14
06/18/2022 00:39:01 - INFO - __main__ - Saving model with best Classification-F1: 0.09987331892366472 -> 0.10846438507728831 on epoch=14, global_step=200
06/18/2022 00:39:04 - INFO - __main__ - Step 210 Global step 210 Train loss 1.94 on epoch=14
06/18/2022 00:39:06 - INFO - __main__ - Step 220 Global step 220 Train loss 1.79 on epoch=15
06/18/2022 00:39:09 - INFO - __main__ - Step 230 Global step 230 Train loss 1.59 on epoch=16
06/18/2022 00:39:12 - INFO - __main__ - Step 240 Global step 240 Train loss 1.76 on epoch=17
06/18/2022 00:39:14 - INFO - __main__ - Step 250 Global step 250 Train loss 1.60 on epoch=17
06/18/2022 00:39:20 - INFO - __main__ - Global step 250 Train loss 1.74 Classification-F1 0.12109067411083539 on epoch=17
06/18/2022 00:39:20 - INFO - __main__ - Saving model with best Classification-F1: 0.10846438507728831 -> 0.12109067411083539 on epoch=17, global_step=250
06/18/2022 00:39:23 - INFO - __main__ - Step 260 Global step 260 Train loss 1.51 on epoch=18
06/18/2022 00:39:25 - INFO - __main__ - Step 270 Global step 270 Train loss 1.49 on epoch=19
06/18/2022 00:39:28 - INFO - __main__ - Step 280 Global step 280 Train loss 1.29 on epoch=19
06/18/2022 00:39:30 - INFO - __main__ - Step 290 Global step 290 Train loss 1.33 on epoch=20
06/18/2022 00:39:33 - INFO - __main__ - Step 300 Global step 300 Train loss 1.22 on epoch=21
06/18/2022 00:39:39 - INFO - __main__ - Global step 300 Train loss 1.37 Classification-F1 0.1951379010850813 on epoch=21
06/18/2022 00:39:39 - INFO - __main__ - Saving model with best Classification-F1: 0.12109067411083539 -> 0.1951379010850813 on epoch=21, global_step=300
06/18/2022 00:39:41 - INFO - __main__ - Step 310 Global step 310 Train loss 1.29 on epoch=22
06/18/2022 00:39:44 - INFO - __main__ - Step 320 Global step 320 Train loss 1.23 on epoch=22
06/18/2022 00:39:46 - INFO - __main__ - Step 330 Global step 330 Train loss 1.20 on epoch=23
06/18/2022 00:39:49 - INFO - __main__ - Step 340 Global step 340 Train loss 1.05 on epoch=24
06/18/2022 00:39:52 - INFO - __main__ - Step 350 Global step 350 Train loss 1.00 on epoch=24
06/18/2022 00:39:58 - INFO - __main__ - Global step 350 Train loss 1.15 Classification-F1 0.3141213358018795 on epoch=24
06/18/2022 00:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1951379010850813 -> 0.3141213358018795 on epoch=24, global_step=350
06/18/2022 00:40:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.99 on epoch=25
06/18/2022 00:40:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.94 on epoch=26
06/18/2022 00:40:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.86 on epoch=27
06/18/2022 00:40:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.90 on epoch=27
06/18/2022 00:40:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.83 on epoch=28
06/18/2022 00:40:17 - INFO - __main__ - Global step 400 Train loss 0.90 Classification-F1 0.3719990152508375 on epoch=28
06/18/2022 00:40:18 - INFO - __main__ - Saving model with best Classification-F1: 0.3141213358018795 -> 0.3719990152508375 on epoch=28, global_step=400
06/18/2022 00:40:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.75 on epoch=29
06/18/2022 00:40:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.79 on epoch=29
06/18/2022 00:40:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.73 on epoch=30
06/18/2022 00:40:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.65 on epoch=31
06/18/2022 00:40:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.72 on epoch=32
06/18/2022 00:40:37 - INFO - __main__ - Global step 450 Train loss 0.73 Classification-F1 0.4606336356584217 on epoch=32
06/18/2022 00:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3719990152508375 -> 0.4606336356584217 on epoch=32, global_step=450
06/18/2022 00:40:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.66 on epoch=32
06/18/2022 00:40:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=33
06/18/2022 00:40:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.58 on epoch=34
06/18/2022 00:40:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.62 on epoch=34
06/18/2022 00:40:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.59 on epoch=35
06/18/2022 00:40:57 - INFO - __main__ - Global step 500 Train loss 0.61 Classification-F1 0.4286579828722488 on epoch=35
06/18/2022 00:40:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.55 on epoch=36
06/18/2022 00:41:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.51 on epoch=37
06/18/2022 00:41:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.53 on epoch=37
06/18/2022 00:41:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=38
06/18/2022 00:41:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=39
06/18/2022 00:41:16 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.4721622693483343 on epoch=39
06/18/2022 00:41:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4606336356584217 -> 0.4721622693483343 on epoch=39, global_step=550
06/18/2022 00:41:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=39
06/18/2022 00:41:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=40
06/18/2022 00:41:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=41
06/18/2022 00:41:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.50 on epoch=42
06/18/2022 00:41:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
06/18/2022 00:41:36 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.5554332853518148 on epoch=42
06/18/2022 00:41:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4721622693483343 -> 0.5554332853518148 on epoch=42, global_step=600
06/18/2022 00:41:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=43
06/18/2022 00:41:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=44
06/18/2022 00:41:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.39 on epoch=44
06/18/2022 00:41:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=45
06/18/2022 00:41:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=46
06/18/2022 00:41:55 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.5102248934900343 on epoch=46
06/18/2022 00:41:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=47
06/18/2022 00:42:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=47
06/18/2022 00:42:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/18/2022 00:42:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/18/2022 00:42:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=49
06/18/2022 00:42:15 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.5558820117104575 on epoch=49
06/18/2022 00:42:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5554332853518148 -> 0.5558820117104575 on epoch=49, global_step=700
06/18/2022 00:42:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/18/2022 00:42:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/18/2022 00:42:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.33 on epoch=52
06/18/2022 00:42:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=52
06/18/2022 00:42:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=53
06/18/2022 00:42:34 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.6248982431845335 on epoch=53
06/18/2022 00:42:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5558820117104575 -> 0.6248982431845335 on epoch=53, global_step=750
06/18/2022 00:42:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
06/18/2022 00:42:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=54
06/18/2022 00:42:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/18/2022 00:42:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
06/18/2022 00:42:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
06/18/2022 00:42:53 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.5720102417133208 on epoch=57
06/18/2022 00:42:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=57
06/18/2022 00:42:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
06/18/2022 00:43:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
06/18/2022 00:43:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=59
06/18/2022 00:43:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
06/18/2022 00:43:13 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.6308241691104595 on epoch=60
06/18/2022 00:43:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6248982431845335 -> 0.6308241691104595 on epoch=60, global_step=850
06/18/2022 00:43:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
06/18/2022 00:43:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=62
06/18/2022 00:43:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
06/18/2022 00:43:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=63
06/18/2022 00:43:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=64
06/18/2022 00:43:32 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.6273833088954056 on epoch=64
06/18/2022 00:43:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=64
06/18/2022 00:43:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=65
06/18/2022 00:43:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=66
06/18/2022 00:43:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
06/18/2022 00:43:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/18/2022 00:43:52 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.7571017688887988 on epoch=67
06/18/2022 00:43:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6308241691104595 -> 0.7571017688887988 on epoch=67, global_step=950
06/18/2022 00:43:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=68
06/18/2022 00:43:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
06/18/2022 00:43:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
06/18/2022 00:44:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/18/2022 00:44:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
06/18/2022 00:44:11 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.6717709206349405 on epoch=71
06/18/2022 00:44:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=72
06/18/2022 00:44:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=72
06/18/2022 00:44:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
06/18/2022 00:44:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
06/18/2022 00:44:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/18/2022 00:44:31 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.6723905065873438 on epoch=74
06/18/2022 00:44:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=75
06/18/2022 00:44:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=76
06/18/2022 00:44:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
06/18/2022 00:44:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
06/18/2022 00:44:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
06/18/2022 00:44:50 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.7294916065604904 on epoch=78
06/18/2022 00:44:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/18/2022 00:44:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
06/18/2022 00:44:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/18/2022 00:45:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=81
06/18/2022 00:45:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/18/2022 00:45:09 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7620641966077206 on epoch=82
06/18/2022 00:45:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7571017688887988 -> 0.7620641966077206 on epoch=82, global_step=1150
06/18/2022 00:45:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=82
06/18/2022 00:45:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
06/18/2022 00:45:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/18/2022 00:45:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=84
06/18/2022 00:45:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
06/18/2022 00:45:29 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.7331195014662756 on epoch=85
06/18/2022 00:45:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/18/2022 00:45:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=87
06/18/2022 00:45:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=87
06/18/2022 00:45:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/18/2022 00:45:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/18/2022 00:45:48 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7762441780231154 on epoch=89
06/18/2022 00:45:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7620641966077206 -> 0.7762441780231154 on epoch=89, global_step=1250
06/18/2022 00:45:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=89
06/18/2022 00:45:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
06/18/2022 00:45:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
06/18/2022 00:45:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
06/18/2022 00:46:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/18/2022 00:46:07 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7721698210075819 on epoch=92
06/18/2022 00:46:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/18/2022 00:46:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/18/2022 00:46:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/18/2022 00:46:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
06/18/2022 00:46:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=96
06/18/2022 00:46:26 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.8170775293255133 on epoch=96
06/18/2022 00:46:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7762441780231154 -> 0.8170775293255133 on epoch=96, global_step=1350
06/18/2022 00:46:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/18/2022 00:46:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=97
06/18/2022 00:46:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/18/2022 00:46:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
06/18/2022 00:46:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/18/2022 00:46:45 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7903181243171755 on epoch=99
06/18/2022 00:46:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=100
06/18/2022 00:46:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/18/2022 00:46:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/18/2022 00:46:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=102
06/18/2022 00:46:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/18/2022 00:47:05 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.8287120083195206 on epoch=103
06/18/2022 00:47:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8170775293255133 -> 0.8287120083195206 on epoch=103, global_step=1450
06/18/2022 00:47:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
06/18/2022 00:47:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/18/2022 00:47:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/18/2022 00:47:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=106
06/18/2022 00:47:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
06/18/2022 00:47:24 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.8378386519767569 on epoch=107
06/18/2022 00:47:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8287120083195206 -> 0.8378386519767569 on epoch=107, global_step=1500
06/18/2022 00:47:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/18/2022 00:47:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/18/2022 00:47:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/18/2022 00:47:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/18/2022 00:47:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
06/18/2022 00:47:43 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.8339125461605301 on epoch=110
06/18/2022 00:47:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/18/2022 00:47:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/18/2022 00:47:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/18/2022 00:47:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/18/2022 00:47:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/18/2022 00:48:02 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.8402968038894191 on epoch=114
06/18/2022 00:48:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8378386519767569 -> 0.8402968038894191 on epoch=114, global_step=1600
06/18/2022 00:48:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/18/2022 00:48:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/18/2022 00:48:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/18/2022 00:48:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/18/2022 00:48:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/18/2022 00:48:21 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.851290628054741 on epoch=117
06/18/2022 00:48:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8402968038894191 -> 0.851290628054741 on epoch=117, global_step=1650
06/18/2022 00:48:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/18/2022 00:48:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
06/18/2022 00:48:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/18/2022 00:48:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
06/18/2022 00:48:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/18/2022 00:48:40 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8427598580766111 on epoch=121
06/18/2022 00:48:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/18/2022 00:48:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/18/2022 00:48:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/18/2022 00:48:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=124
06/18/2022 00:48:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/18/2022 00:48:59 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8375130742155684 on epoch=124
06/18/2022 00:49:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/18/2022 00:49:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/18/2022 00:49:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.14 on epoch=127
06/18/2022 00:49:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
06/18/2022 00:49:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
06/18/2022 00:49:18 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.8402968038894191 on epoch=128
06/18/2022 00:49:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
06/18/2022 00:49:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/18/2022 00:49:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/18/2022 00:49:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/18/2022 00:49:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/18/2022 00:49:37 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.8511154962857325 on epoch=132
06/18/2022 00:49:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/18/2022 00:49:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/18/2022 00:49:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=134
06/18/2022 00:49:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=134
06/18/2022 00:49:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=135
06/18/2022 00:49:56 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.8470710192573845 on epoch=135
06/18/2022 00:49:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/18/2022 00:50:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/18/2022 00:50:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/18/2022 00:50:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/18/2022 00:50:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/18/2022 00:50:15 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8442030538894191 on epoch=139
06/18/2022 00:50:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/18/2022 00:50:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/18/2022 00:50:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/18/2022 00:50:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
06/18/2022 00:50:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/18/2022 00:50:34 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8427598580766111 on epoch=142
06/18/2022 00:50:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/18/2022 00:50:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/18/2022 00:50:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/18/2022 00:50:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=145
06/18/2022 00:50:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/18/2022 00:50:54 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.8427598580766111 on epoch=146
06/18/2022 00:50:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/18/2022 00:50:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/18/2022 00:51:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/18/2022 00:51:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/18/2022 00:51:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
06/18/2022 00:51:13 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.8402968038894191 on epoch=149
06/18/2022 00:51:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/18/2022 00:51:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=151
06/18/2022 00:51:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/18/2022 00:51:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/18/2022 00:51:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=153
06/18/2022 00:51:32 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7908675801312179 on epoch=153
06/18/2022 00:51:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/18/2022 00:51:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=154
06/18/2022 00:51:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/18/2022 00:51:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/18/2022 00:51:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/18/2022 00:51:51 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7893791821630713 on epoch=157
06/18/2022 00:51:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/18/2022 00:51:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/18/2022 00:51:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/18/2022 00:52:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/18/2022 00:52:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/18/2022 00:52:10 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8450587086513238 on epoch=160
06/18/2022 00:52:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/18/2022 00:52:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
06/18/2022 00:52:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/18/2022 00:52:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/18/2022 00:52:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/18/2022 00:52:29 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7953493728483049 on epoch=164
06/18/2022 00:52:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/18/2022 00:52:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/18/2022 00:52:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/18/2022 00:52:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/18/2022 00:52:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
06/18/2022 00:52:48 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8427598580766111 on epoch=167
06/18/2022 00:52:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
06/18/2022 00:52:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/18/2022 00:52:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/18/2022 00:52:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/18/2022 00:53:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/18/2022 00:53:07 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8511154962857325 on epoch=171
06/18/2022 00:53:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/18/2022 00:53:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/18/2022 00:53:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 00:53:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/18/2022 00:53:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/18/2022 00:53:26 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9058404003391897 on epoch=174
06/18/2022 00:53:26 - INFO - __main__ - Saving model with best Classification-F1: 0.851290628054741 -> 0.9058404003391897 on epoch=174, global_step=2450
06/18/2022 00:53:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/18/2022 00:53:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
06/18/2022 00:53:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/18/2022 00:53:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/18/2022 00:53:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
06/18/2022 00:53:46 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.8470710192573845 on epoch=178
06/18/2022 00:53:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
06/18/2022 00:53:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
06/18/2022 00:53:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/18/2022 00:53:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/18/2022 00:53:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/18/2022 00:54:05 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.8427598580766111 on epoch=182
06/18/2022 00:54:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/18/2022 00:54:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/18/2022 00:54:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/18/2022 00:54:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/18/2022 00:54:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/18/2022 00:54:23 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7954758750620935 on epoch=185
06/18/2022 00:54:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/18/2022 00:54:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/18/2022 00:54:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/18/2022 00:54:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=188
06/18/2022 00:54:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/18/2022 00:54:42 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7954758750620935 on epoch=189
06/18/2022 00:54:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/18/2022 00:54:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/18/2022 00:54:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/18/2022 00:54:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/18/2022 00:54:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/18/2022 00:55:01 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7934518396414736 on epoch=192
06/18/2022 00:55:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/18/2022 00:55:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 00:55:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 00:55:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/18/2022 00:55:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/18/2022 00:55:20 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9100070670058564 on epoch=196
06/18/2022 00:55:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9058404003391897 -> 0.9100070670058564 on epoch=196, global_step=2750
06/18/2022 00:55:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/18/2022 00:55:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/18/2022 00:55:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
06/18/2022 00:55:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/18/2022 00:55:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
06/18/2022 00:55:39 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.9100070670058564 on epoch=199
06/18/2022 00:55:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/18/2022 00:55:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/18/2022 00:55:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/18/2022 00:55:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 00:55:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/18/2022 00:55:58 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9100070670058567 on epoch=203
06/18/2022 00:55:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9100070670058564 -> 0.9100070670058567 on epoch=203, global_step=2850
06/18/2022 00:56:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/18/2022 00:56:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 00:56:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/18/2022 00:56:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/18/2022 00:56:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/18/2022 00:56:17 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8471893904695056 on epoch=207
06/18/2022 00:56:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/18/2022 00:56:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/18/2022 00:56:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/18/2022 00:56:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/18/2022 00:56:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/18/2022 00:56:36 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8471893904695056 on epoch=210
06/18/2022 00:56:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
06/18/2022 00:56:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/18/2022 00:56:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/18/2022 00:56:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=213
06/18/2022 00:56:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/18/2022 00:56:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:56:51 - INFO - __main__ - Printing 3 examples
06/18/2022 00:56:51 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 00:56:51 - INFO - __main__ - ['Plant']
06/18/2022 00:56:51 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 00:56:51 - INFO - __main__ - ['Plant']
06/18/2022 00:56:51 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 00:56:51 - INFO - __main__ - ['Plant']
06/18/2022 00:56:51 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:56:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:56:51 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 00:56:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:56:51 - INFO - __main__ - Printing 3 examples
06/18/2022 00:56:51 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 00:56:51 - INFO - __main__ - ['Plant']
06/18/2022 00:56:51 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 00:56:51 - INFO - __main__ - ['Plant']
06/18/2022 00:56:51 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 00:56:51 - INFO - __main__ - ['Plant']
06/18/2022 00:56:51 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:56:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:56:52 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 00:56:56 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.8432831404695057 on epoch=214
06/18/2022 00:56:56 - INFO - __main__ - save last model!
06/18/2022 00:56:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 00:56:56 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 00:56:56 - INFO - __main__ - Printing 3 examples
06/18/2022 00:56:56 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 00:56:56 - INFO - __main__ - ['Animal']
06/18/2022 00:56:56 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 00:56:56 - INFO - __main__ - ['Animal']
06/18/2022 00:56:56 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 00:56:56 - INFO - __main__ - ['Village']
06/18/2022 00:56:56 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:56:57 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:57:01 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 00:57:07 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 00:57:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 00:57:08 - INFO - __main__ - Starting training!
06/18/2022 00:59:04 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/18/2022 00:59:04 - INFO - __main__ - Classification-F1 on test data: 0.6538
06/18/2022 00:59:05 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9100070670058567, test_performance=0.6538348790807644
06/18/2022 00:59:05 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/18/2022 00:59:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:59:06 - INFO - __main__ - Printing 3 examples
06/18/2022 00:59:06 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 00:59:06 - INFO - __main__ - ['Plant']
06/18/2022 00:59:06 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 00:59:06 - INFO - __main__ - ['Plant']
06/18/2022 00:59:06 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 00:59:06 - INFO - __main__ - ['Plant']
06/18/2022 00:59:06 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:59:06 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:59:06 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 00:59:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 00:59:06 - INFO - __main__ - Printing 3 examples
06/18/2022 00:59:06 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 00:59:06 - INFO - __main__ - ['Plant']
06/18/2022 00:59:06 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 00:59:06 - INFO - __main__ - ['Plant']
06/18/2022 00:59:06 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 00:59:06 - INFO - __main__ - ['Plant']
06/18/2022 00:59:06 - INFO - __main__ - Tokenizing Input ...
06/18/2022 00:59:06 - INFO - __main__ - Tokenizing Output ...
06/18/2022 00:59:06 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 00:59:21 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 00:59:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 00:59:22 - INFO - __main__ - Starting training!
06/18/2022 00:59:26 - INFO - __main__ - Step 10 Global step 10 Train loss 5.94 on epoch=0
06/18/2022 00:59:28 - INFO - __main__ - Step 20 Global step 20 Train loss 4.36 on epoch=1
06/18/2022 00:59:31 - INFO - __main__ - Step 30 Global step 30 Train loss 3.84 on epoch=2
06/18/2022 00:59:33 - INFO - __main__ - Step 40 Global step 40 Train loss 3.31 on epoch=2
06/18/2022 00:59:36 - INFO - __main__ - Step 50 Global step 50 Train loss 3.05 on epoch=3
06/18/2022 00:59:42 - INFO - __main__ - Global step 50 Train loss 4.10 Classification-F1 0.08273929772308103 on epoch=3
06/18/2022 00:59:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08273929772308103 on epoch=3, global_step=50
06/18/2022 00:59:44 - INFO - __main__ - Step 60 Global step 60 Train loss 2.61 on epoch=4
06/18/2022 00:59:47 - INFO - __main__ - Step 70 Global step 70 Train loss 2.33 on epoch=4
06/18/2022 00:59:50 - INFO - __main__ - Step 80 Global step 80 Train loss 1.96 on epoch=5
06/18/2022 00:59:52 - INFO - __main__ - Step 90 Global step 90 Train loss 1.83 on epoch=6
06/18/2022 00:59:55 - INFO - __main__ - Step 100 Global step 100 Train loss 1.70 on epoch=7
06/18/2022 01:00:00 - INFO - __main__ - Global step 100 Train loss 2.09 Classification-F1 0.12160545901312478 on epoch=7
06/18/2022 01:00:00 - INFO - __main__ - Saving model with best Classification-F1: 0.08273929772308103 -> 0.12160545901312478 on epoch=7, global_step=100
06/18/2022 01:00:03 - INFO - __main__ - Step 110 Global step 110 Train loss 1.34 on epoch=7
06/18/2022 01:00:05 - INFO - __main__ - Step 120 Global step 120 Train loss 1.50 on epoch=8
06/18/2022 01:00:08 - INFO - __main__ - Step 130 Global step 130 Train loss 1.26 on epoch=9
06/18/2022 01:00:11 - INFO - __main__ - Step 140 Global step 140 Train loss 1.20 on epoch=9
06/18/2022 01:00:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.99 on epoch=10
06/18/2022 01:00:19 - INFO - __main__ - Global step 150 Train loss 1.26 Classification-F1 0.2578836611731348 on epoch=10
06/18/2022 01:00:19 - INFO - __main__ - Saving model with best Classification-F1: 0.12160545901312478 -> 0.2578836611731348 on epoch=10, global_step=150
06/18/2022 01:00:22 - INFO - __main__ - Step 160 Global step 160 Train loss 1.00 on epoch=11
06/18/2022 01:00:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=12
06/18/2022 01:00:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=12
06/18/2022 01:00:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=13
06/18/2022 01:00:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
06/18/2022 01:00:39 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.46370690289990124 on epoch=14
06/18/2022 01:00:39 - INFO - __main__ - Saving model with best Classification-F1: 0.2578836611731348 -> 0.46370690289990124 on epoch=14, global_step=200
06/18/2022 01:00:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=14
06/18/2022 01:00:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=15
06/18/2022 01:00:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=16
06/18/2022 01:00:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=17
06/18/2022 01:00:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=17
06/18/2022 01:00:58 - INFO - __main__ - Global step 250 Train loss 0.47 Classification-F1 0.4373717572780958 on epoch=17
06/18/2022 01:01:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=18
06/18/2022 01:01:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=19
06/18/2022 01:01:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=19
06/18/2022 01:01:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=20
06/18/2022 01:01:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=21
06/18/2022 01:01:18 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.5171056568125616 on epoch=21
06/18/2022 01:01:18 - INFO - __main__ - Saving model with best Classification-F1: 0.46370690289990124 -> 0.5171056568125616 on epoch=21, global_step=300
06/18/2022 01:01:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
06/18/2022 01:01:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=22
06/18/2022 01:01:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=23
06/18/2022 01:01:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=24
06/18/2022 01:01:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=24
06/18/2022 01:01:38 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.5534638257031567 on epoch=24
06/18/2022 01:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5171056568125616 -> 0.5534638257031567 on epoch=24, global_step=350
06/18/2022 01:01:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
06/18/2022 01:01:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=26
06/18/2022 01:01:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=27
06/18/2022 01:01:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=27
06/18/2022 01:01:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=28
06/18/2022 01:01:58 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.523745983397741 on epoch=28
06/18/2022 01:02:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=29
06/18/2022 01:02:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=29
06/18/2022 01:02:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=30
06/18/2022 01:02:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=31
06/18/2022 01:02:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
06/18/2022 01:02:17 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.5764873158007539 on epoch=32
06/18/2022 01:02:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5534638257031567 -> 0.5764873158007539 on epoch=32, global_step=450
06/18/2022 01:02:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
06/18/2022 01:02:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=33
06/18/2022 01:02:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=34
06/18/2022 01:02:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=34
06/18/2022 01:02:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=35
06/18/2022 01:02:37 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.6051851127188103 on epoch=35
06/18/2022 01:02:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5764873158007539 -> 0.6051851127188103 on epoch=35, global_step=500
06/18/2022 01:02:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=36
06/18/2022 01:02:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=37
06/18/2022 01:02:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
06/18/2022 01:02:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
06/18/2022 01:02:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
06/18/2022 01:02:56 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.5447750023125405 on epoch=39
06/18/2022 01:02:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=39
06/18/2022 01:03:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=40
06/18/2022 01:03:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
06/18/2022 01:03:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=42
06/18/2022 01:03:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/18/2022 01:03:16 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.5510152990177327 on epoch=42
06/18/2022 01:03:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=43
06/18/2022 01:03:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
06/18/2022 01:03:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
06/18/2022 01:03:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=45
06/18/2022 01:03:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/18/2022 01:03:35 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.608098332197004 on epoch=46
06/18/2022 01:03:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6051851127188103 -> 0.608098332197004 on epoch=46, global_step=650
06/18/2022 01:03:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=47
06/18/2022 01:03:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
06/18/2022 01:03:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/18/2022 01:03:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
06/18/2022 01:03:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/18/2022 01:03:54 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.5280742074444637 on epoch=49
06/18/2022 01:03:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/18/2022 01:03:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
06/18/2022 01:04:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/18/2022 01:04:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
06/18/2022 01:04:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
06/18/2022 01:04:14 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.666285092006654 on epoch=53
06/18/2022 01:04:14 - INFO - __main__ - Saving model with best Classification-F1: 0.608098332197004 -> 0.666285092006654 on epoch=53, global_step=750
06/18/2022 01:04:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
06/18/2022 01:04:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/18/2022 01:04:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
06/18/2022 01:04:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/18/2022 01:04:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
06/18/2022 01:04:33 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6235601572007102 on epoch=57
06/18/2022 01:04:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/18/2022 01:04:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/18/2022 01:04:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/18/2022 01:04:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/18/2022 01:04:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/18/2022 01:04:52 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6438562898534934 on epoch=60
06/18/2022 01:04:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/18/2022 01:04:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
06/18/2022 01:05:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/18/2022 01:05:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
06/18/2022 01:05:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
06/18/2022 01:05:11 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7253624160645035 on epoch=64
06/18/2022 01:05:11 - INFO - __main__ - Saving model with best Classification-F1: 0.666285092006654 -> 0.7253624160645035 on epoch=64, global_step=900
06/18/2022 01:05:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/18/2022 01:05:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
06/18/2022 01:05:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/18/2022 01:05:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
06/18/2022 01:05:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/18/2022 01:05:31 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7447182353083155 on epoch=67
06/18/2022 01:05:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7253624160645035 -> 0.7447182353083155 on epoch=67, global_step=950
06/18/2022 01:05:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/18/2022 01:05:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/18/2022 01:05:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
06/18/2022 01:05:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
06/18/2022 01:05:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
06/18/2022 01:05:50 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7334986521986357 on epoch=71
06/18/2022 01:05:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
06/18/2022 01:05:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
06/18/2022 01:05:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=73
06/18/2022 01:06:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/18/2022 01:06:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
06/18/2022 01:06:09 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6901591567326113 on epoch=74
06/18/2022 01:06:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/18/2022 01:06:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/18/2022 01:06:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
06/18/2022 01:06:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/18/2022 01:06:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
06/18/2022 01:06:28 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6338719260920399 on epoch=78
06/18/2022 01:06:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/18/2022 01:06:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/18/2022 01:06:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/18/2022 01:06:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/18/2022 01:06:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/18/2022 01:06:47 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6901591567326113 on epoch=82
06/18/2022 01:06:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/18/2022 01:06:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/18/2022 01:06:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/18/2022 01:06:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/18/2022 01:07:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/18/2022 01:07:06 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6767580773383757 on epoch=85
06/18/2022 01:07:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/18/2022 01:07:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/18/2022 01:07:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/18/2022 01:07:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/18/2022 01:07:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/18/2022 01:07:25 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7706405576383302 on epoch=89
06/18/2022 01:07:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7447182353083155 -> 0.7706405576383302 on epoch=89, global_step=1250
06/18/2022 01:07:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/18/2022 01:07:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=90
06/18/2022 01:07:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/18/2022 01:07:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/18/2022 01:07:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/18/2022 01:07:45 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6845022682633789 on epoch=92
06/18/2022 01:07:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/18/2022 01:07:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/18/2022 01:07:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/18/2022 01:07:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/18/2022 01:07:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/18/2022 01:08:04 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.6820942875272247 on epoch=96
06/18/2022 01:08:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/18/2022 01:08:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=97
06/18/2022 01:08:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/18/2022 01:08:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/18/2022 01:08:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/18/2022 01:08:23 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7560245833713855 on epoch=99
06/18/2022 01:08:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/18/2022 01:08:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/18/2022 01:08:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
06/18/2022 01:08:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/18/2022 01:08:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/18/2022 01:08:42 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7095033022727021 on epoch=103
06/18/2022 01:08:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/18/2022 01:08:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/18/2022 01:08:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/18/2022 01:08:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/18/2022 01:08:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/18/2022 01:09:02 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7500030170281067 on epoch=107
06/18/2022 01:09:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/18/2022 01:09:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/18/2022 01:09:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/18/2022 01:09:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/18/2022 01:09:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/18/2022 01:09:21 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7394711903986096 on epoch=110
06/18/2022 01:09:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/18/2022 01:09:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/18/2022 01:09:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/18/2022 01:09:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/18/2022 01:09:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/18/2022 01:09:40 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7449660886040815 on epoch=114
06/18/2022 01:09:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/18/2022 01:09:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/18/2022 01:09:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/18/2022 01:09:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/18/2022 01:09:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/18/2022 01:09:59 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7949503848460205 on epoch=117
06/18/2022 01:09:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7706405576383302 -> 0.7949503848460205 on epoch=117, global_step=1650
06/18/2022 01:10:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/18/2022 01:10:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/18/2022 01:10:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/18/2022 01:10:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/18/2022 01:10:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/18/2022 01:10:18 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7865416943439044 on epoch=121
06/18/2022 01:10:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/18/2022 01:10:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/18/2022 01:10:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/18/2022 01:10:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/18/2022 01:10:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/18/2022 01:10:38 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8407851557045105 on epoch=124
06/18/2022 01:10:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7949503848460205 -> 0.8407851557045105 on epoch=124, global_step=1750
06/18/2022 01:10:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/18/2022 01:10:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/18/2022 01:10:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/18/2022 01:10:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
06/18/2022 01:10:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/18/2022 01:10:57 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7750560634811109 on epoch=128
06/18/2022 01:10:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/18/2022 01:11:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/18/2022 01:11:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/18/2022 01:11:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=131
06/18/2022 01:11:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 01:11:16 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7731334762644062 on epoch=132
06/18/2022 01:11:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/18/2022 01:11:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/18/2022 01:11:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/18/2022 01:11:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/18/2022 01:11:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/18/2022 01:11:35 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7944628879861607 on epoch=135
06/18/2022 01:11:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/18/2022 01:11:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/18/2022 01:11:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/18/2022 01:11:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/18/2022 01:11:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/18/2022 01:11:54 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8467623211307984 on epoch=139
06/18/2022 01:11:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8407851557045105 -> 0.8467623211307984 on epoch=139, global_step=1950
06/18/2022 01:11:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/18/2022 01:12:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/18/2022 01:12:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/18/2022 01:12:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/18/2022 01:12:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/18/2022 01:12:13 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7149119048075404 on epoch=142
06/18/2022 01:12:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/18/2022 01:12:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/18/2022 01:12:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/18/2022 01:12:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/18/2022 01:12:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/18/2022 01:12:32 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7343447121435737 on epoch=146
06/18/2022 01:12:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/18/2022 01:12:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/18/2022 01:12:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/18/2022 01:12:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/18/2022 01:12:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/18/2022 01:12:51 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7074396298280249 on epoch=149
06/18/2022 01:12:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/18/2022 01:12:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/18/2022 01:12:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/18/2022 01:13:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/18/2022 01:13:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.12 on epoch=153
06/18/2022 01:13:11 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7766354166776012 on epoch=153
06/18/2022 01:13:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/18/2022 01:13:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/18/2022 01:13:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/18/2022 01:13:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/18/2022 01:13:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/18/2022 01:13:30 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7905413193587097 on epoch=157
06/18/2022 01:13:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/18/2022 01:13:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/18/2022 01:13:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/18/2022 01:13:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/18/2022 01:13:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/18/2022 01:13:49 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6976913377290819 on epoch=160
06/18/2022 01:13:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/18/2022 01:13:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 01:13:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/18/2022 01:14:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/18/2022 01:14:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/18/2022 01:14:09 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6548363274928739 on epoch=164
06/18/2022 01:14:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/18/2022 01:14:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/18/2022 01:14:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/18/2022 01:14:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/18/2022 01:14:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/18/2022 01:14:28 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.73291621492265 on epoch=167
06/18/2022 01:14:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/18/2022 01:14:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/18/2022 01:14:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/18/2022 01:14:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/18/2022 01:14:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/18/2022 01:14:47 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6935650321249044 on epoch=171
06/18/2022 01:14:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/18/2022 01:14:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/18/2022 01:14:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 01:14:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/18/2022 01:15:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/18/2022 01:15:07 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7336982286078896 on epoch=174
06/18/2022 01:15:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/18/2022 01:15:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/18/2022 01:15:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/18/2022 01:15:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/18/2022 01:15:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/18/2022 01:15:26 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7223321130342004 on epoch=178
06/18/2022 01:15:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 01:15:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/18/2022 01:15:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/18/2022 01:15:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/18/2022 01:15:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/18/2022 01:15:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6215049069481166 on epoch=182
06/18/2022 01:15:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/18/2022 01:15:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/18/2022 01:15:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/18/2022 01:15:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 01:15:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/18/2022 01:16:05 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7342234044651337 on epoch=185
06/18/2022 01:16:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/18/2022 01:16:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/18/2022 01:16:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/18/2022 01:16:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/18/2022 01:16:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/18/2022 01:16:24 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.708864902962576 on epoch=189
06/18/2022 01:16:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/18/2022 01:16:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/18/2022 01:16:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/18/2022 01:16:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 01:16:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/18/2022 01:16:43 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6618223865792652 on epoch=192
06/18/2022 01:16:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/18/2022 01:16:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 01:16:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/18/2022 01:16:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/18/2022 01:16:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/18/2022 01:17:03 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7431576020944566 on epoch=196
06/18/2022 01:17:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/18/2022 01:17:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/18/2022 01:17:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/18/2022 01:17:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/18/2022 01:17:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/18/2022 01:17:23 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7008576956017784 on epoch=199
06/18/2022 01:17:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/18/2022 01:17:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/18/2022 01:17:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/18/2022 01:17:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/18/2022 01:17:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/18/2022 01:17:43 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6916136295543067 on epoch=203
06/18/2022 01:17:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/18/2022 01:17:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/18/2022 01:17:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/18/2022 01:17:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/18/2022 01:17:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 01:18:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6935377948061461 on epoch=207
06/18/2022 01:18:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/18/2022 01:18:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/18/2022 01:18:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/18/2022 01:18:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/18/2022 01:18:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/18/2022 01:18:22 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.5872034705051784 on epoch=210
06/18/2022 01:18:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 01:18:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/18/2022 01:18:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/18/2022 01:18:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/18/2022 01:18:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/18/2022 01:18:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:18:36 - INFO - __main__ - Printing 3 examples
06/18/2022 01:18:36 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 01:18:36 - INFO - __main__ - ['Plant']
06/18/2022 01:18:36 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 01:18:36 - INFO - __main__ - ['Plant']
06/18/2022 01:18:36 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 01:18:36 - INFO - __main__ - ['Plant']
06/18/2022 01:18:36 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:18:36 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:18:37 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 01:18:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:18:37 - INFO - __main__ - Printing 3 examples
06/18/2022 01:18:37 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 01:18:37 - INFO - __main__ - ['Plant']
06/18/2022 01:18:37 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 01:18:37 - INFO - __main__ - ['Plant']
06/18/2022 01:18:37 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 01:18:37 - INFO - __main__ - ['Plant']
06/18/2022 01:18:37 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:18:37 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:18:37 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 01:18:42 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.658438386320265 on epoch=214
06/18/2022 01:18:42 - INFO - __main__ - save last model!
06/18/2022 01:18:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 01:18:42 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 01:18:42 - INFO - __main__ - Printing 3 examples
06/18/2022 01:18:42 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 01:18:42 - INFO - __main__ - ['Animal']
06/18/2022 01:18:42 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 01:18:42 - INFO - __main__ - ['Animal']
06/18/2022 01:18:42 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 01:18:42 - INFO - __main__ - ['Village']
06/18/2022 01:18:42 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:18:44 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:18:47 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 01:18:52 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 01:18:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 01:18:53 - INFO - __main__ - Starting training!
06/18/2022 01:20:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/18/2022 01:20:50 - INFO - __main__ - Classification-F1 on test data: 0.4042
06/18/2022 01:20:50 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.8467623211307984, test_performance=0.40420556704913846
06/18/2022 01:20:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/18/2022 01:20:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:20:51 - INFO - __main__ - Printing 3 examples
06/18/2022 01:20:51 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 01:20:51 - INFO - __main__ - ['Plant']
06/18/2022 01:20:51 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 01:20:51 - INFO - __main__ - ['Plant']
06/18/2022 01:20:51 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 01:20:51 - INFO - __main__ - ['Plant']
06/18/2022 01:20:51 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:20:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:20:52 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 01:20:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:20:52 - INFO - __main__ - Printing 3 examples
06/18/2022 01:20:52 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 01:20:52 - INFO - __main__ - ['Plant']
06/18/2022 01:20:52 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 01:20:52 - INFO - __main__ - ['Plant']
06/18/2022 01:20:52 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 01:20:52 - INFO - __main__ - ['Plant']
06/18/2022 01:20:52 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:20:52 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:20:52 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 01:21:07 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 01:21:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 01:21:08 - INFO - __main__ - Starting training!
06/18/2022 01:21:11 - INFO - __main__ - Step 10 Global step 10 Train loss 6.25 on epoch=0
06/18/2022 01:21:14 - INFO - __main__ - Step 20 Global step 20 Train loss 4.62 on epoch=1
06/18/2022 01:21:17 - INFO - __main__ - Step 30 Global step 30 Train loss 4.12 on epoch=2
06/18/2022 01:21:19 - INFO - __main__ - Step 40 Global step 40 Train loss 3.52 on epoch=2
06/18/2022 01:21:22 - INFO - __main__ - Step 50 Global step 50 Train loss 3.34 on epoch=3
06/18/2022 01:21:27 - INFO - __main__ - Global step 50 Train loss 4.37 Classification-F1 0.063732264974501 on epoch=3
06/18/2022 01:21:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.063732264974501 on epoch=3, global_step=50
06/18/2022 01:21:30 - INFO - __main__ - Step 60 Global step 60 Train loss 2.80 on epoch=4
06/18/2022 01:21:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.63 on epoch=4
06/18/2022 01:21:35 - INFO - __main__ - Step 80 Global step 80 Train loss 2.25 on epoch=5
06/18/2022 01:21:38 - INFO - __main__ - Step 90 Global step 90 Train loss 2.08 on epoch=6
06/18/2022 01:21:41 - INFO - __main__ - Step 100 Global step 100 Train loss 1.99 on epoch=7
06/18/2022 01:21:46 - INFO - __main__ - Global step 100 Train loss 2.35 Classification-F1 0.12043522881416437 on epoch=7
06/18/2022 01:21:46 - INFO - __main__ - Saving model with best Classification-F1: 0.063732264974501 -> 0.12043522881416437 on epoch=7, global_step=100
06/18/2022 01:21:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.79 on epoch=7
06/18/2022 01:21:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.70 on epoch=8
06/18/2022 01:21:54 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=9
06/18/2022 01:21:57 - INFO - __main__ - Step 140 Global step 140 Train loss 1.38 on epoch=9
06/18/2022 01:21:59 - INFO - __main__ - Step 150 Global step 150 Train loss 1.19 on epoch=10
06/18/2022 01:22:05 - INFO - __main__ - Global step 150 Train loss 1.52 Classification-F1 0.16916957857910805 on epoch=10
06/18/2022 01:22:05 - INFO - __main__ - Saving model with best Classification-F1: 0.12043522881416437 -> 0.16916957857910805 on epoch=10, global_step=150
06/18/2022 01:22:08 - INFO - __main__ - Step 160 Global step 160 Train loss 1.27 on epoch=11
06/18/2022 01:22:10 - INFO - __main__ - Step 170 Global step 170 Train loss 1.05 on epoch=12
06/18/2022 01:22:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.97 on epoch=12
06/18/2022 01:22:15 - INFO - __main__ - Step 190 Global step 190 Train loss 1.08 on epoch=13
06/18/2022 01:22:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=14
06/18/2022 01:22:25 - INFO - __main__ - Global step 200 Train loss 1.03 Classification-F1 0.2915047257091171 on epoch=14
06/18/2022 01:22:25 - INFO - __main__ - Saving model with best Classification-F1: 0.16916957857910805 -> 0.2915047257091171 on epoch=14, global_step=200
06/18/2022 01:22:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=14
06/18/2022 01:22:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=15
06/18/2022 01:22:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.83 on epoch=16
06/18/2022 01:22:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=17
06/18/2022 01:22:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=17
06/18/2022 01:22:44 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.43650126395224437 on epoch=17
06/18/2022 01:22:44 - INFO - __main__ - Saving model with best Classification-F1: 0.2915047257091171 -> 0.43650126395224437 on epoch=17, global_step=250
06/18/2022 01:22:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=18
06/18/2022 01:22:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=19
06/18/2022 01:22:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=19
06/18/2022 01:22:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.58 on epoch=20
06/18/2022 01:22:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=21
06/18/2022 01:23:04 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.5035497760761077 on epoch=21
06/18/2022 01:23:04 - INFO - __main__ - Saving model with best Classification-F1: 0.43650126395224437 -> 0.5035497760761077 on epoch=21, global_step=300
06/18/2022 01:23:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=22
06/18/2022 01:23:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
06/18/2022 01:23:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=23
06/18/2022 01:23:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=24
06/18/2022 01:23:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=24
06/18/2022 01:23:24 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.6251385367206459 on epoch=24
06/18/2022 01:23:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5035497760761077 -> 0.6251385367206459 on epoch=24, global_step=350
06/18/2022 01:23:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=25
06/18/2022 01:23:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
06/18/2022 01:23:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=27
06/18/2022 01:23:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=27
06/18/2022 01:23:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
06/18/2022 01:23:44 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.577057181169259 on epoch=28
06/18/2022 01:23:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/18/2022 01:23:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=29
06/18/2022 01:23:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/18/2022 01:23:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
06/18/2022 01:23:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
06/18/2022 01:24:03 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6332712241961252 on epoch=32
06/18/2022 01:24:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6251385367206459 -> 0.6332712241961252 on epoch=32, global_step=450
06/18/2022 01:24:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=32
06/18/2022 01:24:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/18/2022 01:24:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
06/18/2022 01:24:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=34
06/18/2022 01:24:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=35
06/18/2022 01:24:23 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.5740950767872763 on epoch=35
06/18/2022 01:24:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=36
06/18/2022 01:24:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=37
06/18/2022 01:24:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
06/18/2022 01:24:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
06/18/2022 01:24:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
06/18/2022 01:24:42 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6702456238273038 on epoch=39
06/18/2022 01:24:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6332712241961252 -> 0.6702456238273038 on epoch=39, global_step=550
06/18/2022 01:24:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
06/18/2022 01:24:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
06/18/2022 01:24:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=41
06/18/2022 01:24:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=42
06/18/2022 01:24:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
06/18/2022 01:25:01 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.633542223088042 on epoch=42
06/18/2022 01:25:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
06/18/2022 01:25:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=44
06/18/2022 01:25:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/18/2022 01:25:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/18/2022 01:25:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/18/2022 01:25:21 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.5750352955987336 on epoch=46
06/18/2022 01:25:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=47
06/18/2022 01:25:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
06/18/2022 01:25:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/18/2022 01:25:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/18/2022 01:25:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
06/18/2022 01:25:40 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.6233383499015948 on epoch=49
06/18/2022 01:25:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
06/18/2022 01:25:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
06/18/2022 01:25:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/18/2022 01:25:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/18/2022 01:25:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
06/18/2022 01:25:59 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.5848381874667393 on epoch=53
06/18/2022 01:26:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/18/2022 01:26:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=54
06/18/2022 01:26:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/18/2022 01:26:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
06/18/2022 01:26:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/18/2022 01:26:19 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.687258335696659 on epoch=57
06/18/2022 01:26:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6702456238273038 -> 0.687258335696659 on epoch=57, global_step=800
06/18/2022 01:26:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/18/2022 01:26:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/18/2022 01:26:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/18/2022 01:26:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/18/2022 01:26:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/18/2022 01:26:39 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.5958200875658181 on epoch=60
06/18/2022 01:26:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
06/18/2022 01:26:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/18/2022 01:26:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/18/2022 01:26:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/18/2022 01:26:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/18/2022 01:26:58 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.5591462719018636 on epoch=64
06/18/2022 01:27:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/18/2022 01:27:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/18/2022 01:27:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/18/2022 01:27:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=67
06/18/2022 01:27:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/18/2022 01:27:18 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5813912057313817 on epoch=67
06/18/2022 01:27:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/18/2022 01:27:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/18/2022 01:27:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/18/2022 01:27:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
06/18/2022 01:27:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/18/2022 01:27:37 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6715814769083019 on epoch=71
06/18/2022 01:27:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/18/2022 01:27:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/18/2022 01:27:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/18/2022 01:27:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/18/2022 01:27:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/18/2022 01:27:57 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6411458603191011 on epoch=74
06/18/2022 01:28:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=75
06/18/2022 01:28:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/18/2022 01:28:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/18/2022 01:28:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/18/2022 01:28:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
06/18/2022 01:28:17 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7485463503252877 on epoch=78
06/18/2022 01:28:17 - INFO - __main__ - Saving model with best Classification-F1: 0.687258335696659 -> 0.7485463503252877 on epoch=78, global_step=1100
06/18/2022 01:28:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/18/2022 01:28:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/18/2022 01:28:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
06/18/2022 01:28:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/18/2022 01:28:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/18/2022 01:28:36 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7066622581842379 on epoch=82
06/18/2022 01:28:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/18/2022 01:28:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/18/2022 01:28:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/18/2022 01:28:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
06/18/2022 01:28:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/18/2022 01:28:56 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6194822797154051 on epoch=85
06/18/2022 01:28:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/18/2022 01:29:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
06/18/2022 01:29:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/18/2022 01:29:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/18/2022 01:29:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
06/18/2022 01:29:15 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.5693329800735628 on epoch=89
06/18/2022 01:29:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/18/2022 01:29:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/18/2022 01:29:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/18/2022 01:29:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/18/2022 01:29:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/18/2022 01:29:35 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.5954765814984835 on epoch=92
06/18/2022 01:29:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/18/2022 01:29:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/18/2022 01:29:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/18/2022 01:29:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/18/2022 01:29:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/18/2022 01:29:54 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.601226474344754 on epoch=96
06/18/2022 01:29:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
06/18/2022 01:29:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/18/2022 01:30:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/18/2022 01:30:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
06/18/2022 01:30:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/18/2022 01:30:13 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7021168919798202 on epoch=99
06/18/2022 01:30:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/18/2022 01:30:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/18/2022 01:30:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/18/2022 01:30:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/18/2022 01:30:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/18/2022 01:30:33 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7041446743152342 on epoch=103
06/18/2022 01:30:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/18/2022 01:30:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/18/2022 01:30:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/18/2022 01:30:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/18/2022 01:30:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/18/2022 01:30:52 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.656703019260475 on epoch=107
06/18/2022 01:30:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/18/2022 01:30:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/18/2022 01:31:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/18/2022 01:31:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/18/2022 01:31:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/18/2022 01:31:11 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6962443250802868 on epoch=110
06/18/2022 01:31:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/18/2022 01:31:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/18/2022 01:31:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/18/2022 01:31:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/18/2022 01:31:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/18/2022 01:31:31 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6567420636269066 on epoch=114
06/18/2022 01:31:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/18/2022 01:31:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/18/2022 01:31:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/18/2022 01:31:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/18/2022 01:31:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/18/2022 01:31:50 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6853794978326112 on epoch=117
06/18/2022 01:31:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/18/2022 01:31:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/18/2022 01:31:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/18/2022 01:32:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/18/2022 01:32:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/18/2022 01:32:09 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6814183427086653 on epoch=121
06/18/2022 01:32:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/18/2022 01:32:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/18/2022 01:32:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/18/2022 01:32:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/18/2022 01:32:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/18/2022 01:32:28 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7329373978330336 on epoch=124
06/18/2022 01:32:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/18/2022 01:32:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/18/2022 01:32:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/18/2022 01:32:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/18/2022 01:32:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
06/18/2022 01:32:47 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7010658450411772 on epoch=128
06/18/2022 01:32:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/18/2022 01:32:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/18/2022 01:32:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/18/2022 01:32:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/18/2022 01:33:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 01:33:06 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6432772547203787 on epoch=132
06/18/2022 01:33:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/18/2022 01:33:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/18/2022 01:33:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/18/2022 01:33:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/18/2022 01:33:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/18/2022 01:33:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7074437883512102 on epoch=135
06/18/2022 01:33:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/18/2022 01:33:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/18/2022 01:33:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/18/2022 01:33:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/18/2022 01:33:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/18/2022 01:33:45 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7399719936275356 on epoch=139
06/18/2022 01:33:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/18/2022 01:33:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/18/2022 01:33:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/18/2022 01:33:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/18/2022 01:33:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/18/2022 01:34:04 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7240135536506505 on epoch=142
06/18/2022 01:34:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/18/2022 01:34:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/18/2022 01:34:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/18/2022 01:34:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/18/2022 01:34:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/18/2022 01:34:23 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7558391745940921 on epoch=146
06/18/2022 01:34:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7485463503252877 -> 0.7558391745940921 on epoch=146, global_step=2050
06/18/2022 01:34:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/18/2022 01:34:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/18/2022 01:34:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 01:34:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/18/2022 01:34:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/18/2022 01:34:43 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7365297849168818 on epoch=149
06/18/2022 01:34:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/18/2022 01:34:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/18/2022 01:34:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/18/2022 01:34:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/18/2022 01:34:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/18/2022 01:35:03 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7171617457670588 on epoch=153
06/18/2022 01:35:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/18/2022 01:35:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/18/2022 01:35:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/18/2022 01:35:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/18/2022 01:35:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/18/2022 01:35:23 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6089472975720853 on epoch=157
06/18/2022 01:35:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/18/2022 01:35:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/18/2022 01:35:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/18/2022 01:35:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/18/2022 01:35:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/18/2022 01:35:42 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7189857931793416 on epoch=160
06/18/2022 01:35:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/18/2022 01:35:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 01:35:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/18/2022 01:35:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/18/2022 01:35:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/18/2022 01:36:02 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6990435010244258 on epoch=164
06/18/2022 01:36:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/18/2022 01:36:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/18/2022 01:36:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/18/2022 01:36:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/18/2022 01:36:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/18/2022 01:36:22 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7027319030714616 on epoch=167
06/18/2022 01:36:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/18/2022 01:36:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/18/2022 01:36:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/18/2022 01:36:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/18/2022 01:36:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/18/2022 01:36:42 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9052292715717765 on epoch=171
06/18/2022 01:36:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7558391745940921 -> 0.9052292715717765 on epoch=171, global_step=2400
06/18/2022 01:36:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/18/2022 01:36:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/18/2022 01:36:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/18/2022 01:36:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/18/2022 01:36:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/18/2022 01:37:02 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9060034883943803 on epoch=174
06/18/2022 01:37:02 - INFO - __main__ - Saving model with best Classification-F1: 0.9052292715717765 -> 0.9060034883943803 on epoch=174, global_step=2450
06/18/2022 01:37:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/18/2022 01:37:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/18/2022 01:37:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/18/2022 01:37:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/18/2022 01:37:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/18/2022 01:37:22 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7841906733367834 on epoch=178
06/18/2022 01:37:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/18/2022 01:37:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/18/2022 01:37:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/18/2022 01:37:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/18/2022 01:37:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/18/2022 01:37:41 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8345276195578615 on epoch=182
06/18/2022 01:37:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/18/2022 01:37:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/18/2022 01:37:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 01:37:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 01:37:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/18/2022 01:38:01 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7780761290011765 on epoch=185
06/18/2022 01:38:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/18/2022 01:38:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/18/2022 01:38:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/18/2022 01:38:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/18/2022 01:38:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/18/2022 01:38:20 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7830774538554425 on epoch=189
06/18/2022 01:38:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/18/2022 01:38:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/18/2022 01:38:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/18/2022 01:38:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 01:38:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/18/2022 01:38:39 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7500030170281067 on epoch=192
06/18/2022 01:38:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/18/2022 01:38:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/18/2022 01:38:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 01:38:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/18/2022 01:38:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/18/2022 01:38:59 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7989288950487667 on epoch=196
06/18/2022 01:39:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/18/2022 01:39:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/18/2022 01:39:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/18/2022 01:39:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/18/2022 01:39:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/18/2022 01:39:18 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7967076747897711 on epoch=199
06/18/2022 01:39:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/18/2022 01:39:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/18/2022 01:39:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 01:39:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 01:39:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/18/2022 01:39:37 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8512944464809384 on epoch=203
06/18/2022 01:39:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.12 on epoch=204
06/18/2022 01:39:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/18/2022 01:39:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/18/2022 01:39:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/18/2022 01:39:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 01:39:56 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.855196878054741 on epoch=207
06/18/2022 01:39:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/18/2022 01:40:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/18/2022 01:40:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/18/2022 01:40:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 01:40:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/18/2022 01:40:16 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8511608015640274 on epoch=210
06/18/2022 01:40:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 01:40:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/18/2022 01:40:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/18/2022 01:40:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/18/2022 01:40:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/18/2022 01:40:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:40:30 - INFO - __main__ - Printing 3 examples
06/18/2022 01:40:30 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 01:40:30 - INFO - __main__ - ['Plant']
06/18/2022 01:40:30 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 01:40:30 - INFO - __main__ - ['Plant']
06/18/2022 01:40:30 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 01:40:30 - INFO - __main__ - ['Plant']
06/18/2022 01:40:30 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:40:31 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:40:31 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 01:40:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:40:31 - INFO - __main__ - Printing 3 examples
06/18/2022 01:40:31 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 01:40:31 - INFO - __main__ - ['Plant']
06/18/2022 01:40:31 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 01:40:31 - INFO - __main__ - ['Plant']
06/18/2022 01:40:31 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 01:40:31 - INFO - __main__ - ['Plant']
06/18/2022 01:40:31 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:40:31 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:40:31 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 01:40:35 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9060361681329423 on epoch=214
06/18/2022 01:40:36 - INFO - __main__ - Saving model with best Classification-F1: 0.9060034883943803 -> 0.9060361681329423 on epoch=214, global_step=3000
06/18/2022 01:40:36 - INFO - __main__ - save last model!
06/18/2022 01:40:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 01:40:36 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 01:40:36 - INFO - __main__ - Printing 3 examples
06/18/2022 01:40:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 01:40:36 - INFO - __main__ - ['Animal']
06/18/2022 01:40:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 01:40:36 - INFO - __main__ - ['Animal']
06/18/2022 01:40:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 01:40:36 - INFO - __main__ - ['Village']
06/18/2022 01:40:36 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:40:38 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:40:41 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 01:40:46 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 01:40:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 01:40:47 - INFO - __main__ - Starting training!
06/18/2022 01:42:48 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/18/2022 01:42:48 - INFO - __main__ - Classification-F1 on test data: 0.5464
06/18/2022 01:42:49 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9060361681329423, test_performance=0.5463578915556568
06/18/2022 01:42:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/18/2022 01:42:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:42:50 - INFO - __main__ - Printing 3 examples
06/18/2022 01:42:50 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 01:42:50 - INFO - __main__ - ['Plant']
06/18/2022 01:42:50 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 01:42:50 - INFO - __main__ - ['Plant']
06/18/2022 01:42:50 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 01:42:50 - INFO - __main__ - ['Plant']
06/18/2022 01:42:50 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:42:50 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:42:50 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 01:42:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 01:42:50 - INFO - __main__ - Printing 3 examples
06/18/2022 01:42:50 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 01:42:50 - INFO - __main__ - ['Plant']
06/18/2022 01:42:50 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 01:42:50 - INFO - __main__ - ['Plant']
06/18/2022 01:42:50 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 01:42:50 - INFO - __main__ - ['Plant']
06/18/2022 01:42:50 - INFO - __main__ - Tokenizing Input ...
06/18/2022 01:42:50 - INFO - __main__ - Tokenizing Output ...
06/18/2022 01:42:50 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 01:43:06 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 01:43:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 01:43:06 - INFO - __main__ - Starting training!
06/18/2022 01:43:10 - INFO - __main__ - Step 10 Global step 10 Train loss 6.43 on epoch=0
06/18/2022 01:43:13 - INFO - __main__ - Step 20 Global step 20 Train loss 4.98 on epoch=1
06/18/2022 01:43:15 - INFO - __main__ - Step 30 Global step 30 Train loss 4.38 on epoch=2
06/18/2022 01:43:18 - INFO - __main__ - Step 40 Global step 40 Train loss 3.99 on epoch=2
06/18/2022 01:43:20 - INFO - __main__ - Step 50 Global step 50 Train loss 3.84 on epoch=3
06/18/2022 01:43:26 - INFO - __main__ - Global step 50 Train loss 4.72 Classification-F1 0.051399807298518285 on epoch=3
06/18/2022 01:43:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.051399807298518285 on epoch=3, global_step=50
06/18/2022 01:43:29 - INFO - __main__ - Step 60 Global step 60 Train loss 3.21 on epoch=4
06/18/2022 01:43:31 - INFO - __main__ - Step 70 Global step 70 Train loss 3.20 on epoch=4
06/18/2022 01:43:34 - INFO - __main__ - Step 80 Global step 80 Train loss 2.69 on epoch=5
06/18/2022 01:43:36 - INFO - __main__ - Step 90 Global step 90 Train loss 2.78 on epoch=6
06/18/2022 01:43:39 - INFO - __main__ - Step 100 Global step 100 Train loss 2.53 on epoch=7
06/18/2022 01:43:44 - INFO - __main__ - Global step 100 Train loss 2.88 Classification-F1 0.10748874882281115 on epoch=7
06/18/2022 01:43:44 - INFO - __main__ - Saving model with best Classification-F1: 0.051399807298518285 -> 0.10748874882281115 on epoch=7, global_step=100
06/18/2022 01:43:47 - INFO - __main__ - Step 110 Global step 110 Train loss 2.16 on epoch=7
06/18/2022 01:43:49 - INFO - __main__ - Step 120 Global step 120 Train loss 2.16 on epoch=8
06/18/2022 01:43:52 - INFO - __main__ - Step 130 Global step 130 Train loss 1.85 on epoch=9
06/18/2022 01:43:54 - INFO - __main__ - Step 140 Global step 140 Train loss 1.82 on epoch=9
06/18/2022 01:43:57 - INFO - __main__ - Step 150 Global step 150 Train loss 1.65 on epoch=10
06/18/2022 01:44:02 - INFO - __main__ - Global step 150 Train loss 1.93 Classification-F1 0.12391960936751359 on epoch=10
06/18/2022 01:44:02 - INFO - __main__ - Saving model with best Classification-F1: 0.10748874882281115 -> 0.12391960936751359 on epoch=10, global_step=150
06/18/2022 01:44:04 - INFO - __main__ - Step 160 Global step 160 Train loss 1.66 on epoch=11
06/18/2022 01:44:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.60 on epoch=12
06/18/2022 01:44:10 - INFO - __main__ - Step 180 Global step 180 Train loss 1.37 on epoch=12
06/18/2022 01:44:12 - INFO - __main__ - Step 190 Global step 190 Train loss 1.38 on epoch=13
06/18/2022 01:44:15 - INFO - __main__ - Step 200 Global step 200 Train loss 1.21 on epoch=14
06/18/2022 01:44:20 - INFO - __main__ - Global step 200 Train loss 1.45 Classification-F1 0.13733143295663774 on epoch=14
06/18/2022 01:44:20 - INFO - __main__ - Saving model with best Classification-F1: 0.12391960936751359 -> 0.13733143295663774 on epoch=14, global_step=200
06/18/2022 01:44:23 - INFO - __main__ - Step 210 Global step 210 Train loss 1.26 on epoch=14
06/18/2022 01:44:26 - INFO - __main__ - Step 220 Global step 220 Train loss 1.05 on epoch=15
06/18/2022 01:44:28 - INFO - __main__ - Step 230 Global step 230 Train loss 1.05 on epoch=16
06/18/2022 01:44:31 - INFO - __main__ - Step 240 Global step 240 Train loss 1.00 on epoch=17
06/18/2022 01:44:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.96 on epoch=17
06/18/2022 01:44:39 - INFO - __main__ - Global step 250 Train loss 1.06 Classification-F1 0.3274618697909638 on epoch=17
06/18/2022 01:44:39 - INFO - __main__ - Saving model with best Classification-F1: 0.13733143295663774 -> 0.3274618697909638 on epoch=17, global_step=250
06/18/2022 01:44:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.87 on epoch=18
06/18/2022 01:44:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=19
06/18/2022 01:44:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.72 on epoch=19
06/18/2022 01:44:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.82 on epoch=20
06/18/2022 01:44:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=21
06/18/2022 01:44:58 - INFO - __main__ - Global step 300 Train loss 0.77 Classification-F1 0.37824021584194156 on epoch=21
06/18/2022 01:44:59 - INFO - __main__ - Saving model with best Classification-F1: 0.3274618697909638 -> 0.37824021584194156 on epoch=21, global_step=300
06/18/2022 01:45:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=22
06/18/2022 01:45:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=22
06/18/2022 01:45:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.69 on epoch=23
06/18/2022 01:45:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
06/18/2022 01:45:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=24
06/18/2022 01:45:18 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.5422880106751073 on epoch=24
06/18/2022 01:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.37824021584194156 -> 0.5422880106751073 on epoch=24, global_step=350
06/18/2022 01:45:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=25
06/18/2022 01:45:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=26
06/18/2022 01:45:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=27
06/18/2022 01:45:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=27
06/18/2022 01:45:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=28
06/18/2022 01:45:38 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.496671055249214 on epoch=28
06/18/2022 01:45:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
06/18/2022 01:45:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=29
06/18/2022 01:45:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=30
06/18/2022 01:45:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=31
06/18/2022 01:45:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
06/18/2022 01:45:57 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.65358674896276 on epoch=32
06/18/2022 01:45:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5422880106751073 -> 0.65358674896276 on epoch=32, global_step=450
06/18/2022 01:46:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
06/18/2022 01:46:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
06/18/2022 01:46:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
06/18/2022 01:46:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/18/2022 01:46:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=35
06/18/2022 01:46:17 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.6318217228155967 on epoch=35
06/18/2022 01:46:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=36
06/18/2022 01:46:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
06/18/2022 01:46:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=37
06/18/2022 01:46:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/18/2022 01:46:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
06/18/2022 01:46:37 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6701073471010053 on epoch=39
06/18/2022 01:46:37 - INFO - __main__ - Saving model with best Classification-F1: 0.65358674896276 -> 0.6701073471010053 on epoch=39, global_step=550
06/18/2022 01:46:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=39
06/18/2022 01:46:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=40
06/18/2022 01:46:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=41
06/18/2022 01:46:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=42
06/18/2022 01:46:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=42
06/18/2022 01:46:57 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.6715011687832978 on epoch=42
06/18/2022 01:46:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6701073471010053 -> 0.6715011687832978 on epoch=42, global_step=600
06/18/2022 01:46:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
06/18/2022 01:47:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
06/18/2022 01:47:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/18/2022 01:47:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
06/18/2022 01:47:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
06/18/2022 01:47:16 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.6750319392832151 on epoch=46
06/18/2022 01:47:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6715011687832978 -> 0.6750319392832151 on epoch=46, global_step=650
06/18/2022 01:47:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
06/18/2022 01:47:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=47
06/18/2022 01:47:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
06/18/2022 01:47:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/18/2022 01:47:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
06/18/2022 01:47:36 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6803852742081502 on epoch=49
06/18/2022 01:47:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6750319392832151 -> 0.6803852742081502 on epoch=49, global_step=700
06/18/2022 01:47:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
06/18/2022 01:47:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/18/2022 01:47:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/18/2022 01:47:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
06/18/2022 01:47:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/18/2022 01:47:55 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.6666775420271307 on epoch=53
06/18/2022 01:47:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=54
06/18/2022 01:48:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
06/18/2022 01:48:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/18/2022 01:48:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/18/2022 01:48:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/18/2022 01:48:15 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.725601692008811 on epoch=57
06/18/2022 01:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6803852742081502 -> 0.725601692008811 on epoch=57, global_step=800
06/18/2022 01:48:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=57
06/18/2022 01:48:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=58
06/18/2022 01:48:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/18/2022 01:48:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=59
06/18/2022 01:48:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
06/18/2022 01:48:34 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7095249145507876 on epoch=60
06/18/2022 01:48:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/18/2022 01:48:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/18/2022 01:48:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
06/18/2022 01:48:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/18/2022 01:48:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/18/2022 01:48:54 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6924729095644836 on epoch=64
06/18/2022 01:48:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/18/2022 01:48:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
06/18/2022 01:49:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
06/18/2022 01:49:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/18/2022 01:49:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
06/18/2022 01:49:13 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6612374966561916 on epoch=67
06/18/2022 01:49:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/18/2022 01:49:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/18/2022 01:49:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/18/2022 01:49:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
06/18/2022 01:49:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=71
06/18/2022 01:49:32 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.625031610826178 on epoch=71
06/18/2022 01:49:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
06/18/2022 01:49:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/18/2022 01:49:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=73
06/18/2022 01:49:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
06/18/2022 01:49:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/18/2022 01:49:52 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.680498460399435 on epoch=74
06/18/2022 01:49:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/18/2022 01:49:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/18/2022 01:50:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/18/2022 01:50:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/18/2022 01:50:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/18/2022 01:50:11 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.619699108281193 on epoch=78
06/18/2022 01:50:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/18/2022 01:50:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/18/2022 01:50:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/18/2022 01:50:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/18/2022 01:50:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/18/2022 01:50:30 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7384324781239228 on epoch=82
06/18/2022 01:50:30 - INFO - __main__ - Saving model with best Classification-F1: 0.725601692008811 -> 0.7384324781239228 on epoch=82, global_step=1150
06/18/2022 01:50:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
06/18/2022 01:50:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=83
06/18/2022 01:50:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/18/2022 01:50:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/18/2022 01:50:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/18/2022 01:50:50 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6489636335877258 on epoch=85
06/18/2022 01:50:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
06/18/2022 01:50:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/18/2022 01:50:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/18/2022 01:51:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=88
06/18/2022 01:51:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/18/2022 01:51:09 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6493981441550227 on epoch=89
06/18/2022 01:51:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/18/2022 01:51:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/18/2022 01:51:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/18/2022 01:51:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/18/2022 01:51:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/18/2022 01:51:28 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.66143022971652 on epoch=92
06/18/2022 01:51:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/18/2022 01:51:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/18/2022 01:51:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/18/2022 01:51:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/18/2022 01:51:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/18/2022 01:51:47 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6563326679645465 on epoch=96
06/18/2022 01:51:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/18/2022 01:51:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/18/2022 01:51:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/18/2022 01:51:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/18/2022 01:52:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/18/2022 01:52:07 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7401387143322629 on epoch=99
06/18/2022 01:52:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7384324781239228 -> 0.7401387143322629 on epoch=99, global_step=1400
06/18/2022 01:52:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/18/2022 01:52:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/18/2022 01:52:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/18/2022 01:52:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
06/18/2022 01:52:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
06/18/2022 01:52:27 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6948537551004887 on epoch=103
06/18/2022 01:52:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
06/18/2022 01:52:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/18/2022 01:52:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/18/2022 01:52:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/18/2022 01:52:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/18/2022 01:52:46 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6876634836435124 on epoch=107
06/18/2022 01:52:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
06/18/2022 01:52:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/18/2022 01:52:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/18/2022 01:52:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/18/2022 01:52:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
06/18/2022 01:53:06 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.7193344569567981 on epoch=110
06/18/2022 01:53:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/18/2022 01:53:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/18/2022 01:53:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/18/2022 01:53:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/18/2022 01:53:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=114
06/18/2022 01:53:25 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.7228032850224003 on epoch=114
06/18/2022 01:53:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/18/2022 01:53:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/18/2022 01:53:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/18/2022 01:53:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/18/2022 01:53:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/18/2022 01:53:44 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7804220103263572 on epoch=117
06/18/2022 01:53:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7401387143322629 -> 0.7804220103263572 on epoch=117, global_step=1650
06/18/2022 01:53:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/18/2022 01:53:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=119
06/18/2022 01:53:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/18/2022 01:53:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/18/2022 01:53:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/18/2022 01:54:04 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7297038333091463 on epoch=121
06/18/2022 01:54:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/18/2022 01:54:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/18/2022 01:54:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/18/2022 01:54:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/18/2022 01:54:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/18/2022 01:54:23 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7173266336254451 on epoch=124
06/18/2022 01:54:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/18/2022 01:54:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/18/2022 01:54:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
06/18/2022 01:54:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
06/18/2022 01:54:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/18/2022 01:54:42 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7193072238413295 on epoch=128
06/18/2022 01:54:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
06/18/2022 01:54:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/18/2022 01:54:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/18/2022 01:54:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/18/2022 01:54:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 01:55:02 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.74324880685412 on epoch=132
06/18/2022 01:55:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/18/2022 01:55:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/18/2022 01:55:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/18/2022 01:55:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/18/2022 01:55:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/18/2022 01:55:21 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7448270896824027 on epoch=135
06/18/2022 01:55:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/18/2022 01:55:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/18/2022 01:55:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/18/2022 01:55:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/18/2022 01:55:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/18/2022 01:55:40 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7780004230431177 on epoch=139
06/18/2022 01:55:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/18/2022 01:55:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=140
06/18/2022 01:55:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/18/2022 01:55:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/18/2022 01:55:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=142
06/18/2022 01:56:00 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.6927935837091435 on epoch=142
06/18/2022 01:56:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/18/2022 01:56:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/18/2022 01:56:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/18/2022 01:56:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/18/2022 01:56:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/18/2022 01:56:20 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7448270896824027 on epoch=146
06/18/2022 01:56:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/18/2022 01:56:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/18/2022 01:56:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 01:56:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/18/2022 01:56:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/18/2022 01:56:39 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7421395759842464 on epoch=149
06/18/2022 01:56:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/18/2022 01:56:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/18/2022 01:56:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/18/2022 01:56:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/18/2022 01:56:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
06/18/2022 01:56:58 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7421395759842464 on epoch=153
06/18/2022 01:57:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
06/18/2022 01:57:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/18/2022 01:57:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/18/2022 01:57:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/18/2022 01:57:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/18/2022 01:57:18 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8844500507925557 on epoch=157
06/18/2022 01:57:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7804220103263572 -> 0.8844500507925557 on epoch=157, global_step=2200
06/18/2022 01:57:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/18/2022 01:57:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/18/2022 01:57:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/18/2022 01:57:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/18/2022 01:57:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/18/2022 01:57:37 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7923421597377953 on epoch=160
06/18/2022 01:57:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/18/2022 01:57:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/18/2022 01:57:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/18/2022 01:57:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/18/2022 01:57:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/18/2022 01:57:57 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.790671036743143 on epoch=164
06/18/2022 01:58:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/18/2022 01:58:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/18/2022 01:58:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/18/2022 01:58:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/18/2022 01:58:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/18/2022 01:58:16 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8291788856304985 on epoch=167
06/18/2022 01:58:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/18/2022 01:58:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/18/2022 01:58:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/18/2022 01:58:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/18/2022 01:58:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/18/2022 01:58:36 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7448509286412511 on epoch=171
06/18/2022 01:58:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/18/2022 01:58:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/18/2022 01:58:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/18/2022 01:58:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/18/2022 01:58:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/18/2022 01:58:55 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7448543227978711 on epoch=174
06/18/2022 01:58:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=175
06/18/2022 01:59:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/18/2022 01:59:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/18/2022 01:59:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=177
06/18/2022 01:59:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/18/2022 01:59:15 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.8775844466167049 on epoch=178
06/18/2022 01:59:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/18/2022 01:59:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/18/2022 01:59:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/18/2022 01:59:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/18/2022 01:59:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/18/2022 01:59:34 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8719174809497391 on epoch=182
06/18/2022 01:59:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/18/2022 01:59:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/18/2022 01:59:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/18/2022 01:59:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/18/2022 01:59:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
06/18/2022 01:59:54 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7126151122988568 on epoch=185
06/18/2022 01:59:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=186
06/18/2022 01:59:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/18/2022 02:00:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/18/2022 02:00:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/18/2022 02:00:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/18/2022 02:00:13 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.722704255511606 on epoch=189
06/18/2022 02:00:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/18/2022 02:00:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/18/2022 02:00:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/18/2022 02:00:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/18/2022 02:00:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/18/2022 02:00:33 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8097955342038035 on epoch=192
06/18/2022 02:00:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/18/2022 02:00:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/18/2022 02:00:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 02:00:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/18/2022 02:00:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
06/18/2022 02:00:52 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7192382226338084 on epoch=196
06/18/2022 02:00:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/18/2022 02:00:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/18/2022 02:01:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/18/2022 02:01:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/18/2022 02:01:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/18/2022 02:01:11 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7282183906472331 on epoch=199
06/18/2022 02:01:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/18/2022 02:01:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/18/2022 02:01:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 02:01:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/18/2022 02:01:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/18/2022 02:01:31 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.731714451828304 on epoch=203
06/18/2022 02:01:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/18/2022 02:01:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 02:01:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/18/2022 02:01:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/18/2022 02:01:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 02:01:50 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7242825383398888 on epoch=207
06/18/2022 02:01:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/18/2022 02:01:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/18/2022 02:01:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/18/2022 02:02:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 02:02:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/18/2022 02:02:09 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8331244917879813 on epoch=210
06/18/2022 02:02:12 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 02:02:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/18/2022 02:02:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/18/2022 02:02:20 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/18/2022 02:02:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/18/2022 02:02:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:02:24 - INFO - __main__ - Printing 3 examples
06/18/2022 02:02:24 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 02:02:24 - INFO - __main__ - ['Plant']
06/18/2022 02:02:24 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 02:02:24 - INFO - __main__ - ['Plant']
06/18/2022 02:02:24 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 02:02:24 - INFO - __main__ - ['Plant']
06/18/2022 02:02:24 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:02:24 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:02:24 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 02:02:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:02:24 - INFO - __main__ - Printing 3 examples
06/18/2022 02:02:24 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 02:02:24 - INFO - __main__ - ['Plant']
06/18/2022 02:02:24 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 02:02:24 - INFO - __main__ - ['Plant']
06/18/2022 02:02:24 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 02:02:24 - INFO - __main__ - ['Plant']
06/18/2022 02:02:24 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:02:24 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:02:24 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 02:02:28 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.774700910207105 on epoch=214
06/18/2022 02:02:28 - INFO - __main__ - save last model!
06/18/2022 02:02:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 02:02:28 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 02:02:29 - INFO - __main__ - Printing 3 examples
06/18/2022 02:02:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 02:02:29 - INFO - __main__ - ['Animal']
06/18/2022 02:02:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 02:02:29 - INFO - __main__ - ['Animal']
06/18/2022 02:02:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 02:02:29 - INFO - __main__ - ['Village']
06/18/2022 02:02:29 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:02:30 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:02:34 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 02:02:40 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 02:02:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 02:02:40 - INFO - __main__ - Starting training!
06/18/2022 02:04:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/18/2022 02:04:33 - INFO - __main__ - Classification-F1 on test data: 0.4908
06/18/2022 02:04:34 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.8844500507925557, test_performance=0.490833918833348
06/18/2022 02:04:34 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/18/2022 02:04:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:04:35 - INFO - __main__ - Printing 3 examples
06/18/2022 02:04:35 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/18/2022 02:04:35 - INFO - __main__ - ['Plant']
06/18/2022 02:04:35 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/18/2022 02:04:35 - INFO - __main__ - ['Plant']
06/18/2022 02:04:35 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/18/2022 02:04:35 - INFO - __main__ - ['Plant']
06/18/2022 02:04:35 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:04:35 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:04:35 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 02:04:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:04:35 - INFO - __main__ - Printing 3 examples
06/18/2022 02:04:35 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/18/2022 02:04:35 - INFO - __main__ - ['Plant']
06/18/2022 02:04:35 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/18/2022 02:04:35 - INFO - __main__ - ['Plant']
06/18/2022 02:04:35 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/18/2022 02:04:35 - INFO - __main__ - ['Plant']
06/18/2022 02:04:35 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:04:35 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:04:35 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 02:04:54 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 02:04:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 02:04:55 - INFO - __main__ - Starting training!
06/18/2022 02:04:58 - INFO - __main__ - Step 10 Global step 10 Train loss 7.16 on epoch=0
06/18/2022 02:05:01 - INFO - __main__ - Step 20 Global step 20 Train loss 5.34 on epoch=1
06/18/2022 02:05:03 - INFO - __main__ - Step 30 Global step 30 Train loss 4.98 on epoch=2
06/18/2022 02:05:06 - INFO - __main__ - Step 40 Global step 40 Train loss 4.60 on epoch=2
06/18/2022 02:05:09 - INFO - __main__ - Step 50 Global step 50 Train loss 4.21 on epoch=3
06/18/2022 02:05:16 - INFO - __main__ - Global step 50 Train loss 5.26 Classification-F1 0.026289139060258124 on epoch=3
06/18/2022 02:05:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.026289139060258124 on epoch=3, global_step=50
06/18/2022 02:05:19 - INFO - __main__ - Step 60 Global step 60 Train loss 3.92 on epoch=4
06/18/2022 02:05:21 - INFO - __main__ - Step 70 Global step 70 Train loss 3.91 on epoch=4
06/18/2022 02:05:24 - INFO - __main__ - Step 80 Global step 80 Train loss 3.44 on epoch=5
06/18/2022 02:05:27 - INFO - __main__ - Step 90 Global step 90 Train loss 3.36 on epoch=6
06/18/2022 02:05:29 - INFO - __main__ - Step 100 Global step 100 Train loss 3.26 on epoch=7
06/18/2022 02:05:35 - INFO - __main__ - Global step 100 Train loss 3.58 Classification-F1 0.06365112060151865 on epoch=7
06/18/2022 02:05:35 - INFO - __main__ - Saving model with best Classification-F1: 0.026289139060258124 -> 0.06365112060151865 on epoch=7, global_step=100
06/18/2022 02:05:37 - INFO - __main__ - Step 110 Global step 110 Train loss 2.67 on epoch=7
06/18/2022 02:05:40 - INFO - __main__ - Step 120 Global step 120 Train loss 2.90 on epoch=8
06/18/2022 02:05:43 - INFO - __main__ - Step 130 Global step 130 Train loss 2.61 on epoch=9
06/18/2022 02:05:45 - INFO - __main__ - Step 140 Global step 140 Train loss 2.51 on epoch=9
06/18/2022 02:05:48 - INFO - __main__ - Step 150 Global step 150 Train loss 2.16 on epoch=10
06/18/2022 02:05:53 - INFO - __main__ - Global step 150 Train loss 2.57 Classification-F1 0.0997158225165953 on epoch=10
06/18/2022 02:05:53 - INFO - __main__ - Saving model with best Classification-F1: 0.06365112060151865 -> 0.0997158225165953 on epoch=10, global_step=150
06/18/2022 02:05:56 - INFO - __main__ - Step 160 Global step 160 Train loss 2.22 on epoch=11
06/18/2022 02:05:58 - INFO - __main__ - Step 170 Global step 170 Train loss 2.18 on epoch=12
06/18/2022 02:06:01 - INFO - __main__ - Step 180 Global step 180 Train loss 1.99 on epoch=12
06/18/2022 02:06:04 - INFO - __main__ - Step 190 Global step 190 Train loss 1.98 on epoch=13
06/18/2022 02:06:06 - INFO - __main__ - Step 200 Global step 200 Train loss 1.84 on epoch=14
06/18/2022 02:06:11 - INFO - __main__ - Global step 200 Train loss 2.04 Classification-F1 0.1174718956828449 on epoch=14
06/18/2022 02:06:11 - INFO - __main__ - Saving model with best Classification-F1: 0.0997158225165953 -> 0.1174718956828449 on epoch=14, global_step=200
06/18/2022 02:06:14 - INFO - __main__ - Step 210 Global step 210 Train loss 1.81 on epoch=14
06/18/2022 02:06:17 - INFO - __main__ - Step 220 Global step 220 Train loss 1.73 on epoch=15
06/18/2022 02:06:19 - INFO - __main__ - Step 230 Global step 230 Train loss 1.65 on epoch=16
06/18/2022 02:06:22 - INFO - __main__ - Step 240 Global step 240 Train loss 1.62 on epoch=17
06/18/2022 02:06:24 - INFO - __main__ - Step 250 Global step 250 Train loss 1.57 on epoch=17
06/18/2022 02:06:30 - INFO - __main__ - Global step 250 Train loss 1.68 Classification-F1 0.12851920009814746 on epoch=17
06/18/2022 02:06:30 - INFO - __main__ - Saving model with best Classification-F1: 0.1174718956828449 -> 0.12851920009814746 on epoch=17, global_step=250
06/18/2022 02:06:33 - INFO - __main__ - Step 260 Global step 260 Train loss 1.54 on epoch=18
06/18/2022 02:06:35 - INFO - __main__ - Step 270 Global step 270 Train loss 1.33 on epoch=19
06/18/2022 02:06:38 - INFO - __main__ - Step 280 Global step 280 Train loss 1.30 on epoch=19
06/18/2022 02:06:40 - INFO - __main__ - Step 290 Global step 290 Train loss 1.28 on epoch=20
06/18/2022 02:06:43 - INFO - __main__ - Step 300 Global step 300 Train loss 1.19 on epoch=21
06/18/2022 02:06:49 - INFO - __main__ - Global step 300 Train loss 1.33 Classification-F1 0.1422633987466372 on epoch=21
06/18/2022 02:06:49 - INFO - __main__ - Saving model with best Classification-F1: 0.12851920009814746 -> 0.1422633987466372 on epoch=21, global_step=300
06/18/2022 02:06:52 - INFO - __main__ - Step 310 Global step 310 Train loss 1.38 on epoch=22
06/18/2022 02:06:54 - INFO - __main__ - Step 320 Global step 320 Train loss 1.06 on epoch=22
06/18/2022 02:06:57 - INFO - __main__ - Step 330 Global step 330 Train loss 1.10 on epoch=23
06/18/2022 02:07:00 - INFO - __main__ - Step 340 Global step 340 Train loss 1.01 on epoch=24
06/18/2022 02:07:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.99 on epoch=24
06/18/2022 02:07:08 - INFO - __main__ - Global step 350 Train loss 1.11 Classification-F1 0.2279055258588073 on epoch=24
06/18/2022 02:07:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1422633987466372 -> 0.2279055258588073 on epoch=24, global_step=350
06/18/2022 02:07:11 - INFO - __main__ - Step 360 Global step 360 Train loss 1.02 on epoch=25
06/18/2022 02:07:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.90 on epoch=26
06/18/2022 02:07:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.94 on epoch=27
06/18/2022 02:07:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.80 on epoch=27
06/18/2022 02:07:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.88 on epoch=28
06/18/2022 02:07:28 - INFO - __main__ - Global step 400 Train loss 0.91 Classification-F1 0.3750574837537396 on epoch=28
06/18/2022 02:07:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2279055258588073 -> 0.3750574837537396 on epoch=28, global_step=400
06/18/2022 02:07:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.84 on epoch=29
06/18/2022 02:07:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.70 on epoch=29
06/18/2022 02:07:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.78 on epoch=30
06/18/2022 02:07:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.68 on epoch=31
06/18/2022 02:07:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.68 on epoch=32
06/18/2022 02:07:47 - INFO - __main__ - Global step 450 Train loss 0.74 Classification-F1 0.44782820665173606 on epoch=32
06/18/2022 02:07:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3750574837537396 -> 0.44782820665173606 on epoch=32, global_step=450
06/18/2022 02:07:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.55 on epoch=32
06/18/2022 02:07:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.58 on epoch=33
06/18/2022 02:07:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.61 on epoch=34
06/18/2022 02:07:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.60 on epoch=34
06/18/2022 02:08:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.48 on epoch=35
06/18/2022 02:08:07 - INFO - __main__ - Global step 500 Train loss 0.57 Classification-F1 0.4592916288897936 on epoch=35
06/18/2022 02:08:07 - INFO - __main__ - Saving model with best Classification-F1: 0.44782820665173606 -> 0.4592916288897936 on epoch=35, global_step=500
06/18/2022 02:08:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=36
06/18/2022 02:08:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=37
06/18/2022 02:08:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=37
06/18/2022 02:08:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=38
06/18/2022 02:08:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.44 on epoch=39
06/18/2022 02:08:27 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.5388472820099749 on epoch=39
06/18/2022 02:08:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4592916288897936 -> 0.5388472820099749 on epoch=39, global_step=550
06/18/2022 02:08:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=39
06/18/2022 02:08:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.54 on epoch=40
06/18/2022 02:08:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=41
06/18/2022 02:08:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.43 on epoch=42
06/18/2022 02:08:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=42
06/18/2022 02:08:47 - INFO - __main__ - Global step 600 Train loss 0.45 Classification-F1 0.5906852886771049 on epoch=42
06/18/2022 02:08:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5388472820099749 -> 0.5906852886771049 on epoch=42, global_step=600
06/18/2022 02:08:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=43
06/18/2022 02:08:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=44
06/18/2022 02:08:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=44
06/18/2022 02:08:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=45
06/18/2022 02:09:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=46
06/18/2022 02:09:08 - INFO - __main__ - Global step 650 Train loss 0.37 Classification-F1 0.5683469766573468 on epoch=46
06/18/2022 02:09:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=47
06/18/2022 02:09:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=47
06/18/2022 02:09:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=48
06/18/2022 02:09:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=49
06/18/2022 02:09:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
06/18/2022 02:09:28 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.6230238136310243 on epoch=49
06/18/2022 02:09:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5906852886771049 -> 0.6230238136310243 on epoch=49, global_step=700
06/18/2022 02:09:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/18/2022 02:09:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=51
06/18/2022 02:09:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=52
06/18/2022 02:09:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=52
06/18/2022 02:09:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
06/18/2022 02:09:48 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.5486610139753799 on epoch=53
06/18/2022 02:09:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=54
06/18/2022 02:09:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
06/18/2022 02:09:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
06/18/2022 02:09:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=56
06/18/2022 02:10:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/18/2022 02:10:08 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.5699965863444819 on epoch=57
06/18/2022 02:10:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=57
06/18/2022 02:10:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/18/2022 02:10:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=59
06/18/2022 02:10:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/18/2022 02:10:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
06/18/2022 02:10:28 - INFO - __main__ - Global step 850 Train loss 0.25 Classification-F1 0.5737923031207904 on epoch=60
06/18/2022 02:10:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/18/2022 02:10:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
06/18/2022 02:10:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=62
06/18/2022 02:10:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=63
06/18/2022 02:10:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=64
06/18/2022 02:10:47 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.6014435313681208 on epoch=64
06/18/2022 02:10:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=64
06/18/2022 02:10:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=65
06/18/2022 02:10:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/18/2022 02:10:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=67
06/18/2022 02:11:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/18/2022 02:11:07 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.675461199315035 on epoch=67
06/18/2022 02:11:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6230238136310243 -> 0.675461199315035 on epoch=67, global_step=950
06/18/2022 02:11:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=68
06/18/2022 02:11:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
06/18/2022 02:11:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=69
06/18/2022 02:11:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/18/2022 02:11:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=71
06/18/2022 02:11:27 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.584575161058554 on epoch=71
06/18/2022 02:11:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=72
06/18/2022 02:11:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=72
06/18/2022 02:11:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/18/2022 02:11:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=74
06/18/2022 02:11:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=74
06/18/2022 02:11:47 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.5533735116226604 on epoch=74
06/18/2022 02:11:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
06/18/2022 02:11:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
06/18/2022 02:11:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/18/2022 02:11:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.23 on epoch=77
06/18/2022 02:12:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=78
06/18/2022 02:12:07 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.5305708891572269 on epoch=78
06/18/2022 02:12:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
06/18/2022 02:12:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=79
06/18/2022 02:12:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=80
06/18/2022 02:12:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=81
06/18/2022 02:12:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/18/2022 02:12:27 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.5581859349205278 on epoch=82
06/18/2022 02:12:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=82
06/18/2022 02:12:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
06/18/2022 02:12:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
06/18/2022 02:12:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
06/18/2022 02:12:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/18/2022 02:12:46 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.5305708891572269 on epoch=85
06/18/2022 02:12:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=86
06/18/2022 02:12:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/18/2022 02:12:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=87
06/18/2022 02:12:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=88
06/18/2022 02:12:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
06/18/2022 02:13:06 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.615802083554006 on epoch=89
06/18/2022 02:13:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/18/2022 02:13:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=90
06/18/2022 02:13:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
06/18/2022 02:13:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/18/2022 02:13:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=92
06/18/2022 02:13:25 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.6580530980720735 on epoch=92
06/18/2022 02:13:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=93
06/18/2022 02:13:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/18/2022 02:13:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/18/2022 02:13:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/18/2022 02:13:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/18/2022 02:13:44 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.6483126178392332 on epoch=96
06/18/2022 02:13:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
06/18/2022 02:13:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/18/2022 02:13:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=98
06/18/2022 02:13:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
06/18/2022 02:13:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/18/2022 02:14:04 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.6525231441550228 on epoch=99
06/18/2022 02:14:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=100
06/18/2022 02:14:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/18/2022 02:14:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/18/2022 02:14:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=102
06/18/2022 02:14:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=103
06/18/2022 02:14:23 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.684132127436884 on epoch=103
06/18/2022 02:14:23 - INFO - __main__ - Saving model with best Classification-F1: 0.675461199315035 -> 0.684132127436884 on epoch=103, global_step=1450
06/18/2022 02:14:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/18/2022 02:14:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=104
06/18/2022 02:14:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=105
06/18/2022 02:14:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
06/18/2022 02:14:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
06/18/2022 02:14:42 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.6842453136281685 on epoch=107
06/18/2022 02:14:42 - INFO - __main__ - Saving model with best Classification-F1: 0.684132127436884 -> 0.6842453136281685 on epoch=107, global_step=1500
06/18/2022 02:14:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/18/2022 02:14:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
06/18/2022 02:14:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/18/2022 02:14:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
06/18/2022 02:14:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/18/2022 02:15:01 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.6219733105980984 on epoch=110
06/18/2022 02:15:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=111
06/18/2022 02:15:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/18/2022 02:15:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/18/2022 02:15:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=113
06/18/2022 02:15:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=114
06/18/2022 02:15:20 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.6556695992179863 on epoch=114
06/18/2022 02:15:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
06/18/2022 02:15:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
06/18/2022 02:15:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/18/2022 02:15:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/18/2022 02:15:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=117
06/18/2022 02:15:39 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.6959995296158284 on epoch=117
06/18/2022 02:15:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6842453136281685 -> 0.6959995296158284 on epoch=117, global_step=1650
06/18/2022 02:15:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=118
06/18/2022 02:15:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/18/2022 02:15:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
06/18/2022 02:15:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=120
06/18/2022 02:15:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/18/2022 02:15:58 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.6858525045829577 on epoch=121
06/18/2022 02:16:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/18/2022 02:16:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=122
06/18/2022 02:16:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=123
06/18/2022 02:16:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/18/2022 02:16:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=124
06/18/2022 02:16:17 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7223709493315256 on epoch=124
06/18/2022 02:16:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6959995296158284 -> 0.7223709493315256 on epoch=124, global_step=1750
06/18/2022 02:16:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/18/2022 02:16:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/18/2022 02:16:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
06/18/2022 02:16:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
06/18/2022 02:16:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/18/2022 02:16:36 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7170607615262897 on epoch=128
06/18/2022 02:16:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=129
06/18/2022 02:16:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/18/2022 02:16:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/18/2022 02:16:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/18/2022 02:16:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/18/2022 02:16:56 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.776077648585741 on epoch=132
06/18/2022 02:16:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7223709493315256 -> 0.776077648585741 on epoch=132, global_step=1850
06/18/2022 02:16:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
06/18/2022 02:17:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/18/2022 02:17:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/18/2022 02:17:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/18/2022 02:17:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
06/18/2022 02:17:15 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6531205796101431 on epoch=135
06/18/2022 02:17:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/18/2022 02:17:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/18/2022 02:17:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=137
06/18/2022 02:17:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
06/18/2022 02:17:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=139
06/18/2022 02:17:34 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.6910957908398735 on epoch=139
06/18/2022 02:17:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/18/2022 02:17:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
06/18/2022 02:17:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=141
06/18/2022 02:17:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
06/18/2022 02:17:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=142
06/18/2022 02:17:53 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.6947412681695614 on epoch=142
06/18/2022 02:17:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/18/2022 02:17:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/18/2022 02:18:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/18/2022 02:18:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=145
06/18/2022 02:18:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/18/2022 02:18:12 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.6980697474705808 on epoch=146
06/18/2022 02:18:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/18/2022 02:18:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/18/2022 02:18:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=148
06/18/2022 02:18:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
06/18/2022 02:18:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/18/2022 02:18:31 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.6548205711903531 on epoch=149
06/18/2022 02:18:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/18/2022 02:18:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=151
06/18/2022 02:18:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/18/2022 02:18:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/18/2022 02:18:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/18/2022 02:18:51 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6565410012978798 on epoch=153
06/18/2022 02:18:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=154
06/18/2022 02:18:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
06/18/2022 02:18:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=155
06/18/2022 02:19:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=156
06/18/2022 02:19:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
06/18/2022 02:19:10 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.6548205711903531 on epoch=157
06/18/2022 02:19:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=157
06/18/2022 02:19:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/18/2022 02:19:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/18/2022 02:19:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/18/2022 02:19:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/18/2022 02:19:29 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7027125343114557 on epoch=160
06/18/2022 02:19:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=161
06/18/2022 02:19:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/18/2022 02:19:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/18/2022 02:19:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/18/2022 02:19:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.12 on epoch=164
06/18/2022 02:19:49 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.6510110473808292 on epoch=164
06/18/2022 02:19:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=164
06/18/2022 02:19:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=165
06/18/2022 02:19:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=166
06/18/2022 02:19:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/18/2022 02:20:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
06/18/2022 02:20:08 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.740347461288906 on epoch=167
06/18/2022 02:20:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.14 on epoch=168
06/18/2022 02:20:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/18/2022 02:20:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/18/2022 02:20:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/18/2022 02:20:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.11 on epoch=171
06/18/2022 02:20:27 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.7333380052900925 on epoch=171
06/18/2022 02:20:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/18/2022 02:20:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/18/2022 02:20:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=173
06/18/2022 02:20:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/18/2022 02:20:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/18/2022 02:20:47 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7430349749870623 on epoch=174
06/18/2022 02:20:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/18/2022 02:20:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/18/2022 02:20:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/18/2022 02:20:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/18/2022 02:21:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=178
06/18/2022 02:21:06 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7333380052900925 on epoch=178
06/18/2022 02:21:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
06/18/2022 02:21:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
06/18/2022 02:21:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/18/2022 02:21:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.13 on epoch=181
06/18/2022 02:21:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/18/2022 02:21:26 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.6929302891090069 on epoch=182
06/18/2022 02:21:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.09 on epoch=182
06/18/2022 02:21:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/18/2022 02:21:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/18/2022 02:21:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/18/2022 02:21:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/18/2022 02:21:45 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7236789143810017 on epoch=185
06/18/2022 02:21:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=186
06/18/2022 02:21:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=187
06/18/2022 02:21:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/18/2022 02:21:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/18/2022 02:21:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
06/18/2022 02:22:04 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7333380052900925 on epoch=189
06/18/2022 02:22:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/18/2022 02:22:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/18/2022 02:22:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=191
06/18/2022 02:22:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/18/2022 02:22:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/18/2022 02:22:23 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6879043032980845 on epoch=192
06/18/2022 02:22:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=193
06/18/2022 02:22:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/18/2022 02:22:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 02:22:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/18/2022 02:22:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/18/2022 02:22:43 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.6753601976123226 on epoch=196
06/18/2022 02:22:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/18/2022 02:22:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/18/2022 02:22:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=198
06/18/2022 02:22:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/18/2022 02:22:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/18/2022 02:23:02 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7039278710403748 on epoch=199
06/18/2022 02:23:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/18/2022 02:23:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
06/18/2022 02:23:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/18/2022 02:23:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/18/2022 02:23:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/18/2022 02:23:21 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7009015552509013 on epoch=203
06/18/2022 02:23:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/18/2022 02:23:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 02:23:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/18/2022 02:23:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/18/2022 02:23:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/18/2022 02:23:40 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7011625071859812 on epoch=207
06/18/2022 02:23:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/18/2022 02:23:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/18/2022 02:23:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/18/2022 02:23:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/18/2022 02:23:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/18/2022 02:24:00 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7279015228111838 on epoch=210
06/18/2022 02:24:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
06/18/2022 02:24:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/18/2022 02:24:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/18/2022 02:24:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/18/2022 02:24:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/18/2022 02:24:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:24:14 - INFO - __main__ - Printing 3 examples
06/18/2022 02:24:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 02:24:14 - INFO - __main__ - ['Company']
06/18/2022 02:24:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 02:24:14 - INFO - __main__ - ['Company']
06/18/2022 02:24:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 02:24:14 - INFO - __main__ - ['Company']
06/18/2022 02:24:14 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:24:14 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:24:15 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 02:24:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:24:15 - INFO - __main__ - Printing 3 examples
06/18/2022 02:24:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 02:24:15 - INFO - __main__ - ['Company']
06/18/2022 02:24:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 02:24:15 - INFO - __main__ - ['Company']
06/18/2022 02:24:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 02:24:15 - INFO - __main__ - ['Company']
06/18/2022 02:24:15 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:24:15 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:24:15 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 02:24:19 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7356077263098135 on epoch=214
06/18/2022 02:24:19 - INFO - __main__ - save last model!
06/18/2022 02:24:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 02:24:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 02:24:19 - INFO - __main__ - Printing 3 examples
06/18/2022 02:24:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 02:24:19 - INFO - __main__ - ['Animal']
06/18/2022 02:24:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 02:24:19 - INFO - __main__ - ['Animal']
06/18/2022 02:24:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 02:24:19 - INFO - __main__ - ['Village']
06/18/2022 02:24:19 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:24:21 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:24:24 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 02:24:30 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 02:24:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 02:24:31 - INFO - __main__ - Starting training!
06/18/2022 02:26:18 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/18/2022 02:26:18 - INFO - __main__ - Classification-F1 on test data: 0.4669
06/18/2022 02:26:18 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.776077648585741, test_performance=0.4669094101208661
06/18/2022 02:26:18 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/18/2022 02:26:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:26:19 - INFO - __main__ - Printing 3 examples
06/18/2022 02:26:19 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 02:26:19 - INFO - __main__ - ['Company']
06/18/2022 02:26:19 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 02:26:19 - INFO - __main__ - ['Company']
06/18/2022 02:26:19 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 02:26:19 - INFO - __main__ - ['Company']
06/18/2022 02:26:19 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:26:19 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:26:19 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 02:26:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:26:19 - INFO - __main__ - Printing 3 examples
06/18/2022 02:26:19 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 02:26:19 - INFO - __main__ - ['Company']
06/18/2022 02:26:19 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 02:26:19 - INFO - __main__ - ['Company']
06/18/2022 02:26:19 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 02:26:19 - INFO - __main__ - ['Company']
06/18/2022 02:26:19 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:26:20 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:26:20 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 02:26:35 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 02:26:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 02:26:36 - INFO - __main__ - Starting training!
06/18/2022 02:26:39 - INFO - __main__ - Step 10 Global step 10 Train loss 6.25 on epoch=0
06/18/2022 02:26:42 - INFO - __main__ - Step 20 Global step 20 Train loss 4.86 on epoch=1
06/18/2022 02:26:44 - INFO - __main__ - Step 30 Global step 30 Train loss 4.12 on epoch=2
06/18/2022 02:26:47 - INFO - __main__ - Step 40 Global step 40 Train loss 3.73 on epoch=2
06/18/2022 02:26:50 - INFO - __main__ - Step 50 Global step 50 Train loss 3.40 on epoch=3
06/18/2022 02:26:54 - INFO - __main__ - Global step 50 Train loss 4.47 Classification-F1 0.10069255299546831 on epoch=3
06/18/2022 02:26:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10069255299546831 on epoch=3, global_step=50
06/18/2022 02:26:57 - INFO - __main__ - Step 60 Global step 60 Train loss 2.84 on epoch=4
06/18/2022 02:27:00 - INFO - __main__ - Step 70 Global step 70 Train loss 2.45 on epoch=4
06/18/2022 02:27:02 - INFO - __main__ - Step 80 Global step 80 Train loss 2.17 on epoch=5
06/18/2022 02:27:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.97 on epoch=6
06/18/2022 02:27:07 - INFO - __main__ - Step 100 Global step 100 Train loss 1.82 on epoch=7
06/18/2022 02:27:12 - INFO - __main__ - Global step 100 Train loss 2.25 Classification-F1 0.11814507328444412 on epoch=7
06/18/2022 02:27:12 - INFO - __main__ - Saving model with best Classification-F1: 0.10069255299546831 -> 0.11814507328444412 on epoch=7, global_step=100
06/18/2022 02:27:15 - INFO - __main__ - Step 110 Global step 110 Train loss 1.75 on epoch=7
06/18/2022 02:27:18 - INFO - __main__ - Step 120 Global step 120 Train loss 1.46 on epoch=8
06/18/2022 02:27:20 - INFO - __main__ - Step 130 Global step 130 Train loss 1.26 on epoch=9
06/18/2022 02:27:23 - INFO - __main__ - Step 140 Global step 140 Train loss 1.27 on epoch=9
06/18/2022 02:27:25 - INFO - __main__ - Step 150 Global step 150 Train loss 1.10 on epoch=10
06/18/2022 02:27:32 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.25905025257966435 on epoch=10
06/18/2022 02:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.11814507328444412 -> 0.25905025257966435 on epoch=10, global_step=150
06/18/2022 02:27:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.99 on epoch=11
06/18/2022 02:27:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=12
06/18/2022 02:27:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=12
06/18/2022 02:27:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=13
06/18/2022 02:27:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=14
06/18/2022 02:27:52 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.5183390486079749 on epoch=14
06/18/2022 02:27:52 - INFO - __main__ - Saving model with best Classification-F1: 0.25905025257966435 -> 0.5183390486079749 on epoch=14, global_step=200
06/18/2022 02:27:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=14
06/18/2022 02:27:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=15
06/18/2022 02:27:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=16
06/18/2022 02:28:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=17
06/18/2022 02:28:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=17
06/18/2022 02:28:11 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.5107145061014178 on epoch=17
06/18/2022 02:28:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
06/18/2022 02:28:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=19
06/18/2022 02:28:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=19
06/18/2022 02:28:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=20
06/18/2022 02:28:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=21
06/18/2022 02:28:31 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6083611939399416 on epoch=21
06/18/2022 02:28:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5183390486079749 -> 0.6083611939399416 on epoch=21, global_step=300
06/18/2022 02:28:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
06/18/2022 02:28:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=22
06/18/2022 02:28:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
06/18/2022 02:28:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=24
06/18/2022 02:28:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
06/18/2022 02:28:50 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.6438330170777988 on epoch=24
06/18/2022 02:28:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6083611939399416 -> 0.6438330170777988 on epoch=24, global_step=350
06/18/2022 02:28:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/18/2022 02:28:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
06/18/2022 02:28:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=27
06/18/2022 02:29:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=27
06/18/2022 02:29:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=28
06/18/2022 02:29:10 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.6692641199520187 on epoch=28
06/18/2022 02:29:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6438330170777988 -> 0.6692641199520187 on epoch=28, global_step=400
06/18/2022 02:29:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=29
06/18/2022 02:29:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=29
06/18/2022 02:29:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/18/2022 02:29:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=31
06/18/2022 02:29:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/18/2022 02:29:30 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.6372641021217872 on epoch=32
06/18/2022 02:29:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
06/18/2022 02:29:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=33
06/18/2022 02:29:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
06/18/2022 02:29:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=34
06/18/2022 02:29:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
06/18/2022 02:29:49 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6526565464895636 on epoch=35
06/18/2022 02:29:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=36
06/18/2022 02:29:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=37
06/18/2022 02:29:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
06/18/2022 02:29:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/18/2022 02:30:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
06/18/2022 02:30:08 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.7204301075268817 on epoch=39
06/18/2022 02:30:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6692641199520187 -> 0.7204301075268817 on epoch=39, global_step=550
06/18/2022 02:30:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
06/18/2022 02:30:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
06/18/2022 02:30:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=41
06/18/2022 02:30:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
06/18/2022 02:30:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/18/2022 02:30:27 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.71874660584338 on epoch=42
06/18/2022 02:30:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
06/18/2022 02:30:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
06/18/2022 02:30:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/18/2022 02:30:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=45
06/18/2022 02:30:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
06/18/2022 02:30:46 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6794167582143215 on epoch=46
06/18/2022 02:30:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
06/18/2022 02:30:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/18/2022 02:30:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
06/18/2022 02:30:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=49
06/18/2022 02:30:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
06/18/2022 02:31:05 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7135874877810361 on epoch=49
06/18/2022 02:31:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
06/18/2022 02:31:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=51
06/18/2022 02:31:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/18/2022 02:31:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/18/2022 02:31:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/18/2022 02:31:24 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.7310922848557256 on epoch=53
06/18/2022 02:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7204301075268817 -> 0.7310922848557256 on epoch=53, global_step=750
06/18/2022 02:31:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/18/2022 02:31:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
06/18/2022 02:31:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/18/2022 02:31:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=56
06/18/2022 02:31:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
06/18/2022 02:31:43 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8311507936507936 on epoch=57
06/18/2022 02:31:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7310922848557256 -> 0.8311507936507936 on epoch=57, global_step=800
06/18/2022 02:31:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
06/18/2022 02:31:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/18/2022 02:31:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/18/2022 02:31:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/18/2022 02:31:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/18/2022 02:32:01 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.8894117647058823 on epoch=60
06/18/2022 02:32:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8311507936507936 -> 0.8894117647058823 on epoch=60, global_step=850
06/18/2022 02:32:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/18/2022 02:32:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=62
06/18/2022 02:32:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/18/2022 02:32:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/18/2022 02:32:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/18/2022 02:32:20 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.7310227344183201 on epoch=64
06/18/2022 02:32:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/18/2022 02:32:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
06/18/2022 02:32:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/18/2022 02:32:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/18/2022 02:32:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
06/18/2022 02:32:39 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.6756938246419313 on epoch=67
06/18/2022 02:32:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/18/2022 02:32:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/18/2022 02:32:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/18/2022 02:32:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/18/2022 02:32:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/18/2022 02:32:58 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7569544911480395 on epoch=71
06/18/2022 02:33:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/18/2022 02:33:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/18/2022 02:33:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/18/2022 02:33:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
06/18/2022 02:33:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=74
06/18/2022 02:33:16 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.8177103099304238 on epoch=74
06/18/2022 02:33:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/18/2022 02:33:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/18/2022 02:33:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/18/2022 02:33:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/18/2022 02:33:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/18/2022 02:33:35 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8709677419354839 on epoch=78
06/18/2022 02:33:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/18/2022 02:33:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/18/2022 02:33:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/18/2022 02:33:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/18/2022 02:33:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/18/2022 02:33:54 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7507709162688125 on epoch=82
06/18/2022 02:33:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/18/2022 02:33:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/18/2022 02:34:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/18/2022 02:34:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/18/2022 02:34:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/18/2022 02:34:13 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7632873038879713 on epoch=85
06/18/2022 02:34:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/18/2022 02:34:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/18/2022 02:34:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/18/2022 02:34:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/18/2022 02:34:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/18/2022 02:34:31 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8631514235092864 on epoch=89
06/18/2022 02:34:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/18/2022 02:34:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/18/2022 02:34:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/18/2022 02:34:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/18/2022 02:34:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/18/2022 02:34:50 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7613757148796082 on epoch=92
06/18/2022 02:34:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/18/2022 02:34:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/18/2022 02:34:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/18/2022 02:35:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/18/2022 02:35:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/18/2022 02:35:09 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7576257001660226 on epoch=96
06/18/2022 02:35:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/18/2022 02:35:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/18/2022 02:35:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
06/18/2022 02:35:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/18/2022 02:35:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/18/2022 02:35:27 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.721303308833313 on epoch=99
06/18/2022 02:35:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/18/2022 02:35:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/18/2022 02:35:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/18/2022 02:35:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/18/2022 02:35:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/18/2022 02:35:46 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7079671838336118 on epoch=103
06/18/2022 02:35:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/18/2022 02:35:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/18/2022 02:35:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/18/2022 02:35:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/18/2022 02:35:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/18/2022 02:36:05 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8058719822239747 on epoch=107
06/18/2022 02:36:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/18/2022 02:36:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/18/2022 02:36:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/18/2022 02:36:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/18/2022 02:36:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/18/2022 02:36:23 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.757903492657386 on epoch=110
06/18/2022 02:36:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/18/2022 02:36:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/18/2022 02:36:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/18/2022 02:36:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/18/2022 02:36:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/18/2022 02:36:42 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8081865570578519 on epoch=114
06/18/2022 02:36:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/18/2022 02:36:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/18/2022 02:36:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/18/2022 02:36:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/18/2022 02:36:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/18/2022 02:37:01 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7980042583319099 on epoch=117
06/18/2022 02:37:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/18/2022 02:37:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/18/2022 02:37:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/18/2022 02:37:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/18/2022 02:37:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/18/2022 02:37:20 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9228413163897036 on epoch=121
06/18/2022 02:37:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8894117647058823 -> 0.9228413163897036 on epoch=121, global_step=1700
06/18/2022 02:37:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/18/2022 02:37:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/18/2022 02:37:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/18/2022 02:37:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/18/2022 02:37:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/18/2022 02:37:39 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=124
06/18/2022 02:37:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/18/2022 02:37:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/18/2022 02:37:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
06/18/2022 02:37:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/18/2022 02:37:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/18/2022 02:37:58 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9910627007401202 on epoch=128
06/18/2022 02:37:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9228413163897036 -> 0.9910627007401202 on epoch=128, global_step=1800
06/18/2022 02:38:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=129
06/18/2022 02:38:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/18/2022 02:38:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/18/2022 02:38:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/18/2022 02:38:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/18/2022 02:38:17 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.99553135037006 on epoch=132
06/18/2022 02:38:17 - INFO - __main__ - Saving model with best Classification-F1: 0.9910627007401202 -> 0.99553135037006 on epoch=132, global_step=1850
06/18/2022 02:38:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/18/2022 02:38:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/18/2022 02:38:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/18/2022 02:38:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/18/2022 02:38:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/18/2022 02:38:36 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9821297653958945 on epoch=135
06/18/2022 02:38:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/18/2022 02:38:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
06/18/2022 02:38:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/18/2022 02:38:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/18/2022 02:38:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/18/2022 02:38:55 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9910627007401202 on epoch=139
06/18/2022 02:38:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/18/2022 02:39:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/18/2022 02:39:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/18/2022 02:39:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/18/2022 02:39:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/18/2022 02:39:14 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=142
06/18/2022 02:39:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/18/2022 02:39:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/18/2022 02:39:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/18/2022 02:39:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/18/2022 02:39:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/18/2022 02:39:33 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9270120560443141 on epoch=146
06/18/2022 02:39:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/18/2022 02:39:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/18/2022 02:39:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 02:39:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/18/2022 02:39:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/18/2022 02:39:52 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.99553135037006 on epoch=149
06/18/2022 02:39:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/18/2022 02:39:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/18/2022 02:40:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/18/2022 02:40:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/18/2022 02:40:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/18/2022 02:40:12 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9228413163897033 on epoch=153
06/18/2022 02:40:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/18/2022 02:40:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/18/2022 02:40:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/18/2022 02:40:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/18/2022 02:40:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/18/2022 02:40:31 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.99553135037006 on epoch=157
06/18/2022 02:40:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/18/2022 02:40:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/18/2022 02:40:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/18/2022 02:40:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/18/2022 02:40:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/18/2022 02:40:50 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=160
06/18/2022 02:40:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/18/2022 02:40:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/18/2022 02:40:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/18/2022 02:41:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/18/2022 02:41:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/18/2022 02:41:10 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=164
06/18/2022 02:41:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/18/2022 02:41:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/18/2022 02:41:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/18/2022 02:41:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/18/2022 02:41:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/18/2022 02:41:29 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.99553135037006 on epoch=167
06/18/2022 02:41:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/18/2022 02:41:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/18/2022 02:41:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/18/2022 02:41:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/18/2022 02:41:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/18/2022 02:41:49 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=171
06/18/2022 02:41:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=172
06/18/2022 02:41:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/18/2022 02:41:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/18/2022 02:41:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/18/2022 02:42:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=174
06/18/2022 02:42:09 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9270120560443141 on epoch=174
06/18/2022 02:42:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/18/2022 02:42:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/18/2022 02:42:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/18/2022 02:42:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/18/2022 02:42:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/18/2022 02:42:28 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 1.0 on epoch=178
06/18/2022 02:42:28 - INFO - __main__ - Saving model with best Classification-F1: 0.99553135037006 -> 1.0 on epoch=178, global_step=2500
06/18/2022 02:42:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 02:42:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/18/2022 02:42:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/18/2022 02:42:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/18/2022 02:42:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/18/2022 02:42:47 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.99553135037006 on epoch=182
06/18/2022 02:42:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/18/2022 02:42:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
06/18/2022 02:42:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/18/2022 02:42:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 02:43:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/18/2022 02:43:07 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.99553135037006 on epoch=185
06/18/2022 02:43:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/18/2022 02:43:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/18/2022 02:43:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/18/2022 02:43:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/18/2022 02:43:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/18/2022 02:43:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9154680445003026 on epoch=189
06/18/2022 02:43:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/18/2022 02:43:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/18/2022 02:43:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/18/2022 02:43:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/18/2022 02:43:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/18/2022 02:43:46 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9085942707701089 on epoch=192
06/18/2022 02:43:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/18/2022 02:43:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/18/2022 02:43:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/18/2022 02:43:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/18/2022 02:43:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/18/2022 02:44:06 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8649071358748779 on epoch=196
06/18/2022 02:44:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/18/2022 02:44:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/18/2022 02:44:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/18/2022 02:44:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/18/2022 02:44:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/18/2022 02:44:25 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8570908174486804 on epoch=199
06/18/2022 02:44:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/18/2022 02:44:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/18/2022 02:44:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/18/2022 02:44:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 02:44:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/18/2022 02:44:45 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9205474095796676 on epoch=203
06/18/2022 02:44:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/18/2022 02:44:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/18/2022 02:44:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/18/2022 02:44:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/18/2022 02:44:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 02:45:04 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=207
06/18/2022 02:45:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/18/2022 02:45:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/18/2022 02:45:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/18/2022 02:45:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 02:45:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/18/2022 02:45:24 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=210
06/18/2022 02:45:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 02:45:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/18/2022 02:45:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/18/2022 02:45:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/18/2022 02:45:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/18/2022 02:45:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:45:38 - INFO - __main__ - Printing 3 examples
06/18/2022 02:45:38 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 02:45:38 - INFO - __main__ - ['Company']
06/18/2022 02:45:38 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 02:45:38 - INFO - __main__ - ['Company']
06/18/2022 02:45:38 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 02:45:38 - INFO - __main__ - ['Company']
06/18/2022 02:45:38 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:45:38 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:45:39 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 02:45:39 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:45:39 - INFO - __main__ - Printing 3 examples
06/18/2022 02:45:39 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 02:45:39 - INFO - __main__ - ['Company']
06/18/2022 02:45:39 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 02:45:39 - INFO - __main__ - ['Company']
06/18/2022 02:45:39 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 02:45:39 - INFO - __main__ - ['Company']
06/18/2022 02:45:39 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:45:39 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:45:39 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 02:45:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=214
06/18/2022 02:45:43 - INFO - __main__ - save last model!
06/18/2022 02:45:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 02:45:43 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 02:45:43 - INFO - __main__ - Printing 3 examples
06/18/2022 02:45:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 02:45:43 - INFO - __main__ - ['Animal']
06/18/2022 02:45:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 02:45:43 - INFO - __main__ - ['Animal']
06/18/2022 02:45:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 02:45:43 - INFO - __main__ - ['Village']
06/18/2022 02:45:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:45:45 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:45:49 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 02:45:58 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 02:45:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 02:45:59 - INFO - __main__ - Starting training!
06/18/2022 02:47:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/18/2022 02:47:57 - INFO - __main__ - Classification-F1 on test data: 0.5451
06/18/2022 02:47:58 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=1.0, test_performance=0.5451495855541265
06/18/2022 02:47:58 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/18/2022 02:47:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:47:59 - INFO - __main__ - Printing 3 examples
06/18/2022 02:47:59 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 02:47:59 - INFO - __main__ - ['Company']
06/18/2022 02:47:59 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 02:47:59 - INFO - __main__ - ['Company']
06/18/2022 02:47:59 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 02:47:59 - INFO - __main__ - ['Company']
06/18/2022 02:47:59 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:47:59 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:47:59 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 02:47:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 02:47:59 - INFO - __main__ - Printing 3 examples
06/18/2022 02:47:59 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 02:47:59 - INFO - __main__ - ['Company']
06/18/2022 02:47:59 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 02:47:59 - INFO - __main__ - ['Company']
06/18/2022 02:47:59 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 02:47:59 - INFO - __main__ - ['Company']
06/18/2022 02:47:59 - INFO - __main__ - Tokenizing Input ...
06/18/2022 02:47:59 - INFO - __main__ - Tokenizing Output ...
06/18/2022 02:47:59 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 02:48:14 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 02:48:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 02:48:15 - INFO - __main__ - Starting training!
06/18/2022 02:48:18 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=0
06/18/2022 02:48:21 - INFO - __main__ - Step 20 Global step 20 Train loss 4.85 on epoch=1
06/18/2022 02:48:24 - INFO - __main__ - Step 30 Global step 30 Train loss 4.62 on epoch=2
06/18/2022 02:48:26 - INFO - __main__ - Step 40 Global step 40 Train loss 4.09 on epoch=2
06/18/2022 02:48:29 - INFO - __main__ - Step 50 Global step 50 Train loss 3.60 on epoch=3
06/18/2022 02:48:34 - INFO - __main__ - Global step 50 Train loss 4.75 Classification-F1 0.06470518887976193 on epoch=3
06/18/2022 02:48:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06470518887976193 on epoch=3, global_step=50
06/18/2022 02:48:36 - INFO - __main__ - Step 60 Global step 60 Train loss 3.25 on epoch=4
06/18/2022 02:48:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.76 on epoch=4
06/18/2022 02:48:42 - INFO - __main__ - Step 80 Global step 80 Train loss 2.63 on epoch=5
06/18/2022 02:48:44 - INFO - __main__ - Step 90 Global step 90 Train loss 2.30 on epoch=6
06/18/2022 02:48:47 - INFO - __main__ - Step 100 Global step 100 Train loss 2.26 on epoch=7
06/18/2022 02:48:52 - INFO - __main__ - Global step 100 Train loss 2.64 Classification-F1 0.10012121774349166 on epoch=7
06/18/2022 02:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.06470518887976193 -> 0.10012121774349166 on epoch=7, global_step=100
06/18/2022 02:48:54 - INFO - __main__ - Step 110 Global step 110 Train loss 1.99 on epoch=7
06/18/2022 02:48:57 - INFO - __main__ - Step 120 Global step 120 Train loss 1.92 on epoch=8
06/18/2022 02:48:59 - INFO - __main__ - Step 130 Global step 130 Train loss 1.79 on epoch=9
06/18/2022 02:49:02 - INFO - __main__ - Step 140 Global step 140 Train loss 1.58 on epoch=9
06/18/2022 02:49:05 - INFO - __main__ - Step 150 Global step 150 Train loss 1.54 on epoch=10
06/18/2022 02:49:10 - INFO - __main__ - Global step 150 Train loss 1.76 Classification-F1 0.13968205795642238 on epoch=10
06/18/2022 02:49:10 - INFO - __main__ - Saving model with best Classification-F1: 0.10012121774349166 -> 0.13968205795642238 on epoch=10, global_step=150
06/18/2022 02:49:13 - INFO - __main__ - Step 160 Global step 160 Train loss 1.24 on epoch=11
06/18/2022 02:49:15 - INFO - __main__ - Step 170 Global step 170 Train loss 1.44 on epoch=12
06/18/2022 02:49:18 - INFO - __main__ - Step 180 Global step 180 Train loss 1.17 on epoch=12
06/18/2022 02:49:21 - INFO - __main__ - Step 190 Global step 190 Train loss 1.07 on epoch=13
06/18/2022 02:49:23 - INFO - __main__ - Step 200 Global step 200 Train loss 1.06 on epoch=14
06/18/2022 02:49:29 - INFO - __main__ - Global step 200 Train loss 1.20 Classification-F1 0.31124668337211886 on epoch=14
06/18/2022 02:49:29 - INFO - __main__ - Saving model with best Classification-F1: 0.13968205795642238 -> 0.31124668337211886 on epoch=14, global_step=200
06/18/2022 02:49:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.97 on epoch=14
06/18/2022 02:49:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.90 on epoch=15
06/18/2022 02:49:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=16
06/18/2022 02:49:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=17
06/18/2022 02:49:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.68 on epoch=17
06/18/2022 02:49:49 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.5087260990872672 on epoch=17
06/18/2022 02:49:49 - INFO - __main__ - Saving model with best Classification-F1: 0.31124668337211886 -> 0.5087260990872672 on epoch=17, global_step=250
06/18/2022 02:49:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=18
06/18/2022 02:49:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.70 on epoch=19
06/18/2022 02:49:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=19
06/18/2022 02:49:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=20
06/18/2022 02:50:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=21
06/18/2022 02:50:08 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.49852722127900395 on epoch=21
06/18/2022 02:50:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=22
06/18/2022 02:50:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=22
06/18/2022 02:50:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/18/2022 02:50:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=24
06/18/2022 02:50:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=24
06/18/2022 02:50:27 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.5552824023427725 on epoch=24
06/18/2022 02:50:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5087260990872672 -> 0.5552824023427725 on epoch=24, global_step=350
06/18/2022 02:50:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=25
06/18/2022 02:50:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.41 on epoch=26
06/18/2022 02:50:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/18/2022 02:50:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=27
06/18/2022 02:50:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=28
06/18/2022 02:50:46 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.6578853046594982 on epoch=28
06/18/2022 02:50:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5552824023427725 -> 0.6578853046594982 on epoch=28, global_step=400
06/18/2022 02:50:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=29
06/18/2022 02:50:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=29
06/18/2022 02:50:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=30
06/18/2022 02:50:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=31
06/18/2022 02:50:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
06/18/2022 02:51:06 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.7309836718438869 on epoch=32
06/18/2022 02:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6578853046594982 -> 0.7309836718438869 on epoch=32, global_step=450
06/18/2022 02:51:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=32
06/18/2022 02:51:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/18/2022 02:51:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
06/18/2022 02:51:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/18/2022 02:51:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=35
06/18/2022 02:51:25 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6892181578089898 on epoch=35
06/18/2022 02:51:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=36
06/18/2022 02:51:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=37
06/18/2022 02:51:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
06/18/2022 02:51:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=38
06/18/2022 02:51:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=39
06/18/2022 02:51:44 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.7967914438502673 on epoch=39
06/18/2022 02:51:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7309836718438869 -> 0.7967914438502673 on epoch=39, global_step=550
06/18/2022 02:51:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
06/18/2022 02:51:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=40
06/18/2022 02:51:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
06/18/2022 02:51:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/18/2022 02:51:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=42
06/18/2022 02:52:03 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7734280202120286 on epoch=42
06/18/2022 02:52:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
06/18/2022 02:52:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
06/18/2022 02:52:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/18/2022 02:52:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=45
06/18/2022 02:52:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=46
06/18/2022 02:52:23 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.7967914438502673 on epoch=46
06/18/2022 02:52:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
06/18/2022 02:52:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
06/18/2022 02:52:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/18/2022 02:52:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
06/18/2022 02:52:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
06/18/2022 02:52:42 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7853569580324798 on epoch=49
06/18/2022 02:52:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/18/2022 02:52:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
06/18/2022 02:52:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/18/2022 02:52:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=52
06/18/2022 02:52:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/18/2022 02:53:01 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.7740977133766507 on epoch=53
06/18/2022 02:53:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/18/2022 02:53:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/18/2022 02:53:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=55
06/18/2022 02:53:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
06/18/2022 02:53:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/18/2022 02:53:20 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7258245537815431 on epoch=57
06/18/2022 02:53:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/18/2022 02:53:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/18/2022 02:53:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/18/2022 02:53:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/18/2022 02:53:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/18/2022 02:53:39 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.8305355179095099 on epoch=60
06/18/2022 02:53:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7967914438502673 -> 0.8305355179095099 on epoch=60, global_step=850
06/18/2022 02:53:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
06/18/2022 02:53:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/18/2022 02:53:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/18/2022 02:53:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/18/2022 02:53:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
06/18/2022 02:53:58 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8363357073034492 on epoch=64
06/18/2022 02:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8305355179095099 -> 0.8363357073034492 on epoch=64, global_step=900
06/18/2022 02:54:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=64
06/18/2022 02:54:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/18/2022 02:54:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/18/2022 02:54:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/18/2022 02:54:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/18/2022 02:54:17 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.6958405428604696 on epoch=67
06/18/2022 02:54:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/18/2022 02:54:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/18/2022 02:54:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/18/2022 02:54:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/18/2022 02:54:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/18/2022 02:54:36 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7538720538720539 on epoch=71
06/18/2022 02:54:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
06/18/2022 02:54:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=72
06/18/2022 02:54:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/18/2022 02:54:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/18/2022 02:54:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/18/2022 02:54:55 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7631651502619244 on epoch=74
06/18/2022 02:54:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
06/18/2022 02:55:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/18/2022 02:55:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
06/18/2022 02:55:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/18/2022 02:55:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/18/2022 02:55:14 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7229985634060337 on epoch=78
06/18/2022 02:55:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/18/2022 02:55:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/18/2022 02:55:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
06/18/2022 02:55:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/18/2022 02:55:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
06/18/2022 02:55:33 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.9865800865800866 on epoch=82
06/18/2022 02:55:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8363357073034492 -> 0.9865800865800866 on epoch=82, global_step=1150
06/18/2022 02:55:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/18/2022 02:55:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/18/2022 02:55:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/18/2022 02:55:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/18/2022 02:55:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/18/2022 02:55:52 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8591107649071359 on epoch=85
06/18/2022 02:55:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/18/2022 02:55:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/18/2022 02:56:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/18/2022 02:56:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/18/2022 02:56:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/18/2022 02:56:11 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.8043771535232636 on epoch=89
06/18/2022 02:56:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/18/2022 02:56:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/18/2022 02:56:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/18/2022 02:56:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/18/2022 02:56:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/18/2022 02:56:29 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7507709162688125 on epoch=92
06/18/2022 02:56:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/18/2022 02:56:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/18/2022 02:56:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/18/2022 02:56:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/18/2022 02:56:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/18/2022 02:56:48 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8527606046507257 on epoch=96
06/18/2022 02:56:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/18/2022 02:56:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/18/2022 02:56:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/18/2022 02:56:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/18/2022 02:57:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/18/2022 02:57:07 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8535934784674704 on epoch=99
06/18/2022 02:57:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/18/2022 02:57:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/18/2022 02:57:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/18/2022 02:57:17 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/18/2022 02:57:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/18/2022 02:57:26 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.80954845281221 on epoch=103
06/18/2022 02:57:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/18/2022 02:57:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/18/2022 02:57:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/18/2022 02:57:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/18/2022 02:57:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/18/2022 02:57:45 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8607181643324232 on epoch=107
06/18/2022 02:57:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/18/2022 02:57:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/18/2022 02:57:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/18/2022 02:57:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
06/18/2022 02:57:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/18/2022 02:58:05 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8070585679693839 on epoch=110
06/18/2022 02:58:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/18/2022 02:58:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/18/2022 02:58:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/18/2022 02:58:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/18/2022 02:58:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/18/2022 02:58:24 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.916384815900945 on epoch=114
06/18/2022 02:58:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/18/2022 02:58:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/18/2022 02:58:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/18/2022 02:58:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/18/2022 02:58:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/18/2022 02:58:44 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8607181643324232 on epoch=117
06/18/2022 02:58:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/18/2022 02:58:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/18/2022 02:58:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/18/2022 02:58:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/18/2022 02:58:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
06/18/2022 02:59:03 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6581311027681995 on epoch=121
06/18/2022 02:59:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/18/2022 02:59:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/18/2022 02:59:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/18/2022 02:59:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/18/2022 02:59:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/18/2022 02:59:22 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6328711610969675 on epoch=124
06/18/2022 02:59:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/18/2022 02:59:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/18/2022 02:59:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
06/18/2022 02:59:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/18/2022 02:59:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/18/2022 02:59:42 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7076798688640794 on epoch=128
06/18/2022 02:59:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/18/2022 02:59:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/18/2022 02:59:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/18/2022 02:59:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/18/2022 02:59:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/18/2022 03:00:01 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8606913455037187 on epoch=132
06/18/2022 03:00:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/18/2022 03:00:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/18/2022 03:00:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/18/2022 03:00:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/18/2022 03:00:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/18/2022 03:00:20 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8031576266870384 on epoch=135
06/18/2022 03:00:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/18/2022 03:00:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/18/2022 03:00:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/18/2022 03:00:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/18/2022 03:00:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/18/2022 03:00:39 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.703962703962704 on epoch=139
06/18/2022 03:00:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/18/2022 03:00:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/18/2022 03:00:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/18/2022 03:00:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/18/2022 03:00:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/18/2022 03:00:58 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6745621276871276 on epoch=142
06/18/2022 03:01:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/18/2022 03:01:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/18/2022 03:01:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/18/2022 03:01:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/18/2022 03:01:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/18/2022 03:01:17 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7122899737500756 on epoch=146
06/18/2022 03:01:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/18/2022 03:01:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/18/2022 03:01:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 03:01:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/18/2022 03:01:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/18/2022 03:01:37 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7475517075517075 on epoch=149
06/18/2022 03:01:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/18/2022 03:01:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/18/2022 03:01:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/18/2022 03:01:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/18/2022 03:01:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/18/2022 03:01:56 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8137641546658102 on epoch=153
06/18/2022 03:01:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/18/2022 03:02:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/18/2022 03:02:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/18/2022 03:02:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/18/2022 03:02:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
06/18/2022 03:02:16 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8583734813573524 on epoch=157
06/18/2022 03:02:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/18/2022 03:02:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/18/2022 03:02:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/18/2022 03:02:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/18/2022 03:02:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/18/2022 03:02:36 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7548999657515291 on epoch=160
06/18/2022 03:02:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/18/2022 03:02:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/18/2022 03:02:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/18/2022 03:02:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/18/2022 03:02:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/18/2022 03:02:56 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7386597456041899 on epoch=164
06/18/2022 03:02:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/18/2022 03:03:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/18/2022 03:03:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/18/2022 03:03:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/18/2022 03:03:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/18/2022 03:03:16 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7016161808781947 on epoch=167
06/18/2022 03:03:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/18/2022 03:03:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/18/2022 03:03:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/18/2022 03:03:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/18/2022 03:03:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/18/2022 03:03:36 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8587020353001652 on epoch=171
06/18/2022 03:03:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/18/2022 03:03:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/18/2022 03:03:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 03:03:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/18/2022 03:03:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/18/2022 03:03:56 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9141778066604672 on epoch=174
06/18/2022 03:03:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/18/2022 03:04:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/18/2022 03:04:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/18/2022 03:04:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/18/2022 03:04:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/18/2022 03:04:15 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=178
06/18/2022 03:04:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 03:04:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/18/2022 03:04:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/18/2022 03:04:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/18/2022 03:04:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/18/2022 03:04:35 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8569602272727272 on epoch=182
06/18/2022 03:04:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/18/2022 03:04:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/18/2022 03:04:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 03:04:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 03:04:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/18/2022 03:04:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9866027789414886 on epoch=185
06/18/2022 03:04:55 - INFO - __main__ - Saving model with best Classification-F1: 0.9865800865800866 -> 0.9866027789414886 on epoch=185, global_step=2600
06/18/2022 03:04:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=186
06/18/2022 03:05:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/18/2022 03:05:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/18/2022 03:05:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/18/2022 03:05:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/18/2022 03:05:15 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9270120560443141 on epoch=189
06/18/2022 03:05:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/18/2022 03:05:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/18/2022 03:05:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/18/2022 03:05:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 03:05:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/18/2022 03:05:35 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9247181492342783 on epoch=192
06/18/2022 03:05:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/18/2022 03:05:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 03:05:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 03:05:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/18/2022 03:05:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/18/2022 03:05:55 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9270120560443141 on epoch=196
06/18/2022 03:05:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/18/2022 03:06:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/18/2022 03:06:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/18/2022 03:06:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/18/2022 03:06:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/18/2022 03:06:15 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9311827956989248 on epoch=199
06/18/2022 03:06:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/18/2022 03:06:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/18/2022 03:06:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 03:06:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 03:06:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/18/2022 03:06:34 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 1.0 on epoch=203
06/18/2022 03:06:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9866027789414886 -> 1.0 on epoch=203, global_step=2850
06/18/2022 03:06:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/18/2022 03:06:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 03:06:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/18/2022 03:06:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/18/2022 03:06:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 03:06:54 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=207
06/18/2022 03:06:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/18/2022 03:06:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/18/2022 03:07:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/18/2022 03:07:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 03:07:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/18/2022 03:07:14 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=210
06/18/2022 03:07:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/18/2022 03:07:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/18/2022 03:07:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/18/2022 03:07:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/18/2022 03:07:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/18/2022 03:07:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:07:29 - INFO - __main__ - Printing 3 examples
06/18/2022 03:07:29 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 03:07:29 - INFO - __main__ - ['Company']
06/18/2022 03:07:29 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 03:07:29 - INFO - __main__ - ['Company']
06/18/2022 03:07:29 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 03:07:29 - INFO - __main__ - ['Company']
06/18/2022 03:07:29 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:07:29 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:07:29 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 03:07:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:07:29 - INFO - __main__ - Printing 3 examples
06/18/2022 03:07:29 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 03:07:29 - INFO - __main__ - ['Company']
06/18/2022 03:07:29 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 03:07:29 - INFO - __main__ - ['Company']
06/18/2022 03:07:29 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 03:07:29 - INFO - __main__ - ['Company']
06/18/2022 03:07:29 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:07:29 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:07:29 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 03:07:34 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=214
06/18/2022 03:07:34 - INFO - __main__ - save last model!
06/18/2022 03:07:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 03:07:34 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 03:07:34 - INFO - __main__ - Printing 3 examples
06/18/2022 03:07:34 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 03:07:34 - INFO - __main__ - ['Animal']
06/18/2022 03:07:34 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 03:07:34 - INFO - __main__ - ['Animal']
06/18/2022 03:07:34 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 03:07:34 - INFO - __main__ - ['Village']
06/18/2022 03:07:34 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:07:36 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:07:39 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 03:07:48 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 03:07:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 03:07:49 - INFO - __main__ - Starting training!
06/18/2022 03:10:10 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/18/2022 03:10:10 - INFO - __main__ - Classification-F1 on test data: 0.4825
06/18/2022 03:10:10 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=1.0, test_performance=0.4824738129606215
06/18/2022 03:10:10 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/18/2022 03:10:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:10:11 - INFO - __main__ - Printing 3 examples
06/18/2022 03:10:11 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 03:10:11 - INFO - __main__ - ['Company']
06/18/2022 03:10:11 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 03:10:11 - INFO - __main__ - ['Company']
06/18/2022 03:10:11 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 03:10:11 - INFO - __main__ - ['Company']
06/18/2022 03:10:11 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:10:11 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:10:11 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 03:10:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:10:11 - INFO - __main__ - Printing 3 examples
06/18/2022 03:10:11 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 03:10:11 - INFO - __main__ - ['Company']
06/18/2022 03:10:11 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 03:10:11 - INFO - __main__ - ['Company']
06/18/2022 03:10:11 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 03:10:11 - INFO - __main__ - ['Company']
06/18/2022 03:10:11 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:10:11 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:10:12 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 03:10:27 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 03:10:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 03:10:28 - INFO - __main__ - Starting training!
06/18/2022 03:10:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.52 on epoch=0
06/18/2022 03:10:34 - INFO - __main__ - Step 20 Global step 20 Train loss 5.23 on epoch=1
06/18/2022 03:10:36 - INFO - __main__ - Step 30 Global step 30 Train loss 4.81 on epoch=2
06/18/2022 03:10:39 - INFO - __main__ - Step 40 Global step 40 Train loss 4.34 on epoch=2
06/18/2022 03:10:41 - INFO - __main__ - Step 50 Global step 50 Train loss 4.07 on epoch=3
06/18/2022 03:10:47 - INFO - __main__ - Global step 50 Train loss 4.99 Classification-F1 0.048105358529931586 on epoch=3
06/18/2022 03:10:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.048105358529931586 on epoch=3, global_step=50
06/18/2022 03:10:49 - INFO - __main__ - Step 60 Global step 60 Train loss 3.55 on epoch=4
06/18/2022 03:10:52 - INFO - __main__ - Step 70 Global step 70 Train loss 3.23 on epoch=4
06/18/2022 03:10:54 - INFO - __main__ - Step 80 Global step 80 Train loss 3.09 on epoch=5
06/18/2022 03:10:57 - INFO - __main__ - Step 90 Global step 90 Train loss 2.66 on epoch=6
06/18/2022 03:10:59 - INFO - __main__ - Step 100 Global step 100 Train loss 2.56 on epoch=7
06/18/2022 03:11:05 - INFO - __main__ - Global step 100 Train loss 3.02 Classification-F1 0.09228751780933944 on epoch=7
06/18/2022 03:11:05 - INFO - __main__ - Saving model with best Classification-F1: 0.048105358529931586 -> 0.09228751780933944 on epoch=7, global_step=100
06/18/2022 03:11:08 - INFO - __main__ - Step 110 Global step 110 Train loss 2.48 on epoch=7
06/18/2022 03:11:10 - INFO - __main__ - Step 120 Global step 120 Train loss 2.20 on epoch=8
06/18/2022 03:11:13 - INFO - __main__ - Step 130 Global step 130 Train loss 2.09 on epoch=9
06/18/2022 03:11:15 - INFO - __main__ - Step 140 Global step 140 Train loss 1.97 on epoch=9
06/18/2022 03:11:18 - INFO - __main__ - Step 150 Global step 150 Train loss 1.89 on epoch=10
06/18/2022 03:11:23 - INFO - __main__ - Global step 150 Train loss 2.13 Classification-F1 0.1022598222405637 on epoch=10
06/18/2022 03:11:23 - INFO - __main__ - Saving model with best Classification-F1: 0.09228751780933944 -> 0.1022598222405637 on epoch=10, global_step=150
06/18/2022 03:11:26 - INFO - __main__ - Step 160 Global step 160 Train loss 1.69 on epoch=11
06/18/2022 03:11:28 - INFO - __main__ - Step 170 Global step 170 Train loss 1.72 on epoch=12
06/18/2022 03:11:31 - INFO - __main__ - Step 180 Global step 180 Train loss 1.60 on epoch=12
06/18/2022 03:11:33 - INFO - __main__ - Step 190 Global step 190 Train loss 1.45 on epoch=13
06/18/2022 03:11:36 - INFO - __main__ - Step 200 Global step 200 Train loss 1.33 on epoch=14
06/18/2022 03:11:42 - INFO - __main__ - Global step 200 Train loss 1.56 Classification-F1 0.16140396151669495 on epoch=14
06/18/2022 03:11:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1022598222405637 -> 0.16140396151669495 on epoch=14, global_step=200
06/18/2022 03:11:44 - INFO - __main__ - Step 210 Global step 210 Train loss 1.24 on epoch=14
06/18/2022 03:11:47 - INFO - __main__ - Step 220 Global step 220 Train loss 1.20 on epoch=15
06/18/2022 03:11:49 - INFO - __main__ - Step 230 Global step 230 Train loss 1.11 on epoch=16
06/18/2022 03:11:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.97 on epoch=17
06/18/2022 03:11:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.95 on epoch=17
06/18/2022 03:12:01 - INFO - __main__ - Global step 250 Train loss 1.09 Classification-F1 0.29950238486199077 on epoch=17
06/18/2022 03:12:01 - INFO - __main__ - Saving model with best Classification-F1: 0.16140396151669495 -> 0.29950238486199077 on epoch=17, global_step=250
06/18/2022 03:12:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.86 on epoch=18
06/18/2022 03:12:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.95 on epoch=19
06/18/2022 03:12:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.75 on epoch=19
06/18/2022 03:12:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.85 on epoch=20
06/18/2022 03:12:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=21
06/18/2022 03:12:20 - INFO - __main__ - Global step 300 Train loss 0.83 Classification-F1 0.5032910975770549 on epoch=21
06/18/2022 03:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.29950238486199077 -> 0.5032910975770549 on epoch=21, global_step=300
06/18/2022 03:12:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=22
06/18/2022 03:12:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.66 on epoch=22
06/18/2022 03:12:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.62 on epoch=23
06/18/2022 03:12:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=24
06/18/2022 03:12:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=24
06/18/2022 03:12:39 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.514877814683154 on epoch=24
06/18/2022 03:12:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5032910975770549 -> 0.514877814683154 on epoch=24, global_step=350
06/18/2022 03:12:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.53 on epoch=25
06/18/2022 03:12:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.54 on epoch=26
06/18/2022 03:12:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.57 on epoch=27
06/18/2022 03:12:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
06/18/2022 03:12:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=28
06/18/2022 03:12:59 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.5070029325513197 on epoch=28
06/18/2022 03:13:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=29
06/18/2022 03:13:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=29
06/18/2022 03:13:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=30
06/18/2022 03:13:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=31
06/18/2022 03:13:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=32
06/18/2022 03:13:18 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.5485566949802573 on epoch=32
06/18/2022 03:13:18 - INFO - __main__ - Saving model with best Classification-F1: 0.514877814683154 -> 0.5485566949802573 on epoch=32, global_step=450
06/18/2022 03:13:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=32
06/18/2022 03:13:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=33
06/18/2022 03:13:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=34
06/18/2022 03:13:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
06/18/2022 03:13:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=35
06/18/2022 03:13:37 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.6159754224270353 on epoch=35
06/18/2022 03:13:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5485566949802573 -> 0.6159754224270353 on epoch=35, global_step=500
06/18/2022 03:13:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
06/18/2022 03:13:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=37
06/18/2022 03:13:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=37
06/18/2022 03:13:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=38
06/18/2022 03:13:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=39
06/18/2022 03:13:56 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6404996837444655 on epoch=39
06/18/2022 03:13:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6159754224270353 -> 0.6404996837444655 on epoch=39, global_step=550
06/18/2022 03:13:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
06/18/2022 03:14:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=40
06/18/2022 03:14:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/18/2022 03:14:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=42
06/18/2022 03:14:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=42
06/18/2022 03:14:15 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.6424884792626728 on epoch=42
06/18/2022 03:14:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6404996837444655 -> 0.6424884792626728 on epoch=42, global_step=600
06/18/2022 03:14:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=43
06/18/2022 03:14:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=44
06/18/2022 03:14:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
06/18/2022 03:14:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=45
06/18/2022 03:14:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/18/2022 03:14:35 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.6808149405772496 on epoch=46
06/18/2022 03:14:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6424884792626728 -> 0.6808149405772496 on epoch=46, global_step=650
06/18/2022 03:14:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=47
06/18/2022 03:14:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=47
06/18/2022 03:14:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
06/18/2022 03:14:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=49
06/18/2022 03:14:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=49
06/18/2022 03:14:54 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.7275266732372495 on epoch=49
06/18/2022 03:14:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6808149405772496 -> 0.7275266732372495 on epoch=49, global_step=700
06/18/2022 03:14:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
06/18/2022 03:14:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/18/2022 03:15:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=52
06/18/2022 03:15:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
06/18/2022 03:15:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=53
06/18/2022 03:15:13 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.6892181578089898 on epoch=53
06/18/2022 03:15:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
06/18/2022 03:15:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=54
06/18/2022 03:15:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
06/18/2022 03:15:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
06/18/2022 03:15:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
06/18/2022 03:15:32 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6892357956984468 on epoch=57
06/18/2022 03:15:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=57
06/18/2022 03:15:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=58
06/18/2022 03:15:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
06/18/2022 03:15:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/18/2022 03:15:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/18/2022 03:15:51 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.7759216049438759 on epoch=60
06/18/2022 03:15:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7275266732372495 -> 0.7759216049438759 on epoch=60, global_step=850
06/18/2022 03:15:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
06/18/2022 03:15:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
06/18/2022 03:15:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
06/18/2022 03:16:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/18/2022 03:16:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
06/18/2022 03:16:10 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.8185687520364939 on epoch=64
06/18/2022 03:16:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7759216049438759 -> 0.8185687520364939 on epoch=64, global_step=900
06/18/2022 03:16:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
06/18/2022 03:16:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=65
06/18/2022 03:16:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=66
06/18/2022 03:16:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/18/2022 03:16:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/18/2022 03:16:29 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.8375 on epoch=67
06/18/2022 03:16:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8185687520364939 -> 0.8375 on epoch=67, global_step=950
06/18/2022 03:16:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/18/2022 03:16:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
06/18/2022 03:16:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
06/18/2022 03:16:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/18/2022 03:16:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/18/2022 03:16:48 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.903030303030303 on epoch=71
06/18/2022 03:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8375 -> 0.903030303030303 on epoch=71, global_step=1000
06/18/2022 03:16:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
06/18/2022 03:16:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/18/2022 03:16:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/18/2022 03:16:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/18/2022 03:17:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/18/2022 03:17:07 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.8849918540241121 on epoch=74
06/18/2022 03:17:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=75
06/18/2022 03:17:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
06/18/2022 03:17:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/18/2022 03:17:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=77
06/18/2022 03:17:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/18/2022 03:17:26 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7095588646485523 on epoch=78
06/18/2022 03:17:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/18/2022 03:17:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
06/18/2022 03:17:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=80
06/18/2022 03:17:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
06/18/2022 03:17:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/18/2022 03:17:45 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8178368121442126 on epoch=82
06/18/2022 03:17:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/18/2022 03:17:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/18/2022 03:17:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/18/2022 03:17:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
06/18/2022 03:17:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
06/18/2022 03:18:04 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.8178368121442126 on epoch=85
06/18/2022 03:18:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/18/2022 03:18:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/18/2022 03:18:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/18/2022 03:18:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/18/2022 03:18:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/18/2022 03:18:23 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.830220713073005 on epoch=89
06/18/2022 03:18:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/18/2022 03:18:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/18/2022 03:18:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/18/2022 03:18:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/18/2022 03:18:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/18/2022 03:18:42 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7677047289504036 on epoch=92
06/18/2022 03:18:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/18/2022 03:18:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/18/2022 03:18:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/18/2022 03:18:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/18/2022 03:18:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/18/2022 03:19:00 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7360623781676413 on epoch=96
06/18/2022 03:19:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=97
06/18/2022 03:19:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=97
06/18/2022 03:19:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/18/2022 03:19:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/18/2022 03:19:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/18/2022 03:19:19 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6787658802177858 on epoch=99
06/18/2022 03:19:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/18/2022 03:19:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/18/2022 03:19:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/18/2022 03:19:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/18/2022 03:19:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/18/2022 03:19:38 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7811692985415422 on epoch=103
06/18/2022 03:19:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/18/2022 03:19:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/18/2022 03:19:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=105
06/18/2022 03:19:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
06/18/2022 03:19:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/18/2022 03:19:57 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7825311942959002 on epoch=107
06/18/2022 03:19:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/18/2022 03:20:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/18/2022 03:20:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/18/2022 03:20:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/18/2022 03:20:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/18/2022 03:20:16 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7887955182072829 on epoch=110
06/18/2022 03:20:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/18/2022 03:20:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/18/2022 03:20:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/18/2022 03:20:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/18/2022 03:20:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/18/2022 03:20:35 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7937356760886173 on epoch=114
06/18/2022 03:20:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/18/2022 03:20:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/18/2022 03:20:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/18/2022 03:20:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/18/2022 03:20:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/18/2022 03:20:54 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7948939106434362 on epoch=117
06/18/2022 03:20:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/18/2022 03:20:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/18/2022 03:21:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/18/2022 03:21:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/18/2022 03:21:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/18/2022 03:21:12 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9030756371569837 on epoch=121
06/18/2022 03:21:12 - INFO - __main__ - Saving model with best Classification-F1: 0.903030303030303 -> 0.9030756371569837 on epoch=121, global_step=1700
06/18/2022 03:21:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/18/2022 03:21:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/18/2022 03:21:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/18/2022 03:21:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/18/2022 03:21:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/18/2022 03:21:31 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.856100754084625 on epoch=124
06/18/2022 03:21:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/18/2022 03:21:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/18/2022 03:21:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/18/2022 03:21:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/18/2022 03:21:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/18/2022 03:21:50 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7943098568098568 on epoch=128
06/18/2022 03:21:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/18/2022 03:21:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/18/2022 03:21:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/18/2022 03:22:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/18/2022 03:22:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 03:22:09 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7527139784084229 on epoch=132
06/18/2022 03:22:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/18/2022 03:22:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/18/2022 03:22:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/18/2022 03:22:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/18/2022 03:22:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/18/2022 03:22:28 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8117401192451903 on epoch=135
06/18/2022 03:22:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/18/2022 03:22:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/18/2022 03:22:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/18/2022 03:22:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/18/2022 03:22:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/18/2022 03:22:47 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6798035298035299 on epoch=139
06/18/2022 03:22:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=139
06/18/2022 03:22:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/18/2022 03:22:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/18/2022 03:22:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/18/2022 03:23:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/18/2022 03:23:06 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7128630457440935 on epoch=142
06/18/2022 03:23:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/18/2022 03:23:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=144
06/18/2022 03:23:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/18/2022 03:23:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
06/18/2022 03:23:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/18/2022 03:23:25 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6817739731532835 on epoch=146
06/18/2022 03:23:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/18/2022 03:23:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/18/2022 03:23:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/18/2022 03:23:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/18/2022 03:23:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/18/2022 03:23:45 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.635028003832558 on epoch=149
06/18/2022 03:23:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/18/2022 03:23:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/18/2022 03:23:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/18/2022 03:23:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/18/2022 03:23:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/18/2022 03:24:05 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6330382162640227 on epoch=153
06/18/2022 03:24:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/18/2022 03:24:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/18/2022 03:24:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/18/2022 03:24:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/18/2022 03:24:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/18/2022 03:24:24 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6997676354073038 on epoch=157
06/18/2022 03:24:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/18/2022 03:24:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/18/2022 03:24:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/18/2022 03:24:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/18/2022 03:24:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/18/2022 03:24:44 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7535670429788077 on epoch=160
06/18/2022 03:24:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/18/2022 03:24:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 03:24:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/18/2022 03:24:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/18/2022 03:24:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/18/2022 03:25:03 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7387522281639929 on epoch=164
06/18/2022 03:25:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/18/2022 03:25:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/18/2022 03:25:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/18/2022 03:25:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/18/2022 03:25:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/18/2022 03:25:23 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7130942377122343 on epoch=167
06/18/2022 03:25:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/18/2022 03:25:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/18/2022 03:25:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/18/2022 03:25:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
06/18/2022 03:25:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/18/2022 03:25:42 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7091627279520949 on epoch=171
06/18/2022 03:25:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/18/2022 03:25:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/18/2022 03:25:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/18/2022 03:25:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/18/2022 03:25:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/18/2022 03:26:02 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7238028273681923 on epoch=174
06/18/2022 03:26:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/18/2022 03:26:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/18/2022 03:26:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/18/2022 03:26:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/18/2022 03:26:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/18/2022 03:26:22 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8090711031887503 on epoch=178
06/18/2022 03:26:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
06/18/2022 03:26:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/18/2022 03:26:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/18/2022 03:26:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/18/2022 03:26:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/18/2022 03:26:41 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.806494543518765 on epoch=182
06/18/2022 03:26:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/18/2022 03:26:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=183
06/18/2022 03:26:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/18/2022 03:26:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 03:26:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/18/2022 03:27:01 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8059869842365098 on epoch=185
06/18/2022 03:27:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/18/2022 03:27:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/18/2022 03:27:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/18/2022 03:27:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/18/2022 03:27:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/18/2022 03:27:20 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8666405433646813 on epoch=189
06/18/2022 03:27:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/18/2022 03:27:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/18/2022 03:27:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/18/2022 03:27:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/18/2022 03:27:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/18/2022 03:27:40 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8133435192258721 on epoch=192
06/18/2022 03:27:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/18/2022 03:27:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/18/2022 03:27:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/18/2022 03:27:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/18/2022 03:27:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/18/2022 03:27:59 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8063896887426298 on epoch=196
06/18/2022 03:28:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/18/2022 03:28:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/18/2022 03:28:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/18/2022 03:28:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/18/2022 03:28:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/18/2022 03:28:18 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9223963775687913 on epoch=199
06/18/2022 03:28:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9030756371569837 -> 0.9223963775687913 on epoch=199, global_step=2800
06/18/2022 03:28:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/18/2022 03:28:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/18/2022 03:28:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/18/2022 03:28:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/18/2022 03:28:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/18/2022 03:28:38 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8044921555357988 on epoch=203
06/18/2022 03:28:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/18/2022 03:28:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 03:28:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/18/2022 03:28:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/18/2022 03:28:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/18/2022 03:28:58 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8034970993936839 on epoch=207
06/18/2022 03:29:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/18/2022 03:29:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/18/2022 03:29:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/18/2022 03:29:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/18/2022 03:29:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/18/2022 03:29:17 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8071771637948109 on epoch=210
06/18/2022 03:29:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/18/2022 03:29:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/18/2022 03:29:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
06/18/2022 03:29:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/18/2022 03:29:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/18/2022 03:29:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:29:32 - INFO - __main__ - Printing 3 examples
06/18/2022 03:29:32 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 03:29:32 - INFO - __main__ - ['Company']
06/18/2022 03:29:32 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 03:29:32 - INFO - __main__ - ['Company']
06/18/2022 03:29:32 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 03:29:32 - INFO - __main__ - ['Company']
06/18/2022 03:29:32 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:29:32 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:29:32 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 03:29:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:29:32 - INFO - __main__ - Printing 3 examples
06/18/2022 03:29:32 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 03:29:32 - INFO - __main__ - ['Company']
06/18/2022 03:29:32 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 03:29:32 - INFO - __main__ - ['Company']
06/18/2022 03:29:32 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 03:29:32 - INFO - __main__ - ['Company']
06/18/2022 03:29:32 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:29:32 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:29:32 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 03:29:37 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8641774891774892 on epoch=214
06/18/2022 03:29:37 - INFO - __main__ - save last model!
06/18/2022 03:29:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 03:29:37 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 03:29:37 - INFO - __main__ - Printing 3 examples
06/18/2022 03:29:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 03:29:37 - INFO - __main__ - ['Animal']
06/18/2022 03:29:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 03:29:37 - INFO - __main__ - ['Animal']
06/18/2022 03:29:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 03:29:37 - INFO - __main__ - ['Village']
06/18/2022 03:29:37 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:29:39 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:29:42 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 03:29:51 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 03:29:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 03:29:52 - INFO - __main__ - Starting training!
06/18/2022 03:31:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/18/2022 03:31:50 - INFO - __main__ - Classification-F1 on test data: 0.5199
06/18/2022 03:31:50 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9223963775687913, test_performance=0.5199229989713151
06/18/2022 03:31:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/18/2022 03:31:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:31:51 - INFO - __main__ - Printing 3 examples
06/18/2022 03:31:51 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/18/2022 03:31:51 - INFO - __main__ - ['Company']
06/18/2022 03:31:51 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/18/2022 03:31:51 - INFO - __main__ - ['Company']
06/18/2022 03:31:51 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/18/2022 03:31:51 - INFO - __main__ - ['Company']
06/18/2022 03:31:51 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:31:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:31:51 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 03:31:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:31:51 - INFO - __main__ - Printing 3 examples
06/18/2022 03:31:51 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/18/2022 03:31:51 - INFO - __main__ - ['Company']
06/18/2022 03:31:51 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/18/2022 03:31:51 - INFO - __main__ - ['Company']
06/18/2022 03:31:51 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/18/2022 03:31:51 - INFO - __main__ - ['Company']
06/18/2022 03:31:51 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:31:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:31:52 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 03:32:10 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 03:32:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 03:32:11 - INFO - __main__ - Starting training!
06/18/2022 03:32:14 - INFO - __main__ - Step 10 Global step 10 Train loss 7.10 on epoch=0
06/18/2022 03:32:17 - INFO - __main__ - Step 20 Global step 20 Train loss 5.53 on epoch=1
06/18/2022 03:32:19 - INFO - __main__ - Step 30 Global step 30 Train loss 5.09 on epoch=2
06/18/2022 03:32:22 - INFO - __main__ - Step 40 Global step 40 Train loss 4.74 on epoch=2
06/18/2022 03:32:25 - INFO - __main__ - Step 50 Global step 50 Train loss 4.52 on epoch=3
06/18/2022 03:32:32 - INFO - __main__ - Global step 50 Train loss 5.39 Classification-F1 0.021315904139433548 on epoch=3
06/18/2022 03:32:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.021315904139433548 on epoch=3, global_step=50
06/18/2022 03:32:35 - INFO - __main__ - Step 60 Global step 60 Train loss 4.11 on epoch=4
06/18/2022 03:32:37 - INFO - __main__ - Step 70 Global step 70 Train loss 4.22 on epoch=4
06/18/2022 03:32:40 - INFO - __main__ - Step 80 Global step 80 Train loss 3.83 on epoch=5
06/18/2022 03:32:42 - INFO - __main__ - Step 90 Global step 90 Train loss 3.48 on epoch=6
06/18/2022 03:32:45 - INFO - __main__ - Step 100 Global step 100 Train loss 3.54 on epoch=7
06/18/2022 03:32:50 - INFO - __main__ - Global step 100 Train loss 3.84 Classification-F1 0.05878059840612136 on epoch=7
06/18/2022 03:32:50 - INFO - __main__ - Saving model with best Classification-F1: 0.021315904139433548 -> 0.05878059840612136 on epoch=7, global_step=100
06/18/2022 03:32:53 - INFO - __main__ - Step 110 Global step 110 Train loss 3.34 on epoch=7
06/18/2022 03:32:56 - INFO - __main__ - Step 120 Global step 120 Train loss 3.20 on epoch=8
06/18/2022 03:32:58 - INFO - __main__ - Step 130 Global step 130 Train loss 2.96 on epoch=9
06/18/2022 03:33:01 - INFO - __main__ - Step 140 Global step 140 Train loss 2.76 on epoch=9
06/18/2022 03:33:03 - INFO - __main__ - Step 150 Global step 150 Train loss 2.51 on epoch=10
06/18/2022 03:33:09 - INFO - __main__ - Global step 150 Train loss 2.95 Classification-F1 0.08421485795406741 on epoch=10
06/18/2022 03:33:09 - INFO - __main__ - Saving model with best Classification-F1: 0.05878059840612136 -> 0.08421485795406741 on epoch=10, global_step=150
06/18/2022 03:33:11 - INFO - __main__ - Step 160 Global step 160 Train loss 2.31 on epoch=11
06/18/2022 03:33:14 - INFO - __main__ - Step 170 Global step 170 Train loss 2.33 on epoch=12
06/18/2022 03:33:17 - INFO - __main__ - Step 180 Global step 180 Train loss 2.34 on epoch=12
06/18/2022 03:33:19 - INFO - __main__ - Step 190 Global step 190 Train loss 2.01 on epoch=13
06/18/2022 03:33:22 - INFO - __main__ - Step 200 Global step 200 Train loss 2.02 on epoch=14
06/18/2022 03:33:27 - INFO - __main__ - Global step 200 Train loss 2.20 Classification-F1 0.10155534837181113 on epoch=14
06/18/2022 03:33:28 - INFO - __main__ - Saving model with best Classification-F1: 0.08421485795406741 -> 0.10155534837181113 on epoch=14, global_step=200
06/18/2022 03:33:30 - INFO - __main__ - Step 210 Global step 210 Train loss 1.91 on epoch=14
06/18/2022 03:33:33 - INFO - __main__ - Step 220 Global step 220 Train loss 2.02 on epoch=15
06/18/2022 03:33:35 - INFO - __main__ - Step 230 Global step 230 Train loss 1.81 on epoch=16
06/18/2022 03:33:38 - INFO - __main__ - Step 240 Global step 240 Train loss 1.80 on epoch=17
06/18/2022 03:33:41 - INFO - __main__ - Step 250 Global step 250 Train loss 1.73 on epoch=17
06/18/2022 03:33:46 - INFO - __main__ - Global step 250 Train loss 1.85 Classification-F1 0.10797936003266487 on epoch=17
06/18/2022 03:33:46 - INFO - __main__ - Saving model with best Classification-F1: 0.10155534837181113 -> 0.10797936003266487 on epoch=17, global_step=250
06/18/2022 03:33:49 - INFO - __main__ - Step 260 Global step 260 Train loss 1.61 on epoch=18
06/18/2022 03:33:52 - INFO - __main__ - Step 270 Global step 270 Train loss 1.52 on epoch=19
06/18/2022 03:33:54 - INFO - __main__ - Step 280 Global step 280 Train loss 1.52 on epoch=19
06/18/2022 03:33:57 - INFO - __main__ - Step 290 Global step 290 Train loss 1.54 on epoch=20
06/18/2022 03:33:59 - INFO - __main__ - Step 300 Global step 300 Train loss 1.32 on epoch=21
06/18/2022 03:34:05 - INFO - __main__ - Global step 300 Train loss 1.50 Classification-F1 0.14671805714933345 on epoch=21
06/18/2022 03:34:05 - INFO - __main__ - Saving model with best Classification-F1: 0.10797936003266487 -> 0.14671805714933345 on epoch=21, global_step=300
06/18/2022 03:34:08 - INFO - __main__ - Step 310 Global step 310 Train loss 1.35 on epoch=22
06/18/2022 03:34:11 - INFO - __main__ - Step 320 Global step 320 Train loss 1.32 on epoch=22
06/18/2022 03:34:13 - INFO - __main__ - Step 330 Global step 330 Train loss 1.19 on epoch=23
06/18/2022 03:34:16 - INFO - __main__ - Step 340 Global step 340 Train loss 1.26 on epoch=24
06/18/2022 03:34:18 - INFO - __main__ - Step 350 Global step 350 Train loss 1.20 on epoch=24
06/18/2022 03:34:24 - INFO - __main__ - Global step 350 Train loss 1.26 Classification-F1 0.22721709267163812 on epoch=24
06/18/2022 03:34:24 - INFO - __main__ - Saving model with best Classification-F1: 0.14671805714933345 -> 0.22721709267163812 on epoch=24, global_step=350
06/18/2022 03:34:27 - INFO - __main__ - Step 360 Global step 360 Train loss 1.10 on epoch=25
06/18/2022 03:34:30 - INFO - __main__ - Step 370 Global step 370 Train loss 1.01 on epoch=26
06/18/2022 03:34:32 - INFO - __main__ - Step 380 Global step 380 Train loss 1.06 on epoch=27
06/18/2022 03:34:35 - INFO - __main__ - Step 390 Global step 390 Train loss 1.08 on epoch=27
06/18/2022 03:34:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.90 on epoch=28
06/18/2022 03:34:44 - INFO - __main__ - Global step 400 Train loss 1.03 Classification-F1 0.32482740626160267 on epoch=28
06/18/2022 03:34:44 - INFO - __main__ - Saving model with best Classification-F1: 0.22721709267163812 -> 0.32482740626160267 on epoch=28, global_step=400
06/18/2022 03:34:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.83 on epoch=29
06/18/2022 03:34:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.92 on epoch=29
06/18/2022 03:34:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.85 on epoch=30
06/18/2022 03:34:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.72 on epoch=31
06/18/2022 03:34:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.87 on epoch=32
06/18/2022 03:35:04 - INFO - __main__ - Global step 450 Train loss 0.84 Classification-F1 0.37469559483571413 on epoch=32
06/18/2022 03:35:04 - INFO - __main__ - Saving model with best Classification-F1: 0.32482740626160267 -> 0.37469559483571413 on epoch=32, global_step=450
06/18/2022 03:35:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.84 on epoch=32
06/18/2022 03:35:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.61 on epoch=33
06/18/2022 03:35:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.73 on epoch=34
06/18/2022 03:35:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.63 on epoch=34
06/18/2022 03:35:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.62 on epoch=35
06/18/2022 03:35:23 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.5535030251918297 on epoch=35
06/18/2022 03:35:23 - INFO - __main__ - Saving model with best Classification-F1: 0.37469559483571413 -> 0.5535030251918297 on epoch=35, global_step=500
06/18/2022 03:35:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.57 on epoch=36
06/18/2022 03:35:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.61 on epoch=37
06/18/2022 03:35:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=37
06/18/2022 03:35:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.58 on epoch=38
06/18/2022 03:35:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.55 on epoch=39
06/18/2022 03:35:43 - INFO - __main__ - Global step 550 Train loss 0.57 Classification-F1 0.5783433144945938 on epoch=39
06/18/2022 03:35:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5535030251918297 -> 0.5783433144945938 on epoch=39, global_step=550
06/18/2022 03:35:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.61 on epoch=39
06/18/2022 03:35:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.48 on epoch=40
06/18/2022 03:35:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.49 on epoch=41
06/18/2022 03:35:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.48 on epoch=42
06/18/2022 03:35:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=42
06/18/2022 03:36:03 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.5720438759715912 on epoch=42
06/18/2022 03:36:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.47 on epoch=43
06/18/2022 03:36:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.52 on epoch=44
06/18/2022 03:36:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=44
06/18/2022 03:36:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=45
06/18/2022 03:36:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=46
06/18/2022 03:36:23 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.614336917562724 on epoch=46
06/18/2022 03:36:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5783433144945938 -> 0.614336917562724 on epoch=46, global_step=650
06/18/2022 03:36:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
06/18/2022 03:36:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.45 on epoch=47
06/18/2022 03:36:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=48
06/18/2022 03:36:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.35 on epoch=49
06/18/2022 03:36:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=49
06/18/2022 03:36:43 - INFO - __main__ - Global step 700 Train loss 0.40 Classification-F1 0.6113578178094308 on epoch=49
06/18/2022 03:36:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.39 on epoch=50
06/18/2022 03:36:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=51
06/18/2022 03:36:51 - INFO - __main__ - Step 730 Global step 730 Train loss 0.33 on epoch=52
06/18/2022 03:36:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=52
06/18/2022 03:36:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=53
06/18/2022 03:37:03 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.6113578178094308 on epoch=53
06/18/2022 03:37:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=54
06/18/2022 03:37:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=54
06/18/2022 03:37:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=55
06/18/2022 03:37:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=56
06/18/2022 03:37:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.35 on epoch=57
06/18/2022 03:37:23 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.614336917562724 on epoch=57
06/18/2022 03:37:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
06/18/2022 03:37:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=58
06/18/2022 03:37:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.42 on epoch=59
06/18/2022 03:37:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.38 on epoch=59
06/18/2022 03:37:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=60
06/18/2022 03:37:43 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.614336917562724 on epoch=60
06/18/2022 03:37:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=61
06/18/2022 03:37:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=62
06/18/2022 03:37:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=62
06/18/2022 03:37:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=63
06/18/2022 03:37:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.34 on epoch=64
06/18/2022 03:38:02 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.646774193548387 on epoch=64
06/18/2022 03:38:02 - INFO - __main__ - Saving model with best Classification-F1: 0.614336917562724 -> 0.646774193548387 on epoch=64, global_step=900
06/18/2022 03:38:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=64
06/18/2022 03:38:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=65
06/18/2022 03:38:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=66
06/18/2022 03:38:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/18/2022 03:38:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=67
06/18/2022 03:38:22 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.6159754224270353 on epoch=67
06/18/2022 03:38:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=68
06/18/2022 03:38:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=69
06/18/2022 03:38:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.26 on epoch=69
06/18/2022 03:38:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
06/18/2022 03:38:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.25 on epoch=71
06/18/2022 03:38:42 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.6159754224270353 on epoch=71
06/18/2022 03:38:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
06/18/2022 03:38:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.31 on epoch=72
06/18/2022 03:38:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/18/2022 03:38:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=74
06/18/2022 03:38:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=74
06/18/2022 03:39:01 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.6115533212307407 on epoch=74
06/18/2022 03:39:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=75
06/18/2022 03:39:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=76
06/18/2022 03:39:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=77
06/18/2022 03:39:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=77
06/18/2022 03:39:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/18/2022 03:39:21 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.6099996988042529 on epoch=78
06/18/2022 03:39:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=79
06/18/2022 03:39:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
06/18/2022 03:39:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=80
06/18/2022 03:39:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=81
06/18/2022 03:39:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
06/18/2022 03:39:41 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.613174301978856 on epoch=82
06/18/2022 03:39:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=82
06/18/2022 03:39:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.27 on epoch=83
06/18/2022 03:39:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=84
06/18/2022 03:39:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=84
06/18/2022 03:39:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=85
06/18/2022 03:40:00 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.613174301978856 on epoch=85
06/18/2022 03:40:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/18/2022 03:40:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
06/18/2022 03:40:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
06/18/2022 03:40:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/18/2022 03:40:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=89
06/18/2022 03:40:20 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.6825127334465195 on epoch=89
06/18/2022 03:40:20 - INFO - __main__ - Saving model with best Classification-F1: 0.646774193548387 -> 0.6825127334465195 on epoch=89, global_step=1250
06/18/2022 03:40:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=89
06/18/2022 03:40:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=90
06/18/2022 03:40:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
06/18/2022 03:40:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=92
06/18/2022 03:40:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=92
06/18/2022 03:40:39 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.7205387205387205 on epoch=92
06/18/2022 03:40:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6825127334465195 -> 0.7205387205387205 on epoch=92, global_step=1300
06/18/2022 03:40:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/18/2022 03:40:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=94
06/18/2022 03:40:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=94
06/18/2022 03:40:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/18/2022 03:40:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=96
06/18/2022 03:40:59 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.7287581699346405 on epoch=96
06/18/2022 03:40:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7205387205387205 -> 0.7287581699346405 on epoch=96, global_step=1350
06/18/2022 03:41:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
06/18/2022 03:41:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
06/18/2022 03:41:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=98
06/18/2022 03:41:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
06/18/2022 03:41:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=99
06/18/2022 03:41:18 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.71874660584338 on epoch=99
06/18/2022 03:41:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=100
06/18/2022 03:41:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=101
06/18/2022 03:41:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=102
06/18/2022 03:41:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
06/18/2022 03:41:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.24 on epoch=103
06/18/2022 03:41:38 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.6512391466850669 on epoch=103
06/18/2022 03:41:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/18/2022 03:41:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=104
06/18/2022 03:41:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/18/2022 03:41:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/18/2022 03:41:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.19 on epoch=107
06/18/2022 03:41:57 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.7345679012345678 on epoch=107
06/18/2022 03:41:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7287581699346405 -> 0.7345679012345678 on epoch=107, global_step=1500
06/18/2022 03:42:00 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/18/2022 03:42:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/18/2022 03:42:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=109
06/18/2022 03:42:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.19 on epoch=109
06/18/2022 03:42:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/18/2022 03:42:16 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.7287581699346405 on epoch=110
06/18/2022 03:42:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
06/18/2022 03:42:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
06/18/2022 03:42:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=112
06/18/2022 03:42:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
06/18/2022 03:42:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
06/18/2022 03:42:36 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.7777777777777777 on epoch=114
06/18/2022 03:42:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7345679012345678 -> 0.7777777777777777 on epoch=114, global_step=1600
06/18/2022 03:42:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/18/2022 03:42:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
06/18/2022 03:42:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=116
06/18/2022 03:42:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/18/2022 03:42:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/18/2022 03:42:55 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7778191381507071 on epoch=117
06/18/2022 03:42:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7777777777777777 -> 0.7778191381507071 on epoch=117, global_step=1650
06/18/2022 03:42:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
06/18/2022 03:43:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.17 on epoch=119
06/18/2022 03:43:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/18/2022 03:43:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/18/2022 03:43:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/18/2022 03:43:14 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.9010554351367815 on epoch=121
06/18/2022 03:43:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7778191381507071 -> 0.9010554351367815 on epoch=121, global_step=1700
06/18/2022 03:43:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/18/2022 03:43:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=122
06/18/2022 03:43:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
06/18/2022 03:43:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=124
06/18/2022 03:43:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/18/2022 03:43:34 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.8043771535232636 on epoch=124
06/18/2022 03:43:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/18/2022 03:43:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
06/18/2022 03:43:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=127
06/18/2022 03:43:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
06/18/2022 03:43:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/18/2022 03:43:53 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.7574671445639187 on epoch=128
06/18/2022 03:43:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/18/2022 03:43:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.20 on epoch=129
06/18/2022 03:44:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=130
06/18/2022 03:44:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
06/18/2022 03:44:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=132
06/18/2022 03:44:13 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.7656975972388158 on epoch=132
06/18/2022 03:44:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/18/2022 03:44:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
06/18/2022 03:44:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/18/2022 03:44:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/18/2022 03:44:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
06/18/2022 03:44:32 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.7229985634060337 on epoch=135
06/18/2022 03:44:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/18/2022 03:44:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/18/2022 03:44:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/18/2022 03:44:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
06/18/2022 03:44:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=139
06/18/2022 03:44:51 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.813228517213337 on epoch=139
06/18/2022 03:44:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/18/2022 03:44:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/18/2022 03:44:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
06/18/2022 03:45:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.15 on epoch=142
06/18/2022 03:45:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=142
06/18/2022 03:45:10 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.6820001503872473 on epoch=142
06/18/2022 03:45:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
06/18/2022 03:45:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/18/2022 03:45:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=144
06/18/2022 03:45:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/18/2022 03:45:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=146
06/18/2022 03:45:29 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.8156862745098039 on epoch=146
06/18/2022 03:45:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/18/2022 03:45:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/18/2022 03:45:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=148
06/18/2022 03:45:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/18/2022 03:45:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
06/18/2022 03:45:48 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8624738766980147 on epoch=149
06/18/2022 03:45:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/18/2022 03:45:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
06/18/2022 03:45:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=152
06/18/2022 03:45:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/18/2022 03:46:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
06/18/2022 03:46:07 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.8107386323705109 on epoch=153
06/18/2022 03:46:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/18/2022 03:46:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=154
06/18/2022 03:46:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/18/2022 03:46:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/18/2022 03:46:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/18/2022 03:46:26 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.8177103099304238 on epoch=157
06/18/2022 03:46:29 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/18/2022 03:46:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/18/2022 03:46:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/18/2022 03:46:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=159
06/18/2022 03:46:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
06/18/2022 03:46:45 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.858560794044665 on epoch=160
06/18/2022 03:46:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/18/2022 03:46:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.14 on epoch=162
06/18/2022 03:46:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/18/2022 03:46:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/18/2022 03:46:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=164
06/18/2022 03:47:04 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.9180707685373 on epoch=164
06/18/2022 03:47:04 - INFO - __main__ - Saving model with best Classification-F1: 0.9010554351367815 -> 0.9180707685373 on epoch=164, global_step=2300
06/18/2022 03:47:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
06/18/2022 03:47:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/18/2022 03:47:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/18/2022 03:47:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/18/2022 03:47:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
06/18/2022 03:47:23 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.813228517213337 on epoch=167
06/18/2022 03:47:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.12 on epoch=168
06/18/2022 03:47:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/18/2022 03:47:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=169
06/18/2022 03:47:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/18/2022 03:47:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=171
06/18/2022 03:47:42 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.8585638082718172 on epoch=171
06/18/2022 03:47:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/18/2022 03:47:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/18/2022 03:47:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/18/2022 03:47:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=174
06/18/2022 03:47:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/18/2022 03:48:01 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.8080600548440633 on epoch=174
06/18/2022 03:48:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=175
06/18/2022 03:48:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/18/2022 03:48:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/18/2022 03:48:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/18/2022 03:48:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/18/2022 03:48:20 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8069320657555953 on epoch=178
06/18/2022 03:48:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/18/2022 03:48:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
06/18/2022 03:48:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=180
06/18/2022 03:48:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/18/2022 03:48:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=182
06/18/2022 03:48:39 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.8080600548440633 on epoch=182
06/18/2022 03:48:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/18/2022 03:48:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/18/2022 03:48:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
06/18/2022 03:48:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=184
06/18/2022 03:48:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/18/2022 03:48:59 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7195926880137407 on epoch=185
06/18/2022 03:49:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/18/2022 03:49:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/18/2022 03:49:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/18/2022 03:49:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/18/2022 03:49:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/18/2022 03:49:18 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7170015948963318 on epoch=189
06/18/2022 03:49:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=189
06/18/2022 03:49:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.13 on epoch=190
06/18/2022 03:49:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=191
06/18/2022 03:49:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/18/2022 03:49:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/18/2022 03:49:37 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.7621025065469511 on epoch=192
06/18/2022 03:49:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/18/2022 03:49:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/18/2022 03:49:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/18/2022 03:49:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/18/2022 03:49:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/18/2022 03:49:56 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7209269508081053 on epoch=196
06/18/2022 03:49:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/18/2022 03:50:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/18/2022 03:50:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/18/2022 03:50:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/18/2022 03:50:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/18/2022 03:50:15 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7666434459537909 on epoch=199
06/18/2022 03:50:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/18/2022 03:50:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=201
06/18/2022 03:50:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=202
06/18/2022 03:50:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/18/2022 03:50:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/18/2022 03:50:34 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.813903743315508 on epoch=203
06/18/2022 03:50:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/18/2022 03:50:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=204
06/18/2022 03:50:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/18/2022 03:50:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/18/2022 03:50:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/18/2022 03:50:54 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.813903743315508 on epoch=207
06/18/2022 03:50:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/18/2022 03:50:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/18/2022 03:51:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/18/2022 03:51:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/18/2022 03:51:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/18/2022 03:51:13 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8069320657555953 on epoch=210
06/18/2022 03:51:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/18/2022 03:51:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/18/2022 03:51:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
06/18/2022 03:51:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/18/2022 03:51:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/18/2022 03:51:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:51:27 - INFO - __main__ - Printing 3 examples
06/18/2022 03:51:27 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 03:51:27 - INFO - __main__ - ['Film']
06/18/2022 03:51:27 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 03:51:27 - INFO - __main__ - ['Film']
06/18/2022 03:51:27 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 03:51:27 - INFO - __main__ - ['Film']
06/18/2022 03:51:27 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:51:27 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:51:28 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 03:51:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:51:28 - INFO - __main__ - Printing 3 examples
06/18/2022 03:51:28 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 03:51:28 - INFO - __main__ - ['Film']
06/18/2022 03:51:28 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 03:51:28 - INFO - __main__ - ['Film']
06/18/2022 03:51:28 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 03:51:28 - INFO - __main__ - ['Film']
06/18/2022 03:51:28 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:51:28 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:51:28 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 03:51:32 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8624738766980147 on epoch=214
06/18/2022 03:51:32 - INFO - __main__ - save last model!
06/18/2022 03:51:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 03:51:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 03:51:32 - INFO - __main__ - Printing 3 examples
06/18/2022 03:51:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 03:51:32 - INFO - __main__ - ['Animal']
06/18/2022 03:51:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 03:51:32 - INFO - __main__ - ['Animal']
06/18/2022 03:51:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 03:51:32 - INFO - __main__ - ['Village']
06/18/2022 03:51:32 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:51:34 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:51:38 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 03:51:47 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 03:51:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 03:51:48 - INFO - __main__ - Starting training!
06/18/2022 03:53:48 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/18/2022 03:53:48 - INFO - __main__ - Classification-F1 on test data: 0.5215
06/18/2022 03:53:48 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9180707685373, test_performance=0.5215368294006367
06/18/2022 03:53:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/18/2022 03:53:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:53:49 - INFO - __main__ - Printing 3 examples
06/18/2022 03:53:49 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 03:53:49 - INFO - __main__ - ['Film']
06/18/2022 03:53:49 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 03:53:49 - INFO - __main__ - ['Film']
06/18/2022 03:53:49 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 03:53:49 - INFO - __main__ - ['Film']
06/18/2022 03:53:49 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:53:49 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:53:49 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 03:53:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 03:53:49 - INFO - __main__ - Printing 3 examples
06/18/2022 03:53:49 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 03:53:49 - INFO - __main__ - ['Film']
06/18/2022 03:53:49 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 03:53:49 - INFO - __main__ - ['Film']
06/18/2022 03:53:49 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 03:53:49 - INFO - __main__ - ['Film']
06/18/2022 03:53:49 - INFO - __main__ - Tokenizing Input ...
06/18/2022 03:53:49 - INFO - __main__ - Tokenizing Output ...
06/18/2022 03:53:50 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 03:54:05 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 03:54:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 03:54:06 - INFO - __main__ - Starting training!
06/18/2022 03:54:09 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=0
06/18/2022 03:54:12 - INFO - __main__ - Step 20 Global step 20 Train loss 4.41 on epoch=1
06/18/2022 03:54:15 - INFO - __main__ - Step 30 Global step 30 Train loss 4.17 on epoch=2
06/18/2022 03:54:17 - INFO - __main__ - Step 40 Global step 40 Train loss 3.34 on epoch=2
06/18/2022 03:54:20 - INFO - __main__ - Step 50 Global step 50 Train loss 3.25 on epoch=3
06/18/2022 03:54:26 - INFO - __main__ - Global step 50 Train loss 4.35 Classification-F1 0.09305804930513539 on epoch=3
06/18/2022 03:54:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09305804930513539 on epoch=3, global_step=50
06/18/2022 03:54:28 - INFO - __main__ - Step 60 Global step 60 Train loss 2.84 on epoch=4
06/18/2022 03:54:31 - INFO - __main__ - Step 70 Global step 70 Train loss 2.26 on epoch=4
06/18/2022 03:54:34 - INFO - __main__ - Step 80 Global step 80 Train loss 2.29 on epoch=5
06/18/2022 03:54:36 - INFO - __main__ - Step 90 Global step 90 Train loss 1.90 on epoch=6
06/18/2022 03:54:39 - INFO - __main__ - Step 100 Global step 100 Train loss 1.77 on epoch=7
06/18/2022 03:54:44 - INFO - __main__ - Global step 100 Train loss 2.21 Classification-F1 0.12863950949204406 on epoch=7
06/18/2022 03:54:44 - INFO - __main__ - Saving model with best Classification-F1: 0.09305804930513539 -> 0.12863950949204406 on epoch=7, global_step=100
06/18/2022 03:54:47 - INFO - __main__ - Step 110 Global step 110 Train loss 1.56 on epoch=7
06/18/2022 03:54:50 - INFO - __main__ - Step 120 Global step 120 Train loss 1.70 on epoch=8
06/18/2022 03:54:52 - INFO - __main__ - Step 130 Global step 130 Train loss 1.44 on epoch=9
06/18/2022 03:54:55 - INFO - __main__ - Step 140 Global step 140 Train loss 1.19 on epoch=9
06/18/2022 03:54:58 - INFO - __main__ - Step 150 Global step 150 Train loss 1.32 on epoch=10
06/18/2022 03:55:04 - INFO - __main__ - Global step 150 Train loss 1.44 Classification-F1 0.30376575938587563 on epoch=10
06/18/2022 03:55:04 - INFO - __main__ - Saving model with best Classification-F1: 0.12863950949204406 -> 0.30376575938587563 on epoch=10, global_step=150
06/18/2022 03:55:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.99 on epoch=11
06/18/2022 03:55:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=12
06/18/2022 03:55:12 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=12
06/18/2022 03:55:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=13
06/18/2022 03:55:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=14
06/18/2022 03:55:24 - INFO - __main__ - Global step 200 Train loss 0.86 Classification-F1 0.39122881451936964 on epoch=14
06/18/2022 03:55:24 - INFO - __main__ - Saving model with best Classification-F1: 0.30376575938587563 -> 0.39122881451936964 on epoch=14, global_step=200
06/18/2022 03:55:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.58 on epoch=14
06/18/2022 03:55:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=15
06/18/2022 03:55:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=16
06/18/2022 03:55:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=17
06/18/2022 03:55:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=17
06/18/2022 03:55:44 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.6163229409470331 on epoch=17
06/18/2022 03:55:44 - INFO - __main__ - Saving model with best Classification-F1: 0.39122881451936964 -> 0.6163229409470331 on epoch=17, global_step=250
06/18/2022 03:55:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=18
06/18/2022 03:55:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=19
06/18/2022 03:55:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=19
06/18/2022 03:55:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=20
06/18/2022 03:55:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=21
06/18/2022 03:56:04 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.7098411700852595 on epoch=21
06/18/2022 03:56:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6163229409470331 -> 0.7098411700852595 on epoch=21, global_step=300
06/18/2022 03:56:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
06/18/2022 03:56:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
06/18/2022 03:56:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=23
06/18/2022 03:56:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=24
06/18/2022 03:56:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=24
06/18/2022 03:56:24 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.7186049623405127 on epoch=24
06/18/2022 03:56:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7098411700852595 -> 0.7186049623405127 on epoch=24, global_step=350
06/18/2022 03:56:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=25
06/18/2022 03:56:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=26
06/18/2022 03:56:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=27
06/18/2022 03:56:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=27
06/18/2022 03:56:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=28
06/18/2022 03:56:44 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.7963204065122864 on epoch=28
06/18/2022 03:56:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7186049623405127 -> 0.7963204065122864 on epoch=28, global_step=400
06/18/2022 03:56:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=29
06/18/2022 03:56:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=29
06/18/2022 03:56:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=30
06/18/2022 03:56:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
06/18/2022 03:56:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=32
06/18/2022 03:57:03 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.7730074414233284 on epoch=32
06/18/2022 03:57:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=32
06/18/2022 03:57:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=33
06/18/2022 03:57:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
06/18/2022 03:57:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=34
06/18/2022 03:57:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
06/18/2022 03:57:23 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.7343788764841397 on epoch=35
06/18/2022 03:57:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=36
06/18/2022 03:57:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
06/18/2022 03:57:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
06/18/2022 03:57:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
06/18/2022 03:57:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=39
06/18/2022 03:57:42 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7188528762216302 on epoch=39
06/18/2022 03:57:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
06/18/2022 03:57:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
06/18/2022 03:57:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
06/18/2022 03:57:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/18/2022 03:57:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
06/18/2022 03:58:02 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.8222661676184597 on epoch=42
06/18/2022 03:58:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7963204065122864 -> 0.8222661676184597 on epoch=42, global_step=600
06/18/2022 03:58:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=43
06/18/2022 03:58:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/18/2022 03:58:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
06/18/2022 03:58:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
06/18/2022 03:58:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/18/2022 03:58:21 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.8322912302751013 on epoch=46
06/18/2022 03:58:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8222661676184597 -> 0.8322912302751013 on epoch=46, global_step=650
06/18/2022 03:58:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=47
06/18/2022 03:58:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=47
06/18/2022 03:58:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
06/18/2022 03:58:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/18/2022 03:58:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
06/18/2022 03:58:40 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.8859004794488666 on epoch=49
06/18/2022 03:58:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8322912302751013 -> 0.8859004794488666 on epoch=49, global_step=700
06/18/2022 03:58:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=50
06/18/2022 03:58:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
06/18/2022 03:58:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/18/2022 03:58:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
06/18/2022 03:58:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
06/18/2022 03:58:59 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.764818403929912 on epoch=53
06/18/2022 03:59:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/18/2022 03:59:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
06/18/2022 03:59:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/18/2022 03:59:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=56
06/18/2022 03:59:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
06/18/2022 03:59:19 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.752563030964153 on epoch=57
06/18/2022 03:59:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/18/2022 03:59:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/18/2022 03:59:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
06/18/2022 03:59:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=59
06/18/2022 03:59:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
06/18/2022 03:59:38 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.9126461750117663 on epoch=60
06/18/2022 03:59:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8859004794488666 -> 0.9126461750117663 on epoch=60, global_step=850
06/18/2022 03:59:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=61
06/18/2022 03:59:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/18/2022 03:59:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=62
06/18/2022 03:59:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
06/18/2022 03:59:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
06/18/2022 03:59:57 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.8437536656891496 on epoch=64
06/18/2022 04:00:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
06/18/2022 04:00:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
06/18/2022 04:00:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/18/2022 04:00:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
06/18/2022 04:00:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/18/2022 04:00:16 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.9205474095796676 on epoch=67
06/18/2022 04:00:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9126461750117663 -> 0.9205474095796676 on epoch=67, global_step=950
06/18/2022 04:00:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
06/18/2022 04:00:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
06/18/2022 04:00:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
06/18/2022 04:00:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
06/18/2022 04:00:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/18/2022 04:00:35 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.9186705767350929 on epoch=71
06/18/2022 04:00:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
06/18/2022 04:00:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
06/18/2022 04:00:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/18/2022 04:00:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/18/2022 04:00:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/18/2022 04:00:54 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7417260159195643 on epoch=74
06/18/2022 04:00:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/18/2022 04:01:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
06/18/2022 04:01:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/18/2022 04:01:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/18/2022 04:01:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
06/18/2022 04:01:14 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9186460429724188 on epoch=78
06/18/2022 04:01:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/18/2022 04:01:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/18/2022 04:01:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/18/2022 04:01:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/18/2022 04:01:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
06/18/2022 04:01:33 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.9144012186058905 on epoch=82
06/18/2022 04:01:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/18/2022 04:01:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/18/2022 04:01:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
06/18/2022 04:01:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/18/2022 04:01:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/18/2022 04:01:52 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=85
06/18/2022 04:01:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9205474095796676 -> 0.9820991153059465 on epoch=85, global_step=1200
06/18/2022 04:01:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/18/2022 04:01:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
06/18/2022 04:02:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/18/2022 04:02:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/18/2022 04:02:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/18/2022 04:02:12 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.9865677649358864 on epoch=89
06/18/2022 04:02:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9820991153059465 -> 0.9865677649358864 on epoch=89, global_step=1250
06/18/2022 04:02:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/18/2022 04:02:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/18/2022 04:02:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/18/2022 04:02:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/18/2022 04:02:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/18/2022 04:02:32 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9123247656833996 on epoch=92
06/18/2022 04:02:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/18/2022 04:02:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/18/2022 04:02:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/18/2022 04:02:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/18/2022 04:02:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/18/2022 04:02:52 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.859103128054741 on epoch=96
06/18/2022 04:02:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/18/2022 04:02:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/18/2022 04:03:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/18/2022 04:03:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/18/2022 04:03:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/18/2022 04:03:12 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9120231960381148 on epoch=99
06/18/2022 04:03:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
06/18/2022 04:03:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/18/2022 04:03:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/18/2022 04:03:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/18/2022 04:03:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/18/2022 04:03:32 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.914360540892799 on epoch=103
06/18/2022 04:03:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
06/18/2022 04:03:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/18/2022 04:03:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/18/2022 04:03:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/18/2022 04:03:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/18/2022 04:03:51 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.8964315629638212 on epoch=107
06/18/2022 04:03:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/18/2022 04:03:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/18/2022 04:03:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/18/2022 04:04:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/18/2022 04:04:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/18/2022 04:04:11 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9182256379141808 on epoch=110
06/18/2022 04:04:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/18/2022 04:04:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/18/2022 04:04:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/18/2022 04:04:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/18/2022 04:04:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
06/18/2022 04:04:31 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8377953130627154 on epoch=114
06/18/2022 04:04:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/18/2022 04:04:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/18/2022 04:04:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/18/2022 04:04:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/18/2022 04:04:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/18/2022 04:04:51 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8964274899758773 on epoch=117
06/18/2022 04:04:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/18/2022 04:04:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/18/2022 04:04:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/18/2022 04:05:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/18/2022 04:05:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/18/2022 04:05:11 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8977060842383423 on epoch=121
06/18/2022 04:05:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/18/2022 04:05:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/18/2022 04:05:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/18/2022 04:05:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/18/2022 04:05:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/18/2022 04:05:31 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8434933933673853 on epoch=124
06/18/2022 04:05:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/18/2022 04:05:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/18/2022 04:05:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/18/2022 04:05:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/18/2022 04:05:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/18/2022 04:05:52 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8421721826560535 on epoch=128
06/18/2022 04:05:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/18/2022 04:05:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/18/2022 04:06:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/18/2022 04:06:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/18/2022 04:06:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 04:06:12 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8318944048782758 on epoch=132
06/18/2022 04:06:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
06/18/2022 04:06:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/18/2022 04:06:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/18/2022 04:06:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/18/2022 04:06:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/18/2022 04:06:32 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9513801610575803 on epoch=135
06/18/2022 04:06:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
06/18/2022 04:06:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/18/2022 04:06:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/18/2022 04:06:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/18/2022 04:06:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/18/2022 04:06:52 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.946948085196933 on epoch=139
06/18/2022 04:06:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/18/2022 04:06:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/18/2022 04:07:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/18/2022 04:07:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/18/2022 04:07:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/18/2022 04:07:11 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9284586381360574 on epoch=142
06/18/2022 04:07:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/18/2022 04:07:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/18/2022 04:07:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/18/2022 04:07:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/18/2022 04:07:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/18/2022 04:07:31 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9362869378850888 on epoch=146
06/18/2022 04:07:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
06/18/2022 04:07:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/18/2022 04:07:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
06/18/2022 04:07:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/18/2022 04:07:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
06/18/2022 04:07:51 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.934873394550814 on epoch=149
06/18/2022 04:07:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/18/2022 04:07:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/18/2022 04:07:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/18/2022 04:08:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/18/2022 04:08:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/18/2022 04:08:11 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.894781175813434 on epoch=153
06/18/2022 04:08:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/18/2022 04:08:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/18/2022 04:08:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/18/2022 04:08:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/18/2022 04:08:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/18/2022 04:08:31 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9633009887678818 on epoch=157
06/18/2022 04:08:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/18/2022 04:08:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/18/2022 04:08:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/18/2022 04:08:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/18/2022 04:08:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/18/2022 04:08:51 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.894781175813434 on epoch=160
06/18/2022 04:08:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/18/2022 04:08:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 04:08:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
06/18/2022 04:09:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
06/18/2022 04:09:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/18/2022 04:09:11 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8379459921798632 on epoch=164
06/18/2022 04:09:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/18/2022 04:09:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/18/2022 04:09:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/18/2022 04:09:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/18/2022 04:09:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/18/2022 04:09:32 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8367565119889597 on epoch=167
06/18/2022 04:09:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/18/2022 04:09:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/18/2022 04:09:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/18/2022 04:09:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/18/2022 04:09:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/18/2022 04:09:52 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8502486462163881 on epoch=171
06/18/2022 04:09:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/18/2022 04:09:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/18/2022 04:10:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/18/2022 04:10:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/18/2022 04:10:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/18/2022 04:10:13 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8916414051897924 on epoch=174
06/18/2022 04:10:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/18/2022 04:10:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/18/2022 04:10:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/18/2022 04:10:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/18/2022 04:10:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/18/2022 04:10:33 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8958121448444027 on epoch=178
06/18/2022 04:10:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 04:10:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/18/2022 04:10:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/18/2022 04:10:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/18/2022 04:10:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/18/2022 04:10:53 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9425641541391067 on epoch=182
06/18/2022 04:10:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/18/2022 04:10:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/18/2022 04:11:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/18/2022 04:11:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/18/2022 04:11:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/18/2022 04:11:13 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9632655277816566 on epoch=185
06/18/2022 04:11:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/18/2022 04:11:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/18/2022 04:11:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/18/2022 04:11:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/18/2022 04:11:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/18/2022 04:11:33 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.972843069627487 on epoch=189
06/18/2022 04:11:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/18/2022 04:11:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/18/2022 04:11:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/18/2022 04:11:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 04:11:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/18/2022 04:11:54 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.9776567518503005 on epoch=192
06/18/2022 04:11:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/18/2022 04:11:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/18/2022 04:12:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/18/2022 04:12:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/18/2022 04:12:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/18/2022 04:12:14 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9730388563049855 on epoch=196
06/18/2022 04:12:16 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/18/2022 04:12:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/18/2022 04:12:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/18/2022 04:12:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/18/2022 04:12:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/18/2022 04:12:34 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9008597830356211 on epoch=199
06/18/2022 04:12:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/18/2022 04:12:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/18/2022 04:12:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/18/2022 04:12:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 04:12:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/18/2022 04:12:54 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9140548982595701 on epoch=203
06/18/2022 04:12:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/18/2022 04:13:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/18/2022 04:13:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/18/2022 04:13:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/18/2022 04:13:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/18/2022 04:13:15 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8588204065122864 on epoch=207
06/18/2022 04:13:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/18/2022 04:13:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/18/2022 04:13:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/18/2022 04:13:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/18/2022 04:13:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/18/2022 04:13:36 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=210
06/18/2022 04:13:36 - INFO - __main__ - Saving model with best Classification-F1: 0.9865677649358864 -> 0.9865940511101802 on epoch=210, global_step=2950
06/18/2022 04:13:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 04:13:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/18/2022 04:13:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/18/2022 04:13:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/18/2022 04:13:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/18/2022 04:13:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:13:50 - INFO - __main__ - Printing 3 examples
06/18/2022 04:13:50 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 04:13:50 - INFO - __main__ - ['Film']
06/18/2022 04:13:50 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 04:13:50 - INFO - __main__ - ['Film']
06/18/2022 04:13:50 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 04:13:50 - INFO - __main__ - ['Film']
06/18/2022 04:13:50 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:13:50 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:13:51 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 04:13:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:13:51 - INFO - __main__ - Printing 3 examples
06/18/2022 04:13:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 04:13:51 - INFO - __main__ - ['Film']
06/18/2022 04:13:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 04:13:51 - INFO - __main__ - ['Film']
06/18/2022 04:13:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 04:13:51 - INFO - __main__ - ['Film']
06/18/2022 04:13:51 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:13:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:13:51 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 04:13:55 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=214
06/18/2022 04:13:55 - INFO - __main__ - save last model!
06/18/2022 04:13:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 04:13:55 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 04:13:55 - INFO - __main__ - Printing 3 examples
06/18/2022 04:13:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 04:13:55 - INFO - __main__ - ['Animal']
06/18/2022 04:13:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 04:13:55 - INFO - __main__ - ['Animal']
06/18/2022 04:13:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 04:13:55 - INFO - __main__ - ['Village']
06/18/2022 04:13:55 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:13:57 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:14:01 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 04:14:07 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 04:14:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 04:14:07 - INFO - __main__ - Starting training!
06/18/2022 04:16:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/18/2022 04:16:16 - INFO - __main__ - Classification-F1 on test data: 0.5255
06/18/2022 04:16:17 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9865940511101802, test_performance=0.5254862719657365
06/18/2022 04:16:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/18/2022 04:16:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:16:18 - INFO - __main__ - Printing 3 examples
06/18/2022 04:16:18 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 04:16:18 - INFO - __main__ - ['Film']
06/18/2022 04:16:18 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 04:16:18 - INFO - __main__ - ['Film']
06/18/2022 04:16:18 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 04:16:18 - INFO - __main__ - ['Film']
06/18/2022 04:16:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:16:18 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:16:18 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 04:16:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:16:18 - INFO - __main__ - Printing 3 examples
06/18/2022 04:16:18 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 04:16:18 - INFO - __main__ - ['Film']
06/18/2022 04:16:18 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 04:16:18 - INFO - __main__ - ['Film']
06/18/2022 04:16:18 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 04:16:18 - INFO - __main__ - ['Film']
06/18/2022 04:16:18 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:16:18 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:16:18 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 04:16:33 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 04:16:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 04:16:34 - INFO - __main__ - Starting training!
06/18/2022 04:16:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=0
06/18/2022 04:16:41 - INFO - __main__ - Step 20 Global step 20 Train loss 4.86 on epoch=1
06/18/2022 04:16:44 - INFO - __main__ - Step 30 Global step 30 Train loss 4.21 on epoch=2
06/18/2022 04:16:46 - INFO - __main__ - Step 40 Global step 40 Train loss 3.51 on epoch=2
06/18/2022 04:16:49 - INFO - __main__ - Step 50 Global step 50 Train loss 3.61 on epoch=3
06/18/2022 04:16:54 - INFO - __main__ - Global step 50 Train loss 4.59 Classification-F1 0.08110053918103455 on epoch=3
06/18/2022 04:16:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08110053918103455 on epoch=3, global_step=50
06/18/2022 04:16:57 - INFO - __main__ - Step 60 Global step 60 Train loss 3.11 on epoch=4
06/18/2022 04:17:00 - INFO - __main__ - Step 70 Global step 70 Train loss 2.65 on epoch=4
06/18/2022 04:17:02 - INFO - __main__ - Step 80 Global step 80 Train loss 2.68 on epoch=5
06/18/2022 04:17:05 - INFO - __main__ - Step 90 Global step 90 Train loss 2.24 on epoch=6
06/18/2022 04:17:08 - INFO - __main__ - Step 100 Global step 100 Train loss 2.24 on epoch=7
06/18/2022 04:17:13 - INFO - __main__ - Global step 100 Train loss 2.58 Classification-F1 0.10910918061601792 on epoch=7
06/18/2022 04:17:13 - INFO - __main__ - Saving model with best Classification-F1: 0.08110053918103455 -> 0.10910918061601792 on epoch=7, global_step=100
06/18/2022 04:17:16 - INFO - __main__ - Step 110 Global step 110 Train loss 1.82 on epoch=7
06/18/2022 04:17:18 - INFO - __main__ - Step 120 Global step 120 Train loss 1.90 on epoch=8
06/18/2022 04:17:21 - INFO - __main__ - Step 130 Global step 130 Train loss 1.77 on epoch=9
06/18/2022 04:17:24 - INFO - __main__ - Step 140 Global step 140 Train loss 1.49 on epoch=9
06/18/2022 04:17:26 - INFO - __main__ - Step 150 Global step 150 Train loss 1.61 on epoch=10
06/18/2022 04:17:32 - INFO - __main__ - Global step 150 Train loss 1.72 Classification-F1 0.15622440461673598 on epoch=10
06/18/2022 04:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.10910918061601792 -> 0.15622440461673598 on epoch=10, global_step=150
06/18/2022 04:17:34 - INFO - __main__ - Step 160 Global step 160 Train loss 1.31 on epoch=11
06/18/2022 04:17:37 - INFO - __main__ - Step 170 Global step 170 Train loss 1.25 on epoch=12
06/18/2022 04:17:40 - INFO - __main__ - Step 180 Global step 180 Train loss 1.17 on epoch=12
06/18/2022 04:17:42 - INFO - __main__ - Step 190 Global step 190 Train loss 1.11 on epoch=13
06/18/2022 04:17:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.98 on epoch=14
06/18/2022 04:17:51 - INFO - __main__ - Global step 200 Train loss 1.16 Classification-F1 0.3479951173218964 on epoch=14
06/18/2022 04:17:51 - INFO - __main__ - Saving model with best Classification-F1: 0.15622440461673598 -> 0.3479951173218964 on epoch=14, global_step=200
06/18/2022 04:17:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=14
06/18/2022 04:17:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=15
06/18/2022 04:17:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=16
06/18/2022 04:18:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=17
06/18/2022 04:18:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.70 on epoch=17
06/18/2022 04:18:11 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.4278107426663294 on epoch=17
06/18/2022 04:18:11 - INFO - __main__ - Saving model with best Classification-F1: 0.3479951173218964 -> 0.4278107426663294 on epoch=17, global_step=250
06/18/2022 04:18:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.66 on epoch=18
06/18/2022 04:18:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=19
06/18/2022 04:18:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=19
06/18/2022 04:18:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.58 on epoch=20
06/18/2022 04:18:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=21
06/18/2022 04:18:31 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.5685974000738475 on epoch=21
06/18/2022 04:18:31 - INFO - __main__ - Saving model with best Classification-F1: 0.4278107426663294 -> 0.5685974000738475 on epoch=21, global_step=300
06/18/2022 04:18:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=22
06/18/2022 04:18:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=22
06/18/2022 04:18:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=23
06/18/2022 04:18:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=24
06/18/2022 04:18:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=24
06/18/2022 04:18:50 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6301298701298701 on epoch=24
06/18/2022 04:18:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5685974000738475 -> 0.6301298701298701 on epoch=24, global_step=350
06/18/2022 04:18:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=25
06/18/2022 04:18:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/18/2022 04:18:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=27
06/18/2022 04:19:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=27
06/18/2022 04:19:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=28
06/18/2022 04:19:10 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.7064190289996741 on epoch=28
06/18/2022 04:19:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6301298701298701 -> 0.7064190289996741 on epoch=28, global_step=400
06/18/2022 04:19:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=29
06/18/2022 04:19:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=29
06/18/2022 04:19:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=30
06/18/2022 04:19:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
06/18/2022 04:19:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=32
06/18/2022 04:19:30 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.7094276094276094 on epoch=32
06/18/2022 04:19:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7064190289996741 -> 0.7094276094276094 on epoch=32, global_step=450
06/18/2022 04:19:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=32
06/18/2022 04:19:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
06/18/2022 04:19:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=34
06/18/2022 04:19:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/18/2022 04:19:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/18/2022 04:19:50 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.8137923351158645 on epoch=35
06/18/2022 04:19:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7094276094276094 -> 0.8137923351158645 on epoch=35, global_step=500
06/18/2022 04:19:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
06/18/2022 04:19:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/18/2022 04:19:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
06/18/2022 04:20:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=38
06/18/2022 04:20:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
06/18/2022 04:20:10 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.8710363396271714 on epoch=39
06/18/2022 04:20:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8137923351158645 -> 0.8710363396271714 on epoch=39, global_step=550
06/18/2022 04:20:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
06/18/2022 04:20:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/18/2022 04:20:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=41
06/18/2022 04:20:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=42
06/18/2022 04:20:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=42
06/18/2022 04:20:30 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.8947341578477624 on epoch=42
06/18/2022 04:20:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8710363396271714 -> 0.8947341578477624 on epoch=42, global_step=600
06/18/2022 04:20:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
06/18/2022 04:20:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
06/18/2022 04:20:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=44
06/18/2022 04:20:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=45
06/18/2022 04:20:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
06/18/2022 04:20:50 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.8859004794488666 on epoch=46
06/18/2022 04:20:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
06/18/2022 04:20:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
06/18/2022 04:20:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/18/2022 04:21:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/18/2022 04:21:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/18/2022 04:21:09 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.8857571102732393 on epoch=49
06/18/2022 04:21:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
06/18/2022 04:21:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
06/18/2022 04:21:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/18/2022 04:21:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/18/2022 04:21:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=53
06/18/2022 04:21:29 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.8198205968604451 on epoch=53
06/18/2022 04:21:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
06/18/2022 04:21:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
06/18/2022 04:21:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/18/2022 04:21:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=56
06/18/2022 04:21:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=57
06/18/2022 04:21:49 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.8859004794488666 on epoch=57
06/18/2022 04:21:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
06/18/2022 04:21:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/18/2022 04:21:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
06/18/2022 04:21:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
06/18/2022 04:22:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/18/2022 04:22:09 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.8402859237536657 on epoch=60
06/18/2022 04:22:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
06/18/2022 04:22:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/18/2022 04:22:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/18/2022 04:22:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
06/18/2022 04:22:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
06/18/2022 04:22:28 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.8562351626867756 on epoch=64
06/18/2022 04:22:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/18/2022 04:22:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/18/2022 04:22:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/18/2022 04:22:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/18/2022 04:22:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/18/2022 04:22:48 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.8535896600412729 on epoch=67
06/18/2022 04:22:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/18/2022 04:22:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
06/18/2022 04:22:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/18/2022 04:22:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/18/2022 04:23:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/18/2022 04:23:08 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8424402798142718 on epoch=71
06/18/2022 04:23:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/18/2022 04:23:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/18/2022 04:23:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/18/2022 04:23:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/18/2022 04:23:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
06/18/2022 04:23:27 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7763454389863588 on epoch=74
06/18/2022 04:23:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/18/2022 04:23:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
06/18/2022 04:23:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
06/18/2022 04:23:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
06/18/2022 04:23:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/18/2022 04:23:47 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7750778612481928 on epoch=78
06/18/2022 04:23:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/18/2022 04:23:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/18/2022 04:23:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/18/2022 04:23:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/18/2022 04:24:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/18/2022 04:24:07 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8005705869083478 on epoch=82
06/18/2022 04:24:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/18/2022 04:24:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/18/2022 04:24:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/18/2022 04:24:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/18/2022 04:24:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/18/2022 04:24:27 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.849545183012925 on epoch=85
06/18/2022 04:24:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/18/2022 04:24:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/18/2022 04:24:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/18/2022 04:24:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/18/2022 04:24:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/18/2022 04:24:47 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8523717430141234 on epoch=89
06/18/2022 04:24:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/18/2022 04:24:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/18/2022 04:24:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/18/2022 04:24:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/18/2022 04:25:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/18/2022 04:25:07 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7473323437481143 on epoch=92
06/18/2022 04:25:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/18/2022 04:25:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/18/2022 04:25:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/18/2022 04:25:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/18/2022 04:25:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/18/2022 04:25:27 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7137719665733249 on epoch=96
06/18/2022 04:25:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/18/2022 04:25:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/18/2022 04:25:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/18/2022 04:25:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/18/2022 04:25:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/18/2022 04:25:48 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6469640166340204 on epoch=99
06/18/2022 04:25:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/18/2022 04:25:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/18/2022 04:25:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/18/2022 04:25:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/18/2022 04:26:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/18/2022 04:26:08 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=103
06/18/2022 04:26:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8947341578477624 -> 0.9228413163897036 on epoch=103, global_step=1450
06/18/2022 04:26:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/18/2022 04:26:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/18/2022 04:26:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/18/2022 04:26:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/18/2022 04:26:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/18/2022 04:26:29 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=107
06/18/2022 04:26:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/18/2022 04:26:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/18/2022 04:26:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/18/2022 04:26:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/18/2022 04:26:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/18/2022 04:26:50 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7983364867615341 on epoch=110
06/18/2022 04:26:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/18/2022 04:26:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/18/2022 04:26:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/18/2022 04:27:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/18/2022 04:27:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/18/2022 04:27:10 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7998170349925569 on epoch=114
06/18/2022 04:27:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/18/2022 04:27:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/18/2022 04:27:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/18/2022 04:27:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/18/2022 04:27:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/18/2022 04:27:31 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8424285093639932 on epoch=117
06/18/2022 04:27:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/18/2022 04:27:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/18/2022 04:27:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/18/2022 04:27:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/18/2022 04:27:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/18/2022 04:27:52 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8588204065122864 on epoch=121
06/18/2022 04:27:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/18/2022 04:27:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/18/2022 04:28:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/18/2022 04:28:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/18/2022 04:28:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/18/2022 04:28:13 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8463385777901907 on epoch=124
06/18/2022 04:28:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/18/2022 04:28:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/18/2022 04:28:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/18/2022 04:28:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/18/2022 04:28:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/18/2022 04:28:33 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7040378417148617 on epoch=128
06/18/2022 04:28:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/18/2022 04:28:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/18/2022 04:28:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/18/2022 04:28:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/18/2022 04:28:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/18/2022 04:28:54 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9140548982595701 on epoch=132
06/18/2022 04:28:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/18/2022 04:28:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/18/2022 04:29:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/18/2022 04:29:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/18/2022 04:29:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/18/2022 04:29:14 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9055741227626656 on epoch=135
06/18/2022 04:29:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/18/2022 04:29:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/18/2022 04:29:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/18/2022 04:29:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/18/2022 04:29:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/18/2022 04:29:35 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9007450206106119 on epoch=139
06/18/2022 04:29:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/18/2022 04:29:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/18/2022 04:29:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/18/2022 04:29:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/18/2022 04:29:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/18/2022 04:29:56 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9095262738526496 on epoch=142
06/18/2022 04:29:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/18/2022 04:30:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/18/2022 04:30:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/18/2022 04:30:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/18/2022 04:30:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/18/2022 04:30:17 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7907860387556783 on epoch=146
06/18/2022 04:30:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/18/2022 04:30:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/18/2022 04:30:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/18/2022 04:30:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/18/2022 04:30:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/18/2022 04:30:38 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8505571629311549 on epoch=149
06/18/2022 04:30:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/18/2022 04:30:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/18/2022 04:30:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/18/2022 04:30:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/18/2022 04:30:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/18/2022 04:30:59 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9775075059349254 on epoch=153
06/18/2022 04:30:59 - INFO - __main__ - Saving model with best Classification-F1: 0.9228413163897036 -> 0.9775075059349254 on epoch=153, global_step=2150
06/18/2022 04:31:02 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/18/2022 04:31:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/18/2022 04:31:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/18/2022 04:31:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/18/2022 04:31:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/18/2022 04:31:20 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9098882315929034 on epoch=157
06/18/2022 04:31:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/18/2022 04:31:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/18/2022 04:31:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/18/2022 04:31:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/18/2022 04:31:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/18/2022 04:31:41 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.851004088086089 on epoch=160
06/18/2022 04:31:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/18/2022 04:31:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 04:31:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/18/2022 04:31:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/18/2022 04:31:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/18/2022 04:32:02 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.854910338086089 on epoch=164
06/18/2022 04:32:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/18/2022 04:32:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/18/2022 04:32:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/18/2022 04:32:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/18/2022 04:32:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/18/2022 04:32:22 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7981459119979045 on epoch=167
06/18/2022 04:32:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/18/2022 04:32:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/18/2022 04:32:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/18/2022 04:32:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/18/2022 04:32:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/18/2022 04:32:43 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7961336323385659 on epoch=171
06/18/2022 04:32:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/18/2022 04:32:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/18/2022 04:32:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 04:32:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/18/2022 04:32:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/18/2022 04:33:04 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7924571617503307 on epoch=174
06/18/2022 04:33:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/18/2022 04:33:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/18/2022 04:33:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/18/2022 04:33:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/18/2022 04:33:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/18/2022 04:33:25 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7961336323385659 on epoch=178
06/18/2022 04:33:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/18/2022 04:33:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/18/2022 04:33:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/18/2022 04:33:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/18/2022 04:33:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/18/2022 04:33:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9036654679918438 on epoch=182
06/18/2022 04:33:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/18/2022 04:33:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/18/2022 04:33:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 04:33:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/18/2022 04:33:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/18/2022 04:34:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7876422304302091 on epoch=185
06/18/2022 04:34:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/18/2022 04:34:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/18/2022 04:34:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/18/2022 04:34:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/18/2022 04:34:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/18/2022 04:34:30 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8450626574366493 on epoch=189
06/18/2022 04:34:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/18/2022 04:34:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/18/2022 04:34:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/18/2022 04:34:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 04:34:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/18/2022 04:34:51 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9014001679324262 on epoch=192
06/18/2022 04:34:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/18/2022 04:34:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 04:34:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/18/2022 04:35:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/18/2022 04:35:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/18/2022 04:35:12 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8469565968305888 on epoch=196
06/18/2022 04:35:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/18/2022 04:35:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/18/2022 04:35:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/18/2022 04:35:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/18/2022 04:35:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/18/2022 04:35:34 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9014001679324262 on epoch=199
06/18/2022 04:35:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/18/2022 04:35:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/18/2022 04:35:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 04:35:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 04:35:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/18/2022 04:35:56 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9044391043046958 on epoch=203
06/18/2022 04:35:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/18/2022 04:36:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/18/2022 04:36:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/18/2022 04:36:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/18/2022 04:36:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/18/2022 04:36:16 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9064593063248978 on epoch=207
06/18/2022 04:36:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/18/2022 04:36:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/18/2022 04:36:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/18/2022 04:36:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/18/2022 04:36:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/18/2022 04:36:37 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.907260973793232 on epoch=210
06/18/2022 04:36:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 04:36:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/18/2022 04:36:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/18/2022 04:36:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/18/2022 04:36:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/18/2022 04:36:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:36:52 - INFO - __main__ - Printing 3 examples
06/18/2022 04:36:52 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 04:36:52 - INFO - __main__ - ['Film']
06/18/2022 04:36:52 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 04:36:52 - INFO - __main__ - ['Film']
06/18/2022 04:36:52 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 04:36:52 - INFO - __main__ - ['Film']
06/18/2022 04:36:52 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:36:52 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:36:52 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 04:36:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:36:52 - INFO - __main__ - Printing 3 examples
06/18/2022 04:36:52 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 04:36:52 - INFO - __main__ - ['Film']
06/18/2022 04:36:52 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 04:36:52 - INFO - __main__ - ['Film']
06/18/2022 04:36:52 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 04:36:52 - INFO - __main__ - ['Film']
06/18/2022 04:36:52 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:36:52 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:36:53 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 04:36:58 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.854910338086089 on epoch=214
06/18/2022 04:36:58 - INFO - __main__ - save last model!
06/18/2022 04:36:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 04:36:58 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 04:36:58 - INFO - __main__ - Printing 3 examples
06/18/2022 04:36:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 04:36:58 - INFO - __main__ - ['Animal']
06/18/2022 04:36:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 04:36:58 - INFO - __main__ - ['Animal']
06/18/2022 04:36:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 04:36:58 - INFO - __main__ - ['Village']
06/18/2022 04:36:58 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:37:00 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:37:04 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 04:37:08 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 04:37:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 04:37:08 - INFO - __main__ - Starting training!
06/18/2022 04:40:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/18/2022 04:40:01 - INFO - __main__ - Classification-F1 on test data: 0.5473
06/18/2022 04:40:01 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9775075059349254, test_performance=0.547299650906635
06/18/2022 04:40:01 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/18/2022 04:40:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:40:02 - INFO - __main__ - Printing 3 examples
06/18/2022 04:40:02 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 04:40:02 - INFO - __main__ - ['Film']
06/18/2022 04:40:02 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 04:40:02 - INFO - __main__ - ['Film']
06/18/2022 04:40:02 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 04:40:02 - INFO - __main__ - ['Film']
06/18/2022 04:40:02 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:40:02 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:40:03 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 04:40:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:40:03 - INFO - __main__ - Printing 3 examples
06/18/2022 04:40:03 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 04:40:03 - INFO - __main__ - ['Film']
06/18/2022 04:40:03 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 04:40:03 - INFO - __main__ - ['Film']
06/18/2022 04:40:03 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 04:40:03 - INFO - __main__ - ['Film']
06/18/2022 04:40:03 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:40:03 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:40:03 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 04:40:18 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 04:40:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 04:40:19 - INFO - __main__ - Starting training!
06/18/2022 04:40:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.19 on epoch=0
06/18/2022 04:40:25 - INFO - __main__ - Step 20 Global step 20 Train loss 5.17 on epoch=1
06/18/2022 04:40:28 - INFO - __main__ - Step 30 Global step 30 Train loss 4.64 on epoch=2
06/18/2022 04:40:31 - INFO - __main__ - Step 40 Global step 40 Train loss 4.10 on epoch=2
06/18/2022 04:40:33 - INFO - __main__ - Step 50 Global step 50 Train loss 4.25 on epoch=3
06/18/2022 04:40:40 - INFO - __main__ - Global step 50 Train loss 5.07 Classification-F1 0.0505208943783774 on epoch=3
06/18/2022 04:40:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0505208943783774 on epoch=3, global_step=50
06/18/2022 04:40:42 - INFO - __main__ - Step 60 Global step 60 Train loss 3.66 on epoch=4
06/18/2022 04:40:45 - INFO - __main__ - Step 70 Global step 70 Train loss 2.98 on epoch=4
06/18/2022 04:40:48 - INFO - __main__ - Step 80 Global step 80 Train loss 3.39 on epoch=5
06/18/2022 04:40:50 - INFO - __main__ - Step 90 Global step 90 Train loss 2.66 on epoch=6
06/18/2022 04:40:53 - INFO - __main__ - Step 100 Global step 100 Train loss 2.64 on epoch=7
06/18/2022 04:40:58 - INFO - __main__ - Global step 100 Train loss 3.07 Classification-F1 0.11005321483432082 on epoch=7
06/18/2022 04:40:58 - INFO - __main__ - Saving model with best Classification-F1: 0.0505208943783774 -> 0.11005321483432082 on epoch=7, global_step=100
06/18/2022 04:41:01 - INFO - __main__ - Step 110 Global step 110 Train loss 2.44 on epoch=7
06/18/2022 04:41:03 - INFO - __main__ - Step 120 Global step 120 Train loss 2.39 on epoch=8
06/18/2022 04:41:06 - INFO - __main__ - Step 130 Global step 130 Train loss 2.25 on epoch=9
06/18/2022 04:41:08 - INFO - __main__ - Step 140 Global step 140 Train loss 1.86 on epoch=9
06/18/2022 04:41:11 - INFO - __main__ - Step 150 Global step 150 Train loss 2.10 on epoch=10
06/18/2022 04:41:16 - INFO - __main__ - Global step 150 Train loss 2.21 Classification-F1 0.1258738678999007 on epoch=10
06/18/2022 04:41:16 - INFO - __main__ - Saving model with best Classification-F1: 0.11005321483432082 -> 0.1258738678999007 on epoch=10, global_step=150
06/18/2022 04:41:19 - INFO - __main__ - Step 160 Global step 160 Train loss 1.81 on epoch=11
06/18/2022 04:41:22 - INFO - __main__ - Step 170 Global step 170 Train loss 1.81 on epoch=12
06/18/2022 04:41:24 - INFO - __main__ - Step 180 Global step 180 Train loss 1.57 on epoch=12
06/18/2022 04:41:27 - INFO - __main__ - Step 190 Global step 190 Train loss 1.65 on epoch=13
06/18/2022 04:41:29 - INFO - __main__ - Step 200 Global step 200 Train loss 1.42 on epoch=14
06/18/2022 04:41:35 - INFO - __main__ - Global step 200 Train loss 1.65 Classification-F1 0.15988980390350097 on epoch=14
06/18/2022 04:41:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1258738678999007 -> 0.15988980390350097 on epoch=14, global_step=200
06/18/2022 04:41:38 - INFO - __main__ - Step 210 Global step 210 Train loss 1.30 on epoch=14
06/18/2022 04:41:40 - INFO - __main__ - Step 220 Global step 220 Train loss 1.41 on epoch=15
06/18/2022 04:41:43 - INFO - __main__ - Step 230 Global step 230 Train loss 1.21 on epoch=16
06/18/2022 04:41:46 - INFO - __main__ - Step 240 Global step 240 Train loss 1.12 on epoch=17
06/18/2022 04:41:48 - INFO - __main__ - Step 250 Global step 250 Train loss 1.07 on epoch=17
06/18/2022 04:41:55 - INFO - __main__ - Global step 250 Train loss 1.22 Classification-F1 0.2846629257384868 on epoch=17
06/18/2022 04:41:55 - INFO - __main__ - Saving model with best Classification-F1: 0.15988980390350097 -> 0.2846629257384868 on epoch=17, global_step=250
06/18/2022 04:41:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.97 on epoch=18
06/18/2022 04:42:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.88 on epoch=19
06/18/2022 04:42:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=19
06/18/2022 04:42:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.88 on epoch=20
06/18/2022 04:42:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=21
06/18/2022 04:42:14 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.37000562718842295 on epoch=21
06/18/2022 04:42:14 - INFO - __main__ - Saving model with best Classification-F1: 0.2846629257384868 -> 0.37000562718842295 on epoch=21, global_step=300
06/18/2022 04:42:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.78 on epoch=22
06/18/2022 04:42:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.71 on epoch=22
06/18/2022 04:42:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=23
06/18/2022 04:42:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=24
06/18/2022 04:42:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=24
06/18/2022 04:42:34 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.5355348718602575 on epoch=24
06/18/2022 04:42:34 - INFO - __main__ - Saving model with best Classification-F1: 0.37000562718842295 -> 0.5355348718602575 on epoch=24, global_step=350
06/18/2022 04:42:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=25
06/18/2022 04:42:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=26
06/18/2022 04:42:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.57 on epoch=27
06/18/2022 04:42:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=27
06/18/2022 04:42:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.52 on epoch=28
06/18/2022 04:42:54 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.5834194336171323 on epoch=28
06/18/2022 04:42:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5355348718602575 -> 0.5834194336171323 on epoch=28, global_step=400
06/18/2022 04:42:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=29
06/18/2022 04:42:59 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=29
06/18/2022 04:43:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/18/2022 04:43:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
06/18/2022 04:43:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=32
06/18/2022 04:43:13 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6347507127333978 on epoch=32
06/18/2022 04:43:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5834194336171323 -> 0.6347507127333978 on epoch=32, global_step=450
06/18/2022 04:43:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=32
06/18/2022 04:43:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
06/18/2022 04:43:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=34
06/18/2022 04:43:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=34
06/18/2022 04:43:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=35
06/18/2022 04:43:33 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.7433402881485294 on epoch=35
06/18/2022 04:43:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6347507127333978 -> 0.7433402881485294 on epoch=35, global_step=500
06/18/2022 04:43:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=36
06/18/2022 04:43:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=37
06/18/2022 04:43:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
06/18/2022 04:43:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=38
06/18/2022 04:43:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
06/18/2022 04:43:53 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.752721319681918 on epoch=39
06/18/2022 04:43:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7433402881485294 -> 0.752721319681918 on epoch=39, global_step=550
06/18/2022 04:43:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
06/18/2022 04:43:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=40
06/18/2022 04:44:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
06/18/2022 04:44:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=42
06/18/2022 04:44:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=42
06/18/2022 04:44:13 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.7831407049623368 on epoch=42
06/18/2022 04:44:13 - INFO - __main__ - Saving model with best Classification-F1: 0.752721319681918 -> 0.7831407049623368 on epoch=42, global_step=600
06/18/2022 04:44:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
06/18/2022 04:44:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=44
06/18/2022 04:44:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
06/18/2022 04:44:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
06/18/2022 04:44:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/18/2022 04:44:32 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.7481160772530269 on epoch=46
06/18/2022 04:44:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/18/2022 04:44:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=47
06/18/2022 04:44:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/18/2022 04:44:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/18/2022 04:44:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
06/18/2022 04:44:51 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.7182118464850914 on epoch=49
06/18/2022 04:44:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/18/2022 04:44:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/18/2022 04:44:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=52
06/18/2022 04:45:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
06/18/2022 04:45:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
06/18/2022 04:45:11 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.6939724678264576 on epoch=53
06/18/2022 04:45:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=54
06/18/2022 04:45:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
06/18/2022 04:45:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
06/18/2022 04:45:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/18/2022 04:45:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/18/2022 04:45:30 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7238434143357743 on epoch=57
06/18/2022 04:45:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
06/18/2022 04:45:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/18/2022 04:45:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
06/18/2022 04:45:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/18/2022 04:45:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=60
06/18/2022 04:45:50 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7988929104901871 on epoch=60
06/18/2022 04:45:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7831407049623368 -> 0.7988929104901871 on epoch=60, global_step=850
06/18/2022 04:45:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
06/18/2022 04:45:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=62
06/18/2022 04:45:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/18/2022 04:46:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/18/2022 04:46:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/18/2022 04:46:09 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.795892128112242 on epoch=64
06/18/2022 04:46:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/18/2022 04:46:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=65
06/18/2022 04:46:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/18/2022 04:46:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/18/2022 04:46:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
06/18/2022 04:46:28 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7788511298947731 on epoch=67
06/18/2022 04:46:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/18/2022 04:46:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/18/2022 04:46:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=69
06/18/2022 04:46:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
06/18/2022 04:46:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/18/2022 04:46:47 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.8244167052528683 on epoch=71
06/18/2022 04:46:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7988929104901871 -> 0.8244167052528683 on epoch=71, global_step=1000
06/18/2022 04:46:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/18/2022 04:46:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
06/18/2022 04:46:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/18/2022 04:46:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=74
06/18/2022 04:47:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
06/18/2022 04:47:07 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.849679863147605 on epoch=74
06/18/2022 04:47:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8244167052528683 -> 0.849679863147605 on epoch=74, global_step=1050
06/18/2022 04:47:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/18/2022 04:47:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
06/18/2022 04:47:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
06/18/2022 04:47:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
06/18/2022 04:47:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/18/2022 04:47:26 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.8527567862245282 on epoch=78
06/18/2022 04:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.849679863147605 -> 0.8527567862245282 on epoch=78, global_step=1100
06/18/2022 04:47:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
06/18/2022 04:47:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/18/2022 04:47:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=80
06/18/2022 04:47:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/18/2022 04:47:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/18/2022 04:47:45 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8488237173958237 on epoch=82
06/18/2022 04:47:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/18/2022 04:47:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/18/2022 04:47:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/18/2022 04:47:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/18/2022 04:47:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/18/2022 04:48:04 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7856674457788344 on epoch=85
06/18/2022 04:48:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/18/2022 04:48:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/18/2022 04:48:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
06/18/2022 04:48:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/18/2022 04:48:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/18/2022 04:48:23 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.9078672876775344 on epoch=89
06/18/2022 04:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8527567862245282 -> 0.9078672876775344 on epoch=89, global_step=1250
06/18/2022 04:48:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/18/2022 04:48:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/18/2022 04:48:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/18/2022 04:48:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/18/2022 04:48:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/18/2022 04:48:42 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.8454638012439164 on epoch=92
06/18/2022 04:48:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/18/2022 04:48:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/18/2022 04:48:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/18/2022 04:48:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
06/18/2022 04:48:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/18/2022 04:49:01 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9186705767350929 on epoch=96
06/18/2022 04:49:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9078672876775344 -> 0.9186705767350929 on epoch=96, global_step=1350
06/18/2022 04:49:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/18/2022 04:49:07 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/18/2022 04:49:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/18/2022 04:49:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/18/2022 04:49:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/18/2022 04:49:20 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7946453116826966 on epoch=99
06/18/2022 04:49:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=100
06/18/2022 04:49:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/18/2022 04:49:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/18/2022 04:49:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/18/2022 04:49:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/18/2022 04:49:40 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7969634803294657 on epoch=103
06/18/2022 04:49:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/18/2022 04:49:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/18/2022 04:49:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/18/2022 04:49:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/18/2022 04:49:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/18/2022 04:49:59 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7526877314222732 on epoch=107
06/18/2022 04:50:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/18/2022 04:50:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/18/2022 04:50:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/18/2022 04:50:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/18/2022 04:50:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/18/2022 04:50:18 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.855058651026393 on epoch=110
06/18/2022 04:50:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/18/2022 04:50:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/18/2022 04:50:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/18/2022 04:50:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/18/2022 04:50:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/18/2022 04:50:36 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7800452357337103 on epoch=114
06/18/2022 04:50:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/18/2022 04:50:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/18/2022 04:50:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/18/2022 04:50:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/18/2022 04:50:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/18/2022 04:50:56 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8389367584766066 on epoch=117
06/18/2022 04:50:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/18/2022 04:51:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/18/2022 04:51:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/18/2022 04:51:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/18/2022 04:51:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/18/2022 04:51:15 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7945299201466185 on epoch=121
06/18/2022 04:51:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/18/2022 04:51:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/18/2022 04:51:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/18/2022 04:51:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/18/2022 04:51:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/18/2022 04:51:34 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8550255647119298 on epoch=124
06/18/2022 04:51:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/18/2022 04:51:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/18/2022 04:51:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/18/2022 04:51:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
06/18/2022 04:51:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/18/2022 04:51:53 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9141737336725231 on epoch=128
06/18/2022 04:51:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/18/2022 04:51:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/18/2022 04:52:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/18/2022 04:52:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/18/2022 04:52:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/18/2022 04:52:12 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8999713842977601 on epoch=132
06/18/2022 04:52:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/18/2022 04:52:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/18/2022 04:52:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/18/2022 04:52:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/18/2022 04:52:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/18/2022 04:52:31 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9102345519392238 on epoch=135
06/18/2022 04:52:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/18/2022 04:52:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
06/18/2022 04:52:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/18/2022 04:52:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/18/2022 04:52:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/18/2022 04:52:51 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9103086366511415 on epoch=139
06/18/2022 04:52:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
06/18/2022 04:52:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/18/2022 04:52:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/18/2022 04:53:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/18/2022 04:53:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/18/2022 04:53:10 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9821254014802404 on epoch=142
06/18/2022 04:53:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9186705767350929 -> 0.9821254014802404 on epoch=142, global_step=2000
06/18/2022 04:53:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/18/2022 04:53:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/18/2022 04:53:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/18/2022 04:53:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/18/2022 04:53:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/18/2022 04:53:30 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9143564679048553 on epoch=146
06/18/2022 04:53:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/18/2022 04:53:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/18/2022 04:53:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/18/2022 04:53:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/18/2022 04:53:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/18/2022 04:53:49 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=149
06/18/2022 04:53:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/18/2022 04:53:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/18/2022 04:53:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/18/2022 04:53:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/18/2022 04:54:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/18/2022 04:54:09 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8550217462857325 on epoch=153
06/18/2022 04:54:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/18/2022 04:54:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/18/2022 04:54:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/18/2022 04:54:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/18/2022 04:54:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/18/2022 04:54:28 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9101857282502446 on epoch=157
06/18/2022 04:54:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/18/2022 04:54:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/18/2022 04:54:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/18/2022 04:54:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/18/2022 04:54:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/18/2022 04:54:48 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8103501811281698 on epoch=160
06/18/2022 04:54:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/18/2022 04:54:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/18/2022 04:54:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/18/2022 04:54:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/18/2022 04:55:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/18/2022 04:55:08 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.857086999022483 on epoch=164
06/18/2022 04:55:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/18/2022 04:55:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/18/2022 04:55:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/18/2022 04:55:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/18/2022 04:55:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/18/2022 04:55:27 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8569156856796718 on epoch=167
06/18/2022 04:55:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/18/2022 04:55:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/18/2022 04:55:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/18/2022 04:55:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/18/2022 04:55:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/18/2022 04:55:47 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8609970674486804 on epoch=171
06/18/2022 04:55:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/18/2022 04:55:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/18/2022 04:55:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/18/2022 04:55:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/18/2022 04:56:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/18/2022 04:56:06 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8591069464809384 on epoch=174
06/18/2022 04:56:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/18/2022 04:56:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/18/2022 04:56:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/18/2022 04:56:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/18/2022 04:56:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
06/18/2022 04:56:27 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8631514235092864 on epoch=178
06/18/2022 04:56:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/18/2022 04:56:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/18/2022 04:56:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/18/2022 04:56:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/18/2022 04:56:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/18/2022 04:56:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.905238767604359 on epoch=182
06/18/2022 04:56:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/18/2022 04:56:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/18/2022 04:56:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 04:56:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/18/2022 04:57:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/18/2022 04:57:06 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9100029940179126 on epoch=185
06/18/2022 04:57:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/18/2022 04:57:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/18/2022 04:57:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/18/2022 04:57:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/18/2022 04:57:19 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/18/2022 04:57:26 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9100029940179126 on epoch=189
06/18/2022 04:57:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/18/2022 04:57:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/18/2022 04:57:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/18/2022 04:57:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/18/2022 04:57:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/18/2022 04:57:46 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9100029940179126 on epoch=192
06/18/2022 04:57:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/18/2022 04:57:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/18/2022 04:57:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/18/2022 04:57:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/18/2022 04:57:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/18/2022 04:58:06 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=196
06/18/2022 04:58:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/18/2022 04:58:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/18/2022 04:58:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/18/2022 04:58:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/18/2022 04:58:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/18/2022 04:58:26 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9144998370804825 on epoch=199
06/18/2022 04:58:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
06/18/2022 04:58:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/18/2022 04:58:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 04:58:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/18/2022 04:58:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/18/2022 04:58:47 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=203
06/18/2022 04:58:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9821254014802404 -> 0.9865940511101802 on epoch=203, global_step=2850
06/18/2022 04:58:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/18/2022 04:58:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=204
06/18/2022 04:58:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/18/2022 04:58:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/18/2022 04:59:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/18/2022 04:59:07 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9098841586049595 on epoch=207
06/18/2022 04:59:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/18/2022 04:59:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/18/2022 04:59:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/18/2022 04:59:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/18/2022 04:59:20 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/18/2022 04:59:28 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9098882315929034 on epoch=210
06/18/2022 04:59:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/18/2022 04:59:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/18/2022 04:59:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/18/2022 04:59:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/18/2022 04:59:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/18/2022 04:59:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:59:43 - INFO - __main__ - Printing 3 examples
06/18/2022 04:59:43 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 04:59:43 - INFO - __main__ - ['Film']
06/18/2022 04:59:43 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 04:59:43 - INFO - __main__ - ['Film']
06/18/2022 04:59:43 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 04:59:43 - INFO - __main__ - ['Film']
06/18/2022 04:59:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:59:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:59:43 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 04:59:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 04:59:43 - INFO - __main__ - Printing 3 examples
06/18/2022 04:59:43 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 04:59:43 - INFO - __main__ - ['Film']
06/18/2022 04:59:43 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 04:59:43 - INFO - __main__ - ['Film']
06/18/2022 04:59:43 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 04:59:43 - INFO - __main__ - ['Film']
06/18/2022 04:59:43 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:59:43 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:59:43 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 04:59:49 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8370536005213425 on epoch=214
06/18/2022 04:59:49 - INFO - __main__ - save last model!
06/18/2022 04:59:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 04:59:49 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 04:59:49 - INFO - __main__ - Printing 3 examples
06/18/2022 04:59:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 04:59:49 - INFO - __main__ - ['Animal']
06/18/2022 04:59:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 04:59:49 - INFO - __main__ - ['Animal']
06/18/2022 04:59:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 04:59:49 - INFO - __main__ - ['Village']
06/18/2022 04:59:49 - INFO - __main__ - Tokenizing Input ...
06/18/2022 04:59:51 - INFO - __main__ - Tokenizing Output ...
06/18/2022 04:59:54 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 04:59:59 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 04:59:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 04:59:59 - INFO - __main__ - Starting training!
06/18/2022 05:02:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/18/2022 05:02:08 - INFO - __main__ - Classification-F1 on test data: 0.5191
06/18/2022 05:02:08 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9865940511101802, test_performance=0.5191102088585087
06/18/2022 05:02:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/18/2022 05:02:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 05:02:09 - INFO - __main__ - Printing 3 examples
06/18/2022 05:02:09 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/18/2022 05:02:09 - INFO - __main__ - ['Film']
06/18/2022 05:02:09 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/18/2022 05:02:09 - INFO - __main__ - ['Film']
06/18/2022 05:02:09 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/18/2022 05:02:09 - INFO - __main__ - ['Film']
06/18/2022 05:02:09 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:02:09 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:02:10 - INFO - __main__ - Loaded 224 examples from train data
06/18/2022 05:02:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/18/2022 05:02:10 - INFO - __main__ - Printing 3 examples
06/18/2022 05:02:10 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/18/2022 05:02:10 - INFO - __main__ - ['Film']
06/18/2022 05:02:10 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/18/2022 05:02:10 - INFO - __main__ - ['Film']
06/18/2022 05:02:10 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/18/2022 05:02:10 - INFO - __main__ - ['Film']
06/18/2022 05:02:10 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:02:10 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:02:10 - INFO - __main__ - Loaded 224 examples from dev data
06/18/2022 05:02:25 - INFO - __main__ - load prompt embedding from ckpt
06/18/2022 05:02:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/18/2022 05:02:26 - INFO - __main__ - Starting training!
06/18/2022 05:02:30 - INFO - __main__ - Step 10 Global step 10 Train loss 7.45 on epoch=0
06/18/2022 05:02:32 - INFO - __main__ - Step 20 Global step 20 Train loss 5.48 on epoch=1
06/18/2022 05:02:35 - INFO - __main__ - Step 30 Global step 30 Train loss 5.12 on epoch=2
06/18/2022 05:02:37 - INFO - __main__ - Step 40 Global step 40 Train loss 4.46 on epoch=2
06/18/2022 05:02:40 - INFO - __main__ - Step 50 Global step 50 Train loss 4.63 on epoch=3
06/18/2022 05:02:47 - INFO - __main__ - Global step 50 Train loss 5.43 Classification-F1 0.026548271130314476 on epoch=3
06/18/2022 05:02:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.026548271130314476 on epoch=3, global_step=50
06/18/2022 05:02:49 - INFO - __main__ - Step 60 Global step 60 Train loss 4.37 on epoch=4
06/18/2022 05:02:52 - INFO - __main__ - Step 70 Global step 70 Train loss 3.60 on epoch=4
06/18/2022 05:02:54 - INFO - __main__ - Step 80 Global step 80 Train loss 4.06 on epoch=5
06/18/2022 05:02:57 - INFO - __main__ - Step 90 Global step 90 Train loss 3.57 on epoch=6
06/18/2022 05:03:00 - INFO - __main__ - Step 100 Global step 100 Train loss 3.38 on epoch=7
06/18/2022 05:03:05 - INFO - __main__ - Global step 100 Train loss 3.80 Classification-F1 0.08999842382531843 on epoch=7
06/18/2022 05:03:05 - INFO - __main__ - Saving model with best Classification-F1: 0.026548271130314476 -> 0.08999842382531843 on epoch=7, global_step=100
06/18/2022 05:03:07 - INFO - __main__ - Step 110 Global step 110 Train loss 3.10 on epoch=7
06/18/2022 05:03:10 - INFO - __main__ - Step 120 Global step 120 Train loss 3.13 on epoch=8
06/18/2022 05:03:13 - INFO - __main__ - Step 130 Global step 130 Train loss 2.85 on epoch=9
06/18/2022 05:03:15 - INFO - __main__ - Step 140 Global step 140 Train loss 2.59 on epoch=9
06/18/2022 05:03:18 - INFO - __main__ - Step 150 Global step 150 Train loss 2.74 on epoch=10
06/18/2022 05:03:23 - INFO - __main__ - Global step 150 Train loss 2.88 Classification-F1 0.11528598840426797 on epoch=10
06/18/2022 05:03:23 - INFO - __main__ - Saving model with best Classification-F1: 0.08999842382531843 -> 0.11528598840426797 on epoch=10, global_step=150
06/18/2022 05:03:26 - INFO - __main__ - Step 160 Global step 160 Train loss 2.37 on epoch=11
06/18/2022 05:03:28 - INFO - __main__ - Step 170 Global step 170 Train loss 2.34 on epoch=12
06/18/2022 05:03:31 - INFO - __main__ - Step 180 Global step 180 Train loss 1.98 on epoch=12
06/18/2022 05:03:33 - INFO - __main__ - Step 190 Global step 190 Train loss 2.22 on epoch=13
06/18/2022 05:03:36 - INFO - __main__ - Step 200 Global step 200 Train loss 2.04 on epoch=14
06/18/2022 05:03:41 - INFO - __main__ - Global step 200 Train loss 2.19 Classification-F1 0.12308497286457616 on epoch=14
06/18/2022 05:03:41 - INFO - __main__ - Saving model with best Classification-F1: 0.11528598840426797 -> 0.12308497286457616 on epoch=14, global_step=200
06/18/2022 05:03:44 - INFO - __main__ - Step 210 Global step 210 Train loss 1.88 on epoch=14
06/18/2022 05:03:46 - INFO - __main__ - Step 220 Global step 220 Train loss 2.27 on epoch=15
06/18/2022 05:03:49 - INFO - __main__ - Step 230 Global step 230 Train loss 1.80 on epoch=16
06/18/2022 05:03:52 - INFO - __main__ - Step 240 Global step 240 Train loss 1.72 on epoch=17
06/18/2022 05:03:54 - INFO - __main__ - Step 250 Global step 250 Train loss 1.62 on epoch=17
06/18/2022 05:03:59 - INFO - __main__ - Global step 250 Train loss 1.86 Classification-F1 0.13690792875211621 on epoch=17
06/18/2022 05:03:59 - INFO - __main__ - Saving model with best Classification-F1: 0.12308497286457616 -> 0.13690792875211621 on epoch=17, global_step=250
06/18/2022 05:04:02 - INFO - __main__ - Step 260 Global step 260 Train loss 1.86 on epoch=18
06/18/2022 05:04:04 - INFO - __main__ - Step 270 Global step 270 Train loss 1.58 on epoch=19
06/18/2022 05:04:07 - INFO - __main__ - Step 280 Global step 280 Train loss 1.41 on epoch=19
06/18/2022 05:04:10 - INFO - __main__ - Step 290 Global step 290 Train loss 1.62 on epoch=20
06/18/2022 05:04:12 - INFO - __main__ - Step 300 Global step 300 Train loss 1.45 on epoch=21
06/18/2022 05:04:18 - INFO - __main__ - Global step 300 Train loss 1.58 Classification-F1 0.17133788667533928 on epoch=21
06/18/2022 05:04:18 - INFO - __main__ - Saving model with best Classification-F1: 0.13690792875211621 -> 0.17133788667533928 on epoch=21, global_step=300
06/18/2022 05:04:20 - INFO - __main__ - Step 310 Global step 310 Train loss 1.36 on epoch=22
06/18/2022 05:04:23 - INFO - __main__ - Step 320 Global step 320 Train loss 1.25 on epoch=22
06/18/2022 05:04:26 - INFO - __main__ - Step 330 Global step 330 Train loss 1.20 on epoch=23
06/18/2022 05:04:28 - INFO - __main__ - Step 340 Global step 340 Train loss 1.20 on epoch=24
06/18/2022 05:04:31 - INFO - __main__ - Step 350 Global step 350 Train loss 1.02 on epoch=24
06/18/2022 05:04:37 - INFO - __main__ - Global step 350 Train loss 1.21 Classification-F1 0.24990313358476052 on epoch=24
06/18/2022 05:04:37 - INFO - __main__ - Saving model with best Classification-F1: 0.17133788667533928 -> 0.24990313358476052 on epoch=24, global_step=350
06/18/2022 05:04:39 - INFO - __main__ - Step 360 Global step 360 Train loss 1.23 on epoch=25
06/18/2022 05:04:42 - INFO - __main__ - Step 370 Global step 370 Train loss 1.10 on epoch=26
06/18/2022 05:04:44 - INFO - __main__ - Step 380 Global step 380 Train loss 1.04 on epoch=27
06/18/2022 05:04:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.92 on epoch=27
06/18/2022 05:04:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.96 on epoch=28
06/18/2022 05:04:56 - INFO - __main__ - Global step 400 Train loss 1.05 Classification-F1 0.34342235331156185 on epoch=28
06/18/2022 05:04:56 - INFO - __main__ - Saving model with best Classification-F1: 0.24990313358476052 -> 0.34342235331156185 on epoch=28, global_step=400
06/18/2022 05:04:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.98 on epoch=29
06/18/2022 05:05:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.87 on epoch=29
06/18/2022 05:05:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.83 on epoch=30
06/18/2022 05:05:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.84 on epoch=31
06/18/2022 05:05:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.77 on epoch=32
06/18/2022 05:05:16 - INFO - __main__ - Global step 450 Train loss 0.86 Classification-F1 0.48032743080940427 on epoch=32
06/18/2022 05:05:16 - INFO - __main__ - Saving model with best Classification-F1: 0.34342235331156185 -> 0.48032743080940427 on epoch=32, global_step=450
06/18/2022 05:05:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.65 on epoch=32
06/18/2022 05:05:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.66 on epoch=33
06/18/2022 05:05:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.70 on epoch=34
06/18/2022 05:05:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.75 on epoch=34
06/18/2022 05:05:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.62 on epoch=35
06/18/2022 05:05:36 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.4606033644605053 on epoch=35
06/18/2022 05:05:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.57 on epoch=36
06/18/2022 05:05:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.56 on epoch=37
06/18/2022 05:05:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.58 on epoch=37
06/18/2022 05:05:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.50 on epoch=38
06/18/2022 05:05:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.58 on epoch=39
06/18/2022 05:05:56 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.5344033343156765 on epoch=39
06/18/2022 05:05:56 - INFO - __main__ - Saving model with best Classification-F1: 0.48032743080940427 -> 0.5344033343156765 on epoch=39, global_step=550
06/18/2022 05:05:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.44 on epoch=39
06/18/2022 05:06:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=40
06/18/2022 05:06:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.45 on epoch=41
06/18/2022 05:06:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.52 on epoch=42
06/18/2022 05:06:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.47 on epoch=42
06/18/2022 05:06:16 - INFO - __main__ - Global step 600 Train loss 0.48 Classification-F1 0.5674244691667496 on epoch=42
06/18/2022 05:06:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5344033343156765 -> 0.5674244691667496 on epoch=42, global_step=600
06/18/2022 05:06:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=43
06/18/2022 05:06:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.45 on epoch=44
06/18/2022 05:06:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=44
06/18/2022 05:06:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.45 on epoch=45
06/18/2022 05:06:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.39 on epoch=46
06/18/2022 05:06:36 - INFO - __main__ - Global step 650 Train loss 0.43 Classification-F1 0.6672735475230164 on epoch=46
06/18/2022 05:06:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5674244691667496 -> 0.6672735475230164 on epoch=46, global_step=650
06/18/2022 05:06:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=47
06/18/2022 05:06:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=47
06/18/2022 05:06:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.40 on epoch=48
06/18/2022 05:06:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=49
06/18/2022 05:06:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=49
06/18/2022 05:06:56 - INFO - __main__ - Global step 700 Train loss 0.39 Classification-F1 0.6687746264234761 on epoch=49
06/18/2022 05:06:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6672735475230164 -> 0.6687746264234761 on epoch=49, global_step=700
06/18/2022 05:06:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.32 on epoch=50
06/18/2022 05:07:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=51
06/18/2022 05:07:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=52
06/18/2022 05:07:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=52
06/18/2022 05:07:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=53
06/18/2022 05:07:16 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.7143763090566728 on epoch=53
06/18/2022 05:07:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6687746264234761 -> 0.7143763090566728 on epoch=53, global_step=750
06/18/2022 05:07:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
06/18/2022 05:07:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.30 on epoch=54
06/18/2022 05:07:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/18/2022 05:07:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=56
06/18/2022 05:07:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=57
06/18/2022 05:07:36 - INFO - __main__ - Global step 800 Train loss 0.30 Classification-F1 0.7564230315206987 on epoch=57
06/18/2022 05:07:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7143763090566728 -> 0.7564230315206987 on epoch=57, global_step=800
06/18/2022 05:07:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.28 on epoch=57
06/18/2022 05:07:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=58
06/18/2022 05:07:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=59
06/18/2022 05:07:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/18/2022 05:07:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=60
06/18/2022 05:07:56 - INFO - __main__ - Global step 850 Train loss 0.27 Classification-F1 0.7516531539301937 on epoch=60
06/18/2022 05:07:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
06/18/2022 05:08:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=62
06/18/2022 05:08:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=62
06/18/2022 05:08:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=63
06/18/2022 05:08:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
06/18/2022 05:08:16 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.7702290053233827 on epoch=64
06/18/2022 05:08:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7564230315206987 -> 0.7702290053233827 on epoch=64, global_step=900
06/18/2022 05:08:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=64
06/18/2022 05:08:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.38 on epoch=65
06/18/2022 05:08:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=66
06/18/2022 05:08:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
06/18/2022 05:08:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
06/18/2022 05:08:35 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.7662299894845861 on epoch=67
06/18/2022 05:08:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=68
06/18/2022 05:08:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=69
06/18/2022 05:08:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=69
06/18/2022 05:08:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=70
06/18/2022 05:08:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=71
06/18/2022 05:08:55 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.7662299894845861 on epoch=71
06/18/2022 05:08:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
06/18/2022 05:09:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.25 on epoch=72
06/18/2022 05:09:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.26 on epoch=73
06/18/2022 05:09:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
06/18/2022 05:09:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=74
06/18/2022 05:09:15 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.7622421333549808 on epoch=74
06/18/2022 05:09:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
06/18/2022 05:09:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=76
06/18/2022 05:09:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=77
06/18/2022 05:09:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.23 on epoch=77
06/18/2022 05:09:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=78
06/18/2022 05:09:34 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.7685201157686926 on epoch=78
06/18/2022 05:09:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=79
06/18/2022 05:09:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
06/18/2022 05:09:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=80
06/18/2022 05:09:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/18/2022 05:09:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
06/18/2022 05:09:54 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.8463465298142718 on epoch=82
06/18/2022 05:09:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7702290053233827 -> 0.8463465298142718 on epoch=82, global_step=1150
06/18/2022 05:09:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/18/2022 05:09:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/18/2022 05:10:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
06/18/2022 05:10:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/18/2022 05:10:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/18/2022 05:10:14 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.8275293255131965 on epoch=85
06/18/2022 05:10:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/18/2022 05:10:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
06/18/2022 05:10:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=87
06/18/2022 05:10:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
06/18/2022 05:10:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
06/18/2022 05:10:33 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.8424364613880744 on epoch=89
06/18/2022 05:10:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=89
06/18/2022 05:10:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=90
06/18/2022 05:10:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/18/2022 05:10:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
06/18/2022 05:10:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/18/2022 05:10:53 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.7996986947271577 on epoch=92
06/18/2022 05:10:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=93
06/18/2022 05:10:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/18/2022 05:11:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
06/18/2022 05:11:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/18/2022 05:11:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/18/2022 05:11:13 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.7437002091981054 on epoch=96
06/18/2022 05:11:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/18/2022 05:11:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/18/2022 05:11:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=98
06/18/2022 05:11:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/18/2022 05:11:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=99
06/18/2022 05:11:33 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.8516957206473336 on epoch=99
06/18/2022 05:11:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8463465298142718 -> 0.8516957206473336 on epoch=99, global_step=1400
06/18/2022 05:11:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/18/2022 05:11:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
06/18/2022 05:11:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=102
06/18/2022 05:11:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/18/2022 05:11:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
06/18/2022 05:11:52 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8568042774800284 on epoch=103
06/18/2022 05:11:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8516957206473336 -> 0.8568042774800284 on epoch=103, global_step=1450
06/18/2022 05:11:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/18/2022 05:11:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/18/2022 05:12:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/18/2022 05:12:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/18/2022 05:12:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=107
06/18/2022 05:12:12 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.801595972373961 on epoch=107
06/18/2022 05:12:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/18/2022 05:12:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/18/2022 05:12:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=109
06/18/2022 05:12:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/18/2022 05:12:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
06/18/2022 05:12:31 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.849545183012925 on epoch=110
06/18/2022 05:12:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/18/2022 05:12:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
06/18/2022 05:12:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/18/2022 05:12:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/18/2022 05:12:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
06/18/2022 05:12:50 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.849545183012925 on epoch=114
06/18/2022 05:12:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=114
06/18/2022 05:12:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=115
06/18/2022 05:12:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=116
06/18/2022 05:13:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=117
06/18/2022 05:13:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=117
06/18/2022 05:13:10 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.7551512737892667 on epoch=117
06/18/2022 05:13:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/18/2022 05:13:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
06/18/2022 05:13:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/18/2022 05:13:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/18/2022 05:13:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/18/2022 05:13:30 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.8568042774800284 on epoch=121
06/18/2022 05:13:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/18/2022 05:13:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/18/2022 05:13:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
06/18/2022 05:13:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/18/2022 05:13:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/18/2022 05:13:50 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.8100840902646831 on epoch=124
06/18/2022 05:13:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/18/2022 05:13:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/18/2022 05:13:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/18/2022 05:14:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/18/2022 05:14:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/18/2022 05:14:09 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.810223678914381 on epoch=128
06/18/2022 05:14:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/18/2022 05:14:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=129
06/18/2022 05:14:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/18/2022 05:14:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/18/2022 05:14:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/18/2022 05:14:29 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.8569525904203323 on epoch=132
06/18/2022 05:14:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8568042774800284 -> 0.8569525904203323 on epoch=132, global_step=1850
06/18/2022 05:14:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/18/2022 05:14:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/18/2022 05:14:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/18/2022 05:14:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
06/18/2022 05:14:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
06/18/2022 05:14:49 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8043799904429363 on epoch=135
06/18/2022 05:14:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/18/2022 05:14:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/18/2022 05:14:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/18/2022 05:14:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/18/2022 05:15:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/18/2022 05:15:09 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.859103128054741 on epoch=139
06/18/2022 05:15:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8569525904203323 -> 0.859103128054741 on epoch=139, global_step=1950
06/18/2022 05:15:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=139
06/18/2022 05:15:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
06/18/2022 05:15:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/18/2022 05:15:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/18/2022 05:15:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/18/2022 05:15:28 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.9186705767350929 on epoch=142
06/18/2022 05:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.859103128054741 -> 0.9186705767350929 on epoch=142, global_step=2000
06/18/2022 05:15:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/18/2022 05:15:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
06/18/2022 05:15:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/18/2022 05:15:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/18/2022 05:15:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
06/18/2022 05:15:48 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.810223678914381 on epoch=146
06/18/2022 05:15:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/18/2022 05:15:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/18/2022 05:15:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/18/2022 05:15:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/18/2022 05:16:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/18/2022 05:16:08 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.8063823784259023 on epoch=149
06/18/2022 05:16:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/18/2022 05:16:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/18/2022 05:16:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/18/2022 05:16:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/18/2022 05:16:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/18/2022 05:16:27 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8063823784259023 on epoch=153
06/18/2022 05:16:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/18/2022 05:16:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/18/2022 05:16:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/18/2022 05:16:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/18/2022 05:16:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/18/2022 05:16:46 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8006999260418093 on epoch=157
06/18/2022 05:16:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/18/2022 05:16:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/18/2022 05:16:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/18/2022 05:16:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
06/18/2022 05:17:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/18/2022 05:17:06 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7577806241877432 on epoch=160
06/18/2022 05:17:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/18/2022 05:17:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/18/2022 05:17:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/18/2022 05:17:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/18/2022 05:17:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/18/2022 05:17:25 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8046460813064229 on epoch=164
06/18/2022 05:17:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/18/2022 05:17:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/18/2022 05:17:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/18/2022 05:17:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/18/2022 05:17:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/18/2022 05:17:45 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7540686808762449 on epoch=167
06/18/2022 05:17:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
06/18/2022 05:17:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/18/2022 05:17:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/18/2022 05:17:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/18/2022 05:17:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=171
06/18/2022 05:18:05 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8005632765916202 on epoch=171
06/18/2022 05:18:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/18/2022 05:18:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/18/2022 05:18:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/18/2022 05:18:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/18/2022 05:18:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/18/2022 05:18:24 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8005632765916202 on epoch=174
06/18/2022 05:18:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=175
06/18/2022 05:18:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/18/2022 05:18:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/18/2022 05:18:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/18/2022 05:18:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
06/18/2022 05:18:43 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.8550255647119299 on epoch=178
06/18/2022 05:18:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/18/2022 05:18:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
06/18/2022 05:18:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/18/2022 05:18:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/18/2022 05:18:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/18/2022 05:19:03 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9056888851876747 on epoch=182
06/18/2022 05:19:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/18/2022 05:19:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/18/2022 05:19:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/18/2022 05:19:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/18/2022 05:19:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/18/2022 05:19:22 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.855196878054741 on epoch=185
06/18/2022 05:19:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/18/2022 05:19:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/18/2022 05:19:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/18/2022 05:19:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/18/2022 05:19:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/18/2022 05:19:42 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9056888851876747 on epoch=189
06/18/2022 05:19:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/18/2022 05:19:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/18/2022 05:19:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/18/2022 05:19:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/18/2022 05:19:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/18/2022 05:20:01 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9143564679048553 on epoch=192
06/18/2022 05:20:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/18/2022 05:20:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=194
06/18/2022 05:20:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/18/2022 05:20:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/18/2022 05:20:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
06/18/2022 05:20:21 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9100029940179126 on epoch=196
06/18/2022 05:20:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/18/2022 05:20:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/18/2022 05:20:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
06/18/2022 05:20:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/18/2022 05:20:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/18/2022 05:20:41 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.9186705767350929 on epoch=199
06/18/2022 05:20:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/18/2022 05:20:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/18/2022 05:20:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/18/2022 05:20:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/18/2022 05:20:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/18/2022 05:21:01 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9055830191314063 on epoch=203
06/18/2022 05:21:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/18/2022 05:21:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/18/2022 05:21:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/18/2022 05:21:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/18/2022 05:21:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/18/2022 05:21:20 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9143564679048553 on epoch=207
06/18/2022 05:21:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/18/2022 05:21:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=208
06/18/2022 05:21:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/18/2022 05:21:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/18/2022 05:21:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/18/2022 05:21:40 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9143564679048553 on epoch=210
06/18/2022 05:21:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/18/2022 05:21:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/18/2022 05:21:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/18/2022 05:21:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/18/2022 05:21:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/18/2022 05:21:59 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8064076196764479 on epoch=214
06/18/2022 05:21:59 - INFO - __main__ - save last model!
06/18/2022 05:21:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/18/2022 05:21:59 - INFO - __main__ - Start tokenizing ... 3500 instances
06/18/2022 05:21:59 - INFO - __main__ - Printing 3 examples
06/18/2022 05:21:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/18/2022 05:21:59 - INFO - __main__ - ['Animal']
06/18/2022 05:21:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/18/2022 05:21:59 - INFO - __main__ - ['Animal']
06/18/2022 05:21:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/18/2022 05:21:59 - INFO - __main__ - ['Village']
06/18/2022 05:21:59 - INFO - __main__ - Tokenizing Input ...
06/18/2022 05:22:01 - INFO - __main__ - Tokenizing Output ...
06/18/2022 05:22:05 - INFO - __main__ - Loaded 3500 examples from test data
06/18/2022 05:24:14 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-10-up64shot/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/18/2022 05:24:14 - INFO - __main__ - Classification-F1 on test data: 0.4678
06/18/2022 05:24:15 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9186705767350929, test_performance=0.46782794641742337
