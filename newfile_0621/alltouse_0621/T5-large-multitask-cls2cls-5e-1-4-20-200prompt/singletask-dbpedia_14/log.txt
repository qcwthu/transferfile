06/16/2022 21:57:26 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='4,5')
06/16/2022 21:57:26 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14
06/16/2022 21:57:26 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='4,5')
06/16/2022 21:57:26 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14
06/16/2022 21:57:27 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/16/2022 21:57:27 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/16/2022 21:57:27 - INFO - __main__ - args.device: cuda:0
06/16/2022 21:57:27 - INFO - __main__ - Using 2 gpus
06/16/2022 21:57:27 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/16/2022 21:57:27 - INFO - __main__ - args.device: cuda:1
06/16/2022 21:57:27 - INFO - __main__ - Using 2 gpus
06/16/2022 21:57:27 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/16/2022 21:57:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/16/2022 21:57:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 21:57:33 - INFO - __main__ - Printing 3 examples
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:57:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 21:57:33 - INFO - __main__ - Printing 3 examples
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:57:33 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 21:57:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 21:57:33 - INFO - __main__ - Printing 3 examples
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:57:33 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 21:57:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 21:57:33 - INFO - __main__ - Printing 3 examples
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 21:57:33 - INFO - __main__ - ['Animal']
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Input ...
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:57:33 - INFO - __main__ - Tokenizing Output ...
06/16/2022 21:57:33 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 21:57:33 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 21:57:51 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 21:57:51 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 21:57:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 21:57:52 - INFO - __main__ - Starting training!
06/16/2022 21:57:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 21:57:56 - INFO - __main__ - Starting training!
06/16/2022 21:58:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.68 on epoch=0
06/16/2022 21:58:04 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=1
06/16/2022 21:58:06 - INFO - __main__ - Step 30 Global step 30 Train loss 3.39 on epoch=2
06/16/2022 21:58:09 - INFO - __main__ - Step 40 Global step 40 Train loss 3.18 on epoch=2
06/16/2022 21:58:12 - INFO - __main__ - Step 50 Global step 50 Train loss 2.79 on epoch=3
06/16/2022 21:58:18 - INFO - __main__ - Global step 50 Train loss 4.11 Classification-F1 0.11721541185911208 on epoch=3
06/16/2022 21:58:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11721541185911208 on epoch=3, global_step=50
06/16/2022 21:58:20 - INFO - __main__ - Step 60 Global step 60 Train loss 2.65 on epoch=4
06/16/2022 21:58:23 - INFO - __main__ - Step 70 Global step 70 Train loss 2.04 on epoch=4
06/16/2022 21:58:26 - INFO - __main__ - Step 80 Global step 80 Train loss 2.07 on epoch=5
06/16/2022 21:58:29 - INFO - __main__ - Step 90 Global step 90 Train loss 1.80 on epoch=6
06/16/2022 21:58:32 - INFO - __main__ - Step 100 Global step 100 Train loss 1.57 on epoch=7
06/16/2022 21:58:38 - INFO - __main__ - Global step 100 Train loss 2.02 Classification-F1 0.15248079877112133 on epoch=7
06/16/2022 21:58:38 - INFO - __main__ - Saving model with best Classification-F1: 0.11721541185911208 -> 0.15248079877112133 on epoch=7, global_step=100
06/16/2022 21:58:41 - INFO - __main__ - Step 110 Global step 110 Train loss 1.41 on epoch=7
06/16/2022 21:58:44 - INFO - __main__ - Step 120 Global step 120 Train loss 1.31 on epoch=8
06/16/2022 21:58:47 - INFO - __main__ - Step 130 Global step 130 Train loss 1.11 on epoch=9
06/16/2022 21:58:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=9
06/16/2022 21:58:53 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=10
06/16/2022 21:58:59 - INFO - __main__ - Global step 150 Train loss 1.14 Classification-F1 0.3622132553699 on epoch=10
06/16/2022 21:58:59 - INFO - __main__ - Saving model with best Classification-F1: 0.15248079877112133 -> 0.3622132553699 on epoch=10, global_step=150
06/16/2022 21:59:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
06/16/2022 21:59:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=12
06/16/2022 21:59:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=12
06/16/2022 21:59:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=13
06/16/2022 21:59:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=14
06/16/2022 21:59:20 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5692816571665545 on epoch=14
06/16/2022 21:59:20 - INFO - __main__ - Saving model with best Classification-F1: 0.3622132553699 -> 0.5692816571665545 on epoch=14, global_step=200
06/16/2022 21:59:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=14
06/16/2022 21:59:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=15
06/16/2022 21:59:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=16
06/16/2022 21:59:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=17
06/16/2022 21:59:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=17
06/16/2022 21:59:42 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.5637613888325462 on epoch=17
06/16/2022 21:59:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=18
06/16/2022 21:59:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=19
06/16/2022 21:59:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=19
06/16/2022 21:59:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=20
06/16/2022 21:59:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=21
06/16/2022 22:00:03 - INFO - __main__ - Global step 300 Train loss 0.31 Classification-F1 0.5913009372483484 on epoch=21
06/16/2022 22:00:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5692816571665545 -> 0.5913009372483484 on epoch=21, global_step=300
06/16/2022 22:00:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=22
06/16/2022 22:00:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=22
06/16/2022 22:00:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=23
06/16/2022 22:00:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=24
06/16/2022 22:00:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=24
06/16/2022 22:00:24 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.5906248535224593 on epoch=24
06/16/2022 22:00:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=25
06/16/2022 22:00:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=26
06/16/2022 22:00:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=27
06/16/2022 22:00:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=27
06/16/2022 22:00:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=28
06/16/2022 22:00:46 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6972597641017503 on epoch=28
06/16/2022 22:00:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5913009372483484 -> 0.6972597641017503 on epoch=28, global_step=400
06/16/2022 22:00:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=29
06/16/2022 22:00:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=29
06/16/2022 22:00:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=30
06/16/2022 22:00:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=31
06/16/2022 22:01:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=32
06/16/2022 22:01:07 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.7824987960030338 on epoch=32
06/16/2022 22:01:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6972597641017503 -> 0.7824987960030338 on epoch=32, global_step=450
06/16/2022 22:01:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.12 on epoch=32
06/16/2022 22:01:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=33
06/16/2022 22:01:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=34
06/16/2022 22:01:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=34
06/16/2022 22:01:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=35
06/16/2022 22:01:28 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.8082662221646043 on epoch=35
06/16/2022 22:01:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7824987960030338 -> 0.8082662221646043 on epoch=35, global_step=500
06/16/2022 22:01:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=36
06/16/2022 22:01:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=37
06/16/2022 22:01:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
06/16/2022 22:01:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=38
06/16/2022 22:01:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
06/16/2022 22:01:49 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.7884261207037186 on epoch=39
06/16/2022 22:01:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
06/16/2022 22:01:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=40
06/16/2022 22:01:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
06/16/2022 22:02:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/16/2022 22:02:04 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=42
06/16/2022 22:02:10 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.8970201966960348 on epoch=42
06/16/2022 22:02:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8082662221646043 -> 0.8970201966960348 on epoch=42, global_step=600
06/16/2022 22:02:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=43
06/16/2022 22:02:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=44
06/16/2022 22:02:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=44
06/16/2022 22:02:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=45
06/16/2022 22:02:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
06/16/2022 22:02:32 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.8331711188874376 on epoch=46
06/16/2022 22:02:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
06/16/2022 22:02:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=47
06/16/2022 22:02:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=48
06/16/2022 22:02:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=49
06/16/2022 22:02:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/16/2022 22:02:53 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.8925428566794793 on epoch=49
06/16/2022 22:02:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
06/16/2022 22:02:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
06/16/2022 22:03:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=52
06/16/2022 22:03:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=52
06/16/2022 22:03:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
06/16/2022 22:03:14 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.8870774054199103 on epoch=53
06/16/2022 22:03:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=54
06/16/2022 22:03:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
06/16/2022 22:03:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/16/2022 22:03:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
06/16/2022 22:03:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
06/16/2022 22:03:35 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.8391451448614637 on epoch=57
06/16/2022 22:03:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
06/16/2022 22:03:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
06/16/2022 22:03:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=59
06/16/2022 22:03:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=59
06/16/2022 22:03:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=60
06/16/2022 22:03:56 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.7874049977072077 on epoch=60
06/16/2022 22:03:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/16/2022 22:04:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=62
06/16/2022 22:04:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/16/2022 22:04:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
06/16/2022 22:04:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
06/16/2022 22:04:17 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.8448499634457889 on epoch=64
06/16/2022 22:04:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=64
06/16/2022 22:04:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
06/16/2022 22:04:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=66
06/16/2022 22:04:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=67
06/16/2022 22:04:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
06/16/2022 22:04:38 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8357781765988597 on epoch=67
06/16/2022 22:04:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/16/2022 22:04:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=69
06/16/2022 22:04:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/16/2022 22:04:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/16/2022 22:04:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
06/16/2022 22:04:59 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8395687250763152 on epoch=71
06/16/2022 22:05:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=72
06/16/2022 22:05:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=72
06/16/2022 22:05:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
06/16/2022 22:05:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=74
06/16/2022 22:05:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
06/16/2022 22:05:20 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.8405276069575761 on epoch=74
06/16/2022 22:05:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
06/16/2022 22:05:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=76
06/16/2022 22:05:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/16/2022 22:05:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/16/2022 22:05:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=78
06/16/2022 22:05:41 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.9124436010963526 on epoch=78
06/16/2022 22:05:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8970201966960348 -> 0.9124436010963526 on epoch=78, global_step=1100
06/16/2022 22:05:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
06/16/2022 22:05:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/16/2022 22:05:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=80
06/16/2022 22:05:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/16/2022 22:05:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/16/2022 22:06:03 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.9064801443549072 on epoch=82
06/16/2022 22:06:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=82
06/16/2022 22:06:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/16/2022 22:06:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
06/16/2022 22:06:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/16/2022 22:06:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/16/2022 22:06:24 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.9105667682517778 on epoch=85
06/16/2022 22:06:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/16/2022 22:06:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/16/2022 22:06:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
06/16/2022 22:06:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/16/2022 22:06:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/16/2022 22:06:45 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9779113991637711 on epoch=89
06/16/2022 22:06:45 - INFO - __main__ - Saving model with best Classification-F1: 0.9124436010963526 -> 0.9779113991637711 on epoch=89, global_step=1250
06/16/2022 22:06:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/16/2022 22:06:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/16/2022 22:06:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/16/2022 22:06:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
06/16/2022 22:06:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=92
06/16/2022 22:07:06 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.9823800487937111 on epoch=92
06/16/2022 22:07:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9779113991637711 -> 0.9823800487937111 on epoch=92, global_step=1300
06/16/2022 22:07:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/16/2022 22:07:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
06/16/2022 22:07:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/16/2022 22:07:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
06/16/2022 22:07:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/16/2022 22:07:27 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9823800487937111 on epoch=96
06/16/2022 22:07:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/16/2022 22:07:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/16/2022 22:07:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
06/16/2022 22:07:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/16/2022 22:07:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
06/16/2022 22:07:48 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.9823800487937111 on epoch=99
06/16/2022 22:07:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/16/2022 22:07:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/16/2022 22:07:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/16/2022 22:08:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
06/16/2022 22:08:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/16/2022 22:08:09 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8506539712659258 on epoch=103
06/16/2022 22:08:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
06/16/2022 22:08:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/16/2022 22:08:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/16/2022 22:08:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/16/2022 22:08:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/16/2022 22:08:30 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7962165841170195 on epoch=107
06/16/2022 22:08:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/16/2022 22:08:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/16/2022 22:08:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/16/2022 22:08:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/16/2022 22:08:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/16/2022 22:08:52 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=110
06/16/2022 22:08:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/16/2022 22:08:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/16/2022 22:09:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/16/2022 22:09:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/16/2022 22:09:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
06/16/2022 22:09:13 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=114
06/16/2022 22:09:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/16/2022 22:09:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/16/2022 22:09:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/16/2022 22:09:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/16/2022 22:09:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/16/2022 22:09:34 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=117
06/16/2022 22:09:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/16/2022 22:09:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/16/2022 22:09:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/16/2022 22:09:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/16/2022 22:09:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/16/2022 22:09:56 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=121
06/16/2022 22:09:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/16/2022 22:10:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=122
06/16/2022 22:10:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/16/2022 22:10:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=124
06/16/2022 22:10:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/16/2022 22:10:17 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.9147375079063884 on epoch=124
06/16/2022 22:10:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=125
06/16/2022 22:10:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/16/2022 22:10:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/16/2022 22:10:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/16/2022 22:10:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/16/2022 22:10:38 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.977757789332742 on epoch=128
06/16/2022 22:10:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/16/2022 22:10:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/16/2022 22:10:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/16/2022 22:10:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=131
06/16/2022 22:10:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/16/2022 22:11:00 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=132
06/16/2022 22:11:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
06/16/2022 22:11:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=133
06/16/2022 22:11:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=134
06/16/2022 22:11:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/16/2022 22:11:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/16/2022 22:11:22 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9779157630794254 on epoch=135
06/16/2022 22:11:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/16/2022 22:11:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
06/16/2022 22:11:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/16/2022 22:11:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/16/2022 22:11:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/16/2022 22:11:43 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9104274720640945 on epoch=139
06/16/2022 22:11:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/16/2022 22:11:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=140
06/16/2022 22:11:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
06/16/2022 22:11:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/16/2022 22:11:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
06/16/2022 22:12:05 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=142
06/16/2022 22:12:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/16/2022 22:12:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
06/16/2022 22:12:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/16/2022 22:12:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
06/16/2022 22:12:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/16/2022 22:12:26 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9078279226208298 on epoch=146
06/16/2022 22:12:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/16/2022 22:12:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
06/16/2022 22:12:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/16/2022 22:12:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/16/2022 22:12:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/16/2022 22:12:48 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9058077206006279 on epoch=149
06/16/2022 22:12:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/16/2022 22:12:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/16/2022 22:12:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/16/2022 22:13:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/16/2022 22:13:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/16/2022 22:13:10 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9102800299005234 on epoch=153
06/16/2022 22:13:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/16/2022 22:13:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/16/2022 22:13:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/16/2022 22:13:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/16/2022 22:13:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
06/16/2022 22:13:31 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8500245976526812 on epoch=157
06/16/2022 22:13:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/16/2022 22:13:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/16/2022 22:13:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/16/2022 22:13:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/16/2022 22:13:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/16/2022 22:13:53 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.9104233990761508 on epoch=160
06/16/2022 22:13:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/16/2022 22:13:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/16/2022 22:14:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
06/16/2022 22:14:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/16/2022 22:14:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/16/2022 22:14:15 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=164
06/16/2022 22:14:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/16/2022 22:14:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/16/2022 22:14:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/16/2022 22:14:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
06/16/2022 22:14:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/16/2022 22:14:36 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8509772692573845 on epoch=167
06/16/2022 22:14:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/16/2022 22:14:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/16/2022 22:14:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/16/2022 22:14:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/16/2022 22:14:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/16/2022 22:14:58 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.9144753033178081 on epoch=171
06/16/2022 22:15:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/16/2022 22:15:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/16/2022 22:15:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/16/2022 22:15:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/16/2022 22:15:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/16/2022 22:15:19 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.9777577893327418 on epoch=174
06/16/2022 22:15:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/16/2022 22:15:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/16/2022 22:15:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/16/2022 22:15:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/16/2022 22:15:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/16/2022 22:15:41 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=178
06/16/2022 22:15:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/16/2022 22:15:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/16/2022 22:15:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/16/2022 22:15:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/16/2022 22:15:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/16/2022 22:16:02 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=182
06/16/2022 22:16:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/16/2022 22:16:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/16/2022 22:16:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/16/2022 22:16:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/16/2022 22:16:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/16/2022 22:16:24 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9187894121480459 on epoch=185
06/16/2022 22:16:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/16/2022 22:16:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/16/2022 22:16:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/16/2022 22:16:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/16/2022 22:16:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/16/2022 22:16:45 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9140433980583166 on epoch=189
06/16/2022 22:16:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/16/2022 22:16:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/16/2022 22:16:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/16/2022 22:16:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/16/2022 22:17:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/16/2022 22:17:06 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8592145362543845 on epoch=192
06/16/2022 22:17:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/16/2022 22:17:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/16/2022 22:17:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/16/2022 22:17:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/16/2022 22:17:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/16/2022 22:17:28 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8489581259979742 on epoch=196
06/16/2022 22:17:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/16/2022 22:17:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/16/2022 22:17:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/16/2022 22:17:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/16/2022 22:17:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/16/2022 22:17:49 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.855133154485376 on epoch=199
06/16/2022 22:17:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/16/2022 22:17:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/16/2022 22:17:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/16/2022 22:18:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/16/2022 22:18:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/16/2022 22:18:11 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8592145362543845 on epoch=203
06/16/2022 22:18:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/16/2022 22:18:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/16/2022 22:18:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/16/2022 22:18:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/16/2022 22:18:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/16/2022 22:18:32 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9095147736513961 on epoch=207
06/16/2022 22:18:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/16/2022 22:18:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/16/2022 22:18:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/16/2022 22:18:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/16/2022 22:18:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/16/2022 22:18:53 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.8551700592260365 on epoch=210
06/16/2022 22:18:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/16/2022 22:18:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/16/2022 22:19:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/16/2022 22:19:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/16/2022 22:19:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/16/2022 22:19:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:19:10 - INFO - __main__ - Printing 3 examples
06/16/2022 22:19:10 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 22:19:10 - INFO - __main__ - ['Animal']
06/16/2022 22:19:10 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 22:19:10 - INFO - __main__ - ['Animal']
06/16/2022 22:19:10 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 22:19:10 - INFO - __main__ - ['Animal']
06/16/2022 22:19:10 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:19:10 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:19:10 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 22:19:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:19:10 - INFO - __main__ - Printing 3 examples
06/16/2022 22:19:10 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 22:19:10 - INFO - __main__ - ['Animal']
06/16/2022 22:19:10 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 22:19:10 - INFO - __main__ - ['Animal']
06/16/2022 22:19:10 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 22:19:10 - INFO - __main__ - ['Animal']
06/16/2022 22:19:10 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:19:10 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:19:10 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 22:19:15 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9061223238073334 on epoch=214
06/16/2022 22:19:15 - INFO - __main__ - save last model!
06/16/2022 22:19:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 22:19:15 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 22:19:15 - INFO - __main__ - Printing 3 examples
06/16/2022 22:19:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 22:19:15 - INFO - __main__ - ['Animal']
06/16/2022 22:19:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 22:19:15 - INFO - __main__ - ['Animal']
06/16/2022 22:19:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 22:19:15 - INFO - __main__ - ['Village']
06/16/2022 22:19:15 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:19:17 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:19:20 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 22:19:26 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 22:19:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 22:19:26 - INFO - __main__ - Starting training!
06/16/2022 22:21:35 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/16/2022 22:21:35 - INFO - __main__ - Classification-F1 on test data: 0.6192
06/16/2022 22:21:36 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9823800487937111, test_performance=0.6192208001357525
06/16/2022 22:21:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/16/2022 22:21:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:21:37 - INFO - __main__ - Printing 3 examples
06/16/2022 22:21:37 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 22:21:37 - INFO - __main__ - ['Animal']
06/16/2022 22:21:37 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 22:21:37 - INFO - __main__ - ['Animal']
06/16/2022 22:21:37 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 22:21:37 - INFO - __main__ - ['Animal']
06/16/2022 22:21:37 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:21:37 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:21:37 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 22:21:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:21:37 - INFO - __main__ - Printing 3 examples
06/16/2022 22:21:37 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 22:21:37 - INFO - __main__ - ['Animal']
06/16/2022 22:21:37 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 22:21:37 - INFO - __main__ - ['Animal']
06/16/2022 22:21:37 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 22:21:37 - INFO - __main__ - ['Animal']
06/16/2022 22:21:37 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:21:37 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:21:37 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 22:21:52 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 22:21:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 22:21:53 - INFO - __main__ - Starting training!
06/16/2022 22:21:57 - INFO - __main__ - Step 10 Global step 10 Train loss 7.14 on epoch=0
06/16/2022 22:22:00 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=1
06/16/2022 22:22:03 - INFO - __main__ - Step 30 Global step 30 Train loss 4.03 on epoch=2
06/16/2022 22:22:06 - INFO - __main__ - Step 40 Global step 40 Train loss 3.72 on epoch=2
06/16/2022 22:22:09 - INFO - __main__ - Step 50 Global step 50 Train loss 3.18 on epoch=3
06/16/2022 22:22:14 - INFO - __main__ - Global step 50 Train loss 4.61 Classification-F1 0.09781123261162039 on epoch=3
06/16/2022 22:22:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09781123261162039 on epoch=3, global_step=50
06/16/2022 22:22:17 - INFO - __main__ - Step 60 Global step 60 Train loss 2.98 on epoch=4
06/16/2022 22:22:20 - INFO - __main__ - Step 70 Global step 70 Train loss 2.40 on epoch=4
06/16/2022 22:22:23 - INFO - __main__ - Step 80 Global step 80 Train loss 2.54 on epoch=5
06/16/2022 22:22:26 - INFO - __main__ - Step 90 Global step 90 Train loss 2.21 on epoch=6
06/16/2022 22:22:29 - INFO - __main__ - Step 100 Global step 100 Train loss 1.87 on epoch=7
06/16/2022 22:22:34 - INFO - __main__ - Global step 100 Train loss 2.40 Classification-F1 0.14721351445489375 on epoch=7
06/16/2022 22:22:34 - INFO - __main__ - Saving model with best Classification-F1: 0.09781123261162039 -> 0.14721351445489375 on epoch=7, global_step=100
06/16/2022 22:22:37 - INFO - __main__ - Step 110 Global step 110 Train loss 1.88 on epoch=7
06/16/2022 22:22:40 - INFO - __main__ - Step 120 Global step 120 Train loss 1.66 on epoch=8
06/16/2022 22:22:43 - INFO - __main__ - Step 130 Global step 130 Train loss 1.63 on epoch=9
06/16/2022 22:22:46 - INFO - __main__ - Step 140 Global step 140 Train loss 1.25 on epoch=9
06/16/2022 22:22:49 - INFO - __main__ - Step 150 Global step 150 Train loss 1.40 on epoch=10
06/16/2022 22:22:55 - INFO - __main__ - Global step 150 Train loss 1.56 Classification-F1 0.20501592382767544 on epoch=10
06/16/2022 22:22:55 - INFO - __main__ - Saving model with best Classification-F1: 0.14721351445489375 -> 0.20501592382767544 on epoch=10, global_step=150
06/16/2022 22:22:58 - INFO - __main__ - Step 160 Global step 160 Train loss 1.23 on epoch=11
06/16/2022 22:23:01 - INFO - __main__ - Step 170 Global step 170 Train loss 1.12 on epoch=12
06/16/2022 22:23:04 - INFO - __main__ - Step 180 Global step 180 Train loss 1.02 on epoch=12
06/16/2022 22:23:07 - INFO - __main__ - Step 190 Global step 190 Train loss 1.01 on epoch=13
06/16/2022 22:23:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=14
06/16/2022 22:23:16 - INFO - __main__ - Global step 200 Train loss 1.06 Classification-F1 0.3647213064707013 on epoch=14
06/16/2022 22:23:16 - INFO - __main__ - Saving model with best Classification-F1: 0.20501592382767544 -> 0.3647213064707013 on epoch=14, global_step=200
06/16/2022 22:23:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=14
06/16/2022 22:23:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=15
06/16/2022 22:23:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=16
06/16/2022 22:23:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=17
06/16/2022 22:23:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=17
06/16/2022 22:23:37 - INFO - __main__ - Global step 250 Train loss 0.68 Classification-F1 0.4921364704239467 on epoch=17
06/16/2022 22:23:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3647213064707013 -> 0.4921364704239467 on epoch=17, global_step=250
06/16/2022 22:23:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=18
06/16/2022 22:23:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
06/16/2022 22:23:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=19
06/16/2022 22:23:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=20
06/16/2022 22:23:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=21
06/16/2022 22:23:59 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.5315786429040286 on epoch=21
06/16/2022 22:23:59 - INFO - __main__ - Saving model with best Classification-F1: 0.4921364704239467 -> 0.5315786429040286 on epoch=21, global_step=300
06/16/2022 22:24:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=22
06/16/2022 22:24:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=22
06/16/2022 22:24:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=23
06/16/2022 22:24:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=24
06/16/2022 22:24:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
06/16/2022 22:24:20 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.5663373480402186 on epoch=24
06/16/2022 22:24:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5315786429040286 -> 0.5663373480402186 on epoch=24, global_step=350
06/16/2022 22:24:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=25
06/16/2022 22:24:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=26
06/16/2022 22:24:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=27
06/16/2022 22:24:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=27
06/16/2022 22:24:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
06/16/2022 22:24:42 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.5686737942678888 on epoch=28
06/16/2022 22:24:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5663373480402186 -> 0.5686737942678888 on epoch=28, global_step=400
06/16/2022 22:24:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/16/2022 22:24:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=29
06/16/2022 22:24:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=30
06/16/2022 22:24:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
06/16/2022 22:24:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
06/16/2022 22:25:04 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.6534180617043521 on epoch=32
06/16/2022 22:25:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5686737942678888 -> 0.6534180617043521 on epoch=32, global_step=450
06/16/2022 22:25:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
06/16/2022 22:25:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
06/16/2022 22:25:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
06/16/2022 22:25:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=34
06/16/2022 22:25:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
06/16/2022 22:25:26 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.7236403978339463 on epoch=35
06/16/2022 22:25:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6534180617043521 -> 0.7236403978339463 on epoch=35, global_step=500
06/16/2022 22:25:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=36
06/16/2022 22:25:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=37
06/16/2022 22:25:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
06/16/2022 22:25:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=38
06/16/2022 22:25:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
06/16/2022 22:25:47 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.8020239327402515 on epoch=39
06/16/2022 22:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7236403978339463 -> 0.8020239327402515 on epoch=39, global_step=550
06/16/2022 22:25:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
06/16/2022 22:25:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=40
06/16/2022 22:25:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
06/16/2022 22:25:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/16/2022 22:26:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
06/16/2022 22:26:08 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7388716021280373 on epoch=42
06/16/2022 22:26:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
06/16/2022 22:26:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=44
06/16/2022 22:26:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=44
06/16/2022 22:26:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
06/16/2022 22:26:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=46
06/16/2022 22:26:29 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.8135569082838414 on epoch=46
06/16/2022 22:26:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8020239327402515 -> 0.8135569082838414 on epoch=46, global_step=650
06/16/2022 22:26:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
06/16/2022 22:26:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/16/2022 22:26:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=48
06/16/2022 22:26:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=49
06/16/2022 22:26:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/16/2022 22:26:51 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7314863645034424 on epoch=49
06/16/2022 22:26:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/16/2022 22:26:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
06/16/2022 22:26:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=52
06/16/2022 22:27:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/16/2022 22:27:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
06/16/2022 22:27:12 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7715383729824516 on epoch=53
06/16/2022 22:27:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=54
06/16/2022 22:27:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
06/16/2022 22:27:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
06/16/2022 22:27:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
06/16/2022 22:27:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/16/2022 22:27:33 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7594362956498797 on epoch=57
06/16/2022 22:27:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/16/2022 22:27:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/16/2022 22:27:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/16/2022 22:27:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
06/16/2022 22:27:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=60
06/16/2022 22:27:54 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7387931907856006 on epoch=60
06/16/2022 22:27:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/16/2022 22:28:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/16/2022 22:28:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=62
06/16/2022 22:28:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
06/16/2022 22:28:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
06/16/2022 22:28:15 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7949114025461832 on epoch=64
06/16/2022 22:28:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
06/16/2022 22:28:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
06/16/2022 22:28:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
06/16/2022 22:28:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/16/2022 22:28:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
06/16/2022 22:28:36 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.8543412232928362 on epoch=67
06/16/2022 22:28:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8135569082838414 -> 0.8543412232928362 on epoch=67, global_step=950
06/16/2022 22:28:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
06/16/2022 22:28:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/16/2022 22:28:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
06/16/2022 22:28:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/16/2022 22:28:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/16/2022 22:28:57 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.8381868026006427 on epoch=71
06/16/2022 22:29:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/16/2022 22:29:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
06/16/2022 22:29:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
06/16/2022 22:29:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/16/2022 22:29:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
06/16/2022 22:29:19 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.712320784327176 on epoch=74
06/16/2022 22:29:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/16/2022 22:29:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/16/2022 22:29:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
06/16/2022 22:29:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
06/16/2022 22:29:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
06/16/2022 22:29:40 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7432500846542592 on epoch=78
06/16/2022 22:29:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
06/16/2022 22:29:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/16/2022 22:29:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/16/2022 22:29:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/16/2022 22:29:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/16/2022 22:30:01 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8383857413933316 on epoch=82
06/16/2022 22:30:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
06/16/2022 22:30:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/16/2022 22:30:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/16/2022 22:30:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/16/2022 22:30:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/16/2022 22:30:22 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.9105667682517778 on epoch=85
06/16/2022 22:30:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8543412232928362 -> 0.9105667682517778 on epoch=85, global_step=1200
06/16/2022 22:30:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/16/2022 22:30:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
06/16/2022 22:30:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/16/2022 22:30:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/16/2022 22:30:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/16/2022 22:30:43 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.8364918019993921 on epoch=89
06/16/2022 22:30:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/16/2022 22:30:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
06/16/2022 22:30:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=91
06/16/2022 22:30:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
06/16/2022 22:30:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/16/2022 22:31:05 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.898578909787006 on epoch=92
06/16/2022 22:31:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/16/2022 22:31:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/16/2022 22:31:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/16/2022 22:31:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/16/2022 22:31:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/16/2022 22:31:26 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.9147375079063884 on epoch=96
06/16/2022 22:31:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9105667682517778 -> 0.9147375079063884 on epoch=96, global_step=1350
06/16/2022 22:31:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/16/2022 22:31:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/16/2022 22:31:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/16/2022 22:31:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
06/16/2022 22:31:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/16/2022 22:31:47 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9043411069217522 on epoch=99
06/16/2022 22:31:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/16/2022 22:31:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/16/2022 22:31:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/16/2022 22:31:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/16/2022 22:32:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/16/2022 22:32:09 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9016655876966354 on epoch=103
06/16/2022 22:32:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/16/2022 22:32:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/16/2022 22:32:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/16/2022 22:32:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/16/2022 22:32:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/16/2022 22:32:30 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9014007792755422 on epoch=107
06/16/2022 22:32:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/16/2022 22:32:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/16/2022 22:32:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/16/2022 22:32:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/16/2022 22:32:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/16/2022 22:32:51 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8430578829772378 on epoch=110
06/16/2022 22:32:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/16/2022 22:32:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/16/2022 22:33:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/16/2022 22:33:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/16/2022 22:33:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/16/2022 22:33:12 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8383511403664003 on epoch=114
06/16/2022 22:33:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/16/2022 22:33:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/16/2022 22:33:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=116
06/16/2022 22:33:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/16/2022 22:33:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/16/2022 22:33:33 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7890968461406203 on epoch=117
06/16/2022 22:33:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/16/2022 22:33:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=119
06/16/2022 22:33:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/16/2022 22:33:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/16/2022 22:33:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=121
06/16/2022 22:33:55 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.9105938416422286 on epoch=121
06/16/2022 22:33:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/16/2022 22:34:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/16/2022 22:34:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/16/2022 22:34:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/16/2022 22:34:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
06/16/2022 22:34:16 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9779113991637711 on epoch=124
06/16/2022 22:34:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9147375079063884 -> 0.9779113991637711 on epoch=124, global_step=1750
06/16/2022 22:34:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/16/2022 22:34:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/16/2022 22:34:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/16/2022 22:34:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/16/2022 22:34:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/16/2022 22:34:37 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9779113991637711 on epoch=128
06/16/2022 22:34:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/16/2022 22:34:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/16/2022 22:34:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/16/2022 22:34:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/16/2022 22:34:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/16/2022 22:34:58 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=132
06/16/2022 22:35:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/16/2022 22:35:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/16/2022 22:35:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/16/2022 22:35:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/16/2022 22:35:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/16/2022 22:35:20 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9779113991637711 on epoch=135
06/16/2022 22:35:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/16/2022 22:35:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/16/2022 22:35:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/16/2022 22:35:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/16/2022 22:35:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=139
06/16/2022 22:35:41 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9734594350936856 on epoch=139
06/16/2022 22:35:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/16/2022 22:35:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/16/2022 22:35:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/16/2022 22:35:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/16/2022 22:35:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/16/2022 22:36:02 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9734594350936856 on epoch=142
06/16/2022 22:36:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/16/2022 22:36:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/16/2022 22:36:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/16/2022 22:36:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/16/2022 22:36:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/16/2022 22:36:24 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9734594350936856 on epoch=146
06/16/2022 22:36:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/16/2022 22:36:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/16/2022 22:36:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
06/16/2022 22:36:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=149
06/16/2022 22:36:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/16/2022 22:36:45 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9734594350936856 on epoch=149
06/16/2022 22:36:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/16/2022 22:36:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=151
06/16/2022 22:36:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/16/2022 22:36:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/16/2022 22:36:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/16/2022 22:37:06 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=153
06/16/2022 22:37:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9779113991637711 -> 0.9823800487937111 on epoch=153, global_step=2150
06/16/2022 22:37:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/16/2022 22:37:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
06/16/2022 22:37:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/16/2022 22:37:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/16/2022 22:37:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
06/16/2022 22:37:27 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9823800487937111 on epoch=157
06/16/2022 22:37:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/16/2022 22:37:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/16/2022 22:37:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/16/2022 22:37:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/16/2022 22:37:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.14 on epoch=160
06/16/2022 22:37:49 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9147375079063884 on epoch=160
06/16/2022 22:37:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/16/2022 22:37:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/16/2022 22:37:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/16/2022 22:38:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/16/2022 22:38:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/16/2022 22:38:10 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=164
06/16/2022 22:38:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/16/2022 22:38:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/16/2022 22:38:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/16/2022 22:38:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/16/2022 22:38:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/16/2022 22:38:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9105667682517778 on epoch=167
06/16/2022 22:38:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/16/2022 22:38:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/16/2022 22:38:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/16/2022 22:38:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/16/2022 22:38:46 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/16/2022 22:38:53 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9082728614417419 on epoch=171
06/16/2022 22:38:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/16/2022 22:38:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/16/2022 22:39:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/16/2022 22:39:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/16/2022 22:39:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/16/2022 22:39:14 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9105667682517778 on epoch=174
06/16/2022 22:39:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/16/2022 22:39:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/16/2022 22:39:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/16/2022 22:39:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/16/2022 22:39:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/16/2022 22:39:35 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=178
06/16/2022 22:39:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/16/2022 22:39:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/16/2022 22:39:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/16/2022 22:39:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/16/2022 22:39:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/16/2022 22:39:56 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9105667682517778 on epoch=182
06/16/2022 22:39:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/16/2022 22:40:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/16/2022 22:40:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/16/2022 22:40:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/16/2022 22:40:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/16/2022 22:40:18 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=185
06/16/2022 22:40:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/16/2022 22:40:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/16/2022 22:40:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/16/2022 22:40:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/16/2022 22:40:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/16/2022 22:40:39 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.9779113991637711 on epoch=189
06/16/2022 22:40:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/16/2022 22:40:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/16/2022 22:40:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/16/2022 22:40:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/16/2022 22:40:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/16/2022 22:41:00 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=192
06/16/2022 22:41:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/16/2022 22:41:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/16/2022 22:41:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/16/2022 22:41:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/16/2022 22:41:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/16/2022 22:41:21 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.9779113991637711 on epoch=196
06/16/2022 22:41:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/16/2022 22:41:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/16/2022 22:41:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/16/2022 22:41:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/16/2022 22:41:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/16/2022 22:41:42 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9105667682517778 on epoch=199
06/16/2022 22:41:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/16/2022 22:41:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/16/2022 22:41:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/16/2022 22:41:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/16/2022 22:41:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/16/2022 22:42:04 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=203
06/16/2022 22:42:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/16/2022 22:42:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/16/2022 22:42:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/16/2022 22:42:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/16/2022 22:42:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/16/2022 22:42:25 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9779113991637711 on epoch=207
06/16/2022 22:42:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/16/2022 22:42:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/16/2022 22:42:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/16/2022 22:42:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/16/2022 22:42:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/16/2022 22:42:46 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=210
06/16/2022 22:42:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/16/2022 22:42:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/16/2022 22:42:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/16/2022 22:42:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/16/2022 22:43:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/16/2022 22:43:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:43:03 - INFO - __main__ - Printing 3 examples
06/16/2022 22:43:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 22:43:03 - INFO - __main__ - ['Animal']
06/16/2022 22:43:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 22:43:03 - INFO - __main__ - ['Animal']
06/16/2022 22:43:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 22:43:03 - INFO - __main__ - ['Animal']
06/16/2022 22:43:03 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:43:03 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:43:03 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 22:43:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:43:03 - INFO - __main__ - Printing 3 examples
06/16/2022 22:43:03 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 22:43:03 - INFO - __main__ - ['Animal']
06/16/2022 22:43:03 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 22:43:03 - INFO - __main__ - ['Animal']
06/16/2022 22:43:03 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 22:43:03 - INFO - __main__ - ['Animal']
06/16/2022 22:43:03 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:43:03 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:43:03 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 22:43:08 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9779113991637711 on epoch=214
06/16/2022 22:43:08 - INFO - __main__ - save last model!
06/16/2022 22:43:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 22:43:08 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 22:43:08 - INFO - __main__ - Printing 3 examples
06/16/2022 22:43:08 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 22:43:08 - INFO - __main__ - ['Animal']
06/16/2022 22:43:08 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 22:43:08 - INFO - __main__ - ['Animal']
06/16/2022 22:43:08 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 22:43:08 - INFO - __main__ - ['Village']
06/16/2022 22:43:08 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:43:10 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:43:13 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 22:43:19 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 22:43:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 22:43:19 - INFO - __main__ - Starting training!
06/16/2022 22:45:32 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/16/2022 22:45:32 - INFO - __main__ - Classification-F1 on test data: 0.6499
06/16/2022 22:45:33 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9823800487937111, test_performance=0.6499184428263802
06/16/2022 22:45:33 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/16/2022 22:45:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:45:34 - INFO - __main__ - Printing 3 examples
06/16/2022 22:45:34 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 22:45:34 - INFO - __main__ - ['Animal']
06/16/2022 22:45:34 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 22:45:34 - INFO - __main__ - ['Animal']
06/16/2022 22:45:34 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 22:45:34 - INFO - __main__ - ['Animal']
06/16/2022 22:45:34 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:45:34 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:45:34 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 22:45:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 22:45:34 - INFO - __main__ - Printing 3 examples
06/16/2022 22:45:34 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 22:45:34 - INFO - __main__ - ['Animal']
06/16/2022 22:45:34 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 22:45:34 - INFO - __main__ - ['Animal']
06/16/2022 22:45:34 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 22:45:34 - INFO - __main__ - ['Animal']
06/16/2022 22:45:34 - INFO - __main__ - Tokenizing Input ...
06/16/2022 22:45:34 - INFO - __main__ - Tokenizing Output ...
06/16/2022 22:45:34 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 22:45:49 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 22:45:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 22:45:50 - INFO - __main__ - Starting training!
06/16/2022 22:45:54 - INFO - __main__ - Step 10 Global step 10 Train loss 7.54 on epoch=0
06/16/2022 22:45:57 - INFO - __main__ - Step 20 Global step 20 Train loss 5.24 on epoch=1
06/16/2022 22:46:00 - INFO - __main__ - Step 30 Global step 30 Train loss 4.41 on epoch=2
06/16/2022 22:46:03 - INFO - __main__ - Step 40 Global step 40 Train loss 3.81 on epoch=2
06/16/2022 22:46:06 - INFO - __main__ - Step 50 Global step 50 Train loss 3.53 on epoch=3
06/16/2022 22:46:11 - INFO - __main__ - Global step 50 Train loss 4.91 Classification-F1 0.053118214058250325 on epoch=3
06/16/2022 22:46:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.053118214058250325 on epoch=3, global_step=50
06/16/2022 22:46:14 - INFO - __main__ - Step 60 Global step 60 Train loss 3.41 on epoch=4
06/16/2022 22:46:17 - INFO - __main__ - Step 70 Global step 70 Train loss 2.86 on epoch=4
06/16/2022 22:46:20 - INFO - __main__ - Step 80 Global step 80 Train loss 2.74 on epoch=5
06/16/2022 22:46:22 - INFO - __main__ - Step 90 Global step 90 Train loss 2.42 on epoch=6
06/16/2022 22:46:25 - INFO - __main__ - Step 100 Global step 100 Train loss 2.21 on epoch=7
06/16/2022 22:46:30 - INFO - __main__ - Global step 100 Train loss 2.73 Classification-F1 0.1314515281358783 on epoch=7
06/16/2022 22:46:30 - INFO - __main__ - Saving model with best Classification-F1: 0.053118214058250325 -> 0.1314515281358783 on epoch=7, global_step=100
06/16/2022 22:46:33 - INFO - __main__ - Step 110 Global step 110 Train loss 2.12 on epoch=7
06/16/2022 22:46:36 - INFO - __main__ - Step 120 Global step 120 Train loss 1.92 on epoch=8
06/16/2022 22:46:39 - INFO - __main__ - Step 130 Global step 130 Train loss 2.02 on epoch=9
06/16/2022 22:46:42 - INFO - __main__ - Step 140 Global step 140 Train loss 1.69 on epoch=9
06/16/2022 22:46:45 - INFO - __main__ - Step 150 Global step 150 Train loss 1.63 on epoch=10
06/16/2022 22:46:51 - INFO - __main__ - Global step 150 Train loss 1.87 Classification-F1 0.1651902285270906 on epoch=10
06/16/2022 22:46:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1314515281358783 -> 0.1651902285270906 on epoch=10, global_step=150
06/16/2022 22:46:54 - INFO - __main__ - Step 160 Global step 160 Train loss 1.51 on epoch=11
06/16/2022 22:46:57 - INFO - __main__ - Step 170 Global step 170 Train loss 1.53 on epoch=12
06/16/2022 22:47:00 - INFO - __main__ - Step 180 Global step 180 Train loss 1.29 on epoch=12
06/16/2022 22:47:02 - INFO - __main__ - Step 190 Global step 190 Train loss 1.31 on epoch=13
06/16/2022 22:47:05 - INFO - __main__ - Step 200 Global step 200 Train loss 1.27 on epoch=14
06/16/2022 22:47:12 - INFO - __main__ - Global step 200 Train loss 1.38 Classification-F1 0.2859956276253376 on epoch=14
06/16/2022 22:47:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1651902285270906 -> 0.2859956276253376 on epoch=14, global_step=200
06/16/2022 22:47:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=14
06/16/2022 22:47:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.99 on epoch=15
06/16/2022 22:47:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.97 on epoch=16
06/16/2022 22:47:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.91 on epoch=17
06/16/2022 22:47:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=17
06/16/2022 22:47:32 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.3571122767590591 on epoch=17
06/16/2022 22:47:32 - INFO - __main__ - Saving model with best Classification-F1: 0.2859956276253376 -> 0.3571122767590591 on epoch=17, global_step=250
06/16/2022 22:47:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.80 on epoch=18
06/16/2022 22:47:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.71 on epoch=19
06/16/2022 22:47:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.60 on epoch=19
06/16/2022 22:47:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=20
06/16/2022 22:47:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=21
06/16/2022 22:47:54 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.47787508885256386 on epoch=21
06/16/2022 22:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.3571122767590591 -> 0.47787508885256386 on epoch=21, global_step=300
06/16/2022 22:47:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=22
06/16/2022 22:48:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=22
06/16/2022 22:48:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=23
06/16/2022 22:48:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=24
06/16/2022 22:48:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=24
06/16/2022 22:48:15 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.5398630383367617 on epoch=24
06/16/2022 22:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.47787508885256386 -> 0.5398630383367617 on epoch=24, global_step=350
06/16/2022 22:48:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=25
06/16/2022 22:48:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=26
06/16/2022 22:48:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/16/2022 22:48:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
06/16/2022 22:48:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=28
06/16/2022 22:48:36 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.5888588380320557 on epoch=28
06/16/2022 22:48:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5398630383367617 -> 0.5888588380320557 on epoch=28, global_step=400
06/16/2022 22:48:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=29
06/16/2022 22:48:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=29
06/16/2022 22:48:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=30
06/16/2022 22:48:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
06/16/2022 22:48:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=32
06/16/2022 22:48:58 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.7310802399457735 on epoch=32
06/16/2022 22:48:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5888588380320557 -> 0.7310802399457735 on epoch=32, global_step=450
06/16/2022 22:49:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
06/16/2022 22:49:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=33
06/16/2022 22:49:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
06/16/2022 22:49:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/16/2022 22:49:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
06/16/2022 22:49:19 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.729889480241082 on epoch=35
06/16/2022 22:49:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
06/16/2022 22:49:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=37
06/16/2022 22:49:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
06/16/2022 22:49:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
06/16/2022 22:49:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
06/16/2022 22:49:41 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6849913591849077 on epoch=39
06/16/2022 22:49:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=39
06/16/2022 22:49:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=40
06/16/2022 22:49:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/16/2022 22:49:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=42
06/16/2022 22:49:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
06/16/2022 22:50:02 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.7802852858860609 on epoch=42
06/16/2022 22:50:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7310802399457735 -> 0.7802852858860609 on epoch=42, global_step=600
06/16/2022 22:50:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
06/16/2022 22:50:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
06/16/2022 22:50:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=44
06/16/2022 22:50:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
06/16/2022 22:50:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=46
06/16/2022 22:50:24 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.7740426844024393 on epoch=46
06/16/2022 22:50:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/16/2022 22:50:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
06/16/2022 22:50:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=48
06/16/2022 22:50:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
06/16/2022 22:50:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
06/16/2022 22:50:45 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.8208275147791277 on epoch=49
06/16/2022 22:50:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7802852858860609 -> 0.8208275147791277 on epoch=49, global_step=700
06/16/2022 22:50:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/16/2022 22:50:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
06/16/2022 22:50:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
06/16/2022 22:50:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/16/2022 22:51:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/16/2022 22:51:06 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.8257722988388904 on epoch=53
06/16/2022 22:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8208275147791277 -> 0.8257722988388904 on epoch=53, global_step=750
06/16/2022 22:51:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
06/16/2022 22:51:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
06/16/2022 22:51:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/16/2022 22:51:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
06/16/2022 22:51:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=57
06/16/2022 22:51:27 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8295793596030787 on epoch=57
06/16/2022 22:51:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8257722988388904 -> 0.8295793596030787 on epoch=57, global_step=800
06/16/2022 22:51:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
06/16/2022 22:51:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
06/16/2022 22:51:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/16/2022 22:51:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
06/16/2022 22:51:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/16/2022 22:51:49 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.8387761879148857 on epoch=60
06/16/2022 22:51:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8295793596030787 -> 0.8387761879148857 on epoch=60, global_step=850
06/16/2022 22:51:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/16/2022 22:51:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/16/2022 22:51:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/16/2022 22:52:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/16/2022 22:52:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
06/16/2022 22:52:10 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7874310645616037 on epoch=64
06/16/2022 22:52:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
06/16/2022 22:52:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/16/2022 22:52:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/16/2022 22:52:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/16/2022 22:52:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
06/16/2022 22:52:31 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7490866010790109 on epoch=67
06/16/2022 22:52:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/16/2022 22:52:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/16/2022 22:52:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/16/2022 22:52:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/16/2022 22:52:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/16/2022 22:52:52 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7474391673501797 on epoch=71
06/16/2022 22:52:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=72
06/16/2022 22:52:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/16/2022 22:53:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/16/2022 22:53:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/16/2022 22:53:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/16/2022 22:53:14 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7951272752115962 on epoch=74
06/16/2022 22:53:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/16/2022 22:53:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
06/16/2022 22:53:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/16/2022 22:53:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/16/2022 22:53:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/16/2022 22:53:34 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7075516114765091 on epoch=78
06/16/2022 22:53:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/16/2022 22:53:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/16/2022 22:53:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
06/16/2022 22:53:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/16/2022 22:53:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/16/2022 22:53:56 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7916908992335937 on epoch=82
06/16/2022 22:53:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/16/2022 22:54:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/16/2022 22:54:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/16/2022 22:54:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/16/2022 22:54:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/16/2022 22:54:17 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7492898625725951 on epoch=85
06/16/2022 22:54:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/16/2022 22:54:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/16/2022 22:54:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/16/2022 22:54:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/16/2022 22:54:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/16/2022 22:54:38 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7031903189236587 on epoch=89
06/16/2022 22:54:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/16/2022 22:54:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/16/2022 22:54:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/16/2022 22:54:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/16/2022 22:54:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/16/2022 22:54:59 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7490967835488708 on epoch=92
06/16/2022 22:55:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/16/2022 22:55:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/16/2022 22:55:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/16/2022 22:55:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/16/2022 22:55:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/16/2022 22:55:20 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7852985805519571 on epoch=96
06/16/2022 22:55:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/16/2022 22:55:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/16/2022 22:55:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/16/2022 22:55:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/16/2022 22:55:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
06/16/2022 22:55:41 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7027733535148896 on epoch=99
06/16/2022 22:55:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/16/2022 22:55:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/16/2022 22:55:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/16/2022 22:55:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/16/2022 22:55:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/16/2022 22:56:02 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7717493744282449 on epoch=103
06/16/2022 22:56:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/16/2022 22:56:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/16/2022 22:56:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/16/2022 22:56:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/16/2022 22:56:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/16/2022 22:56:23 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7859185917382067 on epoch=107
06/16/2022 22:56:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/16/2022 22:56:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/16/2022 22:56:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/16/2022 22:56:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/16/2022 22:56:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/16/2022 22:56:45 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7498120606991575 on epoch=110
06/16/2022 22:56:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/16/2022 22:56:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/16/2022 22:56:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/16/2022 22:56:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/16/2022 22:56:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/16/2022 22:57:06 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8406909336315171 on epoch=114
06/16/2022 22:57:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8387761879148857 -> 0.8406909336315171 on epoch=114, global_step=1600
06/16/2022 22:57:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/16/2022 22:57:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/16/2022 22:57:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/16/2022 22:57:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/16/2022 22:57:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/16/2022 22:57:27 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7897502504936371 on epoch=117
06/16/2022 22:57:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/16/2022 22:57:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/16/2022 22:57:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/16/2022 22:57:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/16/2022 22:57:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/16/2022 22:57:48 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7366811696982476 on epoch=121
06/16/2022 22:57:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/16/2022 22:57:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/16/2022 22:57:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/16/2022 22:58:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/16/2022 22:58:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/16/2022 22:58:09 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7412462544483418 on epoch=124
06/16/2022 22:58:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/16/2022 22:58:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/16/2022 22:58:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/16/2022 22:58:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/16/2022 22:58:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/16/2022 22:58:30 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6926128067495265 on epoch=128
06/16/2022 22:58:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/16/2022 22:58:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/16/2022 22:58:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=130
06/16/2022 22:58:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/16/2022 22:58:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/16/2022 22:58:51 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7868543228918271 on epoch=132
06/16/2022 22:58:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/16/2022 22:58:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/16/2022 22:59:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/16/2022 22:59:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=134
06/16/2022 22:59:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/16/2022 22:59:13 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7960255623917862 on epoch=135
06/16/2022 22:59:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/16/2022 22:59:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/16/2022 22:59:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/16/2022 22:59:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/16/2022 22:59:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/16/2022 22:59:33 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7488065100968329 on epoch=139
06/16/2022 22:59:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/16/2022 22:59:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/16/2022 22:59:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/16/2022 22:59:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/16/2022 22:59:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/16/2022 22:59:55 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8021955116357393 on epoch=142
06/16/2022 22:59:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/16/2022 23:00:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/16/2022 23:00:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/16/2022 23:00:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/16/2022 23:00:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/16/2022 23:00:16 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8544634129311548 on epoch=146
06/16/2022 23:00:16 - INFO - __main__ - Saving model with best Classification-F1: 0.8406909336315171 -> 0.8544634129311548 on epoch=146, global_step=2050
06/16/2022 23:00:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/16/2022 23:00:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/16/2022 23:00:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/16/2022 23:00:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/16/2022 23:00:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/16/2022 23:00:38 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8479078418594548 on epoch=149
06/16/2022 23:00:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/16/2022 23:00:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/16/2022 23:00:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/16/2022 23:00:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/16/2022 23:00:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
06/16/2022 23:00:59 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8544634129311548 on epoch=153
06/16/2022 23:01:02 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/16/2022 23:01:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/16/2022 23:01:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/16/2022 23:01:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/16/2022 23:01:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/16/2022 23:01:20 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7960255623917862 on epoch=157
06/16/2022 23:01:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/16/2022 23:01:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/16/2022 23:01:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/16/2022 23:01:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/16/2022 23:01:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/16/2022 23:01:42 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8021955116357393 on epoch=160
06/16/2022 23:01:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/16/2022 23:01:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/16/2022 23:01:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/16/2022 23:01:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/16/2022 23:01:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/16/2022 23:02:03 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8592451735092864 on epoch=164
06/16/2022 23:02:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8544634129311548 -> 0.8592451735092864 on epoch=164, global_step=2300
06/16/2022 23:02:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/16/2022 23:02:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/16/2022 23:02:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/16/2022 23:02:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/16/2022 23:02:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/16/2022 23:02:24 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9186460429724188 on epoch=167
06/16/2022 23:02:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8592451735092864 -> 0.9186460429724188 on epoch=167, global_step=2350
06/16/2022 23:02:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/16/2022 23:02:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/16/2022 23:02:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/16/2022 23:02:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/16/2022 23:02:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/16/2022 23:02:46 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9822527251369758 on epoch=171
06/16/2022 23:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9186460429724188 -> 0.9822527251369758 on epoch=171, global_step=2400
06/16/2022 23:02:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/16/2022 23:02:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/16/2022 23:02:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/16/2022 23:02:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/16/2022 23:03:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/16/2022 23:03:07 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9777840755070358 on epoch=174
06/16/2022 23:03:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/16/2022 23:03:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/16/2022 23:03:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/16/2022 23:03:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/16/2022 23:03:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/16/2022 23:03:29 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9777840755070358 on epoch=178
06/16/2022 23:03:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/16/2022 23:03:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/16/2022 23:03:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/16/2022 23:03:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/16/2022 23:03:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/16/2022 23:03:50 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9120231960381148 on epoch=182
06/16/2022 23:03:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/16/2022 23:03:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/16/2022 23:03:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/16/2022 23:04:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/16/2022 23:04:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/16/2022 23:04:11 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9822527251369758 on epoch=185
06/16/2022 23:04:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/16/2022 23:04:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/16/2022 23:04:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/16/2022 23:04:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/16/2022 23:04:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/16/2022 23:04:32 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9822527251369758 on epoch=189
06/16/2022 23:04:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/16/2022 23:04:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/16/2022 23:04:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/16/2022 23:04:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/16/2022 23:04:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/16/2022 23:04:53 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.910434899277404 on epoch=192
06/16/2022 23:04:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/16/2022 23:04:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/16/2022 23:05:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/16/2022 23:05:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/16/2022 23:05:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/16/2022 23:05:15 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9099380905832518 on epoch=196
06/16/2022 23:05:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/16/2022 23:05:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/16/2022 23:05:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/16/2022 23:05:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/16/2022 23:05:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/16/2022 23:05:36 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8511116778595349 on epoch=199
06/16/2022 23:05:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/16/2022 23:05:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/16/2022 23:05:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/16/2022 23:05:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/16/2022 23:05:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/16/2022 23:05:58 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8538232578792351 on epoch=203
06/16/2022 23:06:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/16/2022 23:06:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/16/2022 23:06:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/16/2022 23:06:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/16/2022 23:06:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/16/2022 23:06:20 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8538232578792351 on epoch=207
06/16/2022 23:06:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/16/2022 23:06:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/16/2022 23:06:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/16/2022 23:06:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/16/2022 23:06:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/16/2022 23:06:42 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9822527251369758 on epoch=210
06/16/2022 23:06:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/16/2022 23:06:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/16/2022 23:06:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/16/2022 23:06:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/16/2022 23:06:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/16/2022 23:06:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:06:58 - INFO - __main__ - Printing 3 examples
06/16/2022 23:06:58 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 23:06:58 - INFO - __main__ - ['Animal']
06/16/2022 23:06:58 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 23:06:58 - INFO - __main__ - ['Animal']
06/16/2022 23:06:58 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 23:06:58 - INFO - __main__ - ['Animal']
06/16/2022 23:06:58 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:06:58 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:06:59 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 23:06:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:06:59 - INFO - __main__ - Printing 3 examples
06/16/2022 23:06:59 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 23:06:59 - INFO - __main__ - ['Animal']
06/16/2022 23:06:59 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 23:06:59 - INFO - __main__ - ['Animal']
06/16/2022 23:06:59 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 23:06:59 - INFO - __main__ - ['Animal']
06/16/2022 23:06:59 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:06:59 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:06:59 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 23:07:04 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9061092902459128 on epoch=214
06/16/2022 23:07:04 - INFO - __main__ - save last model!
06/16/2022 23:07:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 23:07:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 23:07:04 - INFO - __main__ - Printing 3 examples
06/16/2022 23:07:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 23:07:04 - INFO - __main__ - ['Animal']
06/16/2022 23:07:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 23:07:04 - INFO - __main__ - ['Animal']
06/16/2022 23:07:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 23:07:04 - INFO - __main__ - ['Village']
06/16/2022 23:07:04 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:07:06 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:07:09 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 23:07:17 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:07:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 23:07:18 - INFO - __main__ - Starting training!
06/16/2022 23:09:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/16/2022 23:09:29 - INFO - __main__ - Classification-F1 on test data: 0.5455
06/16/2022 23:09:29 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9822527251369758, test_performance=0.5455433712264116
06/16/2022 23:09:29 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/16/2022 23:09:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:09:30 - INFO - __main__ - Printing 3 examples
06/16/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/16/2022 23:09:30 - INFO - __main__ - ['Animal']
06/16/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/16/2022 23:09:30 - INFO - __main__ - ['Animal']
06/16/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/16/2022 23:09:30 - INFO - __main__ - ['Animal']
06/16/2022 23:09:30 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:09:30 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:09:30 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 23:09:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:09:30 - INFO - __main__ - Printing 3 examples
06/16/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/16/2022 23:09:30 - INFO - __main__ - ['Animal']
06/16/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/16/2022 23:09:30 - INFO - __main__ - ['Animal']
06/16/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/16/2022 23:09:30 - INFO - __main__ - ['Animal']
06/16/2022 23:09:30 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:09:30 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:09:31 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 23:09:49 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:09:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 23:09:50 - INFO - __main__ - Starting training!
06/16/2022 23:09:54 - INFO - __main__ - Step 10 Global step 10 Train loss 7.97 on epoch=0
06/16/2022 23:09:57 - INFO - __main__ - Step 20 Global step 20 Train loss 6.18 on epoch=1
06/16/2022 23:10:00 - INFO - __main__ - Step 30 Global step 30 Train loss 5.17 on epoch=2
06/16/2022 23:10:03 - INFO - __main__ - Step 40 Global step 40 Train loss 4.64 on epoch=2
06/16/2022 23:10:06 - INFO - __main__ - Step 50 Global step 50 Train loss 4.20 on epoch=3
06/16/2022 23:10:12 - INFO - __main__ - Global step 50 Train loss 5.63 Classification-F1 0.03521666034399481 on epoch=3
06/16/2022 23:10:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03521666034399481 on epoch=3, global_step=50
06/16/2022 23:10:15 - INFO - __main__ - Step 60 Global step 60 Train loss 4.05 on epoch=4
06/16/2022 23:10:18 - INFO - __main__ - Step 70 Global step 70 Train loss 3.52 on epoch=4
06/16/2022 23:10:21 - INFO - __main__ - Step 80 Global step 80 Train loss 3.41 on epoch=5
06/16/2022 23:10:24 - INFO - __main__ - Step 90 Global step 90 Train loss 3.22 on epoch=6
06/16/2022 23:10:27 - INFO - __main__ - Step 100 Global step 100 Train loss 3.20 on epoch=7
06/16/2022 23:10:33 - INFO - __main__ - Global step 100 Train loss 3.48 Classification-F1 0.10080455984746507 on epoch=7
06/16/2022 23:10:33 - INFO - __main__ - Saving model with best Classification-F1: 0.03521666034399481 -> 0.10080455984746507 on epoch=7, global_step=100
06/16/2022 23:10:36 - INFO - __main__ - Step 110 Global step 110 Train loss 2.82 on epoch=7
06/16/2022 23:10:39 - INFO - __main__ - Step 120 Global step 120 Train loss 2.68 on epoch=8
06/16/2022 23:10:42 - INFO - __main__ - Step 130 Global step 130 Train loss 2.62 on epoch=9
06/16/2022 23:10:45 - INFO - __main__ - Step 140 Global step 140 Train loss 2.24 on epoch=9
06/16/2022 23:10:48 - INFO - __main__ - Step 150 Global step 150 Train loss 2.49 on epoch=10
06/16/2022 23:10:54 - INFO - __main__ - Global step 150 Train loss 2.57 Classification-F1 0.14343707099724426 on epoch=10
06/16/2022 23:10:54 - INFO - __main__ - Saving model with best Classification-F1: 0.10080455984746507 -> 0.14343707099724426 on epoch=10, global_step=150
06/16/2022 23:10:57 - INFO - __main__ - Step 160 Global step 160 Train loss 2.08 on epoch=11
06/16/2022 23:11:00 - INFO - __main__ - Step 170 Global step 170 Train loss 1.99 on epoch=12
06/16/2022 23:11:03 - INFO - __main__ - Step 180 Global step 180 Train loss 1.88 on epoch=12
06/16/2022 23:11:06 - INFO - __main__ - Step 190 Global step 190 Train loss 1.93 on epoch=13
06/16/2022 23:11:09 - INFO - __main__ - Step 200 Global step 200 Train loss 1.94 on epoch=14
06/16/2022 23:11:14 - INFO - __main__ - Global step 200 Train loss 1.96 Classification-F1 0.15242972244101055 on epoch=14
06/16/2022 23:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.14343707099724426 -> 0.15242972244101055 on epoch=14, global_step=200
06/16/2022 23:11:17 - INFO - __main__ - Step 210 Global step 210 Train loss 1.62 on epoch=14
06/16/2022 23:11:20 - INFO - __main__ - Step 220 Global step 220 Train loss 1.73 on epoch=15
06/16/2022 23:11:23 - INFO - __main__ - Step 230 Global step 230 Train loss 1.54 on epoch=16
06/16/2022 23:11:26 - INFO - __main__ - Step 240 Global step 240 Train loss 1.56 on epoch=17
06/16/2022 23:11:29 - INFO - __main__ - Step 250 Global step 250 Train loss 1.50 on epoch=17
06/16/2022 23:11:35 - INFO - __main__ - Global step 250 Train loss 1.59 Classification-F1 0.1708663926896604 on epoch=17
06/16/2022 23:11:35 - INFO - __main__ - Saving model with best Classification-F1: 0.15242972244101055 -> 0.1708663926896604 on epoch=17, global_step=250
06/16/2022 23:11:38 - INFO - __main__ - Step 260 Global step 260 Train loss 1.38 on epoch=18
06/16/2022 23:11:41 - INFO - __main__ - Step 270 Global step 270 Train loss 1.37 on epoch=19
06/16/2022 23:11:44 - INFO - __main__ - Step 280 Global step 280 Train loss 1.20 on epoch=19
06/16/2022 23:11:47 - INFO - __main__ - Step 290 Global step 290 Train loss 1.29 on epoch=20
06/16/2022 23:11:50 - INFO - __main__ - Step 300 Global step 300 Train loss 1.19 on epoch=21
06/16/2022 23:11:57 - INFO - __main__ - Global step 300 Train loss 1.29 Classification-F1 0.26219600417320105 on epoch=21
06/16/2022 23:11:57 - INFO - __main__ - Saving model with best Classification-F1: 0.1708663926896604 -> 0.26219600417320105 on epoch=21, global_step=300
06/16/2022 23:12:00 - INFO - __main__ - Step 310 Global step 310 Train loss 1.19 on epoch=22
06/16/2022 23:12:03 - INFO - __main__ - Step 320 Global step 320 Train loss 1.10 on epoch=22
06/16/2022 23:12:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.97 on epoch=23
06/16/2022 23:12:09 - INFO - __main__ - Step 340 Global step 340 Train loss 1.03 on epoch=24
06/16/2022 23:12:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.83 on epoch=24
06/16/2022 23:12:18 - INFO - __main__ - Global step 350 Train loss 1.02 Classification-F1 0.3522582272970644 on epoch=24
06/16/2022 23:12:18 - INFO - __main__ - Saving model with best Classification-F1: 0.26219600417320105 -> 0.3522582272970644 on epoch=24, global_step=350
06/16/2022 23:12:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.82 on epoch=25
06/16/2022 23:12:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.72 on epoch=26
06/16/2022 23:12:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.86 on epoch=27
06/16/2022 23:12:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.77 on epoch=27
06/16/2022 23:12:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.63 on epoch=28
06/16/2022 23:12:40 - INFO - __main__ - Global step 400 Train loss 0.76 Classification-F1 0.4480670416435404 on epoch=28
06/16/2022 23:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.3522582272970644 -> 0.4480670416435404 on epoch=28, global_step=400
06/16/2022 23:12:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.72 on epoch=29
06/16/2022 23:12:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.62 on epoch=29
06/16/2022 23:12:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=30
06/16/2022 23:12:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.69 on epoch=31
06/16/2022 23:12:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=32
06/16/2022 23:13:02 - INFO - __main__ - Global step 450 Train loss 0.65 Classification-F1 0.5681548056807184 on epoch=32
06/16/2022 23:13:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4480670416435404 -> 0.5681548056807184 on epoch=32, global_step=450
06/16/2022 23:13:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=32
06/16/2022 23:13:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=33
06/16/2022 23:13:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=34
06/16/2022 23:13:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=34
06/16/2022 23:13:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=35
06/16/2022 23:13:24 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.6263438395886214 on epoch=35
06/16/2022 23:13:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5681548056807184 -> 0.6263438395886214 on epoch=35, global_step=500
06/16/2022 23:13:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=36
06/16/2022 23:13:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=37
06/16/2022 23:13:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=37
06/16/2022 23:13:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.49 on epoch=38
06/16/2022 23:13:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
06/16/2022 23:13:46 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.5960675637767833 on epoch=39
06/16/2022 23:13:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
06/16/2022 23:13:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=40
06/16/2022 23:13:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=41
06/16/2022 23:13:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
06/16/2022 23:14:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
06/16/2022 23:14:09 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.6091809157680669 on epoch=42
06/16/2022 23:14:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=43
06/16/2022 23:14:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=44
06/16/2022 23:14:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
06/16/2022 23:14:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=45
06/16/2022 23:14:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=46
06/16/2022 23:14:31 - INFO - __main__ - Global step 650 Train loss 0.29 Classification-F1 0.5955714315703473 on epoch=46
06/16/2022 23:14:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=47
06/16/2022 23:14:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=47
06/16/2022 23:14:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=48
06/16/2022 23:14:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
06/16/2022 23:14:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=49
06/16/2022 23:14:53 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.661335625795621 on epoch=49
06/16/2022 23:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6263438395886214 -> 0.661335625795621 on epoch=49, global_step=700
06/16/2022 23:14:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/16/2022 23:14:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=51
06/16/2022 23:15:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=52
06/16/2022 23:15:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=52
06/16/2022 23:15:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/16/2022 23:15:15 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6938530711937478 on epoch=53
06/16/2022 23:15:15 - INFO - __main__ - Saving model with best Classification-F1: 0.661335625795621 -> 0.6938530711937478 on epoch=53, global_step=750
06/16/2022 23:15:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=54
06/16/2022 23:15:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=54
06/16/2022 23:15:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=55
06/16/2022 23:15:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/16/2022 23:15:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
06/16/2022 23:15:37 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6621918778315463 on epoch=57
06/16/2022 23:15:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/16/2022 23:15:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/16/2022 23:15:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
06/16/2022 23:15:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=59
06/16/2022 23:15:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
06/16/2022 23:15:59 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.7338156940945123 on epoch=60
06/16/2022 23:16:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6938530711937478 -> 0.7338156940945123 on epoch=60, global_step=850
06/16/2022 23:16:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
06/16/2022 23:16:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
06/16/2022 23:16:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
06/16/2022 23:16:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=63
06/16/2022 23:16:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
06/16/2022 23:16:21 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.7313217441720975 on epoch=64
06/16/2022 23:16:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/16/2022 23:16:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=65
06/16/2022 23:16:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
06/16/2022 23:16:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=67
06/16/2022 23:16:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
06/16/2022 23:16:44 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.7393815264783006 on epoch=67
06/16/2022 23:16:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7338156940945123 -> 0.7393815264783006 on epoch=67, global_step=950
06/16/2022 23:16:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
06/16/2022 23:16:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
06/16/2022 23:16:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
06/16/2022 23:16:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
06/16/2022 23:16:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=71
06/16/2022 23:17:06 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7303376221782294 on epoch=71
06/16/2022 23:17:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
06/16/2022 23:17:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/16/2022 23:17:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/16/2022 23:17:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/16/2022 23:17:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=74
06/16/2022 23:17:28 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.7809792385652463 on epoch=74
06/16/2022 23:17:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7393815264783006 -> 0.7809792385652463 on epoch=74, global_step=1050
06/16/2022 23:17:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/16/2022 23:17:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/16/2022 23:17:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/16/2022 23:17:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/16/2022 23:17:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/16/2022 23:17:50 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7391844635058891 on epoch=78
06/16/2022 23:17:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/16/2022 23:17:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/16/2022 23:17:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
06/16/2022 23:18:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/16/2022 23:18:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
06/16/2022 23:18:12 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7340044785109137 on epoch=82
06/16/2022 23:18:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/16/2022 23:18:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
06/16/2022 23:18:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/16/2022 23:18:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/16/2022 23:18:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/16/2022 23:18:34 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.8228352150924546 on epoch=85
06/16/2022 23:18:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7809792385652463 -> 0.8228352150924546 on epoch=85, global_step=1200
06/16/2022 23:18:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/16/2022 23:18:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/16/2022 23:18:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/16/2022 23:18:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
06/16/2022 23:18:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/16/2022 23:18:56 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.8145536415934898 on epoch=89
06/16/2022 23:19:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
06/16/2022 23:19:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/16/2022 23:19:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/16/2022 23:19:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/16/2022 23:19:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/16/2022 23:19:19 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8261031889486637 on epoch=92
06/16/2022 23:19:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8228352150924546 -> 0.8261031889486637 on epoch=92, global_step=1300
06/16/2022 23:19:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/16/2022 23:19:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/16/2022 23:19:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/16/2022 23:19:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/16/2022 23:19:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/16/2022 23:19:41 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.8145536415934898 on epoch=96
06/16/2022 23:19:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/16/2022 23:19:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/16/2022 23:19:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/16/2022 23:19:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/16/2022 23:19:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/16/2022 23:20:03 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.8228352150924546 on epoch=99
06/16/2022 23:20:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/16/2022 23:20:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/16/2022 23:20:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/16/2022 23:20:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/16/2022 23:20:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/16/2022 23:20:26 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8297263773544609 on epoch=103
06/16/2022 23:20:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8261031889486637 -> 0.8297263773544609 on epoch=103, global_step=1450
06/16/2022 23:20:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/16/2022 23:20:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/16/2022 23:20:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/16/2022 23:20:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/16/2022 23:20:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=107
06/16/2022 23:20:48 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7672528709028319 on epoch=107
06/16/2022 23:20:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/16/2022 23:20:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/16/2022 23:20:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/16/2022 23:21:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
06/16/2022 23:21:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/16/2022 23:21:10 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.881555630398135 on epoch=110
06/16/2022 23:21:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8297263773544609 -> 0.881555630398135 on epoch=110, global_step=1550
06/16/2022 23:21:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/16/2022 23:21:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/16/2022 23:21:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/16/2022 23:21:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/16/2022 23:21:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/16/2022 23:21:32 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7698996161004246 on epoch=114
06/16/2022 23:21:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/16/2022 23:21:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
06/16/2022 23:21:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/16/2022 23:21:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/16/2022 23:21:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/16/2022 23:21:54 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8200542289251966 on epoch=117
06/16/2022 23:21:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/16/2022 23:22:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/16/2022 23:22:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/16/2022 23:22:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/16/2022 23:22:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/16/2022 23:22:16 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7696375585442636 on epoch=121
06/16/2022 23:22:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/16/2022 23:22:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/16/2022 23:22:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/16/2022 23:22:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/16/2022 23:22:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/16/2022 23:22:38 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7863154584432264 on epoch=124
06/16/2022 23:22:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/16/2022 23:22:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/16/2022 23:22:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/16/2022 23:22:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/16/2022 23:22:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/16/2022 23:23:00 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7333053881664219 on epoch=128
06/16/2022 23:23:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/16/2022 23:23:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/16/2022 23:23:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/16/2022 23:23:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/16/2022 23:23:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/16/2022 23:23:22 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7066824851974592 on epoch=132
06/16/2022 23:23:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/16/2022 23:23:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/16/2022 23:23:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/16/2022 23:23:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/16/2022 23:23:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
06/16/2022 23:23:44 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7361541600087245 on epoch=135
06/16/2022 23:23:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/16/2022 23:23:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/16/2022 23:23:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/16/2022 23:23:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/16/2022 23:23:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/16/2022 23:24:06 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7113886139832845 on epoch=139
06/16/2022 23:24:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/16/2022 23:24:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/16/2022 23:24:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/16/2022 23:24:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/16/2022 23:24:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/16/2022 23:24:28 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6781856746402837 on epoch=142
06/16/2022 23:24:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/16/2022 23:24:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/16/2022 23:24:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/16/2022 23:24:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
06/16/2022 23:24:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/16/2022 23:24:50 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7834216951013392 on epoch=146
06/16/2022 23:24:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/16/2022 23:24:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/16/2022 23:24:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/16/2022 23:25:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/16/2022 23:25:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/16/2022 23:25:12 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7200933997304966 on epoch=149
06/16/2022 23:25:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/16/2022 23:25:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/16/2022 23:25:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/16/2022 23:25:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/16/2022 23:25:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/16/2022 23:25:34 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7374107023063379 on epoch=153
06/16/2022 23:25:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/16/2022 23:25:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/16/2022 23:25:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/16/2022 23:25:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/16/2022 23:25:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/16/2022 23:25:56 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7455424933537871 on epoch=157
06/16/2022 23:25:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/16/2022 23:26:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/16/2022 23:26:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/16/2022 23:26:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/16/2022 23:26:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/16/2022 23:26:18 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7508067696859982 on epoch=160
06/16/2022 23:26:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/16/2022 23:26:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/16/2022 23:26:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/16/2022 23:26:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/16/2022 23:26:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/16/2022 23:26:40 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7509052002279772 on epoch=164
06/16/2022 23:26:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/16/2022 23:26:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/16/2022 23:26:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/16/2022 23:26:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/16/2022 23:26:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/16/2022 23:27:01 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8473918761558623 on epoch=167
06/16/2022 23:27:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/16/2022 23:27:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/16/2022 23:27:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/16/2022 23:27:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/16/2022 23:27:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/16/2022 23:27:23 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7332792475463253 on epoch=171
06/16/2022 23:27:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/16/2022 23:27:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/16/2022 23:27:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/16/2022 23:27:35 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/16/2022 23:27:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/16/2022 23:27:45 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8434818077296649 on epoch=174
06/16/2022 23:27:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/16/2022 23:27:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/16/2022 23:27:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/16/2022 23:27:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/16/2022 23:28:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/16/2022 23:28:07 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7128823047279916 on epoch=178
06/16/2022 23:28:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/16/2022 23:28:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/16/2022 23:28:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/16/2022 23:28:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/16/2022 23:28:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/16/2022 23:28:29 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.75248687721288 on epoch=182
06/16/2022 23:28:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/16/2022 23:28:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/16/2022 23:28:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/16/2022 23:28:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/16/2022 23:28:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/16/2022 23:28:51 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7484985392006265 on epoch=185
06/16/2022 23:28:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/16/2022 23:28:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/16/2022 23:29:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/16/2022 23:29:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/16/2022 23:29:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/16/2022 23:29:13 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.844523910787897 on epoch=189
06/16/2022 23:29:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/16/2022 23:29:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/16/2022 23:29:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/16/2022 23:29:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/16/2022 23:29:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/16/2022 23:29:34 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7897824260895879 on epoch=192
06/16/2022 23:29:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/16/2022 23:29:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/16/2022 23:29:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/16/2022 23:29:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/16/2022 23:29:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/16/2022 23:29:56 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8409466896274133 on epoch=196
06/16/2022 23:29:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/16/2022 23:30:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/16/2022 23:30:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/16/2022 23:30:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/16/2022 23:30:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/16/2022 23:30:18 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7021749770114828 on epoch=199
06/16/2022 23:30:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/16/2022 23:30:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/16/2022 23:30:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/16/2022 23:30:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/16/2022 23:30:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/16/2022 23:30:40 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7928627804884006 on epoch=203
06/16/2022 23:30:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/16/2022 23:30:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/16/2022 23:30:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/16/2022 23:30:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/16/2022 23:30:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/16/2022 23:31:02 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8407824860149339 on epoch=207
06/16/2022 23:31:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/16/2022 23:31:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/16/2022 23:31:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/16/2022 23:31:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/16/2022 23:31:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/16/2022 23:31:24 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8006435447305927 on epoch=210
06/16/2022 23:31:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/16/2022 23:31:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/16/2022 23:31:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/16/2022 23:31:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/16/2022 23:31:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/16/2022 23:31:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:31:41 - INFO - __main__ - Printing 3 examples
06/16/2022 23:31:41 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 23:31:41 - INFO - __main__ - ['Animal']
06/16/2022 23:31:41 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 23:31:41 - INFO - __main__ - ['Animal']
06/16/2022 23:31:41 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 23:31:41 - INFO - __main__ - ['Animal']
06/16/2022 23:31:41 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:31:41 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:31:41 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 23:31:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:31:41 - INFO - __main__ - Printing 3 examples
06/16/2022 23:31:41 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/16/2022 23:31:41 - INFO - __main__ - ['Animal']
06/16/2022 23:31:41 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/16/2022 23:31:41 - INFO - __main__ - ['Animal']
06/16/2022 23:31:41 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/16/2022 23:31:41 - INFO - __main__ - ['Animal']
06/16/2022 23:31:41 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:31:41 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:31:42 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 23:31:46 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7979991153113154 on epoch=214
06/16/2022 23:31:46 - INFO - __main__ - save last model!
06/16/2022 23:31:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 23:31:46 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 23:31:46 - INFO - __main__ - Printing 3 examples
06/16/2022 23:31:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 23:31:46 - INFO - __main__ - ['Animal']
06/16/2022 23:31:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 23:31:46 - INFO - __main__ - ['Animal']
06/16/2022 23:31:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 23:31:46 - INFO - __main__ - ['Village']
06/16/2022 23:31:46 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:31:48 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:31:51 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 23:32:00 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:32:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 23:32:01 - INFO - __main__ - Starting training!
06/16/2022 23:34:09 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/16/2022 23:34:09 - INFO - __main__ - Classification-F1 on test data: 0.4676
06/16/2022 23:34:10 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.881555630398135, test_performance=0.4676176859089478
06/16/2022 23:34:10 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/16/2022 23:34:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:34:11 - INFO - __main__ - Printing 3 examples
06/16/2022 23:34:11 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 23:34:11 - INFO - __main__ - ['Animal']
06/16/2022 23:34:11 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 23:34:11 - INFO - __main__ - ['Animal']
06/16/2022 23:34:11 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 23:34:11 - INFO - __main__ - ['Animal']
06/16/2022 23:34:11 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:34:11 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:34:11 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 23:34:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:34:11 - INFO - __main__ - Printing 3 examples
06/16/2022 23:34:11 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/16/2022 23:34:11 - INFO - __main__ - ['Animal']
06/16/2022 23:34:11 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/16/2022 23:34:11 - INFO - __main__ - ['Animal']
06/16/2022 23:34:11 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/16/2022 23:34:11 - INFO - __main__ - ['Animal']
06/16/2022 23:34:11 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:34:11 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:34:11 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 23:34:30 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:34:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 23:34:31 - INFO - __main__ - Starting training!
06/16/2022 23:34:34 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=0
06/16/2022 23:34:37 - INFO - __main__ - Step 20 Global step 20 Train loss 4.34 on epoch=1
06/16/2022 23:34:41 - INFO - __main__ - Step 30 Global step 30 Train loss 3.80 on epoch=2
06/16/2022 23:34:44 - INFO - __main__ - Step 40 Global step 40 Train loss 3.08 on epoch=2
06/16/2022 23:34:47 - INFO - __main__ - Step 50 Global step 50 Train loss 2.64 on epoch=3
06/16/2022 23:34:52 - INFO - __main__ - Global step 50 Train loss 4.12 Classification-F1 0.07342990966568985 on epoch=3
06/16/2022 23:34:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07342990966568985 on epoch=3, global_step=50
06/16/2022 23:34:55 - INFO - __main__ - Step 60 Global step 60 Train loss 2.59 on epoch=4
06/16/2022 23:34:58 - INFO - __main__ - Step 70 Global step 70 Train loss 2.17 on epoch=4
06/16/2022 23:35:01 - INFO - __main__ - Step 80 Global step 80 Train loss 1.83 on epoch=5
06/16/2022 23:35:04 - INFO - __main__ - Step 90 Global step 90 Train loss 1.67 on epoch=6
06/16/2022 23:35:07 - INFO - __main__ - Step 100 Global step 100 Train loss 1.59 on epoch=7
06/16/2022 23:35:13 - INFO - __main__ - Global step 100 Train loss 1.97 Classification-F1 0.14899404541730882 on epoch=7
06/16/2022 23:35:13 - INFO - __main__ - Saving model with best Classification-F1: 0.07342990966568985 -> 0.14899404541730882 on epoch=7, global_step=100
06/16/2022 23:35:16 - INFO - __main__ - Step 110 Global step 110 Train loss 1.36 on epoch=7
06/16/2022 23:35:19 - INFO - __main__ - Step 120 Global step 120 Train loss 1.28 on epoch=8
06/16/2022 23:35:22 - INFO - __main__ - Step 130 Global step 130 Train loss 1.12 on epoch=9
06/16/2022 23:35:25 - INFO - __main__ - Step 140 Global step 140 Train loss 1.02 on epoch=9
06/16/2022 23:35:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.92 on epoch=10
06/16/2022 23:35:34 - INFO - __main__ - Global step 150 Train loss 1.14 Classification-F1 0.28456735180545945 on epoch=10
06/16/2022 23:35:34 - INFO - __main__ - Saving model with best Classification-F1: 0.14899404541730882 -> 0.28456735180545945 on epoch=10, global_step=150
06/16/2022 23:35:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.79 on epoch=11
06/16/2022 23:35:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=12
06/16/2022 23:35:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=12
06/16/2022 23:35:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=13
06/16/2022 23:35:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=14
06/16/2022 23:35:56 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.5814562400391894 on epoch=14
06/16/2022 23:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.28456735180545945 -> 0.5814562400391894 on epoch=14, global_step=200
06/16/2022 23:35:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=14
06/16/2022 23:36:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=15
06/16/2022 23:36:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
06/16/2022 23:36:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=17
06/16/2022 23:36:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=17
06/16/2022 23:36:18 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.5826280292771806 on epoch=17
06/16/2022 23:36:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5814562400391894 -> 0.5826280292771806 on epoch=17, global_step=250
06/16/2022 23:36:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=18
06/16/2022 23:36:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=19
06/16/2022 23:36:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=19
06/16/2022 23:36:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=20
06/16/2022 23:36:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.19 on epoch=21
06/16/2022 23:36:40 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.6251367690528442 on epoch=21
06/16/2022 23:36:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5826280292771806 -> 0.6251367690528442 on epoch=21, global_step=300
06/16/2022 23:36:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=22
06/16/2022 23:36:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=22
06/16/2022 23:36:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.18 on epoch=23
06/16/2022 23:36:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=24
06/16/2022 23:36:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=24
06/16/2022 23:37:02 - INFO - __main__ - Global step 350 Train loss 0.20 Classification-F1 0.6675502201258334 on epoch=24
06/16/2022 23:37:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6251367690528442 -> 0.6675502201258334 on epoch=24, global_step=350
06/16/2022 23:37:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=25
06/16/2022 23:37:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=26
06/16/2022 23:37:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=27
06/16/2022 23:37:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=27
06/16/2022 23:37:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=28
06/16/2022 23:37:25 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.7743252369661568 on epoch=28
06/16/2022 23:37:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6675502201258334 -> 0.7743252369661568 on epoch=28, global_step=400
06/16/2022 23:37:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
06/16/2022 23:37:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=29
06/16/2022 23:37:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=30
06/16/2022 23:37:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=31
06/16/2022 23:37:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=32
06/16/2022 23:37:47 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.7474704541764347 on epoch=32
06/16/2022 23:37:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=32
06/16/2022 23:37:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
06/16/2022 23:37:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
06/16/2022 23:37:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
06/16/2022 23:38:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=35
06/16/2022 23:38:09 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.8909522645812967 on epoch=35
06/16/2022 23:38:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7743252369661568 -> 0.8909522645812967 on epoch=35, global_step=500
06/16/2022 23:38:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.06 on epoch=36
06/16/2022 23:38:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=37
06/16/2022 23:38:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
06/16/2022 23:38:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=38
06/16/2022 23:38:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=39
06/16/2022 23:38:31 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.7895128720026434 on epoch=39
06/16/2022 23:38:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=39
06/16/2022 23:38:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
06/16/2022 23:38:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
06/16/2022 23:38:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=42
06/16/2022 23:38:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=42
06/16/2022 23:38:53 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.8107464239733084 on epoch=42
06/16/2022 23:38:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=43
06/16/2022 23:38:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=44
06/16/2022 23:39:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=44
06/16/2022 23:39:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=45
06/16/2022 23:39:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=46
06/16/2022 23:39:15 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.8444366517273812 on epoch=46
06/16/2022 23:39:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
06/16/2022 23:39:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=47
06/16/2022 23:39:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=48
06/16/2022 23:39:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=49
06/16/2022 23:39:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
06/16/2022 23:39:37 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.7817925864974008 on epoch=49
06/16/2022 23:39:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=50
06/16/2022 23:39:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=51
06/16/2022 23:39:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
06/16/2022 23:39:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
06/16/2022 23:39:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
06/16/2022 23:39:59 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.8385678844611462 on epoch=53
06/16/2022 23:40:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=54
06/16/2022 23:40:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
06/16/2022 23:40:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=55
06/16/2022 23:40:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=56
06/16/2022 23:40:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=57
06/16/2022 23:40:21 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.835246298838914 on epoch=57
06/16/2022 23:40:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=57
06/16/2022 23:40:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=58
06/16/2022 23:40:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
06/16/2022 23:40:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=59
06/16/2022 23:40:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/16/2022 23:40:42 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.8277615807043419 on epoch=60
06/16/2022 23:40:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=61
06/16/2022 23:40:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/16/2022 23:40:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=62
06/16/2022 23:40:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
06/16/2022 23:40:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
06/16/2022 23:41:04 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.7264909928702215 on epoch=64
06/16/2022 23:41:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/16/2022 23:41:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
06/16/2022 23:41:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
06/16/2022 23:41:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=67
06/16/2022 23:41:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
06/16/2022 23:41:26 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7799113794691349 on epoch=67
06/16/2022 23:41:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
06/16/2022 23:41:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=69
06/16/2022 23:41:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
06/16/2022 23:41:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
06/16/2022 23:41:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/16/2022 23:41:47 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7080692776426254 on epoch=71
06/16/2022 23:41:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=72
06/16/2022 23:41:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/16/2022 23:41:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
06/16/2022 23:41:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=74
06/16/2022 23:42:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
06/16/2022 23:42:09 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.8961354550396841 on epoch=74
06/16/2022 23:42:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8909522645812967 -> 0.8961354550396841 on epoch=74, global_step=1050
06/16/2022 23:42:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/16/2022 23:42:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
06/16/2022 23:42:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
06/16/2022 23:42:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/16/2022 23:42:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=78
06/16/2022 23:42:31 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.727337965697172 on epoch=78
06/16/2022 23:42:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
06/16/2022 23:42:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
06/16/2022 23:42:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/16/2022 23:42:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
06/16/2022 23:42:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
06/16/2022 23:42:53 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7964415839262843 on epoch=82
06/16/2022 23:42:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/16/2022 23:42:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=83
06/16/2022 23:43:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
06/16/2022 23:43:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/16/2022 23:43:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/16/2022 23:43:15 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.9056929581756187 on epoch=85
06/16/2022 23:43:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8961354550396841 -> 0.9056929581756187 on epoch=85, global_step=1200
06/16/2022 23:43:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
06/16/2022 23:43:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
06/16/2022 23:43:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
06/16/2022 23:43:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
06/16/2022 23:43:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/16/2022 23:43:36 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.897481072585437 on epoch=89
06/16/2022 23:43:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/16/2022 23:43:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
06/16/2022 23:43:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
06/16/2022 23:43:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/16/2022 23:43:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/16/2022 23:43:58 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.8357269961276046 on epoch=92
06/16/2022 23:44:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
06/16/2022 23:44:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
06/16/2022 23:44:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/16/2022 23:44:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/16/2022 23:44:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
06/16/2022 23:44:20 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8295709590654443 on epoch=96
06/16/2022 23:44:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
06/16/2022 23:44:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
06/16/2022 23:44:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/16/2022 23:44:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
06/16/2022 23:44:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/16/2022 23:44:42 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8435736802761745 on epoch=99
06/16/2022 23:44:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/16/2022 23:44:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
06/16/2022 23:44:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/16/2022 23:44:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
06/16/2022 23:44:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/16/2022 23:45:03 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7910532081171027 on epoch=103
06/16/2022 23:45:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/16/2022 23:45:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/16/2022 23:45:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/16/2022 23:45:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/16/2022 23:45:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/16/2022 23:45:25 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7340198211901248 on epoch=107
06/16/2022 23:45:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=107
06/16/2022 23:45:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/16/2022 23:45:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/16/2022 23:45:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=109
06/16/2022 23:45:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=110
06/16/2022 23:45:47 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6970914736130386 on epoch=110
06/16/2022 23:45:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/16/2022 23:45:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/16/2022 23:45:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/16/2022 23:45:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/16/2022 23:46:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/16/2022 23:46:09 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7778589197065512 on epoch=114
06/16/2022 23:46:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/16/2022 23:46:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/16/2022 23:46:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/16/2022 23:46:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/16/2022 23:46:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/16/2022 23:46:31 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7741651142561323 on epoch=117
06/16/2022 23:46:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/16/2022 23:46:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/16/2022 23:46:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/16/2022 23:46:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/16/2022 23:46:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/16/2022 23:46:52 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7373964080581727 on epoch=121
06/16/2022 23:46:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/16/2022 23:46:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/16/2022 23:47:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=123
06/16/2022 23:47:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/16/2022 23:47:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
06/16/2022 23:47:15 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8510302113880743 on epoch=124
06/16/2022 23:47:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/16/2022 23:47:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/16/2022 23:47:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
06/16/2022 23:47:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/16/2022 23:47:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/16/2022 23:47:37 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9053134515342525 on epoch=128
06/16/2022 23:47:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/16/2022 23:47:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/16/2022 23:47:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=130
06/16/2022 23:47:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/16/2022 23:47:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/16/2022 23:47:59 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9016804189906656 on epoch=132
06/16/2022 23:48:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/16/2022 23:48:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/16/2022 23:48:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/16/2022 23:48:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/16/2022 23:48:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/16/2022 23:48:21 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.850842860655234 on epoch=135
06/16/2022 23:48:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
06/16/2022 23:48:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/16/2022 23:48:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/16/2022 23:48:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/16/2022 23:48:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=139
06/16/2022 23:48:42 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7901451324685427 on epoch=139
06/16/2022 23:48:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/16/2022 23:48:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/16/2022 23:48:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
06/16/2022 23:48:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/16/2022 23:48:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
06/16/2022 23:49:04 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7851070061068868 on epoch=142
06/16/2022 23:49:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/16/2022 23:49:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
06/16/2022 23:49:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
06/16/2022 23:49:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
06/16/2022 23:49:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
06/16/2022 23:49:26 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.8405864503988236 on epoch=146
06/16/2022 23:49:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/16/2022 23:49:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
06/16/2022 23:49:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
06/16/2022 23:49:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/16/2022 23:49:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
06/16/2022 23:49:48 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9035178867785358 on epoch=149
06/16/2022 23:49:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/16/2022 23:49:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/16/2022 23:49:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/16/2022 23:50:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/16/2022 23:50:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/16/2022 23:50:09 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9056929581756187 on epoch=153
06/16/2022 23:50:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/16/2022 23:50:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/16/2022 23:50:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/16/2022 23:50:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/16/2022 23:50:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/16/2022 23:50:31 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9016451269219049 on epoch=157
06/16/2022 23:50:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/16/2022 23:50:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/16/2022 23:50:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/16/2022 23:50:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/16/2022 23:50:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
06/16/2022 23:50:53 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9726894597964577 on epoch=160
06/16/2022 23:50:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9056929581756187 -> 0.9726894597964577 on epoch=160, global_step=2250
06/16/2022 23:50:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/16/2022 23:50:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/16/2022 23:51:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/16/2022 23:51:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/16/2022 23:51:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/16/2022 23:51:15 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9728167834531932 on epoch=164
06/16/2022 23:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9726894597964577 -> 0.9728167834531932 on epoch=164, global_step=2300
06/16/2022 23:51:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/16/2022 23:51:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
06/16/2022 23:51:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/16/2022 23:51:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/16/2022 23:51:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/16/2022 23:51:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9728167834531932 on epoch=167
06/16/2022 23:51:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/16/2022 23:51:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/16/2022 23:51:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/16/2022 23:51:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/16/2022 23:51:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/16/2022 23:51:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9683524977389075 on epoch=171
06/16/2022 23:52:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/16/2022 23:52:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/16/2022 23:52:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/16/2022 23:52:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/16/2022 23:52:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/16/2022 23:52:21 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9771537455107435 on epoch=174
06/16/2022 23:52:21 - INFO - __main__ - Saving model with best Classification-F1: 0.9728167834531932 -> 0.9771537455107435 on epoch=174, global_step=2450
06/16/2022 23:52:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/16/2022 23:52:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/16/2022 23:52:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/16/2022 23:52:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/16/2022 23:52:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/16/2022 23:52:43 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.9726894597964577 on epoch=178
06/16/2022 23:52:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/16/2022 23:52:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/16/2022 23:52:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/16/2022 23:52:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/16/2022 23:52:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/16/2022 23:53:05 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.9016451269219049 on epoch=182
06/16/2022 23:53:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/16/2022 23:53:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/16/2022 23:53:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/16/2022 23:53:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/16/2022 23:53:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/16/2022 23:53:27 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8993512201118693 on epoch=185
06/16/2022 23:53:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/16/2022 23:53:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/16/2022 23:53:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/16/2022 23:53:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/16/2022 23:53:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/16/2022 23:53:49 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.9728167834531932 on epoch=189
06/16/2022 23:53:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/16/2022 23:53:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/16/2022 23:53:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/16/2022 23:54:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/16/2022 23:54:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/16/2022 23:54:11 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.9726894597964577 on epoch=192
06/16/2022 23:54:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/16/2022 23:54:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/16/2022 23:54:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/16/2022 23:54:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/16/2022 23:54:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/16/2022 23:54:33 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9098596248422853 on epoch=196
06/16/2022 23:54:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/16/2022 23:54:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/16/2022 23:54:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/16/2022 23:54:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/16/2022 23:54:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/16/2022 23:54:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9685918676804324 on epoch=199
06/16/2022 23:54:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/16/2022 23:55:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/16/2022 23:55:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/16/2022 23:55:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/16/2022 23:55:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/16/2022 23:55:17 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9771537455107435 on epoch=203
06/16/2022 23:55:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/16/2022 23:55:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/16/2022 23:55:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/16/2022 23:55:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/16/2022 23:55:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/16/2022 23:55:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9683524977389075 on epoch=207
06/16/2022 23:55:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/16/2022 23:55:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/16/2022 23:55:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/16/2022 23:55:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/16/2022 23:55:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/16/2022 23:56:00 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9016451269219049 on epoch=210
06/16/2022 23:56:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/16/2022 23:56:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/16/2022 23:56:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/16/2022 23:56:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/16/2022 23:56:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/16/2022 23:56:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:56:17 - INFO - __main__ - Printing 3 examples
06/16/2022 23:56:17 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 23:56:17 - INFO - __main__ - ['Animal']
06/16/2022 23:56:17 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 23:56:17 - INFO - __main__ - ['Animal']
06/16/2022 23:56:17 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 23:56:17 - INFO - __main__ - ['Animal']
06/16/2022 23:56:17 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:56:17 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:56:17 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 23:56:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:56:17 - INFO - __main__ - Printing 3 examples
06/16/2022 23:56:17 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/16/2022 23:56:17 - INFO - __main__ - ['Animal']
06/16/2022 23:56:17 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/16/2022 23:56:17 - INFO - __main__ - ['Animal']
06/16/2022 23:56:17 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/16/2022 23:56:17 - INFO - __main__ - ['Animal']
06/16/2022 23:56:17 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:56:18 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:56:18 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 23:56:22 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9017598893469142 on epoch=214
06/16/2022 23:56:22 - INFO - __main__ - save last model!
06/16/2022 23:56:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/16/2022 23:56:22 - INFO - __main__ - Start tokenizing ... 3500 instances
06/16/2022 23:56:22 - INFO - __main__ - Printing 3 examples
06/16/2022 23:56:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/16/2022 23:56:22 - INFO - __main__ - ['Animal']
06/16/2022 23:56:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/16/2022 23:56:22 - INFO - __main__ - ['Animal']
06/16/2022 23:56:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/16/2022 23:56:22 - INFO - __main__ - ['Village']
06/16/2022 23:56:22 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:56:24 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:56:27 - INFO - __main__ - Loaded 3500 examples from test data
06/16/2022 23:56:36 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:56:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 23:56:37 - INFO - __main__ - Starting training!
06/16/2022 23:58:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/16/2022 23:58:46 - INFO - __main__ - Classification-F1 on test data: 0.6537
06/16/2022 23:58:46 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9771537455107435, test_performance=0.6536841173808219
06/16/2022 23:58:46 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/16/2022 23:58:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:58:47 - INFO - __main__ - Printing 3 examples
06/16/2022 23:58:47 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/16/2022 23:58:47 - INFO - __main__ - ['Animal']
06/16/2022 23:58:47 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/16/2022 23:58:47 - INFO - __main__ - ['Animal']
06/16/2022 23:58:47 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/16/2022 23:58:47 - INFO - __main__ - ['Animal']
06/16/2022 23:58:47 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:58:47 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:58:48 - INFO - __main__ - Loaded 224 examples from train data
06/16/2022 23:58:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/16/2022 23:58:48 - INFO - __main__ - Printing 3 examples
06/16/2022 23:58:48 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/16/2022 23:58:48 - INFO - __main__ - ['Animal']
06/16/2022 23:58:48 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/16/2022 23:58:48 - INFO - __main__ - ['Animal']
06/16/2022 23:58:48 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/16/2022 23:58:48 - INFO - __main__ - ['Animal']
06/16/2022 23:58:48 - INFO - __main__ - Tokenizing Input ...
06/16/2022 23:58:48 - INFO - __main__ - Tokenizing Output ...
06/16/2022 23:58:48 - INFO - __main__ - Loaded 224 examples from dev data
06/16/2022 23:59:07 - INFO - __main__ - load prompt embedding from ckpt
06/16/2022 23:59:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/16/2022 23:59:07 - INFO - __main__ - Starting training!
06/16/2022 23:59:11 - INFO - __main__ - Step 10 Global step 10 Train loss 6.83 on epoch=0
06/16/2022 23:59:14 - INFO - __main__ - Step 20 Global step 20 Train loss 4.93 on epoch=1
06/16/2022 23:59:17 - INFO - __main__ - Step 30 Global step 30 Train loss 3.98 on epoch=2
06/16/2022 23:59:21 - INFO - __main__ - Step 40 Global step 40 Train loss 3.51 on epoch=2
06/16/2022 23:59:24 - INFO - __main__ - Step 50 Global step 50 Train loss 3.15 on epoch=3
06/16/2022 23:59:29 - INFO - __main__ - Global step 50 Train loss 4.48 Classification-F1 0.05752914373707343 on epoch=3
06/16/2022 23:59:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05752914373707343 on epoch=3, global_step=50
06/16/2022 23:59:32 - INFO - __main__ - Step 60 Global step 60 Train loss 2.89 on epoch=4
06/16/2022 23:59:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.50 on epoch=4
06/16/2022 23:59:38 - INFO - __main__ - Step 80 Global step 80 Train loss 2.28 on epoch=5
06/16/2022 23:59:41 - INFO - __main__ - Step 90 Global step 90 Train loss 2.08 on epoch=6
06/16/2022 23:59:44 - INFO - __main__ - Step 100 Global step 100 Train loss 2.04 on epoch=7
06/16/2022 23:59:49 - INFO - __main__ - Global step 100 Train loss 2.36 Classification-F1 0.12877395219006443 on epoch=7
06/16/2022 23:59:49 - INFO - __main__ - Saving model with best Classification-F1: 0.05752914373707343 -> 0.12877395219006443 on epoch=7, global_step=100
06/16/2022 23:59:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.81 on epoch=7
06/16/2022 23:59:55 - INFO - __main__ - Step 120 Global step 120 Train loss 1.72 on epoch=8
06/16/2022 23:59:58 - INFO - __main__ - Step 130 Global step 130 Train loss 1.47 on epoch=9
06/17/2022 00:00:02 - INFO - __main__ - Step 140 Global step 140 Train loss 1.37 on epoch=9
06/17/2022 00:00:05 - INFO - __main__ - Step 150 Global step 150 Train loss 1.22 on epoch=10
06/17/2022 00:00:11 - INFO - __main__ - Global step 150 Train loss 1.52 Classification-F1 0.17003482363825984 on epoch=10
06/17/2022 00:00:11 - INFO - __main__ - Saving model with best Classification-F1: 0.12877395219006443 -> 0.17003482363825984 on epoch=10, global_step=150
06/17/2022 00:00:14 - INFO - __main__ - Step 160 Global step 160 Train loss 1.00 on epoch=11
06/17/2022 00:00:17 - INFO - __main__ - Step 170 Global step 170 Train loss 1.07 on epoch=12
06/17/2022 00:00:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.94 on epoch=12
06/17/2022 00:00:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=13
06/17/2022 00:00:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=14
06/17/2022 00:00:33 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.30381658444211607 on epoch=14
06/17/2022 00:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.17003482363825984 -> 0.30381658444211607 on epoch=14, global_step=200
06/17/2022 00:00:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=14
06/17/2022 00:00:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=15
06/17/2022 00:00:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=16
06/17/2022 00:00:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=17
06/17/2022 00:00:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=17
06/17/2022 00:00:55 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.46087847192378134 on epoch=17
06/17/2022 00:00:55 - INFO - __main__ - Saving model with best Classification-F1: 0.30381658444211607 -> 0.46087847192378134 on epoch=17, global_step=250
06/17/2022 00:00:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=18
06/17/2022 00:01:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
06/17/2022 00:01:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=19
06/17/2022 00:01:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
06/17/2022 00:01:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=21
06/17/2022 00:01:18 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.5335955305525092 on epoch=21
06/17/2022 00:01:18 - INFO - __main__ - Saving model with best Classification-F1: 0.46087847192378134 -> 0.5335955305525092 on epoch=21, global_step=300
06/17/2022 00:01:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=22
06/17/2022 00:01:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=22
06/17/2022 00:01:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/17/2022 00:01:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
06/17/2022 00:01:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=24
06/17/2022 00:01:40 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.5075703235975612 on epoch=24
06/17/2022 00:01:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
06/17/2022 00:01:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=26
06/17/2022 00:01:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=27
06/17/2022 00:01:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=27
06/17/2022 00:01:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=28
06/17/2022 00:02:03 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5873994704364424 on epoch=28
06/17/2022 00:02:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5335955305525092 -> 0.5873994704364424 on epoch=28, global_step=400
06/17/2022 00:02:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=29
06/17/2022 00:02:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=29
06/17/2022 00:02:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
06/17/2022 00:02:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
06/17/2022 00:02:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=32
06/17/2022 00:02:26 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.5745449907894217 on epoch=32
06/17/2022 00:02:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
06/17/2022 00:02:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
06/17/2022 00:02:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
06/17/2022 00:02:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
06/17/2022 00:02:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=35
06/17/2022 00:02:49 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6449240798007402 on epoch=35
06/17/2022 00:02:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5873994704364424 -> 0.6449240798007402 on epoch=35, global_step=500
06/17/2022 00:02:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=36
06/17/2022 00:02:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
06/17/2022 00:02:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=37
06/17/2022 00:03:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=38
06/17/2022 00:03:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
06/17/2022 00:03:12 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6760257086745582 on epoch=39
06/17/2022 00:03:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6449240798007402 -> 0.6760257086745582 on epoch=39, global_step=550
06/17/2022 00:03:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
06/17/2022 00:03:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
06/17/2022 00:03:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
06/17/2022 00:03:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
06/17/2022 00:03:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/17/2022 00:03:35 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.8404374799773282 on epoch=42
06/17/2022 00:03:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6760257086745582 -> 0.8404374799773282 on epoch=42, global_step=600
06/17/2022 00:03:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
06/17/2022 00:03:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=44
06/17/2022 00:03:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
06/17/2022 00:03:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=45
06/17/2022 00:03:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/17/2022 00:03:57 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.6293599178640681 on epoch=46
06/17/2022 00:04:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
06/17/2022 00:04:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
06/17/2022 00:04:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
06/17/2022 00:04:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=49
06/17/2022 00:04:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=49
06/17/2022 00:04:20 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7331801021607506 on epoch=49
06/17/2022 00:04:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
06/17/2022 00:04:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
06/17/2022 00:04:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/17/2022 00:04:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
06/17/2022 00:04:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/17/2022 00:04:42 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7795879273067018 on epoch=53
06/17/2022 00:04:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
06/17/2022 00:04:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
06/17/2022 00:04:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
06/17/2022 00:04:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=56
06/17/2022 00:04:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
06/17/2022 00:05:04 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7349083097357324 on epoch=57
06/17/2022 00:05:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
06/17/2022 00:05:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
06/17/2022 00:05:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
06/17/2022 00:05:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/17/2022 00:05:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/17/2022 00:05:27 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.9728685609141018 on epoch=60
06/17/2022 00:05:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8404374799773282 -> 0.9728685609141018 on epoch=60, global_step=850
06/17/2022 00:05:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
06/17/2022 00:05:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
06/17/2022 00:05:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/17/2022 00:05:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
06/17/2022 00:05:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
06/17/2022 00:05:49 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.9730169340463457 on epoch=64
06/17/2022 00:05:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9728685609141018 -> 0.9730169340463457 on epoch=64, global_step=900
06/17/2022 00:05:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=64
06/17/2022 00:05:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/17/2022 00:05:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=66
06/17/2022 00:06:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/17/2022 00:06:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/17/2022 00:06:11 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.889494801493591 on epoch=67
06/17/2022 00:06:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
06/17/2022 00:06:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/17/2022 00:06:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/17/2022 00:06:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/17/2022 00:06:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/17/2022 00:06:33 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8393622906046331 on epoch=71
06/17/2022 00:06:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/17/2022 00:06:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/17/2022 00:06:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
06/17/2022 00:06:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/17/2022 00:06:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
06/17/2022 00:06:56 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.954583449063719 on epoch=74
06/17/2022 00:06:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
06/17/2022 00:07:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/17/2022 00:07:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/17/2022 00:07:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/17/2022 00:07:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/17/2022 00:07:18 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9638671625491132 on epoch=78
06/17/2022 00:07:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/17/2022 00:07:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/17/2022 00:07:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/17/2022 00:07:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/17/2022 00:07:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/17/2022 00:07:40 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.9597862559929423 on epoch=82
06/17/2022 00:07:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/17/2022 00:07:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/17/2022 00:07:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
06/17/2022 00:07:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/17/2022 00:07:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/17/2022 00:08:02 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7819362363327015 on epoch=85
06/17/2022 00:08:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/17/2022 00:08:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
06/17/2022 00:08:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
06/17/2022 00:08:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/17/2022 00:08:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
06/17/2022 00:08:24 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.897458814078097 on epoch=89
06/17/2022 00:08:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/17/2022 00:08:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 00:08:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/17/2022 00:08:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/17/2022 00:08:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/17/2022 00:08:46 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7841298899328102 on epoch=92
06/17/2022 00:08:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/17/2022 00:08:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/17/2022 00:08:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 00:08:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/17/2022 00:09:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/17/2022 00:09:08 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.897458814078097 on epoch=96
06/17/2022 00:09:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/17/2022 00:09:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 00:09:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/17/2022 00:09:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 00:09:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/17/2022 00:09:31 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9682041246066635 on epoch=99
06/17/2022 00:09:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/17/2022 00:09:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/17/2022 00:09:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/17/2022 00:09:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
06/17/2022 00:09:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/17/2022 00:09:53 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8935155593568536 on epoch=103
06/17/2022 00:09:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 00:09:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/17/2022 00:10:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/17/2022 00:10:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 00:10:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/17/2022 00:10:14 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9685315988565514 on epoch=107
06/17/2022 00:10:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/17/2022 00:10:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/17/2022 00:10:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
06/17/2022 00:10:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/17/2022 00:10:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/17/2022 00:10:36 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9684182397299096 on epoch=110
06/17/2022 00:10:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/17/2022 00:10:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/17/2022 00:10:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/17/2022 00:10:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/17/2022 00:10:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/17/2022 00:10:57 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9018122879650394 on epoch=114
06/17/2022 00:11:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/17/2022 00:11:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/17/2022 00:11:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/17/2022 00:11:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/17/2022 00:11:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/17/2022 00:11:18 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9730125701306915 on epoch=117
06/17/2022 00:11:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/17/2022 00:11:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/17/2022 00:11:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/17/2022 00:11:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 00:11:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/17/2022 00:11:40 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9056929581756187 on epoch=121
06/17/2022 00:11:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 00:11:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/17/2022 00:11:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 00:11:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/17/2022 00:11:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 00:12:01 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9728685609141018 on epoch=124
06/17/2022 00:12:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 00:12:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/17/2022 00:12:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 00:12:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/17/2022 00:12:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 00:12:22 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9774908203750707 on epoch=128
06/17/2022 00:12:22 - INFO - __main__ - Saving model with best Classification-F1: 0.9730169340463457 -> 0.9774908203750707 on epoch=128, global_step=1800
06/17/2022 00:12:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/17/2022 00:12:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 00:12:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 00:12:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/17/2022 00:12:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/17/2022 00:12:44 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9728685609141018 on epoch=132
06/17/2022 00:12:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/17/2022 00:12:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/17/2022 00:12:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/17/2022 00:12:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/17/2022 00:12:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 00:13:05 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.973112294771281 on epoch=135
06/17/2022 00:13:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
06/17/2022 00:13:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/17/2022 00:13:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 00:13:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 00:13:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 00:13:26 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9726894597964577 on epoch=139
06/17/2022 00:13:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/17/2022 00:13:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 00:13:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/17/2022 00:13:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/17/2022 00:13:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/17/2022 00:13:48 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9728685609141018 on epoch=142
06/17/2022 00:13:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
06/17/2022 00:13:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/17/2022 00:13:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
06/17/2022 00:13:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/17/2022 00:14:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 00:14:09 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9728685609141018 on epoch=146
06/17/2022 00:14:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 00:14:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 00:14:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/17/2022 00:14:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/17/2022 00:14:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 00:14:30 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9728685609141018 on epoch=149
06/17/2022 00:14:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/17/2022 00:14:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/17/2022 00:14:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 00:14:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/17/2022 00:14:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 00:14:52 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9728685609141018 on epoch=153
06/17/2022 00:14:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/17/2022 00:14:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/17/2022 00:15:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 00:15:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 00:15:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 00:15:13 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9728685609141018 on epoch=157
06/17/2022 00:15:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/17/2022 00:15:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/17/2022 00:15:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 00:15:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/17/2022 00:15:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/17/2022 00:15:35 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8995183811550035 on epoch=160
06/17/2022 00:15:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/17/2022 00:15:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/17/2022 00:15:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 00:15:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 00:15:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 00:15:57 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9685315988565514 on epoch=164
06/17/2022 00:16:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 00:16:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 00:16:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/17/2022 00:16:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 00:16:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 00:16:18 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9728685609141018 on epoch=167
06/17/2022 00:16:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 00:16:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 00:16:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/17/2022 00:16:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 00:16:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 00:16:40 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9016451269219049 on epoch=171
06/17/2022 00:16:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/17/2022 00:16:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 00:16:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/17/2022 00:16:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/17/2022 00:16:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/17/2022 00:17:01 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9059986008088475 on epoch=174
06/17/2022 00:17:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 00:17:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/17/2022 00:17:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/17/2022 00:17:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/17/2022 00:17:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/17/2022 00:17:23 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9773538961038961 on epoch=178
06/17/2022 00:17:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/17/2022 00:17:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/17/2022 00:17:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/17/2022 00:17:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 00:17:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 00:17:44 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9773538961038961 on epoch=182
06/17/2022 00:17:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/17/2022 00:17:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 00:17:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/17/2022 00:17:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 00:17:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/17/2022 00:18:06 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9773538961038961 on epoch=185
06/17/2022 00:18:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/17/2022 00:18:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/17/2022 00:18:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 00:18:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/17/2022 00:18:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 00:18:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9059986008088475 on epoch=189
06/17/2022 00:18:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/17/2022 00:18:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/17/2022 00:18:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 00:18:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 00:18:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/17/2022 00:18:49 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9060026737967914 on epoch=192
06/17/2022 00:18:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/17/2022 00:18:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 00:18:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/17/2022 00:19:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/17/2022 00:19:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/17/2022 00:19:10 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9773538961038961 on epoch=196
06/17/2022 00:19:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/17/2022 00:19:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 00:19:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/17/2022 00:19:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/17/2022 00:19:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 00:19:32 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9686480090569953 on epoch=199
06/17/2022 00:19:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/17/2022 00:19:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/17/2022 00:19:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/17/2022 00:19:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 00:19:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 00:19:54 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9730169340463457 on epoch=203
06/17/2022 00:19:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 00:19:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/17/2022 00:20:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 00:20:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 00:20:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 00:20:15 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9730169340463457 on epoch=207
06/17/2022 00:20:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/17/2022 00:20:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/17/2022 00:20:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 00:20:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 00:20:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/17/2022 00:20:36 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9773538961038961 on epoch=210
06/17/2022 00:20:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 00:20:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 00:20:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/17/2022 00:20:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 00:20:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 00:20:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:20:53 - INFO - __main__ - Printing 3 examples
06/17/2022 00:20:53 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 00:20:53 - INFO - __main__ - ['Animal']
06/17/2022 00:20:53 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 00:20:53 - INFO - __main__ - ['Animal']
06/17/2022 00:20:53 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/17/2022 00:20:53 - INFO - __main__ - ['Animal']
06/17/2022 00:20:53 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:20:53 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:20:53 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 00:20:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:20:53 - INFO - __main__ - Printing 3 examples
06/17/2022 00:20:53 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 00:20:53 - INFO - __main__ - ['Animal']
06/17/2022 00:20:53 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 00:20:53 - INFO - __main__ - ['Animal']
06/17/2022 00:20:53 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 00:20:53 - INFO - __main__ - ['Animal']
06/17/2022 00:20:53 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:20:53 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:20:53 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 00:20:58 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9773538961038961 on epoch=214
06/17/2022 00:20:58 - INFO - __main__ - save last model!
06/17/2022 00:20:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 00:20:59 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 00:20:59 - INFO - __main__ - Printing 3 examples
06/17/2022 00:20:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 00:20:59 - INFO - __main__ - ['Animal']
06/17/2022 00:20:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 00:20:59 - INFO - __main__ - ['Animal']
06/17/2022 00:20:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 00:20:59 - INFO - __main__ - ['Village']
06/17/2022 00:20:59 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:21:01 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:21:04 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 00:21:12 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 00:21:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 00:21:13 - INFO - __main__ - Starting training!
06/17/2022 00:23:27 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/17/2022 00:23:27 - INFO - __main__ - Classification-F1 on test data: 0.6833
06/17/2022 00:23:27 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9774908203750707, test_performance=0.6832900358244632
06/17/2022 00:23:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/17/2022 00:23:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:23:28 - INFO - __main__ - Printing 3 examples
06/17/2022 00:23:28 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 00:23:28 - INFO - __main__ - ['Animal']
06/17/2022 00:23:28 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 00:23:28 - INFO - __main__ - ['Animal']
06/17/2022 00:23:28 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/17/2022 00:23:28 - INFO - __main__ - ['Animal']
06/17/2022 00:23:28 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:23:28 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:23:28 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 00:23:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:23:28 - INFO - __main__ - Printing 3 examples
06/17/2022 00:23:28 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 00:23:28 - INFO - __main__ - ['Animal']
06/17/2022 00:23:28 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 00:23:28 - INFO - __main__ - ['Animal']
06/17/2022 00:23:28 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 00:23:28 - INFO - __main__ - ['Animal']
06/17/2022 00:23:28 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:23:28 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:23:28 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 00:23:47 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 00:23:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 00:23:48 - INFO - __main__ - Starting training!
06/17/2022 00:23:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.82 on epoch=0
06/17/2022 00:23:55 - INFO - __main__ - Step 20 Global step 20 Train loss 4.95 on epoch=1
06/17/2022 00:23:58 - INFO - __main__ - Step 30 Global step 30 Train loss 4.44 on epoch=2
06/17/2022 00:24:01 - INFO - __main__ - Step 40 Global step 40 Train loss 3.62 on epoch=2
06/17/2022 00:24:04 - INFO - __main__ - Step 50 Global step 50 Train loss 3.55 on epoch=3
06/17/2022 00:24:09 - INFO - __main__ - Global step 50 Train loss 4.68 Classification-F1 0.04902546442710895 on epoch=3
06/17/2022 00:24:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04902546442710895 on epoch=3, global_step=50
06/17/2022 00:24:12 - INFO - __main__ - Step 60 Global step 60 Train loss 3.29 on epoch=4
06/17/2022 00:24:15 - INFO - __main__ - Step 70 Global step 70 Train loss 2.75 on epoch=4
06/17/2022 00:24:18 - INFO - __main__ - Step 80 Global step 80 Train loss 2.56 on epoch=5
06/17/2022 00:24:21 - INFO - __main__ - Step 90 Global step 90 Train loss 2.45 on epoch=6
06/17/2022 00:24:24 - INFO - __main__ - Step 100 Global step 100 Train loss 2.41 on epoch=7
06/17/2022 00:24:29 - INFO - __main__ - Global step 100 Train loss 2.69 Classification-F1 0.09052984769113802 on epoch=7
06/17/2022 00:24:29 - INFO - __main__ - Saving model with best Classification-F1: 0.04902546442710895 -> 0.09052984769113802 on epoch=7, global_step=100
06/17/2022 00:24:32 - INFO - __main__ - Step 110 Global step 110 Train loss 2.05 on epoch=7
06/17/2022 00:24:35 - INFO - __main__ - Step 120 Global step 120 Train loss 1.98 on epoch=8
06/17/2022 00:24:38 - INFO - __main__ - Step 130 Global step 130 Train loss 1.97 on epoch=9
06/17/2022 00:24:41 - INFO - __main__ - Step 140 Global step 140 Train loss 1.74 on epoch=9
06/17/2022 00:24:44 - INFO - __main__ - Step 150 Global step 150 Train loss 1.72 on epoch=10
06/17/2022 00:24:49 - INFO - __main__ - Global step 150 Train loss 1.89 Classification-F1 0.1307411255475389 on epoch=10
06/17/2022 00:24:49 - INFO - __main__ - Saving model with best Classification-F1: 0.09052984769113802 -> 0.1307411255475389 on epoch=10, global_step=150
06/17/2022 00:24:52 - INFO - __main__ - Step 160 Global step 160 Train loss 1.53 on epoch=11
06/17/2022 00:24:55 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=12
06/17/2022 00:24:58 - INFO - __main__ - Step 180 Global step 180 Train loss 1.32 on epoch=12
06/17/2022 00:25:01 - INFO - __main__ - Step 190 Global step 190 Train loss 1.26 on epoch=13
06/17/2022 00:25:04 - INFO - __main__ - Step 200 Global step 200 Train loss 1.18 on epoch=14
06/17/2022 00:25:11 - INFO - __main__ - Global step 200 Train loss 1.36 Classification-F1 0.21683781104600983 on epoch=14
06/17/2022 00:25:11 - INFO - __main__ - Saving model with best Classification-F1: 0.1307411255475389 -> 0.21683781104600983 on epoch=14, global_step=200
06/17/2022 00:25:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=14
06/17/2022 00:25:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.99 on epoch=15
06/17/2022 00:25:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.91 on epoch=16
06/17/2022 00:25:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.96 on epoch=17
06/17/2022 00:25:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.83 on epoch=17
06/17/2022 00:25:32 - INFO - __main__ - Global step 250 Train loss 0.94 Classification-F1 0.27480526161081714 on epoch=17
06/17/2022 00:25:32 - INFO - __main__ - Saving model with best Classification-F1: 0.21683781104600983 -> 0.27480526161081714 on epoch=17, global_step=250
06/17/2022 00:25:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.85 on epoch=18
06/17/2022 00:25:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=19
06/17/2022 00:25:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.74 on epoch=19
06/17/2022 00:25:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.60 on epoch=20
06/17/2022 00:25:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.54 on epoch=21
06/17/2022 00:25:54 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.4027630981548032 on epoch=21
06/17/2022 00:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.27480526161081714 -> 0.4027630981548032 on epoch=21, global_step=300
06/17/2022 00:25:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=22
06/17/2022 00:26:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=22
06/17/2022 00:26:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.47 on epoch=23
06/17/2022 00:26:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=24
06/17/2022 00:26:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=24
06/17/2022 00:26:16 - INFO - __main__ - Global step 350 Train loss 0.48 Classification-F1 0.5209309868279838 on epoch=24
06/17/2022 00:26:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4027630981548032 -> 0.5209309868279838 on epoch=24, global_step=350
06/17/2022 00:26:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=25
06/17/2022 00:26:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/17/2022 00:26:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=27
06/17/2022 00:26:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=27
06/17/2022 00:26:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=28
06/17/2022 00:26:38 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5976698278220586 on epoch=28
06/17/2022 00:26:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5209309868279838 -> 0.5976698278220586 on epoch=28, global_step=400
06/17/2022 00:26:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=29
06/17/2022 00:26:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=29
06/17/2022 00:26:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
06/17/2022 00:26:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
06/17/2022 00:26:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=32
06/17/2022 00:27:00 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.5052662809106856 on epoch=32
06/17/2022 00:27:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
06/17/2022 00:27:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/17/2022 00:27:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=34
06/17/2022 00:27:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=34
06/17/2022 00:27:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/17/2022 00:27:21 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.5511338964105853 on epoch=35
06/17/2022 00:27:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
06/17/2022 00:27:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=37
06/17/2022 00:27:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
06/17/2022 00:27:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=38
06/17/2022 00:27:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
06/17/2022 00:27:44 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.6903938579341805 on epoch=39
06/17/2022 00:27:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5976698278220586 -> 0.6903938579341805 on epoch=39, global_step=550
06/17/2022 00:27:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/17/2022 00:27:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
06/17/2022 00:27:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
06/17/2022 00:27:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/17/2022 00:27:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/17/2022 00:28:06 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.6004699359310779 on epoch=42
06/17/2022 00:28:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
06/17/2022 00:28:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=44
06/17/2022 00:28:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=44
06/17/2022 00:28:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/17/2022 00:28:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/17/2022 00:28:28 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.5557792838466403 on epoch=46
06/17/2022 00:28:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
06/17/2022 00:28:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
06/17/2022 00:28:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/17/2022 00:28:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/17/2022 00:28:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
06/17/2022 00:28:50 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7537861717267552 on epoch=49
06/17/2022 00:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6903938579341805 -> 0.7537861717267552 on epoch=49, global_step=700
06/17/2022 00:28:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
06/17/2022 00:28:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
06/17/2022 00:28:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/17/2022 00:29:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/17/2022 00:29:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
06/17/2022 00:29:12 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.5778439940261899 on epoch=53
06/17/2022 00:29:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/17/2022 00:29:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
06/17/2022 00:29:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
06/17/2022 00:29:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/17/2022 00:29:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/17/2022 00:29:34 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.5744044725328148 on epoch=57
06/17/2022 00:29:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/17/2022 00:29:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
06/17/2022 00:29:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/17/2022 00:29:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/17/2022 00:29:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/17/2022 00:29:56 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6946434931791469 on epoch=60
06/17/2022 00:29:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/17/2022 00:30:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/17/2022 00:30:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/17/2022 00:30:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=63
06/17/2022 00:30:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/17/2022 00:30:18 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.5518034953508512 on epoch=64
06/17/2022 00:30:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
06/17/2022 00:30:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/17/2022 00:30:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/17/2022 00:30:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/17/2022 00:30:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/17/2022 00:30:39 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.619460276236051 on epoch=67
06/17/2022 00:30:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=68
06/17/2022 00:30:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/17/2022 00:30:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/17/2022 00:30:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
06/17/2022 00:30:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/17/2022 00:31:01 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6524989386351276 on epoch=71
06/17/2022 00:31:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/17/2022 00:31:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/17/2022 00:31:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
06/17/2022 00:31:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=74
06/17/2022 00:31:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/17/2022 00:31:23 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6242911152730887 on epoch=74
06/17/2022 00:31:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/17/2022 00:31:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/17/2022 00:31:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/17/2022 00:31:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/17/2022 00:31:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
06/17/2022 00:31:44 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7886401923389869 on epoch=78
06/17/2022 00:31:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7537861717267552 -> 0.7886401923389869 on epoch=78, global_step=1100
06/17/2022 00:31:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/17/2022 00:31:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/17/2022 00:31:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
06/17/2022 00:31:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/17/2022 00:31:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/17/2022 00:32:06 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7381038689506432 on epoch=82
06/17/2022 00:32:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/17/2022 00:32:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/17/2022 00:32:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/17/2022 00:32:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/17/2022 00:32:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/17/2022 00:32:27 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8352369824396034 on epoch=85
06/17/2022 00:32:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7886401923389869 -> 0.8352369824396034 on epoch=85, global_step=1200
06/17/2022 00:32:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/17/2022 00:32:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/17/2022 00:32:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/17/2022 00:32:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/17/2022 00:32:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/17/2022 00:32:49 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6893368112795357 on epoch=89
06/17/2022 00:32:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/17/2022 00:32:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/17/2022 00:32:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/17/2022 00:33:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/17/2022 00:33:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/17/2022 00:33:10 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8353827677610127 on epoch=92
06/17/2022 00:33:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8352369824396034 -> 0.8353827677610127 on epoch=92, global_step=1300
06/17/2022 00:33:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/17/2022 00:33:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/17/2022 00:33:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 00:33:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/17/2022 00:33:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/17/2022 00:33:32 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8396634304381577 on epoch=96
06/17/2022 00:33:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8353827677610127 -> 0.8396634304381577 on epoch=96, global_step=1350
06/17/2022 00:33:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/17/2022 00:33:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 00:33:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/17/2022 00:33:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/17/2022 00:33:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/17/2022 00:33:54 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7862427996901711 on epoch=99
06/17/2022 00:33:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/17/2022 00:34:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/17/2022 00:34:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/17/2022 00:34:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/17/2022 00:34:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/17/2022 00:34:15 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9644739274008725 on epoch=103
06/17/2022 00:34:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8396634304381577 -> 0.9644739274008725 on epoch=103, global_step=1450
06/17/2022 00:34:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/17/2022 00:34:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/17/2022 00:34:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/17/2022 00:34:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/17/2022 00:34:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/17/2022 00:34:37 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8978331704138155 on epoch=107
06/17/2022 00:34:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/17/2022 00:34:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/17/2022 00:34:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/17/2022 00:34:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=109
06/17/2022 00:34:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/17/2022 00:34:58 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9554443184898593 on epoch=110
06/17/2022 00:35:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/17/2022 00:35:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/17/2022 00:35:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/17/2022 00:35:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/17/2022 00:35:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/17/2022 00:35:20 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9638671625491132 on epoch=114
06/17/2022 00:35:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/17/2022 00:35:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/17/2022 00:35:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/17/2022 00:35:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/17/2022 00:35:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/17/2022 00:35:42 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8932921474114303 on epoch=117
06/17/2022 00:35:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/17/2022 00:35:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/17/2022 00:35:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/17/2022 00:35:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/17/2022 00:35:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/17/2022 00:36:03 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8202551485373392 on epoch=121
06/17/2022 00:36:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/17/2022 00:36:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/17/2022 00:36:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/17/2022 00:36:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/17/2022 00:36:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/17/2022 00:36:25 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7697741396982384 on epoch=124
06/17/2022 00:36:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 00:36:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 00:36:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/17/2022 00:36:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/17/2022 00:36:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/17/2022 00:36:46 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8845135207148557 on epoch=128
06/17/2022 00:36:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/17/2022 00:36:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 00:36:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/17/2022 00:36:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/17/2022 00:37:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/17/2022 00:37:08 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.887063946453628 on epoch=132
06/17/2022 00:37:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 00:37:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 00:37:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/17/2022 00:37:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/17/2022 00:37:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 00:37:29 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9554227262752608 on epoch=135
06/17/2022 00:37:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/17/2022 00:37:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/17/2022 00:37:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 00:37:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 00:37:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/17/2022 00:37:51 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8862776310510722 on epoch=139
06/17/2022 00:37:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/17/2022 00:37:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/17/2022 00:38:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/17/2022 00:38:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/17/2022 00:38:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 00:38:12 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8978216702125621 on epoch=142
06/17/2022 00:38:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/17/2022 00:38:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/17/2022 00:38:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 00:38:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/17/2022 00:38:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 00:38:34 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8992168115097187 on epoch=146
06/17/2022 00:38:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 00:38:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 00:38:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/17/2022 00:38:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/17/2022 00:38:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/17/2022 00:38:55 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8978045636631974 on epoch=149
06/17/2022 00:38:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/17/2022 00:39:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 00:39:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/17/2022 00:39:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/17/2022 00:39:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 00:39:17 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9644953069204222 on epoch=153
06/17/2022 00:39:17 - INFO - __main__ - Saving model with best Classification-F1: 0.9644739274008725 -> 0.9644953069204222 on epoch=153, global_step=2150
06/17/2022 00:39:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/17/2022 00:39:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 00:39:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 00:39:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 00:39:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/17/2022 00:39:39 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8978004906752534 on epoch=157
06/17/2022 00:39:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/17/2022 00:39:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/17/2022 00:39:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 00:39:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 00:39:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/17/2022 00:40:00 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9645816097700077 on epoch=160
06/17/2022 00:40:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9644953069204222 -> 0.9645816097700077 on epoch=160, global_step=2250
06/17/2022 00:40:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/17/2022 00:40:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/17/2022 00:40:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 00:40:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/17/2022 00:40:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/17/2022 00:40:22 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8436339390961662 on epoch=164
06/17/2022 00:40:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 00:40:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 00:40:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/17/2022 00:40:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 00:40:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/17/2022 00:40:43 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9686895726032348 on epoch=167
06/17/2022 00:40:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9645816097700077 -> 0.9686895726032348 on epoch=167, global_step=2350
06/17/2022 00:40:46 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/17/2022 00:40:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/17/2022 00:40:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/17/2022 00:40:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 00:40:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 00:41:05 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9061092902459126 on epoch=171
06/17/2022 00:41:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/17/2022 00:41:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/17/2022 00:41:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 00:41:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/17/2022 00:41:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 00:41:26 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8976571214996263 on epoch=174
06/17/2022 00:41:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 00:41:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/17/2022 00:41:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 00:41:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 00:41:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 00:41:48 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9685762134765931 on epoch=178
06/17/2022 00:41:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 00:41:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 00:41:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/17/2022 00:42:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 00:42:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 00:42:09 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8394312701253522 on epoch=182
06/17/2022 00:42:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/17/2022 00:42:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/17/2022 00:42:18 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 00:42:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 00:42:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/17/2022 00:42:31 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9018539282770781 on epoch=185
06/17/2022 00:42:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 00:42:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/17/2022 00:42:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/17/2022 00:42:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/17/2022 00:42:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 00:42:53 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9641119277623071 on epoch=189
06/17/2022 00:42:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/17/2022 00:42:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/17/2022 00:43:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/17/2022 00:43:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 00:43:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/17/2022 00:43:14 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8978004906752534 on epoch=192
06/17/2022 00:43:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/17/2022 00:43:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 00:43:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 00:43:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/17/2022 00:43:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 00:43:36 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9059699940582294 on epoch=196
06/17/2022 00:43:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 00:43:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/17/2022 00:43:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 00:43:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/17/2022 00:43:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 00:43:58 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9731355298717725 on epoch=199
06/17/2022 00:43:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9686895726032348 -> 0.9731355298717725 on epoch=199, global_step=2800
06/17/2022 00:44:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/17/2022 00:44:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 00:44:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/17/2022 00:44:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/17/2022 00:44:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 00:44:20 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9598659625140379 on epoch=203
06/17/2022 00:44:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 00:44:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 00:44:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/17/2022 00:44:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 00:44:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/17/2022 00:44:41 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9035138137905918 on epoch=207
06/17/2022 00:44:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/17/2022 00:44:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/17/2022 00:44:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/17/2022 00:44:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 00:44:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/17/2022 00:45:03 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8429628186596714 on epoch=210
06/17/2022 00:45:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/17/2022 00:45:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/17/2022 00:45:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/17/2022 00:45:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 00:45:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 00:45:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:45:19 - INFO - __main__ - Printing 3 examples
06/17/2022 00:45:19 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 00:45:19 - INFO - __main__ - ['Animal']
06/17/2022 00:45:19 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 00:45:19 - INFO - __main__ - ['Animal']
06/17/2022 00:45:19 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/17/2022 00:45:19 - INFO - __main__ - ['Animal']
06/17/2022 00:45:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:45:20 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:45:20 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 00:45:20 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:45:20 - INFO - __main__ - Printing 3 examples
06/17/2022 00:45:20 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 00:45:20 - INFO - __main__ - ['Animal']
06/17/2022 00:45:20 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 00:45:20 - INFO - __main__ - ['Animal']
06/17/2022 00:45:20 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 00:45:20 - INFO - __main__ - ['Animal']
06/17/2022 00:45:20 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:45:20 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:45:20 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 00:45:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9037136545722882 on epoch=214
06/17/2022 00:45:25 - INFO - __main__ - save last model!
06/17/2022 00:45:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 00:45:25 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 00:45:25 - INFO - __main__ - Printing 3 examples
06/17/2022 00:45:25 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 00:45:25 - INFO - __main__ - ['Animal']
06/17/2022 00:45:25 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 00:45:25 - INFO - __main__ - ['Animal']
06/17/2022 00:45:25 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 00:45:25 - INFO - __main__ - ['Village']
06/17/2022 00:45:25 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:45:27 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:45:30 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 00:45:39 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 00:45:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 00:45:39 - INFO - __main__ - Starting training!
06/17/2022 00:47:52 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/17/2022 00:47:52 - INFO - __main__ - Classification-F1 on test data: 0.6772
06/17/2022 00:47:52 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9731355298717725, test_performance=0.6771554220849598
06/17/2022 00:47:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/17/2022 00:47:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:47:53 - INFO - __main__ - Printing 3 examples
06/17/2022 00:47:53 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/17/2022 00:47:53 - INFO - __main__ - ['Animal']
06/17/2022 00:47:53 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/17/2022 00:47:53 - INFO - __main__ - ['Animal']
06/17/2022 00:47:53 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/17/2022 00:47:53 - INFO - __main__ - ['Animal']
06/17/2022 00:47:53 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:47:53 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:47:53 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 00:47:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 00:47:53 - INFO - __main__ - Printing 3 examples
06/17/2022 00:47:53 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/17/2022 00:47:53 - INFO - __main__ - ['Animal']
06/17/2022 00:47:53 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/17/2022 00:47:53 - INFO - __main__ - ['Animal']
06/17/2022 00:47:53 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/17/2022 00:47:53 - INFO - __main__ - ['Animal']
06/17/2022 00:47:53 - INFO - __main__ - Tokenizing Input ...
06/17/2022 00:47:54 - INFO - __main__ - Tokenizing Output ...
06/17/2022 00:47:54 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 00:48:12 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 00:48:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 00:48:13 - INFO - __main__ - Starting training!
06/17/2022 00:48:17 - INFO - __main__ - Step 10 Global step 10 Train loss 7.16 on epoch=0
06/17/2022 00:48:20 - INFO - __main__ - Step 20 Global step 20 Train loss 5.63 on epoch=1
06/17/2022 00:48:23 - INFO - __main__ - Step 30 Global step 30 Train loss 4.97 on epoch=2
06/17/2022 00:48:26 - INFO - __main__ - Step 40 Global step 40 Train loss 4.33 on epoch=2
06/17/2022 00:48:29 - INFO - __main__ - Step 50 Global step 50 Train loss 4.03 on epoch=3
06/17/2022 00:48:34 - INFO - __main__ - Global step 50 Train loss 5.23 Classification-F1 0.03642491112250847 on epoch=3
06/17/2022 00:48:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03642491112250847 on epoch=3, global_step=50
06/17/2022 00:48:37 - INFO - __main__ - Step 60 Global step 60 Train loss 3.66 on epoch=4
06/17/2022 00:48:40 - INFO - __main__ - Step 70 Global step 70 Train loss 3.36 on epoch=4
06/17/2022 00:48:43 - INFO - __main__ - Step 80 Global step 80 Train loss 3.13 on epoch=5
06/17/2022 00:48:46 - INFO - __main__ - Step 90 Global step 90 Train loss 3.17 on epoch=6
06/17/2022 00:48:49 - INFO - __main__ - Step 100 Global step 100 Train loss 3.04 on epoch=7
06/17/2022 00:48:54 - INFO - __main__ - Global step 100 Train loss 3.27 Classification-F1 0.07077733224766863 on epoch=7
06/17/2022 00:48:54 - INFO - __main__ - Saving model with best Classification-F1: 0.03642491112250847 -> 0.07077733224766863 on epoch=7, global_step=100
06/17/2022 00:48:57 - INFO - __main__ - Step 110 Global step 110 Train loss 2.57 on epoch=7
06/17/2022 00:49:00 - INFO - __main__ - Step 120 Global step 120 Train loss 2.68 on epoch=8
06/17/2022 00:49:03 - INFO - __main__ - Step 130 Global step 130 Train loss 2.58 on epoch=9
06/17/2022 00:49:06 - INFO - __main__ - Step 140 Global step 140 Train loss 2.39 on epoch=9
06/17/2022 00:49:09 - INFO - __main__ - Step 150 Global step 150 Train loss 2.33 on epoch=10
06/17/2022 00:49:14 - INFO - __main__ - Global step 150 Train loss 2.51 Classification-F1 0.09717877976579165 on epoch=10
06/17/2022 00:49:14 - INFO - __main__ - Saving model with best Classification-F1: 0.07077733224766863 -> 0.09717877976579165 on epoch=10, global_step=150
06/17/2022 00:49:17 - INFO - __main__ - Step 160 Global step 160 Train loss 2.18 on epoch=11
06/17/2022 00:49:20 - INFO - __main__ - Step 170 Global step 170 Train loss 2.25 on epoch=12
06/17/2022 00:49:23 - INFO - __main__ - Step 180 Global step 180 Train loss 1.90 on epoch=12
06/17/2022 00:49:26 - INFO - __main__ - Step 190 Global step 190 Train loss 1.88 on epoch=13
06/17/2022 00:49:29 - INFO - __main__ - Step 200 Global step 200 Train loss 1.85 on epoch=14
06/17/2022 00:49:35 - INFO - __main__ - Global step 200 Train loss 2.01 Classification-F1 0.1260414048317274 on epoch=14
06/17/2022 00:49:35 - INFO - __main__ - Saving model with best Classification-F1: 0.09717877976579165 -> 0.1260414048317274 on epoch=14, global_step=200
06/17/2022 00:49:38 - INFO - __main__ - Step 210 Global step 210 Train loss 1.69 on epoch=14
06/17/2022 00:49:41 - INFO - __main__ - Step 220 Global step 220 Train loss 1.62 on epoch=15
06/17/2022 00:49:44 - INFO - __main__ - Step 230 Global step 230 Train loss 1.58 on epoch=16
06/17/2022 00:49:47 - INFO - __main__ - Step 240 Global step 240 Train loss 1.47 on epoch=17
06/17/2022 00:49:50 - INFO - __main__ - Step 250 Global step 250 Train loss 1.35 on epoch=17
06/17/2022 00:49:56 - INFO - __main__ - Global step 250 Train loss 1.54 Classification-F1 0.14389765346896077 on epoch=17
06/17/2022 00:49:56 - INFO - __main__ - Saving model with best Classification-F1: 0.1260414048317274 -> 0.14389765346896077 on epoch=17, global_step=250
06/17/2022 00:49:59 - INFO - __main__ - Step 260 Global step 260 Train loss 1.35 on epoch=18
06/17/2022 00:50:02 - INFO - __main__ - Step 270 Global step 270 Train loss 1.32 on epoch=19
06/17/2022 00:50:05 - INFO - __main__ - Step 280 Global step 280 Train loss 1.30 on epoch=19
06/17/2022 00:50:08 - INFO - __main__ - Step 290 Global step 290 Train loss 1.12 on epoch=20
06/17/2022 00:50:11 - INFO - __main__ - Step 300 Global step 300 Train loss 1.07 on epoch=21
06/17/2022 00:50:17 - INFO - __main__ - Global step 300 Train loss 1.23 Classification-F1 0.19511949622450855 on epoch=21
06/17/2022 00:50:17 - INFO - __main__ - Saving model with best Classification-F1: 0.14389765346896077 -> 0.19511949622450855 on epoch=21, global_step=300
06/17/2022 00:50:20 - INFO - __main__ - Step 310 Global step 310 Train loss 1.11 on epoch=22
06/17/2022 00:50:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.90 on epoch=22
06/17/2022 00:50:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.92 on epoch=23
06/17/2022 00:50:29 - INFO - __main__ - Step 340 Global step 340 Train loss 1.01 on epoch=24
06/17/2022 00:50:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.89 on epoch=24
06/17/2022 00:50:38 - INFO - __main__ - Global step 350 Train loss 0.97 Classification-F1 0.2523106490309633 on epoch=24
06/17/2022 00:50:38 - INFO - __main__ - Saving model with best Classification-F1: 0.19511949622450855 -> 0.2523106490309633 on epoch=24, global_step=350
06/17/2022 00:50:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.98 on epoch=25
06/17/2022 00:50:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.84 on epoch=26
06/17/2022 00:50:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.77 on epoch=27
06/17/2022 00:50:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.74 on epoch=27
06/17/2022 00:50:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.82 on epoch=28
06/17/2022 00:50:59 - INFO - __main__ - Global step 400 Train loss 0.83 Classification-F1 0.3646075103255176 on epoch=28
06/17/2022 00:50:59 - INFO - __main__ - Saving model with best Classification-F1: 0.2523106490309633 -> 0.3646075103255176 on epoch=28, global_step=400
06/17/2022 00:51:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.77 on epoch=29
06/17/2022 00:51:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.72 on epoch=29
06/17/2022 00:51:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.60 on epoch=30
06/17/2022 00:51:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.54 on epoch=31
06/17/2022 00:51:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.69 on epoch=32
06/17/2022 00:51:21 - INFO - __main__ - Global step 450 Train loss 0.66 Classification-F1 0.5082642984891398 on epoch=32
06/17/2022 00:51:21 - INFO - __main__ - Saving model with best Classification-F1: 0.3646075103255176 -> 0.5082642984891398 on epoch=32, global_step=450
06/17/2022 00:51:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=32
06/17/2022 00:51:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.52 on epoch=33
06/17/2022 00:51:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.57 on epoch=34
06/17/2022 00:51:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=34
06/17/2022 00:51:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.46 on epoch=35
06/17/2022 00:51:43 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.6105359484048224 on epoch=35
06/17/2022 00:51:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5082642984891398 -> 0.6105359484048224 on epoch=35, global_step=500
06/17/2022 00:51:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.41 on epoch=36
06/17/2022 00:51:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
06/17/2022 00:51:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/17/2022 00:51:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
06/17/2022 00:51:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.44 on epoch=39
06/17/2022 00:52:05 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.5888387196212024 on epoch=39
06/17/2022 00:52:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=39
06/17/2022 00:52:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=40
06/17/2022 00:52:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.43 on epoch=41
06/17/2022 00:52:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.44 on epoch=42
06/17/2022 00:52:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
06/17/2022 00:52:27 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6089989199738186 on epoch=42
06/17/2022 00:52:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=43
06/17/2022 00:52:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=44
06/17/2022 00:52:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=44
06/17/2022 00:52:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
06/17/2022 00:52:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=46
06/17/2022 00:52:49 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.6070163039565726 on epoch=46
06/17/2022 00:52:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
06/17/2022 00:52:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=47
06/17/2022 00:52:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
06/17/2022 00:53:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=49
06/17/2022 00:53:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=49
06/17/2022 00:53:11 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.6353624018934115 on epoch=49
06/17/2022 00:53:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6105359484048224 -> 0.6353624018934115 on epoch=49, global_step=700
06/17/2022 00:53:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=50
06/17/2022 00:53:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
06/17/2022 00:53:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
06/17/2022 00:53:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
06/17/2022 00:53:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
06/17/2022 00:53:33 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.5478622805128267 on epoch=53
06/17/2022 00:53:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
06/17/2022 00:53:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/17/2022 00:53:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=55
06/17/2022 00:53:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
06/17/2022 00:53:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/17/2022 00:53:55 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.5640434560227532 on epoch=57
06/17/2022 00:53:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/17/2022 00:54:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/17/2022 00:54:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/17/2022 00:54:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/17/2022 00:54:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/17/2022 00:54:16 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.5882515210562949 on epoch=60
06/17/2022 00:54:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
06/17/2022 00:54:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
06/17/2022 00:54:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/17/2022 00:54:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/17/2022 00:54:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
06/17/2022 00:54:38 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.5802524757792569 on epoch=64
06/17/2022 00:54:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/17/2022 00:54:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/17/2022 00:54:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/17/2022 00:54:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
06/17/2022 00:54:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
06/17/2022 00:55:00 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6991692467476875 on epoch=67
06/17/2022 00:55:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6353624018934115 -> 0.6991692467476875 on epoch=67, global_step=950
06/17/2022 00:55:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
06/17/2022 00:55:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
06/17/2022 00:55:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
06/17/2022 00:55:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/17/2022 00:55:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=71
06/17/2022 00:55:22 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6001904513773998 on epoch=71
06/17/2022 00:55:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/17/2022 00:55:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=72
06/17/2022 00:55:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/17/2022 00:55:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=74
06/17/2022 00:55:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/17/2022 00:55:44 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6765351813926167 on epoch=74
06/17/2022 00:55:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/17/2022 00:55:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/17/2022 00:55:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=77
06/17/2022 00:55:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
06/17/2022 00:55:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
06/17/2022 00:56:05 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.7579969084308777 on epoch=78
06/17/2022 00:56:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6991692467476875 -> 0.7579969084308777 on epoch=78, global_step=1100
06/17/2022 00:56:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/17/2022 00:56:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=79
06/17/2022 00:56:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/17/2022 00:56:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/17/2022 00:56:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/17/2022 00:56:27 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.6860650828128538 on epoch=82
06/17/2022 00:56:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/17/2022 00:56:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 00:56:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/17/2022 00:56:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/17/2022 00:56:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/17/2022 00:56:48 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.8836511009313033 on epoch=85
06/17/2022 00:56:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7579969084308777 -> 0.8836511009313033 on epoch=85, global_step=1200
06/17/2022 00:56:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/17/2022 00:56:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/17/2022 00:56:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/17/2022 00:57:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/17/2022 00:57:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/17/2022 00:57:10 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.8167633946135175 on epoch=89
06/17/2022 00:57:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/17/2022 00:57:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/17/2022 00:57:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/17/2022 00:57:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/17/2022 00:57:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/17/2022 00:57:32 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8584609723679932 on epoch=92
06/17/2022 00:57:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/17/2022 00:57:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/17/2022 00:57:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/17/2022 00:57:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/17/2022 00:57:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/17/2022 00:57:53 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.760511262620873 on epoch=96
06/17/2022 00:57:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
06/17/2022 00:57:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/17/2022 00:58:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/17/2022 00:58:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/17/2022 00:58:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=99
06/17/2022 00:58:15 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7689354940987377 on epoch=99
06/17/2022 00:58:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=100
06/17/2022 00:58:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/17/2022 00:58:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/17/2022 00:58:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/17/2022 00:58:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/17/2022 00:58:37 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8372378762722097 on epoch=103
06/17/2022 00:58:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/17/2022 00:58:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/17/2022 00:58:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/17/2022 00:58:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/17/2022 00:58:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
06/17/2022 00:58:59 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8354553450779139 on epoch=107
06/17/2022 00:59:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
06/17/2022 00:59:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/17/2022 00:59:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
06/17/2022 00:59:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/17/2022 00:59:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/17/2022 00:59:20 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8289109091217133 on epoch=110
06/17/2022 00:59:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/17/2022 00:59:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/17/2022 00:59:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/17/2022 00:59:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/17/2022 00:59:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/17/2022 00:59:42 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8314758222342937 on epoch=114
06/17/2022 00:59:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/17/2022 00:59:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
06/17/2022 00:59:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/17/2022 00:59:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
06/17/2022 00:59:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/17/2022 01:00:04 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8372009715315493 on epoch=117
06/17/2022 01:00:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=118
06/17/2022 01:00:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
06/17/2022 01:00:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/17/2022 01:00:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/17/2022 01:00:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
06/17/2022 01:00:25 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8354553450779139 on epoch=121
06/17/2022 01:00:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/17/2022 01:00:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/17/2022 01:00:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 01:00:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/17/2022 01:00:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/17/2022 01:00:47 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.893446274893144 on epoch=124
06/17/2022 01:00:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8836511009313033 -> 0.893446274893144 on epoch=124, global_step=1750
06/17/2022 01:00:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/17/2022 01:00:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 01:00:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/17/2022 01:00:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/17/2022 01:01:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/17/2022 01:01:08 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9640812776723593 on epoch=128
06/17/2022 01:01:08 - INFO - __main__ - Saving model with best Classification-F1: 0.893446274893144 -> 0.9640812776723593 on epoch=128, global_step=1800
06/17/2022 01:01:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/17/2022 01:01:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/17/2022 01:01:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/17/2022 01:01:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/17/2022 01:01:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/17/2022 01:01:30 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9638671625491132 on epoch=132
06/17/2022 01:01:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/17/2022 01:01:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/17/2022 01:01:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/17/2022 01:01:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/17/2022 01:01:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/17/2022 01:01:52 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9638671625491132 on epoch=135
06/17/2022 01:01:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/17/2022 01:01:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/17/2022 01:02:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 01:02:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 01:02:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/17/2022 01:02:13 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9638671625491132 on epoch=139
06/17/2022 01:02:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/17/2022 01:02:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/17/2022 01:02:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/17/2022 01:02:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/17/2022 01:02:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/17/2022 01:02:35 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9638671625491132 on epoch=142
06/17/2022 01:02:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/17/2022 01:02:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/17/2022 01:02:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/17/2022 01:02:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/17/2022 01:02:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/17/2022 01:02:57 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9640812776723593 on epoch=146
06/17/2022 01:03:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/17/2022 01:03:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/17/2022 01:03:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/17/2022 01:03:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/17/2022 01:03:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 01:03:18 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9684182397299096 on epoch=149
06/17/2022 01:03:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9640812776723593 -> 0.9684182397299096 on epoch=149, global_step=2100
06/17/2022 01:03:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/17/2022 01:03:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/17/2022 01:03:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/17/2022 01:03:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/17/2022 01:03:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/17/2022 01:03:40 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.973026534660785 on epoch=153
06/17/2022 01:03:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9684182397299096 -> 0.973026534660785 on epoch=153, global_step=2150
06/17/2022 01:03:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/17/2022 01:03:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/17/2022 01:03:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/17/2022 01:03:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/17/2022 01:03:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/17/2022 01:04:01 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.9638671625491132 on epoch=157
06/17/2022 01:04:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/17/2022 01:04:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/17/2022 01:04:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/17/2022 01:04:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/17/2022 01:04:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/17/2022 01:04:23 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9638671625491132 on epoch=160
06/17/2022 01:04:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/17/2022 01:04:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/17/2022 01:04:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
06/17/2022 01:04:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/17/2022 01:04:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/17/2022 01:04:44 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9683481338232534 on epoch=164
06/17/2022 01:04:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/17/2022 01:04:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/17/2022 01:04:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/17/2022 01:04:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/17/2022 01:04:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/17/2022 01:05:06 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9682041246066635 on epoch=167
06/17/2022 01:05:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/17/2022 01:05:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/17/2022 01:05:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 01:05:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/17/2022 01:05:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/17/2022 01:05:27 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9638671625491132 on epoch=171
06/17/2022 01:05:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/17/2022 01:05:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/17/2022 01:05:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/17/2022 01:05:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/17/2022 01:05:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/17/2022 01:05:49 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8976822260235202 on epoch=174
06/17/2022 01:05:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/17/2022 01:05:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/17/2022 01:05:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/17/2022 01:06:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 01:06:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/17/2022 01:06:10 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9016540874953819 on epoch=178
06/17/2022 01:06:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/17/2022 01:06:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/17/2022 01:06:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=180
06/17/2022 01:06:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/17/2022 01:06:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/17/2022 01:06:32 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9728263840676326 on epoch=182
06/17/2022 01:06:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/17/2022 01:06:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/17/2022 01:06:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 01:06:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/17/2022 01:06:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/17/2022 01:06:53 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9682629870129871 on epoch=185
06/17/2022 01:06:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/17/2022 01:06:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/17/2022 01:07:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 01:07:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/17/2022 01:07:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 01:07:15 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9683524977389075 on epoch=189
06/17/2022 01:07:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/17/2022 01:07:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 01:07:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 01:07:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 01:07:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/17/2022 01:07:36 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.901649199909849 on epoch=192
06/17/2022 01:07:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/17/2022 01:07:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 01:07:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/17/2022 01:07:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 01:07:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 01:07:58 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9641065324906382 on epoch=196
06/17/2022 01:08:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 01:08:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 01:08:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 01:08:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 01:08:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/17/2022 01:08:19 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8976822260235202 on epoch=199
06/17/2022 01:08:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/17/2022 01:08:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/17/2022 01:08:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/17/2022 01:08:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/17/2022 01:08:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/17/2022 01:08:41 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8976586548597933 on epoch=203
06/17/2022 01:08:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/17/2022 01:08:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 01:08:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 01:08:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/17/2022 01:08:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/17/2022 01:09:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.977525834380673 on epoch=207
06/17/2022 01:09:02 - INFO - __main__ - Saving model with best Classification-F1: 0.973026534660785 -> 0.977525834380673 on epoch=207, global_step=2900
06/17/2022 01:09:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/17/2022 01:09:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/17/2022 01:09:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 01:09:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/17/2022 01:09:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/17/2022 01:09:24 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9639260249554367 on epoch=210
06/17/2022 01:09:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/17/2022 01:09:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 01:09:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/17/2022 01:09:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/17/2022 01:09:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/17/2022 01:09:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:09:41 - INFO - __main__ - Printing 3 examples
06/17/2022 01:09:41 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 01:09:41 - INFO - __main__ - ['Plant']
06/17/2022 01:09:41 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 01:09:41 - INFO - __main__ - ['Plant']
06/17/2022 01:09:41 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 01:09:41 - INFO - __main__ - ['Plant']
06/17/2022 01:09:41 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:09:41 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:09:41 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 01:09:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:09:41 - INFO - __main__ - Printing 3 examples
06/17/2022 01:09:41 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 01:09:41 - INFO - __main__ - ['Plant']
06/17/2022 01:09:41 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 01:09:41 - INFO - __main__ - ['Plant']
06/17/2022 01:09:41 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 01:09:41 - INFO - __main__ - ['Plant']
06/17/2022 01:09:41 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:09:41 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:09:41 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 01:09:45 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.897513752323999 on epoch=214
06/17/2022 01:09:45 - INFO - __main__ - save last model!
06/17/2022 01:09:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 01:09:46 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 01:09:46 - INFO - __main__ - Printing 3 examples
06/17/2022 01:09:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 01:09:46 - INFO - __main__ - ['Animal']
06/17/2022 01:09:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 01:09:46 - INFO - __main__ - ['Animal']
06/17/2022 01:09:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 01:09:46 - INFO - __main__ - ['Village']
06/17/2022 01:09:46 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:09:47 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:09:51 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 01:10:00 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:10:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 01:10:01 - INFO - __main__ - Starting training!
06/17/2022 01:12:09 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/17/2022 01:12:09 - INFO - __main__ - Classification-F1 on test data: 0.8046
06/17/2022 01:12:10 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.977525834380673, test_performance=0.8046018834033184
06/17/2022 01:12:10 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/17/2022 01:12:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:12:11 - INFO - __main__ - Printing 3 examples
06/17/2022 01:12:11 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 01:12:11 - INFO - __main__ - ['Plant']
06/17/2022 01:12:11 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 01:12:11 - INFO - __main__ - ['Plant']
06/17/2022 01:12:11 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 01:12:11 - INFO - __main__ - ['Plant']
06/17/2022 01:12:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:12:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:12:11 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 01:12:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:12:11 - INFO - __main__ - Printing 3 examples
06/17/2022 01:12:11 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 01:12:11 - INFO - __main__ - ['Plant']
06/17/2022 01:12:11 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 01:12:11 - INFO - __main__ - ['Plant']
06/17/2022 01:12:11 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 01:12:11 - INFO - __main__ - ['Plant']
06/17/2022 01:12:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:12:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:12:11 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 01:12:27 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:12:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 01:12:27 - INFO - __main__ - Starting training!
06/17/2022 01:12:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.30 on epoch=0
06/17/2022 01:12:34 - INFO - __main__ - Step 20 Global step 20 Train loss 4.34 on epoch=1
06/17/2022 01:12:37 - INFO - __main__ - Step 30 Global step 30 Train loss 3.79 on epoch=2
06/17/2022 01:12:40 - INFO - __main__ - Step 40 Global step 40 Train loss 3.00 on epoch=2
06/17/2022 01:12:43 - INFO - __main__ - Step 50 Global step 50 Train loss 2.68 on epoch=3
06/17/2022 01:12:48 - INFO - __main__ - Global step 50 Train loss 4.02 Classification-F1 0.08946014235306633 on epoch=3
06/17/2022 01:12:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08946014235306633 on epoch=3, global_step=50
06/17/2022 01:12:51 - INFO - __main__ - Step 60 Global step 60 Train loss 2.42 on epoch=4
06/17/2022 01:12:54 - INFO - __main__ - Step 70 Global step 70 Train loss 2.07 on epoch=4
06/17/2022 01:12:57 - INFO - __main__ - Step 80 Global step 80 Train loss 1.83 on epoch=5
06/17/2022 01:13:00 - INFO - __main__ - Step 90 Global step 90 Train loss 1.79 on epoch=6
06/17/2022 01:13:03 - INFO - __main__ - Step 100 Global step 100 Train loss 1.56 on epoch=7
06/17/2022 01:13:09 - INFO - __main__ - Global step 100 Train loss 1.93 Classification-F1 0.15692321060062994 on epoch=7
06/17/2022 01:13:09 - INFO - __main__ - Saving model with best Classification-F1: 0.08946014235306633 -> 0.15692321060062994 on epoch=7, global_step=100
06/17/2022 01:13:12 - INFO - __main__ - Step 110 Global step 110 Train loss 1.28 on epoch=7
06/17/2022 01:13:15 - INFO - __main__ - Step 120 Global step 120 Train loss 1.26 on epoch=8
06/17/2022 01:13:18 - INFO - __main__ - Step 130 Global step 130 Train loss 1.14 on epoch=9
06/17/2022 01:13:21 - INFO - __main__ - Step 140 Global step 140 Train loss 1.06 on epoch=9
06/17/2022 01:13:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=10
06/17/2022 01:13:30 - INFO - __main__ - Global step 150 Train loss 1.13 Classification-F1 0.29557042742299056 on epoch=10
06/17/2022 01:13:30 - INFO - __main__ - Saving model with best Classification-F1: 0.15692321060062994 -> 0.29557042742299056 on epoch=10, global_step=150
06/17/2022 01:13:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=11
06/17/2022 01:13:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=12
06/17/2022 01:13:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.65 on epoch=12
06/17/2022 01:13:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=13
06/17/2022 01:13:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=14
06/17/2022 01:13:52 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.5057167999788709 on epoch=14
06/17/2022 01:13:52 - INFO - __main__ - Saving model with best Classification-F1: 0.29557042742299056 -> 0.5057167999788709 on epoch=14, global_step=200
06/17/2022 01:13:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=14
06/17/2022 01:13:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=15
06/17/2022 01:14:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
06/17/2022 01:14:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=17
06/17/2022 01:14:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=17
06/17/2022 01:14:14 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.6025578618120719 on epoch=17
06/17/2022 01:14:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5057167999788709 -> 0.6025578618120719 on epoch=17, global_step=250
06/17/2022 01:14:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=18
06/17/2022 01:14:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=19
06/17/2022 01:14:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=19
06/17/2022 01:14:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=20
06/17/2022 01:14:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=21
06/17/2022 01:14:36 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.678379489063746 on epoch=21
06/17/2022 01:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6025578618120719 -> 0.678379489063746 on epoch=21, global_step=300
06/17/2022 01:14:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=22
06/17/2022 01:14:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=22
06/17/2022 01:14:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.20 on epoch=23
06/17/2022 01:14:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=24
06/17/2022 01:14:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.18 on epoch=24
06/17/2022 01:14:59 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.6530030590028454 on epoch=24
06/17/2022 01:15:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=25
06/17/2022 01:15:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
06/17/2022 01:15:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=27
06/17/2022 01:15:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=27
06/17/2022 01:15:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=28
06/17/2022 01:15:21 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6830270794106713 on epoch=28
06/17/2022 01:15:21 - INFO - __main__ - Saving model with best Classification-F1: 0.678379489063746 -> 0.6830270794106713 on epoch=28, global_step=400
06/17/2022 01:15:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=29
06/17/2022 01:15:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=29
06/17/2022 01:15:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=30
06/17/2022 01:15:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=31
06/17/2022 01:15:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.09 on epoch=32
06/17/2022 01:15:43 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.6439333634151405 on epoch=32
06/17/2022 01:15:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=32
06/17/2022 01:15:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=33
06/17/2022 01:15:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=34
06/17/2022 01:15:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=34
06/17/2022 01:15:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=35
06/17/2022 01:16:05 - INFO - __main__ - Global step 500 Train loss 0.09 Classification-F1 0.7892569358735148 on epoch=35
06/17/2022 01:16:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6830270794106713 -> 0.7892569358735148 on epoch=35, global_step=500
06/17/2022 01:16:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=36
06/17/2022 01:16:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=37
06/17/2022 01:16:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
06/17/2022 01:16:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=38
06/17/2022 01:16:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
06/17/2022 01:16:28 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.6069803940384931 on epoch=39
06/17/2022 01:16:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=39
06/17/2022 01:16:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=40
06/17/2022 01:16:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
06/17/2022 01:16:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=42
06/17/2022 01:16:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=42
06/17/2022 01:16:49 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7413971977764262 on epoch=42
06/17/2022 01:16:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=43
06/17/2022 01:16:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=44
06/17/2022 01:16:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=44
06/17/2022 01:17:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=45
06/17/2022 01:17:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/17/2022 01:17:11 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.5639632532855039 on epoch=46
06/17/2022 01:17:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=47
06/17/2022 01:17:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=47
06/17/2022 01:17:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=48
06/17/2022 01:17:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=49
06/17/2022 01:17:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/17/2022 01:17:33 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.9038480631744389 on epoch=49
06/17/2022 01:17:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7892569358735148 -> 0.9038480631744389 on epoch=49, global_step=700
06/17/2022 01:17:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=50
06/17/2022 01:17:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
06/17/2022 01:17:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=52
06/17/2022 01:17:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
06/17/2022 01:17:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
06/17/2022 01:17:55 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.8975503570491467 on epoch=53
06/17/2022 01:17:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
06/17/2022 01:18:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
06/17/2022 01:18:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=55
06/17/2022 01:18:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
06/17/2022 01:18:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
06/17/2022 01:18:18 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.8978774373762268 on epoch=57
06/17/2022 01:18:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/17/2022 01:18:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
06/17/2022 01:18:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=59
06/17/2022 01:18:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
06/17/2022 01:18:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
06/17/2022 01:18:39 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.905558549573468 on epoch=60
06/17/2022 01:18:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9038480631744389 -> 0.905558549573468 on epoch=60, global_step=850
06/17/2022 01:18:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=61
06/17/2022 01:18:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
06/17/2022 01:18:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/17/2022 01:18:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/17/2022 01:18:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/17/2022 01:19:01 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.8952908023875766 on epoch=64
06/17/2022 01:19:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=64
06/17/2022 01:19:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/17/2022 01:19:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 01:19:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
06/17/2022 01:19:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/17/2022 01:19:23 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.9037658324866332 on epoch=67
06/17/2022 01:19:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/17/2022 01:19:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/17/2022 01:19:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
06/17/2022 01:19:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=70
06/17/2022 01:19:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
06/17/2022 01:19:45 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.9689740999038913 on epoch=71
06/17/2022 01:19:45 - INFO - __main__ - Saving model with best Classification-F1: 0.905558549573468 -> 0.9689740999038913 on epoch=71, global_step=1000
06/17/2022 01:19:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=72
06/17/2022 01:19:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
06/17/2022 01:19:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/17/2022 01:19:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/17/2022 01:20:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/17/2022 01:20:07 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.8976977992127178 on epoch=74
06/17/2022 01:20:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
06/17/2022 01:20:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
06/17/2022 01:20:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
06/17/2022 01:20:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/17/2022 01:20:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/17/2022 01:20:29 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8911613950038998 on epoch=78
06/17/2022 01:20:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
06/17/2022 01:20:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/17/2022 01:20:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/17/2022 01:20:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/17/2022 01:20:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=82
06/17/2022 01:20:51 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7450644418844381 on epoch=82
06/17/2022 01:20:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/17/2022 01:20:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/17/2022 01:21:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
06/17/2022 01:21:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=84
06/17/2022 01:21:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/17/2022 01:21:13 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7930427044027892 on epoch=85
06/17/2022 01:21:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/17/2022 01:21:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=87
06/17/2022 01:21:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/17/2022 01:21:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
06/17/2022 01:21:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/17/2022 01:21:34 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.908036723976003 on epoch=89
06/17/2022 01:21:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/17/2022 01:21:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/17/2022 01:21:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/17/2022 01:21:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/17/2022 01:21:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/17/2022 01:21:56 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9018082149770954 on epoch=92
06/17/2022 01:21:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/17/2022 01:22:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/17/2022 01:22:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 01:22:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/17/2022 01:22:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/17/2022 01:22:18 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.899356107697402 on epoch=96
06/17/2022 01:22:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/17/2022 01:22:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 01:22:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/17/2022 01:22:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 01:22:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/17/2022 01:22:40 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9731757805761602 on epoch=99
06/17/2022 01:22:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9689740999038913 -> 0.9731757805761602 on epoch=99, global_step=1400
06/17/2022 01:22:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/17/2022 01:22:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/17/2022 01:22:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/17/2022 01:22:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/17/2022 01:22:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/17/2022 01:23:02 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9019515841527228 on epoch=103
06/17/2022 01:23:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/17/2022 01:23:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/17/2022 01:23:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/17/2022 01:23:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 01:23:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/17/2022 01:23:23 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8504203734279636 on epoch=107
06/17/2022 01:23:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/17/2022 01:23:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/17/2022 01:23:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 01:23:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/17/2022 01:23:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/17/2022 01:23:45 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7224736372678531 on epoch=110
06/17/2022 01:23:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/17/2022 01:23:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/17/2022 01:23:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/17/2022 01:23:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/17/2022 01:24:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/17/2022 01:24:07 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7303240028922728 on epoch=114
06/17/2022 01:24:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/17/2022 01:24:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/17/2022 01:24:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/17/2022 01:24:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 01:24:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/17/2022 01:24:28 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7990337498249019 on epoch=117
06/17/2022 01:24:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/17/2022 01:24:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/17/2022 01:24:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/17/2022 01:24:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 01:24:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/17/2022 01:24:50 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8334278229676713 on epoch=121
06/17/2022 01:24:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 01:24:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/17/2022 01:24:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/17/2022 01:25:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/17/2022 01:25:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/17/2022 01:25:12 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8553166867920189 on epoch=124
06/17/2022 01:25:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 01:25:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/17/2022 01:25:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
06/17/2022 01:25:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 01:25:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 01:25:33 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8411953830285781 on epoch=128
06/17/2022 01:25:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=129
06/17/2022 01:25:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/17/2022 01:25:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 01:25:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/17/2022 01:25:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/17/2022 01:25:55 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8514104367920189 on epoch=132
06/17/2022 01:25:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
06/17/2022 01:26:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 01:26:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 01:26:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=134
06/17/2022 01:26:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 01:26:17 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9035833189580819 on epoch=135
06/17/2022 01:26:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/17/2022 01:26:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/17/2022 01:26:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 01:26:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 01:26:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 01:26:39 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8488389505868077 on epoch=139
06/17/2022 01:26:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/17/2022 01:26:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 01:26:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/17/2022 01:26:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/17/2022 01:26:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
06/17/2022 01:27:01 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.98211307983604 on epoch=142
06/17/2022 01:27:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9731757805761602 -> 0.98211307983604 on epoch=142, global_step=2000
06/17/2022 01:27:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/17/2022 01:27:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
06/17/2022 01:27:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
06/17/2022 01:27:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/17/2022 01:27:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/17/2022 01:27:23 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9731757805761602 on epoch=146
06/17/2022 01:27:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 01:27:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
06/17/2022 01:27:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/17/2022 01:27:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/17/2022 01:27:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 01:27:45 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9103216702125622 on epoch=149
06/17/2022 01:27:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/17/2022 01:27:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 01:27:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 01:27:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/17/2022 01:28:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 01:28:07 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9731757805761602 on epoch=153
06/17/2022 01:28:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/17/2022 01:28:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/17/2022 01:28:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/17/2022 01:28:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
06/17/2022 01:28:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
06/17/2022 01:28:28 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9776444302061 on epoch=157
06/17/2022 01:28:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/17/2022 01:28:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/17/2022 01:28:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/17/2022 01:28:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/17/2022 01:28:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
06/17/2022 01:28:50 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9776444302061 on epoch=160
06/17/2022 01:28:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/17/2022 01:28:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/17/2022 01:28:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/17/2022 01:29:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
06/17/2022 01:29:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/17/2022 01:29:12 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9776444302061 on epoch=164
06/17/2022 01:29:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 01:29:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 01:29:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/17/2022 01:29:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
06/17/2022 01:29:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 01:29:34 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9731801444918143 on epoch=167
06/17/2022 01:29:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/17/2022 01:29:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/17/2022 01:29:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/17/2022 01:29:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 01:29:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/17/2022 01:29:56 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9731757805761602 on epoch=171
06/17/2022 01:29:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 01:30:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/17/2022 01:30:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/17/2022 01:30:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/17/2022 01:30:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/17/2022 01:30:18 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9776654796816088 on epoch=174
06/17/2022 01:30:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/17/2022 01:30:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/17/2022 01:30:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 01:30:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 01:30:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/17/2022 01:30:40 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=178
06/17/2022 01:30:40 - INFO - __main__ - Saving model with best Classification-F1: 0.98211307983604 -> 0.9821297653958945 on epoch=178, global_step=2500
06/17/2022 01:30:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 01:30:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 01:30:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/17/2022 01:30:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 01:30:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 01:31:02 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9730432202206395 on epoch=182
06/17/2022 01:31:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/17/2022 01:31:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/17/2022 01:31:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/17/2022 01:31:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 01:31:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/17/2022 01:31:24 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.9682506653687868 on epoch=185
06/17/2022 01:31:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/17/2022 01:31:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 01:31:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/17/2022 01:31:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 01:31:39 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/17/2022 01:31:46 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.973057184750733 on epoch=189
06/17/2022 01:31:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 01:31:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/17/2022 01:31:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 01:31:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/17/2022 01:32:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/17/2022 01:32:08 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9100553926360379 on epoch=192
06/17/2022 01:32:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/17/2022 01:32:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 01:32:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 01:32:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 01:32:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 01:32:30 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9776444302061 on epoch=196
06/17/2022 01:32:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/17/2022 01:32:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 01:32:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 01:32:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/17/2022 01:32:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/17/2022 01:32:52 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9728685609141016 on epoch=199
06/17/2022 01:32:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 01:32:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 01:33:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/17/2022 01:33:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/17/2022 01:33:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 01:33:13 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9776444302061 on epoch=203
06/17/2022 01:33:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 01:33:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/17/2022 01:33:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/17/2022 01:33:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 01:33:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 01:33:35 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.972872924829756 on epoch=207
06/17/2022 01:33:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/17/2022 01:33:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/17/2022 01:33:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 01:33:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/17/2022 01:33:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 01:33:57 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9145079830563703 on epoch=210
06/17/2022 01:34:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 01:34:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 01:34:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/17/2022 01:34:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 01:34:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/17/2022 01:34:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:34:14 - INFO - __main__ - Printing 3 examples
06/17/2022 01:34:14 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 01:34:14 - INFO - __main__ - ['Plant']
06/17/2022 01:34:14 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 01:34:14 - INFO - __main__ - ['Plant']
06/17/2022 01:34:14 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 01:34:14 - INFO - __main__ - ['Plant']
06/17/2022 01:34:14 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:34:14 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:34:14 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 01:34:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:34:14 - INFO - __main__ - Printing 3 examples
06/17/2022 01:34:14 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 01:34:14 - INFO - __main__ - ['Plant']
06/17/2022 01:34:14 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 01:34:14 - INFO - __main__ - ['Plant']
06/17/2022 01:34:14 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 01:34:14 - INFO - __main__ - ['Plant']
06/17/2022 01:34:14 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:34:14 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:34:14 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 01:34:19 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9776654796816088 on epoch=214
06/17/2022 01:34:19 - INFO - __main__ - save last model!
06/17/2022 01:34:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 01:34:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 01:34:19 - INFO - __main__ - Printing 3 examples
06/17/2022 01:34:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 01:34:19 - INFO - __main__ - ['Animal']
06/17/2022 01:34:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 01:34:19 - INFO - __main__ - ['Animal']
06/17/2022 01:34:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 01:34:19 - INFO - __main__ - ['Village']
06/17/2022 01:34:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:34:21 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:34:25 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 01:34:33 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:34:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 01:34:34 - INFO - __main__ - Starting training!
06/17/2022 01:36:42 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/17/2022 01:36:42 - INFO - __main__ - Classification-F1 on test data: 0.6161
06/17/2022 01:36:42 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9821297653958945, test_performance=0.6161239915870999
06/17/2022 01:36:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/17/2022 01:36:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:36:43 - INFO - __main__ - Printing 3 examples
06/17/2022 01:36:43 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 01:36:43 - INFO - __main__ - ['Plant']
06/17/2022 01:36:43 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 01:36:43 - INFO - __main__ - ['Plant']
06/17/2022 01:36:43 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 01:36:43 - INFO - __main__ - ['Plant']
06/17/2022 01:36:43 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:36:43 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:36:44 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 01:36:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:36:44 - INFO - __main__ - Printing 3 examples
06/17/2022 01:36:44 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 01:36:44 - INFO - __main__ - ['Plant']
06/17/2022 01:36:44 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 01:36:44 - INFO - __main__ - ['Plant']
06/17/2022 01:36:44 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 01:36:44 - INFO - __main__ - ['Plant']
06/17/2022 01:36:44 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:36:44 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:36:44 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 01:36:59 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:37:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 01:37:00 - INFO - __main__ - Starting training!
06/17/2022 01:37:04 - INFO - __main__ - Step 10 Global step 10 Train loss 6.40 on epoch=0
06/17/2022 01:37:06 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/17/2022 01:37:09 - INFO - __main__ - Step 30 Global step 30 Train loss 4.17 on epoch=2
06/17/2022 01:37:12 - INFO - __main__ - Step 40 Global step 40 Train loss 3.34 on epoch=2
06/17/2022 01:37:15 - INFO - __main__ - Step 50 Global step 50 Train loss 3.18 on epoch=3
06/17/2022 01:37:20 - INFO - __main__ - Global step 50 Train loss 4.39 Classification-F1 0.0701132613784098 on epoch=3
06/17/2022 01:37:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0701132613784098 on epoch=3, global_step=50
06/17/2022 01:37:23 - INFO - __main__ - Step 60 Global step 60 Train loss 2.78 on epoch=4
06/17/2022 01:37:26 - INFO - __main__ - Step 70 Global step 70 Train loss 2.46 on epoch=4
06/17/2022 01:37:29 - INFO - __main__ - Step 80 Global step 80 Train loss 2.19 on epoch=5
06/17/2022 01:37:32 - INFO - __main__ - Step 90 Global step 90 Train loss 1.96 on epoch=6
06/17/2022 01:37:35 - INFO - __main__ - Step 100 Global step 100 Train loss 2.08 on epoch=7
06/17/2022 01:37:40 - INFO - __main__ - Global step 100 Train loss 2.29 Classification-F1 0.1346323273300961 on epoch=7
06/17/2022 01:37:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0701132613784098 -> 0.1346323273300961 on epoch=7, global_step=100
06/17/2022 01:37:43 - INFO - __main__ - Step 110 Global step 110 Train loss 1.66 on epoch=7
06/17/2022 01:37:46 - INFO - __main__ - Step 120 Global step 120 Train loss 1.62 on epoch=8
06/17/2022 01:37:49 - INFO - __main__ - Step 130 Global step 130 Train loss 1.39 on epoch=9
06/17/2022 01:37:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.29 on epoch=9
06/17/2022 01:37:55 - INFO - __main__ - Step 150 Global step 150 Train loss 1.16 on epoch=10
06/17/2022 01:38:01 - INFO - __main__ - Global step 150 Train loss 1.42 Classification-F1 0.20985013009484646 on epoch=10
06/17/2022 01:38:01 - INFO - __main__ - Saving model with best Classification-F1: 0.1346323273300961 -> 0.20985013009484646 on epoch=10, global_step=150
06/17/2022 01:38:04 - INFO - __main__ - Step 160 Global step 160 Train loss 1.15 on epoch=11
06/17/2022 01:38:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.06 on epoch=12
06/17/2022 01:38:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.94 on epoch=12
06/17/2022 01:38:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=13
06/17/2022 01:38:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=14
06/17/2022 01:38:23 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.40806725476676214 on epoch=14
06/17/2022 01:38:23 - INFO - __main__ - Saving model with best Classification-F1: 0.20985013009484646 -> 0.40806725476676214 on epoch=14, global_step=200
06/17/2022 01:38:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=14
06/17/2022 01:38:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=15
06/17/2022 01:38:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=16
06/17/2022 01:38:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=17
06/17/2022 01:38:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=17
06/17/2022 01:38:45 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.5617653256004813 on epoch=17
06/17/2022 01:38:45 - INFO - __main__ - Saving model with best Classification-F1: 0.40806725476676214 -> 0.5617653256004813 on epoch=17, global_step=250
06/17/2022 01:38:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=18
06/17/2022 01:38:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
06/17/2022 01:38:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=19
06/17/2022 01:38:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=20
06/17/2022 01:39:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
06/17/2022 01:39:07 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6117225311095277 on epoch=21
06/17/2022 01:39:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5617653256004813 -> 0.6117225311095277 on epoch=21, global_step=300
06/17/2022 01:39:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
06/17/2022 01:39:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=22
06/17/2022 01:39:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=23
06/17/2022 01:39:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=24
06/17/2022 01:39:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=24
06/17/2022 01:39:29 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.7173620264520958 on epoch=24
06/17/2022 01:39:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6117225311095277 -> 0.7173620264520958 on epoch=24, global_step=350
06/17/2022 01:39:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=25
06/17/2022 01:39:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=26
06/17/2022 01:39:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=27
06/17/2022 01:39:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=27
06/17/2022 01:39:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=28
06/17/2022 01:39:50 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.6454082420126565 on epoch=28
06/17/2022 01:39:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/17/2022 01:39:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=29
06/17/2022 01:39:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=30
06/17/2022 01:40:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=31
06/17/2022 01:40:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
06/17/2022 01:40:12 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.7134787855110993 on epoch=32
06/17/2022 01:40:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
06/17/2022 01:40:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/17/2022 01:40:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=34
06/17/2022 01:40:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=34
06/17/2022 01:40:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
06/17/2022 01:40:33 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.6360793784836128 on epoch=35
06/17/2022 01:40:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
06/17/2022 01:40:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
06/17/2022 01:40:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
06/17/2022 01:40:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
06/17/2022 01:40:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=39
06/17/2022 01:40:55 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.585008621498426 on epoch=39
06/17/2022 01:40:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=39
06/17/2022 01:41:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
06/17/2022 01:41:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
06/17/2022 01:41:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=42
06/17/2022 01:41:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
06/17/2022 01:41:16 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.6555019638087082 on epoch=42
06/17/2022 01:41:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
06/17/2022 01:41:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
06/17/2022 01:41:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=44
06/17/2022 01:41:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=45
06/17/2022 01:41:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
06/17/2022 01:41:38 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.6048202959220422 on epoch=46
06/17/2022 01:41:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=47
06/17/2022 01:41:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=47
06/17/2022 01:41:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=48
06/17/2022 01:41:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=49
06/17/2022 01:41:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
06/17/2022 01:41:59 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.6882941158058936 on epoch=49
06/17/2022 01:42:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/17/2022 01:42:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
06/17/2022 01:42:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=52
06/17/2022 01:42:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
06/17/2022 01:42:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/17/2022 01:42:21 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.7769404898409252 on epoch=53
06/17/2022 01:42:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7173620264520958 -> 0.7769404898409252 on epoch=53, global_step=750
06/17/2022 01:42:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=54
06/17/2022 01:42:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
06/17/2022 01:42:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
06/17/2022 01:42:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=56
06/17/2022 01:42:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
06/17/2022 01:42:43 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7248118838607454 on epoch=57
06/17/2022 01:42:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/17/2022 01:42:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
06/17/2022 01:42:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
06/17/2022 01:42:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
06/17/2022 01:42:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/17/2022 01:43:04 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.8121090658893078 on epoch=60
06/17/2022 01:43:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7769404898409252 -> 0.8121090658893078 on epoch=60, global_step=850
06/17/2022 01:43:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
06/17/2022 01:43:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/17/2022 01:43:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=62
06/17/2022 01:43:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
06/17/2022 01:43:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/17/2022 01:43:26 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8851234514659562 on epoch=64
06/17/2022 01:43:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8121090658893078 -> 0.8851234514659562 on epoch=64, global_step=900
06/17/2022 01:43:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/17/2022 01:43:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
06/17/2022 01:43:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 01:43:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
06/17/2022 01:43:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/17/2022 01:43:48 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.8207892864951969 on epoch=67
06/17/2022 01:43:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
06/17/2022 01:43:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/17/2022 01:43:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
06/17/2022 01:43:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/17/2022 01:44:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/17/2022 01:44:09 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7388586244703728 on epoch=71
06/17/2022 01:44:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
06/17/2022 01:44:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
06/17/2022 01:44:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
06/17/2022 01:44:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
06/17/2022 01:44:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/17/2022 01:44:31 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8281757261833164 on epoch=74
06/17/2022 01:44:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/17/2022 01:44:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
06/17/2022 01:44:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/17/2022 01:44:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/17/2022 01:44:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
06/17/2022 01:44:52 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7788601496604622 on epoch=78
06/17/2022 01:44:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/17/2022 01:44:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=79
06/17/2022 01:45:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
06/17/2022 01:45:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/17/2022 01:45:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/17/2022 01:45:14 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.8279063678257226 on epoch=82
06/17/2022 01:45:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/17/2022 01:45:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/17/2022 01:45:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/17/2022 01:45:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/17/2022 01:45:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/17/2022 01:45:36 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8208872793787405 on epoch=85
06/17/2022 01:45:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/17/2022 01:45:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=87
06/17/2022 01:45:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/17/2022 01:45:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/17/2022 01:45:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/17/2022 01:45:57 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8972170060595109 on epoch=89
06/17/2022 01:45:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8851234514659562 -> 0.8972170060595109 on epoch=89, global_step=1250
06/17/2022 01:46:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/17/2022 01:46:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/17/2022 01:46:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/17/2022 01:46:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/17/2022 01:46:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/17/2022 01:46:19 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.8531539301937785 on epoch=92
06/17/2022 01:46:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/17/2022 01:46:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/17/2022 01:46:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/17/2022 01:46:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/17/2022 01:46:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/17/2022 01:46:40 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7932434830540568 on epoch=96
06/17/2022 01:46:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/17/2022 01:46:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/17/2022 01:46:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/17/2022 01:46:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/17/2022 01:46:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/17/2022 01:47:01 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9015467522836822 on epoch=99
06/17/2022 01:47:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8972170060595109 -> 0.9015467522836822 on epoch=99, global_step=1400
06/17/2022 01:47:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/17/2022 01:47:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/17/2022 01:47:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
06/17/2022 01:47:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/17/2022 01:47:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/17/2022 01:47:23 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7949958262200623 on epoch=103
06/17/2022 01:47:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 01:47:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/17/2022 01:47:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/17/2022 01:47:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
06/17/2022 01:47:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/17/2022 01:47:44 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8405634880418443 on epoch=107
06/17/2022 01:47:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/17/2022 01:47:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/17/2022 01:47:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 01:47:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/17/2022 01:47:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/17/2022 01:48:06 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9013845947432285 on epoch=110
06/17/2022 01:48:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/17/2022 01:48:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/17/2022 01:48:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/17/2022 01:48:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/17/2022 01:48:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/17/2022 01:48:27 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7788135591015377 on epoch=114
06/17/2022 01:48:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/17/2022 01:48:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/17/2022 01:48:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/17/2022 01:48:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 01:48:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/17/2022 01:48:49 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9101742280489908 on epoch=117
06/17/2022 01:48:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9015467522836822 -> 0.9101742280489908 on epoch=117, global_step=1650
06/17/2022 01:48:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/17/2022 01:48:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/17/2022 01:48:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/17/2022 01:49:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/17/2022 01:49:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/17/2022 01:49:10 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.8002907908031248 on epoch=121
06/17/2022 01:49:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 01:49:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/17/2022 01:49:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/17/2022 01:49:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/17/2022 01:49:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 01:49:32 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9022729934810897 on epoch=124
06/17/2022 01:49:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/17/2022 01:49:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 01:49:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 01:49:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 01:49:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/17/2022 01:49:53 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9032131425395183 on epoch=128
06/17/2022 01:49:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/17/2022 01:49:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/17/2022 01:50:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 01:50:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/17/2022 01:50:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/17/2022 01:50:15 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8400991602856522 on epoch=132
06/17/2022 01:50:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 01:50:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/17/2022 01:50:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/17/2022 01:50:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/17/2022 01:50:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 01:50:36 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8964862914862916 on epoch=135
06/17/2022 01:50:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 01:50:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/17/2022 01:50:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 01:50:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
06/17/2022 01:50:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 01:50:58 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8434883953785164 on epoch=139
06/17/2022 01:51:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 01:51:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/17/2022 01:51:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/17/2022 01:51:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/17/2022 01:51:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/17/2022 01:51:19 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8429205203398752 on epoch=142
06/17/2022 01:51:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/17/2022 01:51:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/17/2022 01:51:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 01:51:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/17/2022 01:51:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/17/2022 01:51:41 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8935644578908336 on epoch=146
06/17/2022 01:51:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
06/17/2022 01:51:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/17/2022 01:51:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/17/2022 01:51:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/17/2022 01:51:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 01:52:02 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9005226225387515 on epoch=149
06/17/2022 01:52:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/17/2022 01:52:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/17/2022 01:52:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 01:52:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/17/2022 01:52:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
06/17/2022 01:52:23 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9006414579517047 on epoch=153
06/17/2022 01:52:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/17/2022 01:52:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 01:52:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/17/2022 01:52:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 01:52:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 01:52:45 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8464027152283201 on epoch=157
06/17/2022 01:52:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/17/2022 01:52:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/17/2022 01:52:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 01:52:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/17/2022 01:53:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
06/17/2022 01:53:07 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.8509894882212163 on epoch=160
06/17/2022 01:53:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/17/2022 01:53:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/17/2022 01:53:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/17/2022 01:53:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 01:53:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/17/2022 01:53:28 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9688721896383188 on epoch=164
06/17/2022 01:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9101742280489908 -> 0.9688721896383188 on epoch=164, global_step=2300
06/17/2022 01:53:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 01:53:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 01:53:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/17/2022 01:53:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
06/17/2022 01:53:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 01:53:50 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9101742280489908 on epoch=167
06/17/2022 01:53:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 01:53:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/17/2022 01:53:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/17/2022 01:54:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/17/2022 01:54:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 01:54:11 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9776444302061 on epoch=171
06/17/2022 01:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9688721896383188 -> 0.9776444302061 on epoch=171, global_step=2400
06/17/2022 01:54:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/17/2022 01:54:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 01:54:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=173
06/17/2022 01:54:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 01:54:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/17/2022 01:54:33 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9103175972246181 on epoch=174
06/17/2022 01:54:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/17/2022 01:54:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/17/2022 01:54:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/17/2022 01:54:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 01:54:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/17/2022 01:54:54 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.977311719257427 on epoch=178
06/17/2022 01:54:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/17/2022 01:55:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/17/2022 01:55:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/17/2022 01:55:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/17/2022 01:55:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/17/2022 01:55:16 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9100308588733635 on epoch=182
06/17/2022 01:55:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/17/2022 01:55:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/17/2022 01:55:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 01:55:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/17/2022 01:55:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 01:55:37 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9057494297816878 on epoch=185
06/17/2022 01:55:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 01:55:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 01:55:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 01:55:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/17/2022 01:55:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/17/2022 01:55:59 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.972872924829756 on epoch=189
06/17/2022 01:56:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/17/2022 01:56:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/17/2022 01:56:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/17/2022 01:56:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 01:56:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 01:56:20 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9058641922066968 on epoch=192
06/17/2022 01:56:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/17/2022 01:56:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 01:56:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/17/2022 01:56:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 01:56:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/17/2022 01:56:42 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9018654284783316 on epoch=196
06/17/2022 01:56:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 01:56:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 01:56:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 01:56:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/17/2022 01:56:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 01:57:04 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8403765389574274 on epoch=199
06/17/2022 01:57:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 01:57:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 01:57:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/17/2022 01:57:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 01:57:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/17/2022 01:57:25 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9728852464739562 on epoch=203
06/17/2022 01:57:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 01:57:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 01:57:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 01:57:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 01:57:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/17/2022 01:57:47 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.972872924829756 on epoch=207
06/17/2022 01:57:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/17/2022 01:57:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 01:57:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 01:57:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/17/2022 01:58:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 01:58:08 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9728852464739562 on epoch=210
06/17/2022 01:58:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 01:58:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 01:58:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/17/2022 01:58:20 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 01:58:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 01:58:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:58:24 - INFO - __main__ - Printing 3 examples
06/17/2022 01:58:24 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 01:58:24 - INFO - __main__ - ['Plant']
06/17/2022 01:58:24 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 01:58:24 - INFO - __main__ - ['Plant']
06/17/2022 01:58:24 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 01:58:24 - INFO - __main__ - ['Plant']
06/17/2022 01:58:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:58:25 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:58:25 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 01:58:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 01:58:25 - INFO - __main__ - Printing 3 examples
06/17/2022 01:58:25 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 01:58:25 - INFO - __main__ - ['Plant']
06/17/2022 01:58:25 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 01:58:25 - INFO - __main__ - ['Plant']
06/17/2022 01:58:25 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 01:58:25 - INFO - __main__ - ['Plant']
06/17/2022 01:58:25 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:58:25 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:58:25 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 01:58:30 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.84334448313783 on epoch=214
06/17/2022 01:58:30 - INFO - __main__ - save last model!
06/17/2022 01:58:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 01:58:30 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 01:58:30 - INFO - __main__ - Printing 3 examples
06/17/2022 01:58:30 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 01:58:30 - INFO - __main__ - ['Animal']
06/17/2022 01:58:30 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 01:58:30 - INFO - __main__ - ['Animal']
06/17/2022 01:58:30 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 01:58:30 - INFO - __main__ - ['Village']
06/17/2022 01:58:30 - INFO - __main__ - Tokenizing Input ...
06/17/2022 01:58:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 01:58:36 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 01:58:43 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 01:58:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 01:58:44 - INFO - __main__ - Starting training!
06/17/2022 02:00:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/17/2022 02:00:50 - INFO - __main__ - Classification-F1 on test data: 0.5924
06/17/2022 02:00:51 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9776444302061, test_performance=0.5924333362962501
06/17/2022 02:00:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/17/2022 02:00:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:00:52 - INFO - __main__ - Printing 3 examples
06/17/2022 02:00:52 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 02:00:52 - INFO - __main__ - ['Plant']
06/17/2022 02:00:52 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 02:00:52 - INFO - __main__ - ['Plant']
06/17/2022 02:00:52 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 02:00:52 - INFO - __main__ - ['Plant']
06/17/2022 02:00:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:00:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:00:52 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 02:00:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:00:52 - INFO - __main__ - Printing 3 examples
06/17/2022 02:00:52 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 02:00:52 - INFO - __main__ - ['Plant']
06/17/2022 02:00:52 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 02:00:52 - INFO - __main__ - ['Plant']
06/17/2022 02:00:52 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 02:00:52 - INFO - __main__ - ['Plant']
06/17/2022 02:00:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:00:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:00:52 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 02:01:07 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:01:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 02:01:08 - INFO - __main__ - Starting training!
06/17/2022 02:01:12 - INFO - __main__ - Step 10 Global step 10 Train loss 6.50 on epoch=0
06/17/2022 02:01:15 - INFO - __main__ - Step 20 Global step 20 Train loss 5.16 on epoch=1
06/17/2022 02:01:18 - INFO - __main__ - Step 30 Global step 30 Train loss 4.51 on epoch=2
06/17/2022 02:01:21 - INFO - __main__ - Step 40 Global step 40 Train loss 3.78 on epoch=2
06/17/2022 02:01:24 - INFO - __main__ - Step 50 Global step 50 Train loss 3.49 on epoch=3
06/17/2022 02:01:29 - INFO - __main__ - Global step 50 Train loss 4.69 Classification-F1 0.05145214602659055 on epoch=3
06/17/2022 02:01:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05145214602659055 on epoch=3, global_step=50
06/17/2022 02:01:32 - INFO - __main__ - Step 60 Global step 60 Train loss 3.20 on epoch=4
06/17/2022 02:01:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.90 on epoch=4
06/17/2022 02:01:38 - INFO - __main__ - Step 80 Global step 80 Train loss 2.60 on epoch=5
06/17/2022 02:01:41 - INFO - __main__ - Step 90 Global step 90 Train loss 2.48 on epoch=6
06/17/2022 02:01:44 - INFO - __main__ - Step 100 Global step 100 Train loss 2.28 on epoch=7
06/17/2022 02:01:49 - INFO - __main__ - Global step 100 Train loss 2.69 Classification-F1 0.11828802758294024 on epoch=7
06/17/2022 02:01:49 - INFO - __main__ - Saving model with best Classification-F1: 0.05145214602659055 -> 0.11828802758294024 on epoch=7, global_step=100
06/17/2022 02:01:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.98 on epoch=7
06/17/2022 02:01:55 - INFO - __main__ - Step 120 Global step 120 Train loss 2.03 on epoch=8
06/17/2022 02:01:58 - INFO - __main__ - Step 130 Global step 130 Train loss 1.66 on epoch=9
06/17/2022 02:02:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.61 on epoch=9
06/17/2022 02:02:04 - INFO - __main__ - Step 150 Global step 150 Train loss 1.53 on epoch=10
06/17/2022 02:02:10 - INFO - __main__ - Global step 150 Train loss 1.76 Classification-F1 0.1676673713883016 on epoch=10
06/17/2022 02:02:10 - INFO - __main__ - Saving model with best Classification-F1: 0.11828802758294024 -> 0.1676673713883016 on epoch=10, global_step=150
06/17/2022 02:02:13 - INFO - __main__ - Step 160 Global step 160 Train loss 1.46 on epoch=11
06/17/2022 02:02:16 - INFO - __main__ - Step 170 Global step 170 Train loss 1.39 on epoch=12
06/17/2022 02:02:18 - INFO - __main__ - Step 180 Global step 180 Train loss 1.34 on epoch=12
06/17/2022 02:02:21 - INFO - __main__ - Step 190 Global step 190 Train loss 1.19 on epoch=13
06/17/2022 02:02:24 - INFO - __main__ - Step 200 Global step 200 Train loss 1.01 on epoch=14
06/17/2022 02:02:31 - INFO - __main__ - Global step 200 Train loss 1.28 Classification-F1 0.236215804609914 on epoch=14
06/17/2022 02:02:31 - INFO - __main__ - Saving model with best Classification-F1: 0.1676673713883016 -> 0.236215804609914 on epoch=14, global_step=200
06/17/2022 02:02:34 - INFO - __main__ - Step 210 Global step 210 Train loss 1.15 on epoch=14
06/17/2022 02:02:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.91 on epoch=15
06/17/2022 02:02:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.89 on epoch=16
06/17/2022 02:02:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.96 on epoch=17
06/17/2022 02:02:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.77 on epoch=17
06/17/2022 02:02:52 - INFO - __main__ - Global step 250 Train loss 0.94 Classification-F1 0.33644852253529156 on epoch=17
06/17/2022 02:02:52 - INFO - __main__ - Saving model with best Classification-F1: 0.236215804609914 -> 0.33644852253529156 on epoch=17, global_step=250
06/17/2022 02:02:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=18
06/17/2022 02:02:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.71 on epoch=19
06/17/2022 02:03:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=19
06/17/2022 02:03:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=20
06/17/2022 02:03:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=21
06/17/2022 02:03:14 - INFO - __main__ - Global step 300 Train loss 0.63 Classification-F1 0.4987418756471176 on epoch=21
06/17/2022 02:03:14 - INFO - __main__ - Saving model with best Classification-F1: 0.33644852253529156 -> 0.4987418756471176 on epoch=21, global_step=300
06/17/2022 02:03:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=22
06/17/2022 02:03:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=22
06/17/2022 02:03:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/17/2022 02:03:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=24
06/17/2022 02:03:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=24
06/17/2022 02:03:36 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.5871594196717349 on epoch=24
06/17/2022 02:03:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4987418756471176 -> 0.5871594196717349 on epoch=24, global_step=350
06/17/2022 02:03:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=25
06/17/2022 02:03:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
06/17/2022 02:03:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=27
06/17/2022 02:03:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=27
06/17/2022 02:03:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=28
06/17/2022 02:03:58 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.5735120932238348 on epoch=28
06/17/2022 02:04:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
06/17/2022 02:04:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=29
06/17/2022 02:04:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
06/17/2022 02:04:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/17/2022 02:04:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
06/17/2022 02:04:20 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.589541880238614 on epoch=32
06/17/2022 02:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5871594196717349 -> 0.589541880238614 on epoch=32, global_step=450
06/17/2022 02:04:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=32
06/17/2022 02:04:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=33
06/17/2022 02:04:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
06/17/2022 02:04:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=34
06/17/2022 02:04:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/17/2022 02:04:43 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6521834897119936 on epoch=35
06/17/2022 02:04:43 - INFO - __main__ - Saving model with best Classification-F1: 0.589541880238614 -> 0.6521834897119936 on epoch=35, global_step=500
06/17/2022 02:04:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/17/2022 02:04:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=37
06/17/2022 02:04:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=37
06/17/2022 02:04:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/17/2022 02:04:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
06/17/2022 02:05:05 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7841144716480056 on epoch=39
06/17/2022 02:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6521834897119936 -> 0.7841144716480056 on epoch=39, global_step=550
06/17/2022 02:05:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/17/2022 02:05:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=40
06/17/2022 02:05:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
06/17/2022 02:05:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
06/17/2022 02:05:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=42
06/17/2022 02:05:27 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7070557315976203 on epoch=42
06/17/2022 02:05:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
06/17/2022 02:05:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
06/17/2022 02:05:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/17/2022 02:05:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=45
06/17/2022 02:05:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
06/17/2022 02:05:49 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7004705818545758 on epoch=46
06/17/2022 02:05:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=47
06/17/2022 02:05:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
06/17/2022 02:05:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
06/17/2022 02:06:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/17/2022 02:06:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/17/2022 02:06:11 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.6997722012877743 on epoch=49
06/17/2022 02:06:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/17/2022 02:06:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
06/17/2022 02:06:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
06/17/2022 02:06:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
06/17/2022 02:06:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
06/17/2022 02:06:33 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6411106030334366 on epoch=53
06/17/2022 02:06:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
06/17/2022 02:06:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/17/2022 02:06:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/17/2022 02:06:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/17/2022 02:06:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/17/2022 02:06:55 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7970083614394287 on epoch=57
06/17/2022 02:06:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7841144716480056 -> 0.7970083614394287 on epoch=57, global_step=800
06/17/2022 02:06:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=57
06/17/2022 02:07:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/17/2022 02:07:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/17/2022 02:07:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=59
06/17/2022 02:07:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/17/2022 02:07:17 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.741777378287762 on epoch=60
06/17/2022 02:07:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
06/17/2022 02:07:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/17/2022 02:07:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/17/2022 02:07:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
06/17/2022 02:07:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
06/17/2022 02:07:39 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7091400707699519 on epoch=64
06/17/2022 02:07:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
06/17/2022 02:07:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
06/17/2022 02:07:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 02:07:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=67
06/17/2022 02:07:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
06/17/2022 02:08:01 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7054961140787498 on epoch=67
06/17/2022 02:08:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/17/2022 02:08:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/17/2022 02:08:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/17/2022 02:08:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/17/2022 02:08:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/17/2022 02:08:23 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.9030746609494237 on epoch=71
06/17/2022 02:08:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7970083614394287 -> 0.9030746609494237 on epoch=71, global_step=1000
06/17/2022 02:08:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/17/2022 02:08:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/17/2022 02:08:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/17/2022 02:08:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/17/2022 02:08:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/17/2022 02:08:45 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8369211265884653 on epoch=74
06/17/2022 02:08:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=75
06/17/2022 02:08:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/17/2022 02:08:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/17/2022 02:08:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/17/2022 02:09:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
06/17/2022 02:09:07 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9121813965077723 on epoch=78
06/17/2022 02:09:07 - INFO - __main__ - Saving model with best Classification-F1: 0.9030746609494237 -> 0.9121813965077723 on epoch=78, global_step=1100
06/17/2022 02:09:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/17/2022 02:09:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/17/2022 02:09:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/17/2022 02:09:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/17/2022 02:09:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/17/2022 02:09:30 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.9688016188880244 on epoch=82
06/17/2022 02:09:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9121813965077723 -> 0.9688016188880244 on epoch=82, global_step=1150
06/17/2022 02:09:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/17/2022 02:09:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 02:09:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
06/17/2022 02:09:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/17/2022 02:09:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/17/2022 02:09:52 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9146227454813792 on epoch=85
06/17/2022 02:09:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
06/17/2022 02:09:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/17/2022 02:10:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/17/2022 02:10:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/17/2022 02:10:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/17/2022 02:10:13 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.9101611944875702 on epoch=89
06/17/2022 02:10:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/17/2022 02:10:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
06/17/2022 02:10:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/17/2022 02:10:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/17/2022 02:10:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=92
06/17/2022 02:10:35 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.9776487941217543 on epoch=92
06/17/2022 02:10:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9688016188880244 -> 0.9776487941217543 on epoch=92, global_step=1300
06/17/2022 02:10:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/17/2022 02:10:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/17/2022 02:10:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/17/2022 02:10:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
06/17/2022 02:10:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/17/2022 02:10:57 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9019753033178082 on epoch=96
06/17/2022 02:11:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/17/2022 02:11:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/17/2022 02:11:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
06/17/2022 02:11:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/17/2022 02:11:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/17/2022 02:11:19 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.9775214704650187 on epoch=99
06/17/2022 02:11:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/17/2022 02:11:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/17/2022 02:11:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/17/2022 02:11:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/17/2022 02:11:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/17/2022 02:11:41 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.910198761811665 on epoch=103
06/17/2022 02:11:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 02:11:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/17/2022 02:11:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/17/2022 02:11:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/17/2022 02:11:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/17/2022 02:12:03 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9103086366511415 on epoch=107
06/17/2022 02:12:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/17/2022 02:12:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/17/2022 02:12:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/17/2022 02:12:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/17/2022 02:12:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/17/2022 02:12:25 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7762497794142431 on epoch=110
06/17/2022 02:12:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
06/17/2022 02:12:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/17/2022 02:12:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/17/2022 02:12:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/17/2022 02:12:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/17/2022 02:12:47 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8258495076600263 on epoch=114
06/17/2022 02:12:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/17/2022 02:12:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/17/2022 02:12:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/17/2022 02:12:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/17/2022 02:13:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/17/2022 02:13:08 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7803757280038115 on epoch=117
06/17/2022 02:13:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/17/2022 02:13:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/17/2022 02:13:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/17/2022 02:13:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/17/2022 02:13:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/17/2022 02:13:30 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8320583739929889 on epoch=121
06/17/2022 02:13:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/17/2022 02:13:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/17/2022 02:13:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/17/2022 02:13:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/17/2022 02:13:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 02:13:52 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9641188541348384 on epoch=124
06/17/2022 02:13:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/17/2022 02:13:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/17/2022 02:14:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/17/2022 02:14:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/17/2022 02:14:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/17/2022 02:14:14 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8276742460180553 on epoch=128
06/17/2022 02:14:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/17/2022 02:14:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 02:14:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/17/2022 02:14:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/17/2022 02:14:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/17/2022 02:14:35 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8318531316485539 on epoch=132
06/17/2022 02:14:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/17/2022 02:14:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/17/2022 02:14:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/17/2022 02:14:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/17/2022 02:14:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=135
06/17/2022 02:14:57 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.889239165852069 on epoch=135
06/17/2022 02:15:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/17/2022 02:15:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/17/2022 02:15:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 02:15:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 02:15:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/17/2022 02:15:19 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7785455712386733 on epoch=139
06/17/2022 02:15:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/17/2022 02:15:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/17/2022 02:15:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/17/2022 02:15:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/17/2022 02:15:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/17/2022 02:15:41 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7741215875689589 on epoch=142
06/17/2022 02:15:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/17/2022 02:15:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/17/2022 02:15:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 02:15:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/17/2022 02:15:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=146
06/17/2022 02:16:02 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7823918570360696 on epoch=146
06/17/2022 02:16:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 02:16:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/17/2022 02:16:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/17/2022 02:16:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/17/2022 02:16:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 02:16:24 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.901673733672523 on epoch=149
06/17/2022 02:16:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/17/2022 02:16:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
06/17/2022 02:16:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/17/2022 02:16:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/17/2022 02:16:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/17/2022 02:16:46 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.9101938742261323 on epoch=153
06/17/2022 02:16:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/17/2022 02:16:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/17/2022 02:16:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/17/2022 02:16:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/17/2022 02:17:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 02:17:08 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8869724194550799 on epoch=157
06/17/2022 02:17:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/17/2022 02:17:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/17/2022 02:17:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 02:17:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 02:17:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 02:17:30 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9599215077037658 on epoch=160
06/17/2022 02:17:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/17/2022 02:17:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 02:17:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/17/2022 02:17:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/17/2022 02:17:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/17/2022 02:17:51 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9061509305579515 on epoch=164
06/17/2022 02:17:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 02:17:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 02:18:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/17/2022 02:18:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 02:18:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 02:18:13 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8937113271506062 on epoch=167
06/17/2022 02:18:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/17/2022 02:18:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 02:18:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 02:18:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/17/2022 02:18:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/17/2022 02:18:35 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8977979510474767 on epoch=171
06/17/2022 02:18:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/17/2022 02:18:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 02:18:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 02:18:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/17/2022 02:18:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/17/2022 02:18:57 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9594590182113902 on epoch=174
06/17/2022 02:19:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/17/2022 02:19:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/17/2022 02:19:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 02:19:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/17/2022 02:19:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/17/2022 02:19:19 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9642305235877343 on epoch=178
06/17/2022 02:19:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/17/2022 02:19:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 02:19:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/17/2022 02:19:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/17/2022 02:19:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 02:19:40 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9016975255400301 on epoch=182
06/17/2022 02:19:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/17/2022 02:19:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 02:19:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 02:19:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 02:19:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/17/2022 02:20:02 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8434719287275028 on epoch=185
06/17/2022 02:20:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 02:20:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/17/2022 02:20:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/17/2022 02:20:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/17/2022 02:20:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/17/2022 02:20:24 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9019556571406667 on epoch=189
06/17/2022 02:20:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/17/2022 02:20:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/17/2022 02:20:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/17/2022 02:20:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 02:20:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 02:20:46 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9061338240085869 on epoch=192
06/17/2022 02:20:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/17/2022 02:20:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/17/2022 02:20:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 02:20:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/17/2022 02:21:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 02:21:07 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9683736251098678 on epoch=196
06/17/2022 02:21:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/17/2022 02:21:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 02:21:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/17/2022 02:21:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/17/2022 02:21:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 02:21:29 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9683736251098678 on epoch=199
06/17/2022 02:21:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/17/2022 02:21:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/17/2022 02:21:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/17/2022 02:21:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/17/2022 02:21:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/17/2022 02:21:51 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9015500833764588 on epoch=203
06/17/2022 02:21:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/17/2022 02:21:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 02:22:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 02:22:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/17/2022 02:22:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/17/2022 02:22:13 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9639189400100214 on epoch=207
06/17/2022 02:22:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/17/2022 02:22:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 02:22:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 02:22:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/17/2022 02:22:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/17/2022 02:22:35 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9688721896383188 on epoch=210
06/17/2022 02:22:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/17/2022 02:22:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 02:22:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
06/17/2022 02:22:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/17/2022 02:22:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 02:22:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:22:51 - INFO - __main__ - Printing 3 examples
06/17/2022 02:22:51 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 02:22:51 - INFO - __main__ - ['Plant']
06/17/2022 02:22:51 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 02:22:51 - INFO - __main__ - ['Plant']
06/17/2022 02:22:51 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 02:22:51 - INFO - __main__ - ['Plant']
06/17/2022 02:22:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:22:51 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:22:51 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 02:22:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:22:51 - INFO - __main__ - Printing 3 examples
06/17/2022 02:22:51 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 02:22:51 - INFO - __main__ - ['Plant']
06/17/2022 02:22:51 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 02:22:51 - INFO - __main__ - ['Plant']
06/17/2022 02:22:51 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 02:22:51 - INFO - __main__ - ['Plant']
06/17/2022 02:22:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:22:51 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:22:52 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 02:22:57 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9687158587775286 on epoch=214
06/17/2022 02:22:57 - INFO - __main__ - save last model!
06/17/2022 02:22:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 02:22:57 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 02:22:57 - INFO - __main__ - Printing 3 examples
06/17/2022 02:22:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 02:22:57 - INFO - __main__ - ['Animal']
06/17/2022 02:22:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 02:22:57 - INFO - __main__ - ['Animal']
06/17/2022 02:22:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 02:22:57 - INFO - __main__ - ['Village']
06/17/2022 02:22:57 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:22:59 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:23:02 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 02:23:10 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:23:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 02:23:11 - INFO - __main__ - Starting training!
06/17/2022 02:25:21 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/17/2022 02:25:21 - INFO - __main__ - Classification-F1 on test data: 0.5918
06/17/2022 02:25:21 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9776487941217543, test_performance=0.5918477030222474
06/17/2022 02:25:21 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/17/2022 02:25:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:25:22 - INFO - __main__ - Printing 3 examples
06/17/2022 02:25:22 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/17/2022 02:25:22 - INFO - __main__ - ['Plant']
06/17/2022 02:25:22 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/17/2022 02:25:22 - INFO - __main__ - ['Plant']
06/17/2022 02:25:22 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/17/2022 02:25:22 - INFO - __main__ - ['Plant']
06/17/2022 02:25:22 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:25:22 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:25:23 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 02:25:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:25:23 - INFO - __main__ - Printing 3 examples
06/17/2022 02:25:23 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/17/2022 02:25:23 - INFO - __main__ - ['Plant']
06/17/2022 02:25:23 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/17/2022 02:25:23 - INFO - __main__ - ['Plant']
06/17/2022 02:25:23 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/17/2022 02:25:23 - INFO - __main__ - ['Plant']
06/17/2022 02:25:23 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:25:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:25:23 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 02:25:38 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:25:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 02:25:39 - INFO - __main__ - Starting training!
06/17/2022 02:25:43 - INFO - __main__ - Step 10 Global step 10 Train loss 7.29 on epoch=0
06/17/2022 02:25:46 - INFO - __main__ - Step 20 Global step 20 Train loss 5.83 on epoch=1
06/17/2022 02:25:49 - INFO - __main__ - Step 30 Global step 30 Train loss 5.08 on epoch=2
06/17/2022 02:25:52 - INFO - __main__ - Step 40 Global step 40 Train loss 4.25 on epoch=2
06/17/2022 02:25:55 - INFO - __main__ - Step 50 Global step 50 Train loss 4.22 on epoch=3
06/17/2022 02:26:00 - INFO - __main__ - Global step 50 Train loss 5.33 Classification-F1 0.02074074074074074 on epoch=3
06/17/2022 02:26:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02074074074074074 on epoch=3, global_step=50
06/17/2022 02:26:03 - INFO - __main__ - Step 60 Global step 60 Train loss 3.60 on epoch=4
06/17/2022 02:26:06 - INFO - __main__ - Step 70 Global step 70 Train loss 3.58 on epoch=4
06/17/2022 02:26:09 - INFO - __main__ - Step 80 Global step 80 Train loss 3.24 on epoch=5
06/17/2022 02:26:12 - INFO - __main__ - Step 90 Global step 90 Train loss 3.08 on epoch=6
06/17/2022 02:26:15 - INFO - __main__ - Step 100 Global step 100 Train loss 3.08 on epoch=7
06/17/2022 02:26:20 - INFO - __main__ - Global step 100 Train loss 3.32 Classification-F1 0.0828004698305032 on epoch=7
06/17/2022 02:26:20 - INFO - __main__ - Saving model with best Classification-F1: 0.02074074074074074 -> 0.0828004698305032 on epoch=7, global_step=100
06/17/2022 02:26:23 - INFO - __main__ - Step 110 Global step 110 Train loss 2.47 on epoch=7
06/17/2022 02:26:26 - INFO - __main__ - Step 120 Global step 120 Train loss 2.66 on epoch=8
06/17/2022 02:26:29 - INFO - __main__ - Step 130 Global step 130 Train loss 2.29 on epoch=9
06/17/2022 02:26:32 - INFO - __main__ - Step 140 Global step 140 Train loss 2.32 on epoch=9
06/17/2022 02:26:35 - INFO - __main__ - Step 150 Global step 150 Train loss 2.12 on epoch=10
06/17/2022 02:26:39 - INFO - __main__ - Global step 150 Train loss 2.37 Classification-F1 0.12341893148659577 on epoch=10
06/17/2022 02:26:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0828004698305032 -> 0.12341893148659577 on epoch=10, global_step=150
06/17/2022 02:26:42 - INFO - __main__ - Step 160 Global step 160 Train loss 1.98 on epoch=11
06/17/2022 02:26:45 - INFO - __main__ - Step 170 Global step 170 Train loss 2.08 on epoch=12
06/17/2022 02:26:48 - INFO - __main__ - Step 180 Global step 180 Train loss 1.73 on epoch=12
06/17/2022 02:26:51 - INFO - __main__ - Step 190 Global step 190 Train loss 1.82 on epoch=13
06/17/2022 02:26:54 - INFO - __main__ - Step 200 Global step 200 Train loss 1.76 on epoch=14
06/17/2022 02:27:00 - INFO - __main__ - Global step 200 Train loss 1.87 Classification-F1 0.1314098842834475 on epoch=14
06/17/2022 02:27:00 - INFO - __main__ - Saving model with best Classification-F1: 0.12341893148659577 -> 0.1314098842834475 on epoch=14, global_step=200
06/17/2022 02:27:03 - INFO - __main__ - Step 210 Global step 210 Train loss 1.63 on epoch=14
06/17/2022 02:27:05 - INFO - __main__ - Step 220 Global step 220 Train loss 1.63 on epoch=15
06/17/2022 02:27:08 - INFO - __main__ - Step 230 Global step 230 Train loss 1.72 on epoch=16
06/17/2022 02:27:11 - INFO - __main__ - Step 240 Global step 240 Train loss 1.49 on epoch=17
06/17/2022 02:27:14 - INFO - __main__ - Step 250 Global step 250 Train loss 1.37 on epoch=17
06/17/2022 02:27:20 - INFO - __main__ - Global step 250 Train loss 1.57 Classification-F1 0.16669493418262477 on epoch=17
06/17/2022 02:27:20 - INFO - __main__ - Saving model with best Classification-F1: 0.1314098842834475 -> 0.16669493418262477 on epoch=17, global_step=250
06/17/2022 02:27:23 - INFO - __main__ - Step 260 Global step 260 Train loss 1.37 on epoch=18
06/17/2022 02:27:26 - INFO - __main__ - Step 270 Global step 270 Train loss 1.27 on epoch=19
06/17/2022 02:27:29 - INFO - __main__ - Step 280 Global step 280 Train loss 1.24 on epoch=19
06/17/2022 02:27:32 - INFO - __main__ - Step 290 Global step 290 Train loss 1.13 on epoch=20
06/17/2022 02:27:35 - INFO - __main__ - Step 300 Global step 300 Train loss 1.19 on epoch=21
06/17/2022 02:27:40 - INFO - __main__ - Global step 300 Train loss 1.24 Classification-F1 0.19424879776838783 on epoch=21
06/17/2022 02:27:41 - INFO - __main__ - Saving model with best Classification-F1: 0.16669493418262477 -> 0.19424879776838783 on epoch=21, global_step=300
06/17/2022 02:27:43 - INFO - __main__ - Step 310 Global step 310 Train loss 1.15 on epoch=22
06/17/2022 02:27:46 - INFO - __main__ - Step 320 Global step 320 Train loss 1.04 on epoch=22
06/17/2022 02:27:49 - INFO - __main__ - Step 330 Global step 330 Train loss 1.04 on epoch=23
06/17/2022 02:27:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.88 on epoch=24
06/17/2022 02:27:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.86 on epoch=24
06/17/2022 02:28:02 - INFO - __main__ - Global step 350 Train loss 0.99 Classification-F1 0.26838435386036585 on epoch=24
06/17/2022 02:28:02 - INFO - __main__ - Saving model with best Classification-F1: 0.19424879776838783 -> 0.26838435386036585 on epoch=24, global_step=350
06/17/2022 02:28:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.84 on epoch=25
06/17/2022 02:28:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.85 on epoch=26
06/17/2022 02:28:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.83 on epoch=27
06/17/2022 02:28:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.69 on epoch=27
06/17/2022 02:28:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.84 on epoch=28
06/17/2022 02:28:23 - INFO - __main__ - Global step 400 Train loss 0.81 Classification-F1 0.40542021970593395 on epoch=28
06/17/2022 02:28:23 - INFO - __main__ - Saving model with best Classification-F1: 0.26838435386036585 -> 0.40542021970593395 on epoch=28, global_step=400
06/17/2022 02:28:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.68 on epoch=29
06/17/2022 02:28:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.57 on epoch=29
06/17/2022 02:28:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.67 on epoch=30
06/17/2022 02:28:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.54 on epoch=31
06/17/2022 02:28:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=32
06/17/2022 02:28:45 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.5110873678384611 on epoch=32
06/17/2022 02:28:45 - INFO - __main__ - Saving model with best Classification-F1: 0.40542021970593395 -> 0.5110873678384611 on epoch=32, global_step=450
06/17/2022 02:28:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.45 on epoch=32
06/17/2022 02:28:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.56 on epoch=33
06/17/2022 02:28:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=34
06/17/2022 02:28:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=34
06/17/2022 02:29:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=35
06/17/2022 02:29:07 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.5190150532067809 on epoch=35
06/17/2022 02:29:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5110873678384611 -> 0.5190150532067809 on epoch=35, global_step=500
06/17/2022 02:29:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
06/17/2022 02:29:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.46 on epoch=37
06/17/2022 02:29:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=37
06/17/2022 02:29:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=38
06/17/2022 02:29:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=39
06/17/2022 02:29:28 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.5586173483163821 on epoch=39
06/17/2022 02:29:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5190150532067809 -> 0.5586173483163821 on epoch=39, global_step=550
06/17/2022 02:29:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=39
06/17/2022 02:29:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=40
06/17/2022 02:29:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
06/17/2022 02:29:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
06/17/2022 02:29:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
06/17/2022 02:29:50 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.5531229055940857 on epoch=42
06/17/2022 02:29:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=43
06/17/2022 02:29:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=44
06/17/2022 02:29:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=44
06/17/2022 02:30:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=45
06/17/2022 02:30:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
06/17/2022 02:30:12 - INFO - __main__ - Global step 650 Train loss 0.29 Classification-F1 0.5471180549734855 on epoch=46
06/17/2022 02:30:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
06/17/2022 02:30:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
06/17/2022 02:30:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/17/2022 02:30:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
06/17/2022 02:30:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=49
06/17/2022 02:30:34 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.5345522910875078 on epoch=49
06/17/2022 02:30:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=50
06/17/2022 02:30:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/17/2022 02:30:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=52
06/17/2022 02:30:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/17/2022 02:30:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=53
06/17/2022 02:30:56 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.5115909766003007 on epoch=53
06/17/2022 02:30:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=54
06/17/2022 02:31:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=54
06/17/2022 02:31:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
06/17/2022 02:31:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
06/17/2022 02:31:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
06/17/2022 02:31:18 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.5851087749149246 on epoch=57
06/17/2022 02:31:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5586173483163821 -> 0.5851087749149246 on epoch=57, global_step=800
06/17/2022 02:31:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=57
06/17/2022 02:31:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=58
06/17/2022 02:31:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/17/2022 02:31:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=59
06/17/2022 02:31:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
06/17/2022 02:31:41 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6477402925979776 on epoch=60
06/17/2022 02:31:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5851087749149246 -> 0.6477402925979776 on epoch=60, global_step=850
06/17/2022 02:31:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=61
06/17/2022 02:31:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=62
06/17/2022 02:31:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/17/2022 02:31:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
06/17/2022 02:31:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
06/17/2022 02:32:03 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.5885021277239235 on epoch=64
06/17/2022 02:32:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=64
06/17/2022 02:32:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/17/2022 02:32:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=66
06/17/2022 02:32:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/17/2022 02:32:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=67
06/17/2022 02:32:26 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.613823320139395 on epoch=67
06/17/2022 02:32:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=68
06/17/2022 02:32:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
06/17/2022 02:32:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/17/2022 02:32:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/17/2022 02:32:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/17/2022 02:32:48 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6101768322187135 on epoch=71
06/17/2022 02:32:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/17/2022 02:32:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/17/2022 02:32:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/17/2022 02:33:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/17/2022 02:33:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/17/2022 02:33:10 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.5614381778466838 on epoch=74
06/17/2022 02:33:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=75
06/17/2022 02:33:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/17/2022 02:33:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/17/2022 02:33:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
06/17/2022 02:33:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
06/17/2022 02:33:33 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6140089836116467 on epoch=78
06/17/2022 02:33:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
06/17/2022 02:33:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/17/2022 02:33:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/17/2022 02:33:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
06/17/2022 02:33:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/17/2022 02:33:55 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.5993233373061302 on epoch=82
06/17/2022 02:33:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
06/17/2022 02:34:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/17/2022 02:34:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/17/2022 02:34:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/17/2022 02:34:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
06/17/2022 02:34:18 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.65438628754667 on epoch=85
06/17/2022 02:34:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6477402925979776 -> 0.65438628754667 on epoch=85, global_step=1200
06/17/2022 02:34:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.19 on epoch=86
06/17/2022 02:34:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/17/2022 02:34:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
06/17/2022 02:34:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
06/17/2022 02:34:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
06/17/2022 02:34:40 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6167483425432734 on epoch=89
06/17/2022 02:34:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/17/2022 02:34:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
06/17/2022 02:34:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/17/2022 02:34:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=92
06/17/2022 02:34:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/17/2022 02:35:03 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7093420112295575 on epoch=92
06/17/2022 02:35:03 - INFO - __main__ - Saving model with best Classification-F1: 0.65438628754667 -> 0.7093420112295575 on epoch=92, global_step=1300
06/17/2022 02:35:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/17/2022 02:35:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=94
06/17/2022 02:35:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/17/2022 02:35:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
06/17/2022 02:35:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/17/2022 02:35:25 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7225558886612018 on epoch=96
06/17/2022 02:35:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7093420112295575 -> 0.7225558886612018 on epoch=96, global_step=1350
06/17/2022 02:35:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/17/2022 02:35:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/17/2022 02:35:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=98
06/17/2022 02:35:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/17/2022 02:35:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=99
06/17/2022 02:35:48 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6487975246431128 on epoch=99
06/17/2022 02:35:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/17/2022 02:35:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/17/2022 02:35:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/17/2022 02:36:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/17/2022 02:36:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/17/2022 02:36:10 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6909247415589171 on epoch=103
06/17/2022 02:36:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=104
06/17/2022 02:36:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/17/2022 02:36:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=105
06/17/2022 02:36:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/17/2022 02:36:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/17/2022 02:36:33 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8411646776151557 on epoch=107
06/17/2022 02:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7225558886612018 -> 0.8411646776151557 on epoch=107, global_step=1500
06/17/2022 02:36:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/17/2022 02:36:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
06/17/2022 02:36:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 02:36:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
06/17/2022 02:36:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/17/2022 02:36:55 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.844753155111018 on epoch=110
06/17/2022 02:36:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8411646776151557 -> 0.844753155111018 on epoch=110, global_step=1550
06/17/2022 02:36:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/17/2022 02:37:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/17/2022 02:37:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=112
06/17/2022 02:37:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/17/2022 02:37:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/17/2022 02:37:17 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7490140560218426 on epoch=114
06/17/2022 02:37:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/17/2022 02:37:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
06/17/2022 02:37:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/17/2022 02:37:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/17/2022 02:37:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
06/17/2022 02:37:39 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7394053026880351 on epoch=117
06/17/2022 02:37:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=118
06/17/2022 02:37:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/17/2022 02:37:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/17/2022 02:37:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/17/2022 02:37:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/17/2022 02:38:02 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.851398217828187 on epoch=121
06/17/2022 02:38:02 - INFO - __main__ - Saving model with best Classification-F1: 0.844753155111018 -> 0.851398217828187 on epoch=121, global_step=1700
06/17/2022 02:38:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/17/2022 02:38:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=122
06/17/2022 02:38:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
06/17/2022 02:38:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/17/2022 02:38:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/17/2022 02:38:24 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7897790270153257 on epoch=124
06/17/2022 02:38:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/17/2022 02:38:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/17/2022 02:38:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/17/2022 02:38:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=127
06/17/2022 02:38:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/17/2022 02:38:46 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7508375734182187 on epoch=128
06/17/2022 02:38:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
06/17/2022 02:38:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 02:38:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/17/2022 02:38:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/17/2022 02:39:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/17/2022 02:39:09 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7425592499952083 on epoch=132
06/17/2022 02:39:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
06/17/2022 02:39:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/17/2022 02:39:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/17/2022 02:39:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/17/2022 02:39:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/17/2022 02:39:31 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7476063608890934 on epoch=135
06/17/2022 02:39:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
06/17/2022 02:39:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/17/2022 02:39:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/17/2022 02:39:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=138
06/17/2022 02:39:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/17/2022 02:39:53 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.749537715868361 on epoch=139
06/17/2022 02:39:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 02:39:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
06/17/2022 02:40:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/17/2022 02:40:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/17/2022 02:40:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/17/2022 02:40:16 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7417512865023989 on epoch=142
06/17/2022 02:40:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
06/17/2022 02:40:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/17/2022 02:40:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/17/2022 02:40:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/17/2022 02:40:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/17/2022 02:40:38 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7021993216178276 on epoch=146
06/17/2022 02:40:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/17/2022 02:40:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/17/2022 02:40:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/17/2022 02:40:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/17/2022 02:40:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/17/2022 02:41:00 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7418456440564339 on epoch=149
06/17/2022 02:41:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/17/2022 02:41:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/17/2022 02:41:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/17/2022 02:41:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/17/2022 02:41:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/17/2022 02:41:22 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8435895362543845 on epoch=153
06/17/2022 02:41:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/17/2022 02:41:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
06/17/2022 02:41:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=155
06/17/2022 02:41:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/17/2022 02:41:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/17/2022 02:41:45 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7936281697429706 on epoch=157
06/17/2022 02:41:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/17/2022 02:41:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/17/2022 02:41:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/17/2022 02:41:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 02:42:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/17/2022 02:42:07 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6879791120028811 on epoch=160
06/17/2022 02:42:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/17/2022 02:42:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 02:42:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/17/2022 02:42:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/17/2022 02:42:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
06/17/2022 02:42:29 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6503384652981428 on epoch=164
06/17/2022 02:42:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/17/2022 02:42:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=165
06/17/2022 02:42:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/17/2022 02:42:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/17/2022 02:42:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/17/2022 02:42:51 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6860147068551142 on epoch=167
06/17/2022 02:42:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 02:42:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/17/2022 02:43:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/17/2022 02:43:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/17/2022 02:43:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/17/2022 02:43:13 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6944909529337816 on epoch=171
06/17/2022 02:43:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/17/2022 02:43:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/17/2022 02:43:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/17/2022 02:43:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=174
06/17/2022 02:43:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/17/2022 02:43:35 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.7306891427147595 on epoch=174
06/17/2022 02:43:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/17/2022 02:43:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/17/2022 02:43:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=177
06/17/2022 02:43:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/17/2022 02:43:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
06/17/2022 02:43:58 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6880282634739341 on epoch=178
06/17/2022 02:44:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/17/2022 02:44:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 02:44:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/17/2022 02:44:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/17/2022 02:44:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/17/2022 02:44:20 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6914201311022943 on epoch=182
06/17/2022 02:44:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/17/2022 02:44:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/17/2022 02:44:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/17/2022 02:44:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/17/2022 02:44:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/17/2022 02:44:42 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6963619642949015 on epoch=185
06/17/2022 02:44:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/17/2022 02:44:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/17/2022 02:44:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/17/2022 02:44:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/17/2022 02:44:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/17/2022 02:45:04 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6930053841731705 on epoch=189
06/17/2022 02:45:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/17/2022 02:45:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/17/2022 02:45:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/17/2022 02:45:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 02:45:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/17/2022 02:45:26 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.5882461502329537 on epoch=192
06/17/2022 02:45:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/17/2022 02:45:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 02:45:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 02:45:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/17/2022 02:45:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/17/2022 02:45:48 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6210980775496905 on epoch=196
06/17/2022 02:45:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/17/2022 02:45:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/17/2022 02:45:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/17/2022 02:46:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/17/2022 02:46:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/17/2022 02:46:10 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6645711143695016 on epoch=199
06/17/2022 02:46:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/17/2022 02:46:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/17/2022 02:46:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/17/2022 02:46:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/17/2022 02:46:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=203
06/17/2022 02:46:32 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.5977536942529611 on epoch=203
06/17/2022 02:46:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/17/2022 02:46:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 02:46:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/17/2022 02:46:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/17/2022 02:46:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/17/2022 02:46:54 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7072461313760126 on epoch=207
06/17/2022 02:46:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/17/2022 02:47:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/17/2022 02:47:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/17/2022 02:47:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/17/2022 02:47:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/17/2022 02:47:17 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7380117030520257 on epoch=210
06/17/2022 02:47:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/17/2022 02:47:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/17/2022 02:47:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/17/2022 02:47:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/17/2022 02:47:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/17/2022 02:47:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:47:33 - INFO - __main__ - Printing 3 examples
06/17/2022 02:47:33 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 02:47:33 - INFO - __main__ - ['Company']
06/17/2022 02:47:33 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 02:47:33 - INFO - __main__ - ['Company']
06/17/2022 02:47:33 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 02:47:33 - INFO - __main__ - ['Company']
06/17/2022 02:47:33 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:47:34 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:47:34 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 02:47:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:47:34 - INFO - __main__ - Printing 3 examples
06/17/2022 02:47:34 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 02:47:34 - INFO - __main__ - ['Company']
06/17/2022 02:47:34 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 02:47:34 - INFO - __main__ - ['Company']
06/17/2022 02:47:34 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 02:47:34 - INFO - __main__ - ['Company']
06/17/2022 02:47:34 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:47:34 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:47:34 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 02:47:39 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7860990211559472 on epoch=214
06/17/2022 02:47:39 - INFO - __main__ - save last model!
06/17/2022 02:47:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 02:47:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 02:47:39 - INFO - __main__ - Printing 3 examples
06/17/2022 02:47:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 02:47:39 - INFO - __main__ - ['Animal']
06/17/2022 02:47:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 02:47:39 - INFO - __main__ - ['Animal']
06/17/2022 02:47:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 02:47:39 - INFO - __main__ - ['Village']
06/17/2022 02:47:39 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:47:41 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:47:44 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 02:47:52 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:47:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 02:47:53 - INFO - __main__ - Starting training!
06/17/2022 02:50:02 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/17/2022 02:50:02 - INFO - __main__ - Classification-F1 on test data: 0.4338
06/17/2022 02:50:02 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.851398217828187, test_performance=0.4338417945407387
06/17/2022 02:50:02 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/17/2022 02:50:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:50:03 - INFO - __main__ - Printing 3 examples
06/17/2022 02:50:03 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 02:50:03 - INFO - __main__ - ['Company']
06/17/2022 02:50:03 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 02:50:03 - INFO - __main__ - ['Company']
06/17/2022 02:50:03 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 02:50:03 - INFO - __main__ - ['Company']
06/17/2022 02:50:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:50:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:50:04 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 02:50:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 02:50:04 - INFO - __main__ - Printing 3 examples
06/17/2022 02:50:04 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 02:50:04 - INFO - __main__ - ['Company']
06/17/2022 02:50:04 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 02:50:04 - INFO - __main__ - ['Company']
06/17/2022 02:50:04 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 02:50:04 - INFO - __main__ - ['Company']
06/17/2022 02:50:04 - INFO - __main__ - Tokenizing Input ...
06/17/2022 02:50:04 - INFO - __main__ - Tokenizing Output ...
06/17/2022 02:50:04 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 02:50:23 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 02:50:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 02:50:23 - INFO - __main__ - Starting training!
06/17/2022 02:50:27 - INFO - __main__ - Step 10 Global step 10 Train loss 7.15 on epoch=0
06/17/2022 02:50:30 - INFO - __main__ - Step 20 Global step 20 Train loss 4.71 on epoch=1
06/17/2022 02:50:33 - INFO - __main__ - Step 30 Global step 30 Train loss 4.12 on epoch=2
06/17/2022 02:50:36 - INFO - __main__ - Step 40 Global step 40 Train loss 3.67 on epoch=2
06/17/2022 02:50:39 - INFO - __main__ - Step 50 Global step 50 Train loss 2.85 on epoch=3
06/17/2022 02:50:45 - INFO - __main__ - Global step 50 Train loss 4.50 Classification-F1 0.08590724073378712 on epoch=3
06/17/2022 02:50:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08590724073378712 on epoch=3, global_step=50
06/17/2022 02:50:48 - INFO - __main__ - Step 60 Global step 60 Train loss 2.62 on epoch=4
06/17/2022 02:50:51 - INFO - __main__ - Step 70 Global step 70 Train loss 2.41 on epoch=4
06/17/2022 02:50:54 - INFO - __main__ - Step 80 Global step 80 Train loss 2.16 on epoch=5
06/17/2022 02:50:57 - INFO - __main__ - Step 90 Global step 90 Train loss 1.96 on epoch=6
06/17/2022 02:51:00 - INFO - __main__ - Step 100 Global step 100 Train loss 1.81 on epoch=7
06/17/2022 02:51:06 - INFO - __main__ - Global step 100 Train loss 2.19 Classification-F1 0.13512163216651157 on epoch=7
06/17/2022 02:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.08590724073378712 -> 0.13512163216651157 on epoch=7, global_step=100
06/17/2022 02:51:09 - INFO - __main__ - Step 110 Global step 110 Train loss 1.45 on epoch=7
06/17/2022 02:51:12 - INFO - __main__ - Step 120 Global step 120 Train loss 1.27 on epoch=8
06/17/2022 02:51:15 - INFO - __main__ - Step 130 Global step 130 Train loss 1.22 on epoch=9
06/17/2022 02:51:18 - INFO - __main__ - Step 140 Global step 140 Train loss 1.21 on epoch=9
06/17/2022 02:51:21 - INFO - __main__ - Step 150 Global step 150 Train loss 1.02 on epoch=10
06/17/2022 02:51:28 - INFO - __main__ - Global step 150 Train loss 1.23 Classification-F1 0.23055158819462715 on epoch=10
06/17/2022 02:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.13512163216651157 -> 0.23055158819462715 on epoch=10, global_step=150
06/17/2022 02:51:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=11
06/17/2022 02:51:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=12
06/17/2022 02:51:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=12
06/17/2022 02:51:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=13
06/17/2022 02:51:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
06/17/2022 02:51:50 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.463203498872761 on epoch=14
06/17/2022 02:51:50 - INFO - __main__ - Saving model with best Classification-F1: 0.23055158819462715 -> 0.463203498872761 on epoch=14, global_step=200
06/17/2022 02:51:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=14
06/17/2022 02:51:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=15
06/17/2022 02:51:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
06/17/2022 02:52:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=17
06/17/2022 02:52:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=17
06/17/2022 02:52:13 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.5034133311126048 on epoch=17
06/17/2022 02:52:13 - INFO - __main__ - Saving model with best Classification-F1: 0.463203498872761 -> 0.5034133311126048 on epoch=17, global_step=250
06/17/2022 02:52:16 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=18
06/17/2022 02:52:19 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=19
06/17/2022 02:52:22 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=19
06/17/2022 02:52:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=20
06/17/2022 02:52:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=21
06/17/2022 02:52:35 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.6616378612110477 on epoch=21
06/17/2022 02:52:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5034133311126048 -> 0.6616378612110477 on epoch=21, global_step=300
06/17/2022 02:52:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=22
06/17/2022 02:52:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=22
06/17/2022 02:52:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.18 on epoch=23
06/17/2022 02:52:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=24
06/17/2022 02:52:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=24
06/17/2022 02:52:58 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.8016044631332258 on epoch=24
06/17/2022 02:52:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6616378612110477 -> 0.8016044631332258 on epoch=24, global_step=350
06/17/2022 02:53:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=25
06/17/2022 02:53:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=26
06/17/2022 02:53:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=27
06/17/2022 02:53:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=27
06/17/2022 02:53:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=28
06/17/2022 02:53:20 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.7007724301841949 on epoch=28
06/17/2022 02:53:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=29
06/17/2022 02:53:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=29
06/17/2022 02:53:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.11 on epoch=30
06/17/2022 02:53:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=31
06/17/2022 02:53:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=32
06/17/2022 02:53:43 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.7809482254174743 on epoch=32
06/17/2022 02:53:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=32
06/17/2022 02:53:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
06/17/2022 02:53:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
06/17/2022 02:53:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=34
06/17/2022 02:53:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=35
06/17/2022 02:54:05 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.7256856049959498 on epoch=35
06/17/2022 02:54:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
06/17/2022 02:54:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=37
06/17/2022 02:54:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=37
06/17/2022 02:54:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=38
06/17/2022 02:54:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
06/17/2022 02:54:28 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.9500149419606496 on epoch=39
06/17/2022 02:54:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8016044631332258 -> 0.9500149419606496 on epoch=39, global_step=550
06/17/2022 02:54:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
06/17/2022 02:54:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/17/2022 02:54:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
06/17/2022 02:54:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=42
06/17/2022 02:54:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=42
06/17/2022 02:54:51 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.8481051878229298 on epoch=42
06/17/2022 02:54:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
06/17/2022 02:54:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
06/17/2022 02:55:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
06/17/2022 02:55:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=45
06/17/2022 02:55:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/17/2022 02:55:13 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7433478363649141 on epoch=46
06/17/2022 02:55:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
06/17/2022 02:55:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/17/2022 02:55:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/17/2022 02:55:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=49
06/17/2022 02:55:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
06/17/2022 02:55:35 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7951115851258166 on epoch=49
06/17/2022 02:55:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=50
06/17/2022 02:55:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
06/17/2022 02:55:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
06/17/2022 02:55:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
06/17/2022 02:55:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=53
06/17/2022 02:55:57 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.8380488471048244 on epoch=53
06/17/2022 02:56:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=54
06/17/2022 02:56:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
06/17/2022 02:56:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/17/2022 02:56:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
06/17/2022 02:56:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
06/17/2022 02:56:20 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.7921596351150432 on epoch=57
06/17/2022 02:56:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
06/17/2022 02:56:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
06/17/2022 02:56:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
06/17/2022 02:56:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/17/2022 02:56:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/17/2022 02:56:42 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.8550708699902249 on epoch=60
06/17/2022 02:56:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
06/17/2022 02:56:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
06/17/2022 02:56:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=62
06/17/2022 02:56:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/17/2022 02:56:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/17/2022 02:57:05 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.8503433950180335 on epoch=64
06/17/2022 02:57:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/17/2022 02:57:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
06/17/2022 02:57:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
06/17/2022 02:57:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=67
06/17/2022 02:57:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/17/2022 02:57:27 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.8503433950180335 on epoch=67
06/17/2022 02:57:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
06/17/2022 02:57:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=69
06/17/2022 02:57:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
06/17/2022 02:57:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/17/2022 02:57:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
06/17/2022 02:57:49 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.8543878720463816 on epoch=71
06/17/2022 02:57:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/17/2022 02:57:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/17/2022 02:57:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
06/17/2022 02:58:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=74
06/17/2022 02:58:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
06/17/2022 02:58:11 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7970480420907367 on epoch=74
06/17/2022 02:58:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/17/2022 02:58:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
06/17/2022 02:58:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/17/2022 02:58:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/17/2022 02:58:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/17/2022 02:58:34 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8503433950180335 on epoch=78
06/17/2022 02:58:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/17/2022 02:58:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/17/2022 02:58:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/17/2022 02:58:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/17/2022 02:58:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=82
06/17/2022 02:58:56 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8080600548440633 on epoch=82
06/17/2022 02:58:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/17/2022 02:59:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=83
06/17/2022 02:59:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
06/17/2022 02:59:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
06/17/2022 02:59:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/17/2022 02:59:17 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7508301062736548 on epoch=85
06/17/2022 02:59:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/17/2022 02:59:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/17/2022 02:59:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/17/2022 02:59:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/17/2022 02:59:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/17/2022 02:59:39 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7489185172652915 on epoch=89
06/17/2022 02:59:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/17/2022 02:59:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 02:59:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/17/2022 02:59:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/17/2022 02:59:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/17/2022 03:00:01 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8561045725108225 on epoch=92
06/17/2022 03:00:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/17/2022 03:00:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/17/2022 03:00:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 03:00:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/17/2022 03:00:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/17/2022 03:00:23 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7963475747380202 on epoch=96
06/17/2022 03:00:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/17/2022 03:00:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 03:00:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
06/17/2022 03:00:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 03:00:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/17/2022 03:00:45 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8383770693231676 on epoch=99
06/17/2022 03:00:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/17/2022 03:00:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/17/2022 03:00:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/17/2022 03:00:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
06/17/2022 03:01:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/17/2022 03:01:07 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7560978373478373 on epoch=103
06/17/2022 03:01:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/17/2022 03:01:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/17/2022 03:01:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/17/2022 03:01:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 03:01:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/17/2022 03:01:29 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.8589847568426198 on epoch=107
06/17/2022 03:01:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/17/2022 03:01:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/17/2022 03:01:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 03:01:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/17/2022 03:01:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/17/2022 03:01:52 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8550746884164223 on epoch=110
06/17/2022 03:01:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/17/2022 03:01:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/17/2022 03:02:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/17/2022 03:02:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/17/2022 03:02:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/17/2022 03:02:14 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7492097968669159 on epoch=114
06/17/2022 03:02:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/17/2022 03:02:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/17/2022 03:02:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/17/2022 03:02:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 03:02:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/17/2022 03:02:36 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8129924044821699 on epoch=117
06/17/2022 03:02:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/17/2022 03:02:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/17/2022 03:02:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/17/2022 03:02:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/17/2022 03:02:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=121
06/17/2022 03:02:58 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.842805103162966 on epoch=121
06/17/2022 03:03:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 03:03:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/17/2022 03:03:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/17/2022 03:03:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/17/2022 03:03:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/17/2022 03:03:20 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8527897421798631 on epoch=124
06/17/2022 03:03:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 03:03:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/17/2022 03:03:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 03:03:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
06/17/2022 03:03:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 03:03:43 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7949054108446899 on epoch=128
06/17/2022 03:03:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/17/2022 03:03:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/17/2022 03:03:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 03:03:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/17/2022 03:03:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/17/2022 03:04:05 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7406204831608059 on epoch=132
06/17/2022 03:04:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/17/2022 03:04:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 03:04:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/17/2022 03:04:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/17/2022 03:04:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 03:04:27 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8372271570341423 on epoch=135
06/17/2022 03:04:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/17/2022 03:04:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/17/2022 03:04:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 03:04:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 03:04:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/17/2022 03:04:49 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9143360071301248 on epoch=139
06/17/2022 03:04:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/17/2022 03:04:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/17/2022 03:04:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/17/2022 03:05:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/17/2022 03:05:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 03:05:11 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9864448051948053 on epoch=142
06/17/2022 03:05:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9500149419606496 -> 0.9864448051948053 on epoch=142, global_step=2000
06/17/2022 03:05:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/17/2022 03:05:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/17/2022 03:05:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 03:05:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
06/17/2022 03:05:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 03:05:33 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9864448051948053 on epoch=146
06/17/2022 03:05:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 03:05:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/17/2022 03:05:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/17/2022 03:05:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/17/2022 03:05:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 03:05:55 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9185312805474095 on epoch=149
06/17/2022 03:05:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/17/2022 03:06:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 03:06:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/17/2022 03:06:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/17/2022 03:06:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/17/2022 03:06:17 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=153
06/17/2022 03:06:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/17/2022 03:06:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/17/2022 03:06:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 03:06:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 03:06:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 03:06:39 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=157
06/17/2022 03:06:39 - INFO - __main__ - Saving model with best Classification-F1: 0.9864448051948053 -> 0.9910627007401202 on epoch=157, global_step=2200
06/17/2022 03:06:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/17/2022 03:06:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/17/2022 03:06:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/17/2022 03:06:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/17/2022 03:06:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
06/17/2022 03:07:02 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=160
06/17/2022 03:07:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/17/2022 03:07:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 03:07:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 03:07:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 03:07:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/17/2022 03:07:24 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=164
06/17/2022 03:07:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/17/2022 03:07:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
06/17/2022 03:07:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/17/2022 03:07:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
06/17/2022 03:07:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 03:07:47 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=167
06/17/2022 03:07:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 03:07:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/17/2022 03:07:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/17/2022 03:07:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/17/2022 03:08:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/17/2022 03:08:09 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8177640652424215 on epoch=171
06/17/2022 03:08:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 03:08:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 03:08:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/17/2022 03:08:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 03:08:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 03:08:31 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8417329545454546 on epoch=174
06/17/2022 03:08:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/17/2022 03:08:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/17/2022 03:08:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/17/2022 03:08:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/17/2022 03:08:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 03:08:53 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8486930185475444 on epoch=178
06/17/2022 03:08:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/17/2022 03:09:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/17/2022 03:09:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/17/2022 03:09:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 03:09:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/17/2022 03:09:16 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9075983977708115 on epoch=182
06/17/2022 03:09:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/17/2022 03:09:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/17/2022 03:09:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 03:09:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 03:09:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 03:09:38 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9063159371492705 on epoch=185
06/17/2022 03:09:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 03:09:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 03:09:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/17/2022 03:09:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/17/2022 03:09:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 03:10:00 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8999949494949495 on epoch=189
06/17/2022 03:10:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/17/2022 03:10:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 03:10:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/17/2022 03:10:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 03:10:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/17/2022 03:10:22 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8882286129662442 on epoch=192
06/17/2022 03:10:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/17/2022 03:10:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 03:10:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 03:10:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 03:10:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/17/2022 03:10:45 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9055176511565963 on epoch=196
06/17/2022 03:10:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/17/2022 03:10:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/17/2022 03:10:54 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/17/2022 03:10:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 03:11:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/17/2022 03:11:07 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9773196769859729 on epoch=199
06/17/2022 03:11:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 03:11:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/17/2022 03:11:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/17/2022 03:11:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 03:11:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/17/2022 03:11:29 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9118913270637409 on epoch=203
06/17/2022 03:11:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 03:11:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/17/2022 03:11:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/17/2022 03:11:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/17/2022 03:11:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 03:11:52 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9819761555648652 on epoch=207
06/17/2022 03:11:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/17/2022 03:11:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 03:12:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 03:12:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 03:12:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 03:12:14 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9864448051948053 on epoch=210
06/17/2022 03:12:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 03:12:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 03:12:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 03:12:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 03:12:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/17/2022 03:12:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:12:31 - INFO - __main__ - Printing 3 examples
06/17/2022 03:12:31 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 03:12:31 - INFO - __main__ - ['Company']
06/17/2022 03:12:31 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 03:12:31 - INFO - __main__ - ['Company']
06/17/2022 03:12:31 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 03:12:31 - INFO - __main__ - ['Company']
06/17/2022 03:12:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:12:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:12:31 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 03:12:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:12:31 - INFO - __main__ - Printing 3 examples
06/17/2022 03:12:31 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 03:12:31 - INFO - __main__ - ['Company']
06/17/2022 03:12:31 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 03:12:31 - INFO - __main__ - ['Company']
06/17/2022 03:12:31 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 03:12:31 - INFO - __main__ - ['Company']
06/17/2022 03:12:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:12:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:12:32 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 03:12:37 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9864448051948053 on epoch=214
06/17/2022 03:12:37 - INFO - __main__ - save last model!
06/17/2022 03:12:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 03:12:37 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 03:12:37 - INFO - __main__ - Printing 3 examples
06/17/2022 03:12:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 03:12:37 - INFO - __main__ - ['Animal']
06/17/2022 03:12:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 03:12:37 - INFO - __main__ - ['Animal']
06/17/2022 03:12:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 03:12:37 - INFO - __main__ - ['Village']
06/17/2022 03:12:37 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:12:39 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:12:42 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 03:12:47 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 03:12:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 03:12:48 - INFO - __main__ - Starting training!
06/17/2022 03:15:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/17/2022 03:15:01 - INFO - __main__ - Classification-F1 on test data: 0.7571
06/17/2022 03:15:02 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.75712224839063
06/17/2022 03:15:02 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/17/2022 03:15:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:15:02 - INFO - __main__ - Printing 3 examples
06/17/2022 03:15:02 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 03:15:02 - INFO - __main__ - ['Company']
06/17/2022 03:15:02 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 03:15:02 - INFO - __main__ - ['Company']
06/17/2022 03:15:02 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 03:15:02 - INFO - __main__ - ['Company']
06/17/2022 03:15:02 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:15:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:15:03 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 03:15:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:15:03 - INFO - __main__ - Printing 3 examples
06/17/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 03:15:03 - INFO - __main__ - ['Company']
06/17/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 03:15:03 - INFO - __main__ - ['Company']
06/17/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 03:15:03 - INFO - __main__ - ['Company']
06/17/2022 03:15:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:15:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:15:03 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 03:15:22 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 03:15:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 03:15:23 - INFO - __main__ - Starting training!
06/17/2022 03:15:26 - INFO - __main__ - Step 10 Global step 10 Train loss 7.49 on epoch=0
06/17/2022 03:15:29 - INFO - __main__ - Step 20 Global step 20 Train loss 5.14 on epoch=1
06/17/2022 03:15:33 - INFO - __main__ - Step 30 Global step 30 Train loss 4.27 on epoch=2
06/17/2022 03:15:36 - INFO - __main__ - Step 40 Global step 40 Train loss 4.00 on epoch=2
06/17/2022 03:15:39 - INFO - __main__ - Step 50 Global step 50 Train loss 3.27 on epoch=3
06/17/2022 03:15:44 - INFO - __main__ - Global step 50 Train loss 4.83 Classification-F1 0.08632627130882624 on epoch=3
06/17/2022 03:15:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08632627130882624 on epoch=3, global_step=50
06/17/2022 03:15:47 - INFO - __main__ - Step 60 Global step 60 Train loss 3.07 on epoch=4
06/17/2022 03:15:50 - INFO - __main__ - Step 70 Global step 70 Train loss 2.94 on epoch=4
06/17/2022 03:15:54 - INFO - __main__ - Step 80 Global step 80 Train loss 2.39 on epoch=5
06/17/2022 03:15:57 - INFO - __main__ - Step 90 Global step 90 Train loss 2.17 on epoch=6
06/17/2022 03:16:00 - INFO - __main__ - Step 100 Global step 100 Train loss 2.16 on epoch=7
06/17/2022 03:16:05 - INFO - __main__ - Global step 100 Train loss 2.54 Classification-F1 0.12142276265344847 on epoch=7
06/17/2022 03:16:05 - INFO - __main__ - Saving model with best Classification-F1: 0.08632627130882624 -> 0.12142276265344847 on epoch=7, global_step=100
06/17/2022 03:16:08 - INFO - __main__ - Step 110 Global step 110 Train loss 2.00 on epoch=7
06/17/2022 03:16:11 - INFO - __main__ - Step 120 Global step 120 Train loss 1.62 on epoch=8
06/17/2022 03:16:14 - INFO - __main__ - Step 130 Global step 130 Train loss 1.75 on epoch=9
06/17/2022 03:16:17 - INFO - __main__ - Step 140 Global step 140 Train loss 1.46 on epoch=9
06/17/2022 03:16:20 - INFO - __main__ - Step 150 Global step 150 Train loss 1.26 on epoch=10
06/17/2022 03:16:26 - INFO - __main__ - Global step 150 Train loss 1.62 Classification-F1 0.159547585733544 on epoch=10
06/17/2022 03:16:26 - INFO - __main__ - Saving model with best Classification-F1: 0.12142276265344847 -> 0.159547585733544 on epoch=10, global_step=150
06/17/2022 03:16:29 - INFO - __main__ - Step 160 Global step 160 Train loss 1.19 on epoch=11
06/17/2022 03:16:32 - INFO - __main__ - Step 170 Global step 170 Train loss 1.14 on epoch=12
06/17/2022 03:16:36 - INFO - __main__ - Step 180 Global step 180 Train loss 1.10 on epoch=12
06/17/2022 03:16:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.97 on epoch=13
06/17/2022 03:16:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=14
06/17/2022 03:16:48 - INFO - __main__ - Global step 200 Train loss 1.06 Classification-F1 0.26734070522419007 on epoch=14
06/17/2022 03:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.159547585733544 -> 0.26734070522419007 on epoch=14, global_step=200
06/17/2022 03:16:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=14
06/17/2022 03:16:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=15
06/17/2022 03:16:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=16
06/17/2022 03:17:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=17
06/17/2022 03:17:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=17
06/17/2022 03:17:10 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.5003404624667139 on epoch=17
06/17/2022 03:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.26734070522419007 -> 0.5003404624667139 on epoch=17, global_step=250
06/17/2022 03:17:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=18
06/17/2022 03:17:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=19
06/17/2022 03:17:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=19
06/17/2022 03:17:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=20
06/17/2022 03:17:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=21
06/17/2022 03:17:32 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.6640423149761011 on epoch=21
06/17/2022 03:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5003404624667139 -> 0.6640423149761011 on epoch=21, global_step=300
06/17/2022 03:17:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=22
06/17/2022 03:17:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
06/17/2022 03:17:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=23
06/17/2022 03:17:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=24
06/17/2022 03:17:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=24
06/17/2022 03:17:54 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.6675342130987293 on epoch=24
06/17/2022 03:17:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6640423149761011 -> 0.6675342130987293 on epoch=24, global_step=350
06/17/2022 03:17:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=25
06/17/2022 03:18:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=26
06/17/2022 03:18:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=27
06/17/2022 03:18:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
06/17/2022 03:18:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
06/17/2022 03:18:16 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.5917397543505217 on epoch=28
06/17/2022 03:18:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/17/2022 03:18:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=29
06/17/2022 03:18:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
06/17/2022 03:18:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=31
06/17/2022 03:18:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=32
06/17/2022 03:18:38 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.5927106369864118 on epoch=32
06/17/2022 03:18:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
06/17/2022 03:18:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=33
06/17/2022 03:18:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=34
06/17/2022 03:18:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
06/17/2022 03:18:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
06/17/2022 03:19:00 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.6252569544351262 on epoch=35
06/17/2022 03:19:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/17/2022 03:19:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=37
06/17/2022 03:19:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
06/17/2022 03:19:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=38
06/17/2022 03:19:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
06/17/2022 03:19:22 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.6354173822426129 on epoch=39
06/17/2022 03:19:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/17/2022 03:19:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=40
06/17/2022 03:19:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
06/17/2022 03:19:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
06/17/2022 03:19:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/17/2022 03:19:44 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.6629921540868345 on epoch=42
06/17/2022 03:19:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
06/17/2022 03:19:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=44
06/17/2022 03:19:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
06/17/2022 03:19:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/17/2022 03:19:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=46
06/17/2022 03:20:06 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7264671970818897 on epoch=46
06/17/2022 03:20:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6675342130987293 -> 0.7264671970818897 on epoch=46, global_step=650
06/17/2022 03:20:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/17/2022 03:20:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/17/2022 03:20:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/17/2022 03:20:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/17/2022 03:20:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/17/2022 03:20:29 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7527178563231695 on epoch=49
06/17/2022 03:20:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7264671970818897 -> 0.7527178563231695 on epoch=49, global_step=700
06/17/2022 03:20:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=50
06/17/2022 03:20:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
06/17/2022 03:20:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=52
06/17/2022 03:20:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/17/2022 03:20:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/17/2022 03:20:51 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.9186460429724186 on epoch=53
06/17/2022 03:20:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7527178563231695 -> 0.9186460429724186 on epoch=53, global_step=750
06/17/2022 03:20:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/17/2022 03:20:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/17/2022 03:21:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/17/2022 03:21:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
06/17/2022 03:21:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=57
06/17/2022 03:21:14 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.9148864994026286 on epoch=57
06/17/2022 03:21:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/17/2022 03:21:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/17/2022 03:21:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
06/17/2022 03:21:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
06/17/2022 03:21:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=60
06/17/2022 03:21:36 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.863147605083089 on epoch=60
06/17/2022 03:21:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/17/2022 03:21:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/17/2022 03:21:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/17/2022 03:21:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/17/2022 03:21:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/17/2022 03:21:58 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.9864404412791509 on epoch=64
06/17/2022 03:21:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9186460429724186 -> 0.9864404412791509 on epoch=64, global_step=900
06/17/2022 03:22:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/17/2022 03:22:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/17/2022 03:22:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
06/17/2022 03:22:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/17/2022 03:22:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/17/2022 03:22:21 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8012715936814608 on epoch=67
06/17/2022 03:22:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/17/2022 03:22:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
06/17/2022 03:22:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
06/17/2022 03:22:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/17/2022 03:22:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/17/2022 03:22:43 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8611314760508308 on epoch=71
06/17/2022 03:22:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
06/17/2022 03:22:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/17/2022 03:22:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/17/2022 03:22:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/17/2022 03:22:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
06/17/2022 03:23:06 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7902771959223572 on epoch=74
06/17/2022 03:23:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/17/2022 03:23:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/17/2022 03:23:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/17/2022 03:23:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=77
06/17/2022 03:23:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/17/2022 03:23:28 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8592375366568915 on epoch=78
06/17/2022 03:23:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/17/2022 03:23:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/17/2022 03:23:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/17/2022 03:23:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/17/2022 03:23:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=82
06/17/2022 03:23:51 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.8505501999186771 on epoch=82
06/17/2022 03:23:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/17/2022 03:23:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/17/2022 03:24:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/17/2022 03:24:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/17/2022 03:24:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/17/2022 03:24:13 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7933542366403178 on epoch=85
06/17/2022 03:24:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
06/17/2022 03:24:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/17/2022 03:24:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/17/2022 03:24:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/17/2022 03:24:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/17/2022 03:24:35 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8352064053766415 on epoch=89
06/17/2022 03:24:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/17/2022 03:24:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 03:24:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/17/2022 03:24:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/17/2022 03:24:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/17/2022 03:24:57 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8947397942559232 on epoch=92
06/17/2022 03:25:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/17/2022 03:25:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/17/2022 03:25:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/17/2022 03:25:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/17/2022 03:25:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/17/2022 03:25:20 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7960068745647493 on epoch=96
06/17/2022 03:25:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/17/2022 03:25:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/17/2022 03:25:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/17/2022 03:25:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/17/2022 03:25:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/17/2022 03:25:42 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9092771028254899 on epoch=99
06/17/2022 03:25:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/17/2022 03:25:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/17/2022 03:25:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
06/17/2022 03:25:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/17/2022 03:25:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/17/2022 03:26:05 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9078524563835039 on epoch=103
06/17/2022 03:26:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/17/2022 03:26:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/17/2022 03:26:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/17/2022 03:26:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/17/2022 03:26:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/17/2022 03:26:27 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8027239614624291 on epoch=107
06/17/2022 03:26:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/17/2022 03:26:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/17/2022 03:26:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/17/2022 03:26:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/17/2022 03:26:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/17/2022 03:26:49 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=110
06/17/2022 03:26:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/17/2022 03:26:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/17/2022 03:26:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/17/2022 03:27:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/17/2022 03:27:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/17/2022 03:27:11 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.9865940511101802 on epoch=114
06/17/2022 03:27:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9864404412791509 -> 0.9865940511101802 on epoch=114, global_step=1600
06/17/2022 03:27:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/17/2022 03:27:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/17/2022 03:27:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/17/2022 03:27:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 03:27:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/17/2022 03:27:33 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=117
06/17/2022 03:27:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/17/2022 03:27:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/17/2022 03:27:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/17/2022 03:27:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/17/2022 03:27:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/17/2022 03:27:55 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9144998370804823 on epoch=121
06/17/2022 03:27:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 03:28:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/17/2022 03:28:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 03:28:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/17/2022 03:28:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/17/2022 03:28:17 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=124
06/17/2022 03:28:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 03:28:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/17/2022 03:28:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/17/2022 03:28:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 03:28:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 03:28:39 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9144998370804823 on epoch=128
06/17/2022 03:28:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/17/2022 03:28:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 03:28:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 03:28:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/17/2022 03:28:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/17/2022 03:29:02 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9144998370804823 on epoch=132
06/17/2022 03:29:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/17/2022 03:29:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 03:29:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 03:29:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=134
06/17/2022 03:29:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 03:29:24 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9821254014802402 on epoch=135
06/17/2022 03:29:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/17/2022 03:29:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/17/2022 03:29:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 03:29:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 03:29:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 03:29:46 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=139
06/17/2022 03:29:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/17/2022 03:29:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 03:29:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/17/2022 03:29:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/17/2022 03:30:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 03:30:08 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=142
06/17/2022 03:30:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/17/2022 03:30:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/17/2022 03:30:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/17/2022 03:30:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/17/2022 03:30:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/17/2022 03:30:31 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=146
06/17/2022 03:30:34 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/17/2022 03:30:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 03:30:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/17/2022 03:30:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/17/2022 03:30:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/17/2022 03:30:53 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9775118698505795 on epoch=149
06/17/2022 03:30:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/17/2022 03:30:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 03:31:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 03:31:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/17/2022 03:31:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 03:31:15 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9101898012381883 on epoch=153
06/17/2022 03:31:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/17/2022 03:31:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/17/2022 03:31:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 03:31:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/17/2022 03:31:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/17/2022 03:31:38 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=157
06/17/2022 03:31:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/17/2022 03:31:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/17/2022 03:31:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 03:31:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/17/2022 03:31:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 03:32:00 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9775075059349252 on epoch=160
06/17/2022 03:32:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/17/2022 03:32:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/17/2022 03:32:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/17/2022 03:32:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
06/17/2022 03:32:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/17/2022 03:32:22 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.972851027356033 on epoch=164
06/17/2022 03:32:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/17/2022 03:32:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 03:32:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/17/2022 03:32:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 03:32:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 03:32:44 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9775075059349252 on epoch=167
06/17/2022 03:32:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/17/2022 03:32:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/17/2022 03:32:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 03:32:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 03:33:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 03:33:06 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9819761555648653 on epoch=171
06/17/2022 03:33:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 03:33:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/17/2022 03:33:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/17/2022 03:33:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 03:33:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 03:33:29 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9775075059349252 on epoch=174
06/17/2022 03:33:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/17/2022 03:33:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/17/2022 03:33:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 03:33:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 03:33:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/17/2022 03:33:51 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9775075059349252 on epoch=178
06/17/2022 03:33:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 03:33:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 03:34:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/17/2022 03:34:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/17/2022 03:34:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/17/2022 03:34:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9821254014802402 on epoch=182
06/17/2022 03:34:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/17/2022 03:34:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/17/2022 03:34:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/17/2022 03:34:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 03:34:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 03:34:34 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=185
06/17/2022 03:34:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/17/2022 03:34:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/17/2022 03:34:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/17/2022 03:34:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/17/2022 03:34:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/17/2022 03:34:56 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.914360540892799 on epoch=189
06/17/2022 03:34:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 03:35:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/17/2022 03:35:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=191
06/17/2022 03:35:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/17/2022 03:35:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/17/2022 03:35:18 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9060190615835777 on epoch=192
06/17/2022 03:35:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/17/2022 03:35:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=194
06/17/2022 03:35:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/17/2022 03:35:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/17/2022 03:35:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/17/2022 03:35:40 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9730388563049852 on epoch=196
06/17/2022 03:35:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 03:35:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 03:35:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/17/2022 03:35:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 03:35:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/17/2022 03:36:01 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9775075059349252 on epoch=199
06/17/2022 03:36:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/17/2022 03:36:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/17/2022 03:36:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/17/2022 03:36:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 03:36:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 03:36:23 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9144998370804823 on epoch=203
06/17/2022 03:36:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 03:36:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/17/2022 03:36:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 03:36:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 03:36:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 03:36:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=207
06/17/2022 03:36:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/17/2022 03:36:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/17/2022 03:36:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 03:36:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 03:37:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 03:37:06 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9730388563049852 on epoch=210
06/17/2022 03:37:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 03:37:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 03:37:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 03:37:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/17/2022 03:37:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/17/2022 03:37:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:37:23 - INFO - __main__ - Printing 3 examples
06/17/2022 03:37:23 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 03:37:23 - INFO - __main__ - ['Company']
06/17/2022 03:37:23 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 03:37:23 - INFO - __main__ - ['Company']
06/17/2022 03:37:23 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 03:37:23 - INFO - __main__ - ['Company']
06/17/2022 03:37:23 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:37:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:37:23 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 03:37:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:37:23 - INFO - __main__ - Printing 3 examples
06/17/2022 03:37:23 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 03:37:23 - INFO - __main__ - ['Company']
06/17/2022 03:37:23 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 03:37:23 - INFO - __main__ - ['Company']
06/17/2022 03:37:23 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 03:37:23 - INFO - __main__ - ['Company']
06/17/2022 03:37:23 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:37:23 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:37:23 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 03:37:28 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9776567518503002 on epoch=214
06/17/2022 03:37:28 - INFO - __main__ - save last model!
06/17/2022 03:37:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 03:37:28 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 03:37:28 - INFO - __main__ - Printing 3 examples
06/17/2022 03:37:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 03:37:28 - INFO - __main__ - ['Animal']
06/17/2022 03:37:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 03:37:28 - INFO - __main__ - ['Animal']
06/17/2022 03:37:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 03:37:28 - INFO - __main__ - ['Village']
06/17/2022 03:37:28 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:37:30 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:37:33 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 03:37:39 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 03:37:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 03:37:39 - INFO - __main__ - Starting training!
06/17/2022 03:39:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/17/2022 03:39:49 - INFO - __main__ - Classification-F1 on test data: 0.4541
06/17/2022 03:39:49 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9865940511101802, test_performance=0.4541081579046674
06/17/2022 03:39:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/17/2022 03:39:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:39:50 - INFO - __main__ - Printing 3 examples
06/17/2022 03:39:50 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 03:39:50 - INFO - __main__ - ['Company']
06/17/2022 03:39:50 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 03:39:50 - INFO - __main__ - ['Company']
06/17/2022 03:39:50 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 03:39:50 - INFO - __main__ - ['Company']
06/17/2022 03:39:50 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:39:50 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:39:50 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 03:39:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 03:39:50 - INFO - __main__ - Printing 3 examples
06/17/2022 03:39:50 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 03:39:50 - INFO - __main__ - ['Company']
06/17/2022 03:39:50 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 03:39:50 - INFO - __main__ - ['Company']
06/17/2022 03:39:50 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 03:39:50 - INFO - __main__ - ['Company']
06/17/2022 03:39:50 - INFO - __main__ - Tokenizing Input ...
06/17/2022 03:39:50 - INFO - __main__ - Tokenizing Output ...
06/17/2022 03:39:51 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 03:40:06 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 03:40:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 03:40:07 - INFO - __main__ - Starting training!
06/17/2022 03:40:11 - INFO - __main__ - Step 10 Global step 10 Train loss 7.19 on epoch=0
06/17/2022 03:40:14 - INFO - __main__ - Step 20 Global step 20 Train loss 5.43 on epoch=1
06/17/2022 03:40:17 - INFO - __main__ - Step 30 Global step 30 Train loss 4.59 on epoch=2
06/17/2022 03:40:20 - INFO - __main__ - Step 40 Global step 40 Train loss 4.17 on epoch=2
06/17/2022 03:40:23 - INFO - __main__ - Step 50 Global step 50 Train loss 3.82 on epoch=3
06/17/2022 03:40:28 - INFO - __main__ - Global step 50 Train loss 5.04 Classification-F1 0.04030762545577821 on epoch=3
06/17/2022 03:40:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04030762545577821 on epoch=3, global_step=50
06/17/2022 03:40:31 - INFO - __main__ - Step 60 Global step 60 Train loss 3.52 on epoch=4
06/17/2022 03:40:34 - INFO - __main__ - Step 70 Global step 70 Train loss 3.08 on epoch=4
06/17/2022 03:40:37 - INFO - __main__ - Step 80 Global step 80 Train loss 2.84 on epoch=5
06/17/2022 03:40:40 - INFO - __main__ - Step 90 Global step 90 Train loss 2.85 on epoch=6
06/17/2022 03:40:43 - INFO - __main__ - Step 100 Global step 100 Train loss 2.55 on epoch=7
06/17/2022 03:40:48 - INFO - __main__ - Global step 100 Train loss 2.97 Classification-F1 0.09679457937522454 on epoch=7
06/17/2022 03:40:48 - INFO - __main__ - Saving model with best Classification-F1: 0.04030762545577821 -> 0.09679457937522454 on epoch=7, global_step=100
06/17/2022 03:40:51 - INFO - __main__ - Step 110 Global step 110 Train loss 2.40 on epoch=7
06/17/2022 03:40:54 - INFO - __main__ - Step 120 Global step 120 Train loss 2.06 on epoch=8
06/17/2022 03:40:57 - INFO - __main__ - Step 130 Global step 130 Train loss 2.03 on epoch=9
06/17/2022 03:41:00 - INFO - __main__ - Step 140 Global step 140 Train loss 1.98 on epoch=9
06/17/2022 03:41:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.78 on epoch=10
06/17/2022 03:41:08 - INFO - __main__ - Global step 150 Train loss 2.05 Classification-F1 0.13627896596946396 on epoch=10
06/17/2022 03:41:08 - INFO - __main__ - Saving model with best Classification-F1: 0.09679457937522454 -> 0.13627896596946396 on epoch=10, global_step=150
06/17/2022 03:41:11 - INFO - __main__ - Step 160 Global step 160 Train loss 1.64 on epoch=11
06/17/2022 03:41:14 - INFO - __main__ - Step 170 Global step 170 Train loss 1.56 on epoch=12
06/17/2022 03:41:17 - INFO - __main__ - Step 180 Global step 180 Train loss 1.50 on epoch=12
06/17/2022 03:41:20 - INFO - __main__ - Step 190 Global step 190 Train loss 1.27 on epoch=13
06/17/2022 03:41:23 - INFO - __main__ - Step 200 Global step 200 Train loss 1.21 on epoch=14
06/17/2022 03:41:30 - INFO - __main__ - Global step 200 Train loss 1.44 Classification-F1 0.1773386280839006 on epoch=14
06/17/2022 03:41:30 - INFO - __main__ - Saving model with best Classification-F1: 0.13627896596946396 -> 0.1773386280839006 on epoch=14, global_step=200
06/17/2022 03:41:33 - INFO - __main__ - Step 210 Global step 210 Train loss 1.19 on epoch=14
06/17/2022 03:41:36 - INFO - __main__ - Step 220 Global step 220 Train loss 1.13 on epoch=15
06/17/2022 03:41:39 - INFO - __main__ - Step 230 Global step 230 Train loss 1.11 on epoch=16
06/17/2022 03:41:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.95 on epoch=17
06/17/2022 03:41:45 - INFO - __main__ - Step 250 Global step 250 Train loss 1.00 on epoch=17
06/17/2022 03:41:51 - INFO - __main__ - Global step 250 Train loss 1.08 Classification-F1 0.2491998649666526 on epoch=17
06/17/2022 03:41:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1773386280839006 -> 0.2491998649666526 on epoch=17, global_step=250
06/17/2022 03:41:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.81 on epoch=18
06/17/2022 03:41:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.82 on epoch=19
06/17/2022 03:42:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.75 on epoch=19
06/17/2022 03:42:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.72 on epoch=20
06/17/2022 03:42:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=21
06/17/2022 03:42:13 - INFO - __main__ - Global step 300 Train loss 0.75 Classification-F1 0.37870065378203505 on epoch=21
06/17/2022 03:42:13 - INFO - __main__ - Saving model with best Classification-F1: 0.2491998649666526 -> 0.37870065378203505 on epoch=21, global_step=300
06/17/2022 03:42:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=22
06/17/2022 03:42:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=22
06/17/2022 03:42:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=23
06/17/2022 03:42:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
06/17/2022 03:42:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=24
06/17/2022 03:42:35 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.5445088414047246 on epoch=24
06/17/2022 03:42:35 - INFO - __main__ - Saving model with best Classification-F1: 0.37870065378203505 -> 0.5445088414047246 on epoch=24, global_step=350
06/17/2022 03:42:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=25
06/17/2022 03:42:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=26
06/17/2022 03:42:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=27
06/17/2022 03:42:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/17/2022 03:42:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=28
06/17/2022 03:42:57 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5687249413228368 on epoch=28
06/17/2022 03:42:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5445088414047246 -> 0.5687249413228368 on epoch=28, global_step=400
06/17/2022 03:43:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=29
06/17/2022 03:43:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=29
06/17/2022 03:43:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
06/17/2022 03:43:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/17/2022 03:43:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=32
06/17/2022 03:43:19 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.617457510863583 on epoch=32
06/17/2022 03:43:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5687249413228368 -> 0.617457510863583 on epoch=32, global_step=450
06/17/2022 03:43:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=32
06/17/2022 03:43:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=33
06/17/2022 03:43:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=34
06/17/2022 03:43:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/17/2022 03:43:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=35
06/17/2022 03:43:42 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.680783038634758 on epoch=35
06/17/2022 03:43:42 - INFO - __main__ - Saving model with best Classification-F1: 0.617457510863583 -> 0.680783038634758 on epoch=35, global_step=500
06/17/2022 03:43:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
06/17/2022 03:43:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
06/17/2022 03:43:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=37
06/17/2022 03:43:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
06/17/2022 03:43:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/17/2022 03:44:04 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.7349903174800575 on epoch=39
06/17/2022 03:44:04 - INFO - __main__ - Saving model with best Classification-F1: 0.680783038634758 -> 0.7349903174800575 on epoch=39, global_step=550
06/17/2022 03:44:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=39
06/17/2022 03:44:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=40
06/17/2022 03:44:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=41
06/17/2022 03:44:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=42
06/17/2022 03:44:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
06/17/2022 03:44:26 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6966721478349386 on epoch=42
06/17/2022 03:44:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
06/17/2022 03:44:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
06/17/2022 03:44:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=44
06/17/2022 03:44:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/17/2022 03:44:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
06/17/2022 03:44:49 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.707181619012289 on epoch=46
06/17/2022 03:44:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/17/2022 03:44:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=47
06/17/2022 03:44:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=48
06/17/2022 03:45:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/17/2022 03:45:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/17/2022 03:45:11 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.7300492610837438 on epoch=49
06/17/2022 03:45:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=50
06/17/2022 03:45:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/17/2022 03:45:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/17/2022 03:45:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/17/2022 03:45:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
06/17/2022 03:45:33 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.8551833838441697 on epoch=53
06/17/2022 03:45:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7349903174800575 -> 0.8551833838441697 on epoch=53, global_step=750
06/17/2022 03:45:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
06/17/2022 03:45:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=54
06/17/2022 03:45:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/17/2022 03:45:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/17/2022 03:45:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/17/2022 03:45:56 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.7739739109981324 on epoch=57
06/17/2022 03:45:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=57
06/17/2022 03:46:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
06/17/2022 03:46:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
06/17/2022 03:46:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
06/17/2022 03:46:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/17/2022 03:46:18 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.9241027789414886 on epoch=60
06/17/2022 03:46:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8551833838441697 -> 0.9241027789414886 on epoch=60, global_step=850
06/17/2022 03:46:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
06/17/2022 03:46:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/17/2022 03:46:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
06/17/2022 03:46:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
06/17/2022 03:46:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/17/2022 03:46:40 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.957436112274822 on epoch=64
06/17/2022 03:46:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9241027789414886 -> 0.957436112274822 on epoch=64, global_step=900
06/17/2022 03:46:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/17/2022 03:46:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/17/2022 03:46:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/17/2022 03:46:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/17/2022 03:46:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/17/2022 03:47:02 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.8916035981506869 on epoch=67
06/17/2022 03:47:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/17/2022 03:47:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/17/2022 03:47:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/17/2022 03:47:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/17/2022 03:47:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/17/2022 03:47:24 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8477629233511587 on epoch=71
06/17/2022 03:47:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
06/17/2022 03:47:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/17/2022 03:47:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
06/17/2022 03:47:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/17/2022 03:47:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/17/2022 03:47:46 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.805380891551223 on epoch=74
06/17/2022 03:47:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/17/2022 03:47:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/17/2022 03:47:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
06/17/2022 03:47:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/17/2022 03:48:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/17/2022 03:48:08 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8542068146906857 on epoch=78
06/17/2022 03:48:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/17/2022 03:48:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/17/2022 03:48:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/17/2022 03:48:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/17/2022 03:48:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/17/2022 03:48:30 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8538232578792351 on epoch=82
06/17/2022 03:48:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/17/2022 03:48:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
06/17/2022 03:48:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
06/17/2022 03:48:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/17/2022 03:48:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/17/2022 03:48:52 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.9186746497230369 on epoch=85
06/17/2022 03:48:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/17/2022 03:48:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/17/2022 03:49:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/17/2022 03:49:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/17/2022 03:49:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/17/2022 03:49:14 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.9864404412791509 on epoch=89
06/17/2022 03:49:14 - INFO - __main__ - Saving model with best Classification-F1: 0.957436112274822 -> 0.9864404412791509 on epoch=89, global_step=1250
06/17/2022 03:49:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/17/2022 03:49:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/17/2022 03:49:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/17/2022 03:49:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/17/2022 03:49:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/17/2022 03:49:35 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.8608664772727272 on epoch=92
06/17/2022 03:49:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/17/2022 03:49:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/17/2022 03:49:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/17/2022 03:49:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/17/2022 03:49:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/17/2022 03:49:57 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.9226979472140762 on epoch=96
06/17/2022 03:50:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/17/2022 03:50:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/17/2022 03:50:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/17/2022 03:50:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/17/2022 03:50:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/17/2022 03:50:19 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8482363356103275 on epoch=99
06/17/2022 03:50:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/17/2022 03:50:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/17/2022 03:50:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/17/2022 03:50:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/17/2022 03:50:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/17/2022 03:50:41 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.810223678914381 on epoch=103
06/17/2022 03:50:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 03:50:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/17/2022 03:50:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/17/2022 03:50:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/17/2022 03:50:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/17/2022 03:51:02 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.80630211028693 on epoch=107
06/17/2022 03:51:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/17/2022 03:51:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/17/2022 03:51:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/17/2022 03:51:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/17/2022 03:51:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/17/2022 03:51:25 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9909090909090909 on epoch=110
06/17/2022 03:51:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9864404412791509 -> 0.9909090909090909 on epoch=110, global_step=1550
06/17/2022 03:51:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/17/2022 03:51:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/17/2022 03:51:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/17/2022 03:51:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/17/2022 03:51:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/17/2022 03:51:46 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.9820991153059465 on epoch=114
06/17/2022 03:51:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/17/2022 03:51:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/17/2022 03:51:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/17/2022 03:51:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/17/2022 03:52:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
06/17/2022 03:52:09 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9820991153059465 on epoch=117
06/17/2022 03:52:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/17/2022 03:52:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/17/2022 03:52:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/17/2022 03:52:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/17/2022 03:52:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/17/2022 03:52:31 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9775075059349252 on epoch=121
06/17/2022 03:52:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
06/17/2022 03:52:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/17/2022 03:52:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
06/17/2022 03:52:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/17/2022 03:52:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/17/2022 03:52:53 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.8628787878787879 on epoch=124
06/17/2022 03:52:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
06/17/2022 03:52:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/17/2022 03:53:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/17/2022 03:53:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/17/2022 03:53:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 03:53:14 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8080600548440633 on epoch=128
06/17/2022 03:53:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/17/2022 03:53:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
06/17/2022 03:53:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/17/2022 03:53:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/17/2022 03:53:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/17/2022 03:53:36 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9864404412791509 on epoch=132
06/17/2022 03:53:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/17/2022 03:53:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/17/2022 03:53:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/17/2022 03:53:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=134
06/17/2022 03:53:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/17/2022 03:53:58 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9163521361623829 on epoch=135
06/17/2022 03:54:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 03:54:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
06/17/2022 03:54:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/17/2022 03:54:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 03:54:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/17/2022 03:54:20 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8046496751193146 on epoch=139
06/17/2022 03:54:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/17/2022 03:54:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/17/2022 03:54:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/17/2022 03:54:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/17/2022 03:54:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/17/2022 03:54:42 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8449588238887931 on epoch=142
06/17/2022 03:54:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/17/2022 03:54:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
06/17/2022 03:54:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/17/2022 03:54:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/17/2022 03:54:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/17/2022 03:55:04 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.910202834799609 on epoch=146
06/17/2022 03:55:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 03:55:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/17/2022 03:55:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/17/2022 03:55:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/17/2022 03:55:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/17/2022 03:55:26 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9864404412791509 on epoch=149
06/17/2022 03:55:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/17/2022 03:55:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/17/2022 03:55:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/17/2022 03:55:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/17/2022 03:55:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/17/2022 03:55:48 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9865677649358864 on epoch=153
06/17/2022 03:55:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/17/2022 03:55:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/17/2022 03:55:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/17/2022 03:56:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/17/2022 03:56:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/17/2022 03:56:11 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=157
06/17/2022 03:56:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/17/2022 03:56:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/17/2022 03:56:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 03:56:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 03:56:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/17/2022 03:56:33 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9773634967183352 on epoch=160
06/17/2022 03:56:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/17/2022 03:56:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/17/2022 03:56:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 03:56:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/17/2022 03:56:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/17/2022 03:56:55 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.973026534660785 on epoch=164
06/17/2022 03:56:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/17/2022 03:57:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 03:57:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/17/2022 03:57:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/17/2022 03:57:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/17/2022 03:57:17 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9142261322906483 on epoch=167
06/17/2022 03:57:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/17/2022 03:57:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/17/2022 03:57:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.15 on epoch=169
06/17/2022 03:57:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/17/2022 03:57:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
06/17/2022 03:57:39 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.9186746497230369 on epoch=171
06/17/2022 03:57:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/17/2022 03:57:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 03:57:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 03:57:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/17/2022 03:57:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/17/2022 03:58:01 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=174
06/17/2022 03:58:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=175
06/17/2022 03:58:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/17/2022 03:58:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/17/2022 03:58:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/17/2022 03:58:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/17/2022 03:58:22 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9185272075594656 on epoch=178
06/17/2022 03:58:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/17/2022 03:58:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 03:58:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/17/2022 03:58:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/17/2022 03:58:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/17/2022 03:58:45 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8511684384164223 on epoch=182
06/17/2022 03:58:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/17/2022 03:58:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/17/2022 03:58:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 03:58:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/17/2022 03:59:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/17/2022 03:59:06 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8550708699902249 on epoch=185
06/17/2022 03:59:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 03:59:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/17/2022 03:59:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/17/2022 03:59:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/17/2022 03:59:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 03:59:28 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8027485480995916 on epoch=189
06/17/2022 03:59:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 03:59:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/17/2022 03:59:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/17/2022 03:59:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 03:59:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 03:59:50 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=192
06/17/2022 03:59:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/17/2022 03:59:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 03:59:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 04:00:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 04:00:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 04:00:12 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9142261322906483 on epoch=196
06/17/2022 04:00:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/17/2022 04:00:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/17/2022 04:00:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/17/2022 04:00:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 04:00:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/17/2022 04:00:35 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=199
06/17/2022 04:00:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/17/2022 04:00:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/17/2022 04:00:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/17/2022 04:00:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/17/2022 04:00:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 04:00:57 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9864544058092444 on epoch=203
06/17/2022 04:01:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 04:01:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 04:01:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 04:01:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/17/2022 04:01:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/17/2022 04:01:19 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9864544058092444 on epoch=207
06/17/2022 04:01:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/17/2022 04:01:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 04:01:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/17/2022 04:01:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/17/2022 04:01:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 04:01:41 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9910670646557743 on epoch=210
06/17/2022 04:01:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9909090909090909 -> 0.9910670646557743 on epoch=210, global_step=2950
06/17/2022 04:01:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/17/2022 04:01:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 04:01:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/17/2022 04:01:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/17/2022 04:01:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 04:01:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:01:57 - INFO - __main__ - Printing 3 examples
06/17/2022 04:01:57 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 04:01:57 - INFO - __main__ - ['Company']
06/17/2022 04:01:57 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 04:01:57 - INFO - __main__ - ['Company']
06/17/2022 04:01:57 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 04:01:57 - INFO - __main__ - ['Company']
06/17/2022 04:01:57 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:01:58 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:01:58 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 04:01:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:01:58 - INFO - __main__ - Printing 3 examples
06/17/2022 04:01:58 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 04:01:58 - INFO - __main__ - ['Company']
06/17/2022 04:01:58 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 04:01:58 - INFO - __main__ - ['Company']
06/17/2022 04:01:58 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 04:01:58 - INFO - __main__ - ['Company']
06/17/2022 04:01:58 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:01:58 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:01:58 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 04:02:03 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9773634967183352 on epoch=214
06/17/2022 04:02:03 - INFO - __main__ - save last model!
06/17/2022 04:02:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 04:02:03 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 04:02:03 - INFO - __main__ - Printing 3 examples
06/17/2022 04:02:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 04:02:03 - INFO - __main__ - ['Animal']
06/17/2022 04:02:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 04:02:03 - INFO - __main__ - ['Animal']
06/17/2022 04:02:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 04:02:03 - INFO - __main__ - ['Village']
06/17/2022 04:02:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:02:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:02:09 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 04:02:14 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:02:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 04:02:14 - INFO - __main__ - Starting training!
06/17/2022 04:04:30 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/17/2022 04:04:30 - INFO - __main__ - Classification-F1 on test data: 0.6497
06/17/2022 04:04:31 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9910670646557743, test_performance=0.649699091921754
06/17/2022 04:04:31 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/17/2022 04:04:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:04:32 - INFO - __main__ - Printing 3 examples
06/17/2022 04:04:32 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/17/2022 04:04:32 - INFO - __main__ - ['Company']
06/17/2022 04:04:32 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/17/2022 04:04:32 - INFO - __main__ - ['Company']
06/17/2022 04:04:32 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/17/2022 04:04:32 - INFO - __main__ - ['Company']
06/17/2022 04:04:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:04:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:04:32 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 04:04:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:04:32 - INFO - __main__ - Printing 3 examples
06/17/2022 04:04:32 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/17/2022 04:04:32 - INFO - __main__ - ['Company']
06/17/2022 04:04:32 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/17/2022 04:04:32 - INFO - __main__ - ['Company']
06/17/2022 04:04:32 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/17/2022 04:04:32 - INFO - __main__ - ['Company']
06/17/2022 04:04:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:04:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:04:32 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 04:04:48 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:04:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 04:04:49 - INFO - __main__ - Starting training!
06/17/2022 04:04:52 - INFO - __main__ - Step 10 Global step 10 Train loss 7.59 on epoch=0
06/17/2022 04:04:55 - INFO - __main__ - Step 20 Global step 20 Train loss 6.10 on epoch=1
06/17/2022 04:04:58 - INFO - __main__ - Step 30 Global step 30 Train loss 5.24 on epoch=2
06/17/2022 04:05:01 - INFO - __main__ - Step 40 Global step 40 Train loss 4.84 on epoch=2
06/17/2022 04:05:04 - INFO - __main__ - Step 50 Global step 50 Train loss 4.47 on epoch=3
06/17/2022 04:05:10 - INFO - __main__ - Global step 50 Train loss 5.65 Classification-F1 0.018633057143968568 on epoch=3
06/17/2022 04:05:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.018633057143968568 on epoch=3, global_step=50
06/17/2022 04:05:13 - INFO - __main__ - Step 60 Global step 60 Train loss 4.11 on epoch=4
06/17/2022 04:05:16 - INFO - __main__ - Step 70 Global step 70 Train loss 3.95 on epoch=4
06/17/2022 04:05:19 - INFO - __main__ - Step 80 Global step 80 Train loss 3.63 on epoch=5
06/17/2022 04:05:22 - INFO - __main__ - Step 90 Global step 90 Train loss 3.23 on epoch=6
06/17/2022 04:05:25 - INFO - __main__ - Step 100 Global step 100 Train loss 3.31 on epoch=7
06/17/2022 04:05:30 - INFO - __main__ - Global step 100 Train loss 3.65 Classification-F1 0.054745299327342664 on epoch=7
06/17/2022 04:05:30 - INFO - __main__ - Saving model with best Classification-F1: 0.018633057143968568 -> 0.054745299327342664 on epoch=7, global_step=100
06/17/2022 04:05:33 - INFO - __main__ - Step 110 Global step 110 Train loss 3.14 on epoch=7
06/17/2022 04:05:36 - INFO - __main__ - Step 120 Global step 120 Train loss 3.01 on epoch=8
06/17/2022 04:05:39 - INFO - __main__ - Step 130 Global step 130 Train loss 2.65 on epoch=9
06/17/2022 04:05:42 - INFO - __main__ - Step 140 Global step 140 Train loss 2.60 on epoch=9
06/17/2022 04:05:45 - INFO - __main__ - Step 150 Global step 150 Train loss 2.59 on epoch=10
06/17/2022 04:05:50 - INFO - __main__ - Global step 150 Train loss 2.80 Classification-F1 0.10538208668977654 on epoch=10
06/17/2022 04:05:50 - INFO - __main__ - Saving model with best Classification-F1: 0.054745299327342664 -> 0.10538208668977654 on epoch=10, global_step=150
06/17/2022 04:05:53 - INFO - __main__ - Step 160 Global step 160 Train loss 2.32 on epoch=11
06/17/2022 04:05:56 - INFO - __main__ - Step 170 Global step 170 Train loss 2.37 on epoch=12
06/17/2022 04:05:59 - INFO - __main__ - Step 180 Global step 180 Train loss 2.27 on epoch=12
06/17/2022 04:06:02 - INFO - __main__ - Step 190 Global step 190 Train loss 1.89 on epoch=13
06/17/2022 04:06:05 - INFO - __main__ - Step 200 Global step 200 Train loss 1.90 on epoch=14
06/17/2022 04:06:11 - INFO - __main__ - Global step 200 Train loss 2.15 Classification-F1 0.12307377644621048 on epoch=14
06/17/2022 04:06:11 - INFO - __main__ - Saving model with best Classification-F1: 0.10538208668977654 -> 0.12307377644621048 on epoch=14, global_step=200
06/17/2022 04:06:14 - INFO - __main__ - Step 210 Global step 210 Train loss 1.96 on epoch=14
06/17/2022 04:06:17 - INFO - __main__ - Step 220 Global step 220 Train loss 1.85 on epoch=15
06/17/2022 04:06:20 - INFO - __main__ - Step 230 Global step 230 Train loss 1.63 on epoch=16
06/17/2022 04:06:23 - INFO - __main__ - Step 240 Global step 240 Train loss 1.68 on epoch=17
06/17/2022 04:06:26 - INFO - __main__ - Step 250 Global step 250 Train loss 1.61 on epoch=17
06/17/2022 04:06:31 - INFO - __main__ - Global step 250 Train loss 1.75 Classification-F1 0.13545585710271618 on epoch=17
06/17/2022 04:06:31 - INFO - __main__ - Saving model with best Classification-F1: 0.12307377644621048 -> 0.13545585710271618 on epoch=17, global_step=250
06/17/2022 04:06:34 - INFO - __main__ - Step 260 Global step 260 Train loss 1.43 on epoch=18
06/17/2022 04:06:37 - INFO - __main__ - Step 270 Global step 270 Train loss 1.43 on epoch=19
06/17/2022 04:06:40 - INFO - __main__ - Step 280 Global step 280 Train loss 1.47 on epoch=19
06/17/2022 04:06:43 - INFO - __main__ - Step 290 Global step 290 Train loss 1.27 on epoch=20
06/17/2022 04:06:46 - INFO - __main__ - Step 300 Global step 300 Train loss 1.23 on epoch=21
06/17/2022 04:06:52 - INFO - __main__ - Global step 300 Train loss 1.37 Classification-F1 0.16116658507314793 on epoch=21
06/17/2022 04:06:52 - INFO - __main__ - Saving model with best Classification-F1: 0.13545585710271618 -> 0.16116658507314793 on epoch=21, global_step=300
06/17/2022 04:06:55 - INFO - __main__ - Step 310 Global step 310 Train loss 1.19 on epoch=22
06/17/2022 04:06:58 - INFO - __main__ - Step 320 Global step 320 Train loss 1.23 on epoch=22
06/17/2022 04:07:01 - INFO - __main__ - Step 330 Global step 330 Train loss 1.14 on epoch=23
06/17/2022 04:07:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.97 on epoch=24
06/17/2022 04:07:07 - INFO - __main__ - Step 350 Global step 350 Train loss 1.09 on epoch=24
06/17/2022 04:07:13 - INFO - __main__ - Global step 350 Train loss 1.12 Classification-F1 0.2223536169719961 on epoch=24
06/17/2022 04:07:13 - INFO - __main__ - Saving model with best Classification-F1: 0.16116658507314793 -> 0.2223536169719961 on epoch=24, global_step=350
06/17/2022 04:07:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.93 on epoch=25
06/17/2022 04:07:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.98 on epoch=26
06/17/2022 04:07:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.85 on epoch=27
06/17/2022 04:07:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.79 on epoch=27
06/17/2022 04:07:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.77 on epoch=28
06/17/2022 04:07:35 - INFO - __main__ - Global step 400 Train loss 0.87 Classification-F1 0.29634284634092395 on epoch=28
06/17/2022 04:07:35 - INFO - __main__ - Saving model with best Classification-F1: 0.2223536169719961 -> 0.29634284634092395 on epoch=28, global_step=400
06/17/2022 04:07:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.80 on epoch=29
06/17/2022 04:07:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.83 on epoch=29
06/17/2022 04:07:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.79 on epoch=30
06/17/2022 04:07:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.70 on epoch=31
06/17/2022 04:07:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.67 on epoch=32
06/17/2022 04:07:57 - INFO - __main__ - Global step 450 Train loss 0.76 Classification-F1 0.40968310147398024 on epoch=32
06/17/2022 04:07:57 - INFO - __main__ - Saving model with best Classification-F1: 0.29634284634092395 -> 0.40968310147398024 on epoch=32, global_step=450
06/17/2022 04:08:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.58 on epoch=32
06/17/2022 04:08:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.55 on epoch=33
06/17/2022 04:08:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.68 on epoch=34
06/17/2022 04:08:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=34
06/17/2022 04:08:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.57 on epoch=35
06/17/2022 04:08:19 - INFO - __main__ - Global step 500 Train loss 0.59 Classification-F1 0.5269315546355395 on epoch=35
06/17/2022 04:08:19 - INFO - __main__ - Saving model with best Classification-F1: 0.40968310147398024 -> 0.5269315546355395 on epoch=35, global_step=500
06/17/2022 04:08:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=36
06/17/2022 04:08:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.53 on epoch=37
06/17/2022 04:08:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.48 on epoch=37
06/17/2022 04:08:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=38
06/17/2022 04:08:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.50 on epoch=39
06/17/2022 04:08:41 - INFO - __main__ - Global step 550 Train loss 0.47 Classification-F1 0.6055775976079582 on epoch=39
06/17/2022 04:08:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5269315546355395 -> 0.6055775976079582 on epoch=39, global_step=550
06/17/2022 04:08:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=39
06/17/2022 04:08:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=40
06/17/2022 04:08:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=41
06/17/2022 04:08:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.43 on epoch=42
06/17/2022 04:08:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=42
06/17/2022 04:09:03 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.6026585805387649 on epoch=42
06/17/2022 04:09:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=43
06/17/2022 04:09:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=44
06/17/2022 04:09:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=44
06/17/2022 04:09:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.34 on epoch=45
06/17/2022 04:09:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=46
06/17/2022 04:09:24 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.6579038122968515 on epoch=46
06/17/2022 04:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6055775976079582 -> 0.6579038122968515 on epoch=46, global_step=650
06/17/2022 04:09:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=47
06/17/2022 04:09:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.44 on epoch=47
06/17/2022 04:09:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=48
06/17/2022 04:09:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=49
06/17/2022 04:09:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.32 on epoch=49
06/17/2022 04:09:47 - INFO - __main__ - Global step 700 Train loss 0.36 Classification-F1 0.7050421993495998 on epoch=49
06/17/2022 04:09:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6579038122968515 -> 0.7050421993495998 on epoch=49, global_step=700
06/17/2022 04:09:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=50
06/17/2022 04:09:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=51
06/17/2022 04:09:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=52
06/17/2022 04:09:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
06/17/2022 04:10:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=53
06/17/2022 04:10:09 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.7068343140449402 on epoch=53
06/17/2022 04:10:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7050421993495998 -> 0.7068343140449402 on epoch=53, global_step=750
06/17/2022 04:10:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=54
06/17/2022 04:10:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=54
06/17/2022 04:10:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=55
06/17/2022 04:10:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
06/17/2022 04:10:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
06/17/2022 04:10:31 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.6679073049191895 on epoch=57
06/17/2022 04:10:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.29 on epoch=57
06/17/2022 04:10:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=58
06/17/2022 04:10:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=59
06/17/2022 04:10:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.32 on epoch=59
06/17/2022 04:10:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
06/17/2022 04:10:53 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.7034287941308813 on epoch=60
06/17/2022 04:10:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
06/17/2022 04:10:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=62
06/17/2022 04:11:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=62
06/17/2022 04:11:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/17/2022 04:11:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=64
06/17/2022 04:11:14 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.6345119396732299 on epoch=64
06/17/2022 04:11:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
06/17/2022 04:11:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
06/17/2022 04:11:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=66
06/17/2022 04:11:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
06/17/2022 04:11:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
06/17/2022 04:11:37 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.6328990364474235 on epoch=67
06/17/2022 04:11:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/17/2022 04:11:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=69
06/17/2022 04:11:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=69
06/17/2022 04:11:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
06/17/2022 04:11:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=71
06/17/2022 04:11:59 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.6014028680876065 on epoch=71
06/17/2022 04:12:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/17/2022 04:12:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.25 on epoch=72
06/17/2022 04:12:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/17/2022 04:12:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
06/17/2022 04:12:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=74
06/17/2022 04:12:21 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.7099647418432997 on epoch=74
06/17/2022 04:12:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7068343140449402 -> 0.7099647418432997 on epoch=74, global_step=1050
06/17/2022 04:12:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=75
06/17/2022 04:12:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=76
06/17/2022 04:12:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=77
06/17/2022 04:12:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
06/17/2022 04:12:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
06/17/2022 04:12:43 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.6373553644331633 on epoch=78
06/17/2022 04:12:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
06/17/2022 04:12:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=79
06/17/2022 04:12:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
06/17/2022 04:12:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=81
06/17/2022 04:12:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=82
06/17/2022 04:13:06 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.7260508140763808 on epoch=82
06/17/2022 04:13:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7099647418432997 -> 0.7260508140763808 on epoch=82, global_step=1150
06/17/2022 04:13:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=82
06/17/2022 04:13:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=83
06/17/2022 04:13:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/17/2022 04:13:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
06/17/2022 04:13:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
06/17/2022 04:13:28 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.719172525912722 on epoch=85
06/17/2022 04:13:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=86
06/17/2022 04:13:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
06/17/2022 04:13:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
06/17/2022 04:13:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=88
06/17/2022 04:13:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/17/2022 04:13:50 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.6874791937148373 on epoch=89
06/17/2022 04:13:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=89
06/17/2022 04:13:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/17/2022 04:13:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/17/2022 04:14:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=92
06/17/2022 04:14:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/17/2022 04:14:12 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.7741554720905095 on epoch=92
06/17/2022 04:14:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7260508140763808 -> 0.7741554720905095 on epoch=92, global_step=1300
06/17/2022 04:14:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=93
06/17/2022 04:14:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=94
06/17/2022 04:14:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/17/2022 04:14:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/17/2022 04:14:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/17/2022 04:14:34 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.7421287146830626 on epoch=96
06/17/2022 04:14:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
06/17/2022 04:14:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/17/2022 04:14:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
06/17/2022 04:14:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
06/17/2022 04:14:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=99
06/17/2022 04:14:56 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.8470411862015278 on epoch=99
06/17/2022 04:14:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7741554720905095 -> 0.8470411862015278 on epoch=99, global_step=1400
06/17/2022 04:14:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
06/17/2022 04:15:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=101
06/17/2022 04:15:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=102
06/17/2022 04:15:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/17/2022 04:15:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/17/2022 04:15:18 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.8370077413854742 on epoch=103
06/17/2022 04:15:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/17/2022 04:15:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/17/2022 04:15:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=105
06/17/2022 04:15:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/17/2022 04:15:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/17/2022 04:15:39 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.7961270789150575 on epoch=107
06/17/2022 04:15:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
06/17/2022 04:15:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/17/2022 04:15:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
06/17/2022 04:15:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
06/17/2022 04:15:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/17/2022 04:16:01 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.8406309297912713 on epoch=110
06/17/2022 04:16:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/17/2022 04:16:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/17/2022 04:16:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/17/2022 04:16:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
06/17/2022 04:16:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=114
06/17/2022 04:16:23 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7518977967531099 on epoch=114
06/17/2022 04:16:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/17/2022 04:16:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/17/2022 04:16:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=116
06/17/2022 04:16:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/17/2022 04:16:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/17/2022 04:16:45 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7990230065168674 on epoch=117
06/17/2022 04:16:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/17/2022 04:16:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/17/2022 04:16:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/17/2022 04:16:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/17/2022 04:17:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/17/2022 04:17:07 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.8587020353001652 on epoch=121
06/17/2022 04:17:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8470411862015278 -> 0.8587020353001652 on epoch=121, global_step=1700
06/17/2022 04:17:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=122
06/17/2022 04:17:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/17/2022 04:17:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/17/2022 04:17:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=124
06/17/2022 04:17:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
06/17/2022 04:17:29 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.8477748707824609 on epoch=124
06/17/2022 04:17:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/17/2022 04:17:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/17/2022 04:17:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.14 on epoch=127
06/17/2022 04:17:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/17/2022 04:17:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/17/2022 04:17:51 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.8499170078792351 on epoch=128
06/17/2022 04:17:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/17/2022 04:17:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/17/2022 04:18:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/17/2022 04:18:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/17/2022 04:18:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/17/2022 04:18:13 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.8461183476526812 on epoch=132
06/17/2022 04:18:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/17/2022 04:18:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/17/2022 04:18:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/17/2022 04:18:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/17/2022 04:18:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/17/2022 04:18:35 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8544564499186771 on epoch=135
06/17/2022 04:18:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/17/2022 04:18:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
06/17/2022 04:18:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/17/2022 04:18:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
06/17/2022 04:18:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.13 on epoch=139
06/17/2022 04:18:57 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.751910533048526 on epoch=139
06/17/2022 04:19:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=139
06/17/2022 04:19:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
06/17/2022 04:19:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
06/17/2022 04:19:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
06/17/2022 04:19:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/17/2022 04:19:19 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7495536306916235 on epoch=142
06/17/2022 04:19:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
06/17/2022 04:19:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/17/2022 04:19:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=144
06/17/2022 04:19:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/17/2022 04:19:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/17/2022 04:19:41 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.8019583199848854 on epoch=146
06/17/2022 04:19:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/17/2022 04:19:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/17/2022 04:19:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/17/2022 04:19:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/17/2022 04:19:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/17/2022 04:20:04 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.795045877588572 on epoch=149
06/17/2022 04:20:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/17/2022 04:20:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/17/2022 04:20:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
06/17/2022 04:20:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/17/2022 04:20:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=153
06/17/2022 04:20:26 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7961470360214062 on epoch=153
06/17/2022 04:20:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/17/2022 04:20:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/17/2022 04:20:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/17/2022 04:20:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/17/2022 04:20:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/17/2022 04:20:48 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.674631384559082 on epoch=157
06/17/2022 04:20:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/17/2022 04:20:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/17/2022 04:20:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=159
06/17/2022 04:20:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/17/2022 04:21:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/17/2022 04:21:10 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.708939424985763 on epoch=160
06/17/2022 04:21:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/17/2022 04:21:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/17/2022 04:21:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/17/2022 04:21:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/17/2022 04:21:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
06/17/2022 04:21:32 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8547881484477703 on epoch=164
06/17/2022 04:21:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/17/2022 04:21:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/17/2022 04:21:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/17/2022 04:21:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
06/17/2022 04:21:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/17/2022 04:21:54 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.801705315557308 on epoch=167
06/17/2022 04:21:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/17/2022 04:22:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/17/2022 04:22:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/17/2022 04:22:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/17/2022 04:22:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/17/2022 04:22:16 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.9142342782665364 on epoch=171
06/17/2022 04:22:16 - INFO - __main__ - Saving model with best Classification-F1: 0.8587020353001652 -> 0.9142342782665364 on epoch=171, global_step=2400
06/17/2022 04:22:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/17/2022 04:22:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/17/2022 04:22:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/17/2022 04:22:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/17/2022 04:22:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/17/2022 04:22:38 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9112973048456919 on epoch=174
06/17/2022 04:22:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/17/2022 04:22:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/17/2022 04:22:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/17/2022 04:22:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/17/2022 04:22:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/17/2022 04:23:00 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.8039708552042518 on epoch=178
06/17/2022 04:23:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/17/2022 04:23:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/17/2022 04:23:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/17/2022 04:23:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/17/2022 04:23:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/17/2022 04:23:22 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.863147605083089 on epoch=182
06/17/2022 04:23:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/17/2022 04:23:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/17/2022 04:23:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/17/2022 04:23:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/17/2022 04:23:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/17/2022 04:23:44 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9142302052785924 on epoch=185
06/17/2022 04:23:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/17/2022 04:23:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/17/2022 04:23:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/17/2022 04:23:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=188
06/17/2022 04:23:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/17/2022 04:24:06 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.9228413163897036 on epoch=189
06/17/2022 04:24:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9142342782665364 -> 0.9228413163897036 on epoch=189, global_step=2650
06/17/2022 04:24:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/17/2022 04:24:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/17/2022 04:24:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 04:24:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/17/2022 04:24:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/17/2022 04:24:28 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9206907787552948 on epoch=192
06/17/2022 04:24:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/17/2022 04:24:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/17/2022 04:24:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 04:24:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/17/2022 04:24:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
06/17/2022 04:24:50 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9206907787552948 on epoch=196
06/17/2022 04:24:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/17/2022 04:24:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/17/2022 04:24:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
06/17/2022 04:25:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=199
06/17/2022 04:25:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/17/2022 04:25:12 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7976779975594017 on epoch=199
06/17/2022 04:25:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/17/2022 04:25:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/17/2022 04:25:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/17/2022 04:25:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/17/2022 04:25:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/17/2022 04:25:34 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8609970674486804 on epoch=203
06/17/2022 04:25:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/17/2022 04:25:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 04:25:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/17/2022 04:25:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/17/2022 04:25:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/17/2022 04:25:56 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=207
06/17/2022 04:25:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/17/2022 04:26:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/17/2022 04:26:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/17/2022 04:26:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/17/2022 04:26:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/17/2022 04:26:18 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=210
06/17/2022 04:26:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9228413163897036 -> 0.9865940511101802 on epoch=210, global_step=2950
06/17/2022 04:26:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/17/2022 04:26:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/17/2022 04:26:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/17/2022 04:26:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/17/2022 04:26:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/17/2022 04:26:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:26:34 - INFO - __main__ - Printing 3 examples
06/17/2022 04:26:34 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 04:26:34 - INFO - __main__ - ['Film']
06/17/2022 04:26:34 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 04:26:34 - INFO - __main__ - ['Film']
06/17/2022 04:26:34 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 04:26:34 - INFO - __main__ - ['Film']
06/17/2022 04:26:34 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:26:34 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:26:35 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 04:26:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:26:35 - INFO - __main__ - Printing 3 examples
06/17/2022 04:26:35 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 04:26:35 - INFO - __main__ - ['Film']
06/17/2022 04:26:35 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 04:26:35 - INFO - __main__ - ['Film']
06/17/2022 04:26:35 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 04:26:35 - INFO - __main__ - ['Film']
06/17/2022 04:26:35 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:26:35 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:26:35 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 04:26:40 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.914360540892799 on epoch=214
06/17/2022 04:26:40 - INFO - __main__ - save last model!
06/17/2022 04:26:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 04:26:40 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 04:26:40 - INFO - __main__ - Printing 3 examples
06/17/2022 04:26:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 04:26:40 - INFO - __main__ - ['Animal']
06/17/2022 04:26:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 04:26:40 - INFO - __main__ - ['Animal']
06/17/2022 04:26:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 04:26:40 - INFO - __main__ - ['Village']
06/17/2022 04:26:40 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:26:42 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:26:45 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 04:26:50 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:26:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 04:26:51 - INFO - __main__ - Starting training!
06/17/2022 04:29:07 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/17/2022 04:29:07 - INFO - __main__ - Classification-F1 on test data: 0.4873
06/17/2022 04:29:07 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9865940511101802, test_performance=0.48731606279941536
06/17/2022 04:29:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/17/2022 04:29:08 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:29:08 - INFO - __main__ - Printing 3 examples
06/17/2022 04:29:08 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 04:29:08 - INFO - __main__ - ['Film']
06/17/2022 04:29:08 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 04:29:08 - INFO - __main__ - ['Film']
06/17/2022 04:29:08 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 04:29:08 - INFO - __main__ - ['Film']
06/17/2022 04:29:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:29:09 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:29:09 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 04:29:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:29:09 - INFO - __main__ - Printing 3 examples
06/17/2022 04:29:09 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 04:29:09 - INFO - __main__ - ['Film']
06/17/2022 04:29:09 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 04:29:09 - INFO - __main__ - ['Film']
06/17/2022 04:29:09 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 04:29:09 - INFO - __main__ - ['Film']
06/17/2022 04:29:09 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:29:09 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:29:09 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 04:29:24 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:29:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 04:29:25 - INFO - __main__ - Starting training!
06/17/2022 04:29:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.26 on epoch=0
06/17/2022 04:29:32 - INFO - __main__ - Step 20 Global step 20 Train loss 4.81 on epoch=1
06/17/2022 04:29:35 - INFO - __main__ - Step 30 Global step 30 Train loss 3.95 on epoch=2
06/17/2022 04:29:38 - INFO - __main__ - Step 40 Global step 40 Train loss 3.18 on epoch=2
06/17/2022 04:29:41 - INFO - __main__ - Step 50 Global step 50 Train loss 2.99 on epoch=3
06/17/2022 04:29:47 - INFO - __main__ - Global step 50 Train loss 4.44 Classification-F1 0.11539136245018597 on epoch=3
06/17/2022 04:29:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11539136245018597 on epoch=3, global_step=50
06/17/2022 04:29:50 - INFO - __main__ - Step 60 Global step 60 Train loss 2.58 on epoch=4
06/17/2022 04:29:53 - INFO - __main__ - Step 70 Global step 70 Train loss 2.21 on epoch=4
06/17/2022 04:29:56 - INFO - __main__ - Step 80 Global step 80 Train loss 2.17 on epoch=5
06/17/2022 04:29:59 - INFO - __main__ - Step 90 Global step 90 Train loss 1.82 on epoch=6
06/17/2022 04:30:02 - INFO - __main__ - Step 100 Global step 100 Train loss 1.73 on epoch=7
06/17/2022 04:30:07 - INFO - __main__ - Global step 100 Train loss 2.10 Classification-F1 0.1490812873186001 on epoch=7
06/17/2022 04:30:07 - INFO - __main__ - Saving model with best Classification-F1: 0.11539136245018597 -> 0.1490812873186001 on epoch=7, global_step=100
06/17/2022 04:30:10 - INFO - __main__ - Step 110 Global step 110 Train loss 1.43 on epoch=7
06/17/2022 04:30:13 - INFO - __main__ - Step 120 Global step 120 Train loss 1.51 on epoch=8
06/17/2022 04:30:16 - INFO - __main__ - Step 130 Global step 130 Train loss 1.16 on epoch=9
06/17/2022 04:30:19 - INFO - __main__ - Step 140 Global step 140 Train loss 1.22 on epoch=9
06/17/2022 04:30:22 - INFO - __main__ - Step 150 Global step 150 Train loss 1.01 on epoch=10
06/17/2022 04:30:28 - INFO - __main__ - Global step 150 Train loss 1.27 Classification-F1 0.2902049832070116 on epoch=10
06/17/2022 04:30:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1490812873186001 -> 0.2902049832070116 on epoch=10, global_step=150
06/17/2022 04:30:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.86 on epoch=11
06/17/2022 04:30:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.75 on epoch=12
06/17/2022 04:30:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=12
06/17/2022 04:30:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=13
06/17/2022 04:30:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=14
06/17/2022 04:30:50 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.5238911714061636 on epoch=14
06/17/2022 04:30:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2902049832070116 -> 0.5238911714061636 on epoch=14, global_step=200
06/17/2022 04:30:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=14
06/17/2022 04:30:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.46 on epoch=15
06/17/2022 04:30:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.44 on epoch=16
06/17/2022 04:31:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=17
06/17/2022 04:31:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=17
06/17/2022 04:31:12 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.590107115374016 on epoch=17
06/17/2022 04:31:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5238911714061636 -> 0.590107115374016 on epoch=17, global_step=250
06/17/2022 04:31:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=18
06/17/2022 04:31:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=19
06/17/2022 04:31:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=19
06/17/2022 04:31:24 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=20
06/17/2022 04:31:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=21
06/17/2022 04:31:34 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.6776340840115405 on epoch=21
06/17/2022 04:31:34 - INFO - __main__ - Saving model with best Classification-F1: 0.590107115374016 -> 0.6776340840115405 on epoch=21, global_step=300
06/17/2022 04:31:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=22
06/17/2022 04:31:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=22
06/17/2022 04:31:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=23
06/17/2022 04:31:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=24
06/17/2022 04:31:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=24
06/17/2022 04:31:56 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.7244351734138541 on epoch=24
06/17/2022 04:31:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6776340840115405 -> 0.7244351734138541 on epoch=24, global_step=350
06/17/2022 04:31:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=25
06/17/2022 04:32:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=26
06/17/2022 04:32:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=27
06/17/2022 04:32:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.12 on epoch=27
06/17/2022 04:32:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
06/17/2022 04:32:18 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.7000854750832706 on epoch=28
06/17/2022 04:32:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=29
06/17/2022 04:32:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=29
06/17/2022 04:32:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=30
06/17/2022 04:32:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=31
06/17/2022 04:32:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=32
06/17/2022 04:32:41 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.7159200066220939 on epoch=32
06/17/2022 04:32:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
06/17/2022 04:32:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=33
06/17/2022 04:32:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=34
06/17/2022 04:32:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=34
06/17/2022 04:32:56 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=35
06/17/2022 04:33:03 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.7372723652293546 on epoch=35
06/17/2022 04:33:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7244351734138541 -> 0.7372723652293546 on epoch=35, global_step=500
06/17/2022 04:33:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
06/17/2022 04:33:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=37
06/17/2022 04:33:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=37
06/17/2022 04:33:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=38
06/17/2022 04:33:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=39
06/17/2022 04:33:25 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.7222320129341002 on epoch=39
06/17/2022 04:33:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=39
06/17/2022 04:33:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=40
06/17/2022 04:33:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
06/17/2022 04:33:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/17/2022 04:33:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=42
06/17/2022 04:33:47 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.7439840923711891 on epoch=42
06/17/2022 04:33:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7372723652293546 -> 0.7439840923711891 on epoch=42, global_step=600
06/17/2022 04:33:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
06/17/2022 04:33:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=44
06/17/2022 04:33:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=44
06/17/2022 04:33:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=45
06/17/2022 04:34:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/17/2022 04:34:09 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.8511485826001955 on epoch=46
06/17/2022 04:34:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7439840923711891 -> 0.8511485826001955 on epoch=46, global_step=650
06/17/2022 04:34:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=47
06/17/2022 04:34:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=47
06/17/2022 04:34:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=48
06/17/2022 04:34:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=49
06/17/2022 04:34:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/17/2022 04:34:31 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.7918791406903919 on epoch=49
06/17/2022 04:34:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
06/17/2022 04:34:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
06/17/2022 04:34:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=52
06/17/2022 04:34:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=52
06/17/2022 04:34:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=53
06/17/2022 04:34:53 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.9101857282502446 on epoch=53
06/17/2022 04:34:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8511485826001955 -> 0.9101857282502446 on epoch=53, global_step=750
06/17/2022 04:34:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=54
06/17/2022 04:34:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=54
06/17/2022 04:35:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/17/2022 04:35:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
06/17/2022 04:35:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
06/17/2022 04:35:15 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.9144998370804825 on epoch=57
06/17/2022 04:35:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9101857282502446 -> 0.9144998370804825 on epoch=57, global_step=800
06/17/2022 04:35:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/17/2022 04:35:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=58
06/17/2022 04:35:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
06/17/2022 04:35:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=59
06/17/2022 04:35:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=60
06/17/2022 04:35:37 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.9101857282502446 on epoch=60
06/17/2022 04:35:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=61
06/17/2022 04:35:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/17/2022 04:35:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=62
06/17/2022 04:35:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=63
06/17/2022 04:35:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
06/17/2022 04:35:59 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.9059904548329596 on epoch=64
06/17/2022 04:36:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=64
06/17/2022 04:36:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=65
06/17/2022 04:36:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
06/17/2022 04:36:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
06/17/2022 04:36:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=67
06/17/2022 04:36:21 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.8511485826001955 on epoch=67
06/17/2022 04:36:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=68
06/17/2022 04:36:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=69
06/17/2022 04:36:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
06/17/2022 04:36:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/17/2022 04:36:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
06/17/2022 04:36:43 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=71
06/17/2022 04:36:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9144998370804825 -> 0.9185272075594656 on epoch=71, global_step=1000
06/17/2022 04:36:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=72
06/17/2022 04:36:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/17/2022 04:36:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
06/17/2022 04:36:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/17/2022 04:36:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/17/2022 04:37:06 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9143564679048549 on epoch=74
06/17/2022 04:37:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
06/17/2022 04:37:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/17/2022 04:37:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=77
06/17/2022 04:37:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/17/2022 04:37:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/17/2022 04:37:27 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9144998370804825 on epoch=78
06/17/2022 04:37:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/17/2022 04:37:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/17/2022 04:37:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=80
06/17/2022 04:37:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
06/17/2022 04:37:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/17/2022 04:37:49 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7970198616406822 on epoch=82
06/17/2022 04:37:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
06/17/2022 04:37:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/17/2022 04:37:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
06/17/2022 04:38:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=84
06/17/2022 04:38:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=85
06/17/2022 04:38:11 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.9144998370804825 on epoch=85
06/17/2022 04:38:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
06/17/2022 04:38:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=87
06/17/2022 04:38:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
06/17/2022 04:38:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=88
06/17/2022 04:38:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
06/17/2022 04:38:33 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.863147605083089 on epoch=89
06/17/2022 04:38:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
06/17/2022 04:38:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
06/17/2022 04:38:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
06/17/2022 04:38:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
06/17/2022 04:38:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/17/2022 04:38:55 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.910329097425872 on epoch=92
06/17/2022 04:38:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/17/2022 04:39:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
06/17/2022 04:39:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/17/2022 04:39:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
06/17/2022 04:39:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
06/17/2022 04:39:17 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.910329097425872 on epoch=96
06/17/2022 04:39:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
06/17/2022 04:39:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 04:39:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/17/2022 04:39:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
06/17/2022 04:39:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
06/17/2022 04:39:39 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.9103045636631976 on epoch=99
06/17/2022 04:39:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/17/2022 04:39:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/17/2022 04:39:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
06/17/2022 04:39:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/17/2022 04:39:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/17/2022 04:40:01 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9730344923893313 on epoch=103
06/17/2022 04:40:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9185272075594656 -> 0.9730344923893313 on epoch=103, global_step=1450
06/17/2022 04:40:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/17/2022 04:40:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/17/2022 04:40:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/17/2022 04:40:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/17/2022 04:40:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/17/2022 04:40:23 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9101857282502446 on epoch=107
06/17/2022 04:40:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/17/2022 04:40:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/17/2022 04:40:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/17/2022 04:40:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/17/2022 04:40:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/17/2022 04:40:45 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.9144998370804823 on epoch=110
06/17/2022 04:40:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/17/2022 04:40:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/17/2022 04:40:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/17/2022 04:40:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/17/2022 04:41:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
06/17/2022 04:41:06 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9014122794767957 on epoch=114
06/17/2022 04:41:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/17/2022 04:41:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/17/2022 04:41:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=116
06/17/2022 04:41:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/17/2022 04:41:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/17/2022 04:41:28 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.9014122794767957 on epoch=117
06/17/2022 04:41:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/17/2022 04:41:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=119
06/17/2022 04:41:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/17/2022 04:41:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=120
06/17/2022 04:41:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/17/2022 04:41:50 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=121
06/17/2022 04:41:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 04:41:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/17/2022 04:42:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/17/2022 04:42:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/17/2022 04:42:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/17/2022 04:42:13 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9144998370804825 on epoch=124
06/17/2022 04:42:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 04:42:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/17/2022 04:42:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/17/2022 04:42:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/17/2022 04:42:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/17/2022 04:42:35 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=128
06/17/2022 04:42:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=129
06/17/2022 04:42:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/17/2022 04:42:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 04:42:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/17/2022 04:42:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/17/2022 04:42:57 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9010414253678012 on epoch=132
06/17/2022 04:43:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 04:43:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 04:43:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 04:43:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/17/2022 04:43:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
06/17/2022 04:43:19 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9186460429724188 on epoch=135
06/17/2022 04:43:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/17/2022 04:43:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/17/2022 04:43:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/17/2022 04:43:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=138
06/17/2022 04:43:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/17/2022 04:43:41 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9103331704138159 on epoch=139
06/17/2022 04:43:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
06/17/2022 04:43:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 04:43:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
06/17/2022 04:43:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/17/2022 04:43:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
06/17/2022 04:44:03 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.91023047895128 on epoch=142
06/17/2022 04:44:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
06/17/2022 04:44:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
06/17/2022 04:44:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 04:44:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
06/17/2022 04:44:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 04:44:25 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.9186705767350929 on epoch=146
06/17/2022 04:44:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/17/2022 04:44:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 04:44:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/17/2022 04:44:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/17/2022 04:44:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
06/17/2022 04:44:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9103331704138159 on epoch=149
06/17/2022 04:44:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/17/2022 04:44:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=151
06/17/2022 04:44:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/17/2022 04:44:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/17/2022 04:45:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/17/2022 04:45:09 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=153
06/17/2022 04:45:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/17/2022 04:45:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
06/17/2022 04:45:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/17/2022 04:45:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
06/17/2022 04:45:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 04:45:31 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.9186705767350929 on epoch=157
06/17/2022 04:45:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/17/2022 04:45:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/17/2022 04:45:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/17/2022 04:45:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/17/2022 04:45:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 04:45:53 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=160
06/17/2022 04:45:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/17/2022 04:45:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/17/2022 04:46:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 04:46:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/17/2022 04:46:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/17/2022 04:46:15 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9103045636631976 on epoch=164
06/17/2022 04:46:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/17/2022 04:46:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
06/17/2022 04:46:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/17/2022 04:46:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/17/2022 04:46:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/17/2022 04:46:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9144998370804825 on epoch=167
06/17/2022 04:46:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/17/2022 04:46:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/17/2022 04:46:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/17/2022 04:46:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/17/2022 04:46:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/17/2022 04:46:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9103045636631976 on epoch=171
06/17/2022 04:47:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 04:47:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/17/2022 04:47:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 04:47:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 04:47:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/17/2022 04:47:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=174
06/17/2022 04:47:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/17/2022 04:47:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/17/2022 04:47:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/17/2022 04:47:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/17/2022 04:47:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/17/2022 04:47:43 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=178
06/17/2022 04:47:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 04:47:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/17/2022 04:47:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/17/2022 04:47:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/17/2022 04:47:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/17/2022 04:48:06 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9060597392966693 on epoch=182
06/17/2022 04:48:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/17/2022 04:48:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/17/2022 04:48:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/17/2022 04:48:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/17/2022 04:48:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/17/2022 04:48:28 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.9060597392966693 on epoch=185
06/17/2022 04:48:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 04:48:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 04:48:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/17/2022 04:48:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 04:48:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/17/2022 04:48:50 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.9776567518503005 on epoch=189
06/17/2022 04:48:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9730344923893313 -> 0.9776567518503005 on epoch=189, global_step=2650
06/17/2022 04:48:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/17/2022 04:48:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/17/2022 04:48:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 04:49:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 04:49:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 04:49:12 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.91023047895128 on epoch=192
06/17/2022 04:49:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/17/2022 04:49:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/17/2022 04:49:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/17/2022 04:49:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/17/2022 04:49:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/17/2022 04:49:34 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.963991530478103 on epoch=196
06/17/2022 04:49:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/17/2022 04:49:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 04:49:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 04:49:46 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 04:49:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 04:49:56 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9686137899390722 on epoch=199
06/17/2022 04:49:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/17/2022 04:50:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 04:50:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/17/2022 04:50:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 04:50:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/17/2022 04:50:18 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9775031420192712 on epoch=203
06/17/2022 04:50:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 04:50:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/17/2022 04:50:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 04:50:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/17/2022 04:50:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 04:50:40 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9144998370804825 on epoch=207
06/17/2022 04:50:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/17/2022 04:50:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/17/2022 04:50:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 04:50:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 04:50:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 04:51:02 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9014122794767957 on epoch=210
06/17/2022 04:51:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 04:51:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 04:51:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 04:51:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 04:51:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 04:51:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:51:18 - INFO - __main__ - Printing 3 examples
06/17/2022 04:51:18 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 04:51:18 - INFO - __main__ - ['Film']
06/17/2022 04:51:18 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 04:51:18 - INFO - __main__ - ['Film']
06/17/2022 04:51:18 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 04:51:18 - INFO - __main__ - ['Film']
06/17/2022 04:51:18 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:51:19 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:51:19 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 04:51:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:51:19 - INFO - __main__ - Printing 3 examples
06/17/2022 04:51:19 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 04:51:19 - INFO - __main__ - ['Film']
06/17/2022 04:51:19 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 04:51:19 - INFO - __main__ - ['Film']
06/17/2022 04:51:19 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 04:51:19 - INFO - __main__ - ['Film']
06/17/2022 04:51:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:51:19 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:51:19 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 04:51:24 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9731618160460668 on epoch=214
06/17/2022 04:51:24 - INFO - __main__ - save last model!
06/17/2022 04:51:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 04:51:24 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 04:51:24 - INFO - __main__ - Printing 3 examples
06/17/2022 04:51:24 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 04:51:24 - INFO - __main__ - ['Animal']
06/17/2022 04:51:24 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 04:51:24 - INFO - __main__ - ['Animal']
06/17/2022 04:51:24 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 04:51:24 - INFO - __main__ - ['Village']
06/17/2022 04:51:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:51:26 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:51:29 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 04:51:34 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:51:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 04:51:35 - INFO - __main__ - Starting training!
06/17/2022 04:53:44 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/17/2022 04:53:44 - INFO - __main__ - Classification-F1 on test data: 0.5917
06/17/2022 04:53:45 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9776567518503005, test_performance=0.5917470201361471
06/17/2022 04:53:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/17/2022 04:53:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:53:46 - INFO - __main__ - Printing 3 examples
06/17/2022 04:53:46 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 04:53:46 - INFO - __main__ - ['Film']
06/17/2022 04:53:46 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 04:53:46 - INFO - __main__ - ['Film']
06/17/2022 04:53:46 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 04:53:46 - INFO - __main__ - ['Film']
06/17/2022 04:53:46 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:53:46 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:53:46 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 04:53:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 04:53:46 - INFO - __main__ - Printing 3 examples
06/17/2022 04:53:46 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 04:53:46 - INFO - __main__ - ['Film']
06/17/2022 04:53:46 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 04:53:46 - INFO - __main__ - ['Film']
06/17/2022 04:53:46 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 04:53:46 - INFO - __main__ - ['Film']
06/17/2022 04:53:46 - INFO - __main__ - Tokenizing Input ...
06/17/2022 04:53:46 - INFO - __main__ - Tokenizing Output ...
06/17/2022 04:53:46 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 04:54:01 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 04:54:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 04:54:02 - INFO - __main__ - Starting training!
06/17/2022 04:54:06 - INFO - __main__ - Step 10 Global step 10 Train loss 7.46 on epoch=0
06/17/2022 04:54:09 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/17/2022 04:54:12 - INFO - __main__ - Step 30 Global step 30 Train loss 4.06 on epoch=2
06/17/2022 04:54:15 - INFO - __main__ - Step 40 Global step 40 Train loss 3.45 on epoch=2
06/17/2022 04:54:18 - INFO - __main__ - Step 50 Global step 50 Train loss 3.30 on epoch=3
06/17/2022 04:54:24 - INFO - __main__ - Global step 50 Train loss 4.62 Classification-F1 0.0856364854344323 on epoch=3
06/17/2022 04:54:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0856364854344323 on epoch=3, global_step=50
06/17/2022 04:54:27 - INFO - __main__ - Step 60 Global step 60 Train loss 2.99 on epoch=4
06/17/2022 04:54:30 - INFO - __main__ - Step 70 Global step 70 Train loss 2.32 on epoch=4
06/17/2022 04:54:33 - INFO - __main__ - Step 80 Global step 80 Train loss 2.51 on epoch=5
06/17/2022 04:54:36 - INFO - __main__ - Step 90 Global step 90 Train loss 1.99 on epoch=6
06/17/2022 04:54:39 - INFO - __main__ - Step 100 Global step 100 Train loss 1.96 on epoch=7
06/17/2022 04:54:44 - INFO - __main__ - Global step 100 Train loss 2.35 Classification-F1 0.13424772595662204 on epoch=7
06/17/2022 04:54:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0856364854344323 -> 0.13424772595662204 on epoch=7, global_step=100
06/17/2022 04:54:48 - INFO - __main__ - Step 110 Global step 110 Train loss 1.73 on epoch=7
06/17/2022 04:54:51 - INFO - __main__ - Step 120 Global step 120 Train loss 1.74 on epoch=8
06/17/2022 04:54:54 - INFO - __main__ - Step 130 Global step 130 Train loss 1.45 on epoch=9
06/17/2022 04:54:57 - INFO - __main__ - Step 140 Global step 140 Train loss 1.40 on epoch=9
06/17/2022 04:55:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.36 on epoch=10
06/17/2022 04:55:06 - INFO - __main__ - Global step 150 Train loss 1.54 Classification-F1 0.1808903658342311 on epoch=10
06/17/2022 04:55:06 - INFO - __main__ - Saving model with best Classification-F1: 0.13424772595662204 -> 0.1808903658342311 on epoch=10, global_step=150
06/17/2022 04:55:09 - INFO - __main__ - Step 160 Global step 160 Train loss 1.23 on epoch=11
06/17/2022 04:55:12 - INFO - __main__ - Step 170 Global step 170 Train loss 1.04 on epoch=12
06/17/2022 04:55:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.99 on epoch=12
06/17/2022 04:55:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=13
06/17/2022 04:55:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=14
06/17/2022 04:55:28 - INFO - __main__ - Global step 200 Train loss 1.01 Classification-F1 0.3070441422783378 on epoch=14
06/17/2022 04:55:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1808903658342311 -> 0.3070441422783378 on epoch=14, global_step=200
06/17/2022 04:55:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=14
06/17/2022 04:55:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=15
06/17/2022 04:55:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=16
06/17/2022 04:55:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=17
06/17/2022 04:55:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
06/17/2022 04:55:50 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.4567886797894499 on epoch=17
06/17/2022 04:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.3070441422783378 -> 0.4567886797894499 on epoch=17, global_step=250
06/17/2022 04:55:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=18
06/17/2022 04:55:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=19
06/17/2022 04:55:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
06/17/2022 04:56:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=20
06/17/2022 04:56:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=21
06/17/2022 04:56:12 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.6575699938223395 on epoch=21
06/17/2022 04:56:12 - INFO - __main__ - Saving model with best Classification-F1: 0.4567886797894499 -> 0.6575699938223395 on epoch=21, global_step=300
06/17/2022 04:56:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=22
06/17/2022 04:56:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=22
06/17/2022 04:56:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=23
06/17/2022 04:56:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=24
06/17/2022 04:56:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=24
06/17/2022 04:56:35 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.675560250875819 on epoch=24
06/17/2022 04:56:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6575699938223395 -> 0.675560250875819 on epoch=24, global_step=350
06/17/2022 04:56:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=25
06/17/2022 04:56:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/17/2022 04:56:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=27
06/17/2022 04:56:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=27
06/17/2022 04:56:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=28
06/17/2022 04:56:57 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.7283724340175953 on epoch=28
06/17/2022 04:56:57 - INFO - __main__ - Saving model with best Classification-F1: 0.675560250875819 -> 0.7283724340175953 on epoch=28, global_step=400
06/17/2022 04:57:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=29
06/17/2022 04:57:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=29
06/17/2022 04:57:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=30
06/17/2022 04:57:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
06/17/2022 04:57:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
06/17/2022 04:57:20 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6698086715264384 on epoch=32
06/17/2022 04:57:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
06/17/2022 04:57:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=33
06/17/2022 04:57:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
06/17/2022 04:57:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=34
06/17/2022 04:57:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=35
06/17/2022 04:57:42 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7261196039184655 on epoch=35
06/17/2022 04:57:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
06/17/2022 04:57:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
06/17/2022 04:57:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=37
06/17/2022 04:57:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
06/17/2022 04:57:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
06/17/2022 04:58:05 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.7643436038122945 on epoch=39
06/17/2022 04:58:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7283724340175953 -> 0.7643436038122945 on epoch=39, global_step=550
06/17/2022 04:58:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/17/2022 04:58:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/17/2022 04:58:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=41
06/17/2022 04:58:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/17/2022 04:58:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=42
06/17/2022 04:58:28 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7054287212818622 on epoch=42
06/17/2022 04:58:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
06/17/2022 04:58:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/17/2022 04:58:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=44
06/17/2022 04:58:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=45
06/17/2022 04:58:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
06/17/2022 04:58:50 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.8409506764582666 on epoch=46
06/17/2022 04:58:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7643436038122945 -> 0.8409506764582666 on epoch=46, global_step=650
06/17/2022 04:58:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=47
06/17/2022 04:58:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/17/2022 04:58:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=48
06/17/2022 04:59:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
06/17/2022 04:59:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=49
06/17/2022 04:59:12 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.8409073453428293 on epoch=49
06/17/2022 04:59:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
06/17/2022 04:59:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
06/17/2022 04:59:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=52
06/17/2022 04:59:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/17/2022 04:59:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
06/17/2022 04:59:35 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.8507436714194223 on epoch=53
06/17/2022 04:59:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8409506764582666 -> 0.8507436714194223 on epoch=53, global_step=750
06/17/2022 04:59:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=54
06/17/2022 04:59:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
06/17/2022 04:59:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=55
06/17/2022 04:59:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/17/2022 04:59:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/17/2022 04:59:57 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7355397428070769 on epoch=57
06/17/2022 05:00:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
06/17/2022 05:00:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/17/2022 05:00:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
06/17/2022 05:00:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/17/2022 05:00:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
06/17/2022 05:00:19 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7312763339737756 on epoch=60
06/17/2022 05:00:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/17/2022 05:00:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/17/2022 05:00:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/17/2022 05:00:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/17/2022 05:00:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
06/17/2022 05:00:41 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.808008718200598 on epoch=64
06/17/2022 05:00:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/17/2022 05:00:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/17/2022 05:00:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/17/2022 05:00:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
06/17/2022 05:00:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/17/2022 05:01:04 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.8469557926315434 on epoch=67
06/17/2022 05:01:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
06/17/2022 05:01:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/17/2022 05:01:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/17/2022 05:01:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/17/2022 05:01:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
06/17/2022 05:01:25 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7453137464747588 on epoch=71
06/17/2022 05:01:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=72
06/17/2022 05:01:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/17/2022 05:01:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
06/17/2022 05:01:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/17/2022 05:01:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
06/17/2022 05:01:48 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.8974315216361933 on epoch=74
06/17/2022 05:01:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8507436714194223 -> 0.8974315216361933 on epoch=74, global_step=1050
06/17/2022 05:01:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
06/17/2022 05:01:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
06/17/2022 05:01:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/17/2022 05:02:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
06/17/2022 05:02:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=78
06/17/2022 05:02:10 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7727294471350729 on epoch=78
06/17/2022 05:02:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
06/17/2022 05:02:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/17/2022 05:02:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
06/17/2022 05:02:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
06/17/2022 05:02:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
06/17/2022 05:02:32 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7435833155354028 on epoch=82
06/17/2022 05:02:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/17/2022 05:02:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=83
06/17/2022 05:02:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/17/2022 05:02:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/17/2022 05:02:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=85
06/17/2022 05:02:54 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.8553312866568915 on epoch=85
06/17/2022 05:02:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/17/2022 05:03:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/17/2022 05:03:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
06/17/2022 05:03:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=88
06/17/2022 05:03:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
06/17/2022 05:03:16 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.9144998370804825 on epoch=89
06/17/2022 05:03:16 - INFO - __main__ - Saving model with best Classification-F1: 0.8974315216361933 -> 0.9144998370804825 on epoch=89, global_step=1250
06/17/2022 05:03:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/17/2022 05:03:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/17/2022 05:03:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/17/2022 05:03:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/17/2022 05:03:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=92
06/17/2022 05:03:38 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7901530388569045 on epoch=92
06/17/2022 05:03:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/17/2022 05:03:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
06/17/2022 05:03:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/17/2022 05:03:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
06/17/2022 05:03:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/17/2022 05:04:00 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.9144998370804825 on epoch=96
06/17/2022 05:04:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/17/2022 05:04:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/17/2022 05:04:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
06/17/2022 05:04:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
06/17/2022 05:04:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/17/2022 05:04:22 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8029900523259158 on epoch=99
06/17/2022 05:04:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
06/17/2022 05:04:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/17/2022 05:04:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/17/2022 05:04:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/17/2022 05:04:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/17/2022 05:04:44 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8471041055718476 on epoch=103
06/17/2022 05:04:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
06/17/2022 05:04:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/17/2022 05:04:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/17/2022 05:04:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/17/2022 05:04:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/17/2022 05:05:06 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9101857282502446 on epoch=107
06/17/2022 05:05:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/17/2022 05:05:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/17/2022 05:05:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
06/17/2022 05:05:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
06/17/2022 05:05:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/17/2022 05:05:28 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=110
06/17/2022 05:05:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9144998370804825 -> 0.9186705767350929 on epoch=110, global_step=1550
06/17/2022 05:05:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/17/2022 05:05:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/17/2022 05:05:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/17/2022 05:05:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/17/2022 05:05:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
06/17/2022 05:05:51 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8592375366568915 on epoch=114
06/17/2022 05:05:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/17/2022 05:05:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/17/2022 05:06:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/17/2022 05:06:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/17/2022 05:06:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=117
06/17/2022 05:06:13 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8469634294839383 on epoch=117
06/17/2022 05:06:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/17/2022 05:06:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/17/2022 05:06:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/17/2022 05:06:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/17/2022 05:06:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/17/2022 05:06:35 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.795546501035443 on epoch=121
06/17/2022 05:06:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/17/2022 05:06:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=122
06/17/2022 05:06:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/17/2022 05:06:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/17/2022 05:06:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 05:06:57 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7436608791447501 on epoch=124
06/17/2022 05:07:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/17/2022 05:07:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/17/2022 05:07:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/17/2022 05:07:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/17/2022 05:07:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/17/2022 05:07:19 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7421072493745835 on epoch=128
06/17/2022 05:07:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/17/2022 05:07:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 05:07:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 05:07:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/17/2022 05:07:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/17/2022 05:07:41 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7418579031482258 on epoch=132
06/17/2022 05:07:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 05:07:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 05:07:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/17/2022 05:07:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/17/2022 05:07:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/17/2022 05:08:03 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8512638092260365 on epoch=135
06/17/2022 05:08:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/17/2022 05:08:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
06/17/2022 05:08:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=137
06/17/2022 05:08:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/17/2022 05:08:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/17/2022 05:08:25 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8029900523259158 on epoch=139
06/17/2022 05:08:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/17/2022 05:08:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 05:08:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/17/2022 05:08:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/17/2022 05:08:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 05:08:48 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.799183485711 on epoch=142
06/17/2022 05:08:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/17/2022 05:08:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/17/2022 05:08:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/17/2022 05:09:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/17/2022 05:09:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/17/2022 05:09:10 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7565669343657959 on epoch=146
06/17/2022 05:09:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
06/17/2022 05:09:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 05:09:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/17/2022 05:09:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/17/2022 05:09:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/17/2022 05:09:32 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.855058651026393 on epoch=149
06/17/2022 05:09:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/17/2022 05:09:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/17/2022 05:09:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 05:09:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/17/2022 05:09:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/17/2022 05:09:54 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9101857282502446 on epoch=153
06/17/2022 05:09:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/17/2022 05:10:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/17/2022 05:10:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 05:10:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/17/2022 05:10:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/17/2022 05:10:16 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9059904548329596 on epoch=157
06/17/2022 05:10:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/17/2022 05:10:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/17/2022 05:10:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 05:10:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/17/2022 05:10:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/17/2022 05:10:39 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=160
06/17/2022 05:10:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/17/2022 05:10:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 05:10:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
06/17/2022 05:10:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
06/17/2022 05:10:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/17/2022 05:11:01 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.9059904548329596 on epoch=164
06/17/2022 05:11:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/17/2022 05:11:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/17/2022 05:11:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/17/2022 05:11:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
06/17/2022 05:11:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/17/2022 05:11:23 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=167
06/17/2022 05:11:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/17/2022 05:11:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/17/2022 05:11:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 05:11:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/17/2022 05:11:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 05:11:46 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8551930596285435 on epoch=171
06/17/2022 05:11:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/17/2022 05:11:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/17/2022 05:11:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/17/2022 05:11:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/17/2022 05:12:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/17/2022 05:12:08 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9143564679048553 on epoch=174
06/17/2022 05:12:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/17/2022 05:12:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/17/2022 05:12:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 05:12:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/17/2022 05:12:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/17/2022 05:12:30 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.9101987618116653 on epoch=178
06/17/2022 05:12:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/17/2022 05:12:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 05:12:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/17/2022 05:12:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/17/2022 05:12:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 05:12:52 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9144998370804825 on epoch=182
06/17/2022 05:12:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/17/2022 05:12:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/17/2022 05:13:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/17/2022 05:13:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/17/2022 05:13:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 05:13:15 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9100423590746173 on epoch=185
06/17/2022 05:13:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 05:13:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 05:13:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/17/2022 05:13:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/17/2022 05:13:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 05:13:37 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.9059904548329596 on epoch=189
06/17/2022 05:13:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/17/2022 05:13:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/17/2022 05:13:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/17/2022 05:13:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/17/2022 05:13:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/17/2022 05:13:59 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9101857282502446 on epoch=192
06/17/2022 05:14:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/17/2022 05:14:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 05:14:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/17/2022 05:14:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/17/2022 05:14:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/17/2022 05:14:21 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.855327468230694 on epoch=196
06/17/2022 05:14:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/17/2022 05:14:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/17/2022 05:14:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/17/2022 05:14:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 05:14:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/17/2022 05:14:43 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.9017456304664313 on epoch=199
06/17/2022 05:14:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/17/2022 05:14:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 05:14:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/17/2022 05:14:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/17/2022 05:14:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/17/2022 05:15:05 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9143564679048549 on epoch=203
06/17/2022 05:15:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/17/2022 05:15:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/17/2022 05:15:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/17/2022 05:15:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/17/2022 05:15:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/17/2022 05:15:28 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9101857282502446 on epoch=207
06/17/2022 05:15:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/17/2022 05:15:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/17/2022 05:15:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 05:15:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/17/2022 05:15:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 05:15:50 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7028328903628944 on epoch=210
06/17/2022 05:15:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/17/2022 05:15:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 05:15:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 05:16:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/17/2022 05:16:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 05:16:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:16:06 - INFO - __main__ - Printing 3 examples
06/17/2022 05:16:06 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 05:16:06 - INFO - __main__ - ['Film']
06/17/2022 05:16:06 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 05:16:06 - INFO - __main__ - ['Film']
06/17/2022 05:16:06 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 05:16:06 - INFO - __main__ - ['Film']
06/17/2022 05:16:06 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:16:06 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:16:07 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 05:16:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:16:07 - INFO - __main__ - Printing 3 examples
06/17/2022 05:16:07 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 05:16:07 - INFO - __main__ - ['Film']
06/17/2022 05:16:07 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 05:16:07 - INFO - __main__ - ['Film']
06/17/2022 05:16:07 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 05:16:07 - INFO - __main__ - ['Film']
06/17/2022 05:16:07 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:16:07 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:16:07 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 05:16:12 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7990222496236483 on epoch=214
06/17/2022 05:16:12 - INFO - __main__ - save last model!
06/17/2022 05:16:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 05:16:12 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 05:16:12 - INFO - __main__ - Printing 3 examples
06/17/2022 05:16:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 05:16:12 - INFO - __main__ - ['Animal']
06/17/2022 05:16:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 05:16:12 - INFO - __main__ - ['Animal']
06/17/2022 05:16:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 05:16:12 - INFO - __main__ - ['Village']
06/17/2022 05:16:12 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:16:14 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:16:17 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 05:16:25 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 05:16:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 05:16:26 - INFO - __main__ - Starting training!
06/17/2022 05:18:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/17/2022 05:18:34 - INFO - __main__ - Classification-F1 on test data: 0.6238
06/17/2022 05:18:34 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9186705767350929, test_performance=0.6238182897989675
06/17/2022 05:18:34 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/17/2022 05:18:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:18:35 - INFO - __main__ - Printing 3 examples
06/17/2022 05:18:35 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 05:18:35 - INFO - __main__ - ['Film']
06/17/2022 05:18:35 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 05:18:35 - INFO - __main__ - ['Film']
06/17/2022 05:18:35 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 05:18:35 - INFO - __main__ - ['Film']
06/17/2022 05:18:35 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:18:35 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:18:36 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 05:18:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:18:36 - INFO - __main__ - Printing 3 examples
06/17/2022 05:18:36 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 05:18:36 - INFO - __main__ - ['Film']
06/17/2022 05:18:36 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 05:18:36 - INFO - __main__ - ['Film']
06/17/2022 05:18:36 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 05:18:36 - INFO - __main__ - ['Film']
06/17/2022 05:18:36 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:18:36 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:18:36 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 05:18:51 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 05:18:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 05:18:52 - INFO - __main__ - Starting training!
06/17/2022 05:18:56 - INFO - __main__ - Step 10 Global step 10 Train loss 7.85 on epoch=0
06/17/2022 05:18:59 - INFO - __main__ - Step 20 Global step 20 Train loss 5.37 on epoch=1
06/17/2022 05:19:02 - INFO - __main__ - Step 30 Global step 30 Train loss 4.60 on epoch=2
06/17/2022 05:19:05 - INFO - __main__ - Step 40 Global step 40 Train loss 3.74 on epoch=2
06/17/2022 05:19:08 - INFO - __main__ - Step 50 Global step 50 Train loss 3.70 on epoch=3
06/17/2022 05:19:13 - INFO - __main__ - Global step 50 Train loss 5.05 Classification-F1 0.05179969134392887 on epoch=3
06/17/2022 05:19:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05179969134392887 on epoch=3, global_step=50
06/17/2022 05:19:16 - INFO - __main__ - Step 60 Global step 60 Train loss 3.31 on epoch=4
06/17/2022 05:19:19 - INFO - __main__ - Step 70 Global step 70 Train loss 3.06 on epoch=4
06/17/2022 05:19:22 - INFO - __main__ - Step 80 Global step 80 Train loss 3.10 on epoch=5
06/17/2022 05:19:25 - INFO - __main__ - Step 90 Global step 90 Train loss 2.61 on epoch=6
06/17/2022 05:19:28 - INFO - __main__ - Step 100 Global step 100 Train loss 2.36 on epoch=7
06/17/2022 05:19:33 - INFO - __main__ - Global step 100 Train loss 2.89 Classification-F1 0.12048823288442104 on epoch=7
06/17/2022 05:19:33 - INFO - __main__ - Saving model with best Classification-F1: 0.05179969134392887 -> 0.12048823288442104 on epoch=7, global_step=100
06/17/2022 05:19:36 - INFO - __main__ - Step 110 Global step 110 Train loss 2.10 on epoch=7
06/17/2022 05:19:40 - INFO - __main__ - Step 120 Global step 120 Train loss 2.28 on epoch=8
06/17/2022 05:19:43 - INFO - __main__ - Step 130 Global step 130 Train loss 2.08 on epoch=9
06/17/2022 05:19:46 - INFO - __main__ - Step 140 Global step 140 Train loss 1.76 on epoch=9
06/17/2022 05:19:49 - INFO - __main__ - Step 150 Global step 150 Train loss 1.82 on epoch=10
06/17/2022 05:19:54 - INFO - __main__ - Global step 150 Train loss 2.01 Classification-F1 0.14701013592142623 on epoch=10
06/17/2022 05:19:54 - INFO - __main__ - Saving model with best Classification-F1: 0.12048823288442104 -> 0.14701013592142623 on epoch=10, global_step=150
06/17/2022 05:19:57 - INFO - __main__ - Step 160 Global step 160 Train loss 1.59 on epoch=11
06/17/2022 05:20:00 - INFO - __main__ - Step 170 Global step 170 Train loss 1.60 on epoch=12
06/17/2022 05:20:03 - INFO - __main__ - Step 180 Global step 180 Train loss 1.41 on epoch=12
06/17/2022 05:20:06 - INFO - __main__ - Step 190 Global step 190 Train loss 1.46 on epoch=13
06/17/2022 05:20:09 - INFO - __main__ - Step 200 Global step 200 Train loss 1.24 on epoch=14
06/17/2022 05:20:15 - INFO - __main__ - Global step 200 Train loss 1.46 Classification-F1 0.1935057637126603 on epoch=14
06/17/2022 05:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.14701013592142623 -> 0.1935057637126603 on epoch=14, global_step=200
06/17/2022 05:20:18 - INFO - __main__ - Step 210 Global step 210 Train loss 1.17 on epoch=14
06/17/2022 05:20:21 - INFO - __main__ - Step 220 Global step 220 Train loss 1.26 on epoch=15
06/17/2022 05:20:24 - INFO - __main__ - Step 230 Global step 230 Train loss 1.08 on epoch=16
06/17/2022 05:20:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.95 on epoch=17
06/17/2022 05:20:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.90 on epoch=17
06/17/2022 05:20:36 - INFO - __main__ - Global step 250 Train loss 1.07 Classification-F1 0.28572707107785117 on epoch=17
06/17/2022 05:20:36 - INFO - __main__ - Saving model with best Classification-F1: 0.1935057637126603 -> 0.28572707107785117 on epoch=17, global_step=250
06/17/2022 05:20:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.86 on epoch=18
06/17/2022 05:20:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=19
06/17/2022 05:20:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.77 on epoch=19
06/17/2022 05:20:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=20
06/17/2022 05:20:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.73 on epoch=21
06/17/2022 05:20:58 - INFO - __main__ - Global step 300 Train loss 0.76 Classification-F1 0.4130162370424536 on epoch=21
06/17/2022 05:20:58 - INFO - __main__ - Saving model with best Classification-F1: 0.28572707107785117 -> 0.4130162370424536 on epoch=21, global_step=300
06/17/2022 05:21:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=22
06/17/2022 05:21:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=22
06/17/2022 05:21:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=23
06/17/2022 05:21:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=24
06/17/2022 05:21:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=24
06/17/2022 05:21:19 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.5289290838451742 on epoch=24
06/17/2022 05:21:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4130162370424536 -> 0.5289290838451742 on epoch=24, global_step=350
06/17/2022 05:21:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=25
06/17/2022 05:21:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=26
06/17/2022 05:21:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
06/17/2022 05:21:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=27
06/17/2022 05:21:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=28
06/17/2022 05:21:42 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.6454090238245836 on epoch=28
06/17/2022 05:21:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5289290838451742 -> 0.6454090238245836 on epoch=28, global_step=400
06/17/2022 05:21:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=29
06/17/2022 05:21:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/17/2022 05:21:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=30
06/17/2022 05:21:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=31
06/17/2022 05:21:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=32
06/17/2022 05:22:04 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.7011808622810466 on epoch=32
06/17/2022 05:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6454090238245836 -> 0.7011808622810466 on epoch=32, global_step=450
06/17/2022 05:22:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=32
06/17/2022 05:22:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=33
06/17/2022 05:22:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
06/17/2022 05:22:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=34
06/17/2022 05:22:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
06/17/2022 05:22:26 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.7235078980503227 on epoch=35
06/17/2022 05:22:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7011808622810466 -> 0.7235078980503227 on epoch=35, global_step=500
06/17/2022 05:22:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=36
06/17/2022 05:22:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
06/17/2022 05:22:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/17/2022 05:22:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=38
06/17/2022 05:22:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
06/17/2022 05:22:48 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.7231099624600574 on epoch=39
06/17/2022 05:22:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=39
06/17/2022 05:22:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=40
06/17/2022 05:22:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/17/2022 05:23:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=42
06/17/2022 05:23:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=42
06/17/2022 05:23:10 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.6110645035415249 on epoch=42
06/17/2022 05:23:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=43
06/17/2022 05:23:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
06/17/2022 05:23:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/17/2022 05:23:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=45
06/17/2022 05:23:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=46
06/17/2022 05:23:32 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.6587671938276778 on epoch=46
06/17/2022 05:23:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
06/17/2022 05:23:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/17/2022 05:23:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=48
06/17/2022 05:23:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
06/17/2022 05:23:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
06/17/2022 05:23:54 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6536598569046387 on epoch=49
06/17/2022 05:23:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
06/17/2022 05:24:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=51
06/17/2022 05:24:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=52
06/17/2022 05:24:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/17/2022 05:24:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/17/2022 05:24:16 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6331201034113336 on epoch=53
06/17/2022 05:24:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/17/2022 05:24:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/17/2022 05:24:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
06/17/2022 05:24:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=56
06/17/2022 05:24:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
06/17/2022 05:24:38 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.637095624173423 on epoch=57
06/17/2022 05:24:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/17/2022 05:24:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
06/17/2022 05:24:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
06/17/2022 05:24:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
06/17/2022 05:24:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/17/2022 05:25:00 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.795248773996402 on epoch=60
06/17/2022 05:25:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7235078980503227 -> 0.795248773996402 on epoch=60, global_step=850
06/17/2022 05:25:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
06/17/2022 05:25:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/17/2022 05:25:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/17/2022 05:25:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=63
06/17/2022 05:25:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
06/17/2022 05:25:23 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7917771228339295 on epoch=64
06/17/2022 05:25:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/17/2022 05:25:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/17/2022 05:25:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/17/2022 05:25:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/17/2022 05:25:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=67
06/17/2022 05:25:45 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.851259990799839 on epoch=67
06/17/2022 05:25:45 - INFO - __main__ - Saving model with best Classification-F1: 0.795248773996402 -> 0.851259990799839 on epoch=67, global_step=950
06/17/2022 05:25:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
06/17/2022 05:25:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/17/2022 05:25:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/17/2022 05:25:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/17/2022 05:26:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=71
06/17/2022 05:26:06 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7560378338366953 on epoch=71
06/17/2022 05:26:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/17/2022 05:26:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/17/2022 05:26:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/17/2022 05:26:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/17/2022 05:26:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
06/17/2022 05:26:28 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.7988269794721409 on epoch=74
06/17/2022 05:26:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/17/2022 05:26:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/17/2022 05:26:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/17/2022 05:26:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/17/2022 05:26:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/17/2022 05:26:51 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.9144998370804825 on epoch=78
06/17/2022 05:26:51 - INFO - __main__ - Saving model with best Classification-F1: 0.851259990799839 -> 0.9144998370804825 on epoch=78, global_step=1100
06/17/2022 05:26:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/17/2022 05:26:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/17/2022 05:27:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/17/2022 05:27:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/17/2022 05:27:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/17/2022 05:27:13 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9059904548329598 on epoch=82
06/17/2022 05:27:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/17/2022 05:27:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/17/2022 05:27:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/17/2022 05:27:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/17/2022 05:27:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/17/2022 05:27:35 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8436653400363078 on epoch=85
06/17/2022 05:27:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/17/2022 05:27:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/17/2022 05:27:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/17/2022 05:27:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/17/2022 05:27:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/17/2022 05:27:57 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7450130249413404 on epoch=89
06/17/2022 05:28:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/17/2022 05:28:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/17/2022 05:28:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/17/2022 05:28:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/17/2022 05:28:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/17/2022 05:28:19 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8553312866568915 on epoch=92
06/17/2022 05:28:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/17/2022 05:28:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/17/2022 05:28:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/17/2022 05:28:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/17/2022 05:28:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/17/2022 05:28:41 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8551930596285435 on epoch=96
06/17/2022 05:28:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/17/2022 05:28:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/17/2022 05:28:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/17/2022 05:28:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/17/2022 05:28:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/17/2022 05:29:03 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9143564679048553 on epoch=99
06/17/2022 05:29:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/17/2022 05:29:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/17/2022 05:29:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/17/2022 05:29:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/17/2022 05:29:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/17/2022 05:29:25 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9144998370804825 on epoch=103
06/17/2022 05:29:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/17/2022 05:29:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/17/2022 05:29:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/17/2022 05:29:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/17/2022 05:29:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/17/2022 05:29:46 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9186705767350929 on epoch=107
06/17/2022 05:29:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9144998370804825 -> 0.9186705767350929 on epoch=107, global_step=1500
06/17/2022 05:29:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/17/2022 05:29:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/17/2022 05:29:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/17/2022 05:29:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/17/2022 05:30:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/17/2022 05:30:08 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9101857282502446 on epoch=110
06/17/2022 05:30:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/17/2022 05:30:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/17/2022 05:30:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/17/2022 05:30:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/17/2022 05:30:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/17/2022 05:30:30 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=114
06/17/2022 05:30:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9186705767350929 -> 0.9776304656760065 on epoch=114, global_step=1600
06/17/2022 05:30:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/17/2022 05:30:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/17/2022 05:30:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/17/2022 05:30:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/17/2022 05:30:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/17/2022 05:30:52 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.863147605083089 on epoch=117
06/17/2022 05:30:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/17/2022 05:30:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/17/2022 05:31:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/17/2022 05:31:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/17/2022 05:31:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/17/2022 05:31:14 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9776567518503005 on epoch=121
06/17/2022 05:31:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9776304656760065 -> 0.9776567518503005 on epoch=121, global_step=1700
06/17/2022 05:31:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/17/2022 05:31:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/17/2022 05:31:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/17/2022 05:31:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/17/2022 05:31:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/17/2022 05:31:36 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=124
06/17/2022 05:31:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/17/2022 05:31:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/17/2022 05:31:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/17/2022 05:31:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/17/2022 05:31:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/17/2022 05:31:58 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=128
06/17/2022 05:31:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9776567518503005 -> 0.9821254014802404 on epoch=128, global_step=1800
06/17/2022 05:32:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/17/2022 05:32:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/17/2022 05:32:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/17/2022 05:32:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/17/2022 05:32:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/17/2022 05:32:20 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9101857282502446 on epoch=132
06/17/2022 05:32:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/17/2022 05:32:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/17/2022 05:32:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/17/2022 05:32:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/17/2022 05:32:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/17/2022 05:32:42 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9730344923893313 on epoch=135
06/17/2022 05:32:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/17/2022 05:32:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/17/2022 05:32:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/17/2022 05:32:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/17/2022 05:32:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/17/2022 05:33:04 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9731618160460668 on epoch=139
06/17/2022 05:33:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 05:33:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/17/2022 05:33:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/17/2022 05:33:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/17/2022 05:33:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/17/2022 05:33:27 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=142
06/17/2022 05:33:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9821254014802404 -> 0.9865940511101802 on epoch=142, global_step=2000
06/17/2022 05:33:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/17/2022 05:33:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/17/2022 05:33:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/17/2022 05:33:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/17/2022 05:33:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/17/2022 05:33:49 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.972838705711833 on epoch=146
06/17/2022 05:33:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/17/2022 05:33:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/17/2022 05:33:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/17/2022 05:34:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/17/2022 05:34:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/17/2022 05:34:11 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=149
06/17/2022 05:34:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/17/2022 05:34:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/17/2022 05:34:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/17/2022 05:34:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/17/2022 05:34:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/17/2022 05:34:33 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9685395565850976 on epoch=153
06/17/2022 05:34:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/17/2022 05:34:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/17/2022 05:34:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/17/2022 05:34:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/17/2022 05:34:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
06/17/2022 05:34:55 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9821254014802404 on epoch=157
06/17/2022 05:34:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/17/2022 05:35:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/17/2022 05:35:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/17/2022 05:35:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/17/2022 05:35:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/17/2022 05:35:17 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9731618160460668 on epoch=160
06/17/2022 05:35:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/17/2022 05:35:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 05:35:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/17/2022 05:35:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/17/2022 05:35:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 05:35:40 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9730344923893313 on epoch=164
06/17/2022 05:35:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/17/2022 05:35:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/17/2022 05:35:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/17/2022 05:35:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/17/2022 05:35:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/17/2022 05:36:02 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9776567518503005 on epoch=167
06/17/2022 05:36:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
06/17/2022 05:36:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/17/2022 05:36:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/17/2022 05:36:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/17/2022 05:36:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/17/2022 05:36:24 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=171
06/17/2022 05:36:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/17/2022 05:36:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/17/2022 05:36:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/17/2022 05:36:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/17/2022 05:36:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/17/2022 05:36:46 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9730344923893313 on epoch=174
06/17/2022 05:36:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/17/2022 05:36:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/17/2022 05:36:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/17/2022 05:36:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/17/2022 05:37:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/17/2022 05:37:09 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9821254014802404 on epoch=178
06/17/2022 05:37:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/17/2022 05:37:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/17/2022 05:37:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/17/2022 05:37:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/17/2022 05:37:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/17/2022 05:37:31 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9821254014802404 on epoch=182
06/17/2022 05:37:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/17/2022 05:37:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/17/2022 05:37:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/17/2022 05:37:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/17/2022 05:37:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/17/2022 05:37:53 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=185
06/17/2022 05:37:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/17/2022 05:37:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/17/2022 05:38:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/17/2022 05:38:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/17/2022 05:38:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/17/2022 05:38:15 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=189
06/17/2022 05:38:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/17/2022 05:38:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/17/2022 05:38:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 05:38:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 05:38:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/17/2022 05:38:38 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=192
06/17/2022 05:38:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/17/2022 05:38:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/17/2022 05:38:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/17/2022 05:38:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/17/2022 05:38:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/17/2022 05:39:00 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=196
06/17/2022 05:39:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/17/2022 05:39:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 05:39:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/17/2022 05:39:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/17/2022 05:39:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 05:39:22 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=199
06/17/2022 05:39:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/17/2022 05:39:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/17/2022 05:39:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/17/2022 05:39:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/17/2022 05:39:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/17/2022 05:39:44 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9865940511101802 on epoch=203
06/17/2022 05:39:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/17/2022 05:39:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/17/2022 05:39:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/17/2022 05:39:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/17/2022 05:40:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/17/2022 05:40:07 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=207
06/17/2022 05:40:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/17/2022 05:40:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/17/2022 05:40:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/17/2022 05:40:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/17/2022 05:40:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/17/2022 05:40:29 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9865940511101802 on epoch=210
06/17/2022 05:40:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/17/2022 05:40:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/17/2022 05:40:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/17/2022 05:40:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/17/2022 05:40:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/17/2022 05:40:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:40:46 - INFO - __main__ - Printing 3 examples
06/17/2022 05:40:46 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 05:40:46 - INFO - __main__ - ['Film']
06/17/2022 05:40:46 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 05:40:46 - INFO - __main__ - ['Film']
06/17/2022 05:40:46 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 05:40:46 - INFO - __main__ - ['Film']
06/17/2022 05:40:46 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:40:46 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:40:46 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 05:40:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:40:46 - INFO - __main__ - Printing 3 examples
06/17/2022 05:40:46 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 05:40:46 - INFO - __main__ - ['Film']
06/17/2022 05:40:46 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 05:40:46 - INFO - __main__ - ['Film']
06/17/2022 05:40:46 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 05:40:46 - INFO - __main__ - ['Film']
06/17/2022 05:40:46 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:40:46 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:40:47 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 05:40:51 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=214
06/17/2022 05:40:51 - INFO - __main__ - save last model!
06/17/2022 05:40:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 05:40:51 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 05:40:51 - INFO - __main__ - Printing 3 examples
06/17/2022 05:40:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 05:40:51 - INFO - __main__ - ['Animal']
06/17/2022 05:40:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 05:40:51 - INFO - __main__ - ['Animal']
06/17/2022 05:40:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 05:40:51 - INFO - __main__ - ['Village']
06/17/2022 05:40:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:40:53 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:40:57 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 05:41:03 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 05:41:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 05:41:04 - INFO - __main__ - Starting training!
06/17/2022 05:43:12 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/17/2022 05:43:12 - INFO - __main__ - Classification-F1 on test data: 0.6537
06/17/2022 05:43:12 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9865940511101802, test_performance=0.6537083720300936
06/17/2022 05:43:12 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/17/2022 05:43:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:43:13 - INFO - __main__ - Printing 3 examples
06/17/2022 05:43:13 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/17/2022 05:43:13 - INFO - __main__ - ['Film']
06/17/2022 05:43:13 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/17/2022 05:43:13 - INFO - __main__ - ['Film']
06/17/2022 05:43:13 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/17/2022 05:43:13 - INFO - __main__ - ['Film']
06/17/2022 05:43:13 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:43:13 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:43:14 - INFO - __main__ - Loaded 224 examples from train data
06/17/2022 05:43:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/17/2022 05:43:14 - INFO - __main__ - Printing 3 examples
06/17/2022 05:43:14 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/17/2022 05:43:14 - INFO - __main__ - ['Film']
06/17/2022 05:43:14 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/17/2022 05:43:14 - INFO - __main__ - ['Film']
06/17/2022 05:43:14 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/17/2022 05:43:14 - INFO - __main__ - ['Film']
06/17/2022 05:43:14 - INFO - __main__ - Tokenizing Input ...
06/17/2022 05:43:14 - INFO - __main__ - Tokenizing Output ...
06/17/2022 05:43:14 - INFO - __main__ - Loaded 224 examples from dev data
06/17/2022 05:43:29 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 05:43:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 05:43:30 - INFO - __main__ - Starting training!
06/17/2022 05:43:34 - INFO - __main__ - Step 10 Global step 10 Train loss 8.04 on epoch=0
06/17/2022 05:43:37 - INFO - __main__ - Step 20 Global step 20 Train loss 5.90 on epoch=1
06/17/2022 05:43:40 - INFO - __main__ - Step 30 Global step 30 Train loss 5.29 on epoch=2
06/17/2022 05:43:43 - INFO - __main__ - Step 40 Global step 40 Train loss 4.46 on epoch=2
06/17/2022 05:43:46 - INFO - __main__ - Step 50 Global step 50 Train loss 4.59 on epoch=3
06/17/2022 05:43:52 - INFO - __main__ - Global step 50 Train loss 5.66 Classification-F1 0.0415819209039548 on epoch=3
06/17/2022 05:43:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0415819209039548 on epoch=3, global_step=50
06/17/2022 05:43:55 - INFO - __main__ - Step 60 Global step 60 Train loss 4.03 on epoch=4
06/17/2022 05:43:58 - INFO - __main__ - Step 70 Global step 70 Train loss 3.51 on epoch=4
06/17/2022 05:44:01 - INFO - __main__ - Step 80 Global step 80 Train loss 3.56 on epoch=5
06/17/2022 05:44:04 - INFO - __main__ - Step 90 Global step 90 Train loss 3.18 on epoch=6
06/17/2022 05:44:07 - INFO - __main__ - Step 100 Global step 100 Train loss 3.18 on epoch=7
06/17/2022 05:44:12 - INFO - __main__ - Global step 100 Train loss 3.49 Classification-F1 0.07665262177724791 on epoch=7
06/17/2022 05:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.0415819209039548 -> 0.07665262177724791 on epoch=7, global_step=100
06/17/2022 05:44:15 - INFO - __main__ - Step 110 Global step 110 Train loss 2.82 on epoch=7
06/17/2022 05:44:18 - INFO - __main__ - Step 120 Global step 120 Train loss 2.93 on epoch=8
06/17/2022 05:44:21 - INFO - __main__ - Step 130 Global step 130 Train loss 2.71 on epoch=9
06/17/2022 05:44:24 - INFO - __main__ - Step 140 Global step 140 Train loss 2.46 on epoch=9
06/17/2022 05:44:27 - INFO - __main__ - Step 150 Global step 150 Train loss 2.54 on epoch=10
06/17/2022 05:44:32 - INFO - __main__ - Global step 150 Train loss 2.69 Classification-F1 0.12770765712875973 on epoch=10
06/17/2022 05:44:32 - INFO - __main__ - Saving model with best Classification-F1: 0.07665262177724791 -> 0.12770765712875973 on epoch=10, global_step=150
06/17/2022 05:44:35 - INFO - __main__ - Step 160 Global step 160 Train loss 2.18 on epoch=11
06/17/2022 05:44:38 - INFO - __main__ - Step 170 Global step 170 Train loss 2.19 on epoch=12
06/17/2022 05:44:41 - INFO - __main__ - Step 180 Global step 180 Train loss 1.96 on epoch=12
06/17/2022 05:44:44 - INFO - __main__ - Step 190 Global step 190 Train loss 2.07 on epoch=13
06/17/2022 05:44:48 - INFO - __main__ - Step 200 Global step 200 Train loss 1.94 on epoch=14
06/17/2022 05:44:53 - INFO - __main__ - Global step 200 Train loss 2.07 Classification-F1 0.14531061259002434 on epoch=14
06/17/2022 05:44:53 - INFO - __main__ - Saving model with best Classification-F1: 0.12770765712875973 -> 0.14531061259002434 on epoch=14, global_step=200
06/17/2022 05:44:56 - INFO - __main__ - Step 210 Global step 210 Train loss 1.63 on epoch=14
06/17/2022 05:44:59 - INFO - __main__ - Step 220 Global step 220 Train loss 1.96 on epoch=15
06/17/2022 05:45:02 - INFO - __main__ - Step 230 Global step 230 Train loss 1.59 on epoch=16
06/17/2022 05:45:05 - INFO - __main__ - Step 240 Global step 240 Train loss 1.72 on epoch=17
06/17/2022 05:45:08 - INFO - __main__ - Step 250 Global step 250 Train loss 1.43 on epoch=17
06/17/2022 05:45:14 - INFO - __main__ - Global step 250 Train loss 1.67 Classification-F1 0.15150479493510186 on epoch=17
06/17/2022 05:45:14 - INFO - __main__ - Saving model with best Classification-F1: 0.14531061259002434 -> 0.15150479493510186 on epoch=17, global_step=250
06/17/2022 05:45:17 - INFO - __main__ - Step 260 Global step 260 Train loss 1.47 on epoch=18
06/17/2022 05:45:20 - INFO - __main__ - Step 270 Global step 270 Train loss 1.40 on epoch=19
06/17/2022 05:45:23 - INFO - __main__ - Step 280 Global step 280 Train loss 1.24 on epoch=19
06/17/2022 05:45:26 - INFO - __main__ - Step 290 Global step 290 Train loss 1.46 on epoch=20
06/17/2022 05:45:29 - INFO - __main__ - Step 300 Global step 300 Train loss 1.22 on epoch=21
06/17/2022 05:45:35 - INFO - __main__ - Global step 300 Train loss 1.36 Classification-F1 0.21542999355745227 on epoch=21
06/17/2022 05:45:35 - INFO - __main__ - Saving model with best Classification-F1: 0.15150479493510186 -> 0.21542999355745227 on epoch=21, global_step=300
06/17/2022 05:45:38 - INFO - __main__ - Step 310 Global step 310 Train loss 1.17 on epoch=22
06/17/2022 05:45:41 - INFO - __main__ - Step 320 Global step 320 Train loss 1.10 on epoch=22
06/17/2022 05:45:44 - INFO - __main__ - Step 330 Global step 330 Train loss 1.07 on epoch=23
06/17/2022 05:45:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.99 on epoch=24
06/17/2022 05:45:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.99 on epoch=24
06/17/2022 05:45:56 - INFO - __main__ - Global step 350 Train loss 1.06 Classification-F1 0.2644102833505575 on epoch=24
06/17/2022 05:45:56 - INFO - __main__ - Saving model with best Classification-F1: 0.21542999355745227 -> 0.2644102833505575 on epoch=24, global_step=350
06/17/2022 05:45:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.97 on epoch=25
06/17/2022 05:46:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.89 on epoch=26
06/17/2022 05:46:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.85 on epoch=27
06/17/2022 05:46:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.73 on epoch=27
06/17/2022 05:46:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.81 on epoch=28
06/17/2022 05:46:18 - INFO - __main__ - Global step 400 Train loss 0.85 Classification-F1 0.34842625516555853 on epoch=28
06/17/2022 05:46:18 - INFO - __main__ - Saving model with best Classification-F1: 0.2644102833505575 -> 0.34842625516555853 on epoch=28, global_step=400
06/17/2022 05:46:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.72 on epoch=29
06/17/2022 05:46:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.71 on epoch=29
06/17/2022 05:46:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.71 on epoch=30
06/17/2022 05:46:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.65 on epoch=31
06/17/2022 05:46:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.61 on epoch=32
06/17/2022 05:46:40 - INFO - __main__ - Global step 450 Train loss 0.68 Classification-F1 0.4372680149621608 on epoch=32
06/17/2022 05:46:40 - INFO - __main__ - Saving model with best Classification-F1: 0.34842625516555853 -> 0.4372680149621608 on epoch=32, global_step=450
06/17/2022 05:46:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.54 on epoch=32
06/17/2022 05:46:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.57 on epoch=33
06/17/2022 05:46:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.57 on epoch=34
06/17/2022 05:46:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.52 on epoch=34
06/17/2022 05:46:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.53 on epoch=35
06/17/2022 05:47:02 - INFO - __main__ - Global step 500 Train loss 0.54 Classification-F1 0.5339943997673601 on epoch=35
06/17/2022 05:47:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4372680149621608 -> 0.5339943997673601 on epoch=35, global_step=500
06/17/2022 05:47:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=36
06/17/2022 05:47:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.55 on epoch=37
06/17/2022 05:47:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/17/2022 05:47:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.45 on epoch=38
06/17/2022 05:47:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=39
06/17/2022 05:47:24 - INFO - __main__ - Global step 550 Train loss 0.47 Classification-F1 0.5653171852585342 on epoch=39
06/17/2022 05:47:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5339943997673601 -> 0.5653171852585342 on epoch=39, global_step=550
06/17/2022 05:47:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=39
06/17/2022 05:47:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=40
06/17/2022 05:47:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=41
06/17/2022 05:47:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.48 on epoch=42
06/17/2022 05:47:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.42 on epoch=42
06/17/2022 05:47:47 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.561444355579253 on epoch=42
06/17/2022 05:47:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=43
06/17/2022 05:47:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=44
06/17/2022 05:47:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=44
06/17/2022 05:47:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=45
06/17/2022 05:48:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=46
06/17/2022 05:48:09 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.6180091234929945 on epoch=46
06/17/2022 05:48:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5653171852585342 -> 0.6180091234929945 on epoch=46, global_step=650
06/17/2022 05:48:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=47
06/17/2022 05:48:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
06/17/2022 05:48:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/17/2022 05:48:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=49
06/17/2022 05:48:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
06/17/2022 05:48:31 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.621481952249954 on epoch=49
06/17/2022 05:48:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6180091234929945 -> 0.621481952249954 on epoch=49, global_step=700
06/17/2022 05:48:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=50
06/17/2022 05:48:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=51
06/17/2022 05:48:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=52
06/17/2022 05:48:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
06/17/2022 05:48:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=53
06/17/2022 05:48:53 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.5930737706828789 on epoch=53
06/17/2022 05:48:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=54
06/17/2022 05:48:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=54
06/17/2022 05:49:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/17/2022 05:49:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
06/17/2022 05:49:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/17/2022 05:49:15 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.614285365172462 on epoch=57
06/17/2022 05:49:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=57
06/17/2022 05:49:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/17/2022 05:49:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
06/17/2022 05:49:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=59
06/17/2022 05:49:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
06/17/2022 05:49:37 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.6230327543889913 on epoch=60
06/17/2022 05:49:37 - INFO - __main__ - Saving model with best Classification-F1: 0.621481952249954 -> 0.6230327543889913 on epoch=60, global_step=850
06/17/2022 05:49:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/17/2022 05:49:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=62
06/17/2022 05:49:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=62
06/17/2022 05:49:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/17/2022 05:49:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
06/17/2022 05:49:59 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.6033867130641324 on epoch=64
06/17/2022 05:50:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
06/17/2022 05:50:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/17/2022 05:50:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=66
06/17/2022 05:50:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/17/2022 05:50:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
06/17/2022 05:50:21 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.620543584002516 on epoch=67
06/17/2022 05:50:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/17/2022 05:50:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
06/17/2022 05:50:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=69
06/17/2022 05:50:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/17/2022 05:50:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/17/2022 05:50:43 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.6469227796072898 on epoch=71
06/17/2022 05:50:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6230327543889913 -> 0.6469227796072898 on epoch=71, global_step=1000
06/17/2022 05:50:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
06/17/2022 05:50:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=72
06/17/2022 05:50:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=73
06/17/2022 05:50:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=74
06/17/2022 05:50:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/17/2022 05:51:05 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.5815378208512588 on epoch=74
06/17/2022 05:51:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/17/2022 05:51:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
06/17/2022 05:51:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
06/17/2022 05:51:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
06/17/2022 05:51:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
06/17/2022 05:51:28 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.5904480373861088 on epoch=78
06/17/2022 05:51:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/17/2022 05:51:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/17/2022 05:51:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/17/2022 05:51:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
06/17/2022 05:51:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=82
06/17/2022 05:51:50 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.6801459043682085 on epoch=82
06/17/2022 05:51:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6469227796072898 -> 0.6801459043682085 on epoch=82, global_step=1150
06/17/2022 05:51:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/17/2022 05:51:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/17/2022 05:51:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/17/2022 05:52:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
06/17/2022 05:52:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/17/2022 05:52:12 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.683676674868126 on epoch=85
06/17/2022 05:52:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6801459043682085 -> 0.683676674868126 on epoch=85, global_step=1200
06/17/2022 05:52:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
06/17/2022 05:52:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/17/2022 05:52:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/17/2022 05:52:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/17/2022 05:52:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/17/2022 05:52:34 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6757137714042196 on epoch=89
06/17/2022 05:52:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/17/2022 05:52:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
06/17/2022 05:52:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/17/2022 05:52:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
06/17/2022 05:52:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/17/2022 05:52:57 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6801459043682085 on epoch=92
06/17/2022 05:53:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/17/2022 05:53:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=94
06/17/2022 05:53:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/17/2022 05:53:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/17/2022 05:53:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/17/2022 05:53:19 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7179317879442201 on epoch=96
06/17/2022 05:53:19 - INFO - __main__ - Saving model with best Classification-F1: 0.683676674868126 -> 0.7179317879442201 on epoch=96, global_step=1350
06/17/2022 05:53:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/17/2022 05:53:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/17/2022 05:53:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/17/2022 05:53:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/17/2022 05:53:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/17/2022 05:53:41 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.731668443086643 on epoch=99
06/17/2022 05:53:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7179317879442201 -> 0.731668443086643 on epoch=99, global_step=1400
06/17/2022 05:53:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/17/2022 05:53:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/17/2022 05:53:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/17/2022 05:53:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/17/2022 05:53:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=103
06/17/2022 05:54:03 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.6599276237334154 on epoch=103
06/17/2022 05:54:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/17/2022 05:54:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/17/2022 05:54:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/17/2022 05:54:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
06/17/2022 05:54:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=107
06/17/2022 05:54:25 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6911298860615723 on epoch=107
06/17/2022 05:54:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/17/2022 05:54:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
06/17/2022 05:54:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/17/2022 05:54:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/17/2022 05:54:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/17/2022 05:54:47 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.781989173767043 on epoch=110
06/17/2022 05:54:47 - INFO - __main__ - Saving model with best Classification-F1: 0.731668443086643 -> 0.781989173767043 on epoch=110, global_step=1550
06/17/2022 05:54:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/17/2022 05:54:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/17/2022 05:54:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
06/17/2022 05:55:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/17/2022 05:55:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/17/2022 05:55:10 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8431693513688214 on epoch=114
06/17/2022 05:55:10 - INFO - __main__ - Saving model with best Classification-F1: 0.781989173767043 -> 0.8431693513688214 on epoch=114, global_step=1600
06/17/2022 05:55:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/17/2022 05:55:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/17/2022 05:55:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/17/2022 05:55:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/17/2022 05:55:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/17/2022 05:55:32 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.851398217828187 on epoch=117
06/17/2022 05:55:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8431693513688214 -> 0.851398217828187 on epoch=117, global_step=1650
06/17/2022 05:55:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/17/2022 05:55:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/17/2022 05:55:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/17/2022 05:55:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/17/2022 05:55:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
06/17/2022 05:55:54 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9685395565850976 on epoch=121
06/17/2022 05:55:54 - INFO - __main__ - Saving model with best Classification-F1: 0.851398217828187 -> 0.9685395565850976 on epoch=121, global_step=1700
06/17/2022 05:55:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/17/2022 05:56:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/17/2022 05:56:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/17/2022 05:56:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/17/2022 05:56:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/17/2022 05:56:17 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8975096793360552 on epoch=124
06/17/2022 05:56:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/17/2022 05:56:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/17/2022 05:56:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/17/2022 05:56:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/17/2022 05:56:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/17/2022 05:56:39 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.8551930596285435 on epoch=128
06/17/2022 05:56:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/17/2022 05:56:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/17/2022 05:56:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/17/2022 05:56:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/17/2022 05:56:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
06/17/2022 05:57:01 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.9018237881662932 on epoch=132
06/17/2022 05:57:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/17/2022 05:57:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/17/2022 05:57:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
06/17/2022 05:57:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/17/2022 05:57:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/17/2022 05:57:23 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.9061378969965309 on epoch=135
06/17/2022 05:57:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/17/2022 05:57:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/17/2022 05:57:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/17/2022 05:57:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/17/2022 05:57:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/17/2022 05:57:45 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9018237881662929 on epoch=139
06/17/2022 05:57:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/17/2022 05:57:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/17/2022 05:57:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/17/2022 05:57:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/17/2022 05:58:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/17/2022 05:58:07 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8975096793360552 on epoch=142
06/17/2022 05:58:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
06/17/2022 05:58:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=144
06/17/2022 05:58:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/17/2022 05:58:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/17/2022 05:58:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/17/2022 05:58:29 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9639172971241283 on epoch=146
06/17/2022 05:58:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/17/2022 05:58:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/17/2022 05:58:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/17/2022 05:58:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
06/17/2022 05:58:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/17/2022 05:58:51 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8975096793360552 on epoch=149
06/17/2022 05:58:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/17/2022 05:58:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/17/2022 05:59:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/17/2022 05:59:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/17/2022 05:59:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/17/2022 05:59:13 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.843309263771491 on epoch=153
06/17/2022 05:59:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/17/2022 05:59:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/17/2022 05:59:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/17/2022 05:59:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/17/2022 05:59:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/17/2022 05:59:35 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9059904548329598 on epoch=157
06/17/2022 05:59:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/17/2022 05:59:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/17/2022 05:59:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
06/17/2022 05:59:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/17/2022 05:59:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/17/2022 05:59:57 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9685395565850976 on epoch=160
06/17/2022 06:00:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/17/2022 06:00:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/17/2022 06:00:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/17/2022 06:00:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/17/2022 06:00:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/17/2022 06:00:20 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9639172971241283 on epoch=164
06/17/2022 06:00:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/17/2022 06:00:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/17/2022 06:00:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/17/2022 06:00:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=167
06/17/2022 06:00:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/17/2022 06:00:42 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9730344923893313 on epoch=167
06/17/2022 06:00:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9685395565850976 -> 0.9730344923893313 on epoch=167, global_step=2350
06/17/2022 06:00:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/17/2022 06:00:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/17/2022 06:00:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/17/2022 06:00:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/17/2022 06:00:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/17/2022 06:01:04 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9685395565850976 on epoch=171
06/17/2022 06:01:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
06/17/2022 06:01:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/17/2022 06:01:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/17/2022 06:01:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/17/2022 06:01:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/17/2022 06:01:26 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9639172971241283 on epoch=174
06/17/2022 06:01:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/17/2022 06:01:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/17/2022 06:01:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/17/2022 06:01:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/17/2022 06:01:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/17/2022 06:01:48 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9730344923893313 on epoch=178
06/17/2022 06:01:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/17/2022 06:01:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/17/2022 06:01:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/17/2022 06:02:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/17/2022 06:02:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/17/2022 06:02:10 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9059904548329598 on epoch=182
06/17/2022 06:02:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/17/2022 06:02:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/17/2022 06:02:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/17/2022 06:02:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/17/2022 06:02:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/17/2022 06:02:32 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9101857282502446 on epoch=185
06/17/2022 06:02:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/17/2022 06:02:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/17/2022 06:02:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/17/2022 06:02:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/17/2022 06:02:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/17/2022 06:02:54 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=189
06/17/2022 06:02:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9730344923893313 -> 0.9776304656760065 on epoch=189, global_step=2650
06/17/2022 06:02:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/17/2022 06:03:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/17/2022 06:03:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/17/2022 06:03:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/17/2022 06:03:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/17/2022 06:03:16 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8510002696598915 on epoch=192
06/17/2022 06:03:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/17/2022 06:03:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/17/2022 06:03:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/17/2022 06:03:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/17/2022 06:03:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/17/2022 06:03:39 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9730344923893313 on epoch=196
06/17/2022 06:03:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/17/2022 06:03:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/17/2022 06:03:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/17/2022 06:03:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/17/2022 06:03:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/17/2022 06:04:01 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8510002696598915 on epoch=199
06/17/2022 06:04:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/17/2022 06:04:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/17/2022 06:04:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/17/2022 06:04:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/17/2022 06:04:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/17/2022 06:04:23 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8064040258635562 on epoch=203
06/17/2022 06:04:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/17/2022 06:04:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/17/2022 06:04:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/17/2022 06:04:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/17/2022 06:04:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/17/2022 06:04:45 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8551930596285435 on epoch=207
06/17/2022 06:04:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/17/2022 06:04:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/17/2022 06:04:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/17/2022 06:04:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/17/2022 06:05:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/17/2022 06:05:07 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9060190615835779 on epoch=210
06/17/2022 06:05:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/17/2022 06:05:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/17/2022 06:05:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/17/2022 06:05:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/17/2022 06:05:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/17/2022 06:05:29 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8551930596285435 on epoch=214
06/17/2022 06:05:29 - INFO - __main__ - save last model!
06/17/2022 06:05:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 06:05:29 - INFO - __main__ - Start tokenizing ... 3500 instances
06/17/2022 06:05:29 - INFO - __main__ - Printing 3 examples
06/17/2022 06:05:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/17/2022 06:05:29 - INFO - __main__ - ['Animal']
06/17/2022 06:05:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/17/2022 06:05:29 - INFO - __main__ - ['Animal']
06/17/2022 06:05:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/17/2022 06:05:29 - INFO - __main__ - ['Village']
06/17/2022 06:05:29 - INFO - __main__ - Tokenizing Input ...
06/17/2022 06:05:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 06:05:34 - INFO - __main__ - Loaded 3500 examples from test data
06/17/2022 06:07:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/17/2022 06:07:49 - INFO - __main__ - Classification-F1 on test data: 0.5236
06/17/2022 06:07:50 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9776304656760065, test_performance=0.5235891150073512
