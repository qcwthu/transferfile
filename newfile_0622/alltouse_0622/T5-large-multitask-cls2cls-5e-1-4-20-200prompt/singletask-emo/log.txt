06/17/2022 10:05:19 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='4,5')
06/17/2022 10:05:19 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo
06/17/2022 10:05:19 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='4,5')
06/17/2022 10:05:19 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo
06/17/2022 10:05:21 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/17/2022 10:05:21 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/17/2022 10:05:21 - INFO - __main__ - args.device: cuda:0
06/17/2022 10:05:21 - INFO - __main__ - Using 2 gpus
06/17/2022 10:05:21 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/17/2022 10:05:21 - INFO - __main__ - args.device: cuda:1
06/17/2022 10:05:21 - INFO - __main__ - Using 2 gpus
06/17/2022 10:05:21 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/17/2022 10:05:25 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/17/2022 10:05:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:05:26 - INFO - __main__ - Printing 3 examples
06/17/2022 10:05:26 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:05:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:05:26 - INFO - __main__ - Printing 3 examples
06/17/2022 10:05:26 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:05:26 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:05:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:05:26 - INFO - __main__ - Printing 3 examples
06/17/2022 10:05:26 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:05:26 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:05:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:05:26 - INFO - __main__ - Printing 3 examples
06/17/2022 10:05:26 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:05:26 - INFO - __main__ - ['others']
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:05:26 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:05:27 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:05:27 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:05:44 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:05:44 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:05:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:05:45 - INFO - __main__ - Starting training!
06/17/2022 10:05:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:05:50 - INFO - __main__ - Starting training!
06/17/2022 10:05:54 - INFO - __main__ - Step 10 Global step 10 Train loss 4.36 on epoch=2
06/17/2022 10:05:56 - INFO - __main__ - Step 20 Global step 20 Train loss 2.93 on epoch=4
06/17/2022 10:05:59 - INFO - __main__ - Step 30 Global step 30 Train loss 2.26 on epoch=7
06/17/2022 10:06:02 - INFO - __main__ - Step 40 Global step 40 Train loss 1.50 on epoch=9
06/17/2022 10:06:04 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=12
06/17/2022 10:06:05 - INFO - __main__ - Global step 50 Train loss 2.46 Classification-F1 0.3358182387787651 on epoch=12
06/17/2022 10:06:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3358182387787651 on epoch=12, global_step=50
06/17/2022 10:06:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.86 on epoch=14
06/17/2022 10:06:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.86 on epoch=17
06/17/2022 10:06:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.69 on epoch=19
06/17/2022 10:06:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=22
06/17/2022 10:06:19 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=24
06/17/2022 10:06:20 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.5490392385741223 on epoch=24
06/17/2022 10:06:20 - INFO - __main__ - Saving model with best Classification-F1: 0.3358182387787651 -> 0.5490392385741223 on epoch=24, global_step=100
06/17/2022 10:06:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.73 on epoch=27
06/17/2022 10:06:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.54 on epoch=29
06/17/2022 10:06:28 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=32
06/17/2022 10:06:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.58 on epoch=34
06/17/2022 10:06:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=37
06/17/2022 10:06:34 - INFO - __main__ - Global step 150 Train loss 0.62 Classification-F1 0.6206043956043956 on epoch=37
06/17/2022 10:06:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5490392385741223 -> 0.6206043956043956 on epoch=37, global_step=150
06/17/2022 10:06:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.65 on epoch=39
06/17/2022 10:06:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.51 on epoch=42
06/17/2022 10:06:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=44
06/17/2022 10:06:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=47
06/17/2022 10:06:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=49
06/17/2022 10:06:48 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.6275252525252526 on epoch=49
06/17/2022 10:06:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6206043956043956 -> 0.6275252525252526 on epoch=49, global_step=200
06/17/2022 10:06:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=52
06/17/2022 10:06:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.47 on epoch=54
06/17/2022 10:06:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=57
06/17/2022 10:06:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
06/17/2022 10:07:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=62
06/17/2022 10:07:03 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.6110972360972361 on epoch=62
06/17/2022 10:07:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
06/17/2022 10:07:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/17/2022 10:07:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=69
06/17/2022 10:07:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=72
06/17/2022 10:07:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/17/2022 10:07:17 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.6965391239584787 on epoch=74
06/17/2022 10:07:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6275252525252526 -> 0.6965391239584787 on epoch=74, global_step=300
06/17/2022 10:07:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/17/2022 10:07:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/17/2022 10:07:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/17/2022 10:07:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=84
06/17/2022 10:07:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=87
06/17/2022 10:07:31 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.6850188351202551 on epoch=87
06/17/2022 10:07:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/17/2022 10:07:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/17/2022 10:07:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=94
06/17/2022 10:07:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=97
06/17/2022 10:07:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=99
06/17/2022 10:07:46 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.7043067226890757 on epoch=99
06/17/2022 10:07:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6965391239584787 -> 0.7043067226890757 on epoch=99, global_step=400
06/17/2022 10:07:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=102
06/17/2022 10:07:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/17/2022 10:07:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=107
06/17/2022 10:07:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=109
06/17/2022 10:07:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/17/2022 10:08:00 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.7192240627724499 on epoch=112
06/17/2022 10:08:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7043067226890757 -> 0.7192240627724499 on epoch=112, global_step=450
06/17/2022 10:08:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
06/17/2022 10:08:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=117
06/17/2022 10:08:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/17/2022 10:08:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/17/2022 10:08:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
06/17/2022 10:08:14 - INFO - __main__ - Global step 500 Train loss 0.15 Classification-F1 0.7320631700956245 on epoch=124
06/17/2022 10:08:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7192240627724499 -> 0.7320631700956245 on epoch=124, global_step=500
06/17/2022 10:08:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/17/2022 10:08:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=129
06/17/2022 10:08:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
06/17/2022 10:08:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=134
06/17/2022 10:08:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=137
06/17/2022 10:08:28 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.716006216006216 on epoch=137
06/17/2022 10:08:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=139
06/17/2022 10:08:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=142
06/17/2022 10:08:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
06/17/2022 10:08:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=147
06/17/2022 10:08:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/17/2022 10:08:43 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.721115921115921 on epoch=149
06/17/2022 10:08:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=152
06/17/2022 10:08:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=154
06/17/2022 10:08:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/17/2022 10:08:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/17/2022 10:08:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=162
06/17/2022 10:08:57 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7223473473473473 on epoch=162
06/17/2022 10:09:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=164
06/17/2022 10:09:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/17/2022 10:09:05 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/17/2022 10:09:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
06/17/2022 10:09:10 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=174
06/17/2022 10:09:11 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.730528188286809 on epoch=174
06/17/2022 10:09:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/17/2022 10:09:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=179
06/17/2022 10:09:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/17/2022 10:09:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=184
06/17/2022 10:09:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/17/2022 10:09:26 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.7515756302521008 on epoch=187
06/17/2022 10:09:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7320631700956245 -> 0.7515756302521008 on epoch=187, global_step=750
06/17/2022 10:09:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/17/2022 10:09:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/17/2022 10:09:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/17/2022 10:09:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/17/2022 10:09:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/17/2022 10:09:40 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7199582027168234 on epoch=199
06/17/2022 10:09:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/17/2022 10:09:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/17/2022 10:09:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/17/2022 10:09:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/17/2022 10:09:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/17/2022 10:09:54 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.7459383753501401 on epoch=212
06/17/2022 10:09:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/17/2022 10:10:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/17/2022 10:10:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/17/2022 10:10:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/17/2022 10:10:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/17/2022 10:10:09 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.76105476673428 on epoch=224
06/17/2022 10:10:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7515756302521008 -> 0.76105476673428 on epoch=224, global_step=900
06/17/2022 10:10:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/17/2022 10:10:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/17/2022 10:10:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/17/2022 10:10:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/17/2022 10:10:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/17/2022 10:10:23 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7642495436613084 on epoch=237
06/17/2022 10:10:23 - INFO - __main__ - Saving model with best Classification-F1: 0.76105476673428 -> 0.7642495436613084 on epoch=237, global_step=950
06/17/2022 10:10:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/17/2022 10:10:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 10:10:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
06/17/2022 10:10:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/17/2022 10:10:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 10:10:38 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7280701754385964 on epoch=249
06/17/2022 10:10:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/17/2022 10:10:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/17/2022 10:10:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/17/2022 10:10:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/17/2022 10:10:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/17/2022 10:10:52 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7425295425295426 on epoch=262
06/17/2022 10:10:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 10:10:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/17/2022 10:11:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/17/2022 10:11:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/17/2022 10:11:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/17/2022 10:11:06 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7815957495851005 on epoch=274
06/17/2022 10:11:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7642495436613084 -> 0.7815957495851005 on epoch=274, global_step=1100
06/17/2022 10:11:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/17/2022 10:11:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 10:11:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 10:11:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/17/2022 10:11:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/17/2022 10:11:21 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7663690476190477 on epoch=287
06/17/2022 10:11:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/17/2022 10:11:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/17/2022 10:11:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 10:11:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/17/2022 10:11:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/17/2022 10:11:35 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7716450216450217 on epoch=299
06/17/2022 10:11:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/17/2022 10:11:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/17/2022 10:11:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/17/2022 10:11:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/17/2022 10:11:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 10:11:49 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.766022372140281 on epoch=312
06/17/2022 10:11:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/17/2022 10:11:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/17/2022 10:11:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/17/2022 10:12:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/17/2022 10:12:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/17/2022 10:12:04 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7095238095238094 on epoch=324
06/17/2022 10:12:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/17/2022 10:12:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/17/2022 10:12:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/17/2022 10:12:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/17/2022 10:12:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/17/2022 10:12:18 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.777922077922078 on epoch=337
06/17/2022 10:12:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/17/2022 10:12:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 10:12:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 10:12:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/17/2022 10:12:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/17/2022 10:12:33 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7820075757575757 on epoch=349
06/17/2022 10:12:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7815957495851005 -> 0.7820075757575757 on epoch=349, global_step=1400
06/17/2022 10:12:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 10:12:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 10:12:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/17/2022 10:12:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/17/2022 10:12:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/17/2022 10:12:47 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7821736453201971 on epoch=362
06/17/2022 10:12:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7820075757575757 -> 0.7821736453201971 on epoch=362, global_step=1450
06/17/2022 10:12:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/17/2022 10:12:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 10:12:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/17/2022 10:12:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/17/2022 10:13:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 10:13:02 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7693548387096775 on epoch=374
06/17/2022 10:13:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 10:13:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 10:13:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 10:13:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/17/2022 10:13:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/17/2022 10:13:16 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7593731597199503 on epoch=387
06/17/2022 10:13:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 10:13:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/17/2022 10:13:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 10:13:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 10:13:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 10:13:30 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7853530950305144 on epoch=399
06/17/2022 10:13:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7821736453201971 -> 0.7853530950305144 on epoch=399, global_step=1600
06/17/2022 10:13:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/17/2022 10:13:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 10:13:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 10:13:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/17/2022 10:13:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 10:13:45 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7682072829131652 on epoch=412
06/17/2022 10:13:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 10:13:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 10:13:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/17/2022 10:13:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/17/2022 10:13:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/17/2022 10:13:59 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7551729148503342 on epoch=424
06/17/2022 10:14:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 10:14:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 10:14:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 10:14:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 10:14:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 10:14:13 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.781038221740309 on epoch=437
06/17/2022 10:14:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/17/2022 10:14:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 10:14:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 10:14:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 10:14:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 10:14:28 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.781038221740309 on epoch=449
06/17/2022 10:14:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/17/2022 10:14:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/17/2022 10:14:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/17/2022 10:14:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/17/2022 10:14:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/17/2022 10:14:42 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.781038221740309 on epoch=462
06/17/2022 10:14:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 10:14:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 10:14:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/17/2022 10:14:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 10:14:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 10:14:56 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7854159354159355 on epoch=474
06/17/2022 10:14:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7853530950305144 -> 0.7854159354159355 on epoch=474, global_step=1900
06/17/2022 10:14:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/17/2022 10:15:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 10:15:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 10:15:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 10:15:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/17/2022 10:15:11 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7837218758471131 on epoch=487
06/17/2022 10:15:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/17/2022 10:15:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/17/2022 10:15:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 10:15:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 10:15:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 10:15:25 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7837218758471131 on epoch=499
06/17/2022 10:15:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=502
06/17/2022 10:15:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 10:15:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/17/2022 10:15:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/17/2022 10:15:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 10:15:39 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7807507680491551 on epoch=512
06/17/2022 10:15:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=514
06/17/2022 10:15:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 10:15:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 10:15:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 10:15:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 10:15:54 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7649322660098522 on epoch=524
06/17/2022 10:15:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/17/2022 10:15:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 10:16:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 10:16:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 10:16:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 10:16:08 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7649322660098522 on epoch=537
06/17/2022 10:16:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 10:16:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/17/2022 10:16:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 10:16:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/17/2022 10:16:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 10:16:22 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7422878828950935 on epoch=549
06/17/2022 10:16:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/17/2022 10:16:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 10:16:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 10:16:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 10:16:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 10:16:37 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7650282721542455 on epoch=562
06/17/2022 10:16:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 10:16:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 10:16:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 10:16:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 10:16:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 10:16:51 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7653581593927895 on epoch=574
06/17/2022 10:16:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 10:16:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/17/2022 10:16:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 10:17:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 10:17:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/17/2022 10:17:05 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7813973197732932 on epoch=587
06/17/2022 10:17:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 10:17:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 10:17:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 10:17:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 10:17:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 10:17:20 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7649322660098522 on epoch=599
06/17/2022 10:17:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 10:17:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 10:17:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 10:17:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 10:17:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 10:17:34 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7650282721542455 on epoch=612
06/17/2022 10:17:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 10:17:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=617
06/17/2022 10:17:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 10:17:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 10:17:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 10:17:49 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7816514536849223 on epoch=624
06/17/2022 10:17:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 10:17:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 10:17:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/17/2022 10:17:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/17/2022 10:18:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/17/2022 10:18:03 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.76443796410426 on epoch=637
06/17/2022 10:18:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=639
06/17/2022 10:18:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/17/2022 10:18:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 10:18:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 10:18:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 10:18:17 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7816514536849223 on epoch=649
06/17/2022 10:18:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=652
06/17/2022 10:18:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 10:18:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 10:18:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 10:18:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 10:18:31 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7693548387096775 on epoch=662
06/17/2022 10:18:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 10:18:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/17/2022 10:18:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 10:18:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 10:18:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 10:18:46 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7662803052255385 on epoch=674
06/17/2022 10:18:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/17/2022 10:18:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/17/2022 10:18:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 10:18:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 10:18:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 10:19:00 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7483089318461955 on epoch=687
06/17/2022 10:19:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 10:19:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/17/2022 10:19:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 10:19:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 10:19:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/17/2022 10:19:15 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7847485768500949 on epoch=699
06/17/2022 10:19:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/17/2022 10:19:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 10:19:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 10:19:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 10:19:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/17/2022 10:19:30 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7874338624338625 on epoch=712
06/17/2022 10:19:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7854159354159355 -> 0.7874338624338625 on epoch=712, global_step=2850
06/17/2022 10:19:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 10:19:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 10:19:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 10:19:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/17/2022 10:19:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 10:19:44 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7794422855601943 on epoch=724
06/17/2022 10:19:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 10:19:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 10:19:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 10:19:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 10:19:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 10:19:59 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7794422855601943 on epoch=737
06/17/2022 10:20:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 10:20:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 10:20:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/17/2022 10:20:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 10:20:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 10:20:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:20:14 - INFO - __main__ - Printing 3 examples
06/17/2022 10:20:14 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:20:14 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:20:14 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7662878787878789 on epoch=749
06/17/2022 10:20:14 - INFO - __main__ - save last model!
06/17/2022 10:20:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 10:20:14 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:20:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:20:14 - INFO - __main__ - Printing 3 examples
06/17/2022 10:20:14 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:20:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 10:20:14 - INFO - __main__ - Printing 3 examples
06/17/2022 10:20:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 10:20:14 - INFO - __main__ - ['others']
06/17/2022 10:20:14 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:20:14 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:20:14 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:20:16 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:20:21 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 10:20:32 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:20:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:20:33 - INFO - __main__ - Starting training!
06/17/2022 10:22:11 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/17/2022 10:22:11 - INFO - __main__ - Classification-F1 on test data: 0.5053
06/17/2022 10:22:12 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.7874338624338625, test_performance=0.5053162604046684
06/17/2022 10:22:12 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/17/2022 10:22:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:22:13 - INFO - __main__ - Printing 3 examples
06/17/2022 10:22:13 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:22:13 - INFO - __main__ - ['others']
06/17/2022 10:22:13 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:22:13 - INFO - __main__ - ['others']
06/17/2022 10:22:13 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:22:13 - INFO - __main__ - ['others']
06/17/2022 10:22:13 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:22:13 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:22:13 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:22:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:22:13 - INFO - __main__ - Printing 3 examples
06/17/2022 10:22:13 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:22:13 - INFO - __main__ - ['others']
06/17/2022 10:22:13 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:22:13 - INFO - __main__ - ['others']
06/17/2022 10:22:13 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:22:13 - INFO - __main__ - ['others']
06/17/2022 10:22:13 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:22:13 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:22:13 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:22:28 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:22:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:22:28 - INFO - __main__ - Starting training!
06/17/2022 10:22:32 - INFO - __main__ - Step 10 Global step 10 Train loss 4.27 on epoch=2
06/17/2022 10:22:34 - INFO - __main__ - Step 20 Global step 20 Train loss 3.01 on epoch=4
06/17/2022 10:22:37 - INFO - __main__ - Step 30 Global step 30 Train loss 2.39 on epoch=7
06/17/2022 10:22:40 - INFO - __main__ - Step 40 Global step 40 Train loss 1.82 on epoch=9
06/17/2022 10:22:42 - INFO - __main__ - Step 50 Global step 50 Train loss 1.54 on epoch=12
06/17/2022 10:22:43 - INFO - __main__ - Global step 50 Train loss 2.60 Classification-F1 0.15026347583906705 on epoch=12
06/17/2022 10:22:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15026347583906705 on epoch=12, global_step=50
06/17/2022 10:22:46 - INFO - __main__ - Step 60 Global step 60 Train loss 1.09 on epoch=14
06/17/2022 10:22:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=17
06/17/2022 10:22:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=19
06/17/2022 10:22:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=22
06/17/2022 10:22:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=24
06/17/2022 10:22:57 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.5633840699309249 on epoch=24
06/17/2022 10:22:58 - INFO - __main__ - Saving model with best Classification-F1: 0.15026347583906705 -> 0.5633840699309249 on epoch=24, global_step=100
06/17/2022 10:23:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=27
06/17/2022 10:23:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/17/2022 10:23:05 - INFO - __main__ - Step 130 Global step 130 Train loss 0.68 on epoch=32
06/17/2022 10:23:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=34
06/17/2022 10:23:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.62 on epoch=37
06/17/2022 10:23:12 - INFO - __main__ - Global step 150 Train loss 0.68 Classification-F1 0.6097603946441156 on epoch=37
06/17/2022 10:23:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5633840699309249 -> 0.6097603946441156 on epoch=37, global_step=150
06/17/2022 10:23:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=39
06/17/2022 10:23:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=42
06/17/2022 10:23:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=44
06/17/2022 10:23:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.60 on epoch=47
06/17/2022 10:23:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.47 on epoch=49
06/17/2022 10:23:26 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.6807407407407408 on epoch=49
06/17/2022 10:23:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6097603946441156 -> 0.6807407407407408 on epoch=49, global_step=200
06/17/2022 10:23:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=52
06/17/2022 10:23:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=54
06/17/2022 10:23:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=57
06/17/2022 10:23:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.44 on epoch=59
06/17/2022 10:23:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=62
06/17/2022 10:23:40 - INFO - __main__ - Global step 250 Train loss 0.48 Classification-F1 0.6519037953820562 on epoch=62
06/17/2022 10:23:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=64
06/17/2022 10:23:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=67
06/17/2022 10:23:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=69
06/17/2022 10:23:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=72
06/17/2022 10:23:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=74
06/17/2022 10:23:54 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.663859126984127 on epoch=74
06/17/2022 10:23:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=77
06/17/2022 10:23:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=79
06/17/2022 10:24:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=82
06/17/2022 10:24:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
06/17/2022 10:24:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=87
06/17/2022 10:24:08 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.7287496287496287 on epoch=87
06/17/2022 10:24:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6807407407407408 -> 0.7287496287496287 on epoch=87, global_step=350
06/17/2022 10:24:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/17/2022 10:24:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=92
06/17/2022 10:24:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=94
06/17/2022 10:24:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/17/2022 10:24:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=99
06/17/2022 10:24:22 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.7388666085440279 on epoch=99
06/17/2022 10:24:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7287496287496287 -> 0.7388666085440279 on epoch=99, global_step=400
06/17/2022 10:24:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
06/17/2022 10:24:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=104
06/17/2022 10:24:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=107
06/17/2022 10:24:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/17/2022 10:24:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/17/2022 10:24:36 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.7271489621489622 on epoch=112
06/17/2022 10:24:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=114
06/17/2022 10:24:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/17/2022 10:24:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/17/2022 10:24:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=122
06/17/2022 10:24:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=124
06/17/2022 10:24:50 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.7612058080808081 on epoch=124
06/17/2022 10:24:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7388666085440279 -> 0.7612058080808081 on epoch=124, global_step=500
06/17/2022 10:24:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/17/2022 10:24:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/17/2022 10:24:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
06/17/2022 10:25:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=134
06/17/2022 10:25:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=137
06/17/2022 10:25:04 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7506465517241379 on epoch=137
06/17/2022 10:25:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=139
06/17/2022 10:25:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/17/2022 10:25:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/17/2022 10:25:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/17/2022 10:25:17 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=149
06/17/2022 10:25:18 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7807598039215686 on epoch=149
06/17/2022 10:25:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7612058080808081 -> 0.7807598039215686 on epoch=149, global_step=600
06/17/2022 10:25:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
06/17/2022 10:25:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=154
06/17/2022 10:25:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
06/17/2022 10:25:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/17/2022 10:25:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=162
06/17/2022 10:25:33 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7651833717357911 on epoch=162
06/17/2022 10:25:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/17/2022 10:25:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/17/2022 10:25:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/17/2022 10:25:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=172
06/17/2022 10:25:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
06/17/2022 10:25:47 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.7637310606060606 on epoch=174
06/17/2022 10:25:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=177
06/17/2022 10:25:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/17/2022 10:25:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/17/2022 10:25:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/17/2022 10:26:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
06/17/2022 10:26:01 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.7806695992179864 on epoch=187
06/17/2022 10:26:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=189
06/17/2022 10:26:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/17/2022 10:26:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/17/2022 10:26:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=197
06/17/2022 10:26:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/17/2022 10:26:15 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.7458593114665222 on epoch=199
06/17/2022 10:26:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/17/2022 10:26:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/17/2022 10:26:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/17/2022 10:26:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/17/2022 10:26:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=212
06/17/2022 10:26:29 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7507676384336727 on epoch=212
06/17/2022 10:26:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/17/2022 10:26:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/17/2022 10:26:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/17/2022 10:26:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/17/2022 10:26:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/17/2022 10:26:44 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7981778570013864 on epoch=224
06/17/2022 10:26:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7807598039215686 -> 0.7981778570013864 on epoch=224, global_step=900
06/17/2022 10:26:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/17/2022 10:26:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/17/2022 10:26:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/17/2022 10:26:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/17/2022 10:26:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/17/2022 10:26:58 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7499297533253391 on epoch=237
06/17/2022 10:27:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/17/2022 10:27:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/17/2022 10:27:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/17/2022 10:27:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/17/2022 10:27:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=249
06/17/2022 10:27:12 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7496212121212122 on epoch=249
06/17/2022 10:27:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/17/2022 10:27:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/17/2022 10:27:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=257
06/17/2022 10:27:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/17/2022 10:27:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/17/2022 10:27:26 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7641423724915186 on epoch=262
06/17/2022 10:27:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/17/2022 10:27:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/17/2022 10:27:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/17/2022 10:27:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/17/2022 10:27:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/17/2022 10:27:40 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7981778570013864 on epoch=274
06/17/2022 10:27:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/17/2022 10:27:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/17/2022 10:27:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 10:27:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/17/2022 10:27:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/17/2022 10:27:55 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7845751231527094 on epoch=287
06/17/2022 10:27:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/17/2022 10:28:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/17/2022 10:28:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/17/2022 10:28:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/17/2022 10:28:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=299
06/17/2022 10:28:09 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7845751231527094 on epoch=299
06/17/2022 10:28:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/17/2022 10:28:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/17/2022 10:28:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=307
06/17/2022 10:28:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/17/2022 10:28:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/17/2022 10:28:23 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7512927192820702 on epoch=312
06/17/2022 10:28:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/17/2022 10:28:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/17/2022 10:28:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/17/2022 10:28:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/17/2022 10:28:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/17/2022 10:28:37 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7678646889790399 on epoch=324
06/17/2022 10:28:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/17/2022 10:28:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 10:28:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/17/2022 10:28:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/17/2022 10:28:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/17/2022 10:28:51 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7675054112554112 on epoch=337
06/17/2022 10:28:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/17/2022 10:28:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 10:28:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/17/2022 10:29:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 10:29:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/17/2022 10:29:05 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.76515657127448 on epoch=349
06/17/2022 10:29:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 10:29:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 10:29:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/17/2022 10:29:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/17/2022 10:29:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 10:29:20 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7508611460224364 on epoch=362
06/17/2022 10:29:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/17/2022 10:29:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/17/2022 10:29:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/17/2022 10:29:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=372
06/17/2022 10:29:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 10:29:34 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7675945378151261 on epoch=374
06/17/2022 10:29:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/17/2022 10:29:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/17/2022 10:29:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 10:29:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/17/2022 10:29:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 10:29:48 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7675945378151261 on epoch=387
06/17/2022 10:29:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 10:29:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/17/2022 10:29:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/17/2022 10:29:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/17/2022 10:30:01 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 10:30:02 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7508611460224364 on epoch=399
06/17/2022 10:30:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/17/2022 10:30:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 10:30:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/17/2022 10:30:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/17/2022 10:30:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/17/2022 10:30:16 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8174030902683654 on epoch=412
06/17/2022 10:30:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7981778570013864 -> 0.8174030902683654 on epoch=412, global_step=1650
06/17/2022 10:30:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/17/2022 10:30:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/17/2022 10:30:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 10:30:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/17/2022 10:30:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/17/2022 10:30:30 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7528778596141026 on epoch=424
06/17/2022 10:30:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 10:30:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/17/2022 10:30:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 10:30:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/17/2022 10:30:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 10:30:45 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7816471163245358 on epoch=437
06/17/2022 10:30:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/17/2022 10:30:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=442
06/17/2022 10:30:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/17/2022 10:30:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 10:30:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/17/2022 10:30:58 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7818965517241379 on epoch=449
06/17/2022 10:31:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/17/2022 10:31:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 10:31:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/17/2022 10:31:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/17/2022 10:31:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 10:31:12 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7816236016350114 on epoch=462
06/17/2022 10:31:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 10:31:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 10:31:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/17/2022 10:31:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 10:31:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 10:31:26 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7675054112554112 on epoch=474
06/17/2022 10:31:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/17/2022 10:31:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 10:31:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/17/2022 10:31:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/17/2022 10:31:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/17/2022 10:31:40 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.799763655462185 on epoch=487
06/17/2022 10:31:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 10:31:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 10:31:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 10:31:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/17/2022 10:31:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 10:31:53 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.8007310682893847 on epoch=499
06/17/2022 10:31:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/17/2022 10:31:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/17/2022 10:32:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 10:32:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/17/2022 10:32:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 10:32:07 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7503736016350114 on epoch=512
06/17/2022 10:32:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=514
06/17/2022 10:32:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/17/2022 10:32:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 10:32:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 10:32:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.13 on epoch=524
06/17/2022 10:32:21 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7625294692657122 on epoch=524
06/17/2022 10:32:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.17 on epoch=527
06/17/2022 10:32:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 10:32:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/17/2022 10:32:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 10:32:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 10:32:35 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7808090391581853 on epoch=537
06/17/2022 10:32:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 10:32:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 10:32:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/17/2022 10:32:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/17/2022 10:32:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 10:32:49 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7459391032440035 on epoch=549
06/17/2022 10:32:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 10:32:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 10:32:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 10:32:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 10:33:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 10:33:02 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7832399809453563 on epoch=562
06/17/2022 10:33:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/17/2022 10:33:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/17/2022 10:33:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 10:33:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/17/2022 10:33:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 10:33:16 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7761052444033535 on epoch=574
06/17/2022 10:33:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 10:33:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 10:33:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 10:33:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 10:33:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 10:33:30 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7771421107628005 on epoch=587
06/17/2022 10:33:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 10:33:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/17/2022 10:33:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/17/2022 10:33:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 10:33:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/17/2022 10:33:44 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7617413651896411 on epoch=599
06/17/2022 10:33:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/17/2022 10:33:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 10:33:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 10:33:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 10:33:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 10:33:58 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7945887445887446 on epoch=612
06/17/2022 10:34:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/17/2022 10:34:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 10:34:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 10:34:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/17/2022 10:34:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 10:34:11 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8114967357910906 on epoch=624
06/17/2022 10:34:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/17/2022 10:34:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 10:34:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 10:34:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 10:34:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 10:34:25 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7957742398961809 on epoch=637
06/17/2022 10:34:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 10:34:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 10:34:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 10:34:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/17/2022 10:34:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 10:34:39 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.799763655462185 on epoch=649
06/17/2022 10:34:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 10:34:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 10:34:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/17/2022 10:34:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 10:34:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 10:34:53 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7957742398961809 on epoch=662
06/17/2022 10:34:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 10:34:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 10:35:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=669
06/17/2022 10:35:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/17/2022 10:35:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 10:35:07 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8106844305120168 on epoch=674
06/17/2022 10:35:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/17/2022 10:35:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 10:35:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 10:35:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/17/2022 10:35:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/17/2022 10:35:21 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7827978799973828 on epoch=687
06/17/2022 10:35:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 10:35:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 10:35:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 10:35:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 10:35:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 10:35:34 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7774274201758989 on epoch=699
06/17/2022 10:35:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 10:35:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 10:35:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
06/17/2022 10:35:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 10:35:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/17/2022 10:35:48 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.76515657127448 on epoch=712
06/17/2022 10:35:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 10:35:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=717
06/17/2022 10:35:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 10:35:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 10:36:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 10:36:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7935260311020961 on epoch=724
06/17/2022 10:36:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 10:36:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 10:36:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=732
06/17/2022 10:36:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 10:36:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/17/2022 10:36:17 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7627676377676378 on epoch=737
06/17/2022 10:36:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 10:36:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 10:36:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 10:36:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 10:36:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/17/2022 10:36:30 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7774274201758989 on epoch=749
06/17/2022 10:36:30 - INFO - __main__ - save last model!
06/17/2022 10:36:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 10:36:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 10:36:30 - INFO - __main__ - Printing 3 examples
06/17/2022 10:36:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 10:36:30 - INFO - __main__ - ['others']
06/17/2022 10:36:30 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 10:36:30 - INFO - __main__ - ['others']
06/17/2022 10:36:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 10:36:30 - INFO - __main__ - ['others']
06/17/2022 10:36:30 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:36:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:36:31 - INFO - __main__ - Printing 3 examples
06/17/2022 10:36:31 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:36:31 - INFO - __main__ - ['others']
06/17/2022 10:36:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:36:31 - INFO - __main__ - ['others']
06/17/2022 10:36:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:36:31 - INFO - __main__ - ['others']
06/17/2022 10:36:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:36:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:36:31 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:36:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:36:31 - INFO - __main__ - Printing 3 examples
06/17/2022 10:36:31 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:36:31 - INFO - __main__ - ['others']
06/17/2022 10:36:31 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:36:31 - INFO - __main__ - ['others']
06/17/2022 10:36:31 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:36:31 - INFO - __main__ - ['others']
06/17/2022 10:36:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:36:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:36:31 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:36:33 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:36:38 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 10:36:46 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:36:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:36:47 - INFO - __main__ - Starting training!
06/17/2022 10:38:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/17/2022 10:38:23 - INFO - __main__ - Classification-F1 on test data: 0.3481
06/17/2022 10:38:23 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.8174030902683654, test_performance=0.3481080571294999
06/17/2022 10:38:23 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/17/2022 10:38:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:38:24 - INFO - __main__ - Printing 3 examples
06/17/2022 10:38:24 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:38:24 - INFO - __main__ - ['others']
06/17/2022 10:38:24 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:38:24 - INFO - __main__ - ['others']
06/17/2022 10:38:24 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:38:24 - INFO - __main__ - ['others']
06/17/2022 10:38:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:38:24 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:38:24 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:38:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:38:24 - INFO - __main__ - Printing 3 examples
06/17/2022 10:38:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:38:24 - INFO - __main__ - ['others']
06/17/2022 10:38:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:38:24 - INFO - __main__ - ['others']
06/17/2022 10:38:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:38:24 - INFO - __main__ - ['others']
06/17/2022 10:38:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:38:24 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:38:24 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:38:43 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:38:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:38:44 - INFO - __main__ - Starting training!
06/17/2022 10:38:47 - INFO - __main__ - Step 10 Global step 10 Train loss 4.59 on epoch=2
06/17/2022 10:38:49 - INFO - __main__ - Step 20 Global step 20 Train loss 3.45 on epoch=4
06/17/2022 10:38:52 - INFO - __main__ - Step 30 Global step 30 Train loss 2.93 on epoch=7
06/17/2022 10:38:54 - INFO - __main__ - Step 40 Global step 40 Train loss 2.21 on epoch=9
06/17/2022 10:38:57 - INFO - __main__ - Step 50 Global step 50 Train loss 2.09 on epoch=12
06/17/2022 10:38:59 - INFO - __main__ - Global step 50 Train loss 3.05 Classification-F1 0.05307692307692308 on epoch=12
06/17/2022 10:38:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05307692307692308 on epoch=12, global_step=50
06/17/2022 10:39:01 - INFO - __main__ - Step 60 Global step 60 Train loss 1.58 on epoch=14
06/17/2022 10:39:04 - INFO - __main__ - Step 70 Global step 70 Train loss 1.37 on epoch=17
06/17/2022 10:39:06 - INFO - __main__ - Step 80 Global step 80 Train loss 1.13 on epoch=19
06/17/2022 10:39:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=22
06/17/2022 10:39:12 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=24
06/17/2022 10:39:13 - INFO - __main__ - Global step 100 Train loss 1.17 Classification-F1 0.5715216156392626 on epoch=24
06/17/2022 10:39:13 - INFO - __main__ - Saving model with best Classification-F1: 0.05307692307692308 -> 0.5715216156392626 on epoch=24, global_step=100
06/17/2022 10:39:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/17/2022 10:39:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=29
06/17/2022 10:39:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/17/2022 10:39:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=34
06/17/2022 10:39:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
06/17/2022 10:39:26 - INFO - __main__ - Global step 150 Train loss 0.77 Classification-F1 0.5857721500510874 on epoch=37
06/17/2022 10:39:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5715216156392626 -> 0.5857721500510874 on epoch=37, global_step=150
06/17/2022 10:39:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=39
06/17/2022 10:39:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
06/17/2022 10:39:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
06/17/2022 10:39:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/17/2022 10:39:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=49
06/17/2022 10:39:40 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.6013071895424837 on epoch=49
06/17/2022 10:39:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5857721500510874 -> 0.6013071895424837 on epoch=49, global_step=200
06/17/2022 10:39:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=52
06/17/2022 10:39:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.48 on epoch=54
06/17/2022 10:39:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/17/2022 10:39:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=59
06/17/2022 10:39:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.52 on epoch=62
06/17/2022 10:39:54 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.6454207770064546 on epoch=62
06/17/2022 10:39:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6013071895424837 -> 0.6454207770064546 on epoch=62, global_step=250
06/17/2022 10:39:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=64
06/17/2022 10:39:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=67
06/17/2022 10:40:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=69
06/17/2022 10:40:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=72
06/17/2022 10:40:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=74
06/17/2022 10:40:08 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.6745087266826397 on epoch=74
06/17/2022 10:40:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6454207770064546 -> 0.6745087266826397 on epoch=74, global_step=300
06/17/2022 10:40:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/17/2022 10:40:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=79
06/17/2022 10:40:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
06/17/2022 10:40:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=84
06/17/2022 10:40:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=87
06/17/2022 10:40:22 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6827472976370036 on epoch=87
06/17/2022 10:40:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6745087266826397 -> 0.6827472976370036 on epoch=87, global_step=350
06/17/2022 10:40:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=89
06/17/2022 10:40:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=92
06/17/2022 10:40:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/17/2022 10:40:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/17/2022 10:40:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=99
06/17/2022 10:40:36 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.670211038961039 on epoch=99
06/17/2022 10:40:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=102
06/17/2022 10:40:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/17/2022 10:40:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=107
06/17/2022 10:40:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=109
06/17/2022 10:40:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=112
06/17/2022 10:40:50 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.7125389044506691 on epoch=112
06/17/2022 10:40:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6827472976370036 -> 0.7125389044506691 on epoch=112, global_step=450
06/17/2022 10:40:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/17/2022 10:40:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=117
06/17/2022 10:40:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=119
06/17/2022 10:41:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=122
06/17/2022 10:41:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=124
06/17/2022 10:41:03 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.7035294117647058 on epoch=124
06/17/2022 10:41:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/17/2022 10:41:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=129
06/17/2022 10:41:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/17/2022 10:41:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/17/2022 10:41:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=137
06/17/2022 10:41:17 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.721036621036621 on epoch=137
06/17/2022 10:41:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7125389044506691 -> 0.721036621036621 on epoch=137, global_step=550
06/17/2022 10:41:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/17/2022 10:41:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/17/2022 10:41:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/17/2022 10:41:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/17/2022 10:41:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=149
06/17/2022 10:41:31 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7195374800637958 on epoch=149
06/17/2022 10:41:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/17/2022 10:41:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/17/2022 10:41:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=157
06/17/2022 10:41:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/17/2022 10:41:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/17/2022 10:41:45 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7314775910364146 on epoch=162
06/17/2022 10:41:45 - INFO - __main__ - Saving model with best Classification-F1: 0.721036621036621 -> 0.7314775910364146 on epoch=162, global_step=650
06/17/2022 10:41:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/17/2022 10:41:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=167
06/17/2022 10:41:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=169
06/17/2022 10:41:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/17/2022 10:41:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
06/17/2022 10:41:59 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.780058651026393 on epoch=174
06/17/2022 10:41:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7314775910364146 -> 0.780058651026393 on epoch=174, global_step=700
06/17/2022 10:42:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=177
06/17/2022 10:42:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=179
06/17/2022 10:42:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=182
06/17/2022 10:42:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=184
06/17/2022 10:42:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
06/17/2022 10:42:12 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.7508706011730205 on epoch=187
06/17/2022 10:42:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
06/17/2022 10:42:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/17/2022 10:42:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=194
06/17/2022 10:42:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/17/2022 10:42:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/17/2022 10:42:26 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.6983645983645983 on epoch=199
06/17/2022 10:42:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=202
06/17/2022 10:42:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/17/2022 10:42:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/17/2022 10:42:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=209
06/17/2022 10:42:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=212
06/17/2022 10:42:40 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.7507331378299121 on epoch=212
06/17/2022 10:42:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
06/17/2022 10:42:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/17/2022 10:42:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/17/2022 10:42:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/17/2022 10:42:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/17/2022 10:42:54 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.766465053763441 on epoch=224
06/17/2022 10:42:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/17/2022 10:42:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=229
06/17/2022 10:43:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/17/2022 10:43:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/17/2022 10:43:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/17/2022 10:43:08 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7782961460446247 on epoch=237
06/17/2022 10:43:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=239
06/17/2022 10:43:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/17/2022 10:43:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/17/2022 10:43:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/17/2022 10:43:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=249
06/17/2022 10:43:21 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.779733770340981 on epoch=249
06/17/2022 10:43:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/17/2022 10:43:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=254
06/17/2022 10:43:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=257
06/17/2022 10:43:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/17/2022 10:43:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/17/2022 10:43:35 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.8129751020642861 on epoch=262
06/17/2022 10:43:35 - INFO - __main__ - Saving model with best Classification-F1: 0.780058651026393 -> 0.8129751020642861 on epoch=262, global_step=1050
06/17/2022 10:43:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=264
06/17/2022 10:43:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/17/2022 10:43:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/17/2022 10:43:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
06/17/2022 10:43:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/17/2022 10:43:49 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7953493265993266 on epoch=274
06/17/2022 10:43:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/17/2022 10:43:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/17/2022 10:43:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/17/2022 10:43:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/17/2022 10:44:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/17/2022 10:44:03 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7495583717357911 on epoch=287
06/17/2022 10:44:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=289
06/17/2022 10:44:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/17/2022 10:44:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 10:44:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 10:44:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/17/2022 10:44:17 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7989242919389978 on epoch=299
06/17/2022 10:44:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/17/2022 10:44:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/17/2022 10:44:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=307
06/17/2022 10:44:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/17/2022 10:44:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/17/2022 10:44:31 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7337335043988269 on epoch=312
06/17/2022 10:44:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=314
06/17/2022 10:44:36 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/17/2022 10:44:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/17/2022 10:44:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/17/2022 10:44:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/17/2022 10:44:44 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7640356569027315 on epoch=324
06/17/2022 10:44:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/17/2022 10:44:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/17/2022 10:44:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/17/2022 10:44:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/17/2022 10:44:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/17/2022 10:44:58 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7801350195503421 on epoch=337
06/17/2022 10:45:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/17/2022 10:45:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/17/2022 10:45:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/17/2022 10:45:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/17/2022 10:45:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/17/2022 10:45:12 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7944240196078431 on epoch=349
06/17/2022 10:45:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/17/2022 10:45:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/17/2022 10:45:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/17/2022 10:45:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=359
06/17/2022 10:45:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/17/2022 10:45:25 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7419014708488394 on epoch=362
06/17/2022 10:45:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 10:45:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/17/2022 10:45:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/17/2022 10:45:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=372
06/17/2022 10:45:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/17/2022 10:45:39 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7829912023460411 on epoch=374
06/17/2022 10:45:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/17/2022 10:45:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/17/2022 10:45:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/17/2022 10:45:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/17/2022 10:45:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=387
06/17/2022 10:45:53 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7957905669599218 on epoch=387
06/17/2022 10:45:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/17/2022 10:45:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 10:46:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/17/2022 10:46:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 10:46:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 10:46:07 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.780058651026393 on epoch=399
06/17/2022 10:46:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/17/2022 10:46:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 10:46:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/17/2022 10:46:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/17/2022 10:46:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/17/2022 10:46:20 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7793560606060607 on epoch=412
06/17/2022 10:46:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 10:46:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/17/2022 10:46:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/17/2022 10:46:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/17/2022 10:46:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/17/2022 10:46:34 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7962640518084066 on epoch=424
06/17/2022 10:46:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/17/2022 10:46:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/17/2022 10:46:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/17/2022 10:46:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/17/2022 10:46:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/17/2022 10:46:48 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7667613636363637 on epoch=437
06/17/2022 10:46:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/17/2022 10:46:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/17/2022 10:46:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/17/2022 10:46:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/17/2022 10:47:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/17/2022 10:47:02 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7572390572390573 on epoch=449
06/17/2022 10:47:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/17/2022 10:47:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 10:47:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/17/2022 10:47:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 10:47:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/17/2022 10:47:15 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7808942125237192 on epoch=462
06/17/2022 10:47:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 10:47:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=467
06/17/2022 10:47:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/17/2022 10:47:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 10:47:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/17/2022 10:47:29 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8117291271347249 on epoch=474
06/17/2022 10:47:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 10:47:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 10:47:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/17/2022 10:47:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/17/2022 10:47:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/17/2022 10:47:43 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.778187386569873 on epoch=487
06/17/2022 10:47:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/17/2022 10:47:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/17/2022 10:47:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 10:47:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/17/2022 10:47:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 10:47:56 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8091745457916204 on epoch=499
06/17/2022 10:47:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/17/2022 10:48:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/17/2022 10:48:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/17/2022 10:48:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/17/2022 10:48:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/17/2022 10:48:10 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7962640518084066 on epoch=512
06/17/2022 10:48:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/17/2022 10:48:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/17/2022 10:48:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/17/2022 10:48:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 10:48:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/17/2022 10:48:24 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7961693548387095 on epoch=524
06/17/2022 10:48:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/17/2022 10:48:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/17/2022 10:48:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/17/2022 10:48:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/17/2022 10:48:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 10:48:38 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7957905669599218 on epoch=537
06/17/2022 10:48:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=539
06/17/2022 10:48:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/17/2022 10:48:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/17/2022 10:48:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 10:48:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 10:48:51 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7962640518084066 on epoch=549
06/17/2022 10:48:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/17/2022 10:48:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/17/2022 10:48:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/17/2022 10:49:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 10:49:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 10:49:05 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7962640518084066 on epoch=562
06/17/2022 10:49:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 10:49:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/17/2022 10:49:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/17/2022 10:49:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 10:49:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 10:49:18 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7791957393737148 on epoch=574
06/17/2022 10:49:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/17/2022 10:49:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 10:49:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 10:49:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 10:49:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/17/2022 10:49:32 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7842592592592592 on epoch=587
06/17/2022 10:49:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/17/2022 10:49:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/17/2022 10:49:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/17/2022 10:49:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/17/2022 10:49:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 10:49:46 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7961693548387095 on epoch=599
06/17/2022 10:49:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 10:49:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/17/2022 10:49:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 10:49:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=609
06/17/2022 10:49:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 10:50:00 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7662202380952381 on epoch=612
06/17/2022 10:50:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 10:50:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/17/2022 10:50:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/17/2022 10:50:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/17/2022 10:50:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=624
06/17/2022 10:50:13 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7502097847510879 on epoch=624
06/17/2022 10:50:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 10:50:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/17/2022 10:50:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/17/2022 10:50:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 10:50:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 10:50:27 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7663194444444443 on epoch=637
06/17/2022 10:50:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 10:50:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/17/2022 10:50:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 10:50:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.11 on epoch=647
06/17/2022 10:50:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/17/2022 10:50:41 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7663594470046083 on epoch=649
06/17/2022 10:50:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 10:50:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/17/2022 10:50:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/17/2022 10:50:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/17/2022 10:50:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 10:50:55 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7802689716969472 on epoch=662
06/17/2022 10:50:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 10:51:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=667
06/17/2022 10:51:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 10:51:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 10:51:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 10:51:08 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7502097847510879 on epoch=674
06/17/2022 10:51:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/17/2022 10:51:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/17/2022 10:51:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 10:51:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 10:51:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 10:51:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7679802955665025 on epoch=687
06/17/2022 10:51:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 10:51:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 10:51:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 10:51:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/17/2022 10:51:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=699
06/17/2022 10:51:36 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7802689716969472 on epoch=699
06/17/2022 10:51:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/17/2022 10:51:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 10:51:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.13 on epoch=707
06/17/2022 10:51:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/17/2022 10:51:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 10:51:50 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7656520362130762 on epoch=712
06/17/2022 10:51:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=714
06/17/2022 10:51:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 10:51:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/17/2022 10:52:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/17/2022 10:52:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
06/17/2022 10:52:03 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7802689716969472 on epoch=724
06/17/2022 10:52:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/17/2022 10:52:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 10:52:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 10:52:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 10:52:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 10:52:17 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.8117291271347249 on epoch=737
06/17/2022 10:52:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 10:52:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/17/2022 10:52:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 10:52:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 10:52:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 10:52:31 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8117291271347249 on epoch=749
06/17/2022 10:52:31 - INFO - __main__ - save last model!
06/17/2022 10:52:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 10:52:31 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 10:52:31 - INFO - __main__ - Printing 3 examples
06/17/2022 10:52:31 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:52:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:52:31 - INFO - __main__ - Printing 3 examples
06/17/2022 10:52:31 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:52:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:52:31 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:52:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:52:31 - INFO - __main__ - Printing 3 examples
06/17/2022 10:52:31 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:52:31 - INFO - __main__ - ['others']
06/17/2022 10:52:31 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:52:31 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:52:31 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:52:33 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:52:38 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 10:52:46 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:52:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:52:47 - INFO - __main__ - Starting training!
06/17/2022 10:54:09 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/17/2022 10:54:09 - INFO - __main__ - Classification-F1 on test data: 0.3624
06/17/2022 10:54:10 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.8129751020642861, test_performance=0.3623813849292402
06/17/2022 10:54:10 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/17/2022 10:54:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:54:11 - INFO - __main__ - Printing 3 examples
06/17/2022 10:54:11 - INFO - __main__ -  [emo] how cause yes am listening
06/17/2022 10:54:11 - INFO - __main__ - ['others']
06/17/2022 10:54:11 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/17/2022 10:54:11 - INFO - __main__ - ['others']
06/17/2022 10:54:11 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/17/2022 10:54:11 - INFO - __main__ - ['others']
06/17/2022 10:54:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:54:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:54:11 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 10:54:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 10:54:11 - INFO - __main__ - Printing 3 examples
06/17/2022 10:54:11 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/17/2022 10:54:11 - INFO - __main__ - ['others']
06/17/2022 10:54:11 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/17/2022 10:54:11 - INFO - __main__ - ['others']
06/17/2022 10:54:11 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/17/2022 10:54:11 - INFO - __main__ - ['others']
06/17/2022 10:54:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 10:54:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 10:54:11 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 10:54:30 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 10:54:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 10:54:31 - INFO - __main__ - Starting training!
06/17/2022 10:54:34 - INFO - __main__ - Step 10 Global step 10 Train loss 4.70 on epoch=2
06/17/2022 10:54:36 - INFO - __main__ - Step 20 Global step 20 Train loss 3.58 on epoch=4
06/17/2022 10:54:39 - INFO - __main__ - Step 30 Global step 30 Train loss 3.32 on epoch=7
06/17/2022 10:54:41 - INFO - __main__ - Step 40 Global step 40 Train loss 2.82 on epoch=9
06/17/2022 10:54:44 - INFO - __main__ - Step 50 Global step 50 Train loss 2.47 on epoch=12
06/17/2022 10:54:46 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.012345679012345677 on epoch=12
06/17/2022 10:54:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.012345679012345677 on epoch=12, global_step=50
06/17/2022 10:54:49 - INFO - __main__ - Step 60 Global step 60 Train loss 2.09 on epoch=14
06/17/2022 10:54:51 - INFO - __main__ - Step 70 Global step 70 Train loss 2.08 on epoch=17
06/17/2022 10:54:54 - INFO - __main__ - Step 80 Global step 80 Train loss 1.55 on epoch=19
06/17/2022 10:54:56 - INFO - __main__ - Step 90 Global step 90 Train loss 1.56 on epoch=22
06/17/2022 10:54:59 - INFO - __main__ - Step 100 Global step 100 Train loss 1.25 on epoch=24
06/17/2022 10:55:00 - INFO - __main__ - Global step 100 Train loss 1.70 Classification-F1 0.1382001836547291 on epoch=24
06/17/2022 10:55:00 - INFO - __main__ - Saving model with best Classification-F1: 0.012345679012345677 -> 0.1382001836547291 on epoch=24, global_step=100
06/17/2022 10:55:03 - INFO - __main__ - Step 110 Global step 110 Train loss 1.23 on epoch=27
06/17/2022 10:55:05 - INFO - __main__ - Step 120 Global step 120 Train loss 0.96 on epoch=29
06/17/2022 10:55:08 - INFO - __main__ - Step 130 Global step 130 Train loss 1.11 on epoch=32
06/17/2022 10:55:10 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=34
06/17/2022 10:55:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=37
06/17/2022 10:55:14 - INFO - __main__ - Global step 150 Train loss 1.01 Classification-F1 0.5202380952380952 on epoch=37
06/17/2022 10:55:14 - INFO - __main__ - Saving model with best Classification-F1: 0.1382001836547291 -> 0.5202380952380952 on epoch=37, global_step=150
06/17/2022 10:55:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=39
06/17/2022 10:55:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=42
06/17/2022 10:55:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=44
06/17/2022 10:55:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=47
06/17/2022 10:55:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
06/17/2022 10:55:28 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.5074068088773971 on epoch=49
06/17/2022 10:55:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=52
06/17/2022 10:55:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=54
06/17/2022 10:55:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.75 on epoch=57
06/17/2022 10:55:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=59
06/17/2022 10:55:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=62
06/17/2022 10:55:42 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.5896422418161549 on epoch=62
06/17/2022 10:55:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5202380952380952 -> 0.5896422418161549 on epoch=62, global_step=250
06/17/2022 10:55:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=64
06/17/2022 10:55:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.72 on epoch=67
06/17/2022 10:55:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=69
06/17/2022 10:55:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=72
06/17/2022 10:55:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=74
06/17/2022 10:55:56 - INFO - __main__ - Global step 300 Train loss 0.63 Classification-F1 0.6033514492753623 on epoch=74
06/17/2022 10:55:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5896422418161549 -> 0.6033514492753623 on epoch=74, global_step=300
06/17/2022 10:55:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/17/2022 10:56:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=79
06/17/2022 10:56:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=82
06/17/2022 10:56:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.49 on epoch=84
06/17/2022 10:56:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.64 on epoch=87
06/17/2022 10:56:11 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6477990759240759 on epoch=87
06/17/2022 10:56:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6033514492753623 -> 0.6477990759240759 on epoch=87, global_step=350
06/17/2022 10:56:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=89
06/17/2022 10:56:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=92
06/17/2022 10:56:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=94
06/17/2022 10:56:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=97
06/17/2022 10:56:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=99
06/17/2022 10:56:25 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6964408303367113 on epoch=99
06/17/2022 10:56:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6477990759240759 -> 0.6964408303367113 on epoch=99, global_step=400
06/17/2022 10:56:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=102
06/17/2022 10:56:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=104
06/17/2022 10:56:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=107
06/17/2022 10:56:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.55 on epoch=109
06/17/2022 10:56:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=112
06/17/2022 10:56:39 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.6675828284523937 on epoch=112
06/17/2022 10:56:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=114
06/17/2022 10:56:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=117
06/17/2022 10:56:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=119
06/17/2022 10:56:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=122
06/17/2022 10:56:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=124
06/17/2022 10:56:53 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.6828703703703705 on epoch=124
06/17/2022 10:56:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=127
06/17/2022 10:56:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=129
06/17/2022 10:57:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=132
06/17/2022 10:57:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=134
06/17/2022 10:57:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=137
06/17/2022 10:57:07 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.7084383753501401 on epoch=137
06/17/2022 10:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6964408303367113 -> 0.7084383753501401 on epoch=137, global_step=550
06/17/2022 10:57:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=139
06/17/2022 10:57:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=142
06/17/2022 10:57:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=144
06/17/2022 10:57:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=147
06/17/2022 10:57:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/17/2022 10:57:21 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.748171368861024 on epoch=149
06/17/2022 10:57:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7084383753501401 -> 0.748171368861024 on epoch=149, global_step=600
06/17/2022 10:57:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=152
06/17/2022 10:57:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=154
06/17/2022 10:57:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=157
06/17/2022 10:57:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=159
06/17/2022 10:57:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
06/17/2022 10:57:35 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.7021668087524864 on epoch=162
06/17/2022 10:57:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=164
06/17/2022 10:57:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=167
06/17/2022 10:57:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/17/2022 10:57:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=172
06/17/2022 10:57:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=174
06/17/2022 10:57:49 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.7182314163404264 on epoch=174
06/17/2022 10:57:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=177
06/17/2022 10:57:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/17/2022 10:57:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=182
06/17/2022 10:57:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=184
06/17/2022 10:58:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.33 on epoch=187
06/17/2022 10:58:03 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.7630671036743144 on epoch=187
06/17/2022 10:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.748171368861024 -> 0.7630671036743144 on epoch=187, global_step=750
06/17/2022 10:58:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=189
06/17/2022 10:58:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=192
06/17/2022 10:58:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=194
06/17/2022 10:58:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
06/17/2022 10:58:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/17/2022 10:58:17 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.7601450257522364 on epoch=199
06/17/2022 10:58:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/17/2022 10:58:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=204
06/17/2022 10:58:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/17/2022 10:58:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=209
06/17/2022 10:58:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=212
06/17/2022 10:58:30 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.7759604978354978 on epoch=212
06/17/2022 10:58:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7630671036743144 -> 0.7759604978354978 on epoch=212, global_step=850
06/17/2022 10:58:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/17/2022 10:58:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=217
06/17/2022 10:58:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=219
06/17/2022 10:58:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=222
06/17/2022 10:58:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=224
06/17/2022 10:58:44 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.7759604978354978 on epoch=224
06/17/2022 10:58:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
06/17/2022 10:58:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/17/2022 10:58:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/17/2022 10:58:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/17/2022 10:58:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=237
06/17/2022 10:58:58 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.7601450257522364 on epoch=237
06/17/2022 10:59:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/17/2022 10:59:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/17/2022 10:59:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=244
06/17/2022 10:59:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/17/2022 10:59:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/17/2022 10:59:12 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.7759604978354978 on epoch=249
06/17/2022 10:59:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/17/2022 10:59:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/17/2022 10:59:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=257
06/17/2022 10:59:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/17/2022 10:59:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/17/2022 10:59:26 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.7725961538461538 on epoch=262
06/17/2022 10:59:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=264
06/17/2022 10:59:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=267
06/17/2022 10:59:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/17/2022 10:59:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=272
06/17/2022 10:59:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/17/2022 10:59:40 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.7578388047138047 on epoch=274
06/17/2022 10:59:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/17/2022 10:59:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=279
06/17/2022 10:59:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/17/2022 10:59:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=284
06/17/2022 10:59:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/17/2022 10:59:54 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7601450257522364 on epoch=287
06/17/2022 10:59:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/17/2022 10:59:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=292
06/17/2022 11:00:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=294
06/17/2022 11:00:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=297
06/17/2022 11:00:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/17/2022 11:00:08 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7457796244192895 on epoch=299
06/17/2022 11:00:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=302
06/17/2022 11:00:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/17/2022 11:00:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/17/2022 11:00:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=309
06/17/2022 11:00:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/17/2022 11:00:22 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7967986314760509 on epoch=312
06/17/2022 11:00:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7759604978354978 -> 0.7967986314760509 on epoch=312, global_step=1250
06/17/2022 11:00:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/17/2022 11:00:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=317
06/17/2022 11:00:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/17/2022 11:00:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/17/2022 11:00:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=324
06/17/2022 11:00:36 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7772200965025509 on epoch=324
06/17/2022 11:00:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=327
06/17/2022 11:00:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=329
06/17/2022 11:00:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=332
06/17/2022 11:00:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/17/2022 11:00:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/17/2022 11:00:49 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7912289915966386 on epoch=337
06/17/2022 11:00:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/17/2022 11:00:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
06/17/2022 11:00:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=344
06/17/2022 11:01:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=347
06/17/2022 11:01:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/17/2022 11:01:03 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7772200965025509 on epoch=349
06/17/2022 11:01:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=352
06/17/2022 11:01:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/17/2022 11:01:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/17/2022 11:01:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=359
06/17/2022 11:01:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/17/2022 11:01:17 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7984463946869071 on epoch=362
06/17/2022 11:01:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7967986314760509 -> 0.7984463946869071 on epoch=362, global_step=1450
06/17/2022 11:01:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=364
06/17/2022 11:01:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/17/2022 11:01:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=369
06/17/2022 11:01:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/17/2022 11:01:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
06/17/2022 11:01:31 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7641423724915186 on epoch=374
06/17/2022 11:01:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/17/2022 11:01:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=379
06/17/2022 11:01:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
06/17/2022 11:01:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/17/2022 11:01:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=387
06/17/2022 11:01:45 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7643500948766604 on epoch=387
06/17/2022 11:01:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/17/2022 11:01:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/17/2022 11:01:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=394
06/17/2022 11:01:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/17/2022 11:01:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/17/2022 11:01:59 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.781487191650854 on epoch=399
06/17/2022 11:02:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/17/2022 11:02:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/17/2022 11:02:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/17/2022 11:02:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/17/2022 11:02:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/17/2022 11:02:13 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7949308755760369 on epoch=412
06/17/2022 11:02:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=414
06/17/2022 11:02:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
06/17/2022 11:02:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/17/2022 11:02:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/17/2022 11:02:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/17/2022 11:02:26 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7981427174975563 on epoch=424
06/17/2022 11:02:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/17/2022 11:02:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/17/2022 11:02:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/17/2022 11:02:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/17/2022 11:02:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/17/2022 11:02:40 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7493279569892473 on epoch=437
06/17/2022 11:02:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/17/2022 11:02:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/17/2022 11:02:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/17/2022 11:02:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/17/2022 11:02:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=449
06/17/2022 11:02:54 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.731296992481203 on epoch=449
06/17/2022 11:02:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/17/2022 11:02:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/17/2022 11:03:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/17/2022 11:03:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/17/2022 11:03:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/17/2022 11:03:08 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.709469696969697 on epoch=462
06/17/2022 11:03:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/17/2022 11:03:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/17/2022 11:03:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/17/2022 11:03:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/17/2022 11:03:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/17/2022 11:03:22 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7248217468805705 on epoch=474
06/17/2022 11:03:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/17/2022 11:03:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 11:03:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/17/2022 11:03:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/17/2022 11:03:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/17/2022 11:03:36 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8162399860675723 on epoch=487
06/17/2022 11:03:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7984463946869071 -> 0.8162399860675723 on epoch=487, global_step=1950
06/17/2022 11:03:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/17/2022 11:03:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/17/2022 11:03:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/17/2022 11:03:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/17/2022 11:03:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/17/2022 11:03:49 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7246212121212121 on epoch=499
06/17/2022 11:03:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/17/2022 11:03:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/17/2022 11:03:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/17/2022 11:04:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/17/2022 11:04:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/17/2022 11:04:03 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7506740196078432 on epoch=512
06/17/2022 11:04:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/17/2022 11:04:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/17/2022 11:04:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=519
06/17/2022 11:04:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/17/2022 11:04:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/17/2022 11:04:17 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7320920303605314 on epoch=524
06/17/2022 11:04:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/17/2022 11:04:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
06/17/2022 11:04:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/17/2022 11:04:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
06/17/2022 11:04:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/17/2022 11:04:31 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.730510752688172 on epoch=537
06/17/2022 11:04:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/17/2022 11:04:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/17/2022 11:04:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=544
06/17/2022 11:04:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/17/2022 11:04:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/17/2022 11:04:44 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.734002286491163 on epoch=549
06/17/2022 11:04:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/17/2022 11:04:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/17/2022 11:04:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/17/2022 11:04:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/17/2022 11:04:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/17/2022 11:04:58 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7678030303030303 on epoch=562
06/17/2022 11:05:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/17/2022 11:05:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/17/2022 11:05:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/17/2022 11:05:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/17/2022 11:05:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 11:05:12 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7678030303030303 on epoch=574
06/17/2022 11:05:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/17/2022 11:05:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/17/2022 11:05:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/17/2022 11:05:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/17/2022 11:05:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/17/2022 11:05:26 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7862591431556949 on epoch=587
06/17/2022 11:05:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/17/2022 11:05:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/17/2022 11:05:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/17/2022 11:05:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/17/2022 11:05:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=599
06/17/2022 11:05:40 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7366428928928929 on epoch=599
06/17/2022 11:05:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=602
06/17/2022 11:05:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/17/2022 11:05:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 11:05:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=609
06/17/2022 11:05:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=612
06/17/2022 11:05:53 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7529684095860566 on epoch=612
06/17/2022 11:05:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/17/2022 11:05:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/17/2022 11:06:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/17/2022 11:06:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/17/2022 11:06:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/17/2022 11:06:07 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7517940561804659 on epoch=624
06/17/2022 11:06:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=627
06/17/2022 11:06:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/17/2022 11:06:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=632
06/17/2022 11:06:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/17/2022 11:06:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 11:06:21 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7517940561804659 on epoch=637
06/17/2022 11:06:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/17/2022 11:06:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.15 on epoch=642
06/17/2022 11:06:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/17/2022 11:06:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=647
06/17/2022 11:06:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/17/2022 11:06:35 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7309494559494559 on epoch=649
06/17/2022 11:06:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/17/2022 11:06:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/17/2022 11:06:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=657
06/17/2022 11:06:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/17/2022 11:06:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/17/2022 11:06:49 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7498624473369804 on epoch=662
06/17/2022 11:06:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/17/2022 11:06:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=667
06/17/2022 11:06:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
06/17/2022 11:06:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/17/2022 11:07:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/17/2022 11:07:02 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7855238490380478 on epoch=674
06/17/2022 11:07:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/17/2022 11:07:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 11:07:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 11:07:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=684
06/17/2022 11:07:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/17/2022 11:07:16 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.784100971767006 on epoch=687
06/17/2022 11:07:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/17/2022 11:07:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/17/2022 11:07:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/17/2022 11:07:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/17/2022 11:07:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/17/2022 11:07:30 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7320920303605314 on epoch=699
06/17/2022 11:07:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/17/2022 11:07:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 11:07:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/17/2022 11:07:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/17/2022 11:07:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=712
06/17/2022 11:07:44 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7501052188552189 on epoch=712
06/17/2022 11:07:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/17/2022 11:07:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/17/2022 11:07:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/17/2022 11:07:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/17/2022 11:07:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
06/17/2022 11:07:58 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7694327731092437 on epoch=724
06/17/2022 11:08:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/17/2022 11:08:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=729
06/17/2022 11:08:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/17/2022 11:08:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 11:08:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/17/2022 11:08:11 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7606127679403542 on epoch=737
06/17/2022 11:08:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/17/2022 11:08:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 11:08:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/17/2022 11:08:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=747
06/17/2022 11:08:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 11:08:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7829545454545455 on epoch=749
06/17/2022 11:08:25 - INFO - __main__ - save last model!
06/17/2022 11:08:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 11:08:25 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 11:08:25 - INFO - __main__ - Printing 3 examples
06/17/2022 11:08:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:08:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:08:25 - INFO - __main__ - Printing 3 examples
06/17/2022 11:08:25 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:08:25 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:08:25 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:08:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:08:25 - INFO - __main__ - Printing 3 examples
06/17/2022 11:08:25 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:08:25 - INFO - __main__ - ['others']
06/17/2022 11:08:25 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:08:25 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:08:26 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:08:27 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:08:33 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 11:08:41 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:08:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:08:42 - INFO - __main__ - Starting training!
06/17/2022 11:10:09 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/17/2022 11:10:09 - INFO - __main__ - Classification-F1 on test data: 0.4691
06/17/2022 11:10:09 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.8162399860675723, test_performance=0.4690540041134149
06/17/2022 11:10:09 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/17/2022 11:10:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:10:10 - INFO - __main__ - Printing 3 examples
06/17/2022 11:10:10 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:10:10 - INFO - __main__ - ['others']
06/17/2022 11:10:10 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:10:10 - INFO - __main__ - ['others']
06/17/2022 11:10:10 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:10:10 - INFO - __main__ - ['others']
06/17/2022 11:10:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:10:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:10:10 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:10:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:10:10 - INFO - __main__ - Printing 3 examples
06/17/2022 11:10:10 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:10:10 - INFO - __main__ - ['others']
06/17/2022 11:10:10 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:10:10 - INFO - __main__ - ['others']
06/17/2022 11:10:10 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:10:10 - INFO - __main__ - ['others']
06/17/2022 11:10:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:10:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:10:11 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:10:29 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:10:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:10:30 - INFO - __main__ - Starting training!
06/17/2022 11:10:33 - INFO - __main__ - Step 10 Global step 10 Train loss 4.14 on epoch=2
06/17/2022 11:10:36 - INFO - __main__ - Step 20 Global step 20 Train loss 2.98 on epoch=4
06/17/2022 11:10:39 - INFO - __main__ - Step 30 Global step 30 Train loss 2.28 on epoch=7
06/17/2022 11:10:41 - INFO - __main__ - Step 40 Global step 40 Train loss 1.54 on epoch=9
06/17/2022 11:10:44 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=12
06/17/2022 11:10:45 - INFO - __main__ - Global step 50 Train loss 2.41 Classification-F1 0.27272727272727276 on epoch=12
06/17/2022 11:10:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.27272727272727276 on epoch=12, global_step=50
06/17/2022 11:10:48 - INFO - __main__ - Step 60 Global step 60 Train loss 0.80 on epoch=14
06/17/2022 11:10:50 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=17
06/17/2022 11:10:53 - INFO - __main__ - Step 80 Global step 80 Train loss 0.63 on epoch=19
06/17/2022 11:10:55 - INFO - __main__ - Step 90 Global step 90 Train loss 0.60 on epoch=22
06/17/2022 11:10:58 - INFO - __main__ - Step 100 Global step 100 Train loss 0.63 on epoch=24
06/17/2022 11:10:59 - INFO - __main__ - Global step 100 Train loss 0.68 Classification-F1 0.42281052281052284 on epoch=24
06/17/2022 11:10:59 - INFO - __main__ - Saving model with best Classification-F1: 0.27272727272727276 -> 0.42281052281052284 on epoch=24, global_step=100
06/17/2022 11:11:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.54 on epoch=27
06/17/2022 11:11:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.46 on epoch=29
06/17/2022 11:11:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=32
06/17/2022 11:11:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=34
06/17/2022 11:11:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=37
06/17/2022 11:11:13 - INFO - __main__ - Global step 150 Train loss 0.48 Classification-F1 0.6806372549019608 on epoch=37
06/17/2022 11:11:13 - INFO - __main__ - Saving model with best Classification-F1: 0.42281052281052284 -> 0.6806372549019608 on epoch=37, global_step=150
06/17/2022 11:11:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=39
06/17/2022 11:11:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=42
06/17/2022 11:11:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=44
06/17/2022 11:11:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=47
06/17/2022 11:11:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.37 on epoch=49
06/17/2022 11:11:27 - INFO - __main__ - Global step 200 Train loss 0.39 Classification-F1 0.7469159323648489 on epoch=49
06/17/2022 11:11:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6806372549019608 -> 0.7469159323648489 on epoch=49, global_step=200
06/17/2022 11:11:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.27 on epoch=52
06/17/2022 11:11:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=54
06/17/2022 11:11:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=57
06/17/2022 11:11:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=59
06/17/2022 11:11:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=62
06/17/2022 11:11:41 - INFO - __main__ - Global step 250 Train loss 0.27 Classification-F1 0.7276470588235294 on epoch=62
06/17/2022 11:11:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.25 on epoch=64
06/17/2022 11:11:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.20 on epoch=67
06/17/2022 11:11:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/17/2022 11:11:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/17/2022 11:11:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=74
06/17/2022 11:11:55 - INFO - __main__ - Global step 300 Train loss 0.21 Classification-F1 0.7276796612280484 on epoch=74
06/17/2022 11:11:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/17/2022 11:12:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/17/2022 11:12:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=82
06/17/2022 11:12:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=84
06/17/2022 11:12:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.11 on epoch=87
06/17/2022 11:12:09 - INFO - __main__ - Global step 350 Train loss 0.17 Classification-F1 0.8269432773109244 on epoch=87
06/17/2022 11:12:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7469159323648489 -> 0.8269432773109244 on epoch=87, global_step=350
06/17/2022 11:12:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.12 on epoch=89
06/17/2022 11:12:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=92
06/17/2022 11:12:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.10 on epoch=94
06/17/2022 11:12:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=97
06/17/2022 11:12:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=99
06/17/2022 11:12:23 - INFO - __main__ - Global step 400 Train loss 0.14 Classification-F1 0.7921212121212121 on epoch=99
06/17/2022 11:12:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=102
06/17/2022 11:12:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=104
06/17/2022 11:12:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.10 on epoch=107
06/17/2022 11:12:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=109
06/17/2022 11:12:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.06 on epoch=112
06/17/2022 11:12:36 - INFO - __main__ - Global step 450 Train loss 0.09 Classification-F1 0.8424030902683655 on epoch=112
06/17/2022 11:12:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8269432773109244 -> 0.8424030902683655 on epoch=112, global_step=450
06/17/2022 11:12:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=114
06/17/2022 11:12:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=117
06/17/2022 11:12:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.04 on epoch=119
06/17/2022 11:12:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=122
06/17/2022 11:12:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=124
06/17/2022 11:12:50 - INFO - __main__ - Global step 500 Train loss 0.06 Classification-F1 0.7616294793779581 on epoch=124
06/17/2022 11:12:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/17/2022 11:12:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=129
06/17/2022 11:12:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/17/2022 11:13:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=134
06/17/2022 11:13:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=137
06/17/2022 11:13:04 - INFO - __main__ - Global step 550 Train loss 0.05 Classification-F1 0.7726670520788168 on epoch=137
06/17/2022 11:13:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=139
06/17/2022 11:13:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=142
06/17/2022 11:13:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=144
06/17/2022 11:13:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=147
06/17/2022 11:13:17 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=149
06/17/2022 11:13:18 - INFO - __main__ - Global step 600 Train loss 0.04 Classification-F1 0.7275725232621784 on epoch=149
06/17/2022 11:13:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=152
06/17/2022 11:13:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/17/2022 11:13:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=157
06/17/2022 11:13:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/17/2022 11:13:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=162
06/17/2022 11:13:32 - INFO - __main__ - Global step 650 Train loss 0.04 Classification-F1 0.7469265018607123 on epoch=162
06/17/2022 11:13:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
06/17/2022 11:13:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=167
06/17/2022 11:13:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/17/2022 11:13:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/17/2022 11:13:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/17/2022 11:13:46 - INFO - __main__ - Global step 700 Train loss 0.02 Classification-F1 0.792153720462544 on epoch=174
06/17/2022 11:13:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/17/2022 11:13:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=179
06/17/2022 11:13:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/17/2022 11:13:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/17/2022 11:13:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/17/2022 11:14:00 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.7738215421303657 on epoch=187
06/17/2022 11:14:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/17/2022 11:14:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/17/2022 11:14:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/17/2022 11:14:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/17/2022 11:14:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/17/2022 11:14:14 - INFO - __main__ - Global step 800 Train loss 0.02 Classification-F1 0.7766122766122767 on epoch=199
06/17/2022 11:14:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/17/2022 11:14:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=204
06/17/2022 11:14:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/17/2022 11:14:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=209
06/17/2022 11:14:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/17/2022 11:14:28 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.7763746057863705 on epoch=212
06/17/2022 11:14:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/17/2022 11:14:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=217
06/17/2022 11:14:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/17/2022 11:14:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/17/2022 11:14:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/17/2022 11:14:42 - INFO - __main__ - Global step 900 Train loss 0.01 Classification-F1 0.7591156597774245 on epoch=224
06/17/2022 11:14:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/17/2022 11:14:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/17/2022 11:14:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/17/2022 11:14:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/17/2022 11:14:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/17/2022 11:14:56 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.7217489287735468 on epoch=237
06/17/2022 11:14:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/17/2022 11:15:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 11:15:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/17/2022 11:15:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/17/2022 11:15:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/17/2022 11:15:10 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.7739615583075335 on epoch=249
06/17/2022 11:15:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/17/2022 11:15:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/17/2022 11:15:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/17/2022 11:15:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/17/2022 11:15:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/17/2022 11:15:24 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.8098175381263616 on epoch=262
06/17/2022 11:15:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/17/2022 11:15:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/17/2022 11:15:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/17/2022 11:15:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/17/2022 11:15:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/17/2022 11:15:38 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7421449792038027 on epoch=274
06/17/2022 11:15:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
06/17/2022 11:15:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 11:15:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/17/2022 11:15:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/17/2022 11:15:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/17/2022 11:15:52 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.791826923076923 on epoch=287
06/17/2022 11:15:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/17/2022 11:15:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/17/2022 11:16:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 11:16:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 11:16:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/17/2022 11:16:06 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7577421271538919 on epoch=299
06/17/2022 11:16:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/17/2022 11:16:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/17/2022 11:16:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/17/2022 11:16:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/17/2022 11:16:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/17/2022 11:16:20 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7913445378151261 on epoch=312
06/17/2022 11:16:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/17/2022 11:16:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/17/2022 11:16:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/17/2022 11:16:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 11:16:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/17/2022 11:16:34 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7785675381263616 on epoch=324
06/17/2022 11:16:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/17/2022 11:16:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/17/2022 11:16:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/17/2022 11:16:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/17/2022 11:16:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/17/2022 11:16:48 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8090711031887503 on epoch=337
06/17/2022 11:16:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 11:16:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 11:16:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 11:16:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/17/2022 11:17:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/17/2022 11:17:02 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7785675381263616 on epoch=349
06/17/2022 11:17:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 11:17:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 11:17:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 11:17:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/17/2022 11:17:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/17/2022 11:17:16 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.8098175381263616 on epoch=362
06/17/2022 11:17:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 11:17:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 11:17:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 11:17:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/17/2022 11:17:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 11:17:30 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7748626373626374 on epoch=374
06/17/2022 11:17:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/17/2022 11:17:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 11:17:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 11:17:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 11:17:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/17/2022 11:17:44 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7934611344537816 on epoch=387
06/17/2022 11:17:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 11:17:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 11:17:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/17/2022 11:17:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 11:17:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 11:17:58 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.8088984204793027 on epoch=399
06/17/2022 11:18:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 11:18:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 11:18:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 11:18:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 11:18:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 11:18:12 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.7766122766122767 on epoch=412
06/17/2022 11:18:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 11:18:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 11:18:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 11:18:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/17/2022 11:18:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 11:18:26 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7431285831285831 on epoch=424
06/17/2022 11:18:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 11:18:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 11:18:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 11:18:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 11:18:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 11:18:40 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7381320949432405 on epoch=437
06/17/2022 11:18:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 11:18:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 11:18:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 11:18:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 11:18:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 11:18:54 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7572774244833068 on epoch=449
06/17/2022 11:18:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 11:18:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 11:19:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/17/2022 11:19:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 11:19:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 11:19:08 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7772486772486772 on epoch=462
06/17/2022 11:19:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 11:19:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 11:19:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 11:19:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 11:19:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 11:19:22 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7756096028154852 on epoch=474
06/17/2022 11:19:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 11:19:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 11:19:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 11:19:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/17/2022 11:19:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 11:19:36 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7607774578362814 on epoch=487
06/17/2022 11:19:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 11:19:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/17/2022 11:19:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 11:19:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 11:19:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 11:19:50 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7756096028154852 on epoch=499
06/17/2022 11:19:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 11:19:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 11:19:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 11:20:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 11:20:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 11:20:04 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7756096028154852 on epoch=512
06/17/2022 11:20:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 11:20:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 11:20:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 11:20:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 11:20:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/17/2022 11:20:18 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7579744816586922 on epoch=524
06/17/2022 11:20:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/17/2022 11:20:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/17/2022 11:20:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/17/2022 11:20:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 11:20:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 11:20:32 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7618873243873243 on epoch=537
06/17/2022 11:20:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 11:20:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/17/2022 11:20:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/17/2022 11:20:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 11:20:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/17/2022 11:20:45 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7455678200459984 on epoch=549
06/17/2022 11:20:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/17/2022 11:20:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 11:20:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/17/2022 11:20:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 11:20:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 11:20:59 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7772486772486772 on epoch=562
06/17/2022 11:21:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 11:21:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 11:21:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 11:21:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 11:21:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 11:21:13 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7930192865676736 on epoch=574
06/17/2022 11:21:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 11:21:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 11:21:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 11:21:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 11:21:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 11:21:27 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7780021686093793 on epoch=587
06/17/2022 11:21:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 11:21:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 11:21:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 11:21:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 11:21:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 11:21:41 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7766122766122767 on epoch=599
06/17/2022 11:21:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 11:21:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 11:21:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 11:21:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 11:21:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 11:21:55 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7753554689038561 on epoch=612
06/17/2022 11:21:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 11:22:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 11:22:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 11:22:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 11:22:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 11:22:09 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.776402734657004 on epoch=624
06/17/2022 11:22:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 11:22:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/17/2022 11:22:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 11:22:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 11:22:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 11:22:23 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7263011999854105 on epoch=637
06/17/2022 11:22:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 11:22:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 11:22:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 11:22:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=647
06/17/2022 11:22:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 11:22:37 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7711550836550837 on epoch=649
06/17/2022 11:22:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/17/2022 11:22:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 11:22:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 11:22:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 11:22:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 11:22:51 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7421449792038027 on epoch=662
06/17/2022 11:22:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 11:22:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 11:22:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 11:23:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 11:23:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 11:23:05 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7562301587301588 on epoch=674
06/17/2022 11:23:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 11:23:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 11:23:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 11:23:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 11:23:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 11:23:20 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7711550836550837 on epoch=687
06/17/2022 11:23:22 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/17/2022 11:23:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 11:23:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 11:23:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 11:23:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 11:23:34 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7763746057863705 on epoch=699
06/17/2022 11:23:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/17/2022 11:23:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/17/2022 11:23:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 11:23:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 11:23:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=712
06/17/2022 11:23:48 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7381132756132757 on epoch=712
06/17/2022 11:23:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/17/2022 11:23:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 11:23:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 11:23:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 11:24:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 11:24:02 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7785675381263616 on epoch=724
06/17/2022 11:24:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 11:24:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 11:24:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 11:24:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 11:24:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 11:24:16 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7607774578362814 on epoch=737
06/17/2022 11:24:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 11:24:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 11:24:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 11:24:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 11:24:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 11:24:30 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7607774578362814 on epoch=749
06/17/2022 11:24:30 - INFO - __main__ - save last model!
06/17/2022 11:24:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 11:24:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 11:24:30 - INFO - __main__ - Printing 3 examples
06/17/2022 11:24:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:24:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:24:30 - INFO - __main__ - Printing 3 examples
06/17/2022 11:24:30 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:24:30 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:24:30 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:24:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:24:30 - INFO - __main__ - Printing 3 examples
06/17/2022 11:24:30 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:24:30 - INFO - __main__ - ['others']
06/17/2022 11:24:30 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:24:30 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:24:30 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:24:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:24:37 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 11:24:45 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:24:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:24:46 - INFO - __main__ - Starting training!
06/17/2022 11:26:25 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/17/2022 11:26:25 - INFO - __main__ - Classification-F1 on test data: 0.3343
06/17/2022 11:26:26 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.8424030902683655, test_performance=0.33425486784967406
06/17/2022 11:26:26 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/17/2022 11:26:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:26:27 - INFO - __main__ - Printing 3 examples
06/17/2022 11:26:27 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:26:27 - INFO - __main__ - ['others']
06/17/2022 11:26:27 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:26:27 - INFO - __main__ - ['others']
06/17/2022 11:26:27 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:26:27 - INFO - __main__ - ['others']
06/17/2022 11:26:27 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:26:27 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:26:27 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:26:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:26:27 - INFO - __main__ - Printing 3 examples
06/17/2022 11:26:27 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:26:27 - INFO - __main__ - ['others']
06/17/2022 11:26:27 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:26:27 - INFO - __main__ - ['others']
06/17/2022 11:26:27 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:26:27 - INFO - __main__ - ['others']
06/17/2022 11:26:27 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:26:27 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:26:27 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:26:46 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:26:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:26:46 - INFO - __main__ - Starting training!
06/17/2022 11:26:50 - INFO - __main__ - Step 10 Global step 10 Train loss 4.27 on epoch=2
06/17/2022 11:26:53 - INFO - __main__ - Step 20 Global step 20 Train loss 3.15 on epoch=4
06/17/2022 11:26:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.41 on epoch=7
06/17/2022 11:26:58 - INFO - __main__ - Step 40 Global step 40 Train loss 1.86 on epoch=9
06/17/2022 11:27:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.31 on epoch=12
06/17/2022 11:27:02 - INFO - __main__ - Global step 50 Train loss 2.60 Classification-F1 0.23904454022988506 on epoch=12
06/17/2022 11:27:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.23904454022988506 on epoch=12, global_step=50
06/17/2022 11:27:04 - INFO - __main__ - Step 60 Global step 60 Train loss 0.88 on epoch=14
06/17/2022 11:27:07 - INFO - __main__ - Step 70 Global step 70 Train loss 0.77 on epoch=17
06/17/2022 11:27:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=19
06/17/2022 11:27:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.67 on epoch=22
06/17/2022 11:27:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.55 on epoch=24
06/17/2022 11:27:15 - INFO - __main__ - Global step 100 Train loss 0.73 Classification-F1 0.42906204906204903 on epoch=24
06/17/2022 11:27:15 - INFO - __main__ - Saving model with best Classification-F1: 0.23904454022988506 -> 0.42906204906204903 on epoch=24, global_step=100
06/17/2022 11:27:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=27
06/17/2022 11:27:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=29
06/17/2022 11:27:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.46 on epoch=32
06/17/2022 11:27:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.49 on epoch=34
06/17/2022 11:27:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=37
06/17/2022 11:27:29 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.6881756756756756 on epoch=37
06/17/2022 11:27:29 - INFO - __main__ - Saving model with best Classification-F1: 0.42906204906204903 -> 0.6881756756756756 on epoch=37, global_step=150
06/17/2022 11:27:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.49 on epoch=39
06/17/2022 11:27:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=42
06/17/2022 11:27:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.40 on epoch=44
06/17/2022 11:27:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.41 on epoch=47
06/17/2022 11:27:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=49
06/17/2022 11:27:43 - INFO - __main__ - Global step 200 Train loss 0.44 Classification-F1 0.6022838628101785 on epoch=49
06/17/2022 11:27:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=52
06/17/2022 11:27:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=54
06/17/2022 11:27:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=57
06/17/2022 11:27:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=59
06/17/2022 11:27:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=62
06/17/2022 11:27:57 - INFO - __main__ - Global step 250 Train loss 0.34 Classification-F1 0.7335151802656545 on epoch=62
06/17/2022 11:27:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6881756756756756 -> 0.7335151802656545 on epoch=62, global_step=250
06/17/2022 11:28:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=64
06/17/2022 11:28:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=67
06/17/2022 11:28:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/17/2022 11:28:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/17/2022 11:28:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/17/2022 11:28:11 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.7435574229691876 on epoch=74
06/17/2022 11:28:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7335151802656545 -> 0.7435574229691876 on epoch=74, global_step=300
06/17/2022 11:28:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=77
06/17/2022 11:28:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/17/2022 11:28:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/17/2022 11:28:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/17/2022 11:28:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.18 on epoch=87
06/17/2022 11:28:25 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.8278409090909091 on epoch=87
06/17/2022 11:28:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7435574229691876 -> 0.8278409090909091 on epoch=87, global_step=350
06/17/2022 11:28:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=89
06/17/2022 11:28:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=92
06/17/2022 11:28:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/17/2022 11:28:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/17/2022 11:28:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/17/2022 11:28:39 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.7669530483818242 on epoch=99
06/17/2022 11:28:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=102
06/17/2022 11:28:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=104
06/17/2022 11:28:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.10 on epoch=107
06/17/2022 11:28:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=109
06/17/2022 11:28:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.09 on epoch=112
06/17/2022 11:28:53 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.7943724084615925 on epoch=112
06/17/2022 11:28:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=114
06/17/2022 11:28:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
06/17/2022 11:29:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/17/2022 11:29:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=122
06/17/2022 11:29:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
06/17/2022 11:29:07 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.773712507074137 on epoch=124
06/17/2022 11:29:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=127
06/17/2022 11:29:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=129
06/17/2022 11:29:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=132
06/17/2022 11:29:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=134
06/17/2022 11:29:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=137
06/17/2022 11:29:21 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.8247111344537815 on epoch=137
06/17/2022 11:29:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/17/2022 11:29:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/17/2022 11:29:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=144
06/17/2022 11:29:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/17/2022 11:29:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=149
06/17/2022 11:29:34 - INFO - __main__ - Global step 600 Train loss 0.05 Classification-F1 0.7588666085440279 on epoch=149
06/17/2022 11:29:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/17/2022 11:29:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=154
06/17/2022 11:29:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/17/2022 11:29:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
06/17/2022 11:29:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/17/2022 11:29:48 - INFO - __main__ - Global step 650 Train loss 0.05 Classification-F1 0.7619162087912088 on epoch=162
06/17/2022 11:29:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/17/2022 11:29:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/17/2022 11:29:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/17/2022 11:29:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=172
06/17/2022 11:30:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/17/2022 11:30:02 - INFO - __main__ - Global step 700 Train loss 0.04 Classification-F1 0.7864159379968204 on epoch=174
06/17/2022 11:30:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/17/2022 11:30:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/17/2022 11:30:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/17/2022 11:30:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/17/2022 11:30:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/17/2022 11:30:16 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.7928532524120759 on epoch=187
06/17/2022 11:30:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/17/2022 11:30:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
06/17/2022 11:30:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/17/2022 11:30:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/17/2022 11:30:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/17/2022 11:30:30 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.7941925381263616 on epoch=199
06/17/2022 11:30:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/17/2022 11:30:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/17/2022 11:30:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/17/2022 11:30:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/17/2022 11:30:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/17/2022 11:30:44 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.8242226183402654 on epoch=212
06/17/2022 11:30:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/17/2022 11:30:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/17/2022 11:30:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/17/2022 11:30:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
06/17/2022 11:30:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/17/2022 11:30:58 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7748626373626374 on epoch=224
06/17/2022 11:31:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/17/2022 11:31:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=229
06/17/2022 11:31:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=232
06/17/2022 11:31:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/17/2022 11:31:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/17/2022 11:31:12 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7906348553407377 on epoch=237
06/17/2022 11:31:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/17/2022 11:31:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 11:31:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/17/2022 11:31:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/17/2022 11:31:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 11:31:26 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7720023767082591 on epoch=249
06/17/2022 11:31:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/17/2022 11:31:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 11:31:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/17/2022 11:31:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/17/2022 11:31:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/17/2022 11:31:39 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.7906348553407377 on epoch=262
06/17/2022 11:31:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/17/2022 11:31:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/17/2022 11:31:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/17/2022 11:31:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/17/2022 11:31:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/17/2022 11:31:53 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8054298642533937 on epoch=274
06/17/2022 11:31:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/17/2022 11:31:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 11:32:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/17/2022 11:32:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 11:32:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/17/2022 11:32:07 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7681776027364263 on epoch=287
06/17/2022 11:32:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/17/2022 11:32:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=292
06/17/2022 11:32:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/17/2022 11:32:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 11:32:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/17/2022 11:32:21 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.8054298642533937 on epoch=299
06/17/2022 11:32:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/17/2022 11:32:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/17/2022 11:32:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/17/2022 11:32:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/17/2022 11:32:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 11:32:35 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7864705882352941 on epoch=312
06/17/2022 11:32:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/17/2022 11:32:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/17/2022 11:32:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/17/2022 11:32:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 11:32:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/17/2022 11:32:49 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.8054298642533937 on epoch=324
06/17/2022 11:32:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/17/2022 11:32:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 11:32:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/17/2022 11:32:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/17/2022 11:33:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/17/2022 11:33:03 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7902146872735109 on epoch=337
06/17/2022 11:33:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/17/2022 11:33:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/17/2022 11:33:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 11:33:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/17/2022 11:33:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/17/2022 11:33:17 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7873350556438792 on epoch=349
06/17/2022 11:33:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/17/2022 11:33:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/17/2022 11:33:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/17/2022 11:33:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 11:33:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 11:33:31 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7929492585564692 on epoch=362
06/17/2022 11:33:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 11:33:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 11:33:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 11:33:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/17/2022 11:33:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/17/2022 11:33:45 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8054298642533937 on epoch=374
06/17/2022 11:33:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/17/2022 11:33:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/17/2022 11:33:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 11:33:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 11:33:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/17/2022 11:33:59 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7905597722960153 on epoch=387
06/17/2022 11:34:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 11:34:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/17/2022 11:34:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 11:34:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 11:34:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 11:34:13 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7902146872735109 on epoch=399
06/17/2022 11:34:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/17/2022 11:34:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 11:34:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/17/2022 11:34:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 11:34:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 11:34:27 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7581965421303657 on epoch=412
06/17/2022 11:34:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 11:34:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 11:34:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/17/2022 11:34:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 11:34:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 11:34:41 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7910804881393116 on epoch=424
06/17/2022 11:34:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 11:34:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 11:34:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/17/2022 11:34:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 11:34:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/17/2022 11:34:56 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7910804881393116 on epoch=437
06/17/2022 11:34:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 11:35:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/17/2022 11:35:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/17/2022 11:35:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 11:35:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 11:35:10 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7864705882352941 on epoch=449
06/17/2022 11:35:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 11:35:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 11:35:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/17/2022 11:35:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 11:35:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 11:35:24 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7713445378151261 on epoch=462
06/17/2022 11:35:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 11:35:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/17/2022 11:35:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 11:35:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 11:35:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/17/2022 11:35:38 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7904876373626374 on epoch=474
06/17/2022 11:35:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 11:35:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 11:35:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 11:35:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 11:35:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 11:35:52 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.8257395181755582 on epoch=487
06/17/2022 11:35:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 11:35:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 11:35:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 11:36:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 11:36:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/17/2022 11:36:06 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7717647058823529 on epoch=499
06/17/2022 11:36:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/17/2022 11:36:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 11:36:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 11:36:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 11:36:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 11:36:20 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7359848484848485 on epoch=512
06/17/2022 11:36:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 11:36:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/17/2022 11:36:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 11:36:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 11:36:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 11:36:34 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7747926093514329 on epoch=524
06/17/2022 11:36:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/17/2022 11:36:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 11:36:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/17/2022 11:36:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/17/2022 11:36:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 11:36:48 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7902146872735109 on epoch=537
06/17/2022 11:36:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 11:36:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 11:36:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/17/2022 11:36:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 11:37:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/17/2022 11:37:02 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7873350556438792 on epoch=549
06/17/2022 11:37:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/17/2022 11:37:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 11:37:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 11:37:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 11:37:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 11:37:16 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7712554112554113 on epoch=562
06/17/2022 11:37:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 11:37:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 11:37:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 11:37:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 11:37:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 11:37:30 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.8056526806526807 on epoch=574
06/17/2022 11:37:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 11:37:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 11:37:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/17/2022 11:37:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 11:37:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 11:37:44 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7712554112554113 on epoch=587
06/17/2022 11:37:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 11:37:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 11:37:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 11:37:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 11:37:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/17/2022 11:37:58 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7864705882352941 on epoch=599
06/17/2022 11:38:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 11:38:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 11:38:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 11:38:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/17/2022 11:38:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 11:38:12 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7717936117936118 on epoch=612
06/17/2022 11:38:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 11:38:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 11:38:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 11:38:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 11:38:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=624
06/17/2022 11:38:26 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7902146872735109 on epoch=624
06/17/2022 11:38:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 11:38:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/17/2022 11:38:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 11:38:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 11:38:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 11:38:40 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7873350556438792 on epoch=637
06/17/2022 11:38:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 11:38:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 11:38:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 11:38:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/17/2022 11:38:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 11:38:54 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7664215686274509 on epoch=649
06/17/2022 11:38:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 11:39:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
06/17/2022 11:39:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 11:39:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 11:39:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 11:39:08 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7681776027364263 on epoch=662
06/17/2022 11:39:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 11:39:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 11:39:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 11:39:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 11:39:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 11:39:22 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7681776027364263 on epoch=674
06/17/2022 11:39:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 11:39:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 11:39:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 11:39:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 11:39:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 11:39:36 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7260004254910877 on epoch=687
06/17/2022 11:39:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 11:39:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 11:39:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=694
06/17/2022 11:39:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 11:39:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 11:39:51 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7672860360360361 on epoch=699
06/17/2022 11:39:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 11:39:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 11:39:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 11:40:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 11:40:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 11:40:04 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7463319297558428 on epoch=712
06/17/2022 11:40:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 11:40:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/17/2022 11:40:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 11:40:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 11:40:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/17/2022 11:40:19 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7910804881393116 on epoch=724
06/17/2022 11:40:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 11:40:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 11:40:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 11:40:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 11:40:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/17/2022 11:40:33 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.8054298642533937 on epoch=737
06/17/2022 11:40:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/17/2022 11:40:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 11:40:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 11:40:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 11:40:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 11:40:47 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8054298642533937 on epoch=749
06/17/2022 11:40:47 - INFO - __main__ - save last model!
06/17/2022 11:40:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 11:40:47 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 11:40:47 - INFO - __main__ - Printing 3 examples
06/17/2022 11:40:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:40:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:40:47 - INFO - __main__ - Printing 3 examples
06/17/2022 11:40:47 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:40:47 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:40:47 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:40:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:40:47 - INFO - __main__ - Printing 3 examples
06/17/2022 11:40:47 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:40:47 - INFO - __main__ - ['others']
06/17/2022 11:40:47 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:40:47 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:40:47 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:40:49 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:40:54 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 11:41:03 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:41:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:41:03 - INFO - __main__ - Starting training!
06/17/2022 11:42:42 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/17/2022 11:42:42 - INFO - __main__ - Classification-F1 on test data: 0.3112
06/17/2022 11:42:43 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.8278409090909091, test_performance=0.31119106667442953
06/17/2022 11:42:43 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/17/2022 11:42:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:42:44 - INFO - __main__ - Printing 3 examples
06/17/2022 11:42:44 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:42:44 - INFO - __main__ - ['others']
06/17/2022 11:42:44 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:42:44 - INFO - __main__ - ['others']
06/17/2022 11:42:44 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:42:44 - INFO - __main__ - ['others']
06/17/2022 11:42:44 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:42:44 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:42:44 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:42:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:42:44 - INFO - __main__ - Printing 3 examples
06/17/2022 11:42:44 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:42:44 - INFO - __main__ - ['others']
06/17/2022 11:42:44 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:42:44 - INFO - __main__ - ['others']
06/17/2022 11:42:44 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:42:44 - INFO - __main__ - ['others']
06/17/2022 11:42:44 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:42:44 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:42:44 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:43:02 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:43:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:43:03 - INFO - __main__ - Starting training!
06/17/2022 11:43:07 - INFO - __main__ - Step 10 Global step 10 Train loss 4.42 on epoch=2
06/17/2022 11:43:09 - INFO - __main__ - Step 20 Global step 20 Train loss 3.27 on epoch=4
06/17/2022 11:43:12 - INFO - __main__ - Step 30 Global step 30 Train loss 2.75 on epoch=7
06/17/2022 11:43:15 - INFO - __main__ - Step 40 Global step 40 Train loss 2.23 on epoch=9
06/17/2022 11:43:17 - INFO - __main__ - Step 50 Global step 50 Train loss 1.71 on epoch=12
06/17/2022 11:43:18 - INFO - __main__ - Global step 50 Train loss 2.88 Classification-F1 0.11786168319349098 on epoch=12
06/17/2022 11:43:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11786168319349098 on epoch=12, global_step=50
06/17/2022 11:43:21 - INFO - __main__ - Step 60 Global step 60 Train loss 1.51 on epoch=14
06/17/2022 11:43:24 - INFO - __main__ - Step 70 Global step 70 Train loss 1.22 on epoch=17
06/17/2022 11:43:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=19
06/17/2022 11:43:29 - INFO - __main__ - Step 90 Global step 90 Train loss 0.81 on epoch=22
06/17/2022 11:43:31 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=24
06/17/2022 11:43:32 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.37981826877092295 on epoch=24
06/17/2022 11:43:32 - INFO - __main__ - Saving model with best Classification-F1: 0.11786168319349098 -> 0.37981826877092295 on epoch=24, global_step=100
06/17/2022 11:43:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=27
06/17/2022 11:43:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.66 on epoch=29
06/17/2022 11:43:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=32
06/17/2022 11:43:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=34
06/17/2022 11:43:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.60 on epoch=37
06/17/2022 11:43:46 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.6530872636135795 on epoch=37
06/17/2022 11:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.37981826877092295 -> 0.6530872636135795 on epoch=37, global_step=150
06/17/2022 11:43:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=39
06/17/2022 11:43:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
06/17/2022 11:43:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
06/17/2022 11:43:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/17/2022 11:43:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=49
06/17/2022 11:44:00 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.7307908809456797 on epoch=49
06/17/2022 11:44:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6530872636135795 -> 0.7307908809456797 on epoch=49, global_step=200
06/17/2022 11:44:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=52
06/17/2022 11:44:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=54
06/17/2022 11:44:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=57
06/17/2022 11:44:11 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=59
06/17/2022 11:44:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=62
06/17/2022 11:44:15 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.7590996168582376 on epoch=62
06/17/2022 11:44:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7307908809456797 -> 0.7590996168582376 on epoch=62, global_step=250
06/17/2022 11:44:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/17/2022 11:44:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/17/2022 11:44:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=69
06/17/2022 11:44:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/17/2022 11:44:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=74
06/17/2022 11:44:29 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.6948547840188708 on epoch=74
06/17/2022 11:44:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=77
06/17/2022 11:44:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=79
06/17/2022 11:44:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=82
06/17/2022 11:44:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
06/17/2022 11:44:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=87
06/17/2022 11:44:43 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.7655400155400155 on epoch=87
06/17/2022 11:44:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7590996168582376 -> 0.7655400155400155 on epoch=87, global_step=350
06/17/2022 11:44:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/17/2022 11:44:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/17/2022 11:44:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/17/2022 11:44:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
06/17/2022 11:44:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/17/2022 11:44:57 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.7399749373433584 on epoch=99
06/17/2022 11:45:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/17/2022 11:45:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/17/2022 11:45:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=107
06/17/2022 11:45:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/17/2022 11:45:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/17/2022 11:45:12 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.8097319347319348 on epoch=112
06/17/2022 11:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7655400155400155 -> 0.8097319347319348 on epoch=112, global_step=450
06/17/2022 11:45:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/17/2022 11:45:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=117
06/17/2022 11:45:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/17/2022 11:45:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/17/2022 11:45:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
06/17/2022 11:45:26 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.8260241596638656 on epoch=124
06/17/2022 11:45:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8097319347319348 -> 0.8260241596638656 on epoch=124, global_step=500
06/17/2022 11:45:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/17/2022 11:45:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/17/2022 11:45:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=132
06/17/2022 11:45:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=134
06/17/2022 11:45:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/17/2022 11:45:40 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7780812324929972 on epoch=137
06/17/2022 11:45:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/17/2022 11:45:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/17/2022 11:45:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=144
06/17/2022 11:45:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=147
06/17/2022 11:45:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=149
06/17/2022 11:45:54 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7435574229691876 on epoch=149
06/17/2022 11:45:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/17/2022 11:46:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=154
06/17/2022 11:46:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/17/2022 11:46:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/17/2022 11:46:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/17/2022 11:46:09 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.8108089826839827 on epoch=162
06/17/2022 11:46:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/17/2022 11:46:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/17/2022 11:46:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
06/17/2022 11:46:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=172
06/17/2022 11:46:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
06/17/2022 11:46:23 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7376443001443003 on epoch=174
06/17/2022 11:46:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/17/2022 11:46:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/17/2022 11:46:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/17/2022 11:46:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/17/2022 11:46:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
06/17/2022 11:46:37 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.796250318309142 on epoch=187
06/17/2022 11:46:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=189
06/17/2022 11:46:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=192
06/17/2022 11:46:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/17/2022 11:46:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/17/2022 11:46:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=199
06/17/2022 11:46:52 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.7720023767082591 on epoch=199
06/17/2022 11:46:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/17/2022 11:46:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/17/2022 11:46:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/17/2022 11:47:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/17/2022 11:47:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/17/2022 11:47:06 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.8086254703901763 on epoch=212
06/17/2022 11:47:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/17/2022 11:47:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/17/2022 11:47:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/17/2022 11:47:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/17/2022 11:47:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/17/2022 11:47:20 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7469373763491411 on epoch=224
06/17/2022 11:47:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/17/2022 11:47:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/17/2022 11:47:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/17/2022 11:47:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=234
06/17/2022 11:47:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/17/2022 11:47:35 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.8260241596638656 on epoch=237
06/17/2022 11:47:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/17/2022 11:47:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/17/2022 11:47:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/17/2022 11:47:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/17/2022 11:47:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/17/2022 11:47:49 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7934102934102935 on epoch=249
06/17/2022 11:47:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/17/2022 11:47:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/17/2022 11:47:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/17/2022 11:47:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/17/2022 11:48:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/17/2022 11:48:03 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7613122171945702 on epoch=262
06/17/2022 11:48:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/17/2022 11:48:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/17/2022 11:48:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/17/2022 11:48:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/17/2022 11:48:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/17/2022 11:48:17 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7755088049205697 on epoch=274
06/17/2022 11:48:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/17/2022 11:48:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/17/2022 11:48:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 11:48:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 11:48:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/17/2022 11:48:32 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7763746057863705 on epoch=287
06/17/2022 11:48:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/17/2022 11:48:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/17/2022 11:48:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/17/2022 11:48:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/17/2022 11:48:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/17/2022 11:48:46 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7763746057863705 on epoch=299
06/17/2022 11:48:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/17/2022 11:48:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/17/2022 11:48:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/17/2022 11:48:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/17/2022 11:48:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/17/2022 11:49:00 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7720023767082591 on epoch=312
06/17/2022 11:49:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/17/2022 11:49:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/17/2022 11:49:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/17/2022 11:49:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/17/2022 11:49:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/17/2022 11:49:15 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7577421271538919 on epoch=324
06/17/2022 11:49:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/17/2022 11:49:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 11:49:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/17/2022 11:49:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/17/2022 11:49:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/17/2022 11:49:29 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.73832020523197 on epoch=337
06/17/2022 11:49:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/17/2022 11:49:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 11:49:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/17/2022 11:49:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/17/2022 11:49:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/17/2022 11:49:43 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.737874572433396 on epoch=349
06/17/2022 11:49:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/17/2022 11:49:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/17/2022 11:49:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/17/2022 11:49:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/17/2022 11:49:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/17/2022 11:49:57 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7649993743743743 on epoch=362
06/17/2022 11:50:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 11:50:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/17/2022 11:50:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/17/2022 11:50:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/17/2022 11:50:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/17/2022 11:50:12 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7792137056842939 on epoch=374
06/17/2022 11:50:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 11:50:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/17/2022 11:50:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/17/2022 11:50:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/17/2022 11:50:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 11:50:26 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7792137056842939 on epoch=387
06/17/2022 11:50:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 11:50:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/17/2022 11:50:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 11:50:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 11:50:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 11:50:40 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7763746057863705 on epoch=399
06/17/2022 11:50:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 11:50:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 11:50:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 11:50:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/17/2022 11:50:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/17/2022 11:50:54 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8088984204793027 on epoch=412
06/17/2022 11:50:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/17/2022 11:51:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/17/2022 11:51:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/17/2022 11:51:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/17/2022 11:51:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/17/2022 11:51:09 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7942760942760942 on epoch=424
06/17/2022 11:51:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/17/2022 11:51:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 11:51:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 11:51:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 11:51:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/17/2022 11:51:23 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7562301587301588 on epoch=437
06/17/2022 11:51:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 11:51:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 11:51:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/17/2022 11:51:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/17/2022 11:51:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 11:51:37 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7720023767082591 on epoch=449
06/17/2022 11:51:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 11:51:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/17/2022 11:51:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=457
06/17/2022 11:51:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 11:51:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/17/2022 11:51:52 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7906348553407377 on epoch=462
06/17/2022 11:51:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 11:51:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 11:52:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 11:52:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 11:52:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 11:52:06 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7562301587301588 on epoch=474
06/17/2022 11:52:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 11:52:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 11:52:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 11:52:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 11:52:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/17/2022 11:52:21 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7763746057863705 on epoch=487
06/17/2022 11:52:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 11:52:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 11:52:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 11:52:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/17/2022 11:52:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 11:52:35 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7619162087912088 on epoch=499
06/17/2022 11:52:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/17/2022 11:52:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/17/2022 11:52:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 11:52:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 11:52:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/17/2022 11:52:50 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7785675381263616 on epoch=512
06/17/2022 11:52:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/17/2022 11:52:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 11:52:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 11:53:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 11:53:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 11:53:05 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7966959511077158 on epoch=524
06/17/2022 11:53:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 11:53:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 11:53:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 11:53:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 11:53:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 11:53:19 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7577421271538919 on epoch=537
06/17/2022 11:53:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 11:53:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 11:53:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/17/2022 11:53:30 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=547
06/17/2022 11:53:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/17/2022 11:53:34 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7577421271538919 on epoch=549
06/17/2022 11:53:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 11:53:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 11:53:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 11:53:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 11:53:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/17/2022 11:53:48 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7930192865676736 on epoch=562
06/17/2022 11:53:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 11:53:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 11:53:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 11:53:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 11:54:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/17/2022 11:54:03 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.791826923076923 on epoch=574
06/17/2022 11:54:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 11:54:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 11:54:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 11:54:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 11:54:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 11:54:17 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.791826923076923 on epoch=587
06/17/2022 11:54:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/17/2022 11:54:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 11:54:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 11:54:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 11:54:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 11:54:32 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7771987868762062 on epoch=599
06/17/2022 11:54:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 11:54:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 11:54:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 11:54:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 11:54:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 11:54:46 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7939195880372352 on epoch=612
06/17/2022 11:54:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 11:54:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 11:54:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 11:54:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 11:55:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 11:55:01 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7791245791245791 on epoch=624
06/17/2022 11:55:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/17/2022 11:55:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 11:55:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 11:55:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 11:55:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 11:55:16 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7423529411764705 on epoch=637
06/17/2022 11:55:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 11:55:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 11:55:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 11:55:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 11:55:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/17/2022 11:55:30 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7612230906348554 on epoch=649
06/17/2022 11:55:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/17/2022 11:55:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 11:55:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 11:55:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 11:55:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 11:55:45 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7612230906348554 on epoch=662
06/17/2022 11:55:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 11:55:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 11:55:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/17/2022 11:55:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 11:55:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/17/2022 11:55:59 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7914845011619206 on epoch=674
06/17/2022 11:56:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 11:56:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 11:56:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 11:56:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 11:56:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/17/2022 11:56:14 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7721212121212121 on epoch=687
06/17/2022 11:56:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 11:56:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 11:56:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 11:56:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 11:56:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 11:56:29 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7575694444444444 on epoch=699
06/17/2022 11:56:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/17/2022 11:56:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=704
06/17/2022 11:56:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 11:56:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 11:56:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 11:56:43 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7731944444444444 on epoch=712
06/17/2022 11:56:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 11:56:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 11:56:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 11:56:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 11:56:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 11:56:58 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7721212121212121 on epoch=724
06/17/2022 11:57:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 11:57:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 11:57:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 11:57:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 11:57:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 11:57:13 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7766122766122767 on epoch=737
06/17/2022 11:57:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=739
06/17/2022 11:57:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 11:57:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 11:57:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 11:57:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/17/2022 11:57:27 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7381475225225225 on epoch=749
06/17/2022 11:57:27 - INFO - __main__ - save last model!
06/17/2022 11:57:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 11:57:27 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 11:57:27 - INFO - __main__ - Printing 3 examples
06/17/2022 11:57:27 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 11:57:27 - INFO - __main__ - ['others']
06/17/2022 11:57:27 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 11:57:27 - INFO - __main__ - ['others']
06/17/2022 11:57:27 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 11:57:27 - INFO - __main__ - ['others']
06/17/2022 11:57:27 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:57:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:57:28 - INFO - __main__ - Printing 3 examples
06/17/2022 11:57:28 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:57:28 - INFO - __main__ - ['others']
06/17/2022 11:57:28 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:57:28 - INFO - __main__ - ['others']
06/17/2022 11:57:28 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:57:28 - INFO - __main__ - ['others']
06/17/2022 11:57:28 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:57:28 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:57:28 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:57:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:57:28 - INFO - __main__ - Printing 3 examples
06/17/2022 11:57:28 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:57:28 - INFO - __main__ - ['others']
06/17/2022 11:57:28 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:57:28 - INFO - __main__ - ['others']
06/17/2022 11:57:28 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:57:28 - INFO - __main__ - ['others']
06/17/2022 11:57:28 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:57:28 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:57:28 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:57:30 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:57:35 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 11:57:47 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:57:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:57:47 - INFO - __main__ - Starting training!
06/17/2022 11:59:22 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/17/2022 11:59:22 - INFO - __main__ - Classification-F1 on test data: 0.2580
06/17/2022 11:59:23 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.8260241596638656, test_performance=0.25795064673949747
06/17/2022 11:59:23 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/17/2022 11:59:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:59:24 - INFO - __main__ - Printing 3 examples
06/17/2022 11:59:24 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/17/2022 11:59:24 - INFO - __main__ - ['others']
06/17/2022 11:59:24 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/17/2022 11:59:24 - INFO - __main__ - ['others']
06/17/2022 11:59:24 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/17/2022 11:59:24 - INFO - __main__ - ['others']
06/17/2022 11:59:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:59:24 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:59:24 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 11:59:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 11:59:24 - INFO - __main__ - Printing 3 examples
06/17/2022 11:59:24 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/17/2022 11:59:24 - INFO - __main__ - ['others']
06/17/2022 11:59:24 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/17/2022 11:59:24 - INFO - __main__ - ['others']
06/17/2022 11:59:24 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/17/2022 11:59:24 - INFO - __main__ - ['others']
06/17/2022 11:59:24 - INFO - __main__ - Tokenizing Input ...
06/17/2022 11:59:24 - INFO - __main__ - Tokenizing Output ...
06/17/2022 11:59:24 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 11:59:42 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 11:59:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 11:59:43 - INFO - __main__ - Starting training!
06/17/2022 11:59:47 - INFO - __main__ - Step 10 Global step 10 Train loss 4.67 on epoch=2
06/17/2022 11:59:49 - INFO - __main__ - Step 20 Global step 20 Train loss 3.73 on epoch=4
06/17/2022 11:59:52 - INFO - __main__ - Step 30 Global step 30 Train loss 3.21 on epoch=7
06/17/2022 11:59:55 - INFO - __main__ - Step 40 Global step 40 Train loss 2.82 on epoch=9
06/17/2022 11:59:57 - INFO - __main__ - Step 50 Global step 50 Train loss 2.66 on epoch=12
06/17/2022 11:59:59 - INFO - __main__ - Global step 50 Train loss 3.42 Classification-F1 0.027689929018202258 on epoch=12
06/17/2022 11:59:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.027689929018202258 on epoch=12, global_step=50
06/17/2022 12:00:02 - INFO - __main__ - Step 60 Global step 60 Train loss 2.15 on epoch=14
06/17/2022 12:00:05 - INFO - __main__ - Step 70 Global step 70 Train loss 2.10 on epoch=17
06/17/2022 12:00:07 - INFO - __main__ - Step 80 Global step 80 Train loss 1.53 on epoch=19
06/17/2022 12:00:10 - INFO - __main__ - Step 90 Global step 90 Train loss 1.33 on epoch=22
06/17/2022 12:00:13 - INFO - __main__ - Step 100 Global step 100 Train loss 1.26 on epoch=24
06/17/2022 12:00:14 - INFO - __main__ - Global step 100 Train loss 1.68 Classification-F1 0.23940837639965545 on epoch=24
06/17/2022 12:00:14 - INFO - __main__ - Saving model with best Classification-F1: 0.027689929018202258 -> 0.23940837639965545 on epoch=24, global_step=100
06/17/2022 12:00:17 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=27
06/17/2022 12:00:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=29
06/17/2022 12:00:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=32
06/17/2022 12:00:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=34
06/17/2022 12:00:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.69 on epoch=37
06/17/2022 12:00:28 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.5020799601444763 on epoch=37
06/17/2022 12:00:29 - INFO - __main__ - Saving model with best Classification-F1: 0.23940837639965545 -> 0.5020799601444763 on epoch=37, global_step=150
06/17/2022 12:00:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=39
06/17/2022 12:00:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=42
06/17/2022 12:00:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.61 on epoch=44
06/17/2022 12:00:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=47
06/17/2022 12:00:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=49
06/17/2022 12:00:43 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.45280357757137946 on epoch=49
06/17/2022 12:00:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=52
06/17/2022 12:00:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=54
06/17/2022 12:00:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.56 on epoch=57
06/17/2022 12:00:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=59
06/17/2022 12:00:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=62
06/17/2022 12:00:57 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.7510280225450504 on epoch=62
06/17/2022 12:00:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5020799601444763 -> 0.7510280225450504 on epoch=62, global_step=250
06/17/2022 12:01:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=64
06/17/2022 12:01:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
06/17/2022 12:01:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=69
06/17/2022 12:01:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=72
06/17/2022 12:01:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=74
06/17/2022 12:01:12 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.7190756302521009 on epoch=74
06/17/2022 12:01:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=77
06/17/2022 12:01:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=79
06/17/2022 12:01:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=82
06/17/2022 12:01:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=84
06/17/2022 12:01:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
06/17/2022 12:01:26 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.765428607340372 on epoch=87
06/17/2022 12:01:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7510280225450504 -> 0.765428607340372 on epoch=87, global_step=350
06/17/2022 12:01:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=89
06/17/2022 12:01:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=92
06/17/2022 12:01:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/17/2022 12:01:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=97
06/17/2022 12:01:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=99
06/17/2022 12:01:41 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.7480555555555555 on epoch=99
06/17/2022 12:01:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=102
06/17/2022 12:01:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=104
06/17/2022 12:01:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
06/17/2022 12:01:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/17/2022 12:01:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=112
06/17/2022 12:01:55 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7618181818181817 on epoch=112
06/17/2022 12:01:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=114
06/17/2022 12:02:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=117
06/17/2022 12:02:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=119
06/17/2022 12:02:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=122
06/17/2022 12:02:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=124
06/17/2022 12:02:09 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.7760338680926916 on epoch=124
06/17/2022 12:02:09 - INFO - __main__ - Saving model with best Classification-F1: 0.765428607340372 -> 0.7760338680926916 on epoch=124, global_step=500
06/17/2022 12:02:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/17/2022 12:02:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=129
06/17/2022 12:02:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=132
06/17/2022 12:02:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=134
06/17/2022 12:02:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
06/17/2022 12:02:24 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.7591342414391415 on epoch=137
06/17/2022 12:02:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=139
06/17/2022 12:02:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/17/2022 12:02:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=144
06/17/2022 12:02:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/17/2022 12:02:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/17/2022 12:02:38 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.7640442242221996 on epoch=149
06/17/2022 12:02:41 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=152
06/17/2022 12:02:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/17/2022 12:02:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
06/17/2022 12:02:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=159
06/17/2022 12:02:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/17/2022 12:02:53 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.8112572223246666 on epoch=162
06/17/2022 12:02:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7760338680926916 -> 0.8112572223246666 on epoch=162, global_step=650
06/17/2022 12:02:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/17/2022 12:02:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/17/2022 12:03:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=169
06/17/2022 12:03:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/17/2022 12:03:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/17/2022 12:03:07 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.8241513388572212 on epoch=174
06/17/2022 12:03:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8112572223246666 -> 0.8241513388572212 on epoch=174, global_step=700
06/17/2022 12:03:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
06/17/2022 12:03:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=179
06/17/2022 12:03:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/17/2022 12:03:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/17/2022 12:03:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/17/2022 12:03:22 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.8264339826839827 on epoch=187
06/17/2022 12:03:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8241513388572212 -> 0.8264339826839827 on epoch=187, global_step=750
06/17/2022 12:03:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=189
06/17/2022 12:03:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/17/2022 12:03:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/17/2022 12:03:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/17/2022 12:03:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=199
06/17/2022 12:03:36 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8094454565042801 on epoch=199
06/17/2022 12:03:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/17/2022 12:03:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/17/2022 12:03:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/17/2022 12:03:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=209
06/17/2022 12:03:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
06/17/2022 12:03:51 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8086254703901763 on epoch=212
06/17/2022 12:03:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=214
06/17/2022 12:03:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=217
06/17/2022 12:03:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=219
06/17/2022 12:04:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/17/2022 12:04:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=224
06/17/2022 12:04:05 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8243542609351433 on epoch=224
06/17/2022 12:04:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/17/2022 12:04:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/17/2022 12:04:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/17/2022 12:04:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/17/2022 12:04:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=237
06/17/2022 12:04:20 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8114018334606571 on epoch=237
06/17/2022 12:04:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/17/2022 12:04:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/17/2022 12:04:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/17/2022 12:04:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/17/2022 12:04:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/17/2022 12:04:34 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7957157784743992 on epoch=249
06/17/2022 12:04:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/17/2022 12:04:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/17/2022 12:04:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/17/2022 12:04:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/17/2022 12:04:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/17/2022 12:04:49 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.8112572223246666 on epoch=262
06/17/2022 12:04:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/17/2022 12:04:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/17/2022 12:04:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/17/2022 12:04:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/17/2022 12:05:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=274
06/17/2022 12:05:03 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8088984204793027 on epoch=274
06/17/2022 12:05:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/17/2022 12:05:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/17/2022 12:05:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/17/2022 12:05:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/17/2022 12:05:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/17/2022 12:05:18 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7562301587301588 on epoch=287
06/17/2022 12:05:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/17/2022 12:05:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/17/2022 12:05:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 12:05:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/17/2022 12:05:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/17/2022 12:05:32 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7942760942760942 on epoch=299
06/17/2022 12:05:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/17/2022 12:05:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/17/2022 12:05:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/17/2022 12:05:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/17/2022 12:05:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/17/2022 12:05:47 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7928532524120759 on epoch=312
06/17/2022 12:05:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/17/2022 12:05:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/17/2022 12:05:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/17/2022 12:05:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/17/2022 12:06:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/17/2022 12:06:01 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7928532524120759 on epoch=324
06/17/2022 12:06:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/17/2022 12:06:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/17/2022 12:06:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/17/2022 12:06:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/17/2022 12:06:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=337
06/17/2022 12:06:16 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8098175381263616 on epoch=337
06/17/2022 12:06:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/17/2022 12:06:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/17/2022 12:06:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/17/2022 12:06:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/17/2022 12:06:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/17/2022 12:06:30 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7906348553407377 on epoch=349
06/17/2022 12:06:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/17/2022 12:06:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/17/2022 12:06:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/17/2022 12:06:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/17/2022 12:06:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/17/2022 12:06:44 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7748626373626374 on epoch=362
06/17/2022 12:06:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/17/2022 12:06:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/17/2022 12:06:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/17/2022 12:06:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/17/2022 12:06:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/17/2022 12:06:58 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7930192865676736 on epoch=374
06/17/2022 12:07:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 12:07:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/17/2022 12:07:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=382
06/17/2022 12:07:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/17/2022 12:07:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/17/2022 12:07:12 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8088984204793027 on epoch=387
06/17/2022 12:07:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/17/2022 12:07:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 12:07:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/17/2022 12:07:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/17/2022 12:07:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/17/2022 12:07:27 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7906348553407377 on epoch=399
06/17/2022 12:07:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/17/2022 12:07:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 12:07:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/17/2022 12:07:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/17/2022 12:07:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 12:07:41 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7906348553407377 on epoch=412
06/17/2022 12:07:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 12:07:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/17/2022 12:07:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 12:07:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/17/2022 12:07:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/17/2022 12:07:55 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7748626373626374 on epoch=424
06/17/2022 12:07:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/17/2022 12:08:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=429
06/17/2022 12:08:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/17/2022 12:08:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/17/2022 12:08:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/17/2022 12:08:10 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.791826923076923 on epoch=437
06/17/2022 12:08:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/17/2022 12:08:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/17/2022 12:08:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/17/2022 12:08:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 12:08:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/17/2022 12:08:24 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.8088984204793027 on epoch=449
06/17/2022 12:08:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/17/2022 12:08:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/17/2022 12:08:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/17/2022 12:08:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/17/2022 12:08:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/17/2022 12:08:38 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8088984204793027 on epoch=462
06/17/2022 12:08:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 12:08:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 12:08:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/17/2022 12:08:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 12:08:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/17/2022 12:08:53 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8098175381263616 on epoch=474
06/17/2022 12:08:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/17/2022 12:08:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/17/2022 12:09:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
06/17/2022 12:09:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=484
06/17/2022 12:09:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/17/2022 12:09:07 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7930192865676736 on epoch=487
06/17/2022 12:09:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/17/2022 12:09:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/17/2022 12:09:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 12:09:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/17/2022 12:09:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/17/2022 12:09:21 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7930192865676736 on epoch=499
06/17/2022 12:09:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/17/2022 12:09:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 12:09:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/17/2022 12:09:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/17/2022 12:09:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/17/2022 12:09:35 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8260241596638656 on epoch=512
06/17/2022 12:09:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/17/2022 12:09:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/17/2022 12:09:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/17/2022 12:09:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/17/2022 12:09:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 12:09:50 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8088984204793027 on epoch=524
06/17/2022 12:09:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/17/2022 12:09:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/17/2022 12:09:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 12:10:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/17/2022 12:10:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 12:10:04 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7906348553407377 on epoch=537
06/17/2022 12:10:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 12:10:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 12:10:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/17/2022 12:10:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=547
06/17/2022 12:10:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/17/2022 12:10:19 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7906348553407377 on epoch=549
06/17/2022 12:10:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/17/2022 12:10:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/17/2022 12:10:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/17/2022 12:10:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 12:10:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 12:10:33 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7930192865676736 on epoch=562
06/17/2022 12:10:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/17/2022 12:10:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/17/2022 12:10:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 12:10:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=572
06/17/2022 12:10:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 12:10:47 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7578354978354979 on epoch=574
06/17/2022 12:10:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 12:10:53 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/17/2022 12:10:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 12:10:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/17/2022 12:11:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/17/2022 12:11:02 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7907239819004525 on epoch=587
06/17/2022 12:11:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/17/2022 12:11:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/17/2022 12:11:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 12:11:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/17/2022 12:11:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 12:11:16 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7717647058823529 on epoch=599
06/17/2022 12:11:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/17/2022 12:11:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/17/2022 12:11:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 12:11:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/17/2022 12:11:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 12:11:31 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7561038961038961 on epoch=612
06/17/2022 12:11:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 12:11:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/17/2022 12:11:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 12:11:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/17/2022 12:11:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 12:11:45 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7717647058823529 on epoch=624
06/17/2022 12:11:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 12:11:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 12:11:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 12:11:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 12:11:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 12:12:00 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.8260241596638656 on epoch=637
06/17/2022 12:12:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 12:12:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/17/2022 12:12:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 12:12:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 12:12:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 12:12:14 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.8062320032908268 on epoch=649
06/17/2022 12:12:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/17/2022 12:12:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 12:12:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 12:12:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/17/2022 12:12:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 12:12:28 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7717647058823529 on epoch=662
06/17/2022 12:12:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/17/2022 12:12:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/17/2022 12:12:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 12:12:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/17/2022 12:12:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 12:12:43 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.792153720462544 on epoch=674
06/17/2022 12:12:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=677
06/17/2022 12:12:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/17/2022 12:12:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/17/2022 12:12:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 12:12:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 12:12:57 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8417048637636874 on epoch=687
06/17/2022 12:12:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8264339826839827 -> 0.8417048637636874 on epoch=687, global_step=2750
06/17/2022 12:13:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 12:13:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 12:13:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 12:13:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 12:13:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/17/2022 12:13:12 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8062320032908268 on epoch=699
06/17/2022 12:13:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 12:13:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 12:13:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 12:13:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/17/2022 12:13:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/17/2022 12:13:26 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8062320032908268 on epoch=712
06/17/2022 12:13:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 12:13:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 12:13:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 12:13:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/17/2022 12:13:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 12:13:41 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8260241596638656 on epoch=724
06/17/2022 12:13:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/17/2022 12:13:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/17/2022 12:13:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/17/2022 12:13:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 12:13:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/17/2022 12:13:56 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7906348553407377 on epoch=737
06/17/2022 12:13:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 12:14:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 12:14:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=744
06/17/2022 12:14:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 12:14:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/17/2022 12:14:10 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7731944444444444 on epoch=749
06/17/2022 12:14:10 - INFO - __main__ - save last model!
06/17/2022 12:14:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 12:14:10 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 12:14:10 - INFO - __main__ - Printing 3 examples
06/17/2022 12:14:10 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 12:14:10 - INFO - __main__ - ['others']
06/17/2022 12:14:10 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 12:14:10 - INFO - __main__ - ['others']
06/17/2022 12:14:10 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 12:14:10 - INFO - __main__ - ['others']
06/17/2022 12:14:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:14:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:14:11 - INFO - __main__ - Printing 3 examples
06/17/2022 12:14:11 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 12:14:11 - INFO - __main__ - ['sad']
06/17/2022 12:14:11 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 12:14:11 - INFO - __main__ - ['sad']
06/17/2022 12:14:11 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 12:14:11 - INFO - __main__ - ['sad']
06/17/2022 12:14:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:14:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:14:11 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 12:14:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:14:11 - INFO - __main__ - Printing 3 examples
06/17/2022 12:14:11 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 12:14:11 - INFO - __main__ - ['sad']
06/17/2022 12:14:11 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 12:14:11 - INFO - __main__ - ['sad']
06/17/2022 12:14:11 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 12:14:11 - INFO - __main__ - ['sad']
06/17/2022 12:14:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:14:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:14:11 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 12:14:12 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:14:18 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 12:14:27 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 12:14:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 12:14:27 - INFO - __main__ - Starting training!
06/17/2022 12:15:59 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/17/2022 12:15:59 - INFO - __main__ - Classification-F1 on test data: 0.2973
06/17/2022 12:16:00 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.8417048637636874, test_performance=0.2972906730344703
06/17/2022 12:16:00 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/17/2022 12:16:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:16:01 - INFO - __main__ - Printing 3 examples
06/17/2022 12:16:01 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 12:16:01 - INFO - __main__ - ['sad']
06/17/2022 12:16:01 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 12:16:01 - INFO - __main__ - ['sad']
06/17/2022 12:16:01 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 12:16:01 - INFO - __main__ - ['sad']
06/17/2022 12:16:01 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:16:01 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:16:01 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 12:16:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:16:01 - INFO - __main__ - Printing 3 examples
06/17/2022 12:16:01 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 12:16:01 - INFO - __main__ - ['sad']
06/17/2022 12:16:01 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 12:16:01 - INFO - __main__ - ['sad']
06/17/2022 12:16:01 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 12:16:01 - INFO - __main__ - ['sad']
06/17/2022 12:16:01 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:16:01 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:16:01 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 12:16:19 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 12:16:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 12:16:20 - INFO - __main__ - Starting training!
06/17/2022 12:16:23 - INFO - __main__ - Step 10 Global step 10 Train loss 4.55 on epoch=2
06/17/2022 12:16:26 - INFO - __main__ - Step 20 Global step 20 Train loss 2.85 on epoch=4
06/17/2022 12:16:29 - INFO - __main__ - Step 30 Global step 30 Train loss 2.08 on epoch=7
06/17/2022 12:16:31 - INFO - __main__ - Step 40 Global step 40 Train loss 1.55 on epoch=9
06/17/2022 12:16:34 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=12
06/17/2022 12:16:35 - INFO - __main__ - Global step 50 Train loss 2.43 Classification-F1 0.23114104323499626 on epoch=12
06/17/2022 12:16:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.23114104323499626 on epoch=12, global_step=50
06/17/2022 12:16:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.85 on epoch=14
06/17/2022 12:16:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.58 on epoch=17
06/17/2022 12:16:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.67 on epoch=19
06/17/2022 12:16:45 - INFO - __main__ - Step 90 Global step 90 Train loss 0.56 on epoch=22
06/17/2022 12:16:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.50 on epoch=24
06/17/2022 12:16:49 - INFO - __main__ - Global step 100 Train loss 0.63 Classification-F1 0.6320519435844514 on epoch=24
06/17/2022 12:16:49 - INFO - __main__ - Saving model with best Classification-F1: 0.23114104323499626 -> 0.6320519435844514 on epoch=24, global_step=100
06/17/2022 12:16:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.50 on epoch=27
06/17/2022 12:16:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.46 on epoch=29
06/17/2022 12:16:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.44 on epoch=32
06/17/2022 12:16:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.37 on epoch=34
06/17/2022 12:17:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.40 on epoch=37
06/17/2022 12:17:03 - INFO - __main__ - Global step 150 Train loss 0.43 Classification-F1 0.6665288770551927 on epoch=37
06/17/2022 12:17:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6320519435844514 -> 0.6665288770551927 on epoch=37, global_step=150
06/17/2022 12:17:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.32 on epoch=39
06/17/2022 12:17:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.44 on epoch=42
06/17/2022 12:17:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.27 on epoch=44
06/17/2022 12:17:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.36 on epoch=47
06/17/2022 12:17:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/17/2022 12:17:17 - INFO - __main__ - Global step 200 Train loss 0.33 Classification-F1 0.711662633595483 on epoch=49
06/17/2022 12:17:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6665288770551927 -> 0.711662633595483 on epoch=49, global_step=200
06/17/2022 12:17:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=52
06/17/2022 12:17:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=54
06/17/2022 12:17:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=57
06/17/2022 12:17:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.18 on epoch=59
06/17/2022 12:17:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=62
06/17/2022 12:17:31 - INFO - __main__ - Global step 250 Train loss 0.27 Classification-F1 0.6627492877492878 on epoch=62
06/17/2022 12:17:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=64
06/17/2022 12:17:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/17/2022 12:17:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.16 on epoch=69
06/17/2022 12:17:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/17/2022 12:17:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.17 on epoch=74
06/17/2022 12:17:46 - INFO - __main__ - Global step 300 Train loss 0.21 Classification-F1 0.6730994152046784 on epoch=74
06/17/2022 12:17:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.18 on epoch=77
06/17/2022 12:17:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=79
06/17/2022 12:17:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.12 on epoch=82
06/17/2022 12:17:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=84
06/17/2022 12:17:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=87
06/17/2022 12:18:00 - INFO - __main__ - Global step 350 Train loss 0.16 Classification-F1 0.7179429916339325 on epoch=87
06/17/2022 12:18:00 - INFO - __main__ - Saving model with best Classification-F1: 0.711662633595483 -> 0.7179429916339325 on epoch=87, global_step=350
06/17/2022 12:18:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.13 on epoch=89
06/17/2022 12:18:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=92
06/17/2022 12:18:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=94
06/17/2022 12:18:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=97
06/17/2022 12:18:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.06 on epoch=99
06/17/2022 12:18:14 - INFO - __main__ - Global step 400 Train loss 0.12 Classification-F1 0.7235964640198511 on epoch=99
06/17/2022 12:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7179429916339325 -> 0.7235964640198511 on epoch=99, global_step=400
06/17/2022 12:18:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.06 on epoch=102
06/17/2022 12:18:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=104
06/17/2022 12:18:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=107
06/17/2022 12:18:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=109
06/17/2022 12:18:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=112
06/17/2022 12:18:28 - INFO - __main__ - Global step 450 Train loss 0.07 Classification-F1 0.7436816469074534 on epoch=112
06/17/2022 12:18:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7235964640198511 -> 0.7436816469074534 on epoch=112, global_step=450
06/17/2022 12:18:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.03 on epoch=114
06/17/2022 12:18:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.04 on epoch=117
06/17/2022 12:18:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=119
06/17/2022 12:18:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=122
06/17/2022 12:18:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=124
06/17/2022 12:18:42 - INFO - __main__ - Global step 500 Train loss 0.05 Classification-F1 0.6803990364474236 on epoch=124
06/17/2022 12:18:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/17/2022 12:18:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.02 on epoch=129
06/17/2022 12:18:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=132
06/17/2022 12:18:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.01 on epoch=134
06/17/2022 12:18:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=137
06/17/2022 12:18:57 - INFO - __main__ - Global step 550 Train loss 0.03 Classification-F1 0.7660709096192967 on epoch=137
06/17/2022 12:18:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7436816469074534 -> 0.7660709096192967 on epoch=137, global_step=550
06/17/2022 12:18:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=139
06/17/2022 12:19:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.01 on epoch=142
06/17/2022 12:19:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=144
06/17/2022 12:19:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=147
06/17/2022 12:19:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=149
06/17/2022 12:19:11 - INFO - __main__ - Global step 600 Train loss 0.03 Classification-F1 0.6944212542851381 on epoch=149
06/17/2022 12:19:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=152
06/17/2022 12:19:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/17/2022 12:19:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=157
06/17/2022 12:19:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=159
06/17/2022 12:19:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=162
06/17/2022 12:19:25 - INFO - __main__ - Global step 650 Train loss 0.03 Classification-F1 0.724318087151891 on epoch=162
06/17/2022 12:19:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/17/2022 12:19:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.00 on epoch=167
06/17/2022 12:19:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/17/2022 12:19:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=172
06/17/2022 12:19:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=174
06/17/2022 12:19:39 - INFO - __main__ - Global step 700 Train loss 0.02 Classification-F1 0.6934831725408853 on epoch=174
06/17/2022 12:19:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/17/2022 12:19:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
06/17/2022 12:19:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/17/2022 12:19:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.00 on epoch=184
06/17/2022 12:19:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=187
06/17/2022 12:19:53 - INFO - __main__ - Global step 750 Train loss 0.01 Classification-F1 0.7377403846153846 on epoch=187
06/17/2022 12:19:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.00 on epoch=189
06/17/2022 12:19:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/17/2022 12:20:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/17/2022 12:20:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/17/2022 12:20:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=199
06/17/2022 12:20:08 - INFO - __main__ - Global step 800 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=199
06/17/2022 12:20:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/17/2022 12:20:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/17/2022 12:20:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/17/2022 12:20:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/17/2022 12:20:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/17/2022 12:20:22 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.7322431633407243 on epoch=212
06/17/2022 12:20:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/17/2022 12:20:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/17/2022 12:20:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=219
06/17/2022 12:20:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/17/2022 12:20:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=224
06/17/2022 12:20:36 - INFO - __main__ - Global step 900 Train loss 0.01 Classification-F1 0.74673899983806 on epoch=224
06/17/2022 12:20:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=227
06/17/2022 12:20:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/17/2022 12:20:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
06/17/2022 12:20:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/17/2022 12:20:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/17/2022 12:20:51 - INFO - __main__ - Global step 950 Train loss 0.00 Classification-F1 0.74673899983806 on epoch=237
06/17/2022 12:20:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/17/2022 12:20:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=242
06/17/2022 12:20:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/17/2022 12:21:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/17/2022 12:21:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/17/2022 12:21:05 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.724004526977088 on epoch=249
06/17/2022 12:21:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/17/2022 12:21:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 12:21:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/17/2022 12:21:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/17/2022 12:21:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/17/2022 12:21:19 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7473553653042586 on epoch=262
06/17/2022 12:21:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 12:21:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/17/2022 12:21:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/17/2022 12:21:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/17/2022 12:21:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/17/2022 12:21:33 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7476067382377677 on epoch=274
06/17/2022 12:21:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/17/2022 12:21:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/17/2022 12:21:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/17/2022 12:21:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/17/2022 12:21:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/17/2022 12:21:48 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7308362369337978 on epoch=287
06/17/2022 12:21:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/17/2022 12:21:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/17/2022 12:21:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/17/2022 12:21:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 12:22:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/17/2022 12:22:02 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7094872026114116 on epoch=299
06/17/2022 12:22:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/17/2022 12:22:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/17/2022 12:22:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/17/2022 12:22:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/17/2022 12:22:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 12:22:16 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.724004526977088 on epoch=312
06/17/2022 12:22:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/17/2022 12:22:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/17/2022 12:22:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/17/2022 12:22:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 12:22:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/17/2022 12:22:30 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7248495989304813 on epoch=324
06/17/2022 12:22:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/17/2022 12:22:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/17/2022 12:22:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/17/2022 12:22:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/17/2022 12:22:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/17/2022 12:22:45 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.724004526977088 on epoch=337
06/17/2022 12:22:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 12:22:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/17/2022 12:22:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/17/2022 12:22:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 12:22:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/17/2022 12:22:59 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.7397106958082568 on epoch=349
06/17/2022 12:23:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 12:23:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 12:23:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 12:23:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 12:23:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 12:23:13 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=362
06/17/2022 12:23:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/17/2022 12:23:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 12:23:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 12:23:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/17/2022 12:23:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/17/2022 12:23:27 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.7390239695048322 on epoch=374
06/17/2022 12:23:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 12:23:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 12:23:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 12:23:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/17/2022 12:23:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 12:23:42 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7397106958082568 on epoch=387
06/17/2022 12:23:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 12:23:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 12:23:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 12:23:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 12:23:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 12:23:56 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7628116357889921 on epoch=399
06/17/2022 12:23:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 12:24:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 12:24:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 12:24:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 12:24:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 12:24:10 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.6846615170458427 on epoch=412
06/17/2022 12:24:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 12:24:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 12:24:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 12:24:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/17/2022 12:24:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 12:24:24 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7625068804557738 on epoch=424
06/17/2022 12:24:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 12:24:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 12:24:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/17/2022 12:24:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 12:24:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 12:24:39 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.724004526977088 on epoch=437
06/17/2022 12:24:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/17/2022 12:24:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 12:24:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 12:24:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 12:24:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/17/2022 12:24:53 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7088530118255728 on epoch=449
06/17/2022 12:24:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 12:24:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 12:25:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/17/2022 12:25:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 12:25:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 12:25:07 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7390239695048322 on epoch=462
06/17/2022 12:25:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 12:25:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 12:25:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 12:25:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 12:25:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 12:25:22 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7227272727272728 on epoch=474
06/17/2022 12:25:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/17/2022 12:25:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 12:25:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 12:25:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 12:25:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 12:25:36 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7227272727272728 on epoch=487
06/17/2022 12:25:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 12:25:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 12:25:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 12:25:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/17/2022 12:25:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 12:25:50 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7390239695048322 on epoch=499
06/17/2022 12:25:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 12:25:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 12:25:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 12:26:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 12:26:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 12:26:05 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=512
06/17/2022 12:26:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 12:26:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 12:26:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 12:26:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/17/2022 12:26:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 12:26:19 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7390239695048322 on epoch=524
06/17/2022 12:26:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 12:26:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 12:26:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 12:26:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 12:26:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 12:26:33 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7476067382377677 on epoch=537
06/17/2022 12:26:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 12:26:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 12:26:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 12:26:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/17/2022 12:26:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 12:26:48 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7476067382377677 on epoch=549
06/17/2022 12:26:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 12:26:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 12:26:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
06/17/2022 12:26:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 12:27:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/17/2022 12:27:02 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7628116357889921 on epoch=562
06/17/2022 12:27:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 12:27:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/17/2022 12:27:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/17/2022 12:27:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 12:27:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 12:27:17 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7476067382377677 on epoch=574
06/17/2022 12:27:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 12:27:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 12:27:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 12:27:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 12:27:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 12:27:31 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=587
06/17/2022 12:27:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 12:27:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 12:27:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/17/2022 12:27:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 12:27:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 12:27:45 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7244058386875428 on epoch=599
06/17/2022 12:27:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 12:27:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 12:27:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 12:27:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 12:27:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 12:28:00 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7341397150648622 on epoch=612
06/17/2022 12:28:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=614
06/17/2022 12:28:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 12:28:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 12:28:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 12:28:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 12:28:14 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.724004526977088 on epoch=624
06/17/2022 12:28:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 12:28:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 12:28:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 12:28:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 12:28:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 12:28:28 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.739629526977088 on epoch=637
06/17/2022 12:28:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 12:28:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 12:28:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/17/2022 12:28:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 12:28:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 12:28:43 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7244058386875428 on epoch=649
06/17/2022 12:28:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 12:28:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 12:28:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 12:28:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 12:28:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 12:28:57 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7227272727272728 on epoch=662
06/17/2022 12:29:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 12:29:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/17/2022 12:29:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 12:29:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 12:29:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 12:29:11 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7227272727272728 on epoch=674
06/17/2022 12:29:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 12:29:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 12:29:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 12:29:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 12:29:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 12:29:26 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.760700437257652 on epoch=687
06/17/2022 12:29:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 12:29:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 12:29:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/17/2022 12:29:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 12:29:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 12:29:40 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7227272727272728 on epoch=699
06/17/2022 12:29:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 12:29:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 12:29:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/17/2022 12:29:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 12:29:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 12:29:54 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7227272727272728 on epoch=712
06/17/2022 12:29:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 12:30:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 12:30:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 12:30:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 12:30:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 12:30:09 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7456809947299077 on epoch=724
06/17/2022 12:30:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 12:30:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 12:30:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 12:30:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 12:30:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 12:30:23 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7456809947299077 on epoch=737
06/17/2022 12:30:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 12:30:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 12:30:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 12:30:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 12:30:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 12:30:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:30:37 - INFO - __main__ - Printing 3 examples
06/17/2022 12:30:37 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 12:30:37 - INFO - __main__ - ['sad']
06/17/2022 12:30:37 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 12:30:37 - INFO - __main__ - ['sad']
06/17/2022 12:30:37 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 12:30:37 - INFO - __main__ - ['sad']
06/17/2022 12:30:37 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:30:37 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7373495989304812 on epoch=749
06/17/2022 12:30:37 - INFO - __main__ - save last model!
06/17/2022 12:30:37 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:30:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 12:30:37 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 12:30:37 - INFO - __main__ - Printing 3 examples
06/17/2022 12:30:37 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 12:30:37 - INFO - __main__ - ['others']
06/17/2022 12:30:37 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 12:30:37 - INFO - __main__ - ['others']
06/17/2022 12:30:37 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 12:30:37 - INFO - __main__ - ['others']
06/17/2022 12:30:37 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:30:37 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 12:30:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:30:37 - INFO - __main__ - Printing 3 examples
06/17/2022 12:30:37 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 12:30:37 - INFO - __main__ - ['sad']
06/17/2022 12:30:37 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 12:30:37 - INFO - __main__ - ['sad']
06/17/2022 12:30:37 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 12:30:37 - INFO - __main__ - ['sad']
06/17/2022 12:30:37 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:30:37 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:30:37 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 12:30:39 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:30:45 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 12:30:53 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 12:30:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 12:30:54 - INFO - __main__ - Starting training!
06/17/2022 12:32:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/17/2022 12:32:33 - INFO - __main__ - Classification-F1 on test data: 0.3141
06/17/2022 12:32:34 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.7660709096192967, test_performance=0.31409118345111925
06/17/2022 12:32:34 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/17/2022 12:32:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:32:35 - INFO - __main__ - Printing 3 examples
06/17/2022 12:32:35 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 12:32:35 - INFO - __main__ - ['sad']
06/17/2022 12:32:35 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 12:32:35 - INFO - __main__ - ['sad']
06/17/2022 12:32:35 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 12:32:35 - INFO - __main__ - ['sad']
06/17/2022 12:32:35 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:32:35 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:32:35 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 12:32:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:32:35 - INFO - __main__ - Printing 3 examples
06/17/2022 12:32:35 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 12:32:35 - INFO - __main__ - ['sad']
06/17/2022 12:32:35 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 12:32:35 - INFO - __main__ - ['sad']
06/17/2022 12:32:35 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 12:32:35 - INFO - __main__ - ['sad']
06/17/2022 12:32:35 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:32:35 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:32:35 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 12:32:53 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 12:32:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 12:32:54 - INFO - __main__ - Starting training!
06/17/2022 12:32:58 - INFO - __main__ - Step 10 Global step 10 Train loss 4.18 on epoch=2
06/17/2022 12:33:00 - INFO - __main__ - Step 20 Global step 20 Train loss 2.96 on epoch=4
06/17/2022 12:33:03 - INFO - __main__ - Step 30 Global step 30 Train loss 2.40 on epoch=7
06/17/2022 12:33:05 - INFO - __main__ - Step 40 Global step 40 Train loss 1.78 on epoch=9
06/17/2022 12:33:08 - INFO - __main__ - Step 50 Global step 50 Train loss 1.43 on epoch=12
06/17/2022 12:33:09 - INFO - __main__ - Global step 50 Train loss 2.55 Classification-F1 0.17763845350052246 on epoch=12
06/17/2022 12:33:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.17763845350052246 on epoch=12, global_step=50
06/17/2022 12:33:12 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=14
06/17/2022 12:33:15 - INFO - __main__ - Step 70 Global step 70 Train loss 0.82 on epoch=17
06/17/2022 12:33:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.68 on epoch=19
06/17/2022 12:33:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=22
06/17/2022 12:33:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.50 on epoch=24
06/17/2022 12:33:24 - INFO - __main__ - Global step 100 Train loss 0.75 Classification-F1 0.6536133221617093 on epoch=24
06/17/2022 12:33:24 - INFO - __main__ - Saving model with best Classification-F1: 0.17763845350052246 -> 0.6536133221617093 on epoch=24, global_step=100
06/17/2022 12:33:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=27
06/17/2022 12:33:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.47 on epoch=29
06/17/2022 12:33:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.50 on epoch=32
06/17/2022 12:33:34 - INFO - __main__ - Step 140 Global step 140 Train loss 0.49 on epoch=34
06/17/2022 12:33:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.45 on epoch=37
06/17/2022 12:33:38 - INFO - __main__ - Global step 150 Train loss 0.49 Classification-F1 0.623514704635986 on epoch=37
06/17/2022 12:33:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.34 on epoch=39
06/17/2022 12:33:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=42
06/17/2022 12:33:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=44
06/17/2022 12:33:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=47
06/17/2022 12:33:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=49
06/17/2022 12:33:52 - INFO - __main__ - Global step 200 Train loss 0.38 Classification-F1 0.688463399460842 on epoch=49
06/17/2022 12:33:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6536133221617093 -> 0.688463399460842 on epoch=49, global_step=200
06/17/2022 12:33:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=52
06/17/2022 12:33:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=54
06/17/2022 12:34:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.37 on epoch=57
06/17/2022 12:34:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=59
06/17/2022 12:34:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.36 on epoch=62
06/17/2022 12:34:06 - INFO - __main__ - Global step 250 Train loss 0.34 Classification-F1 0.6753345210568211 on epoch=62
06/17/2022 12:34:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=64
06/17/2022 12:34:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=67
06/17/2022 12:34:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=69
06/17/2022 12:34:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=72
06/17/2022 12:34:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/17/2022 12:34:20 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.7180294795783926 on epoch=74
06/17/2022 12:34:20 - INFO - __main__ - Saving model with best Classification-F1: 0.688463399460842 -> 0.7180294795783926 on epoch=74, global_step=300
06/17/2022 12:34:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=77
06/17/2022 12:34:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/17/2022 12:34:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/17/2022 12:34:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/17/2022 12:34:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.18 on epoch=87
06/17/2022 12:34:34 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.7026596402937051 on epoch=87
06/17/2022 12:34:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/17/2022 12:34:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/17/2022 12:34:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.14 on epoch=94
06/17/2022 12:34:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=97
06/17/2022 12:34:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=99
06/17/2022 12:34:49 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.7112891737891738 on epoch=99
06/17/2022 12:34:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=102
06/17/2022 12:34:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=104
06/17/2022 12:34:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=107
06/17/2022 12:34:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.07 on epoch=109
06/17/2022 12:35:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=112
06/17/2022 12:35:03 - INFO - __main__ - Global step 450 Train loss 0.10 Classification-F1 0.6862179487179487 on epoch=112
06/17/2022 12:35:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=114
06/17/2022 12:35:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=117
06/17/2022 12:35:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=119
06/17/2022 12:35:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=122
06/17/2022 12:35:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=124
06/17/2022 12:35:17 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.6870098039215686 on epoch=124
06/17/2022 12:35:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=127
06/17/2022 12:35:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=129
06/17/2022 12:35:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/17/2022 12:35:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/17/2022 12:35:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/17/2022 12:35:31 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.6666666666666667 on epoch=137
06/17/2022 12:35:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/17/2022 12:35:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/17/2022 12:35:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=144
06/17/2022 12:35:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=147
06/17/2022 12:35:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=149
06/17/2022 12:35:45 - INFO - __main__ - Global step 600 Train loss 0.06 Classification-F1 0.71743287558926 on epoch=149
06/17/2022 12:35:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/17/2022 12:35:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
06/17/2022 12:35:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=157
06/17/2022 12:35:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/17/2022 12:35:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/17/2022 12:35:59 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.7004249815225425 on epoch=162
06/17/2022 12:36:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/17/2022 12:36:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/17/2022 12:36:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=169
06/17/2022 12:36:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/17/2022 12:36:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/17/2022 12:36:13 - INFO - __main__ - Global step 700 Train loss 0.04 Classification-F1 0.6657925407925408 on epoch=174
06/17/2022 12:36:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/17/2022 12:36:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/17/2022 12:36:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/17/2022 12:36:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/17/2022 12:36:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/17/2022 12:36:28 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.654626867555548 on epoch=187
06/17/2022 12:36:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/17/2022 12:36:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/17/2022 12:36:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/17/2022 12:36:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/17/2022 12:36:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/17/2022 12:36:42 - INFO - __main__ - Global step 800 Train loss 0.02 Classification-F1 0.7167953383162864 on epoch=199
06/17/2022 12:36:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/17/2022 12:36:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/17/2022 12:36:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/17/2022 12:36:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/17/2022 12:36:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/17/2022 12:36:56 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.6934205098589226 on epoch=212
06/17/2022 12:36:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/17/2022 12:37:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/17/2022 12:37:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/17/2022 12:37:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/17/2022 12:37:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/17/2022 12:37:10 - INFO - __main__ - Global step 900 Train loss 0.01 Classification-F1 0.70879034914361 on epoch=224
06/17/2022 12:37:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/17/2022 12:37:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/17/2022 12:37:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/17/2022 12:37:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/17/2022 12:37:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/17/2022 12:37:24 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7087583148558757 on epoch=237
06/17/2022 12:37:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/17/2022 12:37:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 12:37:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/17/2022 12:37:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/17/2022 12:37:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 12:37:39 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.6962583148558759 on epoch=249
06/17/2022 12:37:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/17/2022 12:37:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 12:37:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/17/2022 12:37:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/17/2022 12:37:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/17/2022 12:37:53 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7169696969696969 on epoch=262
06/17/2022 12:37:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 12:37:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/17/2022 12:38:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/17/2022 12:38:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/17/2022 12:38:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=274
06/17/2022 12:38:07 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7100676033934252 on epoch=274
06/17/2022 12:38:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/17/2022 12:38:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 12:38:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 12:38:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 12:38:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/17/2022 12:38:21 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7528024193548387 on epoch=287
06/17/2022 12:38:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7180294795783926 -> 0.7528024193548387 on epoch=287, global_step=1150
06/17/2022 12:38:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/17/2022 12:38:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/17/2022 12:38:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/17/2022 12:38:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 12:38:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/17/2022 12:38:36 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7717767783291977 on epoch=299
06/17/2022 12:38:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7528024193548387 -> 0.7717767783291977 on epoch=299, global_step=1200
06/17/2022 12:38:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/17/2022 12:38:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/17/2022 12:38:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/17/2022 12:38:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/17/2022 12:38:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 12:38:50 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.736969696969697 on epoch=312
06/17/2022 12:38:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/17/2022 12:38:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/17/2022 12:38:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/17/2022 12:39:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 12:39:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/17/2022 12:39:04 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7528024193548387 on epoch=324
06/17/2022 12:39:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/17/2022 12:39:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 12:39:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/17/2022 12:39:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
06/17/2022 12:39:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/17/2022 12:39:18 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7304347826086957 on epoch=337
06/17/2022 12:39:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 12:39:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 12:39:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/17/2022 12:39:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/17/2022 12:39:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/17/2022 12:39:32 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7474317338282077 on epoch=349
06/17/2022 12:39:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/17/2022 12:39:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/17/2022 12:39:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 12:39:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 12:39:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 12:39:47 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7308823529411764 on epoch=362
06/17/2022 12:39:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 12:39:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 12:39:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 12:39:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/17/2022 12:40:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 12:40:01 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.7087583148558757 on epoch=374
06/17/2022 12:40:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/17/2022 12:40:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 12:40:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 12:40:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/17/2022 12:40:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 12:40:15 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7169696969696969 on epoch=387
06/17/2022 12:40:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=389
06/17/2022 12:40:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/17/2022 12:40:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 12:40:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 12:40:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 12:40:29 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7087583148558757 on epoch=399
06/17/2022 12:40:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 12:40:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 12:40:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 12:40:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 12:40:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 12:40:43 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.6993673993987839 on epoch=412
06/17/2022 12:40:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 12:40:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/17/2022 12:40:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 12:40:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 12:40:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 12:40:58 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7670155993431855 on epoch=424
06/17/2022 12:41:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/17/2022 12:41:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 12:41:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 12:41:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 12:41:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 12:41:12 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7474317338282077 on epoch=437
06/17/2022 12:41:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/17/2022 12:41:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/17/2022 12:41:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 12:41:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 12:41:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 12:41:26 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7474317338282077 on epoch=449
06/17/2022 12:41:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 12:41:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 12:41:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/17/2022 12:41:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 12:41:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/17/2022 12:41:40 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7528024193548387 on epoch=462
06/17/2022 12:41:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 12:41:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 12:41:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 12:41:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 12:41:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 12:41:55 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7677083333333333 on epoch=474
06/17/2022 12:41:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 12:42:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 12:42:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 12:42:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 12:42:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 12:42:09 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7677083333333333 on epoch=487
06/17/2022 12:42:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 12:42:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/17/2022 12:42:17 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 12:42:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/17/2022 12:42:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/17/2022 12:42:23 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7677083333333333 on epoch=499
06/17/2022 12:42:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 12:42:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 12:42:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 12:42:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 12:42:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/17/2022 12:42:37 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7708629605688428 on epoch=512
06/17/2022 12:42:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 12:42:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 12:42:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 12:42:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 12:42:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 12:42:52 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7677083333333333 on epoch=524
06/17/2022 12:42:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 12:42:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 12:42:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/17/2022 12:43:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 12:43:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 12:43:06 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7827834799608994 on epoch=537
06/17/2022 12:43:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7717767783291977 -> 0.7827834799608994 on epoch=537, global_step=2150
06/17/2022 12:43:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 12:43:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 12:43:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 12:43:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 12:43:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 12:43:20 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=549
06/17/2022 12:43:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/17/2022 12:43:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 12:43:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 12:43:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 12:43:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 12:43:34 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7677083333333333 on epoch=562
06/17/2022 12:43:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/17/2022 12:43:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 12:43:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 12:43:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/17/2022 12:43:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 12:43:49 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=574
06/17/2022 12:43:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/17/2022 12:43:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/17/2022 12:43:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 12:43:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 12:44:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 12:44:03 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7390239695048322 on epoch=587
06/17/2022 12:44:06 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 12:44:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/17/2022 12:44:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 12:44:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 12:44:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 12:44:18 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7827834799608994 on epoch=599
06/17/2022 12:44:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 12:44:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 12:44:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 12:44:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 12:44:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 12:44:32 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7239881999133471 on epoch=612
06/17/2022 12:44:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 12:44:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 12:44:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/17/2022 12:44:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 12:44:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 12:44:46 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=624
06/17/2022 12:44:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 12:44:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 12:44:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/17/2022 12:44:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 12:44:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 12:45:00 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7456809947299077 on epoch=637
06/17/2022 12:45:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/17/2022 12:45:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 12:45:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 12:45:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 12:45:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 12:45:15 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.760700437257652 on epoch=649
06/17/2022 12:45:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 12:45:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 12:45:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 12:45:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 12:45:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 12:45:29 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7467986314760509 on epoch=662
06/17/2022 12:45:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 12:45:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 12:45:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 12:45:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 12:45:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 12:45:44 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.760700437257652 on epoch=674
06/17/2022 12:45:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/17/2022 12:45:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 12:45:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 12:45:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 12:45:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 12:45:58 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7447204968944099 on epoch=687
06/17/2022 12:46:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 12:46:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 12:46:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 12:46:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 12:46:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 12:46:12 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7447204968944099 on epoch=699
06/17/2022 12:46:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 12:46:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 12:46:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
06/17/2022 12:46:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 12:46:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 12:46:27 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.724004526977088 on epoch=712
06/17/2022 12:46:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 12:46:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 12:46:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 12:46:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/17/2022 12:46:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 12:46:41 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.760700437257652 on epoch=724
06/17/2022 12:46:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 12:46:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 12:46:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 12:46:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 12:46:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 12:46:55 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7528024193548387 on epoch=737
06/17/2022 12:46:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 12:47:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 12:47:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 12:47:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 12:47:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 12:47:10 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7390239695048322 on epoch=749
06/17/2022 12:47:10 - INFO - __main__ - save last model!
06/17/2022 12:47:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 12:47:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:47:10 - INFO - __main__ - Printing 3 examples
06/17/2022 12:47:10 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 12:47:10 - INFO - __main__ - ['sad']
06/17/2022 12:47:10 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 12:47:10 - INFO - __main__ - ['sad']
06/17/2022 12:47:10 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 12:47:10 - INFO - __main__ - ['sad']
06/17/2022 12:47:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:47:10 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 12:47:10 - INFO - __main__ - Printing 3 examples
06/17/2022 12:47:10 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 12:47:10 - INFO - __main__ - ['others']
06/17/2022 12:47:10 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 12:47:10 - INFO - __main__ - ['others']
06/17/2022 12:47:10 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 12:47:10 - INFO - __main__ - ['others']
06/17/2022 12:47:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:47:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:47:10 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 12:47:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:47:10 - INFO - __main__ - Printing 3 examples
06/17/2022 12:47:10 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 12:47:10 - INFO - __main__ - ['sad']
06/17/2022 12:47:10 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 12:47:10 - INFO - __main__ - ['sad']
06/17/2022 12:47:10 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 12:47:10 - INFO - __main__ - ['sad']
06/17/2022 12:47:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:47:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:47:10 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 12:47:12 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:47:17 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 12:47:26 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 12:47:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 12:47:27 - INFO - __main__ - Starting training!
06/17/2022 12:49:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/17/2022 12:49:08 - INFO - __main__ - Classification-F1 on test data: 0.2451
06/17/2022 12:49:08 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7827834799608994, test_performance=0.24509796751447763
06/17/2022 12:49:08 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/17/2022 12:49:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:49:09 - INFO - __main__ - Printing 3 examples
06/17/2022 12:49:09 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 12:49:09 - INFO - __main__ - ['sad']
06/17/2022 12:49:09 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 12:49:09 - INFO - __main__ - ['sad']
06/17/2022 12:49:09 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 12:49:09 - INFO - __main__ - ['sad']
06/17/2022 12:49:09 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:49:09 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:49:09 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 12:49:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 12:49:09 - INFO - __main__ - Printing 3 examples
06/17/2022 12:49:09 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 12:49:09 - INFO - __main__ - ['sad']
06/17/2022 12:49:09 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 12:49:09 - INFO - __main__ - ['sad']
06/17/2022 12:49:09 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 12:49:09 - INFO - __main__ - ['sad']
06/17/2022 12:49:09 - INFO - __main__ - Tokenizing Input ...
06/17/2022 12:49:09 - INFO - __main__ - Tokenizing Output ...
06/17/2022 12:49:09 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 12:49:25 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 12:49:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 12:49:25 - INFO - __main__ - Starting training!
06/17/2022 12:49:28 - INFO - __main__ - Step 10 Global step 10 Train loss 4.56 on epoch=2
06/17/2022 12:49:31 - INFO - __main__ - Step 20 Global step 20 Train loss 3.30 on epoch=4
06/17/2022 12:49:34 - INFO - __main__ - Step 30 Global step 30 Train loss 2.96 on epoch=7
06/17/2022 12:49:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.30 on epoch=9
06/17/2022 12:49:39 - INFO - __main__ - Step 50 Global step 50 Train loss 1.90 on epoch=12
06/17/2022 12:49:40 - INFO - __main__ - Global step 50 Train loss 3.00 Classification-F1 0.07799517555615115 on epoch=12
06/17/2022 12:49:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07799517555615115 on epoch=12, global_step=50
06/17/2022 12:49:43 - INFO - __main__ - Step 60 Global step 60 Train loss 1.55 on epoch=14
06/17/2022 12:49:46 - INFO - __main__ - Step 70 Global step 70 Train loss 1.16 on epoch=17
06/17/2022 12:49:48 - INFO - __main__ - Step 80 Global step 80 Train loss 1.07 on epoch=19
06/17/2022 12:49:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=22
06/17/2022 12:49:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=24
06/17/2022 12:49:54 - INFO - __main__ - Global step 100 Train loss 1.09 Classification-F1 0.6043233082706767 on epoch=24
06/17/2022 12:49:55 - INFO - __main__ - Saving model with best Classification-F1: 0.07799517555615115 -> 0.6043233082706767 on epoch=24, global_step=100
06/17/2022 12:49:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.70 on epoch=27
06/17/2022 12:50:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=29
06/17/2022 12:50:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.57 on epoch=32
06/17/2022 12:50:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.56 on epoch=34
06/17/2022 12:50:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.47 on epoch=37
06/17/2022 12:50:09 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.5880466251836488 on epoch=37
06/17/2022 12:50:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=39
06/17/2022 12:50:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=42
06/17/2022 12:50:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
06/17/2022 12:50:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.32 on epoch=47
06/17/2022 12:50:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.49 on epoch=49
06/17/2022 12:50:23 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.6545992014742015 on epoch=49
06/17/2022 12:50:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6043233082706767 -> 0.6545992014742015 on epoch=49, global_step=200
06/17/2022 12:50:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=52
06/17/2022 12:50:28 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=54
06/17/2022 12:50:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=57
06/17/2022 12:50:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/17/2022 12:50:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=62
06/17/2022 12:50:37 - INFO - __main__ - Global step 250 Train loss 0.34 Classification-F1 0.6359147609147608 on epoch=62
06/17/2022 12:50:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=64
06/17/2022 12:50:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/17/2022 12:50:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/17/2022 12:50:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=72
06/17/2022 12:50:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/17/2022 12:50:51 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.6897910138399268 on epoch=74
06/17/2022 12:50:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6545992014742015 -> 0.6897910138399268 on epoch=74, global_step=300
06/17/2022 12:50:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/17/2022 12:50:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.34 on epoch=79
06/17/2022 12:50:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/17/2022 12:51:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/17/2022 12:51:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=87
06/17/2022 12:51:05 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.6539130579877609 on epoch=87
06/17/2022 12:51:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/17/2022 12:51:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
06/17/2022 12:51:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=94
06/17/2022 12:51:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=97
06/17/2022 12:51:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/17/2022 12:51:20 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.6825244930508089 on epoch=99
06/17/2022 12:51:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/17/2022 12:51:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/17/2022 12:51:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=107
06/17/2022 12:51:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=109
06/17/2022 12:51:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=112
06/17/2022 12:51:34 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.7029326923076923 on epoch=112
06/17/2022 12:51:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6897910138399268 -> 0.7029326923076923 on epoch=112, global_step=450
06/17/2022 12:51:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=114
06/17/2022 12:51:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/17/2022 12:51:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=119
06/17/2022 12:51:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/17/2022 12:51:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=124
06/17/2022 12:51:48 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.7179429916339325 on epoch=124
06/17/2022 12:51:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7029326923076923 -> 0.7179429916339325 on epoch=124, global_step=500
06/17/2022 12:51:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
06/17/2022 12:51:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/17/2022 12:51:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=132
06/17/2022 12:51:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=134
06/17/2022 12:52:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=137
06/17/2022 12:52:02 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.7768375070741369 on epoch=137
06/17/2022 12:52:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7179429916339325 -> 0.7768375070741369 on epoch=137, global_step=550
06/17/2022 12:52:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=139
06/17/2022 12:52:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/17/2022 12:52:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=144
06/17/2022 12:52:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
06/17/2022 12:52:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/17/2022 12:52:17 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7533872377622378 on epoch=149
06/17/2022 12:52:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/17/2022 12:52:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/17/2022 12:52:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/17/2022 12:52:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/17/2022 12:52:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/17/2022 12:52:31 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.6954378342245989 on epoch=162
06/17/2022 12:52:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/17/2022 12:52:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=167
06/17/2022 12:52:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/17/2022 12:52:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/17/2022 12:52:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/17/2022 12:52:45 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.6687383872166481 on epoch=174
06/17/2022 12:52:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=177
06/17/2022 12:52:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
06/17/2022 12:52:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/17/2022 12:52:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
06/17/2022 12:52:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/17/2022 12:52:59 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7020325499927018 on epoch=187
06/17/2022 12:53:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/17/2022 12:53:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/17/2022 12:53:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/17/2022 12:53:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/17/2022 12:53:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/17/2022 12:53:13 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.7234841628959277 on epoch=199
06/17/2022 12:53:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/17/2022 12:53:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/17/2022 12:53:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/17/2022 12:53:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/17/2022 12:53:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/17/2022 12:53:28 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.7036764705882352 on epoch=212
06/17/2022 12:53:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=214
06/17/2022 12:53:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/17/2022 12:53:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/17/2022 12:53:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/17/2022 12:53:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/17/2022 12:53:42 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.7473553653042586 on epoch=224
06/17/2022 12:53:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/17/2022 12:53:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/17/2022 12:53:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/17/2022 12:53:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/17/2022 12:53:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/17/2022 12:53:56 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7544767899291897 on epoch=237
06/17/2022 12:53:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/17/2022 12:54:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 12:54:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/17/2022 12:54:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/17/2022 12:54:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 12:54:10 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.7322038501527435 on epoch=249
06/17/2022 12:54:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/17/2022 12:54:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 12:54:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/17/2022 12:54:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=259
06/17/2022 12:54:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/17/2022 12:54:24 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7474317338282077 on epoch=262
06/17/2022 12:54:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 12:54:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/17/2022 12:54:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/17/2022 12:54:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/17/2022 12:54:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/17/2022 12:54:39 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7474317338282077 on epoch=274
06/17/2022 12:54:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/17/2022 12:54:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 12:54:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/17/2022 12:54:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 12:54:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/17/2022 12:54:53 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7474317338282077 on epoch=287
06/17/2022 12:54:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/17/2022 12:54:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/17/2022 12:55:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 12:55:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/17/2022 12:55:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/17/2022 12:55:07 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7322038501527435 on epoch=299
06/17/2022 12:55:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/17/2022 12:55:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/17/2022 12:55:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/17/2022 12:55:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/17/2022 12:55:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/17/2022 12:55:21 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7322038501527435 on epoch=312
06/17/2022 12:55:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/17/2022 12:55:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/17/2022 12:55:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/17/2022 12:55:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/17/2022 12:55:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/17/2022 12:55:35 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7884274193548387 on epoch=324
06/17/2022 12:55:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7768375070741369 -> 0.7884274193548387 on epoch=324, global_step=1300
06/17/2022 12:55:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/17/2022 12:55:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/17/2022 12:55:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/17/2022 12:55:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/17/2022 12:55:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/17/2022 12:55:49 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7537577039076843 on epoch=337
06/17/2022 12:55:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 12:55:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 12:55:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 12:56:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 12:56:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/17/2022 12:56:04 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7537577039076843 on epoch=349
06/17/2022 12:56:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/17/2022 12:56:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 12:56:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/17/2022 12:56:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/17/2022 12:56:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/17/2022 12:56:18 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7322038501527435 on epoch=362
06/17/2022 12:56:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 12:56:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/17/2022 12:56:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 12:56:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/17/2022 12:56:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/17/2022 12:56:32 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=374
06/17/2022 12:56:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/17/2022 12:56:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 12:56:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/17/2022 12:56:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/17/2022 12:56:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 12:56:47 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6994509555485166 on epoch=387
06/17/2022 12:56:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/17/2022 12:56:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 12:56:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/17/2022 12:56:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/17/2022 12:57:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 12:57:01 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=399
06/17/2022 12:57:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 12:57:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/17/2022 12:57:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 12:57:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 12:57:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 12:57:15 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=412
06/17/2022 12:57:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 12:57:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/17/2022 12:57:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 12:57:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/17/2022 12:57:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 12:57:30 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=424
06/17/2022 12:57:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 12:57:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 12:57:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 12:57:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 12:57:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 12:57:44 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=437
06/17/2022 12:57:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/17/2022 12:57:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/17/2022 12:57:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 12:57:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/17/2022 12:57:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 12:57:58 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=449
06/17/2022 12:58:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 12:58:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/17/2022 12:58:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/17/2022 12:58:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 12:58:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 12:58:13 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=462
06/17/2022 12:58:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/17/2022 12:58:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 12:58:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 12:58:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 12:58:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 12:58:27 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7473553653042586 on epoch=474
06/17/2022 12:58:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 12:58:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 12:58:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 12:58:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=484
06/17/2022 12:58:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 12:58:41 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.724004526977088 on epoch=487
06/17/2022 12:58:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 12:58:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 12:58:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 12:58:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 12:58:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 12:58:56 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=499
06/17/2022 12:58:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/17/2022 12:59:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 12:59:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 12:59:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/17/2022 12:59:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 12:59:10 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=512
06/17/2022 12:59:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 12:59:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/17/2022 12:59:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/17/2022 12:59:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 12:59:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 12:59:24 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7474317338282077 on epoch=524
06/17/2022 12:59:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 12:59:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
06/17/2022 12:59:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/17/2022 12:59:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 12:59:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 12:59:39 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.724004526977088 on epoch=537
06/17/2022 12:59:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 12:59:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 12:59:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/17/2022 12:59:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 12:59:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 12:59:53 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=549
06/17/2022 12:59:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 12:59:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 13:00:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 13:00:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/17/2022 13:00:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 13:00:07 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=562
06/17/2022 13:00:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 13:00:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 13:00:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 13:00:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 13:00:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 13:00:22 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.724004526977088 on epoch=574
06/17/2022 13:00:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 13:00:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 13:00:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 13:00:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 13:00:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 13:00:36 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=587
06/17/2022 13:00:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 13:00:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 13:00:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 13:00:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 13:00:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 13:00:51 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=599
06/17/2022 13:00:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 13:00:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 13:00:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 13:01:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/17/2022 13:01:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 13:01:05 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7676319648093842 on epoch=612
06/17/2022 13:01:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 13:01:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 13:01:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 13:01:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 13:01:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 13:01:19 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=624
06/17/2022 13:01:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 13:01:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 13:01:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 13:01:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 13:01:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 13:01:33 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7628116357889921 on epoch=637
06/17/2022 13:01:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 13:01:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 13:01:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 13:01:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 13:01:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 13:01:48 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7676319648093842 on epoch=649
06/17/2022 13:01:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 13:01:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 13:01:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 13:01:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 13:02:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 13:02:02 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7830882352941176 on epoch=662
06/17/2022 13:02:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/17/2022 13:02:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/17/2022 13:02:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 13:02:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 13:02:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 13:02:17 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7676319648093842 on epoch=674
06/17/2022 13:02:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 13:02:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 13:02:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 13:02:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 13:02:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/17/2022 13:02:31 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7830882352941176 on epoch=687
06/17/2022 13:02:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 13:02:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/17/2022 13:02:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 13:02:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 13:02:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 13:02:46 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7628116357889921 on epoch=699
06/17/2022 13:02:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/17/2022 13:02:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 13:02:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 13:02:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 13:02:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 13:03:00 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6994509555485166 on epoch=712
06/17/2022 13:03:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 13:03:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 13:03:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 13:03:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 13:03:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 13:03:15 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=724
06/17/2022 13:03:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 13:03:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 13:03:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 13:03:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 13:03:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 13:03:29 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7473553653042586 on epoch=737
06/17/2022 13:03:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 13:03:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 13:03:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 13:03:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 13:03:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.14 on epoch=749
06/17/2022 13:03:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:03:43 - INFO - __main__ - Printing 3 examples
06/17/2022 13:03:43 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 13:03:43 - INFO - __main__ - ['sad']
06/17/2022 13:03:43 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 13:03:43 - INFO - __main__ - ['sad']
06/17/2022 13:03:43 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 13:03:43 - INFO - __main__ - ['sad']
06/17/2022 13:03:43 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:03:43 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:03:43 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7884274193548387 on epoch=749
06/17/2022 13:03:43 - INFO - __main__ - save last model!
06/17/2022 13:03:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 13:03:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 13:03:43 - INFO - __main__ - Printing 3 examples
06/17/2022 13:03:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 13:03:43 - INFO - __main__ - ['others']
06/17/2022 13:03:43 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 13:03:43 - INFO - __main__ - ['others']
06/17/2022 13:03:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 13:03:43 - INFO - __main__ - ['others']
06/17/2022 13:03:43 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:03:43 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:03:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:03:43 - INFO - __main__ - Printing 3 examples
06/17/2022 13:03:43 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 13:03:43 - INFO - __main__ - ['sad']
06/17/2022 13:03:43 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 13:03:43 - INFO - __main__ - ['sad']
06/17/2022 13:03:43 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 13:03:43 - INFO - __main__ - ['sad']
06/17/2022 13:03:43 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:03:43 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:03:43 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:03:45 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:03:51 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 13:03:59 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:03:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:04:00 - INFO - __main__ - Starting training!
06/17/2022 13:05:39 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/17/2022 13:05:39 - INFO - __main__ - Classification-F1 on test data: 0.2764
06/17/2022 13:05:40 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.7884274193548387, test_performance=0.2764308068031818
06/17/2022 13:05:40 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/17/2022 13:05:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:05:41 - INFO - __main__ - Printing 3 examples
06/17/2022 13:05:41 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/17/2022 13:05:41 - INFO - __main__ - ['sad']
06/17/2022 13:05:41 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/17/2022 13:05:41 - INFO - __main__ - ['sad']
06/17/2022 13:05:41 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/17/2022 13:05:41 - INFO - __main__ - ['sad']
06/17/2022 13:05:41 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:05:41 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:05:41 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:05:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:05:41 - INFO - __main__ - Printing 3 examples
06/17/2022 13:05:41 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/17/2022 13:05:41 - INFO - __main__ - ['sad']
06/17/2022 13:05:41 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/17/2022 13:05:41 - INFO - __main__ - ['sad']
06/17/2022 13:05:41 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/17/2022 13:05:41 - INFO - __main__ - ['sad']
06/17/2022 13:05:41 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:05:41 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:05:41 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:05:59 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:06:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:06:00 - INFO - __main__ - Starting training!
06/17/2022 13:06:03 - INFO - __main__ - Step 10 Global step 10 Train loss 4.95 on epoch=2
06/17/2022 13:06:06 - INFO - __main__ - Step 20 Global step 20 Train loss 3.70 on epoch=4
06/17/2022 13:06:09 - INFO - __main__ - Step 30 Global step 30 Train loss 3.17 on epoch=7
06/17/2022 13:06:11 - INFO - __main__ - Step 40 Global step 40 Train loss 2.74 on epoch=9
06/17/2022 13:06:14 - INFO - __main__ - Step 50 Global step 50 Train loss 2.47 on epoch=12
06/17/2022 13:06:15 - INFO - __main__ - Global step 50 Train loss 3.41 Classification-F1 0.027777777777777773 on epoch=12
06/17/2022 13:06:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.027777777777777773 on epoch=12, global_step=50
06/17/2022 13:06:18 - INFO - __main__ - Step 60 Global step 60 Train loss 2.25 on epoch=14
06/17/2022 13:06:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.92 on epoch=17
06/17/2022 13:06:23 - INFO - __main__ - Step 80 Global step 80 Train loss 1.71 on epoch=19
06/17/2022 13:06:26 - INFO - __main__ - Step 90 Global step 90 Train loss 1.41 on epoch=22
06/17/2022 13:06:28 - INFO - __main__ - Step 100 Global step 100 Train loss 1.26 on epoch=24
06/17/2022 13:06:30 - INFO - __main__ - Global step 100 Train loss 1.71 Classification-F1 0.17017127799736495 on epoch=24
06/17/2022 13:06:30 - INFO - __main__ - Saving model with best Classification-F1: 0.027777777777777773 -> 0.17017127799736495 on epoch=24, global_step=100
06/17/2022 13:06:32 - INFO - __main__ - Step 110 Global step 110 Train loss 1.00 on epoch=27
06/17/2022 13:06:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=29
06/17/2022 13:06:38 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=32
06/17/2022 13:06:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=34
06/17/2022 13:06:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.61 on epoch=37
06/17/2022 13:06:44 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.6157509157509158 on epoch=37
06/17/2022 13:06:44 - INFO - __main__ - Saving model with best Classification-F1: 0.17017127799736495 -> 0.6157509157509158 on epoch=37, global_step=150
06/17/2022 13:06:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=39
06/17/2022 13:06:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=42
06/17/2022 13:06:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=44
06/17/2022 13:06:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.54 on epoch=47
06/17/2022 13:06:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.53 on epoch=49
06/17/2022 13:06:58 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.6146825396825396 on epoch=49
06/17/2022 13:07:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.66 on epoch=52
06/17/2022 13:07:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
06/17/2022 13:07:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/17/2022 13:07:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=59
06/17/2022 13:07:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.41 on epoch=62
06/17/2022 13:07:12 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.6479885057471264 on epoch=62
06/17/2022 13:07:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6157509157509158 -> 0.6479885057471264 on epoch=62, global_step=250
06/17/2022 13:07:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=64
06/17/2022 13:07:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
06/17/2022 13:07:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=69
06/17/2022 13:07:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=72
06/17/2022 13:07:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=74
06/17/2022 13:07:26 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.6688948306595366 on epoch=74
06/17/2022 13:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6479885057471264 -> 0.6688948306595366 on epoch=74, global_step=300
06/17/2022 13:07:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=77
06/17/2022 13:07:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=79
06/17/2022 13:07:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=82
06/17/2022 13:07:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=84
06/17/2022 13:07:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=87
06/17/2022 13:07:39 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.7307885304659499 on epoch=87
06/17/2022 13:07:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6688948306595366 -> 0.7307885304659499 on epoch=87, global_step=350
06/17/2022 13:07:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=89
06/17/2022 13:07:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=92
06/17/2022 13:07:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=94
06/17/2022 13:07:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=97
06/17/2022 13:07:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/17/2022 13:07:53 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6971846846846846 on epoch=99
06/17/2022 13:07:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=102
06/17/2022 13:07:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=104
06/17/2022 13:08:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=107
06/17/2022 13:08:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=109
06/17/2022 13:08:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=112
06/17/2022 13:08:07 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.6753345210568211 on epoch=112
06/17/2022 13:08:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=114
06/17/2022 13:08:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=117
06/17/2022 13:08:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=119
06/17/2022 13:08:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/17/2022 13:08:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=124
06/17/2022 13:08:21 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.6771630898633185 on epoch=124
06/17/2022 13:08:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/17/2022 13:08:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/17/2022 13:08:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=132
06/17/2022 13:08:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/17/2022 13:08:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=137
06/17/2022 13:08:35 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.7117419839194034 on epoch=137
06/17/2022 13:08:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/17/2022 13:08:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=142
06/17/2022 13:08:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/17/2022 13:08:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=147
06/17/2022 13:08:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/17/2022 13:08:49 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.6974415204678364 on epoch=149
06/17/2022 13:08:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=152
06/17/2022 13:08:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/17/2022 13:08:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/17/2022 13:08:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/17/2022 13:09:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=162
06/17/2022 13:09:03 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.6897910138399268 on epoch=162
06/17/2022 13:09:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/17/2022 13:09:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/17/2022 13:09:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/17/2022 13:09:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=172
06/17/2022 13:09:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
06/17/2022 13:09:16 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7039459561198691 on epoch=174
06/17/2022 13:09:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/17/2022 13:09:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/17/2022 13:09:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=182
06/17/2022 13:09:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/17/2022 13:09:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=187
06/17/2022 13:09:30 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7054160138399268 on epoch=187
06/17/2022 13:09:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/17/2022 13:09:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=192
06/17/2022 13:09:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/17/2022 13:09:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/17/2022 13:09:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/17/2022 13:09:44 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6771630898633185 on epoch=199
06/17/2022 13:09:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=202
06/17/2022 13:09:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/17/2022 13:09:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=207
06/17/2022 13:09:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/17/2022 13:09:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/17/2022 13:09:58 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7301201201201201 on epoch=212
06/17/2022 13:10:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
06/17/2022 13:10:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/17/2022 13:10:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=219
06/17/2022 13:10:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=222
06/17/2022 13:10:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/17/2022 13:10:12 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7161248278575645 on epoch=224
06/17/2022 13:10:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/17/2022 13:10:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=229
06/17/2022 13:10:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=232
06/17/2022 13:10:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/17/2022 13:10:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=237
06/17/2022 13:10:26 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7385934594550894 on epoch=237
06/17/2022 13:10:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7307885304659499 -> 0.7385934594550894 on epoch=237, global_step=950
06/17/2022 13:10:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/17/2022 13:10:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/17/2022 13:10:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/17/2022 13:10:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=247
06/17/2022 13:10:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/17/2022 13:10:40 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6952375762859634 on epoch=249
06/17/2022 13:10:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/17/2022 13:10:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/17/2022 13:10:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/17/2022 13:10:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/17/2022 13:10:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/17/2022 13:10:54 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7106981981981981 on epoch=262
06/17/2022 13:10:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/17/2022 13:10:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/17/2022 13:11:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/17/2022 13:11:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
06/17/2022 13:11:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/17/2022 13:11:08 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7166818688557818 on epoch=274
06/17/2022 13:11:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/17/2022 13:11:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/17/2022 13:11:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/17/2022 13:11:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/17/2022 13:11:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/17/2022 13:11:21 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7300559947299077 on epoch=287
06/17/2022 13:11:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/17/2022 13:11:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/17/2022 13:11:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 13:11:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/17/2022 13:11:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/17/2022 13:11:35 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7153779644268774 on epoch=299
06/17/2022 13:11:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/17/2022 13:11:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/17/2022 13:11:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/17/2022 13:11:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/17/2022 13:11:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/17/2022 13:11:49 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.702338063151682 on epoch=312
06/17/2022 13:11:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/17/2022 13:11:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/17/2022 13:11:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/17/2022 13:12:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/17/2022 13:12:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/17/2022 13:12:03 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6787772901879442 on epoch=324
06/17/2022 13:12:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/17/2022 13:12:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/17/2022 13:12:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/17/2022 13:12:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/17/2022 13:12:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/17/2022 13:12:17 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6950757575757576 on epoch=337
06/17/2022 13:12:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/17/2022 13:12:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/17/2022 13:12:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/17/2022 13:12:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/17/2022 13:12:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/17/2022 13:12:31 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.6704386299974535 on epoch=349
06/17/2022 13:12:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/17/2022 13:12:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/17/2022 13:12:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.23 on epoch=357
06/17/2022 13:12:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/17/2022 13:12:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/17/2022 13:12:45 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6950757575757576 on epoch=362
06/17/2022 13:12:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
06/17/2022 13:12:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/17/2022 13:12:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/17/2022 13:12:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/17/2022 13:12:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/17/2022 13:12:59 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6704386299974535 on epoch=374
06/17/2022 13:13:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/17/2022 13:13:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/17/2022 13:13:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/17/2022 13:13:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/17/2022 13:13:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/17/2022 13:13:13 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6950757575757576 on epoch=387
06/17/2022 13:13:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/17/2022 13:13:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 13:13:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/17/2022 13:13:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/17/2022 13:13:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/17/2022 13:13:27 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7091537081339713 on epoch=399
06/17/2022 13:13:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/17/2022 13:13:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 13:13:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/17/2022 13:13:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/17/2022 13:13:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 13:13:41 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7170517260367845 on epoch=412
06/17/2022 13:13:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 13:13:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/17/2022 13:13:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/17/2022 13:13:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/17/2022 13:13:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/17/2022 13:13:55 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7372774244833068 on epoch=424
06/17/2022 13:13:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/17/2022 13:14:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/17/2022 13:14:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/17/2022 13:14:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/17/2022 13:14:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/17/2022 13:14:09 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7191095946387709 on epoch=437
06/17/2022 13:14:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/17/2022 13:14:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/17/2022 13:14:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/17/2022 13:14:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/17/2022 13:14:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/17/2022 13:14:23 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6725607725607726 on epoch=449
06/17/2022 13:14:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/17/2022 13:14:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/17/2022 13:14:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=457
06/17/2022 13:14:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/17/2022 13:14:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/17/2022 13:14:37 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7236143228790288 on epoch=462
06/17/2022 13:14:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 13:14:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/17/2022 13:14:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/17/2022 13:14:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/17/2022 13:14:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 13:14:51 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7032371092809914 on epoch=474
06/17/2022 13:14:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/17/2022 13:14:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 13:14:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/17/2022 13:15:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 13:15:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/17/2022 13:15:05 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7308307102105056 on epoch=487
06/17/2022 13:15:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/17/2022 13:15:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/17/2022 13:15:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 13:15:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/17/2022 13:15:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/17/2022 13:15:19 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7166818688557818 on epoch=499
06/17/2022 13:15:21 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/17/2022 13:15:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/17/2022 13:15:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/17/2022 13:15:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/17/2022 13:15:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/17/2022 13:15:33 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6950757575757576 on epoch=512
06/17/2022 13:15:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/17/2022 13:15:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 13:15:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 13:15:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 13:15:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/17/2022 13:15:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6937014966740576 on epoch=524
06/17/2022 13:15:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/17/2022 13:15:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 13:15:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/17/2022 13:15:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/17/2022 13:16:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 13:16:01 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.671577380952381 on epoch=537
06/17/2022 13:16:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 13:16:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/17/2022 13:16:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 13:16:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/17/2022 13:16:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 13:16:15 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7110628342245989 on epoch=549
06/17/2022 13:16:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 13:16:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/17/2022 13:16:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/17/2022 13:16:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 13:16:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/17/2022 13:16:29 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7191369969040248 on epoch=562
06/17/2022 13:16:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 13:16:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 13:16:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/17/2022 13:16:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 13:16:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 13:16:43 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7191369969040248 on epoch=574
06/17/2022 13:16:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/17/2022 13:16:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 13:16:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 13:16:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/17/2022 13:16:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 13:16:57 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7172987616099071 on epoch=587
06/17/2022 13:16:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/17/2022 13:17:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/17/2022 13:17:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 13:17:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 13:17:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/17/2022 13:17:11 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7314443146985842 on epoch=599
06/17/2022 13:17:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/17/2022 13:17:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.13 on epoch=604
06/17/2022 13:17:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 13:17:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 13:17:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 13:17:25 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7528959276018099 on epoch=612
06/17/2022 13:17:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7385934594550894 -> 0.7528959276018099 on epoch=612, global_step=2450
06/17/2022 13:17:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 13:17:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 13:17:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 13:17:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/17/2022 13:17:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 13:17:39 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7172987616099071 on epoch=624
06/17/2022 13:17:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/17/2022 13:17:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 13:17:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 13:17:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 13:17:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 13:17:53 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6946918927754169 on epoch=637
06/17/2022 13:17:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/17/2022 13:17:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/17/2022 13:18:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 13:18:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/17/2022 13:18:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 13:18:07 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.724716579775723 on epoch=649
06/17/2022 13:18:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/17/2022 13:18:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/17/2022 13:18:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 13:18:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 13:18:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 13:18:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6822068256850866 on epoch=662
06/17/2022 13:18:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/17/2022 13:18:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 13:18:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 13:18:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=672
06/17/2022 13:18:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 13:18:36 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7100942535725145 on epoch=674
06/17/2022 13:18:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 13:18:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 13:18:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 13:18:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 13:18:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/17/2022 13:18:49 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7475733469566487 on epoch=687
06/17/2022 13:18:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 13:18:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 13:18:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/17/2022 13:19:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/17/2022 13:19:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=699
06/17/2022 13:19:03 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.724716579775723 on epoch=699
06/17/2022 13:19:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 13:19:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 13:19:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 13:19:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 13:19:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/17/2022 13:19:18 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7315934065934065 on epoch=712
06/17/2022 13:19:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 13:19:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 13:19:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 13:19:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 13:19:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/17/2022 13:19:32 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7329237616099071 on epoch=724
06/17/2022 13:19:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 13:19:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/17/2022 13:19:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/17/2022 13:19:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 13:19:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/17/2022 13:19:46 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7104641107535172 on epoch=737
06/17/2022 13:19:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/17/2022 13:19:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 13:19:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 13:19:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 13:19:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 13:20:00 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7692578389352583 on epoch=749
06/17/2022 13:20:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7528959276018099 -> 0.7692578389352583 on epoch=749, global_step=3000
06/17/2022 13:20:00 - INFO - __main__ - save last model!
06/17/2022 13:20:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 13:20:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:20:00 - INFO - __main__ - Printing 3 examples
06/17/2022 13:20:00 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 13:20:00 - INFO - __main__ - ['happy']
06/17/2022 13:20:00 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 13:20:00 - INFO - __main__ - ['happy']
06/17/2022 13:20:00 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 13:20:00 - INFO - __main__ - ['happy']
06/17/2022 13:20:00 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:20:00 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 13:20:00 - INFO - __main__ - Printing 3 examples
06/17/2022 13:20:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 13:20:00 - INFO - __main__ - ['others']
06/17/2022 13:20:00 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 13:20:00 - INFO - __main__ - ['others']
06/17/2022 13:20:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 13:20:00 - INFO - __main__ - ['others']
06/17/2022 13:20:00 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:20:00 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:20:00 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:20:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:20:00 - INFO - __main__ - Printing 3 examples
06/17/2022 13:20:00 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 13:20:00 - INFO - __main__ - ['happy']
06/17/2022 13:20:00 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 13:20:00 - INFO - __main__ - ['happy']
06/17/2022 13:20:00 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 13:20:00 - INFO - __main__ - ['happy']
06/17/2022 13:20:00 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:20:00 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:20:00 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:20:02 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:20:08 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 13:20:16 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:20:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:20:17 - INFO - __main__ - Starting training!
06/17/2022 13:21:54 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/17/2022 13:21:54 - INFO - __main__ - Classification-F1 on test data: 0.3155
06/17/2022 13:21:55 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.7692578389352583, test_performance=0.3155306225084687
06/17/2022 13:21:55 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/17/2022 13:21:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:21:56 - INFO - __main__ - Printing 3 examples
06/17/2022 13:21:56 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 13:21:56 - INFO - __main__ - ['happy']
06/17/2022 13:21:56 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 13:21:56 - INFO - __main__ - ['happy']
06/17/2022 13:21:56 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 13:21:56 - INFO - __main__ - ['happy']
06/17/2022 13:21:56 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:21:56 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:21:56 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:21:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:21:56 - INFO - __main__ - Printing 3 examples
06/17/2022 13:21:56 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 13:21:56 - INFO - __main__ - ['happy']
06/17/2022 13:21:56 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 13:21:56 - INFO - __main__ - ['happy']
06/17/2022 13:21:56 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 13:21:56 - INFO - __main__ - ['happy']
06/17/2022 13:21:56 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:21:56 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:21:56 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:22:14 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:22:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:22:15 - INFO - __main__ - Starting training!
06/17/2022 13:22:19 - INFO - __main__ - Step 10 Global step 10 Train loss 4.39 on epoch=2
06/17/2022 13:22:21 - INFO - __main__ - Step 20 Global step 20 Train loss 3.13 on epoch=4
06/17/2022 13:22:24 - INFO - __main__ - Step 30 Global step 30 Train loss 2.27 on epoch=7
06/17/2022 13:22:27 - INFO - __main__ - Step 40 Global step 40 Train loss 1.75 on epoch=9
06/17/2022 13:22:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.28 on epoch=12
06/17/2022 13:22:30 - INFO - __main__ - Global step 50 Train loss 2.56 Classification-F1 0.31080208883412547 on epoch=12
06/17/2022 13:22:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.31080208883412547 on epoch=12, global_step=50
06/17/2022 13:22:33 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=14
06/17/2022 13:22:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
06/17/2022 13:22:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
06/17/2022 13:22:41 - INFO - __main__ - Step 90 Global step 90 Train loss 0.65 on epoch=22
06/17/2022 13:22:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.57 on epoch=24
06/17/2022 13:22:45 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.6379994102904321 on epoch=24
06/17/2022 13:22:45 - INFO - __main__ - Saving model with best Classification-F1: 0.31080208883412547 -> 0.6379994102904321 on epoch=24, global_step=100
06/17/2022 13:22:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.63 on epoch=27
06/17/2022 13:22:50 - INFO - __main__ - Step 120 Global step 120 Train loss 0.54 on epoch=29
06/17/2022 13:22:53 - INFO - __main__ - Step 130 Global step 130 Train loss 0.47 on epoch=32
06/17/2022 13:22:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.46 on epoch=34
06/17/2022 13:22:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.35 on epoch=37
06/17/2022 13:22:59 - INFO - __main__ - Global step 150 Train loss 0.49 Classification-F1 0.6544925662572723 on epoch=37
06/17/2022 13:22:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6379994102904321 -> 0.6544925662572723 on epoch=37, global_step=150
06/17/2022 13:23:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=39
06/17/2022 13:23:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=42
06/17/2022 13:23:07 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
06/17/2022 13:23:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=47
06/17/2022 13:23:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.37 on epoch=49
06/17/2022 13:23:13 - INFO - __main__ - Global step 200 Train loss 0.43 Classification-F1 0.7651597394540942 on epoch=49
06/17/2022 13:23:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6544925662572723 -> 0.7651597394540942 on epoch=49, global_step=200
06/17/2022 13:23:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.32 on epoch=52
06/17/2022 13:23:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=54
06/17/2022 13:23:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=57
06/17/2022 13:23:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=59
06/17/2022 13:23:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=62
06/17/2022 13:23:27 - INFO - __main__ - Global step 250 Train loss 0.30 Classification-F1 0.699931628056628 on epoch=62
06/17/2022 13:23:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/17/2022 13:23:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/17/2022 13:23:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/17/2022 13:23:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.20 on epoch=72
06/17/2022 13:23:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.17 on epoch=74
06/17/2022 13:23:42 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.7655219780219781 on epoch=74
06/17/2022 13:23:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7651597394540942 -> 0.7655219780219781 on epoch=74, global_step=300
06/17/2022 13:23:44 - INFO - __main__ - Step 310 Global step 310 Train loss 0.18 on epoch=77
06/17/2022 13:23:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.16 on epoch=79
06/17/2022 13:23:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.13 on epoch=82
06/17/2022 13:23:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=84
06/17/2022 13:23:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=87
06/17/2022 13:23:56 - INFO - __main__ - Global step 350 Train loss 0.15 Classification-F1 0.7122875816993464 on epoch=87
06/17/2022 13:23:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.16 on epoch=89
06/17/2022 13:24:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=92
06/17/2022 13:24:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.09 on epoch=94
06/17/2022 13:24:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=97
06/17/2022 13:24:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.08 on epoch=99
06/17/2022 13:24:10 - INFO - __main__ - Global step 400 Train loss 0.12 Classification-F1 0.7939195880372352 on epoch=99
06/17/2022 13:24:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7655219780219781 -> 0.7939195880372352 on epoch=99, global_step=400
06/17/2022 13:24:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=102
06/17/2022 13:24:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=104
06/17/2022 13:24:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.10 on epoch=107
06/17/2022 13:24:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=109
06/17/2022 13:24:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=112
06/17/2022 13:24:24 - INFO - __main__ - Global step 450 Train loss 0.10 Classification-F1 0.7978056426332288 on epoch=112
06/17/2022 13:24:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7939195880372352 -> 0.7978056426332288 on epoch=112, global_step=450
06/17/2022 13:24:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.08 on epoch=114
06/17/2022 13:24:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=117
06/17/2022 13:24:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=119
06/17/2022 13:24:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=122
06/17/2022 13:24:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=124
06/17/2022 13:24:39 - INFO - __main__ - Global step 500 Train loss 0.07 Classification-F1 0.7767947738535975 on epoch=124
06/17/2022 13:24:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/17/2022 13:24:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=129
06/17/2022 13:24:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=132
06/17/2022 13:24:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/17/2022 13:24:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=137
06/17/2022 13:24:53 - INFO - __main__ - Global step 550 Train loss 0.07 Classification-F1 0.7454545454545455 on epoch=137
06/17/2022 13:24:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=139
06/17/2022 13:24:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=142
06/17/2022 13:25:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=144
06/17/2022 13:25:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
06/17/2022 13:25:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/17/2022 13:25:07 - INFO - __main__ - Global step 600 Train loss 0.04 Classification-F1 0.7338275631569242 on epoch=149
06/17/2022 13:25:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=152
06/17/2022 13:25:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/17/2022 13:25:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/17/2022 13:25:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/17/2022 13:25:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/17/2022 13:25:21 - INFO - __main__ - Global step 650 Train loss 0.03 Classification-F1 0.70772238514174 on epoch=162
06/17/2022 13:25:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/17/2022 13:25:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/17/2022 13:25:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=169
06/17/2022 13:25:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/17/2022 13:25:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/17/2022 13:25:36 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.7285747642284145 on epoch=174
06/17/2022 13:25:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/17/2022 13:25:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/17/2022 13:25:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/17/2022 13:25:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/17/2022 13:25:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/17/2022 13:25:50 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.7268246187363834 on epoch=187
06/17/2022 13:25:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/17/2022 13:25:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/17/2022 13:25:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/17/2022 13:26:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/17/2022 13:26:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=199
06/17/2022 13:26:04 - INFO - __main__ - Global step 800 Train loss 0.02 Classification-F1 0.7609816653934302 on epoch=199
06/17/2022 13:26:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/17/2022 13:26:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/17/2022 13:26:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/17/2022 13:26:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/17/2022 13:26:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/17/2022 13:26:19 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.742858122269887 on epoch=212
06/17/2022 13:26:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/17/2022 13:26:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=217
06/17/2022 13:26:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=219
06/17/2022 13:26:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/17/2022 13:26:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=224
06/17/2022 13:26:33 - INFO - __main__ - Global step 900 Train loss 0.01 Classification-F1 0.8107007575757577 on epoch=224
06/17/2022 13:26:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7978056426332288 -> 0.8107007575757577 on epoch=224, global_step=900
06/17/2022 13:26:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/17/2022 13:26:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/17/2022 13:26:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/17/2022 13:26:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/17/2022 13:26:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/17/2022 13:26:48 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7453431372549019 on epoch=237
06/17/2022 13:26:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=239
06/17/2022 13:26:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 13:26:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/17/2022 13:26:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/17/2022 13:27:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 13:27:02 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7811430840664713 on epoch=249
06/17/2022 13:27:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/17/2022 13:27:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 13:27:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/17/2022 13:27:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/17/2022 13:27:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/17/2022 13:27:17 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.7756875477463714 on epoch=262
06/17/2022 13:27:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 13:27:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/17/2022 13:27:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/17/2022 13:27:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/17/2022 13:27:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/17/2022 13:27:31 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7517936117936118 on epoch=274
06/17/2022 13:27:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/17/2022 13:27:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 13:27:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 13:27:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 13:27:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/17/2022 13:27:46 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7313717532467532 on epoch=287
06/17/2022 13:27:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/17/2022 13:27:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/17/2022 13:27:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/17/2022 13:27:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/17/2022 13:27:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/17/2022 13:28:00 - INFO - __main__ - Global step 1200 Train loss 0.00 Classification-F1 0.7636849606613806 on epoch=299
06/17/2022 13:28:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/17/2022 13:28:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/17/2022 13:28:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/17/2022 13:28:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/17/2022 13:28:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/17/2022 13:28:15 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7163019225178935 on epoch=312
06/17/2022 13:28:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/17/2022 13:28:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/17/2022 13:28:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/17/2022 13:28:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/17/2022 13:28:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/17/2022 13:28:29 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7614718614718615 on epoch=324
06/17/2022 13:28:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/17/2022 13:28:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 13:28:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/17/2022 13:28:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/17/2022 13:28:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/17/2022 13:28:44 - INFO - __main__ - Global step 1350 Train loss 0.00 Classification-F1 0.7939903234020882 on epoch=337
06/17/2022 13:28:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 13:28:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/17/2022 13:28:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/17/2022 13:28:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/17/2022 13:28:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/17/2022 13:28:58 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7787552521008404 on epoch=349
06/17/2022 13:29:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 13:29:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 13:29:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/17/2022 13:29:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 13:29:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/17/2022 13:29:13 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7425920688788336 on epoch=362
06/17/2022 13:29:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/17/2022 13:29:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/17/2022 13:29:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/17/2022 13:29:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/17/2022 13:29:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/17/2022 13:29:27 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7635127364728883 on epoch=374
06/17/2022 13:29:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/17/2022 13:29:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 13:29:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 13:29:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 13:29:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 13:29:42 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7370098039215686 on epoch=387
06/17/2022 13:29:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 13:29:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 13:29:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 13:29:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 13:29:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 13:29:56 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7493055555555556 on epoch=399
06/17/2022 13:29:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/17/2022 13:30:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/17/2022 13:30:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/17/2022 13:30:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/17/2022 13:30:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 13:30:11 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7537725225225225 on epoch=412
06/17/2022 13:30:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 13:30:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/17/2022 13:30:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 13:30:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 13:30:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/17/2022 13:30:25 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7639296187683285 on epoch=424
06/17/2022 13:30:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 13:30:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 13:30:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/17/2022 13:30:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 13:30:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 13:30:39 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7478354978354979 on epoch=437
06/17/2022 13:30:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/17/2022 13:30:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 13:30:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 13:30:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 13:30:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 13:30:54 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7326778218618826 on epoch=449
06/17/2022 13:30:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/17/2022 13:30:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 13:31:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/17/2022 13:31:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 13:31:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/17/2022 13:31:08 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7306770984255772 on epoch=462
06/17/2022 13:31:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 13:31:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/17/2022 13:31:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 13:31:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 13:31:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 13:31:23 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7306770984255772 on epoch=474
06/17/2022 13:31:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 13:31:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 13:31:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 13:31:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 13:31:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 13:31:38 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7571438365556012 on epoch=487
06/17/2022 13:31:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/17/2022 13:31:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/17/2022 13:31:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 13:31:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/17/2022 13:31:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 13:31:52 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7636863156259708 on epoch=499
06/17/2022 13:31:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 13:31:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 13:32:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=507
06/17/2022 13:32:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 13:32:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 13:32:07 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7637976780357204 on epoch=512
06/17/2022 13:32:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 13:32:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 13:32:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 13:32:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 13:32:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/17/2022 13:32:21 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7272447868036104 on epoch=524
06/17/2022 13:32:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 13:32:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 13:32:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/17/2022 13:32:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 13:32:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 13:32:36 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7606060606060606 on epoch=537
06/17/2022 13:32:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 13:32:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 13:32:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 13:32:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 13:32:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 13:32:50 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7473437650922439 on epoch=549
06/17/2022 13:32:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 13:32:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 13:32:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 13:33:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 13:33:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 13:33:05 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7114372895622896 on epoch=562
06/17/2022 13:33:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 13:33:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 13:33:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 13:33:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 13:33:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 13:33:19 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7231817202405438 on epoch=574
06/17/2022 13:33:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 13:33:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 13:33:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 13:33:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 13:33:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 13:33:34 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7308104082297631 on epoch=587
06/17/2022 13:33:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/17/2022 13:33:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 13:33:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 13:33:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 13:33:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/17/2022 13:33:49 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7451839826839827 on epoch=599
06/17/2022 13:33:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=602
06/17/2022 13:33:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 13:33:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 13:33:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 13:34:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 13:34:03 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7426223014458309 on epoch=612
06/17/2022 13:34:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 13:34:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 13:34:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 13:34:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 13:34:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 13:34:18 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7652677357557781 on epoch=624
06/17/2022 13:34:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 13:34:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 13:34:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 13:34:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/17/2022 13:34:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 13:34:33 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7091103341103341 on epoch=637
06/17/2022 13:34:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 13:34:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 13:34:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 13:34:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 13:34:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 13:34:47 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7612330198537096 on epoch=649
06/17/2022 13:34:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 13:34:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 13:34:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 13:34:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 13:35:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 13:35:02 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7580746187363834 on epoch=662
06/17/2022 13:35:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 13:35:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 13:35:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 13:35:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/17/2022 13:35:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 13:35:16 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7496442125237192 on epoch=674
06/17/2022 13:35:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/17/2022 13:35:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 13:35:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 13:35:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 13:35:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 13:35:31 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7270251534957417 on epoch=687
06/17/2022 13:35:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 13:35:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/17/2022 13:35:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 13:35:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 13:35:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 13:35:46 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7270251534957417 on epoch=699
06/17/2022 13:35:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 13:35:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 13:35:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/17/2022 13:35:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 13:35:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 13:36:00 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7459700965025509 on epoch=712
06/17/2022 13:36:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 13:36:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 13:36:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 13:36:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/17/2022 13:36:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 13:36:15 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7293101111412306 on epoch=724
06/17/2022 13:36:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/17/2022 13:36:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 13:36:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 13:36:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 13:36:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 13:36:29 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7469235970250169 on epoch=737
06/17/2022 13:36:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
06/17/2022 13:36:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 13:36:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 13:36:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 13:36:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 13:36:44 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7652677357557781 on epoch=749
06/17/2022 13:36:44 - INFO - __main__ - save last model!
06/17/2022 13:36:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 13:36:44 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 13:36:44 - INFO - __main__ - Printing 3 examples
06/17/2022 13:36:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 13:36:44 - INFO - __main__ - ['others']
06/17/2022 13:36:44 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 13:36:44 - INFO - __main__ - ['others']
06/17/2022 13:36:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 13:36:44 - INFO - __main__ - ['others']
06/17/2022 13:36:44 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:36:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:36:44 - INFO - __main__ - Printing 3 examples
06/17/2022 13:36:44 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 13:36:44 - INFO - __main__ - ['happy']
06/17/2022 13:36:44 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 13:36:44 - INFO - __main__ - ['happy']
06/17/2022 13:36:44 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 13:36:44 - INFO - __main__ - ['happy']
06/17/2022 13:36:44 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:36:44 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:36:44 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:36:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:36:44 - INFO - __main__ - Printing 3 examples
06/17/2022 13:36:44 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 13:36:44 - INFO - __main__ - ['happy']
06/17/2022 13:36:44 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 13:36:44 - INFO - __main__ - ['happy']
06/17/2022 13:36:44 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 13:36:44 - INFO - __main__ - ['happy']
06/17/2022 13:36:44 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:36:44 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:36:44 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:36:46 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:36:52 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 13:37:00 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:37:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:37:00 - INFO - __main__ - Starting training!
06/17/2022 13:38:41 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/17/2022 13:38:41 - INFO - __main__ - Classification-F1 on test data: 0.3612
06/17/2022 13:38:41 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.8107007575757577, test_performance=0.36115658538651807
06/17/2022 13:38:41 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/17/2022 13:38:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:38:42 - INFO - __main__ - Printing 3 examples
06/17/2022 13:38:42 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 13:38:42 - INFO - __main__ - ['happy']
06/17/2022 13:38:42 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 13:38:42 - INFO - __main__ - ['happy']
06/17/2022 13:38:42 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 13:38:42 - INFO - __main__ - ['happy']
06/17/2022 13:38:42 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:38:42 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:38:42 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:38:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:38:42 - INFO - __main__ - Printing 3 examples
06/17/2022 13:38:42 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 13:38:42 - INFO - __main__ - ['happy']
06/17/2022 13:38:42 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 13:38:42 - INFO - __main__ - ['happy']
06/17/2022 13:38:42 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 13:38:42 - INFO - __main__ - ['happy']
06/17/2022 13:38:42 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:38:42 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:38:43 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:39:01 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:39:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:39:02 - INFO - __main__ - Starting training!
06/17/2022 13:39:05 - INFO - __main__ - Step 10 Global step 10 Train loss 4.07 on epoch=2
06/17/2022 13:39:08 - INFO - __main__ - Step 20 Global step 20 Train loss 3.36 on epoch=4
06/17/2022 13:39:10 - INFO - __main__ - Step 30 Global step 30 Train loss 2.68 on epoch=7
06/17/2022 13:39:13 - INFO - __main__ - Step 40 Global step 40 Train loss 2.04 on epoch=9
06/17/2022 13:39:16 - INFO - __main__ - Step 50 Global step 50 Train loss 1.56 on epoch=12
06/17/2022 13:39:17 - INFO - __main__ - Global step 50 Train loss 2.74 Classification-F1 0.13226613965744402 on epoch=12
06/17/2022 13:39:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13226613965744402 on epoch=12, global_step=50
06/17/2022 13:39:19 - INFO - __main__ - Step 60 Global step 60 Train loss 1.24 on epoch=14
06/17/2022 13:39:22 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/17/2022 13:39:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=19
06/17/2022 13:39:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.79 on epoch=22
06/17/2022 13:39:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=24
06/17/2022 13:39:31 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.6522444017652829 on epoch=24
06/17/2022 13:39:31 - INFO - __main__ - Saving model with best Classification-F1: 0.13226613965744402 -> 0.6522444017652829 on epoch=24, global_step=100
06/17/2022 13:39:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=27
06/17/2022 13:39:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=29
06/17/2022 13:39:38 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=32
06/17/2022 13:39:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.51 on epoch=34
06/17/2022 13:39:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
06/17/2022 13:39:44 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.6729551150603783 on epoch=37
06/17/2022 13:39:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6522444017652829 -> 0.6729551150603783 on epoch=37, global_step=150
06/17/2022 13:39:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.58 on epoch=39
06/17/2022 13:39:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=42
06/17/2022 13:39:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/17/2022 13:39:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=47
06/17/2022 13:39:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=49
06/17/2022 13:39:58 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.6878342245989305 on epoch=49
06/17/2022 13:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6729551150603783 -> 0.6878342245989305 on epoch=49, global_step=200
06/17/2022 13:40:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=52
06/17/2022 13:40:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=54
06/17/2022 13:40:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=57
06/17/2022 13:40:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/17/2022 13:40:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=62
06/17/2022 13:40:12 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.7286435786435785 on epoch=62
06/17/2022 13:40:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6878342245989305 -> 0.7286435786435785 on epoch=62, global_step=250
06/17/2022 13:40:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=64
06/17/2022 13:40:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=67
06/17/2022 13:40:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=69
06/17/2022 13:40:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=72
06/17/2022 13:40:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/17/2022 13:40:26 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.7619444444444443 on epoch=74
06/17/2022 13:40:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7286435786435785 -> 0.7619444444444443 on epoch=74, global_step=300
06/17/2022 13:40:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=77
06/17/2022 13:40:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/17/2022 13:40:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=82
06/17/2022 13:40:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
06/17/2022 13:40:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/17/2022 13:40:40 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.7625906120023767 on epoch=87
06/17/2022 13:40:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7619444444444443 -> 0.7625906120023767 on epoch=87, global_step=350
06/17/2022 13:40:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/17/2022 13:40:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/17/2022 13:40:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/17/2022 13:40:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=97
06/17/2022 13:40:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=99
06/17/2022 13:40:54 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.7235091137904437 on epoch=99
06/17/2022 13:40:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/17/2022 13:40:59 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/17/2022 13:41:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=107
06/17/2022 13:41:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=109
06/17/2022 13:41:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=112
06/17/2022 13:41:07 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.7278861865258924 on epoch=112
06/17/2022 13:41:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=114
06/17/2022 13:41:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/17/2022 13:41:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/17/2022 13:41:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=122
06/17/2022 13:41:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=124
06/17/2022 13:41:21 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.7231686900804548 on epoch=124
06/17/2022 13:41:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=127
06/17/2022 13:41:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
06/17/2022 13:41:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=132
06/17/2022 13:41:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/17/2022 13:41:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=137
06/17/2022 13:41:35 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.7134534534534535 on epoch=137
06/17/2022 13:41:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=139
06/17/2022 13:41:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=142
06/17/2022 13:41:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
06/17/2022 13:41:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=147
06/17/2022 13:41:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=149
06/17/2022 13:41:49 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.6982905982905983 on epoch=149
06/17/2022 13:41:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=152
06/17/2022 13:41:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=154
06/17/2022 13:41:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=157
06/17/2022 13:41:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/17/2022 13:42:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/17/2022 13:42:03 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.7616432587020823 on epoch=162
06/17/2022 13:42:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/17/2022 13:42:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/17/2022 13:42:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/17/2022 13:42:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/17/2022 13:42:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/17/2022 13:42:16 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.7305239300021084 on epoch=174
06/17/2022 13:42:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=177
06/17/2022 13:42:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=179
06/17/2022 13:42:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/17/2022 13:42:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/17/2022 13:42:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/17/2022 13:42:30 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7613122171945701 on epoch=187
06/17/2022 13:42:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/17/2022 13:42:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/17/2022 13:42:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/17/2022 13:42:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/17/2022 13:42:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/17/2022 13:42:44 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.6728255528255528 on epoch=199
06/17/2022 13:42:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/17/2022 13:42:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/17/2022 13:42:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/17/2022 13:42:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/17/2022 13:42:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/17/2022 13:42:58 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6780563554757102 on epoch=212
06/17/2022 13:43:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/17/2022 13:43:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/17/2022 13:43:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/17/2022 13:43:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/17/2022 13:43:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/17/2022 13:43:12 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6785664785664786 on epoch=224
06/17/2022 13:43:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/17/2022 13:43:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/17/2022 13:43:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/17/2022 13:43:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/17/2022 13:43:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=237
06/17/2022 13:43:26 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.6776945168785775 on epoch=237
06/17/2022 13:43:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/17/2022 13:43:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/17/2022 13:43:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/17/2022 13:43:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/17/2022 13:43:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 13:43:40 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6874390968508615 on epoch=249
06/17/2022 13:43:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/17/2022 13:43:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/17/2022 13:43:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/17/2022 13:43:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/17/2022 13:43:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=262
06/17/2022 13:43:54 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7144074675324675 on epoch=262
06/17/2022 13:43:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 13:43:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/17/2022 13:44:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/17/2022 13:44:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/17/2022 13:44:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=274
06/17/2022 13:44:08 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.6929041546688606 on epoch=274
06/17/2022 13:44:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/17/2022 13:44:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 13:44:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 13:44:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/17/2022 13:44:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/17/2022 13:44:22 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.6962857744107743 on epoch=287
06/17/2022 13:44:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/17/2022 13:44:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/17/2022 13:44:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/17/2022 13:44:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/17/2022 13:44:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/17/2022 13:44:36 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7303729485524617 on epoch=299
06/17/2022 13:44:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/17/2022 13:44:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/17/2022 13:44:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/17/2022 13:44:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/17/2022 13:44:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 13:44:50 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7117845117845117 on epoch=312
06/17/2022 13:44:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/17/2022 13:44:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/17/2022 13:44:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/17/2022 13:45:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 13:45:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/17/2022 13:45:05 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6777672558922558 on epoch=324
06/17/2022 13:45:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/17/2022 13:45:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/17/2022 13:45:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/17/2022 13:45:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/17/2022 13:45:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/17/2022 13:45:19 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6971055088702148 on epoch=337
06/17/2022 13:45:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 13:45:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/17/2022 13:45:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/17/2022 13:45:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 13:45:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/17/2022 13:45:34 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6931227556227556 on epoch=349
06/17/2022 13:45:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 13:45:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 13:45:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 13:45:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 13:45:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/17/2022 13:45:48 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6931227556227556 on epoch=362
06/17/2022 13:45:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/17/2022 13:45:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/17/2022 13:45:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/17/2022 13:45:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/17/2022 13:46:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 13:46:02 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6981165225947009 on epoch=374
06/17/2022 13:46:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 13:46:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 13:46:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/17/2022 13:46:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 13:46:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/17/2022 13:46:16 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7283249158249159 on epoch=387
06/17/2022 13:46:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 13:46:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/17/2022 13:46:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 13:46:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/17/2022 13:46:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 13:46:30 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7633228840125391 on epoch=399
06/17/2022 13:46:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7625906120023767 -> 0.7633228840125391 on epoch=399, global_step=1600
06/17/2022 13:46:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/17/2022 13:46:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 13:46:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 13:46:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/17/2022 13:46:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 13:46:45 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7632114758128957 on epoch=412
06/17/2022 13:46:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 13:46:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 13:46:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/17/2022 13:46:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 13:46:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 13:46:59 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7146042287882896 on epoch=424
06/17/2022 13:47:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/17/2022 13:47:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 13:47:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 13:47:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 13:47:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 13:47:13 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7321860891186286 on epoch=437
06/17/2022 13:47:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 13:47:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 13:47:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 13:47:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 13:47:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 13:47:27 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7305672268907564 on epoch=449
06/17/2022 13:47:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 13:47:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/17/2022 13:47:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/17/2022 13:47:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 13:47:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=462
06/17/2022 13:47:41 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7120054114835899 on epoch=462
06/17/2022 13:47:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 13:47:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 13:47:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 13:47:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 13:47:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 13:47:55 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7120054114835899 on epoch=474
06/17/2022 13:47:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/17/2022 13:48:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 13:48:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 13:48:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 13:48:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 13:48:09 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7087418300653595 on epoch=487
06/17/2022 13:48:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 13:48:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 13:48:17 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 13:48:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 13:48:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/17/2022 13:48:23 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7633228840125392 on epoch=499
06/17/2022 13:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7633228840125391 -> 0.7633228840125392 on epoch=499, global_step=2000
06/17/2022 13:48:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 13:48:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/17/2022 13:48:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/17/2022 13:48:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 13:48:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 13:48:38 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7632114758128957 on epoch=512
06/17/2022 13:48:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/17/2022 13:48:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 13:48:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 13:48:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/17/2022 13:48:51 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 13:48:52 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7960227272727274 on epoch=524
06/17/2022 13:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7633228840125392 -> 0.7960227272727274 on epoch=524, global_step=2100
06/17/2022 13:48:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/17/2022 13:48:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/17/2022 13:49:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 13:49:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 13:49:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/17/2022 13:49:06 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7476686457776558 on epoch=537
06/17/2022 13:49:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 13:49:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 13:49:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 13:49:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 13:49:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 13:49:20 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7476686457776558 on epoch=549
06/17/2022 13:49:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 13:49:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 13:49:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 13:49:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/17/2022 13:49:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 13:49:34 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.73832020523197 on epoch=562
06/17/2022 13:49:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 13:49:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 13:49:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 13:49:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 13:49:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 13:49:49 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7632114758128957 on epoch=574
06/17/2022 13:49:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 13:49:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 13:49:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 13:49:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 13:50:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 13:50:03 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7632114758128957 on epoch=587
06/17/2022 13:50:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/17/2022 13:50:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=592
06/17/2022 13:50:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/17/2022 13:50:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/17/2022 13:50:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 13:50:17 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7799242424242425 on epoch=599
06/17/2022 13:50:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 13:50:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 13:50:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 13:50:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/17/2022 13:50:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/17/2022 13:50:31 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7642156862745099 on epoch=612
06/17/2022 13:50:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 13:50:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 13:50:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 13:50:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=622
06/17/2022 13:50:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 13:50:45 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.780479127134725 on epoch=624
06/17/2022 13:50:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 13:50:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 13:50:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 13:50:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 13:50:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 13:51:00 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7643500948766604 on epoch=637
06/17/2022 13:51:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 13:51:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 13:51:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 13:51:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 13:51:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 13:51:14 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7645822551894659 on epoch=649
06/17/2022 13:51:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 13:51:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 13:51:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 13:51:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 13:51:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 13:51:28 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7316513297603396 on epoch=662
06/17/2022 13:51:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 13:51:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 13:51:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 13:51:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 13:51:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 13:51:42 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.731927486744931 on epoch=674
06/17/2022 13:51:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 13:51:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/17/2022 13:51:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 13:51:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 13:51:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 13:51:56 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7112817887011436 on epoch=687
06/17/2022 13:51:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 13:52:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 13:52:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 13:52:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 13:52:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 13:52:10 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6777526395173454 on epoch=699
06/17/2022 13:52:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 13:52:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 13:52:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 13:52:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 13:52:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 13:52:25 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7647727272727273 on epoch=712
06/17/2022 13:52:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 13:52:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 13:52:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 13:52:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 13:52:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 13:52:39 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7321860891186286 on epoch=724
06/17/2022 13:52:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/17/2022 13:52:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 13:52:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 13:52:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/17/2022 13:52:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/17/2022 13:52:53 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6965410320673479 on epoch=737
06/17/2022 13:52:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 13:52:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 13:53:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 13:53:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 13:53:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 13:53:08 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7317775923866023 on epoch=749
06/17/2022 13:53:08 - INFO - __main__ - save last model!
06/17/2022 13:53:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 13:53:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 13:53:08 - INFO - __main__ - Printing 3 examples
06/17/2022 13:53:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 13:53:08 - INFO - __main__ - ['others']
06/17/2022 13:53:08 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 13:53:08 - INFO - __main__ - ['others']
06/17/2022 13:53:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 13:53:08 - INFO - __main__ - ['others']
06/17/2022 13:53:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:53:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:53:08 - INFO - __main__ - Printing 3 examples
06/17/2022 13:53:08 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 13:53:08 - INFO - __main__ - ['happy']
06/17/2022 13:53:08 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 13:53:08 - INFO - __main__ - ['happy']
06/17/2022 13:53:08 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 13:53:08 - INFO - __main__ - ['happy']
06/17/2022 13:53:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:53:08 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:53:08 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:53:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:53:08 - INFO - __main__ - Printing 3 examples
06/17/2022 13:53:08 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 13:53:08 - INFO - __main__ - ['happy']
06/17/2022 13:53:08 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 13:53:08 - INFO - __main__ - ['happy']
06/17/2022 13:53:08 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 13:53:08 - INFO - __main__ - ['happy']
06/17/2022 13:53:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:53:08 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:53:08 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:53:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:53:15 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 13:53:26 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:53:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:53:27 - INFO - __main__ - Starting training!
06/17/2022 13:55:06 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/17/2022 13:55:06 - INFO - __main__ - Classification-F1 on test data: 0.3497
06/17/2022 13:55:07 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.7960227272727274, test_performance=0.34969592370210867
06/17/2022 13:55:07 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/17/2022 13:55:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:55:08 - INFO - __main__ - Printing 3 examples
06/17/2022 13:55:08 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 13:55:08 - INFO - __main__ - ['happy']
06/17/2022 13:55:08 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 13:55:08 - INFO - __main__ - ['happy']
06/17/2022 13:55:08 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 13:55:08 - INFO - __main__ - ['happy']
06/17/2022 13:55:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:55:08 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:55:08 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 13:55:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 13:55:08 - INFO - __main__ - Printing 3 examples
06/17/2022 13:55:08 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 13:55:08 - INFO - __main__ - ['happy']
06/17/2022 13:55:08 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 13:55:08 - INFO - __main__ - ['happy']
06/17/2022 13:55:08 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 13:55:08 - INFO - __main__ - ['happy']
06/17/2022 13:55:08 - INFO - __main__ - Tokenizing Input ...
06/17/2022 13:55:08 - INFO - __main__ - Tokenizing Output ...
06/17/2022 13:55:08 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 13:55:23 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 13:55:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 13:55:24 - INFO - __main__ - Starting training!
06/17/2022 13:55:27 - INFO - __main__ - Step 10 Global step 10 Train loss 4.60 on epoch=2
06/17/2022 13:55:30 - INFO - __main__ - Step 20 Global step 20 Train loss 3.48 on epoch=4
06/17/2022 13:55:33 - INFO - __main__ - Step 30 Global step 30 Train loss 2.91 on epoch=7
06/17/2022 13:55:35 - INFO - __main__ - Step 40 Global step 40 Train loss 2.36 on epoch=9
06/17/2022 13:55:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.96 on epoch=12
06/17/2022 13:55:39 - INFO - __main__ - Global step 50 Train loss 3.06 Classification-F1 0.09047619047619047 on epoch=12
06/17/2022 13:55:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09047619047619047 on epoch=12, global_step=50
06/17/2022 13:55:42 - INFO - __main__ - Step 60 Global step 60 Train loss 1.51 on epoch=14
06/17/2022 13:55:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.32 on epoch=17
06/17/2022 13:55:48 - INFO - __main__ - Step 80 Global step 80 Train loss 1.12 on epoch=19
06/17/2022 13:55:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.81 on epoch=22
06/17/2022 13:55:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.93 on epoch=24
06/17/2022 13:55:54 - INFO - __main__ - Global step 100 Train loss 1.14 Classification-F1 0.6309456797072897 on epoch=24
06/17/2022 13:55:54 - INFO - __main__ - Saving model with best Classification-F1: 0.09047619047619047 -> 0.6309456797072897 on epoch=24, global_step=100
06/17/2022 13:55:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=27
06/17/2022 13:55:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
06/17/2022 13:56:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.62 on epoch=32
06/17/2022 13:56:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=34
06/17/2022 13:56:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=37
06/17/2022 13:56:08 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.6797619047619048 on epoch=37
06/17/2022 13:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6309456797072897 -> 0.6797619047619048 on epoch=37, global_step=150
06/17/2022 13:56:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
06/17/2022 13:56:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=42
06/17/2022 13:56:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.49 on epoch=44
06/17/2022 13:56:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/17/2022 13:56:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.47 on epoch=49
06/17/2022 13:56:22 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.7113727121803579 on epoch=49
06/17/2022 13:56:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6797619047619048 -> 0.7113727121803579 on epoch=49, global_step=200
06/17/2022 13:56:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=52
06/17/2022 13:56:28 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=54
06/17/2022 13:56:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=57
06/17/2022 13:56:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=59
06/17/2022 13:56:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=62
06/17/2022 13:56:37 - INFO - __main__ - Global step 250 Train loss 0.47 Classification-F1 0.7500910178394966 on epoch=62
06/17/2022 13:56:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7113727121803579 -> 0.7500910178394966 on epoch=62, global_step=250
06/17/2022 13:56:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=64
06/17/2022 13:56:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=67
06/17/2022 13:56:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=69
06/17/2022 13:56:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=72
06/17/2022 13:56:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/17/2022 13:56:51 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.7509072704318884 on epoch=74
06/17/2022 13:56:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7500910178394966 -> 0.7509072704318884 on epoch=74, global_step=300
06/17/2022 13:56:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/17/2022 13:56:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=79
06/17/2022 13:56:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=82
06/17/2022 13:57:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=84
06/17/2022 13:57:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/17/2022 13:57:05 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.7435574229691877 on epoch=87
06/17/2022 13:57:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=89
06/17/2022 13:57:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/17/2022 13:57:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=94
06/17/2022 13:57:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/17/2022 13:57:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=99
06/17/2022 13:57:20 - INFO - __main__ - Global step 400 Train loss 0.27 Classification-F1 0.7339043309631545 on epoch=99
06/17/2022 13:57:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=102
06/17/2022 13:57:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/17/2022 13:57:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/17/2022 13:57:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
06/17/2022 13:57:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
06/17/2022 13:57:34 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.7636412663537402 on epoch=112
06/17/2022 13:57:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7509072704318884 -> 0.7636412663537402 on epoch=112, global_step=450
06/17/2022 13:57:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/17/2022 13:57:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=117
06/17/2022 13:57:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=119
06/17/2022 13:57:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/17/2022 13:57:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=124
06/17/2022 13:57:48 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7329673423423423 on epoch=124
06/17/2022 13:57:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/17/2022 13:57:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=129
06/17/2022 13:57:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=132
06/17/2022 13:57:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/17/2022 13:58:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/17/2022 13:58:03 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7471025910364145 on epoch=137
06/17/2022 13:58:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=139
06/17/2022 13:58:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/17/2022 13:58:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=144
06/17/2022 13:58:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
06/17/2022 13:58:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/17/2022 13:58:17 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.7293948412698413 on epoch=149
06/17/2022 13:58:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/17/2022 13:58:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/17/2022 13:58:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=157
06/17/2022 13:58:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/17/2022 13:58:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=162
06/17/2022 13:58:31 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7434926184926186 on epoch=162
06/17/2022 13:58:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=164
06/17/2022 13:58:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
06/17/2022 13:58:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=169
06/17/2022 13:58:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/17/2022 13:58:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/17/2022 13:58:45 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7287031799899447 on epoch=174
06/17/2022 13:58:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/17/2022 13:58:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/17/2022 13:58:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/17/2022 13:58:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/17/2022 13:58:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/17/2022 13:59:00 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.7281267751855988 on epoch=187
06/17/2022 13:59:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/17/2022 13:59:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/17/2022 13:59:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/17/2022 13:59:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/17/2022 13:59:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/17/2022 13:59:14 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.6993416493416493 on epoch=199
06/17/2022 13:59:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/17/2022 13:59:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/17/2022 13:59:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/17/2022 13:59:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
06/17/2022 13:59:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/17/2022 13:59:28 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.6993416493416493 on epoch=212
06/17/2022 13:59:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/17/2022 13:59:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/17/2022 13:59:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/17/2022 13:59:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/17/2022 13:59:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/17/2022 13:59:43 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7140612076095947 on epoch=224
06/17/2022 13:59:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/17/2022 13:59:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/17/2022 13:59:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/17/2022 13:59:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/17/2022 13:59:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/17/2022 13:59:57 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.6983645983645983 on epoch=237
06/17/2022 14:00:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/17/2022 14:00:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/17/2022 14:00:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/17/2022 14:00:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/17/2022 14:00:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/17/2022 14:00:11 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7141144716996111 on epoch=249
06/17/2022 14:00:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/17/2022 14:00:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/17/2022 14:00:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/17/2022 14:00:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/17/2022 14:00:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/17/2022 14:00:26 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7291430416430417 on epoch=262
06/17/2022 14:00:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 14:00:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/17/2022 14:00:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/17/2022 14:00:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/17/2022 14:00:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/17/2022 14:00:40 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7283249158249159 on epoch=274
06/17/2022 14:00:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/17/2022 14:00:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/17/2022 14:00:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 14:00:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/17/2022 14:00:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/17/2022 14:00:55 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.727784062342886 on epoch=287
06/17/2022 14:00:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/17/2022 14:01:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/17/2022 14:01:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/17/2022 14:01:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 14:01:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/17/2022 14:01:09 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7635127364728883 on epoch=299
06/17/2022 14:01:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/17/2022 14:01:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/17/2022 14:01:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/17/2022 14:01:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/17/2022 14:01:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/17/2022 14:01:24 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7635127364728883 on epoch=312
06/17/2022 14:01:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/17/2022 14:01:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/17/2022 14:01:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/17/2022 14:01:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 14:01:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/17/2022 14:01:38 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7270604395604396 on epoch=324
06/17/2022 14:01:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/17/2022 14:01:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 14:01:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/17/2022 14:01:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/17/2022 14:01:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/17/2022 14:01:53 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7128551628551628 on epoch=337
06/17/2022 14:01:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/17/2022 14:01:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/17/2022 14:02:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 14:02:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 14:02:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/17/2022 14:02:07 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.746652962260173 on epoch=349
06/17/2022 14:02:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/17/2022 14:02:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/17/2022 14:02:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/17/2022 14:02:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/17/2022 14:02:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/17/2022 14:02:22 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7296685340802987 on epoch=362
06/17/2022 14:02:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/17/2022 14:02:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/17/2022 14:02:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/17/2022 14:02:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/17/2022 14:02:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 14:02:36 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7460497835497836 on epoch=374
06/17/2022 14:02:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/17/2022 14:02:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 14:02:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 14:02:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 14:02:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/17/2022 14:02:51 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.6931597774244833 on epoch=387
06/17/2022 14:02:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/17/2022 14:02:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/17/2022 14:02:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 14:03:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/17/2022 14:03:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 14:03:05 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7457796244192895 on epoch=399
06/17/2022 14:03:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 14:03:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 14:03:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 14:03:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/17/2022 14:03:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 14:03:20 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7289525695597803 on epoch=412
06/17/2022 14:03:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 14:03:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/17/2022 14:03:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/17/2022 14:03:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 14:03:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/17/2022 14:03:34 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7274108209592081 on epoch=424
06/17/2022 14:03:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/17/2022 14:03:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 14:03:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 14:03:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 14:03:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 14:03:49 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7318445068445069 on epoch=437
06/17/2022 14:03:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 14:03:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/17/2022 14:03:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/17/2022 14:03:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/17/2022 14:04:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 14:04:03 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7311825148032045 on epoch=449
06/17/2022 14:04:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 14:04:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 14:04:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/17/2022 14:04:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 14:04:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 14:04:18 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7424124894713131 on epoch=462
06/17/2022 14:04:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 14:04:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/17/2022 14:04:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/17/2022 14:04:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/17/2022 14:04:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/17/2022 14:04:32 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.712037037037037 on epoch=474
06/17/2022 14:04:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/17/2022 14:04:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 14:04:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 14:04:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 14:04:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=487
06/17/2022 14:04:47 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7297619047619048 on epoch=487
06/17/2022 14:04:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/17/2022 14:04:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/17/2022 14:04:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 14:04:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 14:05:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/17/2022 14:05:01 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7090580286168522 on epoch=499
06/17/2022 14:05:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 14:05:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/17/2022 14:05:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/17/2022 14:05:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 14:05:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/17/2022 14:05:15 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7296685340802987 on epoch=512
06/17/2022 14:05:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/17/2022 14:05:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 14:05:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 14:05:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 14:05:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 14:05:30 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7136836343732895 on epoch=524
06/17/2022 14:05:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 14:05:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 14:05:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 14:05:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 14:05:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/17/2022 14:05:44 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7460497835497836 on epoch=537
06/17/2022 14:05:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 14:05:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/17/2022 14:05:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 14:05:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 14:05:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 14:05:59 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7283249158249159 on epoch=549
06/17/2022 14:06:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 14:06:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 14:06:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 14:06:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 14:06:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 14:06:13 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.696237616927272 on epoch=562
06/17/2022 14:06:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 14:06:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 14:06:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 14:06:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/17/2022 14:06:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 14:06:28 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7318445068445069 on epoch=574
06/17/2022 14:06:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=577
06/17/2022 14:06:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 14:06:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 14:06:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 14:06:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 14:06:42 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.714439352385023 on epoch=587
06/17/2022 14:06:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 14:06:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/17/2022 14:06:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 14:06:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 14:06:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 14:06:57 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7434926184926186 on epoch=599
06/17/2022 14:07:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/17/2022 14:07:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 14:07:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 14:07:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 14:07:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 14:07:11 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7291430416430417 on epoch=612
06/17/2022 14:07:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/17/2022 14:07:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 14:07:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/17/2022 14:07:22 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 14:07:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 14:07:26 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7283249158249159 on epoch=624
06/17/2022 14:07:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 14:07:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 14:07:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/17/2022 14:07:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/17/2022 14:07:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 14:07:40 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7291430416430417 on epoch=637
06/17/2022 14:07:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 14:07:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/17/2022 14:07:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 14:07:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/17/2022 14:07:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/17/2022 14:07:55 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7460497835497836 on epoch=649
06/17/2022 14:07:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 14:08:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 14:08:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/17/2022 14:08:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 14:08:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 14:08:10 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.714439352385023 on epoch=662
06/17/2022 14:08:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 14:08:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 14:08:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 14:08:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/17/2022 14:08:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/17/2022 14:08:24 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.714439352385023 on epoch=674
06/17/2022 14:08:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 14:08:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 14:08:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 14:08:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 14:08:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 14:08:39 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7138188608776844 on epoch=687
06/17/2022 14:08:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 14:08:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
06/17/2022 14:08:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 14:08:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 14:08:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/17/2022 14:08:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7147561354457905 on epoch=699
06/17/2022 14:08:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 14:08:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 14:09:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/17/2022 14:09:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 14:09:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/17/2022 14:09:08 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7318829093022641 on epoch=712
06/17/2022 14:09:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 14:09:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/17/2022 14:09:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 14:09:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/17/2022 14:09:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/17/2022 14:09:23 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7304272664673109 on epoch=724
06/17/2022 14:09:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 14:09:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 14:09:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/17/2022 14:09:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 14:09:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 14:09:37 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7304272664673109 on epoch=737
06/17/2022 14:09:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 14:09:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 14:09:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 14:09:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 14:09:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/17/2022 14:09:52 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7283411033411034 on epoch=749
06/17/2022 14:09:52 - INFO - __main__ - save last model!
06/17/2022 14:09:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 14:09:52 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 14:09:52 - INFO - __main__ - Printing 3 examples
06/17/2022 14:09:52 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 14:09:52 - INFO - __main__ - ['others']
06/17/2022 14:09:52 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 14:09:52 - INFO - __main__ - ['others']
06/17/2022 14:09:52 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 14:09:52 - INFO - __main__ - ['others']
06/17/2022 14:09:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:09:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:09:52 - INFO - __main__ - Printing 3 examples
06/17/2022 14:09:52 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 14:09:52 - INFO - __main__ - ['happy']
06/17/2022 14:09:52 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 14:09:52 - INFO - __main__ - ['happy']
06/17/2022 14:09:52 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 14:09:52 - INFO - __main__ - ['happy']
06/17/2022 14:09:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:09:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:09:52 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 14:09:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:09:52 - INFO - __main__ - Printing 3 examples
06/17/2022 14:09:52 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 14:09:52 - INFO - __main__ - ['happy']
06/17/2022 14:09:52 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 14:09:52 - INFO - __main__ - ['happy']
06/17/2022 14:09:52 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 14:09:52 - INFO - __main__ - ['happy']
06/17/2022 14:09:52 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:09:52 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:09:52 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 14:09:54 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:09:59 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 14:10:08 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 14:10:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 14:10:08 - INFO - __main__ - Starting training!
06/17/2022 14:11:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/17/2022 14:11:50 - INFO - __main__ - Classification-F1 on test data: 0.3121
06/17/2022 14:11:50 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.7636412663537402, test_performance=0.3121089296548055
06/17/2022 14:11:50 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/17/2022 14:11:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:11:51 - INFO - __main__ - Printing 3 examples
06/17/2022 14:11:51 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/17/2022 14:11:51 - INFO - __main__ - ['happy']
06/17/2022 14:11:51 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/17/2022 14:11:51 - INFO - __main__ - ['happy']
06/17/2022 14:11:51 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/17/2022 14:11:51 - INFO - __main__ - ['happy']
06/17/2022 14:11:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:11:51 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:11:51 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 14:11:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:11:51 - INFO - __main__ - Printing 3 examples
06/17/2022 14:11:51 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/17/2022 14:11:51 - INFO - __main__ - ['happy']
06/17/2022 14:11:51 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/17/2022 14:11:51 - INFO - __main__ - ['happy']
06/17/2022 14:11:51 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/17/2022 14:11:51 - INFO - __main__ - ['happy']
06/17/2022 14:11:51 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:11:51 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:11:52 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 14:12:07 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 14:12:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 14:12:07 - INFO - __main__ - Starting training!
06/17/2022 14:12:11 - INFO - __main__ - Step 10 Global step 10 Train loss 4.71 on epoch=2
06/17/2022 14:12:13 - INFO - __main__ - Step 20 Global step 20 Train loss 4.07 on epoch=4
06/17/2022 14:12:16 - INFO - __main__ - Step 30 Global step 30 Train loss 3.38 on epoch=7
06/17/2022 14:12:18 - INFO - __main__ - Step 40 Global step 40 Train loss 2.84 on epoch=9
06/17/2022 14:12:21 - INFO - __main__ - Step 50 Global step 50 Train loss 2.66 on epoch=12
06/17/2022 14:12:22 - INFO - __main__ - Global step 50 Train loss 3.53 Classification-F1 0.025320512820512824 on epoch=12
06/17/2022 14:12:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.025320512820512824 on epoch=12, global_step=50
06/17/2022 14:12:25 - INFO - __main__ - Step 60 Global step 60 Train loss 2.46 on epoch=14
06/17/2022 14:12:28 - INFO - __main__ - Step 70 Global step 70 Train loss 2.03 on epoch=17
06/17/2022 14:12:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.86 on epoch=19
06/17/2022 14:12:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.43 on epoch=22
06/17/2022 14:12:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.47 on epoch=24
06/17/2022 14:12:37 - INFO - __main__ - Global step 100 Train loss 1.85 Classification-F1 0.23805361305361306 on epoch=24
06/17/2022 14:12:37 - INFO - __main__ - Saving model with best Classification-F1: 0.025320512820512824 -> 0.23805361305361306 on epoch=24, global_step=100
06/17/2022 14:12:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.21 on epoch=27
06/17/2022 14:12:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.10 on epoch=29
06/17/2022 14:12:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.94 on epoch=32
06/17/2022 14:12:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.93 on epoch=34
06/17/2022 14:12:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.90 on epoch=37
06/17/2022 14:12:51 - INFO - __main__ - Global step 150 Train loss 1.02 Classification-F1 0.6912903225806452 on epoch=37
06/17/2022 14:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.23805361305361306 -> 0.6912903225806452 on epoch=37, global_step=150
06/17/2022 14:12:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=39
06/17/2022 14:12:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=42
06/17/2022 14:12:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=44
06/17/2022 14:13:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=47
06/17/2022 14:13:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=49
06/17/2022 14:13:05 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.6183712121212122 on epoch=49
06/17/2022 14:13:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/17/2022 14:13:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=54
06/17/2022 14:13:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=57
06/17/2022 14:13:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=59
06/17/2022 14:13:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=62
06/17/2022 14:13:19 - INFO - __main__ - Global step 250 Train loss 0.65 Classification-F1 0.6068948412698413 on epoch=62
06/17/2022 14:13:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=64
06/17/2022 14:13:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/17/2022 14:13:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=69
06/17/2022 14:13:29 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=72
06/17/2022 14:13:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.64 on epoch=74
06/17/2022 14:13:33 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.6851457688338494 on epoch=74
06/17/2022 14:13:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=77
06/17/2022 14:13:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=79
06/17/2022 14:13:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=82
06/17/2022 14:13:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.59 on epoch=84
06/17/2022 14:13:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.44 on epoch=87
06/17/2022 14:13:47 - INFO - __main__ - Global step 350 Train loss 0.53 Classification-F1 0.71667731948467 on epoch=87
06/17/2022 14:13:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6912903225806452 -> 0.71667731948467 on epoch=87, global_step=350
06/17/2022 14:13:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=89
06/17/2022 14:13:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=92
06/17/2022 14:13:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=94
06/17/2022 14:13:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=97
06/17/2022 14:14:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=99
06/17/2022 14:14:01 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.7173303167420814 on epoch=99
06/17/2022 14:14:01 - INFO - __main__ - Saving model with best Classification-F1: 0.71667731948467 -> 0.7173303167420814 on epoch=99, global_step=400
06/17/2022 14:14:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
06/17/2022 14:14:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=104
06/17/2022 14:14:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=107
06/17/2022 14:14:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=109
06/17/2022 14:14:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=112
06/17/2022 14:14:15 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.7976430976430977 on epoch=112
06/17/2022 14:14:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7173303167420814 -> 0.7976430976430977 on epoch=112, global_step=450
06/17/2022 14:14:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=114
06/17/2022 14:14:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=117
06/17/2022 14:14:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=119
06/17/2022 14:14:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=122
06/17/2022 14:14:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=124
06/17/2022 14:14:29 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.7625906120023767 on epoch=124
06/17/2022 14:14:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=127
06/17/2022 14:14:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=129
06/17/2022 14:14:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/17/2022 14:14:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=134
06/17/2022 14:14:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=137
06/17/2022 14:14:43 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.7623529411764705 on epoch=137
06/17/2022 14:14:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/17/2022 14:14:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/17/2022 14:14:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=144
06/17/2022 14:14:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/17/2022 14:14:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=149
06/17/2022 14:14:57 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.7802623830399792 on epoch=149
06/17/2022 14:15:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/17/2022 14:15:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/17/2022 14:15:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/17/2022 14:15:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=159
06/17/2022 14:15:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/17/2022 14:15:11 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.7287017231134879 on epoch=162
06/17/2022 14:15:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/17/2022 14:15:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/17/2022 14:15:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/17/2022 14:15:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/17/2022 14:15:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=174
06/17/2022 14:15:25 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.7138762312955861 on epoch=174
06/17/2022 14:15:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/17/2022 14:15:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/17/2022 14:15:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/17/2022 14:15:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
06/17/2022 14:15:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
06/17/2022 14:15:39 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7184139732314174 on epoch=187
06/17/2022 14:15:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/17/2022 14:15:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/17/2022 14:15:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=194
06/17/2022 14:15:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/17/2022 14:15:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=199
06/17/2022 14:15:53 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7283997252747253 on epoch=199
06/17/2022 14:15:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=202
06/17/2022 14:15:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
06/17/2022 14:16:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/17/2022 14:16:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=209
06/17/2022 14:16:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/17/2022 14:16:07 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6871094591682827 on epoch=212
06/17/2022 14:16:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=214
06/17/2022 14:16:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/17/2022 14:16:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=219
06/17/2022 14:16:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
06/17/2022 14:16:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/17/2022 14:16:21 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7965073529411765 on epoch=224
06/17/2022 14:16:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/17/2022 14:16:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=229
06/17/2022 14:16:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/17/2022 14:16:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=234
06/17/2022 14:16:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=237
06/17/2022 14:16:35 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7647727272727273 on epoch=237
06/17/2022 14:16:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/17/2022 14:16:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/17/2022 14:16:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/17/2022 14:16:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/17/2022 14:16:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/17/2022 14:16:49 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7458593114665222 on epoch=249
06/17/2022 14:16:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/17/2022 14:16:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/17/2022 14:16:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/17/2022 14:17:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/17/2022 14:17:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=262
06/17/2022 14:17:03 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7289525695597803 on epoch=262
06/17/2022 14:17:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/17/2022 14:17:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/17/2022 14:17:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/17/2022 14:17:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/17/2022 14:17:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/17/2022 14:17:18 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7092095437683673 on epoch=274
06/17/2022 14:17:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/17/2022 14:17:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/17/2022 14:17:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/17/2022 14:17:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/17/2022 14:17:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/17/2022 14:17:32 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.6841491841491841 on epoch=287
06/17/2022 14:17:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/17/2022 14:17:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/17/2022 14:17:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/17/2022 14:17:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/17/2022 14:17:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/17/2022 14:17:46 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7315580286168522 on epoch=299
06/17/2022 14:17:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/17/2022 14:17:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/17/2022 14:17:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/17/2022 14:17:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/17/2022 14:17:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/17/2022 14:18:00 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7141144716996111 on epoch=312
06/17/2022 14:18:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/17/2022 14:18:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/17/2022 14:18:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
06/17/2022 14:18:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/17/2022 14:18:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/17/2022 14:18:14 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7645021645021646 on epoch=324
06/17/2022 14:18:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/17/2022 14:18:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/17/2022 14:18:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/17/2022 14:18:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/17/2022 14:18:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/17/2022 14:18:28 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.746652962260173 on epoch=337
06/17/2022 14:18:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/17/2022 14:18:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/17/2022 14:18:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 14:18:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/17/2022 14:18:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/17/2022 14:18:43 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7141144716996111 on epoch=349
06/17/2022 14:18:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/17/2022 14:18:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/17/2022 14:18:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/17/2022 14:18:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/17/2022 14:18:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/17/2022 14:18:57 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7490196078431373 on epoch=362
06/17/2022 14:18:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/17/2022 14:19:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/17/2022 14:19:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/17/2022 14:19:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/17/2022 14:19:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/17/2022 14:19:11 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7473437650922439 on epoch=374
06/17/2022 14:19:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/17/2022 14:19:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/17/2022 14:19:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/17/2022 14:19:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/17/2022 14:19:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/17/2022 14:19:25 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6623368180163312 on epoch=387
06/17/2022 14:19:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/17/2022 14:19:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/17/2022 14:19:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/17/2022 14:19:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/17/2022 14:19:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/17/2022 14:19:39 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7317572274468827 on epoch=399
06/17/2022 14:19:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/17/2022 14:19:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 14:19:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/17/2022 14:19:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/17/2022 14:19:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 14:19:53 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7140241153932838 on epoch=412
06/17/2022 14:19:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/17/2022 14:19:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/17/2022 14:20:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/17/2022 14:20:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/17/2022 14:20:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 14:20:07 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7304855275443511 on epoch=424
06/17/2022 14:20:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/17/2022 14:20:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/17/2022 14:20:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/17/2022 14:20:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/17/2022 14:20:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/17/2022 14:20:21 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7308104082297631 on epoch=437
06/17/2022 14:20:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 14:20:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/17/2022 14:20:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/17/2022 14:20:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/17/2022 14:20:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/17/2022 14:20:36 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7133643907837456 on epoch=449
06/17/2022 14:20:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/17/2022 14:20:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/17/2022 14:20:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/17/2022 14:20:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=459
06/17/2022 14:20:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/17/2022 14:20:50 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6952085831542537 on epoch=462
06/17/2022 14:20:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=464
06/17/2022 14:20:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/17/2022 14:20:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/17/2022 14:21:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 14:21:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 14:21:04 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7308104082297631 on epoch=474
06/17/2022 14:21:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 14:21:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/17/2022 14:21:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/17/2022 14:21:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 14:21:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/17/2022 14:21:18 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7478354978354979 on epoch=487
06/17/2022 14:21:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/17/2022 14:21:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/17/2022 14:21:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/17/2022 14:21:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/17/2022 14:21:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/17/2022 14:21:33 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7091103341103341 on epoch=499
06/17/2022 14:21:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/17/2022 14:21:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/17/2022 14:21:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/17/2022 14:21:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/17/2022 14:21:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 14:21:47 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7304272664673109 on epoch=512
06/17/2022 14:21:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/17/2022 14:21:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/17/2022 14:21:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/17/2022 14:21:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/17/2022 14:22:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/17/2022 14:22:01 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7226839826839828 on epoch=524
06/17/2022 14:22:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/17/2022 14:22:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/17/2022 14:22:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 14:22:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 14:22:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 14:22:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7104833716168981 on epoch=537
06/17/2022 14:22:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/17/2022 14:22:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 14:22:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 14:22:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/17/2022 14:22:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 14:22:30 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7304272664673109 on epoch=549
06/17/2022 14:22:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/17/2022 14:22:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/17/2022 14:22:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 14:22:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 14:22:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 14:22:44 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.730102385781899 on epoch=562
06/17/2022 14:22:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/17/2022 14:22:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/17/2022 14:22:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/17/2022 14:22:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/17/2022 14:22:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/17/2022 14:22:58 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7281344437416545 on epoch=574
06/17/2022 14:23:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/17/2022 14:23:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/17/2022 14:23:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/17/2022 14:23:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/17/2022 14:23:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/17/2022 14:23:13 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7126283846872083 on epoch=587
06/17/2022 14:23:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/17/2022 14:23:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=592
06/17/2022 14:23:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/17/2022 14:23:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 14:23:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 14:23:27 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7126283846872083 on epoch=599
06/17/2022 14:23:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 14:23:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 14:23:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 14:23:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/17/2022 14:23:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 14:23:41 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6968289645774434 on epoch=612
06/17/2022 14:23:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 14:23:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/17/2022 14:23:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/17/2022 14:23:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/17/2022 14:23:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/17/2022 14:23:55 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7426223014458309 on epoch=624
06/17/2022 14:23:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/17/2022 14:24:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/17/2022 14:24:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/17/2022 14:24:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/17/2022 14:24:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/17/2022 14:24:10 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7460815047021944 on epoch=637
06/17/2022 14:24:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/17/2022 14:24:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/17/2022 14:24:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 14:24:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 14:24:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/17/2022 14:24:24 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6681651681651681 on epoch=649
06/17/2022 14:24:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/17/2022 14:24:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 14:24:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=657
06/17/2022 14:24:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=659
06/17/2022 14:24:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 14:24:38 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6984447796607507 on epoch=662
06/17/2022 14:24:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/17/2022 14:24:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 14:24:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 14:24:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 14:24:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 14:24:53 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.733034983034983 on epoch=674
06/17/2022 14:24:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 14:24:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 14:25:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/17/2022 14:25:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 14:25:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 14:25:07 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7130395100983337 on epoch=687
06/17/2022 14:25:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 14:25:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 14:25:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 14:25:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/17/2022 14:25:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 14:25:21 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7133004926108375 on epoch=699
06/17/2022 14:25:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 14:25:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=704
06/17/2022 14:25:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/17/2022 14:25:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/17/2022 14:25:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 14:25:36 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7142993979200876 on epoch=712
06/17/2022 14:25:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 14:25:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 14:25:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 14:25:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 14:25:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 14:25:50 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7112817887011434 on epoch=724
06/17/2022 14:25:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/17/2022 14:25:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/17/2022 14:25:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 14:26:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/17/2022 14:26:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/17/2022 14:26:04 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7142993979200876 on epoch=737
06/17/2022 14:26:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/17/2022 14:26:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 14:26:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 14:26:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 14:26:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 14:26:19 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7142993979200876 on epoch=749
06/17/2022 14:26:19 - INFO - __main__ - save last model!
06/17/2022 14:26:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 14:26:19 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 14:26:19 - INFO - __main__ - Printing 3 examples
06/17/2022 14:26:19 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:26:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:26:19 - INFO - __main__ - Printing 3 examples
06/17/2022 14:26:19 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:26:19 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:26:19 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 14:26:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:26:19 - INFO - __main__ - Printing 3 examples
06/17/2022 14:26:19 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 14:26:19 - INFO - __main__ - ['others']
06/17/2022 14:26:19 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:26:19 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:26:19 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 14:26:21 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:26:27 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 14:26:35 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 14:26:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 14:26:36 - INFO - __main__ - Starting training!
06/17/2022 14:28:15 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/17/2022 14:28:15 - INFO - __main__ - Classification-F1 on test data: 0.3437
06/17/2022 14:28:16 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.7976430976430977, test_performance=0.3437273160781147
06/17/2022 14:28:16 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/17/2022 14:28:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:28:17 - INFO - __main__ - Printing 3 examples
06/17/2022 14:28:17 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 14:28:17 - INFO - __main__ - ['others']
06/17/2022 14:28:17 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 14:28:17 - INFO - __main__ - ['others']
06/17/2022 14:28:17 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 14:28:17 - INFO - __main__ - ['others']
06/17/2022 14:28:17 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:28:17 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:28:17 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 14:28:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:28:17 - INFO - __main__ - Printing 3 examples
06/17/2022 14:28:17 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 14:28:17 - INFO - __main__ - ['others']
06/17/2022 14:28:17 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 14:28:17 - INFO - __main__ - ['others']
06/17/2022 14:28:17 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 14:28:17 - INFO - __main__ - ['others']
06/17/2022 14:28:17 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:28:17 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:28:17 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 14:28:32 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 14:28:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 14:28:33 - INFO - __main__ - Starting training!
06/17/2022 14:28:36 - INFO - __main__ - Step 10 Global step 10 Train loss 4.12 on epoch=2
06/17/2022 14:28:39 - INFO - __main__ - Step 20 Global step 20 Train loss 2.78 on epoch=4
06/17/2022 14:28:41 - INFO - __main__ - Step 30 Global step 30 Train loss 2.03 on epoch=7
06/17/2022 14:28:44 - INFO - __main__ - Step 40 Global step 40 Train loss 1.41 on epoch=9
06/17/2022 14:28:47 - INFO - __main__ - Step 50 Global step 50 Train loss 1.04 on epoch=12
06/17/2022 14:28:48 - INFO - __main__ - Global step 50 Train loss 2.27 Classification-F1 0.2656778425655977 on epoch=12
06/17/2022 14:28:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2656778425655977 on epoch=12, global_step=50
06/17/2022 14:28:51 - INFO - __main__ - Step 60 Global step 60 Train loss 0.76 on epoch=14
06/17/2022 14:28:53 - INFO - __main__ - Step 70 Global step 70 Train loss 0.72 on epoch=17
06/17/2022 14:28:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.65 on epoch=19
06/17/2022 14:28:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.59 on epoch=22
06/17/2022 14:29:01 - INFO - __main__ - Step 100 Global step 100 Train loss 0.57 on epoch=24
06/17/2022 14:29:02 - INFO - __main__ - Global step 100 Train loss 0.66 Classification-F1 0.5674242424242424 on epoch=24
06/17/2022 14:29:02 - INFO - __main__ - Saving model with best Classification-F1: 0.2656778425655977 -> 0.5674242424242424 on epoch=24, global_step=100
06/17/2022 14:29:05 - INFO - __main__ - Step 110 Global step 110 Train loss 0.55 on epoch=27
06/17/2022 14:29:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=29
06/17/2022 14:29:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=32
06/17/2022 14:29:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.42 on epoch=34
06/17/2022 14:29:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
06/17/2022 14:29:17 - INFO - __main__ - Global step 150 Train loss 0.50 Classification-F1 0.7087017231134879 on epoch=37
06/17/2022 14:29:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5674242424242424 -> 0.7087017231134879 on epoch=37, global_step=150
06/17/2022 14:29:20 - INFO - __main__ - Step 160 Global step 160 Train loss 0.37 on epoch=39
06/17/2022 14:29:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=42
06/17/2022 14:29:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=44
06/17/2022 14:29:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=47
06/17/2022 14:29:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=49
06/17/2022 14:29:31 - INFO - __main__ - Global step 200 Train loss 0.33 Classification-F1 0.7116014791209453 on epoch=49
06/17/2022 14:29:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7087017231134879 -> 0.7116014791209453 on epoch=49, global_step=200
06/17/2022 14:29:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.30 on epoch=52
06/17/2022 14:29:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=54
06/17/2022 14:29:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.31 on epoch=57
06/17/2022 14:29:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=59
06/17/2022 14:29:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.20 on epoch=62
06/17/2022 14:29:46 - INFO - __main__ - Global step 250 Train loss 0.27 Classification-F1 0.7096774193548387 on epoch=62
06/17/2022 14:29:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=64
06/17/2022 14:29:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=67
06/17/2022 14:29:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.13 on epoch=69
06/17/2022 14:29:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.18 on epoch=72
06/17/2022 14:29:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.13 on epoch=74
06/17/2022 14:30:00 - INFO - __main__ - Global step 300 Train loss 0.18 Classification-F1 0.7133306012528542 on epoch=74
06/17/2022 14:30:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7116014791209453 -> 0.7133306012528542 on epoch=74, global_step=300
06/17/2022 14:30:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=77
06/17/2022 14:30:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.17 on epoch=79
06/17/2022 14:30:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.11 on epoch=82
06/17/2022 14:30:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/17/2022 14:30:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=87
06/17/2022 14:30:15 - INFO - __main__ - Global step 350 Train loss 0.15 Classification-F1 0.726564956297554 on epoch=87
06/17/2022 14:30:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7133306012528542 -> 0.726564956297554 on epoch=87, global_step=350
06/17/2022 14:30:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.10 on epoch=89
06/17/2022 14:30:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.10 on epoch=92
06/17/2022 14:30:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/17/2022 14:30:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=97
06/17/2022 14:30:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=99
06/17/2022 14:30:29 - INFO - __main__ - Global step 400 Train loss 0.13 Classification-F1 0.7010448916408669 on epoch=99
06/17/2022 14:30:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.07 on epoch=102
06/17/2022 14:30:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=104
06/17/2022 14:30:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=107
06/17/2022 14:30:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=109
06/17/2022 14:30:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.06 on epoch=112
06/17/2022 14:30:44 - INFO - __main__ - Global step 450 Train loss 0.07 Classification-F1 0.7158750615973617 on epoch=112
06/17/2022 14:30:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=114
06/17/2022 14:30:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.05 on epoch=117
06/17/2022 14:30:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/17/2022 14:30:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.06 on epoch=122
06/17/2022 14:30:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=124
06/17/2022 14:30:58 - INFO - __main__ - Global step 500 Train loss 0.06 Classification-F1 0.7086467586467586 on epoch=124
06/17/2022 14:31:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.03 on epoch=127
06/17/2022 14:31:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=129
06/17/2022 14:31:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=132
06/17/2022 14:31:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=134
06/17/2022 14:31:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/17/2022 14:31:13 - INFO - __main__ - Global step 550 Train loss 0.04 Classification-F1 0.756251089799477 on epoch=137
06/17/2022 14:31:13 - INFO - __main__ - Saving model with best Classification-F1: 0.726564956297554 -> 0.756251089799477 on epoch=137, global_step=550
06/17/2022 14:31:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=139
06/17/2022 14:31:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=142
06/17/2022 14:31:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=144
06/17/2022 14:31:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
06/17/2022 14:31:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=149
06/17/2022 14:31:28 - INFO - __main__ - Global step 600 Train loss 0.05 Classification-F1 0.6937423609749587 on epoch=149
06/17/2022 14:31:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=152
06/17/2022 14:31:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=154
06/17/2022 14:31:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=157
06/17/2022 14:31:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/17/2022 14:31:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/17/2022 14:31:42 - INFO - __main__ - Global step 650 Train loss 0.03 Classification-F1 0.7412737142338661 on epoch=162
06/17/2022 14:31:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/17/2022 14:31:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/17/2022 14:31:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=169
06/17/2022 14:31:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/17/2022 14:31:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/17/2022 14:31:57 - INFO - __main__ - Global step 700 Train loss 0.02 Classification-F1 0.7010448916408669 on epoch=174
06/17/2022 14:31:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/17/2022 14:32:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/17/2022 14:32:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/17/2022 14:32:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/17/2022 14:32:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=187
06/17/2022 14:32:11 - INFO - __main__ - Global step 750 Train loss 0.01 Classification-F1 0.691980091980092 on epoch=187
06/17/2022 14:32:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/17/2022 14:32:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/17/2022 14:32:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=194
06/17/2022 14:32:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/17/2022 14:32:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=199
06/17/2022 14:32:26 - INFO - __main__ - Global step 800 Train loss 0.02 Classification-F1 0.69409797975163 on epoch=199
06/17/2022 14:32:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=202
06/17/2022 14:32:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/17/2022 14:32:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/17/2022 14:32:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=209
06/17/2022 14:32:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/17/2022 14:32:40 - INFO - __main__ - Global step 850 Train loss 0.01 Classification-F1 0.7168726911054277 on epoch=212
06/17/2022 14:32:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/17/2022 14:32:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/17/2022 14:32:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=219
06/17/2022 14:32:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/17/2022 14:32:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/17/2022 14:32:55 - INFO - __main__ - Global step 900 Train loss 0.01 Classification-F1 0.7160556976413752 on epoch=224
06/17/2022 14:32:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/17/2022 14:33:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/17/2022 14:33:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
06/17/2022 14:33:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=234
06/17/2022 14:33:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/17/2022 14:33:10 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.6698412698412698 on epoch=237
06/17/2022 14:33:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/17/2022 14:33:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/17/2022 14:33:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/17/2022 14:33:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/17/2022 14:33:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/17/2022 14:33:24 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.6937017231134878 on epoch=249
06/17/2022 14:33:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/17/2022 14:33:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 14:33:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/17/2022 14:33:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=259
06/17/2022 14:33:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/17/2022 14:33:39 - INFO - __main__ - Global step 1050 Train loss 0.00 Classification-F1 0.7160556976413752 on epoch=262
06/17/2022 14:33:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/17/2022 14:33:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/17/2022 14:33:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/17/2022 14:33:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/17/2022 14:33:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/17/2022 14:33:53 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.6840996840996841 on epoch=274
06/17/2022 14:33:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/17/2022 14:33:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/17/2022 14:34:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/17/2022 14:34:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 14:34:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/17/2022 14:34:08 - INFO - __main__ - Global step 1150 Train loss 0.00 Classification-F1 0.7310823051312181 on epoch=287
06/17/2022 14:34:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=289
06/17/2022 14:34:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/17/2022 14:34:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/17/2022 14:34:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/17/2022 14:34:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/17/2022 14:34:23 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7301963088408101 on epoch=299
06/17/2022 14:34:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/17/2022 14:34:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/17/2022 14:34:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/17/2022 14:34:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/17/2022 14:34:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 14:34:37 - INFO - __main__ - Global step 1250 Train loss 0.00 Classification-F1 0.723954808632228 on epoch=312
06/17/2022 14:34:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/17/2022 14:34:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/17/2022 14:34:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/17/2022 14:34:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/17/2022 14:34:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/17/2022 14:34:52 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6835233244401326 on epoch=324
06/17/2022 14:34:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/17/2022 14:34:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/17/2022 14:35:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/17/2022 14:35:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/17/2022 14:35:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/17/2022 14:35:07 - INFO - __main__ - Global step 1350 Train loss 0.00 Classification-F1 0.7301071822810954 on epoch=337
06/17/2022 14:35:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/17/2022 14:35:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/17/2022 14:35:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/17/2022 14:35:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 14:35:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/17/2022 14:35:21 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6682475419317525 on epoch=349
06/17/2022 14:35:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/17/2022 14:35:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/17/2022 14:35:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 14:35:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 14:35:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 14:35:36 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6937950937950937 on epoch=362
06/17/2022 14:35:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/17/2022 14:35:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 14:35:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 14:35:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/17/2022 14:35:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 14:35:51 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.692822966507177 on epoch=374
06/17/2022 14:35:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/17/2022 14:35:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/17/2022 14:35:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 14:36:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/17/2022 14:36:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 14:36:05 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7445958186447317 on epoch=387
06/17/2022 14:36:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 14:36:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/17/2022 14:36:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/17/2022 14:36:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/17/2022 14:36:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 14:36:20 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7081285831285832 on epoch=399
06/17/2022 14:36:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 14:36:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/17/2022 14:36:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 14:36:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/17/2022 14:36:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/17/2022 14:36:34 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7301071822810954 on epoch=412
06/17/2022 14:36:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 14:36:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 14:36:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 14:36:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 14:36:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 14:36:49 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7160556976413752 on epoch=424
06/17/2022 14:36:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 14:36:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 14:36:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 14:37:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 14:37:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/17/2022 14:37:04 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7150819297558428 on epoch=437
06/17/2022 14:37:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/17/2022 14:37:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 14:37:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 14:37:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/17/2022 14:37:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 14:37:18 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7301822573561705 on epoch=449
06/17/2022 14:37:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 14:37:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 14:37:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/17/2022 14:37:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 14:37:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/17/2022 14:37:33 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6996670029444813 on epoch=462
06/17/2022 14:37:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 14:37:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/17/2022 14:37:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 14:37:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/17/2022 14:37:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 14:37:48 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7301822573561705 on epoch=474
06/17/2022 14:37:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 14:37:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/17/2022 14:37:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 14:37:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 14:38:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 14:38:02 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7301822573561705 on epoch=487
06/17/2022 14:38:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 14:38:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 14:38:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 14:38:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 14:38:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 14:38:17 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7168726911054277 on epoch=499
06/17/2022 14:38:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 14:38:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 14:38:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 14:38:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/17/2022 14:38:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/17/2022 14:38:32 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7301822573561705 on epoch=512
06/17/2022 14:38:34 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 14:38:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 14:38:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 14:38:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 14:38:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/17/2022 14:38:46 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7301822573561705 on epoch=524
06/17/2022 14:38:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 14:38:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 14:38:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/17/2022 14:38:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 14:39:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 14:39:01 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7445958186447317 on epoch=537
06/17/2022 14:39:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 14:39:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 14:39:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 14:39:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 14:39:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 14:39:16 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7445958186447317 on epoch=549
06/17/2022 14:39:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 14:39:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 14:39:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 14:39:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 14:39:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 14:39:30 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7445958186447317 on epoch=562
06/17/2022 14:39:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 14:39:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 14:39:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 14:39:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 14:39:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 14:39:45 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7224631180223285 on epoch=574
06/17/2022 14:39:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 14:39:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 14:39:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/17/2022 14:39:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 14:39:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 14:40:00 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7222601959444065 on epoch=587
06/17/2022 14:40:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 14:40:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 14:40:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 14:40:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 14:40:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 14:40:14 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6984342189934295 on epoch=599
06/17/2022 14:40:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 14:40:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/17/2022 14:40:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 14:40:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 14:40:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 14:40:29 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6984342189934295 on epoch=612
06/17/2022 14:40:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 14:40:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 14:40:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/17/2022 14:40:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/17/2022 14:40:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/17/2022 14:40:43 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6840996840996841 on epoch=624
06/17/2022 14:40:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 14:40:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 14:40:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 14:40:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 14:40:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 14:40:58 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7077532077532078 on epoch=637
06/17/2022 14:41:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 14:41:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 14:41:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 14:41:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 14:41:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/17/2022 14:41:13 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7082877376995024 on epoch=649
06/17/2022 14:41:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/17/2022 14:41:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 14:41:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/17/2022 14:41:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/17/2022 14:41:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 14:41:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6979095465937571 on epoch=662
06/17/2022 14:41:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 14:41:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 14:41:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 14:41:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 14:41:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 14:41:42 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6840996840996841 on epoch=674
06/17/2022 14:41:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 14:41:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 14:41:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 14:41:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/17/2022 14:41:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 14:41:57 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7445958186447317 on epoch=687
06/17/2022 14:41:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 14:42:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 14:42:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 14:42:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 14:42:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 14:42:11 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7093912093912094 on epoch=699
06/17/2022 14:42:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 14:42:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 14:42:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 14:42:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=709
06/17/2022 14:42:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 14:42:26 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7075906120023767 on epoch=712
06/17/2022 14:42:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 14:42:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 14:42:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 14:42:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 14:42:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 14:42:41 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7299445865302643 on epoch=724
06/17/2022 14:42:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 14:42:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 14:42:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/17/2022 14:42:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 14:42:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 14:42:55 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6945187165775402 on epoch=737
06/17/2022 14:42:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 14:43:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 14:43:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/17/2022 14:43:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 14:43:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 14:43:10 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6929770679770679 on epoch=749
06/17/2022 14:43:10 - INFO - __main__ - save last model!
06/17/2022 14:43:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 14:43:10 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 14:43:10 - INFO - __main__ - Printing 3 examples
06/17/2022 14:43:10 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 14:43:10 - INFO - __main__ - ['others']
06/17/2022 14:43:10 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 14:43:10 - INFO - __main__ - ['others']
06/17/2022 14:43:10 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 14:43:10 - INFO - __main__ - ['others']
06/17/2022 14:43:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:43:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:43:11 - INFO - __main__ - Printing 3 examples
06/17/2022 14:43:11 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 14:43:11 - INFO - __main__ - ['others']
06/17/2022 14:43:11 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 14:43:11 - INFO - __main__ - ['others']
06/17/2022 14:43:11 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 14:43:11 - INFO - __main__ - ['others']
06/17/2022 14:43:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:43:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:43:11 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 14:43:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:43:11 - INFO - __main__ - Printing 3 examples
06/17/2022 14:43:11 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 14:43:11 - INFO - __main__ - ['others']
06/17/2022 14:43:11 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 14:43:11 - INFO - __main__ - ['others']
06/17/2022 14:43:11 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 14:43:11 - INFO - __main__ - ['others']
06/17/2022 14:43:11 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:43:11 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:43:11 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 14:43:12 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:43:18 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 14:43:29 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 14:43:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 14:43:30 - INFO - __main__ - Starting training!
06/17/2022 14:45:09 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/17/2022 14:45:09 - INFO - __main__ - Classification-F1 on test data: 0.3228
06/17/2022 14:45:09 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.756251089799477, test_performance=0.32276497722477565
06/17/2022 14:45:09 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/17/2022 14:45:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:45:10 - INFO - __main__ - Printing 3 examples
06/17/2022 14:45:10 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 14:45:10 - INFO - __main__ - ['others']
06/17/2022 14:45:10 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 14:45:10 - INFO - __main__ - ['others']
06/17/2022 14:45:10 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 14:45:10 - INFO - __main__ - ['others']
06/17/2022 14:45:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:45:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:45:10 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 14:45:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 14:45:10 - INFO - __main__ - Printing 3 examples
06/17/2022 14:45:10 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 14:45:10 - INFO - __main__ - ['others']
06/17/2022 14:45:10 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 14:45:10 - INFO - __main__ - ['others']
06/17/2022 14:45:10 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 14:45:10 - INFO - __main__ - ['others']
06/17/2022 14:45:10 - INFO - __main__ - Tokenizing Input ...
06/17/2022 14:45:10 - INFO - __main__ - Tokenizing Output ...
06/17/2022 14:45:10 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 14:45:25 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 14:45:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 14:45:26 - INFO - __main__ - Starting training!
06/17/2022 14:45:29 - INFO - __main__ - Step 10 Global step 10 Train loss 4.10 on epoch=2
06/17/2022 14:45:32 - INFO - __main__ - Step 20 Global step 20 Train loss 2.95 on epoch=4
06/17/2022 14:45:34 - INFO - __main__ - Step 30 Global step 30 Train loss 2.44 on epoch=7
06/17/2022 14:45:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.71 on epoch=9
06/17/2022 14:45:40 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=12
06/17/2022 14:45:41 - INFO - __main__ - Global step 50 Train loss 2.49 Classification-F1 0.24854280510018212 on epoch=12
06/17/2022 14:45:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.24854280510018212 on epoch=12, global_step=50
06/17/2022 14:45:44 - INFO - __main__ - Step 60 Global step 60 Train loss 1.05 on epoch=14
06/17/2022 14:45:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.78 on epoch=17
06/17/2022 14:45:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=19
06/17/2022 14:45:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=22
06/17/2022 14:45:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.71 on epoch=24
06/17/2022 14:45:56 - INFO - __main__ - Global step 100 Train loss 0.82 Classification-F1 0.546706857233173 on epoch=24
06/17/2022 14:45:56 - INFO - __main__ - Saving model with best Classification-F1: 0.24854280510018212 -> 0.546706857233173 on epoch=24, global_step=100
06/17/2022 14:45:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=27
06/17/2022 14:46:01 - INFO - __main__ - Step 120 Global step 120 Train loss 0.53 on epoch=29
06/17/2022 14:46:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=32
06/17/2022 14:46:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.53 on epoch=34
06/17/2022 14:46:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
06/17/2022 14:46:10 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.6328185328185327 on epoch=37
06/17/2022 14:46:10 - INFO - __main__ - Saving model with best Classification-F1: 0.546706857233173 -> 0.6328185328185327 on epoch=37, global_step=150
06/17/2022 14:46:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=39
06/17/2022 14:46:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.54 on epoch=42
06/17/2022 14:46:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
06/17/2022 14:46:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=47
06/17/2022 14:46:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.38 on epoch=49
06/17/2022 14:46:25 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.6722947191697192 on epoch=49
06/17/2022 14:46:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6328185328185327 -> 0.6722947191697192 on epoch=49, global_step=200
06/17/2022 14:46:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=52
06/17/2022 14:46:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=54
06/17/2022 14:46:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=57
06/17/2022 14:46:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=59
06/17/2022 14:46:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=62
06/17/2022 14:46:39 - INFO - __main__ - Global step 250 Train loss 0.33 Classification-F1 0.6933551198257081 on epoch=62
06/17/2022 14:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6722947191697192 -> 0.6933551198257081 on epoch=62, global_step=250
06/17/2022 14:46:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=64
06/17/2022 14:46:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=67
06/17/2022 14:46:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/17/2022 14:46:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/17/2022 14:46:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/17/2022 14:46:54 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.7222983930414272 on epoch=74
06/17/2022 14:46:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6933551198257081 -> 0.7222983930414272 on epoch=74, global_step=300
06/17/2022 14:46:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.15 on epoch=77
06/17/2022 14:46:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=79
06/17/2022 14:47:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/17/2022 14:47:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.15 on epoch=84
06/17/2022 14:47:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=87
06/17/2022 14:47:08 - INFO - __main__ - Global step 350 Train loss 0.17 Classification-F1 0.7087079057667293 on epoch=87
06/17/2022 14:47:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.14 on epoch=89
06/17/2022 14:47:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=92
06/17/2022 14:47:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/17/2022 14:47:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=97
06/17/2022 14:47:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.12 on epoch=99
06/17/2022 14:47:23 - INFO - __main__ - Global step 400 Train loss 0.15 Classification-F1 0.6970408207250313 on epoch=99
06/17/2022 14:47:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=102
06/17/2022 14:47:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.08 on epoch=104
06/17/2022 14:47:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.10 on epoch=107
06/17/2022 14:47:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=109
06/17/2022 14:47:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=112
06/17/2022 14:47:38 - INFO - __main__ - Global step 450 Train loss 0.11 Classification-F1 0.715848870260635 on epoch=112
06/17/2022 14:47:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=114
06/17/2022 14:47:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=117
06/17/2022 14:47:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/17/2022 14:47:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.06 on epoch=122
06/17/2022 14:47:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=124
06/17/2022 14:47:52 - INFO - __main__ - Global step 500 Train loss 0.09 Classification-F1 0.6844272844272844 on epoch=124
06/17/2022 14:47:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=127
06/17/2022 14:47:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=129
06/17/2022 14:48:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=132
06/17/2022 14:48:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=134
06/17/2022 14:48:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=137
06/17/2022 14:48:07 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.7077532077532078 on epoch=137
06/17/2022 14:48:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=139
06/17/2022 14:48:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/17/2022 14:48:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=144
06/17/2022 14:48:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/17/2022 14:48:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/17/2022 14:48:21 - INFO - __main__ - Global step 600 Train loss 0.05 Classification-F1 0.6847540818129053 on epoch=149
06/17/2022 14:48:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=152
06/17/2022 14:48:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/17/2022 14:48:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=157
06/17/2022 14:48:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=159
06/17/2022 14:48:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=162
06/17/2022 14:48:36 - INFO - __main__ - Global step 650 Train loss 0.03 Classification-F1 0.722166769041769 on epoch=162
06/17/2022 14:48:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
06/17/2022 14:48:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=167
06/17/2022 14:48:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/17/2022 14:48:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=172
06/17/2022 14:48:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/17/2022 14:48:50 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.7077532077532078 on epoch=174
06/17/2022 14:48:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/17/2022 14:48:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/17/2022 14:48:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/17/2022 14:49:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/17/2022 14:49:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/17/2022 14:49:05 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.7075155369273016 on epoch=187
06/17/2022 14:49:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/17/2022 14:49:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/17/2022 14:49:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/17/2022 14:49:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/17/2022 14:49:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/17/2022 14:49:19 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.7083732057416268 on epoch=199
06/17/2022 14:49:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/17/2022 14:49:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/17/2022 14:49:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/17/2022 14:49:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/17/2022 14:49:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/17/2022 14:49:34 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.7222214192802427 on epoch=212
06/17/2022 14:49:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/17/2022 14:49:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/17/2022 14:49:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/17/2022 14:49:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/17/2022 14:49:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/17/2022 14:49:48 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.7072558744884722 on epoch=224
06/17/2022 14:49:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/17/2022 14:49:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/17/2022 14:49:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/17/2022 14:49:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/17/2022 14:50:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/17/2022 14:50:03 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.6847540818129053 on epoch=237
06/17/2022 14:50:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/17/2022 14:50:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=242
06/17/2022 14:50:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/17/2022 14:50:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/17/2022 14:50:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/17/2022 14:50:17 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.7072558744884722 on epoch=249
06/17/2022 14:50:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/17/2022 14:50:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/17/2022 14:50:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/17/2022 14:50:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/17/2022 14:50:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/17/2022 14:50:32 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.6929492291334396 on epoch=262
06/17/2022 14:50:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/17/2022 14:50:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/17/2022 14:50:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/17/2022 14:50:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/17/2022 14:50:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/17/2022 14:50:47 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7209880762512342 on epoch=274
06/17/2022 14:50:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/17/2022 14:50:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/17/2022 14:50:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/17/2022 14:50:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/17/2022 14:51:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/17/2022 14:51:01 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7123801220575414 on epoch=287
06/17/2022 14:51:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/17/2022 14:51:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/17/2022 14:51:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/17/2022 14:51:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 14:51:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/17/2022 14:51:16 - INFO - __main__ - Global step 1200 Train loss 0.00 Classification-F1 0.7068381180223285 on epoch=299
06/17/2022 14:51:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/17/2022 14:51:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/17/2022 14:51:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/17/2022 14:51:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/17/2022 14:51:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/17/2022 14:51:30 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7123801220575414 on epoch=312
06/17/2022 14:51:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/17/2022 14:51:36 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/17/2022 14:51:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/17/2022 14:51:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/17/2022 14:51:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/17/2022 14:51:45 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7160556976413752 on epoch=324
06/17/2022 14:51:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/17/2022 14:51:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/17/2022 14:51:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/17/2022 14:51:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/17/2022 14:51:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/17/2022 14:52:00 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7217503217503217 on epoch=337
06/17/2022 14:52:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/17/2022 14:52:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/17/2022 14:52:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/17/2022 14:52:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/17/2022 14:52:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/17/2022 14:52:14 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.708080808080808 on epoch=349
06/17/2022 14:52:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/17/2022 14:52:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/17/2022 14:52:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 14:52:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
06/17/2022 14:52:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 14:52:29 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7352638352638352 on epoch=362
06/17/2022 14:52:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7222983930414272 -> 0.7352638352638352 on epoch=362, global_step=1450
06/17/2022 14:52:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/17/2022 14:52:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/17/2022 14:52:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 14:52:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/17/2022 14:52:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/17/2022 14:52:43 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7355906326494561 on epoch=374
06/17/2022 14:52:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7352638352638352 -> 0.7355906326494561 on epoch=374, global_step=1500
06/17/2022 14:52:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/17/2022 14:52:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/17/2022 14:52:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/17/2022 14:52:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 14:52:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/17/2022 14:52:58 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7201322563164668 on epoch=387
06/17/2022 14:53:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/17/2022 14:53:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 14:53:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 14:53:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/17/2022 14:53:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/17/2022 14:53:13 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7574027464919306 on epoch=399
06/17/2022 14:53:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7355906326494561 -> 0.7574027464919306 on epoch=399, global_step=1600
06/17/2022 14:53:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 14:53:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 14:53:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/17/2022 14:53:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 14:53:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 14:53:27 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7068381180223285 on epoch=412
06/17/2022 14:53:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/17/2022 14:53:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 14:53:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/17/2022 14:53:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/17/2022 14:53:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 14:53:42 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7083680518463128 on epoch=424
06/17/2022 14:53:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/17/2022 14:53:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/17/2022 14:53:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/17/2022 14:53:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/17/2022 14:53:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/17/2022 14:53:56 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7357142857142857 on epoch=437
06/17/2022 14:53:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 14:54:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/17/2022 14:54:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/17/2022 14:54:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 14:54:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 14:54:11 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7158488702606349 on epoch=449
06/17/2022 14:54:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/17/2022 14:54:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/17/2022 14:54:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/17/2022 14:54:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 14:54:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 14:54:25 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.692822966507177 on epoch=462
06/17/2022 14:54:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 14:54:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/17/2022 14:54:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 14:54:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 14:54:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/17/2022 14:54:40 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7427101760718059 on epoch=474
06/17/2022 14:54:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/17/2022 14:54:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/17/2022 14:54:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 14:54:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/17/2022 14:54:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 14:54:55 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7368705855547961 on epoch=487
06/17/2022 14:54:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 14:55:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 14:55:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 14:55:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 14:55:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/17/2022 14:55:09 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7306998556998557 on epoch=499
06/17/2022 14:55:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=502
06/17/2022 14:55:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 14:55:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 14:55:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 14:55:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 14:55:24 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7361111111111112 on epoch=512
06/17/2022 14:55:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 14:55:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/17/2022 14:55:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 14:55:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 14:55:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/17/2022 14:55:38 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7361111111111112 on epoch=524
06/17/2022 14:55:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 14:55:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 14:55:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 14:55:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 14:55:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 14:55:53 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7212601256718904 on epoch=537
06/17/2022 14:55:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 14:55:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 14:56:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 14:56:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/17/2022 14:56:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 14:56:08 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7368705855547961 on epoch=549
06/17/2022 14:56:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 14:56:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 14:56:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 14:56:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/17/2022 14:56:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/17/2022 14:56:22 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7025252525252526 on epoch=562
06/17/2022 14:56:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/17/2022 14:56:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/17/2022 14:56:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 14:56:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 14:56:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 14:56:37 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7446969696969697 on epoch=574
06/17/2022 14:56:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 14:56:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 14:56:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 14:56:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 14:56:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 14:56:52 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.722452494511318 on epoch=587
06/17/2022 14:56:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 14:56:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 14:57:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 14:57:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 14:57:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 14:57:07 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7445285239402887 on epoch=599
06/17/2022 14:57:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/17/2022 14:57:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 14:57:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 14:57:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/17/2022 14:57:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 14:57:22 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7214285714285714 on epoch=612
06/17/2022 14:57:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 14:57:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 14:57:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/17/2022 14:57:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/17/2022 14:57:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/17/2022 14:57:36 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.722452494511318 on epoch=624
06/17/2022 14:57:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/17/2022 14:57:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 14:57:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 14:57:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 14:57:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 14:57:51 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7361111111111112 on epoch=637
06/17/2022 14:57:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 14:57:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 14:57:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 14:58:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/17/2022 14:58:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 14:58:06 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7495495495495496 on epoch=649
06/17/2022 14:58:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 14:58:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 14:58:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 14:58:16 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 14:58:19 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 14:58:20 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7368705855547961 on epoch=662
06/17/2022 14:58:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 14:58:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 14:58:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 14:58:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 14:58:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 14:58:35 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.745093795093795 on epoch=674
06/17/2022 14:58:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/17/2022 14:58:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 14:58:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 14:58:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 14:58:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 14:58:50 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.745093795093795 on epoch=687
06/17/2022 14:58:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 14:58:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 14:58:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 14:59:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 14:59:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 14:59:04 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.758982683982684 on epoch=699
06/17/2022 14:59:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7574027464919306 -> 0.758982683982684 on epoch=699, global_step=2800
06/17/2022 14:59:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 14:59:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 14:59:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/17/2022 14:59:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 14:59:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/17/2022 14:59:19 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7593795093795094 on epoch=712
06/17/2022 14:59:19 - INFO - __main__ - Saving model with best Classification-F1: 0.758982683982684 -> 0.7593795093795094 on epoch=712, global_step=2850
06/17/2022 14:59:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 14:59:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/17/2022 14:59:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 14:59:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 14:59:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 14:59:34 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.758982683982684 on epoch=724
06/17/2022 14:59:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 14:59:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.09 on epoch=729
06/17/2022 14:59:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=732
06/17/2022 14:59:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 14:59:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 14:59:49 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.745093795093795 on epoch=737
06/17/2022 14:59:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 14:59:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/17/2022 14:59:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 14:59:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 15:00:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 15:00:03 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7457208927797163 on epoch=749
06/17/2022 15:00:03 - INFO - __main__ - save last model!
06/17/2022 15:00:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:00:03 - INFO - __main__ - Printing 3 examples
06/17/2022 15:00:03 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:00:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 15:00:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:00:03 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 15:00:03 - INFO - __main__ - Printing 3 examples
06/17/2022 15:00:03 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:00:03 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 15:00:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:00:03 - INFO - __main__ - Printing 3 examples
06/17/2022 15:00:03 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 15:00:03 - INFO - __main__ - ['others']
06/17/2022 15:00:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:00:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:00:04 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 15:00:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:00:11 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 15:00:19 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:00:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 15:00:20 - INFO - __main__ - Starting training!
06/17/2022 15:02:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/17/2022 15:02:01 - INFO - __main__ - Classification-F1 on test data: 0.3930
06/17/2022 15:02:02 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.7593795093795094, test_performance=0.3930079064598799
06/17/2022 15:02:02 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/17/2022 15:02:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:02:03 - INFO - __main__ - Printing 3 examples
06/17/2022 15:02:03 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 15:02:03 - INFO - __main__ - ['others']
06/17/2022 15:02:03 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 15:02:03 - INFO - __main__ - ['others']
06/17/2022 15:02:03 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 15:02:03 - INFO - __main__ - ['others']
06/17/2022 15:02:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:02:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:02:03 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 15:02:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:02:03 - INFO - __main__ - Printing 3 examples
06/17/2022 15:02:03 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 15:02:03 - INFO - __main__ - ['others']
06/17/2022 15:02:03 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 15:02:03 - INFO - __main__ - ['others']
06/17/2022 15:02:03 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 15:02:03 - INFO - __main__ - ['others']
06/17/2022 15:02:03 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:02:03 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:02:03 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 15:02:18 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:02:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 15:02:18 - INFO - __main__ - Starting training!
06/17/2022 15:02:22 - INFO - __main__ - Step 10 Global step 10 Train loss 4.45 on epoch=2
06/17/2022 15:02:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.37 on epoch=4
06/17/2022 15:02:27 - INFO - __main__ - Step 30 Global step 30 Train loss 2.69 on epoch=7
06/17/2022 15:02:30 - INFO - __main__ - Step 40 Global step 40 Train loss 2.20 on epoch=9
06/17/2022 15:02:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.86 on epoch=12
06/17/2022 15:02:34 - INFO - __main__ - Global step 50 Train loss 2.91 Classification-F1 0.08861465332053567 on epoch=12
06/17/2022 15:02:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08861465332053567 on epoch=12, global_step=50
06/17/2022 15:02:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=14
06/17/2022 15:02:39 - INFO - __main__ - Step 70 Global step 70 Train loss 1.27 on epoch=17
06/17/2022 15:02:42 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=19
06/17/2022 15:02:45 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=22
06/17/2022 15:02:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.77 on epoch=24
06/17/2022 15:02:48 - INFO - __main__ - Global step 100 Train loss 1.04 Classification-F1 0.5773164528969483 on epoch=24
06/17/2022 15:02:48 - INFO - __main__ - Saving model with best Classification-F1: 0.08861465332053567 -> 0.5773164528969483 on epoch=24, global_step=100
06/17/2022 15:02:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.73 on epoch=27
06/17/2022 15:02:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=29
06/17/2022 15:02:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=32
06/17/2022 15:02:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.64 on epoch=34
06/17/2022 15:03:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.62 on epoch=37
06/17/2022 15:03:03 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.6169358382773017 on epoch=37
06/17/2022 15:03:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5773164528969483 -> 0.6169358382773017 on epoch=37, global_step=150
06/17/2022 15:03:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
06/17/2022 15:03:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=42
06/17/2022 15:03:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.54 on epoch=44
06/17/2022 15:03:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=47
06/17/2022 15:03:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=49
06/17/2022 15:03:17 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.645066605720256 on epoch=49
06/17/2022 15:03:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6169358382773017 -> 0.645066605720256 on epoch=49, global_step=200
06/17/2022 15:03:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=52
06/17/2022 15:03:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.43 on epoch=54
06/17/2022 15:03:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=57
06/17/2022 15:03:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/17/2022 15:03:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=62
06/17/2022 15:03:32 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.6806653491436101 on epoch=62
06/17/2022 15:03:32 - INFO - __main__ - Saving model with best Classification-F1: 0.645066605720256 -> 0.6806653491436101 on epoch=62, global_step=250
06/17/2022 15:03:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
06/17/2022 15:03:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=67
06/17/2022 15:03:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=69
06/17/2022 15:03:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=72
06/17/2022 15:03:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=74
06/17/2022 15:03:46 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.6575015747341724 on epoch=74
06/17/2022 15:03:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=77
06/17/2022 15:03:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=79
06/17/2022 15:03:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/17/2022 15:03:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=84
06/17/2022 15:03:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/17/2022 15:04:00 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.6871838415956062 on epoch=87
06/17/2022 15:04:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6806653491436101 -> 0.6871838415956062 on epoch=87, global_step=350
06/17/2022 15:04:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/17/2022 15:04:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/17/2022 15:04:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/17/2022 15:04:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=97
06/17/2022 15:04:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/17/2022 15:04:15 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.7021820207304078 on epoch=99
06/17/2022 15:04:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6871838415956062 -> 0.7021820207304078 on epoch=99, global_step=400
06/17/2022 15:04:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/17/2022 15:04:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=104
06/17/2022 15:04:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/17/2022 15:04:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=109
06/17/2022 15:04:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=112
06/17/2022 15:04:29 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.7021668087524864 on epoch=112
06/17/2022 15:04:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/17/2022 15:04:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
06/17/2022 15:04:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=119
06/17/2022 15:04:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=122
06/17/2022 15:04:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=124
06/17/2022 15:04:44 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.6937017231134878 on epoch=124
06/17/2022 15:04:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=127
06/17/2022 15:04:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=129
06/17/2022 15:04:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=132
06/17/2022 15:04:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=134
06/17/2022 15:04:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/17/2022 15:04:58 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.6937017231134878 on epoch=137
06/17/2022 15:05:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/17/2022 15:05:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=142
06/17/2022 15:05:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=144
06/17/2022 15:05:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
06/17/2022 15:05:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/17/2022 15:05:13 - INFO - __main__ - Global step 600 Train loss 0.06 Classification-F1 0.6800308529208785 on epoch=149
06/17/2022 15:05:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/17/2022 15:05:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/17/2022 15:05:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=157
06/17/2022 15:05:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=159
06/17/2022 15:05:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=162
06/17/2022 15:05:27 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.701797385620915 on epoch=162
06/17/2022 15:05:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=164
06/17/2022 15:05:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/17/2022 15:05:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/17/2022 15:05:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/17/2022 15:05:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/17/2022 15:05:42 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7021284271284272 on epoch=174
06/17/2022 15:05:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/17/2022 15:05:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/17/2022 15:05:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/17/2022 15:05:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
06/17/2022 15:05:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/17/2022 15:05:57 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.6937950937950937 on epoch=187
06/17/2022 15:05:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/17/2022 15:06:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/17/2022 15:06:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/17/2022 15:06:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/17/2022 15:06:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/17/2022 15:06:11 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.6937950937950937 on epoch=199
06/17/2022 15:06:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/17/2022 15:06:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/17/2022 15:06:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/17/2022 15:06:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/17/2022 15:06:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/17/2022 15:06:27 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.6792961410608469 on epoch=212
06/17/2022 15:06:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/17/2022 15:06:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/17/2022 15:06:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/17/2022 15:06:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/17/2022 15:06:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/17/2022 15:06:42 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6792961410608469 on epoch=224
06/17/2022 15:06:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/17/2022 15:06:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/17/2022 15:06:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=232
06/17/2022 15:06:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/17/2022 15:06:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/17/2022 15:06:57 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.6792961410608469 on epoch=237
06/17/2022 15:06:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/17/2022 15:07:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/17/2022 15:07:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/17/2022 15:07:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/17/2022 15:07:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/17/2022 15:07:12 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.679088179088179 on epoch=249
06/17/2022 15:07:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/17/2022 15:07:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/17/2022 15:07:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/17/2022 15:07:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/17/2022 15:07:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/17/2022 15:07:27 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6792961410608469 on epoch=262
06/17/2022 15:07:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/17/2022 15:07:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/17/2022 15:07:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/17/2022 15:07:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/17/2022 15:07:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/17/2022 15:07:42 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.6792961410608469 on epoch=274
06/17/2022 15:07:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/17/2022 15:07:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/17/2022 15:07:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/17/2022 15:07:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/17/2022 15:07:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/17/2022 15:07:56 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7019769129743554 on epoch=287
06/17/2022 15:07:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/17/2022 15:08:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/17/2022 15:08:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/17/2022 15:08:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/17/2022 15:08:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/17/2022 15:08:11 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7019769129743554 on epoch=299
06/17/2022 15:08:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/17/2022 15:08:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/17/2022 15:08:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/17/2022 15:08:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/17/2022 15:08:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/17/2022 15:08:26 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7074390968508615 on epoch=312
06/17/2022 15:08:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7021820207304078 -> 0.7074390968508615 on epoch=312, global_step=1250
06/17/2022 15:08:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/17/2022 15:08:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/17/2022 15:08:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/17/2022 15:08:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/17/2022 15:08:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/17/2022 15:08:41 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6655319001866316 on epoch=324
06/17/2022 15:08:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/17/2022 15:08:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/17/2022 15:08:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/17/2022 15:08:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/17/2022 15:08:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/17/2022 15:08:56 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6876294743941803 on epoch=337
06/17/2022 15:08:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/17/2022 15:09:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/17/2022 15:09:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/17/2022 15:09:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/17/2022 15:09:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/17/2022 15:09:10 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7011562998405103 on epoch=349
06/17/2022 15:09:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/17/2022 15:09:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/17/2022 15:09:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/17/2022 15:09:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/17/2022 15:09:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/17/2022 15:09:25 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7155037384206854 on epoch=362
06/17/2022 15:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7074390968508615 -> 0.7155037384206854 on epoch=362, global_step=1450
06/17/2022 15:09:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 15:09:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/17/2022 15:09:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/17/2022 15:09:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/17/2022 15:09:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/17/2022 15:09:40 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7019769129743554 on epoch=374
06/17/2022 15:09:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 15:09:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/17/2022 15:09:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/17/2022 15:09:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/17/2022 15:09:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/17/2022 15:09:55 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7019769129743554 on epoch=387
06/17/2022 15:09:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/17/2022 15:10:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 15:10:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/17/2022 15:10:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/17/2022 15:10:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 15:10:09 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7087847774244833 on epoch=399
06/17/2022 15:10:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 15:10:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/17/2022 15:10:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/17/2022 15:10:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/17/2022 15:10:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/17/2022 15:10:24 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.6937950937950937 on epoch=412
06/17/2022 15:10:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/17/2022 15:10:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/17/2022 15:10:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/17/2022 15:10:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=422
06/17/2022 15:10:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/17/2022 15:10:39 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7307615799943166 on epoch=424
06/17/2022 15:10:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7155037384206854 -> 0.7307615799943166 on epoch=424, global_step=1700
06/17/2022 15:10:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/17/2022 15:10:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/17/2022 15:10:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/17/2022 15:10:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/17/2022 15:10:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/17/2022 15:10:54 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7021284271284272 on epoch=437
06/17/2022 15:10:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/17/2022 15:10:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/17/2022 15:11:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/17/2022 15:11:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/17/2022 15:11:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/17/2022 15:11:09 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7375694444444444 on epoch=449
06/17/2022 15:11:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7307615799943166 -> 0.7375694444444444 on epoch=449, global_step=1800
06/17/2022 15:11:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/17/2022 15:11:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/17/2022 15:11:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/17/2022 15:11:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/17/2022 15:11:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 15:11:23 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7232837301587302 on epoch=462
06/17/2022 15:11:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/17/2022 15:11:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/17/2022 15:11:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/17/2022 15:11:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/17/2022 15:11:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/17/2022 15:11:38 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7236143228790288 on epoch=474
06/17/2022 15:11:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/17/2022 15:11:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/17/2022 15:11:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/17/2022 15:11:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/17/2022 15:11:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 15:11:53 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7019769129743554 on epoch=487
06/17/2022 15:11:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 15:11:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 15:12:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/17/2022 15:12:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/17/2022 15:12:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/17/2022 15:12:08 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7019769129743554 on epoch=499
06/17/2022 15:12:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/17/2022 15:12:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 15:12:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/17/2022 15:12:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/17/2022 15:12:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 15:12:23 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7155037384206854 on epoch=512
06/17/2022 15:12:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/17/2022 15:12:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/17/2022 15:12:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 15:12:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/17/2022 15:12:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/17/2022 15:12:37 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7307615799943166 on epoch=524
06/17/2022 15:12:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/17/2022 15:12:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/17/2022 15:12:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 15:12:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/17/2022 15:12:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/17/2022 15:12:52 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7523989898989899 on epoch=537
06/17/2022 15:12:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7375694444444444 -> 0.7523989898989899 on epoch=537, global_step=2150
06/17/2022 15:12:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/17/2022 15:12:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/17/2022 15:13:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/17/2022 15:13:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/17/2022 15:13:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/17/2022 15:13:07 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7307615799943166 on epoch=549
06/17/2022 15:13:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 15:13:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 15:13:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 15:13:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 15:13:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/17/2022 15:13:22 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6792961410608469 on epoch=562
06/17/2022 15:13:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=564
06/17/2022 15:13:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 15:13:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/17/2022 15:13:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 15:13:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/17/2022 15:13:37 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7019769129743554 on epoch=574
06/17/2022 15:13:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/17/2022 15:13:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/17/2022 15:13:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 15:13:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/17/2022 15:13:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/17/2022 15:13:52 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6792961410608469 on epoch=587
06/17/2022 15:13:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 15:13:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/17/2022 15:14:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 15:14:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/17/2022 15:14:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 15:14:06 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7164758657086023 on epoch=599
06/17/2022 15:14:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/17/2022 15:14:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 15:14:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/17/2022 15:14:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/17/2022 15:14:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/17/2022 15:14:21 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7307615799943166 on epoch=612
06/17/2022 15:14:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/17/2022 15:14:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 15:14:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/17/2022 15:14:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/17/2022 15:14:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/17/2022 15:14:36 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7307615799943166 on epoch=624
06/17/2022 15:14:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/17/2022 15:14:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/17/2022 15:14:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/17/2022 15:14:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 15:14:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/17/2022 15:14:51 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7087847774244833 on epoch=637
06/17/2022 15:14:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 15:14:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/17/2022 15:14:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/17/2022 15:15:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 15:15:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/17/2022 15:15:06 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6876294743941803 on epoch=649
06/17/2022 15:15:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/17/2022 15:15:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/17/2022 15:15:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 15:15:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 15:15:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 15:15:21 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6792961410608469 on epoch=662
06/17/2022 15:15:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 15:15:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/17/2022 15:15:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/17/2022 15:15:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 15:15:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 15:15:36 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6800308529208785 on epoch=674
06/17/2022 15:15:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=677
06/17/2022 15:15:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/17/2022 15:15:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/17/2022 15:15:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 15:15:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/17/2022 15:15:51 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7158488702606349 on epoch=687
06/17/2022 15:15:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 15:15:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/17/2022 15:15:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/17/2022 15:16:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 15:16:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 15:16:06 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6790587256329617 on epoch=699
06/17/2022 15:16:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/17/2022 15:16:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/17/2022 15:16:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/17/2022 15:16:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/17/2022 15:16:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 15:16:21 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6937950937950937 on epoch=712
06/17/2022 15:16:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 15:16:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 15:16:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 15:16:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/17/2022 15:16:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
06/17/2022 15:16:35 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.692822966507177 on epoch=724
06/17/2022 15:16:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 15:16:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 15:16:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 15:16:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 15:16:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 15:16:50 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7087847774244833 on epoch=737
06/17/2022 15:16:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/17/2022 15:16:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/17/2022 15:16:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/17/2022 15:17:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 15:17:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/17/2022 15:17:05 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7223116028708133 on epoch=749
06/17/2022 15:17:05 - INFO - __main__ - save last model!
06/17/2022 15:17:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 15:17:05 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 15:17:05 - INFO - __main__ - Printing 3 examples
06/17/2022 15:17:05 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:17:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:17:05 - INFO - __main__ - Printing 3 examples
06/17/2022 15:17:05 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:17:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:17:05 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 15:17:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:17:05 - INFO - __main__ - Printing 3 examples
06/17/2022 15:17:05 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 15:17:05 - INFO - __main__ - ['others']
06/17/2022 15:17:05 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:17:05 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:17:05 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 15:17:07 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:17:13 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 15:17:21 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:17:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 15:17:22 - INFO - __main__ - Starting training!
06/17/2022 15:19:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/17/2022 15:19:01 - INFO - __main__ - Classification-F1 on test data: 0.3470
06/17/2022 15:19:01 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.7523989898989899, test_performance=0.3470384292833085
06/17/2022 15:19:01 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/17/2022 15:19:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:19:02 - INFO - __main__ - Printing 3 examples
06/17/2022 15:19:02 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/17/2022 15:19:02 - INFO - __main__ - ['others']
06/17/2022 15:19:02 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/17/2022 15:19:02 - INFO - __main__ - ['others']
06/17/2022 15:19:02 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/17/2022 15:19:02 - INFO - __main__ - ['others']
06/17/2022 15:19:02 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:19:02 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:19:02 - INFO - __main__ - Loaded 64 examples from train data
06/17/2022 15:19:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/17/2022 15:19:02 - INFO - __main__ - Printing 3 examples
06/17/2022 15:19:02 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/17/2022 15:19:02 - INFO - __main__ - ['others']
06/17/2022 15:19:02 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/17/2022 15:19:02 - INFO - __main__ - ['others']
06/17/2022 15:19:02 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/17/2022 15:19:02 - INFO - __main__ - ['others']
06/17/2022 15:19:02 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:19:02 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:19:02 - INFO - __main__ - Loaded 64 examples from dev data
06/17/2022 15:19:17 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:19:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 15:19:18 - INFO - __main__ - Starting training!
06/17/2022 15:19:21 - INFO - __main__ - Step 10 Global step 10 Train loss 4.55 on epoch=2
06/17/2022 15:19:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.64 on epoch=4
06/17/2022 15:19:27 - INFO - __main__ - Step 30 Global step 30 Train loss 3.36 on epoch=7
06/17/2022 15:19:30 - INFO - __main__ - Step 40 Global step 40 Train loss 2.58 on epoch=9
06/17/2022 15:19:32 - INFO - __main__ - Step 50 Global step 50 Train loss 2.38 on epoch=12
06/17/2022 15:19:34 - INFO - __main__ - Global step 50 Train loss 3.30 Classification-F1 0.024819574018658683 on epoch=12
06/17/2022 15:19:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.024819574018658683 on epoch=12, global_step=50
06/17/2022 15:19:37 - INFO - __main__ - Step 60 Global step 60 Train loss 2.03 on epoch=14
06/17/2022 15:19:39 - INFO - __main__ - Step 70 Global step 70 Train loss 1.78 on epoch=17
06/17/2022 15:19:42 - INFO - __main__ - Step 80 Global step 80 Train loss 1.54 on epoch=19
06/17/2022 15:19:45 - INFO - __main__ - Step 90 Global step 90 Train loss 1.23 on epoch=22
06/17/2022 15:19:47 - INFO - __main__ - Step 100 Global step 100 Train loss 1.21 on epoch=24
06/17/2022 15:19:49 - INFO - __main__ - Global step 100 Train loss 1.56 Classification-F1 0.23919693379116894 on epoch=24
06/17/2022 15:19:49 - INFO - __main__ - Saving model with best Classification-F1: 0.024819574018658683 -> 0.23919693379116894 on epoch=24, global_step=100
06/17/2022 15:19:51 - INFO - __main__ - Step 110 Global step 110 Train loss 1.05 on epoch=27
06/17/2022 15:19:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=29
06/17/2022 15:19:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.88 on epoch=32
06/17/2022 15:19:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=34
06/17/2022 15:20:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.66 on epoch=37
06/17/2022 15:20:03 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.47448377169739403 on epoch=37
06/17/2022 15:20:03 - INFO - __main__ - Saving model with best Classification-F1: 0.23919693379116894 -> 0.47448377169739403 on epoch=37, global_step=150
06/17/2022 15:20:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/17/2022 15:20:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=42
06/17/2022 15:20:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=44
06/17/2022 15:20:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=47
06/17/2022 15:20:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=49
06/17/2022 15:20:18 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5857643870556353 on epoch=49
06/17/2022 15:20:18 - INFO - __main__ - Saving model with best Classification-F1: 0.47448377169739403 -> 0.5857643870556353 on epoch=49, global_step=200
06/17/2022 15:20:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=52
06/17/2022 15:20:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.55 on epoch=54
06/17/2022 15:20:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=57
06/17/2022 15:20:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=59
06/17/2022 15:20:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=62
06/17/2022 15:20:32 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.646108367983368 on epoch=62
06/17/2022 15:20:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5857643870556353 -> 0.646108367983368 on epoch=62, global_step=250
06/17/2022 15:20:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=64
06/17/2022 15:20:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
06/17/2022 15:20:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=69
06/17/2022 15:20:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=72
06/17/2022 15:20:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=74
06/17/2022 15:20:47 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.6162698412698413 on epoch=74
06/17/2022 15:20:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=77
06/17/2022 15:20:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=79
06/17/2022 15:20:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=82
06/17/2022 15:20:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=84
06/17/2022 15:21:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=87
06/17/2022 15:21:02 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.6702833638317509 on epoch=87
06/17/2022 15:21:02 - INFO - __main__ - Saving model with best Classification-F1: 0.646108367983368 -> 0.6702833638317509 on epoch=87, global_step=350
06/17/2022 15:21:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=89
06/17/2022 15:21:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=92
06/17/2022 15:21:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/17/2022 15:21:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=97
06/17/2022 15:21:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=99
06/17/2022 15:21:16 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.6942396942396942 on epoch=99
06/17/2022 15:21:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6702833638317509 -> 0.6942396942396942 on epoch=99, global_step=400
06/17/2022 15:21:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=102
06/17/2022 15:21:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=104
06/17/2022 15:21:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=107
06/17/2022 15:21:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=109
06/17/2022 15:21:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=112
06/17/2022 15:21:31 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.7419923214040861 on epoch=112
06/17/2022 15:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6942396942396942 -> 0.7419923214040861 on epoch=112, global_step=450
06/17/2022 15:21:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
06/17/2022 15:21:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=117
06/17/2022 15:21:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=119
06/17/2022 15:21:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
06/17/2022 15:21:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=124
06/17/2022 15:21:46 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.7575640046228282 on epoch=124
06/17/2022 15:21:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7419923214040861 -> 0.7575640046228282 on epoch=124, global_step=500
06/17/2022 15:21:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/17/2022 15:21:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=129
06/17/2022 15:21:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=132
06/17/2022 15:21:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=134
06/17/2022 15:21:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/17/2022 15:22:00 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.7722698869757694 on epoch=137
06/17/2022 15:22:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7575640046228282 -> 0.7722698869757694 on epoch=137, global_step=550
06/17/2022 15:22:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=139
06/17/2022 15:22:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=142
06/17/2022 15:22:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/17/2022 15:22:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/17/2022 15:22:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/17/2022 15:22:15 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.7714932126696833 on epoch=149
06/17/2022 15:22:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/17/2022 15:22:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/17/2022 15:22:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=157
06/17/2022 15:22:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/17/2022 15:22:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=162
06/17/2022 15:22:29 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.759469696969697 on epoch=162
06/17/2022 15:22:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
06/17/2022 15:22:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/17/2022 15:22:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/17/2022 15:22:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/17/2022 15:22:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/17/2022 15:22:44 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.7899597338935574 on epoch=174
06/17/2022 15:22:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7722698869757694 -> 0.7899597338935574 on epoch=174, global_step=700
06/17/2022 15:22:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/17/2022 15:22:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=179
06/17/2022 15:22:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/17/2022 15:22:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=184
06/17/2022 15:22:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
06/17/2022 15:22:59 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.7712568681318681 on epoch=187
06/17/2022 15:23:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=189
06/17/2022 15:23:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/17/2022 15:23:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=194
06/17/2022 15:23:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=197
06/17/2022 15:23:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=199
06/17/2022 15:23:13 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7608981092436975 on epoch=199
06/17/2022 15:23:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/17/2022 15:23:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/17/2022 15:23:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/17/2022 15:23:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/17/2022 15:23:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/17/2022 15:23:28 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.8052584670231729 on epoch=212
06/17/2022 15:23:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7899597338935574 -> 0.8052584670231729 on epoch=212, global_step=850
06/17/2022 15:23:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/17/2022 15:23:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/17/2022 15:23:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/17/2022 15:23:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
06/17/2022 15:23:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/17/2022 15:23:43 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.775094696969697 on epoch=224
06/17/2022 15:23:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/17/2022 15:23:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=229
06/17/2022 15:23:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/17/2022 15:23:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/17/2022 15:23:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/17/2022 15:23:58 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.765625 on epoch=237
06/17/2022 15:24:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/17/2022 15:24:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/17/2022 15:24:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/17/2022 15:24:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/17/2022 15:24:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/17/2022 15:24:12 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7705368040851913 on epoch=249
06/17/2022 15:24:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/17/2022 15:24:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/17/2022 15:24:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=257
06/17/2022 15:24:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/17/2022 15:24:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=262
06/17/2022 15:24:27 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7365288675772548 on epoch=262
06/17/2022 15:24:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/17/2022 15:24:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/17/2022 15:24:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/17/2022 15:24:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=272
06/17/2022 15:24:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/17/2022 15:24:42 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7712554112554113 on epoch=274
06/17/2022 15:24:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/17/2022 15:24:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/17/2022 15:24:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/17/2022 15:24:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/17/2022 15:24:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/17/2022 15:24:57 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7570588235294118 on epoch=287
06/17/2022 15:24:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/17/2022 15:25:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/17/2022 15:25:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/17/2022 15:25:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/17/2022 15:25:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/17/2022 15:25:11 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7296849240914347 on epoch=299
06/17/2022 15:25:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/17/2022 15:25:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/17/2022 15:25:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/17/2022 15:25:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/17/2022 15:25:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/17/2022 15:25:26 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7153032036613272 on epoch=312
06/17/2022 15:25:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/17/2022 15:25:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/17/2022 15:25:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/17/2022 15:25:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/17/2022 15:25:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/17/2022 15:25:41 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7013498152884341 on epoch=324
06/17/2022 15:25:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/17/2022 15:25:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/17/2022 15:25:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/17/2022 15:25:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/17/2022 15:25:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/17/2022 15:25:56 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7570588235294118 on epoch=337
06/17/2022 15:25:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/17/2022 15:26:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/17/2022 15:26:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/17/2022 15:26:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/17/2022 15:26:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/17/2022 15:26:11 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7307615799943166 on epoch=349
06/17/2022 15:26:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/17/2022 15:26:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/17/2022 15:26:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/17/2022 15:26:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/17/2022 15:26:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/17/2022 15:26:25 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7154573051312181 on epoch=362
06/17/2022 15:26:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/17/2022 15:26:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/17/2022 15:26:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/17/2022 15:26:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/17/2022 15:26:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/17/2022 15:26:40 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7299445865302643 on epoch=374
06/17/2022 15:26:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/17/2022 15:26:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/17/2022 15:26:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/17/2022 15:26:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/17/2022 15:26:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/17/2022 15:26:55 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7299445865302643 on epoch=387
06/17/2022 15:26:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/17/2022 15:27:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/17/2022 15:27:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/17/2022 15:27:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/17/2022 15:27:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/17/2022 15:27:10 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7446504688832054 on epoch=399
06/17/2022 15:27:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/17/2022 15:27:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/17/2022 15:27:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/17/2022 15:27:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/17/2022 15:27:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/17/2022 15:27:25 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7154573051312181 on epoch=412
06/17/2022 15:27:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/17/2022 15:27:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/17/2022 15:27:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/17/2022 15:27:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/17/2022 15:27:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/17/2022 15:27:39 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7299445865302643 on epoch=424
06/17/2022 15:27:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/17/2022 15:27:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/17/2022 15:27:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=432
06/17/2022 15:27:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/17/2022 15:27:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/17/2022 15:27:54 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7520424836601307 on epoch=437
06/17/2022 15:27:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/17/2022 15:27:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/17/2022 15:28:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/17/2022 15:28:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/17/2022 15:28:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/17/2022 15:28:09 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7154573051312181 on epoch=449
06/17/2022 15:28:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/17/2022 15:28:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/17/2022 15:28:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/17/2022 15:28:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/17/2022 15:28:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/17/2022 15:28:24 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7157278679017808 on epoch=462
06/17/2022 15:28:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/17/2022 15:28:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/17/2022 15:28:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/17/2022 15:28:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=472
06/17/2022 15:28:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/17/2022 15:28:39 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7157278679017808 on epoch=474
06/17/2022 15:28:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/17/2022 15:28:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/17/2022 15:28:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/17/2022 15:28:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/17/2022 15:28:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/17/2022 15:28:54 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7304347826086957 on epoch=487
06/17/2022 15:28:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/17/2022 15:28:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/17/2022 15:29:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/17/2022 15:29:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/17/2022 15:29:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/17/2022 15:29:08 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7368082368082368 on epoch=499
06/17/2022 15:29:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/17/2022 15:29:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/17/2022 15:29:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/17/2022 15:29:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/17/2022 15:29:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/17/2022 15:29:23 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7303414119270897 on epoch=512
06/17/2022 15:29:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/17/2022 15:29:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/17/2022 15:29:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/17/2022 15:29:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/17/2022 15:29:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/17/2022 15:29:38 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7157278679017808 on epoch=524
06/17/2022 15:29:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/17/2022 15:29:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/17/2022 15:29:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/17/2022 15:29:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/17/2022 15:29:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/17/2022 15:29:53 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7157278679017808 on epoch=537
06/17/2022 15:29:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/17/2022 15:29:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/17/2022 15:30:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/17/2022 15:30:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/17/2022 15:30:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/17/2022 15:30:08 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7520424836601307 on epoch=549
06/17/2022 15:30:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/17/2022 15:30:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/17/2022 15:30:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/17/2022 15:30:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/17/2022 15:30:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/17/2022 15:30:23 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7295889179470415 on epoch=562
06/17/2022 15:30:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/17/2022 15:30:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/17/2022 15:30:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/17/2022 15:30:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/17/2022 15:30:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/17/2022 15:30:38 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7295889179470415 on epoch=574
06/17/2022 15:30:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/17/2022 15:30:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/17/2022 15:30:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/17/2022 15:30:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/17/2022 15:30:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/17/2022 15:30:52 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7299445865302643 on epoch=587
06/17/2022 15:30:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/17/2022 15:30:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/17/2022 15:31:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/17/2022 15:31:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/17/2022 15:31:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/17/2022 15:31:07 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7303414119270897 on epoch=599
06/17/2022 15:31:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/17/2022 15:31:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/17/2022 15:31:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/17/2022 15:31:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/17/2022 15:31:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/17/2022 15:31:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7299445865302643 on epoch=612
06/17/2022 15:31:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/17/2022 15:31:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/17/2022 15:31:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/17/2022 15:31:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/17/2022 15:31:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/17/2022 15:31:37 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6994569297558428 on epoch=624
06/17/2022 15:31:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/17/2022 15:31:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/17/2022 15:31:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/17/2022 15:31:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/17/2022 15:31:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/17/2022 15:31:52 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7303414119270897 on epoch=637
06/17/2022 15:31:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/17/2022 15:31:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/17/2022 15:32:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/17/2022 15:32:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/17/2022 15:32:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/17/2022 15:32:07 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7520424836601307 on epoch=649
06/17/2022 15:32:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/17/2022 15:32:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
06/17/2022 15:32:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/17/2022 15:32:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/17/2022 15:32:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/17/2022 15:32:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7157278679017808 on epoch=662
06/17/2022 15:32:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/17/2022 15:32:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/17/2022 15:32:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/17/2022 15:32:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/17/2022 15:32:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/17/2022 15:32:37 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7374289396348219 on epoch=674
06/17/2022 15:32:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/17/2022 15:32:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=679
06/17/2022 15:32:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/17/2022 15:32:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/17/2022 15:32:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/17/2022 15:32:51 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7152387041773232 on epoch=687
06/17/2022 15:32:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/17/2022 15:32:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/17/2022 15:33:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=694
06/17/2022 15:33:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/17/2022 15:33:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/17/2022 15:33:06 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6998041519780651 on epoch=699
06/17/2022 15:33:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/17/2022 15:33:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/17/2022 15:33:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/17/2022 15:33:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/17/2022 15:33:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/17/2022 15:33:21 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7295889179470415 on epoch=712
06/17/2022 15:33:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/17/2022 15:33:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/17/2022 15:33:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/17/2022 15:33:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/17/2022 15:33:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/17/2022 15:33:36 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7295889179470415 on epoch=724
06/17/2022 15:33:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/17/2022 15:33:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/17/2022 15:33:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/17/2022 15:33:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/17/2022 15:33:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/17/2022 15:33:51 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7450472942800308 on epoch=737
06/17/2022 15:33:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/17/2022 15:33:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=742
06/17/2022 15:33:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/17/2022 15:34:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/17/2022 15:34:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/17/2022 15:34:06 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7303647545974912 on epoch=749
06/17/2022 15:34:06 - INFO - __main__ - save last model!
06/17/2022 15:34:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/17/2022 15:34:06 - INFO - __main__ - Start tokenizing ... 5509 instances
06/17/2022 15:34:06 - INFO - __main__ - Printing 3 examples
06/17/2022 15:34:06 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/17/2022 15:34:06 - INFO - __main__ - ['others']
06/17/2022 15:34:06 - INFO - __main__ -  [emo] what you like very little things ok
06/17/2022 15:34:06 - INFO - __main__ - ['others']
06/17/2022 15:34:06 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/17/2022 15:34:06 - INFO - __main__ - ['others']
06/17/2022 15:34:06 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:34:08 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:34:14 - INFO - __main__ - Loaded 5509 examples from test data
06/17/2022 15:36:04 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/17/2022 15:36:04 - INFO - __main__ - Classification-F1 on test data: 0.2679
06/17/2022 15:36:04 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.8052584670231729, test_performance=0.26790991299223693
