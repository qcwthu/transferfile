05/15/2022 18:58:18 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-maml-nopara2para-3e-5-2-5000-5e-1', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/glue-qqp/', task_name='glue-qqp', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
05/15/2022 18:58:18 - INFO - __main__ - models/T5-large-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp
06/24/2022 20:05:15 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-maml-nopara2para-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-nopara2para-3e-5-2-5000-5e-1-t5base/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
06/24/2022 20:05:15 - INFO - __main__ - models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp
06/24/2022 20:05:15 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-maml-nopara2para-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-nopara2para-3e-5-2-5000-5e-1-t5base/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
06/24/2022 20:05:15 - INFO - __main__ - models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp
06/24/2022 20:05:16 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/24/2022 20:05:16 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/24/2022 20:05:16 - INFO - __main__ - args.device: cuda:0
06/24/2022 20:05:16 - INFO - __main__ - args.device: cuda:1
06/24/2022 20:05:16 - INFO - __main__ - Using 2 gpus
06/24/2022 20:05:16 - INFO - __main__ - Using 2 gpus
06/24/2022 20:05:16 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/24/2022 20:05:16 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/24/2022 20:05:21 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.5, bsz=8 ...
06/24/2022 20:05:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:05:22 - INFO - __main__ - Printing 3 examples
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:05:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:05:22 - INFO - __main__ - Printing 3 examples
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:05:22 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:05:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:05:22 - INFO - __main__ - Printing 3 examples
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:05:22 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:05:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:05:22 - INFO - __main__ - Printing 3 examples
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:05:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:05:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:05:22 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:05:22 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:05:28 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:05:28 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:05:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:05:28 - INFO - __main__ - Starting training!
06/24/2022 20:05:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:05:33 - INFO - __main__ - Starting training!
06/24/2022 20:05:35 - INFO - __main__ - Step 10 Global step 10 Train loss 6.23 on epoch=4
06/24/2022 20:05:36 - INFO - __main__ - Step 20 Global step 20 Train loss 6.05 on epoch=9
06/24/2022 20:05:37 - INFO - __main__ - Step 30 Global step 30 Train loss 5.79 on epoch=14
06/24/2022 20:05:39 - INFO - __main__ - Step 40 Global step 40 Train loss 5.55 on epoch=19
06/24/2022 20:05:40 - INFO - __main__ - Step 50 Global step 50 Train loss 5.28 on epoch=24
06/24/2022 20:05:43 - INFO - __main__ - Global step 50 Train loss 5.78 ACC 0.0 on epoch=24
06/24/2022 20:05:44 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 20:05:45 - INFO - __main__ - Step 60 Global step 60 Train loss 5.04 on epoch=29
06/24/2022 20:05:46 - INFO - __main__ - Step 70 Global step 70 Train loss 5.00 on epoch=34
06/24/2022 20:05:47 - INFO - __main__ - Step 80 Global step 80 Train loss 4.81 on epoch=39
06/24/2022 20:05:48 - INFO - __main__ - Step 90 Global step 90 Train loss 4.59 on epoch=44
06/24/2022 20:05:50 - INFO - __main__ - Step 100 Global step 100 Train loss 4.41 on epoch=49
06/24/2022 20:05:52 - INFO - __main__ - Global step 100 Train loss 4.77 ACC 0.0 on epoch=49
06/24/2022 20:05:53 - INFO - __main__ - Step 110 Global step 110 Train loss 4.21 on epoch=54
06/24/2022 20:05:54 - INFO - __main__ - Step 120 Global step 120 Train loss 4.13 on epoch=59
06/24/2022 20:05:55 - INFO - __main__ - Step 130 Global step 130 Train loss 3.89 on epoch=64
06/24/2022 20:05:56 - INFO - __main__ - Step 140 Global step 140 Train loss 3.68 on epoch=69
06/24/2022 20:05:58 - INFO - __main__ - Step 150 Global step 150 Train loss 3.73 on epoch=74
06/24/2022 20:06:00 - INFO - __main__ - Global step 150 Train loss 3.93 ACC 0.0 on epoch=74
06/24/2022 20:06:02 - INFO - __main__ - Step 160 Global step 160 Train loss 3.53 on epoch=79
06/24/2022 20:06:03 - INFO - __main__ - Step 170 Global step 170 Train loss 3.51 on epoch=84
06/24/2022 20:06:04 - INFO - __main__ - Step 180 Global step 180 Train loss 3.39 on epoch=89
06/24/2022 20:06:05 - INFO - __main__ - Step 190 Global step 190 Train loss 3.34 on epoch=94
06/24/2022 20:06:07 - INFO - __main__ - Step 200 Global step 200 Train loss 3.15 on epoch=99
06/24/2022 20:06:08 - INFO - __main__ - Global step 200 Train loss 3.38 ACC 0.34375 on epoch=99
06/24/2022 20:06:08 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.34375 on epoch=99, global_step=200
06/24/2022 20:06:10 - INFO - __main__ - Step 210 Global step 210 Train loss 3.12 on epoch=104
06/24/2022 20:06:11 - INFO - __main__ - Step 220 Global step 220 Train loss 2.98 on epoch=109
06/24/2022 20:06:12 - INFO - __main__ - Step 230 Global step 230 Train loss 3.00 on epoch=114
06/24/2022 20:06:13 - INFO - __main__ - Step 240 Global step 240 Train loss 2.87 on epoch=119
06/24/2022 20:06:15 - INFO - __main__ - Step 250 Global step 250 Train loss 2.90 on epoch=124
06/24/2022 20:06:17 - INFO - __main__ - Global step 250 Train loss 2.98 ACC 0.25 on epoch=124
06/24/2022 20:06:18 - INFO - __main__ - Step 260 Global step 260 Train loss 2.96 on epoch=129
06/24/2022 20:06:19 - INFO - __main__ - Step 270 Global step 270 Train loss 2.87 on epoch=134
06/24/2022 20:06:21 - INFO - __main__ - Step 280 Global step 280 Train loss 2.63 on epoch=139
06/24/2022 20:06:22 - INFO - __main__ - Step 290 Global step 290 Train loss 2.71 on epoch=144
06/24/2022 20:06:23 - INFO - __main__ - Step 300 Global step 300 Train loss 2.52 on epoch=149
06/24/2022 20:06:29 - INFO - __main__ - Global step 300 Train loss 2.74 ACC 0.15625 on epoch=149
06/24/2022 20:06:31 - INFO - __main__ - Step 310 Global step 310 Train loss 2.56 on epoch=154
06/24/2022 20:06:32 - INFO - __main__ - Step 320 Global step 320 Train loss 2.46 on epoch=159
06/24/2022 20:06:33 - INFO - __main__ - Step 330 Global step 330 Train loss 2.24 on epoch=164
06/24/2022 20:06:34 - INFO - __main__ - Step 340 Global step 340 Train loss 2.34 on epoch=169
06/24/2022 20:06:36 - INFO - __main__ - Step 350 Global step 350 Train loss 2.31 on epoch=174
06/24/2022 20:06:40 - INFO - __main__ - Global step 350 Train loss 2.38 ACC 0.34375 on epoch=174
06/24/2022 20:06:41 - INFO - __main__ - Step 360 Global step 360 Train loss 2.20 on epoch=179
06/24/2022 20:06:42 - INFO - __main__ - Step 370 Global step 370 Train loss 2.06 on epoch=184
06/24/2022 20:06:43 - INFO - __main__ - Step 380 Global step 380 Train loss 2.01 on epoch=189
06/24/2022 20:06:45 - INFO - __main__ - Step 390 Global step 390 Train loss 1.98 on epoch=194
06/24/2022 20:06:46 - INFO - __main__ - Step 400 Global step 400 Train loss 2.02 on epoch=199
06/24/2022 20:06:52 - INFO - __main__ - Global step 400 Train loss 2.05 ACC 0.375 on epoch=199
06/24/2022 20:06:52 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.375 on epoch=199, global_step=400
06/24/2022 20:06:53 - INFO - __main__ - Step 410 Global step 410 Train loss 2.07 on epoch=204
06/24/2022 20:06:54 - INFO - __main__ - Step 420 Global step 420 Train loss 1.92 on epoch=209
06/24/2022 20:06:56 - INFO - __main__ - Step 430 Global step 430 Train loss 1.94 on epoch=214
06/24/2022 20:06:57 - INFO - __main__ - Step 440 Global step 440 Train loss 1.87 on epoch=219
06/24/2022 20:06:58 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=224
06/24/2022 20:07:05 - INFO - __main__ - Global step 450 Train loss 1.91 ACC 0.3125 on epoch=224
06/24/2022 20:07:06 - INFO - __main__ - Step 460 Global step 460 Train loss 1.83 on epoch=229
06/24/2022 20:07:08 - INFO - __main__ - Step 470 Global step 470 Train loss 1.57 on epoch=234
06/24/2022 20:07:09 - INFO - __main__ - Step 480 Global step 480 Train loss 1.69 on epoch=239
06/24/2022 20:07:10 - INFO - __main__ - Step 490 Global step 490 Train loss 1.60 on epoch=244
06/24/2022 20:07:11 - INFO - __main__ - Step 500 Global step 500 Train loss 1.55 on epoch=249
06/24/2022 20:07:21 - INFO - __main__ - Global step 500 Train loss 1.65 ACC 0.375 on epoch=249
06/24/2022 20:07:22 - INFO - __main__ - Step 510 Global step 510 Train loss 1.50 on epoch=254
06/24/2022 20:07:23 - INFO - __main__ - Step 520 Global step 520 Train loss 1.50 on epoch=259
06/24/2022 20:07:25 - INFO - __main__ - Step 530 Global step 530 Train loss 1.62 on epoch=264
06/24/2022 20:07:26 - INFO - __main__ - Step 540 Global step 540 Train loss 1.49 on epoch=269
06/24/2022 20:07:27 - INFO - __main__ - Step 550 Global step 550 Train loss 1.51 on epoch=274
06/24/2022 20:07:29 - INFO - __main__ - Global step 550 Train loss 1.52 ACC 0.5 on epoch=274
06/24/2022 20:07:29 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.5 on epoch=274, global_step=550
06/24/2022 20:07:31 - INFO - __main__ - Step 560 Global step 560 Train loss 1.46 on epoch=279
06/24/2022 20:07:32 - INFO - __main__ - Step 570 Global step 570 Train loss 1.42 on epoch=284
06/24/2022 20:07:33 - INFO - __main__ - Step 580 Global step 580 Train loss 1.43 on epoch=289
06/24/2022 20:07:34 - INFO - __main__ - Step 590 Global step 590 Train loss 1.47 on epoch=294
06/24/2022 20:07:36 - INFO - __main__ - Step 600 Global step 600 Train loss 1.39 on epoch=299
06/24/2022 20:07:40 - INFO - __main__ - Global step 600 Train loss 1.43 ACC 0.375 on epoch=299
06/24/2022 20:07:41 - INFO - __main__ - Step 610 Global step 610 Train loss 1.31 on epoch=304
06/24/2022 20:07:42 - INFO - __main__ - Step 620 Global step 620 Train loss 1.29 on epoch=309
06/24/2022 20:07:43 - INFO - __main__ - Step 630 Global step 630 Train loss 1.19 on epoch=314
06/24/2022 20:07:45 - INFO - __main__ - Step 640 Global step 640 Train loss 1.28 on epoch=319
06/24/2022 20:07:46 - INFO - __main__ - Step 650 Global step 650 Train loss 1.31 on epoch=324
06/24/2022 20:07:48 - INFO - __main__ - Global step 650 Train loss 1.27 ACC 0.5 on epoch=324
06/24/2022 20:07:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.08 on epoch=329
06/24/2022 20:07:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.06 on epoch=334
06/24/2022 20:07:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.09 on epoch=339
06/24/2022 20:07:53 - INFO - __main__ - Step 690 Global step 690 Train loss 1.11 on epoch=344
06/24/2022 20:07:54 - INFO - __main__ - Step 700 Global step 700 Train loss 1.05 on epoch=349
06/24/2022 20:08:00 - INFO - __main__ - Global step 700 Train loss 1.08 ACC 0.46875 on epoch=349
06/24/2022 20:08:01 - INFO - __main__ - Step 710 Global step 710 Train loss 1.01 on epoch=354
06/24/2022 20:08:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.99 on epoch=359
06/24/2022 20:08:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.92 on epoch=364
06/24/2022 20:08:05 - INFO - __main__ - Step 740 Global step 740 Train loss 1.04 on epoch=369
06/24/2022 20:08:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.97 on epoch=374
06/24/2022 20:08:07 - INFO - __main__ - Global step 750 Train loss 0.99 ACC 0.5 on epoch=374
06/24/2022 20:08:09 - INFO - __main__ - Step 760 Global step 760 Train loss 1.02 on epoch=379
06/24/2022 20:08:10 - INFO - __main__ - Step 770 Global step 770 Train loss 1.00 on epoch=384
06/24/2022 20:08:11 - INFO - __main__ - Step 780 Global step 780 Train loss 1.03 on epoch=389
06/24/2022 20:08:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.93 on epoch=394
06/24/2022 20:08:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.91 on epoch=399
06/24/2022 20:08:15 - INFO - __main__ - Global step 800 Train loss 0.98 ACC 0.5 on epoch=399
06/24/2022 20:08:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.96 on epoch=404
06/24/2022 20:08:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.81 on epoch=409
06/24/2022 20:08:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.95 on epoch=414
06/24/2022 20:08:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.85 on epoch=419
06/24/2022 20:08:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.86 on epoch=424
06/24/2022 20:08:22 - INFO - __main__ - Global step 850 Train loss 0.88 ACC 0.5 on epoch=424
06/24/2022 20:08:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.77 on epoch=429
06/24/2022 20:08:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.78 on epoch=434
06/24/2022 20:08:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.79 on epoch=439
06/24/2022 20:08:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.77 on epoch=444
06/24/2022 20:08:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.80 on epoch=449
06/24/2022 20:08:29 - INFO - __main__ - Global step 900 Train loss 0.78 ACC 0.5 on epoch=449
06/24/2022 20:08:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.77 on epoch=454
06/24/2022 20:08:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.77 on epoch=459
06/24/2022 20:08:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.76 on epoch=464
06/24/2022 20:08:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.76 on epoch=469
06/24/2022 20:08:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.68 on epoch=474
06/24/2022 20:08:35 - INFO - __main__ - Global step 950 Train loss 0.75 ACC 0.5 on epoch=474
06/24/2022 20:08:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.77 on epoch=479
06/24/2022 20:08:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.70 on epoch=484
06/24/2022 20:08:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.70 on epoch=489
06/24/2022 20:08:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.62 on epoch=494
06/24/2022 20:08:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.66 on epoch=499
06/24/2022 20:08:42 - INFO - __main__ - Global step 1000 Train loss 0.69 ACC 0.5 on epoch=499
06/24/2022 20:08:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.75 on epoch=504
06/24/2022 20:08:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.61 on epoch=509
06/24/2022 20:08:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.59 on epoch=514
06/24/2022 20:08:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.66 on epoch=519
06/24/2022 20:08:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.62 on epoch=524
06/24/2022 20:08:49 - INFO - __main__ - Global step 1050 Train loss 0.64 ACC 0.5 on epoch=524
06/24/2022 20:08:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.62 on epoch=529
06/24/2022 20:08:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.59 on epoch=534
06/24/2022 20:08:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.67 on epoch=539
06/24/2022 20:08:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.61 on epoch=544
06/24/2022 20:08:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.62 on epoch=549
06/24/2022 20:08:56 - INFO - __main__ - Global step 1100 Train loss 0.62 ACC 0.5 on epoch=549
06/24/2022 20:08:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.57 on epoch=554
06/24/2022 20:08:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.53 on epoch=559
06/24/2022 20:09:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.50 on epoch=564
06/24/2022 20:09:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.59 on epoch=569
06/24/2022 20:09:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.66 on epoch=574
06/24/2022 20:09:03 - INFO - __main__ - Global step 1150 Train loss 0.57 ACC 0.5 on epoch=574
06/24/2022 20:09:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.63 on epoch=579
06/24/2022 20:09:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.53 on epoch=584
06/24/2022 20:09:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.60 on epoch=589
06/24/2022 20:09:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.60 on epoch=594
06/24/2022 20:09:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.65 on epoch=599
06/24/2022 20:09:09 - INFO - __main__ - Global step 1200 Train loss 0.60 ACC 0.5 on epoch=599
06/24/2022 20:09:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.61 on epoch=604
06/24/2022 20:09:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.49 on epoch=609
06/24/2022 20:09:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.59 on epoch=614
06/24/2022 20:09:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.53 on epoch=619
06/24/2022 20:09:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.54 on epoch=624
06/24/2022 20:09:16 - INFO - __main__ - Global step 1250 Train loss 0.55 ACC 0.5 on epoch=624
06/24/2022 20:09:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.57 on epoch=629
06/24/2022 20:09:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.49 on epoch=634
06/24/2022 20:09:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.47 on epoch=639
06/24/2022 20:09:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.55 on epoch=644
06/24/2022 20:09:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.45 on epoch=649
06/24/2022 20:09:23 - INFO - __main__ - Global step 1300 Train loss 0.51 ACC 0.5 on epoch=649
06/24/2022 20:09:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.51 on epoch=654
06/24/2022 20:09:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.50 on epoch=659
06/24/2022 20:09:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.52 on epoch=664
06/24/2022 20:09:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.53 on epoch=669
06/24/2022 20:09:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.54 on epoch=674
06/24/2022 20:09:30 - INFO - __main__ - Global step 1350 Train loss 0.52 ACC 0.5 on epoch=674
06/24/2022 20:09:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.51 on epoch=679
06/24/2022 20:09:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.47 on epoch=684
06/24/2022 20:09:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.57 on epoch=689
06/24/2022 20:09:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.56 on epoch=694
06/24/2022 20:09:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.53 on epoch=699
06/24/2022 20:09:36 - INFO - __main__ - Global step 1400 Train loss 0.53 ACC 0.5 on epoch=699
06/24/2022 20:09:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.57 on epoch=704
06/24/2022 20:09:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.54 on epoch=709
06/24/2022 20:09:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.51 on epoch=714
06/24/2022 20:09:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.46 on epoch=719
06/24/2022 20:09:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.50 on epoch=724
06/24/2022 20:09:43 - INFO - __main__ - Global step 1450 Train loss 0.52 ACC 0.5 on epoch=724
06/24/2022 20:09:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.52 on epoch=729
06/24/2022 20:09:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.46 on epoch=734
06/24/2022 20:09:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.56 on epoch=739
06/24/2022 20:09:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.52 on epoch=744
06/24/2022 20:09:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.52 on epoch=749
06/24/2022 20:09:50 - INFO - __main__ - Global step 1500 Train loss 0.51 ACC 0.5 on epoch=749
06/24/2022 20:09:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.55 on epoch=754
06/24/2022 20:09:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.55 on epoch=759
06/24/2022 20:09:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.50 on epoch=764
06/24/2022 20:09:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.42 on epoch=769
06/24/2022 20:09:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.43 on epoch=774
06/24/2022 20:09:56 - INFO - __main__ - Global step 1550 Train loss 0.49 ACC 0.5 on epoch=774
06/24/2022 20:09:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.42 on epoch=779
06/24/2022 20:09:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.45 on epoch=784
06/24/2022 20:10:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.39 on epoch=789
06/24/2022 20:10:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.49 on epoch=794
06/24/2022 20:10:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.50 on epoch=799
06/24/2022 20:10:03 - INFO - __main__ - Global step 1600 Train loss 0.45 ACC 0.5 on epoch=799
06/24/2022 20:10:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.41 on epoch=804
06/24/2022 20:10:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.47 on epoch=809
06/24/2022 20:10:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.47 on epoch=814
06/24/2022 20:10:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.40 on epoch=819
06/24/2022 20:10:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.42 on epoch=824
06/24/2022 20:10:10 - INFO - __main__ - Global step 1650 Train loss 0.43 ACC 0.5 on epoch=824
06/24/2022 20:10:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.40 on epoch=829
06/24/2022 20:10:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.49 on epoch=834
06/24/2022 20:10:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.42 on epoch=839
06/24/2022 20:10:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.41 on epoch=844
06/24/2022 20:10:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.39 on epoch=849
06/24/2022 20:10:16 - INFO - __main__ - Global step 1700 Train loss 0.42 ACC 0.5 on epoch=849
06/24/2022 20:10:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.48 on epoch=854
06/24/2022 20:10:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.46 on epoch=859
06/24/2022 20:10:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.44 on epoch=864
06/24/2022 20:10:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.40 on epoch=869
06/24/2022 20:10:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.50 on epoch=874
06/24/2022 20:10:23 - INFO - __main__ - Global step 1750 Train loss 0.46 ACC 0.5 on epoch=874
06/24/2022 20:10:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.40 on epoch=879
06/24/2022 20:10:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.41 on epoch=884
06/24/2022 20:10:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.43 on epoch=889
06/24/2022 20:10:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.41 on epoch=894
06/24/2022 20:10:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.43 on epoch=899
06/24/2022 20:10:30 - INFO - __main__ - Global step 1800 Train loss 0.42 ACC 0.53125 on epoch=899
06/24/2022 20:10:30 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=899, global_step=1800
06/24/2022 20:10:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.46 on epoch=904
06/24/2022 20:10:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.44 on epoch=909
06/24/2022 20:10:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.39 on epoch=914
06/24/2022 20:10:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.36 on epoch=919
06/24/2022 20:10:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.41 on epoch=924
06/24/2022 20:10:37 - INFO - __main__ - Global step 1850 Train loss 0.41 ACC 0.5 on epoch=924
06/24/2022 20:10:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.34 on epoch=929
06/24/2022 20:10:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.42 on epoch=934
06/24/2022 20:10:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.36 on epoch=939
06/24/2022 20:10:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.38 on epoch=944
06/24/2022 20:10:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.40 on epoch=949
06/24/2022 20:10:43 - INFO - __main__ - Global step 1900 Train loss 0.38 ACC 0.5 on epoch=949
06/24/2022 20:10:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.33 on epoch=954
06/24/2022 20:10:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.44 on epoch=959
06/24/2022 20:10:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.37 on epoch=964
06/24/2022 20:10:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.42 on epoch=969
06/24/2022 20:10:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.38 on epoch=974
06/24/2022 20:10:50 - INFO - __main__ - Global step 1950 Train loss 0.39 ACC 0.5 on epoch=974
06/24/2022 20:10:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.34 on epoch=979
06/24/2022 20:10:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.38 on epoch=984
06/24/2022 20:10:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.35 on epoch=989
06/24/2022 20:10:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.39 on epoch=994
06/24/2022 20:10:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.34 on epoch=999
06/24/2022 20:10:57 - INFO - __main__ - Global step 2000 Train loss 0.36 ACC 0.5 on epoch=999
06/24/2022 20:10:57 - INFO - __main__ - save last model!
06/24/2022 20:10:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 20:10:57 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 20:10:57 - INFO - __main__ - Printing 3 examples
06/24/2022 20:10:57 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 20:10:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:57 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 20:10:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:57 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 20:10:57 - INFO - __main__ - ['duplicate']
06/24/2022 20:10:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:10:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:10:57 - INFO - __main__ - Printing 3 examples
06/24/2022 20:10:57 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:10:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:57 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:10:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:57 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:10:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:10:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:10:58 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:10:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:10:58 - INFO - __main__ - Printing 3 examples
06/24/2022 20:10:58 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:10:58 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:58 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:10:58 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:58 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:10:58 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:10:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:10:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:10:58 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:11:03 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:11:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:11:03 - INFO - __main__ - Starting training!
06/24/2022 20:11:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:11:56 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 20:23:58 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_100_0.5_8_predictions.txt
06/24/2022 20:23:58 - INFO - __main__ - ACC on test data: 0.3704
06/24/2022 20:23:58 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.5, bsz=8, dev_performance=0.53125, test_performance=0.37041800643086814
06/24/2022 20:23:58 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.4, bsz=8 ...
06/24/2022 20:23:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:23:59 - INFO - __main__ - Printing 3 examples
06/24/2022 20:23:59 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:23:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:23:59 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:23:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:23:59 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:23:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:23:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:23:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:23:59 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:23:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:23:59 - INFO - __main__ - Printing 3 examples
06/24/2022 20:23:59 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:23:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:23:59 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:23:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:23:59 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:23:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:23:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:23:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:23:59 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:24:05 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:24:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:24:05 - INFO - __main__ - Starting training!
06/24/2022 20:24:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.33 on epoch=4
06/24/2022 20:24:08 - INFO - __main__ - Step 20 Global step 20 Train loss 6.08 on epoch=9
06/24/2022 20:24:09 - INFO - __main__ - Step 30 Global step 30 Train loss 5.95 on epoch=14
06/24/2022 20:24:10 - INFO - __main__ - Step 40 Global step 40 Train loss 5.79 on epoch=19
06/24/2022 20:24:11 - INFO - __main__ - Step 50 Global step 50 Train loss 5.47 on epoch=24
06/24/2022 20:24:13 - INFO - __main__ - Global step 50 Train loss 5.92 ACC 0.0 on epoch=24
06/24/2022 20:24:13 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 20:24:14 - INFO - __main__ - Step 60 Global step 60 Train loss 5.37 on epoch=29
06/24/2022 20:24:16 - INFO - __main__ - Step 70 Global step 70 Train loss 5.14 on epoch=34
06/24/2022 20:24:17 - INFO - __main__ - Step 80 Global step 80 Train loss 5.01 on epoch=39
06/24/2022 20:24:18 - INFO - __main__ - Step 90 Global step 90 Train loss 4.75 on epoch=44
06/24/2022 20:24:19 - INFO - __main__ - Step 100 Global step 100 Train loss 4.68 on epoch=49
06/24/2022 20:24:21 - INFO - __main__ - Global step 100 Train loss 4.99 ACC 0.0 on epoch=49
06/24/2022 20:24:22 - INFO - __main__ - Step 110 Global step 110 Train loss 4.54 on epoch=54
06/24/2022 20:24:23 - INFO - __main__ - Step 120 Global step 120 Train loss 4.34 on epoch=59
06/24/2022 20:24:25 - INFO - __main__ - Step 130 Global step 130 Train loss 4.23 on epoch=64
06/24/2022 20:24:26 - INFO - __main__ - Step 140 Global step 140 Train loss 4.21 on epoch=69
06/24/2022 20:24:27 - INFO - __main__ - Step 150 Global step 150 Train loss 4.08 on epoch=74
06/24/2022 20:24:29 - INFO - __main__ - Global step 150 Train loss 4.28 ACC 0.0 on epoch=74
06/24/2022 20:24:30 - INFO - __main__ - Step 160 Global step 160 Train loss 3.85 on epoch=79
06/24/2022 20:24:31 - INFO - __main__ - Step 170 Global step 170 Train loss 3.86 on epoch=84
06/24/2022 20:24:32 - INFO - __main__ - Step 180 Global step 180 Train loss 3.64 on epoch=89
06/24/2022 20:24:34 - INFO - __main__ - Step 190 Global step 190 Train loss 3.63 on epoch=94
06/24/2022 20:24:35 - INFO - __main__ - Step 200 Global step 200 Train loss 3.41 on epoch=99
06/24/2022 20:24:36 - INFO - __main__ - Global step 200 Train loss 3.68 ACC 0.0 on epoch=99
06/24/2022 20:24:37 - INFO - __main__ - Step 210 Global step 210 Train loss 3.35 on epoch=104
06/24/2022 20:24:38 - INFO - __main__ - Step 220 Global step 220 Train loss 3.32 on epoch=109
06/24/2022 20:24:40 - INFO - __main__ - Step 230 Global step 230 Train loss 3.23 on epoch=114
06/24/2022 20:24:41 - INFO - __main__ - Step 240 Global step 240 Train loss 3.08 on epoch=119
06/24/2022 20:24:42 - INFO - __main__ - Step 250 Global step 250 Train loss 2.93 on epoch=124
06/24/2022 20:24:48 - INFO - __main__ - Global step 250 Train loss 3.18 ACC 0.40625 on epoch=124
06/24/2022 20:24:48 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.40625 on epoch=124, global_step=250
06/24/2022 20:24:49 - INFO - __main__ - Step 260 Global step 260 Train loss 2.88 on epoch=129
06/24/2022 20:24:50 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=134
06/24/2022 20:24:52 - INFO - __main__ - Step 280 Global step 280 Train loss 2.54 on epoch=139
06/24/2022 20:24:53 - INFO - __main__ - Step 290 Global step 290 Train loss 2.47 on epoch=144
06/24/2022 20:24:54 - INFO - __main__ - Step 300 Global step 300 Train loss 2.40 on epoch=149
06/24/2022 20:24:57 - INFO - __main__ - Global step 300 Train loss 2.58 ACC 0.46875 on epoch=149
06/24/2022 20:24:57 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.46875 on epoch=149, global_step=300
06/24/2022 20:24:58 - INFO - __main__ - Step 310 Global step 310 Train loss 2.33 on epoch=154
06/24/2022 20:24:59 - INFO - __main__ - Step 320 Global step 320 Train loss 2.23 on epoch=159
06/24/2022 20:25:01 - INFO - __main__ - Step 330 Global step 330 Train loss 2.12 on epoch=164
06/24/2022 20:25:02 - INFO - __main__ - Step 340 Global step 340 Train loss 2.02 on epoch=169
06/24/2022 20:25:03 - INFO - __main__ - Step 350 Global step 350 Train loss 1.98 on epoch=174
06/24/2022 20:25:05 - INFO - __main__ - Global step 350 Train loss 2.13 ACC 0.375 on epoch=174
06/24/2022 20:25:06 - INFO - __main__ - Step 360 Global step 360 Train loss 2.01 on epoch=179
06/24/2022 20:25:07 - INFO - __main__ - Step 370 Global step 370 Train loss 1.79 on epoch=184
06/24/2022 20:25:09 - INFO - __main__ - Step 380 Global step 380 Train loss 1.86 on epoch=189
06/24/2022 20:25:10 - INFO - __main__ - Step 390 Global step 390 Train loss 1.70 on epoch=194
06/24/2022 20:25:11 - INFO - __main__ - Step 400 Global step 400 Train loss 1.75 on epoch=199
06/24/2022 20:25:14 - INFO - __main__ - Global step 400 Train loss 1.82 ACC 0.3125 on epoch=199
06/24/2022 20:25:15 - INFO - __main__ - Step 410 Global step 410 Train loss 1.71 on epoch=204
06/24/2022 20:25:16 - INFO - __main__ - Step 420 Global step 420 Train loss 1.71 on epoch=209
06/24/2022 20:25:17 - INFO - __main__ - Step 430 Global step 430 Train loss 1.45 on epoch=214
06/24/2022 20:25:19 - INFO - __main__ - Step 440 Global step 440 Train loss 1.45 on epoch=219
06/24/2022 20:25:20 - INFO - __main__ - Step 450 Global step 450 Train loss 1.51 on epoch=224
06/24/2022 20:25:25 - INFO - __main__ - Global step 450 Train loss 1.56 ACC 0.46875 on epoch=224
06/24/2022 20:25:26 - INFO - __main__ - Step 460 Global step 460 Train loss 1.40 on epoch=229
06/24/2022 20:25:28 - INFO - __main__ - Step 470 Global step 470 Train loss 1.33 on epoch=234
06/24/2022 20:25:29 - INFO - __main__ - Step 480 Global step 480 Train loss 1.40 on epoch=239
06/24/2022 20:25:30 - INFO - __main__ - Step 490 Global step 490 Train loss 1.41 on epoch=244
06/24/2022 20:25:31 - INFO - __main__ - Step 500 Global step 500 Train loss 1.29 on epoch=249
06/24/2022 20:25:33 - INFO - __main__ - Global step 500 Train loss 1.37 ACC 0.5 on epoch=249
06/24/2022 20:25:33 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=249, global_step=500
06/24/2022 20:25:34 - INFO - __main__ - Step 510 Global step 510 Train loss 1.22 on epoch=254
06/24/2022 20:25:36 - INFO - __main__ - Step 520 Global step 520 Train loss 1.16 on epoch=259
06/24/2022 20:25:37 - INFO - __main__ - Step 530 Global step 530 Train loss 1.19 on epoch=264
06/24/2022 20:25:38 - INFO - __main__ - Step 540 Global step 540 Train loss 1.16 on epoch=269
06/24/2022 20:25:39 - INFO - __main__ - Step 550 Global step 550 Train loss 1.07 on epoch=274
06/24/2022 20:25:41 - INFO - __main__ - Global step 550 Train loss 1.16 ACC 0.5 on epoch=274
06/24/2022 20:25:42 - INFO - __main__ - Step 560 Global step 560 Train loss 1.12 on epoch=279
06/24/2022 20:25:43 - INFO - __main__ - Step 570 Global step 570 Train loss 1.09 on epoch=284
06/24/2022 20:25:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.97 on epoch=289
06/24/2022 20:25:46 - INFO - __main__ - Step 590 Global step 590 Train loss 1.02 on epoch=294
06/24/2022 20:25:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.96 on epoch=299
06/24/2022 20:25:49 - INFO - __main__ - Global step 600 Train loss 1.03 ACC 0.5 on epoch=299
06/24/2022 20:25:50 - INFO - __main__ - Step 610 Global step 610 Train loss 1.02 on epoch=304
06/24/2022 20:25:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.90 on epoch=309
06/24/2022 20:25:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.86 on epoch=314
06/24/2022 20:25:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.87 on epoch=319
06/24/2022 20:25:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.87 on epoch=324
06/24/2022 20:25:57 - INFO - __main__ - Global step 650 Train loss 0.91 ACC 0.5 on epoch=324
06/24/2022 20:25:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.95 on epoch=329
06/24/2022 20:25:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.75 on epoch=334
06/24/2022 20:26:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.81 on epoch=339
06/24/2022 20:26:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.85 on epoch=344
06/24/2022 20:26:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.81 on epoch=349
06/24/2022 20:26:05 - INFO - __main__ - Global step 700 Train loss 0.83 ACC 0.5 on epoch=349
06/24/2022 20:26:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.78 on epoch=354
06/24/2022 20:26:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.78 on epoch=359
06/24/2022 20:26:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.72 on epoch=364
06/24/2022 20:26:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.71 on epoch=369
06/24/2022 20:26:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.74 on epoch=374
06/24/2022 20:26:13 - INFO - __main__ - Global step 750 Train loss 0.75 ACC 0.5 on epoch=374
06/24/2022 20:26:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.67 on epoch=379
06/24/2022 20:26:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.68 on epoch=384
06/24/2022 20:26:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.70 on epoch=389
06/24/2022 20:26:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.71 on epoch=394
06/24/2022 20:26:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.64 on epoch=399
06/24/2022 20:26:20 - INFO - __main__ - Global step 800 Train loss 0.68 ACC 0.5 on epoch=399
06/24/2022 20:26:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.64 on epoch=404
06/24/2022 20:26:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.63 on epoch=409
06/24/2022 20:26:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.65 on epoch=414
06/24/2022 20:26:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.65 on epoch=419
06/24/2022 20:26:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.65 on epoch=424
06/24/2022 20:26:29 - INFO - __main__ - Global step 850 Train loss 0.64 ACC 0.5 on epoch=424
06/24/2022 20:26:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.63 on epoch=429
06/24/2022 20:26:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.49 on epoch=434
06/24/2022 20:26:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.56 on epoch=439
06/24/2022 20:26:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.63 on epoch=444
06/24/2022 20:26:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.58 on epoch=449
06/24/2022 20:26:36 - INFO - __main__ - Global step 900 Train loss 0.58 ACC 0.5 on epoch=449
06/24/2022 20:26:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.48 on epoch=454
06/24/2022 20:26:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.55 on epoch=459
06/24/2022 20:26:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.56 on epoch=464
06/24/2022 20:26:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.47 on epoch=469
06/24/2022 20:26:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.55 on epoch=474
06/24/2022 20:26:43 - INFO - __main__ - Global step 950 Train loss 0.52 ACC 0.5 on epoch=474
06/24/2022 20:26:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.54 on epoch=479
06/24/2022 20:26:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.56 on epoch=484
06/24/2022 20:26:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.50 on epoch=489
06/24/2022 20:26:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.53 on epoch=494
06/24/2022 20:26:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.52 on epoch=499
06/24/2022 20:26:50 - INFO - __main__ - Global step 1000 Train loss 0.53 ACC 0.5 on epoch=499
06/24/2022 20:26:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.54 on epoch=504
06/24/2022 20:26:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.42 on epoch=509
06/24/2022 20:26:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.57 on epoch=514
06/24/2022 20:26:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.51 on epoch=519
06/24/2022 20:26:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.52 on epoch=524
06/24/2022 20:26:57 - INFO - __main__ - Global step 1050 Train loss 0.51 ACC 0.5 on epoch=524
06/24/2022 20:26:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.57 on epoch=529
06/24/2022 20:26:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.49 on epoch=534
06/24/2022 20:27:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.46 on epoch=539
06/24/2022 20:27:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.53 on epoch=544
06/24/2022 20:27:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.52 on epoch=549
06/24/2022 20:27:04 - INFO - __main__ - Global step 1100 Train loss 0.51 ACC 0.5 on epoch=549
06/24/2022 20:27:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.51 on epoch=554
06/24/2022 20:27:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.43 on epoch=559
06/24/2022 20:27:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.52 on epoch=564
06/24/2022 20:27:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.51 on epoch=569
06/24/2022 20:27:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.43 on epoch=574
06/24/2022 20:27:11 - INFO - __main__ - Global step 1150 Train loss 0.48 ACC 0.5 on epoch=574
06/24/2022 20:27:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.45 on epoch=579
06/24/2022 20:27:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.50 on epoch=584
06/24/2022 20:27:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.41 on epoch=589
06/24/2022 20:27:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.47 on epoch=594
06/24/2022 20:27:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.43 on epoch=599
06/24/2022 20:27:18 - INFO - __main__ - Global step 1200 Train loss 0.45 ACC 0.5 on epoch=599
06/24/2022 20:27:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.39 on epoch=604
06/24/2022 20:27:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.45 on epoch=609
06/24/2022 20:27:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.43 on epoch=614
06/24/2022 20:27:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.39 on epoch=619
06/24/2022 20:27:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.41 on epoch=624
06/24/2022 20:27:25 - INFO - __main__ - Global step 1250 Train loss 0.41 ACC 0.5 on epoch=624
06/24/2022 20:27:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.46 on epoch=629
06/24/2022 20:27:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.43 on epoch=634
06/24/2022 20:27:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.42 on epoch=639
06/24/2022 20:27:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.41 on epoch=644
06/24/2022 20:27:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.43 on epoch=649
06/24/2022 20:27:32 - INFO - __main__ - Global step 1300 Train loss 0.43 ACC 0.5 on epoch=649
06/24/2022 20:27:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.41 on epoch=654
06/24/2022 20:27:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.39 on epoch=659
06/24/2022 20:27:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.42 on epoch=664
06/24/2022 20:27:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.38 on epoch=669
06/24/2022 20:27:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.44 on epoch=674
06/24/2022 20:27:39 - INFO - __main__ - Global step 1350 Train loss 0.41 ACC 0.5 on epoch=674
06/24/2022 20:27:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.35 on epoch=679
06/24/2022 20:27:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.38 on epoch=684
06/24/2022 20:27:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.38 on epoch=689
06/24/2022 20:27:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.37 on epoch=694
06/24/2022 20:27:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.40 on epoch=699
06/24/2022 20:27:46 - INFO - __main__ - Global step 1400 Train loss 0.38 ACC 0.5 on epoch=699
06/24/2022 20:27:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.36 on epoch=704
06/24/2022 20:27:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.39 on epoch=709
06/24/2022 20:27:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.38 on epoch=714
06/24/2022 20:27:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.37 on epoch=719
06/24/2022 20:27:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.34 on epoch=724
06/24/2022 20:27:53 - INFO - __main__ - Global step 1450 Train loss 0.37 ACC 0.5 on epoch=724
06/24/2022 20:27:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.40 on epoch=729
06/24/2022 20:27:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.37 on epoch=734
06/24/2022 20:27:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.36 on epoch=739
06/24/2022 20:27:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.37 on epoch=744
06/24/2022 20:28:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.35 on epoch=749
06/24/2022 20:28:00 - INFO - __main__ - Global step 1500 Train loss 0.37 ACC 0.5 on epoch=749
06/24/2022 20:28:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.43 on epoch=754
06/24/2022 20:28:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.30 on epoch=759
06/24/2022 20:28:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.37 on epoch=764
06/24/2022 20:28:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.35 on epoch=769
06/24/2022 20:28:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.38 on epoch=774
06/24/2022 20:28:07 - INFO - __main__ - Global step 1550 Train loss 0.37 ACC 0.5 on epoch=774
06/24/2022 20:28:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.37 on epoch=779
06/24/2022 20:28:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.35 on epoch=784
06/24/2022 20:28:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.29 on epoch=789
06/24/2022 20:28:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.38 on epoch=794
06/24/2022 20:28:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.34 on epoch=799
06/24/2022 20:28:15 - INFO - __main__ - Global step 1600 Train loss 0.35 ACC 0.5 on epoch=799
06/24/2022 20:28:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.35 on epoch=804
06/24/2022 20:28:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.36 on epoch=809
06/24/2022 20:28:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.34 on epoch=814
06/24/2022 20:28:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.29 on epoch=819
06/24/2022 20:28:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.35 on epoch=824
06/24/2022 20:28:22 - INFO - __main__ - Global step 1650 Train loss 0.34 ACC 0.5 on epoch=824
06/24/2022 20:28:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.36 on epoch=829
06/24/2022 20:28:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.37 on epoch=834
06/24/2022 20:28:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.34 on epoch=839
06/24/2022 20:28:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.33 on epoch=844
06/24/2022 20:28:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.37 on epoch=849
06/24/2022 20:28:29 - INFO - __main__ - Global step 1700 Train loss 0.35 ACC 0.5 on epoch=849
06/24/2022 20:28:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.30 on epoch=854
06/24/2022 20:28:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.36 on epoch=859
06/24/2022 20:28:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.32 on epoch=864
06/24/2022 20:28:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.41 on epoch=869
06/24/2022 20:28:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.33 on epoch=874
06/24/2022 20:28:36 - INFO - __main__ - Global step 1750 Train loss 0.34 ACC 0.5 on epoch=874
06/24/2022 20:28:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.31 on epoch=879
06/24/2022 20:28:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.33 on epoch=884
06/24/2022 20:28:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.31 on epoch=889
06/24/2022 20:28:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.31 on epoch=894
06/24/2022 20:28:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.36 on epoch=899
06/24/2022 20:28:43 - INFO - __main__ - Global step 1800 Train loss 0.32 ACC 0.5 on epoch=899
06/24/2022 20:28:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.32 on epoch=904
06/24/2022 20:28:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.37 on epoch=909
06/24/2022 20:28:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.31 on epoch=914
06/24/2022 20:28:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.35 on epoch=919
06/24/2022 20:28:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.28 on epoch=924
06/24/2022 20:28:50 - INFO - __main__ - Global step 1850 Train loss 0.33 ACC 0.5 on epoch=924
06/24/2022 20:28:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.26 on epoch=929
06/24/2022 20:28:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.36 on epoch=934
06/24/2022 20:28:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.32 on epoch=939
06/24/2022 20:28:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.40 on epoch=944
06/24/2022 20:28:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.29 on epoch=949
06/24/2022 20:28:57 - INFO - __main__ - Global step 1900 Train loss 0.33 ACC 0.5 on epoch=949
06/24/2022 20:28:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.32 on epoch=954
06/24/2022 20:29:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.31 on epoch=959
06/24/2022 20:29:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.27 on epoch=964
06/24/2022 20:29:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.39 on epoch=969
06/24/2022 20:29:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.35 on epoch=974
06/24/2022 20:29:04 - INFO - __main__ - Global step 1950 Train loss 0.33 ACC 0.5 on epoch=974
06/24/2022 20:29:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.31 on epoch=979
06/24/2022 20:29:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.28 on epoch=984
06/24/2022 20:29:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.33 on epoch=989
06/24/2022 20:29:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.31 on epoch=994
06/24/2022 20:29:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.39 on epoch=999
06/24/2022 20:29:11 - INFO - __main__ - Global step 2000 Train loss 0.32 ACC 0.5 on epoch=999
06/24/2022 20:29:11 - INFO - __main__ - save last model!
06/24/2022 20:29:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 20:29:11 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 20:29:11 - INFO - __main__ - Printing 3 examples
06/24/2022 20:29:11 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 20:29:11 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:11 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 20:29:11 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:11 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 20:29:11 - INFO - __main__ - ['duplicate']
06/24/2022 20:29:11 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:29:12 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:29:12 - INFO - __main__ - Printing 3 examples
06/24/2022 20:29:12 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:29:12 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:12 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:29:12 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:12 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:29:12 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:12 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:29:12 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:29:12 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:29:12 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:29:12 - INFO - __main__ - Printing 3 examples
06/24/2022 20:29:12 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:29:12 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:12 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:29:12 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:12 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:29:12 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:29:12 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:29:12 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:29:12 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:29:17 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:29:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:29:18 - INFO - __main__ - Starting training!
06/24/2022 20:29:30 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:30:12 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 20:39:35 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_100_0.4_8_predictions.txt
06/24/2022 20:39:36 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 20:39:36 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.4, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 20:39:36 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.3, bsz=8 ...
06/24/2022 20:39:37 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:39:37 - INFO - __main__ - Printing 3 examples
06/24/2022 20:39:37 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:39:37 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:39:37 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:39:37 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:39:37 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:39:37 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:39:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:39:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:39:37 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:39:37 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:39:37 - INFO - __main__ - Printing 3 examples
06/24/2022 20:39:37 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:39:37 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:39:37 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:39:37 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:39:37 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:39:37 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:39:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:39:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:39:37 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:39:42 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:39:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:39:42 - INFO - __main__ - Starting training!
06/24/2022 20:39:44 - INFO - __main__ - Step 10 Global step 10 Train loss 6.31 on epoch=4
06/24/2022 20:39:45 - INFO - __main__ - Step 20 Global step 20 Train loss 6.16 on epoch=9
06/24/2022 20:39:46 - INFO - __main__ - Step 30 Global step 30 Train loss 6.07 on epoch=14
06/24/2022 20:39:48 - INFO - __main__ - Step 40 Global step 40 Train loss 5.78 on epoch=19
06/24/2022 20:39:49 - INFO - __main__ - Step 50 Global step 50 Train loss 5.62 on epoch=24
06/24/2022 20:39:55 - INFO - __main__ - Global step 50 Train loss 5.99 ACC 0.0 on epoch=24
06/24/2022 20:39:55 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 20:39:57 - INFO - __main__ - Step 60 Global step 60 Train loss 5.43 on epoch=29
06/24/2022 20:39:58 - INFO - __main__ - Step 70 Global step 70 Train loss 5.48 on epoch=34
06/24/2022 20:39:59 - INFO - __main__ - Step 80 Global step 80 Train loss 5.26 on epoch=39
06/24/2022 20:40:00 - INFO - __main__ - Step 90 Global step 90 Train loss 5.27 on epoch=44
06/24/2022 20:40:02 - INFO - __main__ - Step 100 Global step 100 Train loss 5.13 on epoch=49
06/24/2022 20:40:03 - INFO - __main__ - Global step 100 Train loss 5.31 ACC 0.0 on epoch=49
06/24/2022 20:40:04 - INFO - __main__ - Step 110 Global step 110 Train loss 5.01 on epoch=54
06/24/2022 20:40:06 - INFO - __main__ - Step 120 Global step 120 Train loss 5.05 on epoch=59
06/24/2022 20:40:07 - INFO - __main__ - Step 130 Global step 130 Train loss 4.88 on epoch=64
06/24/2022 20:40:08 - INFO - __main__ - Step 140 Global step 140 Train loss 4.73 on epoch=69
06/24/2022 20:40:09 - INFO - __main__ - Step 150 Global step 150 Train loss 4.63 on epoch=74
06/24/2022 20:40:11 - INFO - __main__ - Global step 150 Train loss 4.86 ACC 0.0 on epoch=74
06/24/2022 20:40:12 - INFO - __main__ - Step 160 Global step 160 Train loss 4.59 on epoch=79
06/24/2022 20:40:13 - INFO - __main__ - Step 170 Global step 170 Train loss 4.50 on epoch=84
06/24/2022 20:40:14 - INFO - __main__ - Step 180 Global step 180 Train loss 4.40 on epoch=89
06/24/2022 20:40:16 - INFO - __main__ - Step 190 Global step 190 Train loss 4.26 on epoch=94
06/24/2022 20:40:17 - INFO - __main__ - Step 200 Global step 200 Train loss 4.12 on epoch=99
06/24/2022 20:40:18 - INFO - __main__ - Global step 200 Train loss 4.37 ACC 0.0 on epoch=99
06/24/2022 20:40:20 - INFO - __main__ - Step 210 Global step 210 Train loss 4.02 on epoch=104
06/24/2022 20:40:21 - INFO - __main__ - Step 220 Global step 220 Train loss 4.01 on epoch=109
06/24/2022 20:40:22 - INFO - __main__ - Step 230 Global step 230 Train loss 3.86 on epoch=114
06/24/2022 20:40:23 - INFO - __main__ - Step 240 Global step 240 Train loss 3.85 on epoch=119
06/24/2022 20:40:25 - INFO - __main__ - Step 250 Global step 250 Train loss 3.59 on epoch=124
06/24/2022 20:40:26 - INFO - __main__ - Global step 250 Train loss 3.86 ACC 0.0 on epoch=124
06/24/2022 20:40:28 - INFO - __main__ - Step 260 Global step 260 Train loss 3.43 on epoch=129
06/24/2022 20:40:29 - INFO - __main__ - Step 270 Global step 270 Train loss 3.31 on epoch=134
06/24/2022 20:40:30 - INFO - __main__ - Step 280 Global step 280 Train loss 3.35 on epoch=139
06/24/2022 20:40:32 - INFO - __main__ - Step 290 Global step 290 Train loss 3.23 on epoch=144
06/24/2022 20:40:33 - INFO - __main__ - Step 300 Global step 300 Train loss 3.17 on epoch=149
06/24/2022 20:40:34 - INFO - __main__ - Global step 300 Train loss 3.30 ACC 0.0 on epoch=149
06/24/2022 20:40:35 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=154
06/24/2022 20:40:36 - INFO - __main__ - Step 320 Global step 320 Train loss 2.92 on epoch=159
06/24/2022 20:40:38 - INFO - __main__ - Step 330 Global step 330 Train loss 2.75 on epoch=164
06/24/2022 20:40:39 - INFO - __main__ - Step 340 Global step 340 Train loss 2.88 on epoch=169
06/24/2022 20:40:40 - INFO - __main__ - Step 350 Global step 350 Train loss 2.64 on epoch=174
06/24/2022 20:40:41 - INFO - __main__ - Global step 350 Train loss 2.85 ACC 0.0 on epoch=174
06/24/2022 20:40:42 - INFO - __main__ - Step 360 Global step 360 Train loss 2.67 on epoch=179
06/24/2022 20:40:44 - INFO - __main__ - Step 370 Global step 370 Train loss 2.57 on epoch=184
06/24/2022 20:40:45 - INFO - __main__ - Step 380 Global step 380 Train loss 2.51 on epoch=189
06/24/2022 20:40:46 - INFO - __main__ - Step 390 Global step 390 Train loss 2.48 on epoch=194
06/24/2022 20:40:47 - INFO - __main__ - Step 400 Global step 400 Train loss 2.37 on epoch=199
06/24/2022 20:40:49 - INFO - __main__ - Global step 400 Train loss 2.52 ACC 0.28125 on epoch=199
06/24/2022 20:40:49 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.28125 on epoch=199, global_step=400
06/24/2022 20:40:50 - INFO - __main__ - Step 410 Global step 410 Train loss 2.33 on epoch=204
06/24/2022 20:40:51 - INFO - __main__ - Step 420 Global step 420 Train loss 2.26 on epoch=209
06/24/2022 20:40:52 - INFO - __main__ - Step 430 Global step 430 Train loss 2.32 on epoch=214
06/24/2022 20:40:54 - INFO - __main__ - Step 440 Global step 440 Train loss 2.20 on epoch=219
06/24/2022 20:40:55 - INFO - __main__ - Step 450 Global step 450 Train loss 2.12 on epoch=224
06/24/2022 20:40:56 - INFO - __main__ - Global step 450 Train loss 2.24 ACC 0.4375 on epoch=224
06/24/2022 20:40:56 - INFO - __main__ - Saving model with best ACC: 0.28125 -> 0.4375 on epoch=224, global_step=450
06/24/2022 20:40:58 - INFO - __main__ - Step 460 Global step 460 Train loss 2.06 on epoch=229
06/24/2022 20:40:59 - INFO - __main__ - Step 470 Global step 470 Train loss 2.13 on epoch=234
06/24/2022 20:41:00 - INFO - __main__ - Step 480 Global step 480 Train loss 2.01 on epoch=239
06/24/2022 20:41:01 - INFO - __main__ - Step 490 Global step 490 Train loss 1.97 on epoch=244
06/24/2022 20:41:03 - INFO - __main__ - Step 500 Global step 500 Train loss 1.94 on epoch=249
06/24/2022 20:41:05 - INFO - __main__ - Global step 500 Train loss 2.02 ACC 0.4375 on epoch=249
06/24/2022 20:41:06 - INFO - __main__ - Step 510 Global step 510 Train loss 1.98 on epoch=254
06/24/2022 20:41:07 - INFO - __main__ - Step 520 Global step 520 Train loss 1.89 on epoch=259
06/24/2022 20:41:08 - INFO - __main__ - Step 530 Global step 530 Train loss 1.90 on epoch=264
06/24/2022 20:41:10 - INFO - __main__ - Step 540 Global step 540 Train loss 1.85 on epoch=269
06/24/2022 20:41:11 - INFO - __main__ - Step 550 Global step 550 Train loss 1.79 on epoch=274
06/24/2022 20:41:16 - INFO - __main__ - Global step 550 Train loss 1.88 ACC 0.46875 on epoch=274
06/24/2022 20:41:16 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=274, global_step=550
06/24/2022 20:41:17 - INFO - __main__ - Step 560 Global step 560 Train loss 1.73 on epoch=279
06/24/2022 20:41:18 - INFO - __main__ - Step 570 Global step 570 Train loss 1.68 on epoch=284
06/24/2022 20:41:20 - INFO - __main__ - Step 580 Global step 580 Train loss 1.52 on epoch=289
06/24/2022 20:41:21 - INFO - __main__ - Step 590 Global step 590 Train loss 1.64 on epoch=294
06/24/2022 20:41:22 - INFO - __main__ - Step 600 Global step 600 Train loss 1.57 on epoch=299
06/24/2022 20:41:27 - INFO - __main__ - Global step 600 Train loss 1.63 ACC 0.5 on epoch=299
06/24/2022 20:41:27 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=299, global_step=600
06/24/2022 20:41:29 - INFO - __main__ - Step 610 Global step 610 Train loss 1.42 on epoch=304
06/24/2022 20:41:30 - INFO - __main__ - Step 620 Global step 620 Train loss 1.52 on epoch=309
06/24/2022 20:41:31 - INFO - __main__ - Step 630 Global step 630 Train loss 1.50 on epoch=314
06/24/2022 20:41:33 - INFO - __main__ - Step 640 Global step 640 Train loss 1.47 on epoch=319
06/24/2022 20:41:34 - INFO - __main__ - Step 650 Global step 650 Train loss 1.40 on epoch=324
06/24/2022 20:41:40 - INFO - __main__ - Global step 650 Train loss 1.47 ACC 0.5 on epoch=324
06/24/2022 20:41:41 - INFO - __main__ - Step 660 Global step 660 Train loss 1.44 on epoch=329
06/24/2022 20:41:42 - INFO - __main__ - Step 670 Global step 670 Train loss 1.39 on epoch=334
06/24/2022 20:41:44 - INFO - __main__ - Step 680 Global step 680 Train loss 1.34 on epoch=339
06/24/2022 20:41:45 - INFO - __main__ - Step 690 Global step 690 Train loss 1.31 on epoch=344
06/24/2022 20:41:46 - INFO - __main__ - Step 700 Global step 700 Train loss 1.35 on epoch=349
06/24/2022 20:41:48 - INFO - __main__ - Global step 700 Train loss 1.37 ACC 0.5 on epoch=349
06/24/2022 20:41:49 - INFO - __main__ - Step 710 Global step 710 Train loss 1.28 on epoch=354
06/24/2022 20:41:50 - INFO - __main__ - Step 720 Global step 720 Train loss 1.30 on epoch=359
06/24/2022 20:41:52 - INFO - __main__ - Step 730 Global step 730 Train loss 1.23 on epoch=364
06/24/2022 20:41:53 - INFO - __main__ - Step 740 Global step 740 Train loss 1.23 on epoch=369
06/24/2022 20:41:54 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=374
06/24/2022 20:41:57 - INFO - __main__ - Global step 750 Train loss 1.23 ACC 0.5 on epoch=374
06/24/2022 20:41:59 - INFO - __main__ - Step 760 Global step 760 Train loss 1.23 on epoch=379
06/24/2022 20:42:00 - INFO - __main__ - Step 770 Global step 770 Train loss 1.15 on epoch=384
06/24/2022 20:42:01 - INFO - __main__ - Step 780 Global step 780 Train loss 1.17 on epoch=389
06/24/2022 20:42:02 - INFO - __main__ - Step 790 Global step 790 Train loss 1.15 on epoch=394
06/24/2022 20:42:04 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=399
06/24/2022 20:42:05 - INFO - __main__ - Global step 800 Train loss 1.17 ACC 0.5 on epoch=399
06/24/2022 20:42:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.95 on epoch=404
06/24/2022 20:42:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.93 on epoch=409
06/24/2022 20:42:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.98 on epoch=414
06/24/2022 20:42:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.98 on epoch=419
06/24/2022 20:42:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.96 on epoch=424
06/24/2022 20:42:12 - INFO - __main__ - Global step 850 Train loss 0.96 ACC 0.5 on epoch=424
06/24/2022 20:42:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.93 on epoch=429
06/24/2022 20:42:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.91 on epoch=434
06/24/2022 20:42:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.85 on epoch=439
06/24/2022 20:42:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.88 on epoch=444
06/24/2022 20:42:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.83 on epoch=449
06/24/2022 20:42:20 - INFO - __main__ - Global step 900 Train loss 0.88 ACC 0.5 on epoch=449
06/24/2022 20:42:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.87 on epoch=454
06/24/2022 20:42:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.75 on epoch=459
06/24/2022 20:42:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.81 on epoch=464
06/24/2022 20:42:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.82 on epoch=469
06/24/2022 20:42:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.82 on epoch=474
06/24/2022 20:42:27 - INFO - __main__ - Global step 950 Train loss 0.81 ACC 0.5 on epoch=474
06/24/2022 20:42:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.72 on epoch=479
06/24/2022 20:42:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.69 on epoch=484
06/24/2022 20:42:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.71 on epoch=489
06/24/2022 20:42:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.69 on epoch=494
06/24/2022 20:42:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.72 on epoch=499
06/24/2022 20:42:34 - INFO - __main__ - Global step 1000 Train loss 0.71 ACC 0.5 on epoch=499
06/24/2022 20:42:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.71 on epoch=504
06/24/2022 20:42:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.59 on epoch=509
06/24/2022 20:42:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.65 on epoch=514
06/24/2022 20:42:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.62 on epoch=519
06/24/2022 20:42:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.70 on epoch=524
06/24/2022 20:42:40 - INFO - __main__ - Global step 1050 Train loss 0.65 ACC 0.5 on epoch=524
06/24/2022 20:42:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.59 on epoch=529
06/24/2022 20:42:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.58 on epoch=534
06/24/2022 20:42:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.59 on epoch=539
06/24/2022 20:42:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.65 on epoch=544
06/24/2022 20:42:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.60 on epoch=549
06/24/2022 20:42:47 - INFO - __main__ - Global step 1100 Train loss 0.60 ACC 0.5 on epoch=549
06/24/2022 20:42:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.57 on epoch=554
06/24/2022 20:42:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.60 on epoch=559
06/24/2022 20:42:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.64 on epoch=564
06/24/2022 20:42:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.61 on epoch=569
06/24/2022 20:42:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.61 on epoch=574
06/24/2022 20:42:54 - INFO - __main__ - Global step 1150 Train loss 0.60 ACC 0.5 on epoch=574
06/24/2022 20:42:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.49 on epoch=579
06/24/2022 20:42:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.51 on epoch=584
06/24/2022 20:42:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.57 on epoch=589
06/24/2022 20:42:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.55 on epoch=594
06/24/2022 20:43:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.51 on epoch=599
06/24/2022 20:43:01 - INFO - __main__ - Global step 1200 Train loss 0.53 ACC 0.5 on epoch=599
06/24/2022 20:43:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.51 on epoch=604
06/24/2022 20:43:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.47 on epoch=609
06/24/2022 20:43:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.57 on epoch=614
06/24/2022 20:43:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.49 on epoch=619
06/24/2022 20:43:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.60 on epoch=624
06/24/2022 20:43:08 - INFO - __main__ - Global step 1250 Train loss 0.53 ACC 0.5 on epoch=624
06/24/2022 20:43:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.53 on epoch=629
06/24/2022 20:43:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.49 on epoch=634
06/24/2022 20:43:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.52 on epoch=639
06/24/2022 20:43:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.47 on epoch=644
06/24/2022 20:43:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.56 on epoch=649
06/24/2022 20:43:15 - INFO - __main__ - Global step 1300 Train loss 0.51 ACC 0.5 on epoch=649
06/24/2022 20:43:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.45 on epoch=654
06/24/2022 20:43:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.48 on epoch=659
06/24/2022 20:43:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.48 on epoch=664
06/24/2022 20:43:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.49 on epoch=669
06/24/2022 20:43:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.47 on epoch=674
06/24/2022 20:43:22 - INFO - __main__ - Global step 1350 Train loss 0.47 ACC 0.5 on epoch=674
06/24/2022 20:43:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.55 on epoch=679
06/24/2022 20:43:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.47 on epoch=684
06/24/2022 20:43:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.41 on epoch=689
06/24/2022 20:43:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.47 on epoch=694
06/24/2022 20:43:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.53 on epoch=699
06/24/2022 20:43:28 - INFO - __main__ - Global step 1400 Train loss 0.49 ACC 0.5 on epoch=699
06/24/2022 20:43:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.42 on epoch=704
06/24/2022 20:43:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.47 on epoch=709
06/24/2022 20:43:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.45 on epoch=714
06/24/2022 20:43:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.44 on epoch=719
06/24/2022 20:43:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.39 on epoch=724
06/24/2022 20:43:35 - INFO - __main__ - Global step 1450 Train loss 0.44 ACC 0.5 on epoch=724
06/24/2022 20:43:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.52 on epoch=729
06/24/2022 20:43:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.44 on epoch=734
06/24/2022 20:43:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.43 on epoch=739
06/24/2022 20:43:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.48 on epoch=744
06/24/2022 20:43:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.47 on epoch=749
06/24/2022 20:43:42 - INFO - __main__ - Global step 1500 Train loss 0.47 ACC 0.5 on epoch=749
06/24/2022 20:43:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.40 on epoch=754
06/24/2022 20:43:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.43 on epoch=759
06/24/2022 20:43:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.38 on epoch=764
06/24/2022 20:43:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.44 on epoch=769
06/24/2022 20:43:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.42 on epoch=774
06/24/2022 20:43:49 - INFO - __main__ - Global step 1550 Train loss 0.42 ACC 0.5 on epoch=774
06/24/2022 20:43:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.42 on epoch=779
06/24/2022 20:43:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.42 on epoch=784
06/24/2022 20:43:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.45 on epoch=789
06/24/2022 20:43:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.43 on epoch=794
06/24/2022 20:43:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.39 on epoch=799
06/24/2022 20:43:56 - INFO - __main__ - Global step 1600 Train loss 0.42 ACC 0.5 on epoch=799
06/24/2022 20:43:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.43 on epoch=804
06/24/2022 20:43:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.37 on epoch=809
06/24/2022 20:44:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.43 on epoch=814
06/24/2022 20:44:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.42 on epoch=819
06/24/2022 20:44:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.40 on epoch=824
06/24/2022 20:44:03 - INFO - __main__ - Global step 1650 Train loss 0.41 ACC 0.5 on epoch=824
06/24/2022 20:44:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.36 on epoch=829
06/24/2022 20:44:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.34 on epoch=834
06/24/2022 20:44:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.48 on epoch=839
06/24/2022 20:44:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.40 on epoch=844
06/24/2022 20:44:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.42 on epoch=849
06/24/2022 20:44:10 - INFO - __main__ - Global step 1700 Train loss 0.40 ACC 0.5 on epoch=849
06/24/2022 20:44:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.39 on epoch=854
06/24/2022 20:44:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.37 on epoch=859
06/24/2022 20:44:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.39 on epoch=864
06/24/2022 20:44:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.36 on epoch=869
06/24/2022 20:44:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.39 on epoch=874
06/24/2022 20:44:17 - INFO - __main__ - Global step 1750 Train loss 0.38 ACC 0.5 on epoch=874
06/24/2022 20:44:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.38 on epoch=879
06/24/2022 20:44:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.42 on epoch=884
06/24/2022 20:44:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.46 on epoch=889
06/24/2022 20:44:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.41 on epoch=894
06/24/2022 20:44:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.41 on epoch=899
06/24/2022 20:44:24 - INFO - __main__ - Global step 1800 Train loss 0.42 ACC 0.5 on epoch=899
06/24/2022 20:44:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.48 on epoch=904
06/24/2022 20:44:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.43 on epoch=909
06/24/2022 20:44:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.41 on epoch=914
06/24/2022 20:44:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.42 on epoch=919
06/24/2022 20:44:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.43 on epoch=924
06/24/2022 20:44:31 - INFO - __main__ - Global step 1850 Train loss 0.43 ACC 0.5 on epoch=924
06/24/2022 20:44:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.42 on epoch=929
06/24/2022 20:44:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.41 on epoch=934
06/24/2022 20:44:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.37 on epoch=939
06/24/2022 20:44:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.39 on epoch=944
06/24/2022 20:44:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.37 on epoch=949
06/24/2022 20:44:37 - INFO - __main__ - Global step 1900 Train loss 0.39 ACC 0.5 on epoch=949
06/24/2022 20:44:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.37 on epoch=954
06/24/2022 20:44:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.37 on epoch=959
06/24/2022 20:44:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.40 on epoch=964
06/24/2022 20:44:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.37 on epoch=969
06/24/2022 20:44:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.34 on epoch=974
06/24/2022 20:44:44 - INFO - __main__ - Global step 1950 Train loss 0.37 ACC 0.5 on epoch=974
06/24/2022 20:44:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.31 on epoch=979
06/24/2022 20:44:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.40 on epoch=984
06/24/2022 20:44:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.40 on epoch=989
06/24/2022 20:44:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.36 on epoch=994
06/24/2022 20:44:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.38 on epoch=999
06/24/2022 20:44:51 - INFO - __main__ - Global step 2000 Train loss 0.37 ACC 0.5 on epoch=999
06/24/2022 20:44:51 - INFO - __main__ - save last model!
06/24/2022 20:44:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 20:44:51 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 20:44:51 - INFO - __main__ - Printing 3 examples
06/24/2022 20:44:51 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 20:44:51 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:51 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 20:44:51 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:51 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 20:44:51 - INFO - __main__ - ['duplicate']
06/24/2022 20:44:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:44:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:44:51 - INFO - __main__ - Printing 3 examples
06/24/2022 20:44:51 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:44:51 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:51 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:44:51 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:51 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:44:51 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:44:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:44:52 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:44:52 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:44:52 - INFO - __main__ - Printing 3 examples
06/24/2022 20:44:52 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:44:52 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:52 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:44:52 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:52 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:44:52 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:44:52 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:44:52 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:44:52 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:44:58 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:44:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:44:58 - INFO - __main__ - Starting training!
06/24/2022 20:45:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:45:51 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 20:56:13 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_100_0.3_8_predictions.txt
06/24/2022 20:56:13 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 20:56:13 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.3, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 20:56:13 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.2, bsz=8 ...
06/24/2022 20:56:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:56:14 - INFO - __main__ - Printing 3 examples
06/24/2022 20:56:14 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 20:56:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:56:14 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 20:56:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:56:14 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 20:56:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:56:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:56:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:56:14 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 20:56:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 20:56:14 - INFO - __main__ - Printing 3 examples
06/24/2022 20:56:14 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 20:56:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:56:14 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 20:56:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:56:14 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 20:56:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 20:56:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 20:56:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 20:56:14 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 20:56:19 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 20:56:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 20:56:20 - INFO - __main__ - Starting training!
06/24/2022 20:56:21 - INFO - __main__ - Step 10 Global step 10 Train loss 6.40 on epoch=4
06/24/2022 20:56:22 - INFO - __main__ - Step 20 Global step 20 Train loss 6.22 on epoch=9
06/24/2022 20:56:24 - INFO - __main__ - Step 30 Global step 30 Train loss 6.11 on epoch=14
06/24/2022 20:56:25 - INFO - __main__ - Step 40 Global step 40 Train loss 6.02 on epoch=19
06/24/2022 20:56:26 - INFO - __main__ - Step 50 Global step 50 Train loss 5.96 on epoch=24
06/24/2022 20:56:30 - INFO - __main__ - Global step 50 Train loss 6.14 ACC 0.0 on epoch=24
06/24/2022 20:56:30 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 20:56:31 - INFO - __main__ - Step 60 Global step 60 Train loss 5.79 on epoch=29
06/24/2022 20:56:32 - INFO - __main__ - Step 70 Global step 70 Train loss 5.67 on epoch=34
06/24/2022 20:56:34 - INFO - __main__ - Step 80 Global step 80 Train loss 5.59 on epoch=39
06/24/2022 20:56:35 - INFO - __main__ - Step 90 Global step 90 Train loss 5.52 on epoch=44
06/24/2022 20:56:36 - INFO - __main__ - Step 100 Global step 100 Train loss 5.41 on epoch=49
06/24/2022 20:56:38 - INFO - __main__ - Global step 100 Train loss 5.59 ACC 0.0 on epoch=49
06/24/2022 20:56:39 - INFO - __main__ - Step 110 Global step 110 Train loss 5.37 on epoch=54
06/24/2022 20:56:40 - INFO - __main__ - Step 120 Global step 120 Train loss 5.31 on epoch=59
06/24/2022 20:56:41 - INFO - __main__ - Step 130 Global step 130 Train loss 5.13 on epoch=64
06/24/2022 20:56:43 - INFO - __main__ - Step 140 Global step 140 Train loss 5.03 on epoch=69
06/24/2022 20:56:44 - INFO - __main__ - Step 150 Global step 150 Train loss 4.98 on epoch=74
06/24/2022 20:56:45 - INFO - __main__ - Global step 150 Train loss 5.16 ACC 0.0 on epoch=74
06/24/2022 20:56:47 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=79
06/24/2022 20:56:48 - INFO - __main__ - Step 170 Global step 170 Train loss 4.79 on epoch=84
06/24/2022 20:56:49 - INFO - __main__ - Step 180 Global step 180 Train loss 4.83 on epoch=89
06/24/2022 20:56:50 - INFO - __main__ - Step 190 Global step 190 Train loss 4.72 on epoch=94
06/24/2022 20:56:52 - INFO - __main__ - Step 200 Global step 200 Train loss 4.79 on epoch=99
06/24/2022 20:56:53 - INFO - __main__ - Global step 200 Train loss 4.82 ACC 0.0 on epoch=99
06/24/2022 20:56:54 - INFO - __main__ - Step 210 Global step 210 Train loss 4.69 on epoch=104
06/24/2022 20:56:56 - INFO - __main__ - Step 220 Global step 220 Train loss 4.64 on epoch=109
06/24/2022 20:56:57 - INFO - __main__ - Step 230 Global step 230 Train loss 4.60 on epoch=114
06/24/2022 20:56:58 - INFO - __main__ - Step 240 Global step 240 Train loss 4.48 on epoch=119
06/24/2022 20:56:59 - INFO - __main__ - Step 250 Global step 250 Train loss 4.46 on epoch=124
06/24/2022 20:57:01 - INFO - __main__ - Global step 250 Train loss 4.58 ACC 0.0 on epoch=124
06/24/2022 20:57:02 - INFO - __main__ - Step 260 Global step 260 Train loss 4.35 on epoch=129
06/24/2022 20:57:03 - INFO - __main__ - Step 270 Global step 270 Train loss 4.40 on epoch=134
06/24/2022 20:57:05 - INFO - __main__ - Step 280 Global step 280 Train loss 4.28 on epoch=139
06/24/2022 20:57:06 - INFO - __main__ - Step 290 Global step 290 Train loss 4.16 on epoch=144
06/24/2022 20:57:07 - INFO - __main__ - Step 300 Global step 300 Train loss 4.23 on epoch=149
06/24/2022 20:57:09 - INFO - __main__ - Global step 300 Train loss 4.28 ACC 0.0 on epoch=149
06/24/2022 20:57:10 - INFO - __main__ - Step 310 Global step 310 Train loss 4.05 on epoch=154
06/24/2022 20:57:12 - INFO - __main__ - Step 320 Global step 320 Train loss 4.05 on epoch=159
06/24/2022 20:57:13 - INFO - __main__ - Step 330 Global step 330 Train loss 3.95 on epoch=164
06/24/2022 20:57:14 - INFO - __main__ - Step 340 Global step 340 Train loss 3.93 on epoch=169
06/24/2022 20:57:15 - INFO - __main__ - Step 350 Global step 350 Train loss 3.92 on epoch=174
06/24/2022 20:57:17 - INFO - __main__ - Global step 350 Train loss 3.98 ACC 0.03125 on epoch=174
06/24/2022 20:57:17 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=174, global_step=350
06/24/2022 20:57:18 - INFO - __main__ - Step 360 Global step 360 Train loss 3.88 on epoch=179
06/24/2022 20:57:19 - INFO - __main__ - Step 370 Global step 370 Train loss 3.87 on epoch=184
06/24/2022 20:57:20 - INFO - __main__ - Step 380 Global step 380 Train loss 3.67 on epoch=189
06/24/2022 20:57:22 - INFO - __main__ - Step 390 Global step 390 Train loss 3.63 on epoch=194
06/24/2022 20:57:23 - INFO - __main__ - Step 400 Global step 400 Train loss 3.66 on epoch=199
06/24/2022 20:57:24 - INFO - __main__ - Global step 400 Train loss 3.74 ACC 0.125 on epoch=199
06/24/2022 20:57:25 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.125 on epoch=199, global_step=400
06/24/2022 20:57:26 - INFO - __main__ - Step 410 Global step 410 Train loss 3.56 on epoch=204
06/24/2022 20:57:27 - INFO - __main__ - Step 420 Global step 420 Train loss 3.48 on epoch=209
06/24/2022 20:57:28 - INFO - __main__ - Step 430 Global step 430 Train loss 3.44 on epoch=214
06/24/2022 20:57:30 - INFO - __main__ - Step 440 Global step 440 Train loss 3.29 on epoch=219
06/24/2022 20:57:31 - INFO - __main__ - Step 450 Global step 450 Train loss 3.34 on epoch=224
06/24/2022 20:57:34 - INFO - __main__ - Global step 450 Train loss 3.42 ACC 0.03125 on epoch=224
06/24/2022 20:57:35 - INFO - __main__ - Step 460 Global step 460 Train loss 3.19 on epoch=229
06/24/2022 20:57:37 - INFO - __main__ - Step 470 Global step 470 Train loss 3.26 on epoch=234
06/24/2022 20:57:38 - INFO - __main__ - Step 480 Global step 480 Train loss 3.31 on epoch=239
06/24/2022 20:57:39 - INFO - __main__ - Step 490 Global step 490 Train loss 3.32 on epoch=244
06/24/2022 20:57:40 - INFO - __main__ - Step 500 Global step 500 Train loss 3.15 on epoch=249
06/24/2022 20:57:44 - INFO - __main__ - Global step 500 Train loss 3.24 ACC 0.375 on epoch=249
06/24/2022 20:57:44 - INFO - __main__ - Saving model with best ACC: 0.125 -> 0.375 on epoch=249, global_step=500
06/24/2022 20:57:45 - INFO - __main__ - Step 510 Global step 510 Train loss 3.08 on epoch=254
06/24/2022 20:57:46 - INFO - __main__ - Step 520 Global step 520 Train loss 3.06 on epoch=259
06/24/2022 20:57:48 - INFO - __main__ - Step 530 Global step 530 Train loss 3.10 on epoch=264
06/24/2022 20:57:49 - INFO - __main__ - Step 540 Global step 540 Train loss 2.92 on epoch=269
06/24/2022 20:57:50 - INFO - __main__ - Step 550 Global step 550 Train loss 2.90 on epoch=274
06/24/2022 20:57:52 - INFO - __main__ - Global step 550 Train loss 3.01 ACC 0.5 on epoch=274
06/24/2022 20:57:52 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.5 on epoch=274, global_step=550
06/24/2022 20:57:54 - INFO - __main__ - Step 560 Global step 560 Train loss 2.81 on epoch=279
06/24/2022 20:57:55 - INFO - __main__ - Step 570 Global step 570 Train loss 2.87 on epoch=284
06/24/2022 20:57:56 - INFO - __main__ - Step 580 Global step 580 Train loss 2.79 on epoch=289
06/24/2022 20:57:58 - INFO - __main__ - Step 590 Global step 590 Train loss 2.83 on epoch=294
06/24/2022 20:57:59 - INFO - __main__ - Step 600 Global step 600 Train loss 2.68 on epoch=299
06/24/2022 20:58:05 - INFO - __main__ - Global step 600 Train loss 2.79 ACC 0.40625 on epoch=299
06/24/2022 20:58:06 - INFO - __main__ - Step 610 Global step 610 Train loss 2.65 on epoch=304
06/24/2022 20:58:08 - INFO - __main__ - Step 620 Global step 620 Train loss 2.68 on epoch=309
06/24/2022 20:58:09 - INFO - __main__ - Step 630 Global step 630 Train loss 2.48 on epoch=314
06/24/2022 20:58:10 - INFO - __main__ - Step 640 Global step 640 Train loss 2.55 on epoch=319
06/24/2022 20:58:11 - INFO - __main__ - Step 650 Global step 650 Train loss 2.59 on epoch=324
06/24/2022 20:58:12 - INFO - __main__ - Global step 650 Train loss 2.59 ACC 0.5 on epoch=324
06/24/2022 20:58:14 - INFO - __main__ - Step 660 Global step 660 Train loss 2.41 on epoch=329
06/24/2022 20:58:15 - INFO - __main__ - Step 670 Global step 670 Train loss 2.41 on epoch=334
06/24/2022 20:58:16 - INFO - __main__ - Step 680 Global step 680 Train loss 2.43 on epoch=339
06/24/2022 20:58:17 - INFO - __main__ - Step 690 Global step 690 Train loss 2.45 on epoch=344
06/24/2022 20:58:19 - INFO - __main__ - Step 700 Global step 700 Train loss 2.44 on epoch=349
06/24/2022 20:58:20 - INFO - __main__ - Global step 700 Train loss 2.43 ACC 0.5 on epoch=349
06/24/2022 20:58:21 - INFO - __main__ - Step 710 Global step 710 Train loss 2.29 on epoch=354
06/24/2022 20:58:22 - INFO - __main__ - Step 720 Global step 720 Train loss 2.28 on epoch=359
06/24/2022 20:58:24 - INFO - __main__ - Step 730 Global step 730 Train loss 2.22 on epoch=364
06/24/2022 20:58:25 - INFO - __main__ - Step 740 Global step 740 Train loss 2.24 on epoch=369
06/24/2022 20:58:26 - INFO - __main__ - Step 750 Global step 750 Train loss 2.28 on epoch=374
06/24/2022 20:58:29 - INFO - __main__ - Global step 750 Train loss 2.26 ACC 0.5 on epoch=374
06/24/2022 20:58:30 - INFO - __main__ - Step 760 Global step 760 Train loss 2.18 on epoch=379
06/24/2022 20:58:31 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=384
06/24/2022 20:58:33 - INFO - __main__ - Step 780 Global step 780 Train loss 2.16 on epoch=389
06/24/2022 20:58:34 - INFO - __main__ - Step 790 Global step 790 Train loss 2.15 on epoch=394
06/24/2022 20:58:35 - INFO - __main__ - Step 800 Global step 800 Train loss 2.05 on epoch=399
06/24/2022 20:58:39 - INFO - __main__ - Global step 800 Train loss 2.16 ACC 0.3125 on epoch=399
06/24/2022 20:58:40 - INFO - __main__ - Step 810 Global step 810 Train loss 2.19 on epoch=404
06/24/2022 20:58:41 - INFO - __main__ - Step 820 Global step 820 Train loss 2.17 on epoch=409
06/24/2022 20:58:42 - INFO - __main__ - Step 830 Global step 830 Train loss 2.18 on epoch=414
06/24/2022 20:58:44 - INFO - __main__ - Step 840 Global step 840 Train loss 2.10 on epoch=419
06/24/2022 20:58:45 - INFO - __main__ - Step 850 Global step 850 Train loss 2.11 on epoch=424
06/24/2022 20:58:47 - INFO - __main__ - Global step 850 Train loss 2.15 ACC 0.375 on epoch=424
06/24/2022 20:58:49 - INFO - __main__ - Step 860 Global step 860 Train loss 2.06 on epoch=429
06/24/2022 20:58:50 - INFO - __main__ - Step 870 Global step 870 Train loss 2.06 on epoch=434
06/24/2022 20:58:51 - INFO - __main__ - Step 880 Global step 880 Train loss 2.11 on epoch=439
06/24/2022 20:58:52 - INFO - __main__ - Step 890 Global step 890 Train loss 2.08 on epoch=444
06/24/2022 20:58:54 - INFO - __main__ - Step 900 Global step 900 Train loss 2.06 on epoch=449
06/24/2022 20:58:57 - INFO - __main__ - Global step 900 Train loss 2.08 ACC 0.34375 on epoch=449
06/24/2022 20:58:58 - INFO - __main__ - Step 910 Global step 910 Train loss 1.91 on epoch=454
06/24/2022 20:58:59 - INFO - __main__ - Step 920 Global step 920 Train loss 1.92 on epoch=459
06/24/2022 20:59:00 - INFO - __main__ - Step 930 Global step 930 Train loss 1.87 on epoch=464
06/24/2022 20:59:02 - INFO - __main__ - Step 940 Global step 940 Train loss 1.91 on epoch=469
06/24/2022 20:59:03 - INFO - __main__ - Step 950 Global step 950 Train loss 1.88 on epoch=474
06/24/2022 20:59:05 - INFO - __main__ - Global step 950 Train loss 1.90 ACC 0.4375 on epoch=474
06/24/2022 20:59:07 - INFO - __main__ - Step 960 Global step 960 Train loss 1.92 on epoch=479
06/24/2022 20:59:08 - INFO - __main__ - Step 970 Global step 970 Train loss 1.75 on epoch=484
06/24/2022 20:59:09 - INFO - __main__ - Step 980 Global step 980 Train loss 1.76 on epoch=489
06/24/2022 20:59:11 - INFO - __main__ - Step 990 Global step 990 Train loss 1.85 on epoch=494
06/24/2022 20:59:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.74 on epoch=499
06/24/2022 20:59:14 - INFO - __main__ - Global step 1000 Train loss 1.80 ACC 0.5 on epoch=499
06/24/2022 20:59:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.74 on epoch=504
06/24/2022 20:59:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.68 on epoch=509
06/24/2022 20:59:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.69 on epoch=514
06/24/2022 20:59:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.66 on epoch=519
06/24/2022 20:59:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.62 on epoch=524
06/24/2022 20:59:23 - INFO - __main__ - Global step 1050 Train loss 1.68 ACC 0.46875 on epoch=524
06/24/2022 20:59:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.61 on epoch=529
06/24/2022 20:59:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.64 on epoch=534
06/24/2022 20:59:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.59 on epoch=539
06/24/2022 20:59:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.54 on epoch=544
06/24/2022 20:59:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.59 on epoch=549
06/24/2022 20:59:32 - INFO - __main__ - Global step 1100 Train loss 1.59 ACC 0.5 on epoch=549
06/24/2022 20:59:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.54 on epoch=554
06/24/2022 20:59:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.47 on epoch=559
06/24/2022 20:59:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.46 on epoch=564
06/24/2022 20:59:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.53 on epoch=569
06/24/2022 20:59:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.48 on epoch=574
06/24/2022 20:59:40 - INFO - __main__ - Global step 1150 Train loss 1.50 ACC 0.5 on epoch=574
06/24/2022 20:59:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.47 on epoch=579
06/24/2022 20:59:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.44 on epoch=584
06/24/2022 20:59:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.44 on epoch=589
06/24/2022 20:59:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.44 on epoch=594
06/24/2022 20:59:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.45 on epoch=599
06/24/2022 20:59:48 - INFO - __main__ - Global step 1200 Train loss 1.45 ACC 0.5 on epoch=599
06/24/2022 20:59:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.31 on epoch=604
06/24/2022 20:59:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.31 on epoch=609
06/24/2022 20:59:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.31 on epoch=614
06/24/2022 20:59:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.40 on epoch=619
06/24/2022 20:59:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.30 on epoch=624
06/24/2022 20:59:55 - INFO - __main__ - Global step 1250 Train loss 1.33 ACC 0.5 on epoch=624
06/24/2022 20:59:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.26 on epoch=629
06/24/2022 20:59:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.20 on epoch=634
06/24/2022 20:59:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.14 on epoch=639
06/24/2022 21:00:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.22 on epoch=644
06/24/2022 21:00:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.22 on epoch=649
06/24/2022 21:00:03 - INFO - __main__ - Global step 1300 Train loss 1.21 ACC 0.5 on epoch=649
06/24/2022 21:00:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.24 on epoch=654
06/24/2022 21:00:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=659
06/24/2022 21:00:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.13 on epoch=664
06/24/2022 21:00:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.14 on epoch=669
06/24/2022 21:00:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.13 on epoch=674
06/24/2022 21:00:10 - INFO - __main__ - Global step 1350 Train loss 1.17 ACC 0.5 on epoch=674
06/24/2022 21:00:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=679
06/24/2022 21:00:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=684
06/24/2022 21:00:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=689
06/24/2022 21:00:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.15 on epoch=694
06/24/2022 21:00:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.95 on epoch=699
06/24/2022 21:00:17 - INFO - __main__ - Global step 1400 Train loss 1.08 ACC 0.5 on epoch=699
06/24/2022 21:00:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.01 on epoch=704
06/24/2022 21:00:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.97 on epoch=709
06/24/2022 21:00:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.05 on epoch=714
06/24/2022 21:00:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=719
06/24/2022 21:00:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=724
06/24/2022 21:00:23 - INFO - __main__ - Global step 1450 Train loss 1.03 ACC 0.5 on epoch=724
06/24/2022 21:00:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.93 on epoch=729
06/24/2022 21:00:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.02 on epoch=734
06/24/2022 21:00:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.03 on epoch=739
06/24/2022 21:00:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.92 on epoch=744
06/24/2022 21:00:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.94 on epoch=749
06/24/2022 21:00:30 - INFO - __main__ - Global step 1500 Train loss 0.97 ACC 0.5 on epoch=749
06/24/2022 21:00:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.94 on epoch=754
06/24/2022 21:00:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.92 on epoch=759
06/24/2022 21:00:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.88 on epoch=764
06/24/2022 21:00:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.89 on epoch=769
06/24/2022 21:00:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.90 on epoch=774
06/24/2022 21:00:37 - INFO - __main__ - Global step 1550 Train loss 0.91 ACC 0.5 on epoch=774
06/24/2022 21:00:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.93 on epoch=779
06/24/2022 21:00:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.93 on epoch=784
06/24/2022 21:00:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.93 on epoch=789
06/24/2022 21:00:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.79 on epoch=794
06/24/2022 21:00:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.85 on epoch=799
06/24/2022 21:00:44 - INFO - __main__ - Global step 1600 Train loss 0.89 ACC 0.5 on epoch=799
06/24/2022 21:00:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.94 on epoch=804
06/24/2022 21:00:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.82 on epoch=809
06/24/2022 21:00:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.83 on epoch=814
06/24/2022 21:00:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.85 on epoch=819
06/24/2022 21:00:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.80 on epoch=824
06/24/2022 21:00:50 - INFO - __main__ - Global step 1650 Train loss 0.85 ACC 0.5 on epoch=824
06/24/2022 21:00:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.84 on epoch=829
06/24/2022 21:00:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.87 on epoch=834
06/24/2022 21:00:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.81 on epoch=839
06/24/2022 21:00:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.88 on epoch=844
06/24/2022 21:00:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.83 on epoch=849
06/24/2022 21:00:57 - INFO - __main__ - Global step 1700 Train loss 0.84 ACC 0.5 on epoch=849
06/24/2022 21:00:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.80 on epoch=854
06/24/2022 21:00:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.76 on epoch=859
06/24/2022 21:01:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.71 on epoch=864
06/24/2022 21:01:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.71 on epoch=869
06/24/2022 21:01:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.88 on epoch=874
06/24/2022 21:01:04 - INFO - __main__ - Global step 1750 Train loss 0.77 ACC 0.5 on epoch=874
06/24/2022 21:01:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.71 on epoch=879
06/24/2022 21:01:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.71 on epoch=884
06/24/2022 21:01:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.71 on epoch=889
06/24/2022 21:01:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.75 on epoch=894
06/24/2022 21:01:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.77 on epoch=899
06/24/2022 21:01:10 - INFO - __main__ - Global step 1800 Train loss 0.73 ACC 0.5 on epoch=899
06/24/2022 21:01:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.69 on epoch=904
06/24/2022 21:01:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.66 on epoch=909
06/24/2022 21:01:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.73 on epoch=914
06/24/2022 21:01:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.78 on epoch=919
06/24/2022 21:01:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.75 on epoch=924
06/24/2022 21:01:17 - INFO - __main__ - Global step 1850 Train loss 0.72 ACC 0.5 on epoch=924
06/24/2022 21:01:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.65 on epoch=929
06/24/2022 21:01:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.65 on epoch=934
06/24/2022 21:01:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.62 on epoch=939
06/24/2022 21:01:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.68 on epoch=944
06/24/2022 21:01:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.70 on epoch=949
06/24/2022 21:01:24 - INFO - __main__ - Global step 1900 Train loss 0.66 ACC 0.5 on epoch=949
06/24/2022 21:01:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.65 on epoch=954
06/24/2022 21:01:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.64 on epoch=959
06/24/2022 21:01:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.69 on epoch=964
06/24/2022 21:01:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.68 on epoch=969
06/24/2022 21:01:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.64 on epoch=974
06/24/2022 21:01:31 - INFO - __main__ - Global step 1950 Train loss 0.66 ACC 0.5 on epoch=974
06/24/2022 21:01:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.73 on epoch=979
06/24/2022 21:01:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.63 on epoch=984
06/24/2022 21:01:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.68 on epoch=989
06/24/2022 21:01:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.65 on epoch=994
06/24/2022 21:01:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.72 on epoch=999
06/24/2022 21:01:37 - INFO - __main__ - Global step 2000 Train loss 0.68 ACC 0.5 on epoch=999
06/24/2022 21:01:37 - INFO - __main__ - save last model!
06/24/2022 21:01:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 21:01:38 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 21:01:38 - INFO - __main__ - Printing 3 examples
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 21:01:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 21:01:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:01:38 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:01:38 - INFO - __main__ - Printing 3 examples
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:01:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:01:38 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 21:01:38 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:01:38 - INFO - __main__ - Printing 3 examples
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 21:01:38 - INFO - __main__ - ['duplicate']
06/24/2022 21:01:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:01:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:01:38 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 21:01:44 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:01:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 21:01:44 - INFO - __main__ - Starting training!
06/24/2022 21:01:56 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:02:37 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 21:14:46 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_100_0.2_8_predictions.txt
06/24/2022 21:14:46 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 21:14:46 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.2, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 21:14:46 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.5, bsz=8 ...
06/24/2022 21:14:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:14:47 - INFO - __main__ - Printing 3 examples
06/24/2022 21:14:47 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 21:14:47 - INFO - __main__ - ['duplicate']
06/24/2022 21:14:47 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 21:14:47 - INFO - __main__ - ['duplicate']
06/24/2022 21:14:47 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 21:14:47 - INFO - __main__ - ['duplicate']
06/24/2022 21:14:47 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:14:47 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:14:47 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 21:14:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:14:47 - INFO - __main__ - Printing 3 examples
06/24/2022 21:14:47 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 21:14:47 - INFO - __main__ - ['duplicate']
06/24/2022 21:14:47 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 21:14:47 - INFO - __main__ - ['duplicate']
06/24/2022 21:14:47 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 21:14:47 - INFO - __main__ - ['duplicate']
06/24/2022 21:14:47 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:14:47 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:14:47 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 21:14:53 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:14:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 21:14:53 - INFO - __main__ - Starting training!
06/24/2022 21:14:54 - INFO - __main__ - Step 10 Global step 10 Train loss 6.56 on epoch=4
06/24/2022 21:14:56 - INFO - __main__ - Step 20 Global step 20 Train loss 6.42 on epoch=9
06/24/2022 21:14:57 - INFO - __main__ - Step 30 Global step 30 Train loss 6.19 on epoch=14
06/24/2022 21:14:58 - INFO - __main__ - Step 40 Global step 40 Train loss 5.91 on epoch=19
06/24/2022 21:14:59 - INFO - __main__ - Step 50 Global step 50 Train loss 5.70 on epoch=24
06/24/2022 21:15:02 - INFO - __main__ - Global step 50 Train loss 6.16 ACC 0.0 on epoch=24
06/24/2022 21:15:02 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 21:15:03 - INFO - __main__ - Step 60 Global step 60 Train loss 5.40 on epoch=29
06/24/2022 21:15:04 - INFO - __main__ - Step 70 Global step 70 Train loss 5.15 on epoch=34
06/24/2022 21:15:05 - INFO - __main__ - Step 80 Global step 80 Train loss 4.90 on epoch=39
06/24/2022 21:15:07 - INFO - __main__ - Step 90 Global step 90 Train loss 4.77 on epoch=44
06/24/2022 21:15:08 - INFO - __main__ - Step 100 Global step 100 Train loss 4.60 on epoch=49
06/24/2022 21:15:09 - INFO - __main__ - Global step 100 Train loss 4.96 ACC 0.0 on epoch=49
06/24/2022 21:15:10 - INFO - __main__ - Step 110 Global step 110 Train loss 4.46 on epoch=54
06/24/2022 21:15:12 - INFO - __main__ - Step 120 Global step 120 Train loss 4.31 on epoch=59
06/24/2022 21:15:13 - INFO - __main__ - Step 130 Global step 130 Train loss 4.37 on epoch=64
06/24/2022 21:15:14 - INFO - __main__ - Step 140 Global step 140 Train loss 4.24 on epoch=69
06/24/2022 21:15:15 - INFO - __main__ - Step 150 Global step 150 Train loss 4.04 on epoch=74
06/24/2022 21:15:17 - INFO - __main__ - Global step 150 Train loss 4.28 ACC 0.0 on epoch=74
06/24/2022 21:15:18 - INFO - __main__ - Step 160 Global step 160 Train loss 3.90 on epoch=79
06/24/2022 21:15:19 - INFO - __main__ - Step 170 Global step 170 Train loss 3.82 on epoch=84
06/24/2022 21:15:20 - INFO - __main__ - Step 180 Global step 180 Train loss 3.76 on epoch=89
06/24/2022 21:15:22 - INFO - __main__ - Step 190 Global step 190 Train loss 3.46 on epoch=94
06/24/2022 21:15:23 - INFO - __main__ - Step 200 Global step 200 Train loss 3.30 on epoch=99
06/24/2022 21:15:24 - INFO - __main__ - Global step 200 Train loss 3.65 ACC 0.03125 on epoch=99
06/24/2022 21:15:24 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=99, global_step=200
06/24/2022 21:15:25 - INFO - __main__ - Step 210 Global step 210 Train loss 3.26 on epoch=104
06/24/2022 21:15:27 - INFO - __main__ - Step 220 Global step 220 Train loss 3.11 on epoch=109
06/24/2022 21:15:28 - INFO - __main__ - Step 230 Global step 230 Train loss 3.03 on epoch=114
06/24/2022 21:15:29 - INFO - __main__ - Step 240 Global step 240 Train loss 2.97 on epoch=119
06/24/2022 21:15:30 - INFO - __main__ - Step 250 Global step 250 Train loss 2.80 on epoch=124
06/24/2022 21:15:32 - INFO - __main__ - Global step 250 Train loss 3.03 ACC 0.3125 on epoch=124
06/24/2022 21:15:32 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.3125 on epoch=124, global_step=250
06/24/2022 21:15:33 - INFO - __main__ - Step 260 Global step 260 Train loss 2.73 on epoch=129
06/24/2022 21:15:35 - INFO - __main__ - Step 270 Global step 270 Train loss 2.62 on epoch=134
06/24/2022 21:15:36 - INFO - __main__ - Step 280 Global step 280 Train loss 2.51 on epoch=139
06/24/2022 21:15:37 - INFO - __main__ - Step 290 Global step 290 Train loss 2.48 on epoch=144
06/24/2022 21:15:38 - INFO - __main__ - Step 300 Global step 300 Train loss 2.32 on epoch=149
06/24/2022 21:15:42 - INFO - __main__ - Global step 300 Train loss 2.53 ACC 0.3125 on epoch=149
06/24/2022 21:15:43 - INFO - __main__ - Step 310 Global step 310 Train loss 2.30 on epoch=154
06/24/2022 21:15:44 - INFO - __main__ - Step 320 Global step 320 Train loss 2.20 on epoch=159
06/24/2022 21:15:45 - INFO - __main__ - Step 330 Global step 330 Train loss 2.12 on epoch=164
06/24/2022 21:15:47 - INFO - __main__ - Step 340 Global step 340 Train loss 2.05 on epoch=169
06/24/2022 21:15:48 - INFO - __main__ - Step 350 Global step 350 Train loss 2.09 on epoch=174
06/24/2022 21:15:49 - INFO - __main__ - Global step 350 Train loss 2.15 ACC 0.5 on epoch=174
06/24/2022 21:15:49 - INFO - __main__ - Saving model with best ACC: 0.3125 -> 0.5 on epoch=174, global_step=350
06/24/2022 21:15:51 - INFO - __main__ - Step 360 Global step 360 Train loss 1.92 on epoch=179
06/24/2022 21:15:52 - INFO - __main__ - Step 370 Global step 370 Train loss 2.04 on epoch=184
06/24/2022 21:15:53 - INFO - __main__ - Step 380 Global step 380 Train loss 1.91 on epoch=189
06/24/2022 21:15:54 - INFO - __main__ - Step 390 Global step 390 Train loss 1.79 on epoch=194
06/24/2022 21:15:56 - INFO - __main__ - Step 400 Global step 400 Train loss 1.75 on epoch=199
06/24/2022 21:15:58 - INFO - __main__ - Global step 400 Train loss 1.88 ACC 0.5 on epoch=199
06/24/2022 21:15:59 - INFO - __main__ - Step 410 Global step 410 Train loss 1.74 on epoch=204
06/24/2022 21:16:01 - INFO - __main__ - Step 420 Global step 420 Train loss 1.57 on epoch=209
06/24/2022 21:16:02 - INFO - __main__ - Step 430 Global step 430 Train loss 1.66 on epoch=214
06/24/2022 21:16:03 - INFO - __main__ - Step 440 Global step 440 Train loss 1.58 on epoch=219
06/24/2022 21:16:04 - INFO - __main__ - Step 450 Global step 450 Train loss 1.56 on epoch=224
06/24/2022 21:16:07 - INFO - __main__ - Global step 450 Train loss 1.62 ACC 0.5 on epoch=224
06/24/2022 21:16:08 - INFO - __main__ - Step 460 Global step 460 Train loss 1.63 on epoch=229
06/24/2022 21:16:09 - INFO - __main__ - Step 470 Global step 470 Train loss 1.46 on epoch=234
06/24/2022 21:16:10 - INFO - __main__ - Step 480 Global step 480 Train loss 1.41 on epoch=239
06/24/2022 21:16:12 - INFO - __main__ - Step 490 Global step 490 Train loss 1.37 on epoch=244
06/24/2022 21:16:13 - INFO - __main__ - Step 500 Global step 500 Train loss 1.19 on epoch=249
06/24/2022 21:16:14 - INFO - __main__ - Global step 500 Train loss 1.41 ACC 0.5 on epoch=249
06/24/2022 21:16:15 - INFO - __main__ - Step 510 Global step 510 Train loss 1.23 on epoch=254
06/24/2022 21:16:17 - INFO - __main__ - Step 520 Global step 520 Train loss 1.04 on epoch=259
06/24/2022 21:16:18 - INFO - __main__ - Step 530 Global step 530 Train loss 1.13 on epoch=264
06/24/2022 21:16:19 - INFO - __main__ - Step 540 Global step 540 Train loss 1.12 on epoch=269
06/24/2022 21:16:20 - INFO - __main__ - Step 550 Global step 550 Train loss 1.09 on epoch=274
06/24/2022 21:16:21 - INFO - __main__ - Global step 550 Train loss 1.12 ACC 0.5 on epoch=274
06/24/2022 21:16:22 - INFO - __main__ - Step 560 Global step 560 Train loss 1.02 on epoch=279
06/24/2022 21:16:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.87 on epoch=284
06/24/2022 21:16:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.96 on epoch=289
06/24/2022 21:16:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.90 on epoch=294
06/24/2022 21:16:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.85 on epoch=299
06/24/2022 21:16:29 - INFO - __main__ - Global step 600 Train loss 0.92 ACC 0.5 on epoch=299
06/24/2022 21:16:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.90 on epoch=304
06/24/2022 21:16:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.87 on epoch=309
06/24/2022 21:16:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.93 on epoch=314
06/24/2022 21:16:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.96 on epoch=319
06/24/2022 21:16:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.77 on epoch=324
06/24/2022 21:16:36 - INFO - __main__ - Global step 650 Train loss 0.89 ACC 0.5 on epoch=324
06/24/2022 21:16:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.81 on epoch=329
06/24/2022 21:16:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.87 on epoch=334
06/24/2022 21:16:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.80 on epoch=339
06/24/2022 21:16:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.77 on epoch=344
06/24/2022 21:16:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.83 on epoch=349
06/24/2022 21:16:42 - INFO - __main__ - Global step 700 Train loss 0.82 ACC 0.5 on epoch=349
06/24/2022 21:16:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.71 on epoch=354
06/24/2022 21:16:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.75 on epoch=359
06/24/2022 21:16:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.70 on epoch=364
06/24/2022 21:16:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.66 on epoch=369
06/24/2022 21:16:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.74 on epoch=374
06/24/2022 21:16:49 - INFO - __main__ - Global step 750 Train loss 0.71 ACC 0.5 on epoch=374
06/24/2022 21:16:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.68 on epoch=379
06/24/2022 21:16:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.87 on epoch=384
06/24/2022 21:16:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.65 on epoch=389
06/24/2022 21:16:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.67 on epoch=394
06/24/2022 21:16:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.68 on epoch=399
06/24/2022 21:16:55 - INFO - __main__ - Global step 800 Train loss 0.71 ACC 0.5 on epoch=399
06/24/2022 21:16:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.74 on epoch=404
06/24/2022 21:16:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.73 on epoch=409
06/24/2022 21:16:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.59 on epoch=414
06/24/2022 21:17:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.64 on epoch=419
06/24/2022 21:17:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.64 on epoch=424
06/24/2022 21:17:02 - INFO - __main__ - Global step 850 Train loss 0.67 ACC 0.5 on epoch=424
06/24/2022 21:17:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.59 on epoch=429
06/24/2022 21:17:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.59 on epoch=434
06/24/2022 21:17:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.70 on epoch=439
06/24/2022 21:17:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.55 on epoch=444
06/24/2022 21:17:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.54 on epoch=449
06/24/2022 21:17:09 - INFO - __main__ - Global step 900 Train loss 0.59 ACC 0.5 on epoch=449
06/24/2022 21:17:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.63 on epoch=454
06/24/2022 21:17:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.51 on epoch=459
06/24/2022 21:17:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.56 on epoch=464
06/24/2022 21:17:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.57 on epoch=469
06/24/2022 21:17:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.56 on epoch=474
06/24/2022 21:17:15 - INFO - __main__ - Global step 950 Train loss 0.57 ACC 0.5 on epoch=474
06/24/2022 21:17:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.62 on epoch=479
06/24/2022 21:17:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.59 on epoch=484
06/24/2022 21:17:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.57 on epoch=489
06/24/2022 21:17:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.62 on epoch=494
06/24/2022 21:17:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.58 on epoch=499
06/24/2022 21:17:22 - INFO - __main__ - Global step 1000 Train loss 0.60 ACC 0.5 on epoch=499
06/24/2022 21:17:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.49 on epoch=504
06/24/2022 21:17:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.61 on epoch=509
06/24/2022 21:17:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.57 on epoch=514
06/24/2022 21:17:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.58 on epoch=519
06/24/2022 21:17:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.59 on epoch=524
06/24/2022 21:17:29 - INFO - __main__ - Global step 1050 Train loss 0.57 ACC 0.5 on epoch=524
06/24/2022 21:17:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.51 on epoch=529
06/24/2022 21:17:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.55 on epoch=534
06/24/2022 21:17:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.42 on epoch=539
06/24/2022 21:17:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.44 on epoch=544
06/24/2022 21:17:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.44 on epoch=549
06/24/2022 21:17:36 - INFO - __main__ - Global step 1100 Train loss 0.47 ACC 0.5 on epoch=549
06/24/2022 21:17:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.44 on epoch=554
06/24/2022 21:17:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.47 on epoch=559
06/24/2022 21:17:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.47 on epoch=564
06/24/2022 21:17:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.48 on epoch=569
06/24/2022 21:17:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.50 on epoch=574
06/24/2022 21:17:42 - INFO - __main__ - Global step 1150 Train loss 0.47 ACC 0.5 on epoch=574
06/24/2022 21:17:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.48 on epoch=579
06/24/2022 21:17:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.51 on epoch=584
06/24/2022 21:17:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.46 on epoch=589
06/24/2022 21:17:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.43 on epoch=594
06/24/2022 21:17:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.53 on epoch=599
06/24/2022 21:17:49 - INFO - __main__ - Global step 1200 Train loss 0.48 ACC 0.5 on epoch=599
06/24/2022 21:17:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.44 on epoch=604
06/24/2022 21:17:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.41 on epoch=609
06/24/2022 21:17:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.50 on epoch=614
06/24/2022 21:17:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.48 on epoch=619
06/24/2022 21:17:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.47 on epoch=624
06/24/2022 21:17:56 - INFO - __main__ - Global step 1250 Train loss 0.46 ACC 0.5 on epoch=624
06/24/2022 21:17:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.37 on epoch=629
06/24/2022 21:17:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.50 on epoch=634
06/24/2022 21:18:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.39 on epoch=639
06/24/2022 21:18:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.42 on epoch=644
06/24/2022 21:18:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.61 on epoch=649
06/24/2022 21:18:03 - INFO - __main__ - Global step 1300 Train loss 0.46 ACC 0.5 on epoch=649
06/24/2022 21:18:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.45 on epoch=654
06/24/2022 21:18:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.42 on epoch=659
06/24/2022 21:18:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.45 on epoch=664
06/24/2022 21:18:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.46 on epoch=669
06/24/2022 21:18:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.42 on epoch=674
06/24/2022 21:18:10 - INFO - __main__ - Global step 1350 Train loss 0.44 ACC 0.5 on epoch=674
06/24/2022 21:18:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.41 on epoch=679
06/24/2022 21:18:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.40 on epoch=684
06/24/2022 21:18:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.44 on epoch=689
06/24/2022 21:18:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.39 on epoch=694
06/24/2022 21:18:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.40 on epoch=699
06/24/2022 21:18:16 - INFO - __main__ - Global step 1400 Train loss 0.41 ACC 0.5 on epoch=699
06/24/2022 21:18:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.42 on epoch=704
06/24/2022 21:18:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.43 on epoch=709
06/24/2022 21:18:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.45 on epoch=714
06/24/2022 21:18:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.39 on epoch=719
06/24/2022 21:18:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.45 on epoch=724
06/24/2022 21:18:23 - INFO - __main__ - Global step 1450 Train loss 0.43 ACC 0.5 on epoch=724
06/24/2022 21:18:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.37 on epoch=729
06/24/2022 21:18:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.43 on epoch=734
06/24/2022 21:18:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.37 on epoch=739
06/24/2022 21:18:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.38 on epoch=744
06/24/2022 21:18:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.36 on epoch=749
06/24/2022 21:18:30 - INFO - __main__ - Global step 1500 Train loss 0.39 ACC 0.5 on epoch=749
06/24/2022 21:18:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.42 on epoch=754
06/24/2022 21:18:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.36 on epoch=759
06/24/2022 21:18:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.46 on epoch=764
06/24/2022 21:18:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.44 on epoch=769
06/24/2022 21:18:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.42 on epoch=774
06/24/2022 21:18:37 - INFO - __main__ - Global step 1550 Train loss 0.42 ACC 0.5 on epoch=774
06/24/2022 21:18:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.46 on epoch=779
06/24/2022 21:18:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.42 on epoch=784
06/24/2022 21:18:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.48 on epoch=789
06/24/2022 21:18:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.33 on epoch=794
06/24/2022 21:18:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.42 on epoch=799
06/24/2022 21:18:44 - INFO - __main__ - Global step 1600 Train loss 0.42 ACC 0.5 on epoch=799
06/24/2022 21:18:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.33 on epoch=804
06/24/2022 21:18:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.41 on epoch=809
06/24/2022 21:18:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.42 on epoch=814
06/24/2022 21:18:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.35 on epoch=819
06/24/2022 21:18:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.41 on epoch=824
06/24/2022 21:18:51 - INFO - __main__ - Global step 1650 Train loss 0.38 ACC 0.5 on epoch=824
06/24/2022 21:18:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.35 on epoch=829
06/24/2022 21:18:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.40 on epoch=834
06/24/2022 21:18:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.49 on epoch=839
06/24/2022 21:18:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.39 on epoch=844
06/24/2022 21:18:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.37 on epoch=849
06/24/2022 21:18:57 - INFO - __main__ - Global step 1700 Train loss 0.40 ACC 0.5 on epoch=849
06/24/2022 21:18:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.32 on epoch=854
06/24/2022 21:19:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.36 on epoch=859
06/24/2022 21:19:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.39 on epoch=864
06/24/2022 21:19:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.39 on epoch=869
06/24/2022 21:19:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.32 on epoch=874
06/24/2022 21:19:04 - INFO - __main__ - Global step 1750 Train loss 0.35 ACC 0.5 on epoch=874
06/24/2022 21:19:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.35 on epoch=879
06/24/2022 21:19:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.32 on epoch=884
06/24/2022 21:19:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.37 on epoch=889
06/24/2022 21:19:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.35 on epoch=894
06/24/2022 21:19:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.39 on epoch=899
06/24/2022 21:19:11 - INFO - __main__ - Global step 1800 Train loss 0.36 ACC 0.5 on epoch=899
06/24/2022 21:19:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.38 on epoch=904
06/24/2022 21:19:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.30 on epoch=909
06/24/2022 21:19:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.38 on epoch=914
06/24/2022 21:19:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.35 on epoch=919
06/24/2022 21:19:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.38 on epoch=924
06/24/2022 21:19:18 - INFO - __main__ - Global step 1850 Train loss 0.36 ACC 0.5 on epoch=924
06/24/2022 21:19:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.37 on epoch=929
06/24/2022 21:19:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.42 on epoch=934
06/24/2022 21:19:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.39 on epoch=939
06/24/2022 21:19:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.41 on epoch=944
06/24/2022 21:19:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.38 on epoch=949
06/24/2022 21:19:25 - INFO - __main__ - Global step 1900 Train loss 0.39 ACC 0.5 on epoch=949
06/24/2022 21:19:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.36 on epoch=954
06/24/2022 21:19:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.41 on epoch=959
06/24/2022 21:19:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.34 on epoch=964
06/24/2022 21:19:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.32 on epoch=969
06/24/2022 21:19:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.40 on epoch=974
06/24/2022 21:19:32 - INFO - __main__ - Global step 1950 Train loss 0.37 ACC 0.5 on epoch=974
06/24/2022 21:19:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.33 on epoch=979
06/24/2022 21:19:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.37 on epoch=984
06/24/2022 21:19:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.35 on epoch=989
06/24/2022 21:19:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.38 on epoch=994
06/24/2022 21:19:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.30 on epoch=999
06/24/2022 21:19:39 - INFO - __main__ - Global step 2000 Train loss 0.35 ACC 0.5 on epoch=999
06/24/2022 21:19:39 - INFO - __main__ - save last model!
06/24/2022 21:19:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 21:19:39 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 21:19:39 - INFO - __main__ - Printing 3 examples
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 21:19:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 21:19:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:19:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:19:39 - INFO - __main__ - Printing 3 examples
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:19:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:19:39 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 21:19:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:19:39 - INFO - __main__ - Printing 3 examples
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 21:19:39 - INFO - __main__ - ['duplicate']
06/24/2022 21:19:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:19:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:19:39 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 21:19:45 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:19:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 21:19:45 - INFO - __main__ - Starting training!
06/24/2022 21:19:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:20:38 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 21:32:53 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_13_0.5_8_predictions.txt
06/24/2022 21:32:53 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 21:32:53 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.5, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 21:32:53 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.4, bsz=8 ...
06/24/2022 21:32:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:32:54 - INFO - __main__ - Printing 3 examples
06/24/2022 21:32:54 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 21:32:54 - INFO - __main__ - ['duplicate']
06/24/2022 21:32:54 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 21:32:54 - INFO - __main__ - ['duplicate']
06/24/2022 21:32:54 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 21:32:54 - INFO - __main__ - ['duplicate']
06/24/2022 21:32:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:32:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:32:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 21:32:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:32:54 - INFO - __main__ - Printing 3 examples
06/24/2022 21:32:54 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 21:32:54 - INFO - __main__ - ['duplicate']
06/24/2022 21:32:54 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 21:32:54 - INFO - __main__ - ['duplicate']
06/24/2022 21:32:54 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 21:32:54 - INFO - __main__ - ['duplicate']
06/24/2022 21:32:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:32:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:32:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 21:32:59 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:33:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 21:33:00 - INFO - __main__ - Starting training!
06/24/2022 21:33:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.52 on epoch=4
06/24/2022 21:33:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.36 on epoch=9
06/24/2022 21:33:04 - INFO - __main__ - Step 30 Global step 30 Train loss 6.13 on epoch=14
06/24/2022 21:33:05 - INFO - __main__ - Step 40 Global step 40 Train loss 5.82 on epoch=19
06/24/2022 21:33:06 - INFO - __main__ - Step 50 Global step 50 Train loss 5.64 on epoch=24
06/24/2022 21:33:07 - INFO - __main__ - Global step 50 Train loss 6.09 ACC 0.0 on epoch=24
06/24/2022 21:33:07 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 21:33:09 - INFO - __main__ - Step 60 Global step 60 Train loss 5.42 on epoch=29
06/24/2022 21:33:10 - INFO - __main__ - Step 70 Global step 70 Train loss 5.24 on epoch=34
06/24/2022 21:33:11 - INFO - __main__ - Step 80 Global step 80 Train loss 5.27 on epoch=39
06/24/2022 21:33:12 - INFO - __main__ - Step 90 Global step 90 Train loss 5.14 on epoch=44
06/24/2022 21:33:14 - INFO - __main__ - Step 100 Global step 100 Train loss 5.02 on epoch=49
06/24/2022 21:33:15 - INFO - __main__ - Global step 100 Train loss 5.22 ACC 0.0 on epoch=49
06/24/2022 21:33:16 - INFO - __main__ - Step 110 Global step 110 Train loss 4.81 on epoch=54
06/24/2022 21:33:17 - INFO - __main__ - Step 120 Global step 120 Train loss 4.96 on epoch=59
06/24/2022 21:33:19 - INFO - __main__ - Step 130 Global step 130 Train loss 4.72 on epoch=64
06/24/2022 21:33:20 - INFO - __main__ - Step 140 Global step 140 Train loss 4.81 on epoch=69
06/24/2022 21:33:21 - INFO - __main__ - Step 150 Global step 150 Train loss 4.71 on epoch=74
06/24/2022 21:33:22 - INFO - __main__ - Global step 150 Train loss 4.80 ACC 0.0 on epoch=74
06/24/2022 21:33:24 - INFO - __main__ - Step 160 Global step 160 Train loss 4.54 on epoch=79
06/24/2022 21:33:25 - INFO - __main__ - Step 170 Global step 170 Train loss 4.36 on epoch=84
06/24/2022 21:33:26 - INFO - __main__ - Step 180 Global step 180 Train loss 4.31 on epoch=89
06/24/2022 21:33:27 - INFO - __main__ - Step 190 Global step 190 Train loss 4.30 on epoch=94
06/24/2022 21:33:29 - INFO - __main__ - Step 200 Global step 200 Train loss 4.22 on epoch=99
06/24/2022 21:33:30 - INFO - __main__ - Global step 200 Train loss 4.35 ACC 0.0 on epoch=99
06/24/2022 21:33:31 - INFO - __main__ - Step 210 Global step 210 Train loss 4.13 on epoch=104
06/24/2022 21:33:32 - INFO - __main__ - Step 220 Global step 220 Train loss 4.00 on epoch=109
06/24/2022 21:33:34 - INFO - __main__ - Step 230 Global step 230 Train loss 4.03 on epoch=114
06/24/2022 21:33:35 - INFO - __main__ - Step 240 Global step 240 Train loss 3.88 on epoch=119
06/24/2022 21:33:36 - INFO - __main__ - Step 250 Global step 250 Train loss 3.79 on epoch=124
06/24/2022 21:33:37 - INFO - __main__ - Global step 250 Train loss 3.96 ACC 0.0 on epoch=124
06/24/2022 21:33:38 - INFO - __main__ - Step 260 Global step 260 Train loss 3.72 on epoch=129
06/24/2022 21:33:40 - INFO - __main__ - Step 270 Global step 270 Train loss 3.79 on epoch=134
06/24/2022 21:33:41 - INFO - __main__ - Step 280 Global step 280 Train loss 3.59 on epoch=139
06/24/2022 21:33:42 - INFO - __main__ - Step 290 Global step 290 Train loss 3.56 on epoch=144
06/24/2022 21:33:43 - INFO - __main__ - Step 300 Global step 300 Train loss 3.47 on epoch=149
06/24/2022 21:33:46 - INFO - __main__ - Global step 300 Train loss 3.63 ACC 0.0 on epoch=149
06/24/2022 21:33:47 - INFO - __main__ - Step 310 Global step 310 Train loss 3.34 on epoch=154
06/24/2022 21:33:48 - INFO - __main__ - Step 320 Global step 320 Train loss 3.40 on epoch=159
06/24/2022 21:33:50 - INFO - __main__ - Step 330 Global step 330 Train loss 3.33 on epoch=164
06/24/2022 21:33:51 - INFO - __main__ - Step 340 Global step 340 Train loss 3.15 on epoch=169
06/24/2022 21:33:52 - INFO - __main__ - Step 350 Global step 350 Train loss 3.17 on epoch=174
06/24/2022 21:33:56 - INFO - __main__ - Global step 350 Train loss 3.28 ACC 0.0 on epoch=174
06/24/2022 21:33:57 - INFO - __main__ - Step 360 Global step 360 Train loss 3.11 on epoch=179
06/24/2022 21:33:59 - INFO - __main__ - Step 370 Global step 370 Train loss 3.03 on epoch=184
06/24/2022 21:34:00 - INFO - __main__ - Step 380 Global step 380 Train loss 3.02 on epoch=189
06/24/2022 21:34:01 - INFO - __main__ - Step 390 Global step 390 Train loss 2.81 on epoch=194
06/24/2022 21:34:02 - INFO - __main__ - Step 400 Global step 400 Train loss 2.73 on epoch=199
06/24/2022 21:34:04 - INFO - __main__ - Global step 400 Train loss 2.94 ACC 0.03125 on epoch=199
06/24/2022 21:34:04 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=199, global_step=400
06/24/2022 21:34:05 - INFO - __main__ - Step 410 Global step 410 Train loss 2.68 on epoch=204
06/24/2022 21:34:06 - INFO - __main__ - Step 420 Global step 420 Train loss 2.75 on epoch=209
06/24/2022 21:34:08 - INFO - __main__ - Step 430 Global step 430 Train loss 2.58 on epoch=214
06/24/2022 21:34:09 - INFO - __main__ - Step 440 Global step 440 Train loss 2.54 on epoch=219
06/24/2022 21:34:10 - INFO - __main__ - Step 450 Global step 450 Train loss 2.57 on epoch=224
06/24/2022 21:34:12 - INFO - __main__ - Global step 450 Train loss 2.62 ACC 0.46875 on epoch=224
06/24/2022 21:34:12 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.46875 on epoch=224, global_step=450
06/24/2022 21:34:13 - INFO - __main__ - Step 460 Global step 460 Train loss 2.38 on epoch=229
06/24/2022 21:34:14 - INFO - __main__ - Step 470 Global step 470 Train loss 2.43 on epoch=234
06/24/2022 21:34:16 - INFO - __main__ - Step 480 Global step 480 Train loss 2.30 on epoch=239
06/24/2022 21:34:17 - INFO - __main__ - Step 490 Global step 490 Train loss 2.25 on epoch=244
06/24/2022 21:34:18 - INFO - __main__ - Step 500 Global step 500 Train loss 2.07 on epoch=249
06/24/2022 21:34:19 - INFO - __main__ - Global step 500 Train loss 2.28 ACC 0.5 on epoch=249
06/24/2022 21:34:19 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=249, global_step=500
06/24/2022 21:34:20 - INFO - __main__ - Step 510 Global step 510 Train loss 2.07 on epoch=254
06/24/2022 21:34:22 - INFO - __main__ - Step 520 Global step 520 Train loss 2.25 on epoch=259
06/24/2022 21:34:23 - INFO - __main__ - Step 530 Global step 530 Train loss 2.05 on epoch=264
06/24/2022 21:34:24 - INFO - __main__ - Step 540 Global step 540 Train loss 2.04 on epoch=269
06/24/2022 21:34:25 - INFO - __main__ - Step 550 Global step 550 Train loss 1.98 on epoch=274
06/24/2022 21:34:27 - INFO - __main__ - Global step 550 Train loss 2.08 ACC 0.5 on epoch=274
06/24/2022 21:34:28 - INFO - __main__ - Step 560 Global step 560 Train loss 1.98 on epoch=279
06/24/2022 21:34:29 - INFO - __main__ - Step 570 Global step 570 Train loss 2.04 on epoch=284
06/24/2022 21:34:30 - INFO - __main__ - Step 580 Global step 580 Train loss 1.85 on epoch=289
06/24/2022 21:34:32 - INFO - __main__ - Step 590 Global step 590 Train loss 1.80 on epoch=294
06/24/2022 21:34:33 - INFO - __main__ - Step 600 Global step 600 Train loss 1.80 on epoch=299
06/24/2022 21:34:35 - INFO - __main__ - Global step 600 Train loss 1.89 ACC 0.5 on epoch=299
06/24/2022 21:34:36 - INFO - __main__ - Step 610 Global step 610 Train loss 1.79 on epoch=304
06/24/2022 21:34:38 - INFO - __main__ - Step 620 Global step 620 Train loss 1.73 on epoch=309
06/24/2022 21:34:39 - INFO - __main__ - Step 630 Global step 630 Train loss 1.71 on epoch=314
06/24/2022 21:34:40 - INFO - __main__ - Step 640 Global step 640 Train loss 1.55 on epoch=319
06/24/2022 21:34:42 - INFO - __main__ - Step 650 Global step 650 Train loss 1.67 on epoch=324
06/24/2022 21:34:48 - INFO - __main__ - Global step 650 Train loss 1.69 ACC 0.4375 on epoch=324
06/24/2022 21:34:49 - INFO - __main__ - Step 660 Global step 660 Train loss 1.67 on epoch=329
06/24/2022 21:34:50 - INFO - __main__ - Step 670 Global step 670 Train loss 1.39 on epoch=334
06/24/2022 21:34:51 - INFO - __main__ - Step 680 Global step 680 Train loss 1.54 on epoch=339
06/24/2022 21:34:53 - INFO - __main__ - Step 690 Global step 690 Train loss 1.55 on epoch=344
06/24/2022 21:34:54 - INFO - __main__ - Step 700 Global step 700 Train loss 1.38 on epoch=349
06/24/2022 21:34:55 - INFO - __main__ - Global step 700 Train loss 1.51 ACC 0.5 on epoch=349
06/24/2022 21:34:56 - INFO - __main__ - Step 710 Global step 710 Train loss 1.39 on epoch=354
06/24/2022 21:34:58 - INFO - __main__ - Step 720 Global step 720 Train loss 1.46 on epoch=359
06/24/2022 21:34:59 - INFO - __main__ - Step 730 Global step 730 Train loss 1.29 on epoch=364
06/24/2022 21:35:00 - INFO - __main__ - Step 740 Global step 740 Train loss 1.31 on epoch=369
06/24/2022 21:35:01 - INFO - __main__ - Step 750 Global step 750 Train loss 1.31 on epoch=374
06/24/2022 21:35:03 - INFO - __main__ - Global step 750 Train loss 1.35 ACC 0.5 on epoch=374
06/24/2022 21:35:04 - INFO - __main__ - Step 760 Global step 760 Train loss 1.26 on epoch=379
06/24/2022 21:35:05 - INFO - __main__ - Step 770 Global step 770 Train loss 1.28 on epoch=384
06/24/2022 21:35:07 - INFO - __main__ - Step 780 Global step 780 Train loss 1.16 on epoch=389
06/24/2022 21:35:08 - INFO - __main__ - Step 790 Global step 790 Train loss 1.22 on epoch=394
06/24/2022 21:35:09 - INFO - __main__ - Step 800 Global step 800 Train loss 1.12 on epoch=399
06/24/2022 21:35:10 - INFO - __main__ - Global step 800 Train loss 1.21 ACC 0.5 on epoch=399
06/24/2022 21:35:12 - INFO - __main__ - Step 810 Global step 810 Train loss 1.13 on epoch=404
06/24/2022 21:35:13 - INFO - __main__ - Step 820 Global step 820 Train loss 1.08 on epoch=409
06/24/2022 21:35:14 - INFO - __main__ - Step 830 Global step 830 Train loss 1.09 on epoch=414
06/24/2022 21:35:15 - INFO - __main__ - Step 840 Global step 840 Train loss 1.12 on epoch=419
06/24/2022 21:35:17 - INFO - __main__ - Step 850 Global step 850 Train loss 1.05 on epoch=424
06/24/2022 21:35:19 - INFO - __main__ - Global step 850 Train loss 1.09 ACC 0.5 on epoch=424
06/24/2022 21:35:20 - INFO - __main__ - Step 860 Global step 860 Train loss 1.10 on epoch=429
06/24/2022 21:35:21 - INFO - __main__ - Step 870 Global step 870 Train loss 1.04 on epoch=434
06/24/2022 21:35:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.99 on epoch=439
06/24/2022 21:35:24 - INFO - __main__ - Step 890 Global step 890 Train loss 1.01 on epoch=444
06/24/2022 21:35:25 - INFO - __main__ - Step 900 Global step 900 Train loss 1.07 on epoch=449
06/24/2022 21:35:27 - INFO - __main__ - Global step 900 Train loss 1.04 ACC 0.5 on epoch=449
06/24/2022 21:35:28 - INFO - __main__ - Step 910 Global step 910 Train loss 1.00 on epoch=454
06/24/2022 21:35:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.92 on epoch=459
06/24/2022 21:35:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.87 on epoch=464
06/24/2022 21:35:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.80 on epoch=469
06/24/2022 21:35:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.94 on epoch=474
06/24/2022 21:35:35 - INFO - __main__ - Global step 950 Train loss 0.91 ACC 0.5 on epoch=474
06/24/2022 21:35:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.89 on epoch=479
06/24/2022 21:35:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.89 on epoch=484
06/24/2022 21:35:39 - INFO - __main__ - Step 980 Global step 980 Train loss 1.00 on epoch=489
06/24/2022 21:35:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.88 on epoch=494
06/24/2022 21:35:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.83 on epoch=499
06/24/2022 21:35:43 - INFO - __main__ - Global step 1000 Train loss 0.90 ACC 0.5 on epoch=499
06/24/2022 21:35:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.76 on epoch=504
06/24/2022 21:35:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.83 on epoch=509
06/24/2022 21:35:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.80 on epoch=514
06/24/2022 21:35:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.82 on epoch=519
06/24/2022 21:35:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.76 on epoch=524
06/24/2022 21:35:51 - INFO - __main__ - Global step 1050 Train loss 0.80 ACC 0.5 on epoch=524
06/24/2022 21:35:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.71 on epoch=529
06/24/2022 21:35:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.81 on epoch=534
06/24/2022 21:35:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.84 on epoch=539
06/24/2022 21:35:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.75 on epoch=544
06/24/2022 21:35:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.71 on epoch=549
06/24/2022 21:36:00 - INFO - __main__ - Global step 1100 Train loss 0.76 ACC 0.5 on epoch=549
06/24/2022 21:36:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.75 on epoch=554
06/24/2022 21:36:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.83 on epoch=559
06/24/2022 21:36:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.71 on epoch=564
06/24/2022 21:36:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.71 on epoch=569
06/24/2022 21:36:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.73 on epoch=574
06/24/2022 21:36:09 - INFO - __main__ - Global step 1150 Train loss 0.75 ACC 0.5 on epoch=574
06/24/2022 21:36:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.71 on epoch=579
06/24/2022 21:36:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.68 on epoch=584
06/24/2022 21:36:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.64 on epoch=589
06/24/2022 21:36:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.67 on epoch=594
06/24/2022 21:36:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.69 on epoch=599
06/24/2022 21:36:17 - INFO - __main__ - Global step 1200 Train loss 0.68 ACC 0.5 on epoch=599
06/24/2022 21:36:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.67 on epoch=604
06/24/2022 21:36:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.66 on epoch=609
06/24/2022 21:36:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.62 on epoch=614
06/24/2022 21:36:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.70 on epoch=619
06/24/2022 21:36:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.62 on epoch=624
06/24/2022 21:36:30 - INFO - __main__ - Global step 1250 Train loss 0.66 ACC 0.5 on epoch=624
06/24/2022 21:36:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.70 on epoch=629
06/24/2022 21:36:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.58 on epoch=634
06/24/2022 21:36:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.58 on epoch=639
06/24/2022 21:36:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.63 on epoch=644
06/24/2022 21:36:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.58 on epoch=649
06/24/2022 21:36:39 - INFO - __main__ - Global step 1300 Train loss 0.61 ACC 0.5 on epoch=649
06/24/2022 21:36:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.47 on epoch=654
06/24/2022 21:36:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.60 on epoch=659
06/24/2022 21:36:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.58 on epoch=664
06/24/2022 21:36:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.56 on epoch=669
06/24/2022 21:36:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.59 on epoch=674
06/24/2022 21:36:48 - INFO - __main__ - Global step 1350 Train loss 0.56 ACC 0.5 on epoch=674
06/24/2022 21:36:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.56 on epoch=679
06/24/2022 21:36:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.51 on epoch=684
06/24/2022 21:36:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.61 on epoch=689
06/24/2022 21:36:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.60 on epoch=694
06/24/2022 21:36:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.64 on epoch=699
06/24/2022 21:36:58 - INFO - __main__ - Global step 1400 Train loss 0.58 ACC 0.5 on epoch=699
06/24/2022 21:36:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.54 on epoch=704
06/24/2022 21:37:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.60 on epoch=709
06/24/2022 21:37:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.57 on epoch=714
06/24/2022 21:37:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.53 on epoch=719
06/24/2022 21:37:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.59 on epoch=724
06/24/2022 21:37:07 - INFO - __main__ - Global step 1450 Train loss 0.57 ACC 0.5 on epoch=724
06/24/2022 21:37:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.63 on epoch=729
06/24/2022 21:37:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.47 on epoch=734
06/24/2022 21:37:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.64 on epoch=739
06/24/2022 21:37:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.54 on epoch=744
06/24/2022 21:37:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.67 on epoch=749
06/24/2022 21:37:18 - INFO - __main__ - Global step 1500 Train loss 0.59 ACC 0.5 on epoch=749
06/24/2022 21:37:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.61 on epoch=754
06/24/2022 21:37:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.54 on epoch=759
06/24/2022 21:37:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.58 on epoch=764
06/24/2022 21:37:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.54 on epoch=769
06/24/2022 21:37:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.57 on epoch=774
06/24/2022 21:37:26 - INFO - __main__ - Global step 1550 Train loss 0.57 ACC 0.5 on epoch=774
06/24/2022 21:37:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.55 on epoch=779
06/24/2022 21:37:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.58 on epoch=784
06/24/2022 21:37:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.56 on epoch=789
06/24/2022 21:37:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.58 on epoch=794
06/24/2022 21:37:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.54 on epoch=799
06/24/2022 21:37:35 - INFO - __main__ - Global step 1600 Train loss 0.56 ACC 0.5 on epoch=799
06/24/2022 21:37:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.52 on epoch=804
06/24/2022 21:37:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.46 on epoch=809
06/24/2022 21:37:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.49 on epoch=814
06/24/2022 21:37:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.54 on epoch=819
06/24/2022 21:37:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.45 on epoch=824
06/24/2022 21:37:43 - INFO - __main__ - Global step 1650 Train loss 0.49 ACC 0.5 on epoch=824
06/24/2022 21:37:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.47 on epoch=829
06/24/2022 21:37:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.48 on epoch=834
06/24/2022 21:37:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.46 on epoch=839
06/24/2022 21:37:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.44 on epoch=844
06/24/2022 21:37:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.44 on epoch=849
06/24/2022 21:37:50 - INFO - __main__ - Global step 1700 Train loss 0.46 ACC 0.5 on epoch=849
06/24/2022 21:37:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.51 on epoch=854
06/24/2022 21:37:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.41 on epoch=859
06/24/2022 21:37:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.50 on epoch=864
06/24/2022 21:37:55 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.39 on epoch=869
06/24/2022 21:37:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.44 on epoch=874
06/24/2022 21:37:58 - INFO - __main__ - Global step 1750 Train loss 0.45 ACC 0.5 on epoch=874
06/24/2022 21:37:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.45 on epoch=879
06/24/2022 21:38:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.50 on epoch=884
06/24/2022 21:38:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.46 on epoch=889
06/24/2022 21:38:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.41 on epoch=894
06/24/2022 21:38:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.46 on epoch=899
06/24/2022 21:38:05 - INFO - __main__ - Global step 1800 Train loss 0.46 ACC 0.5 on epoch=899
06/24/2022 21:38:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.41 on epoch=904
06/24/2022 21:38:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.45 on epoch=909
06/24/2022 21:38:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.47 on epoch=914
06/24/2022 21:38:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.40 on epoch=919
06/24/2022 21:38:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.49 on epoch=924
06/24/2022 21:38:12 - INFO - __main__ - Global step 1850 Train loss 0.44 ACC 0.5 on epoch=924
06/24/2022 21:38:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.46 on epoch=929
06/24/2022 21:38:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.44 on epoch=934
06/24/2022 21:38:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.43 on epoch=939
06/24/2022 21:38:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.45 on epoch=944
06/24/2022 21:38:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.39 on epoch=949
06/24/2022 21:38:19 - INFO - __main__ - Global step 1900 Train loss 0.43 ACC 0.5 on epoch=949
06/24/2022 21:38:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.48 on epoch=954
06/24/2022 21:38:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.46 on epoch=959
06/24/2022 21:38:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.45 on epoch=964
06/24/2022 21:38:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.49 on epoch=969
06/24/2022 21:38:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.49 on epoch=974
06/24/2022 21:38:27 - INFO - __main__ - Global step 1950 Train loss 0.47 ACC 0.5 on epoch=974
06/24/2022 21:38:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.48 on epoch=979
06/24/2022 21:38:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.43 on epoch=984
06/24/2022 21:38:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.40 on epoch=989
06/24/2022 21:38:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.42 on epoch=994
06/24/2022 21:38:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.48 on epoch=999
06/24/2022 21:38:34 - INFO - __main__ - Global step 2000 Train loss 0.44 ACC 0.5 on epoch=999
06/24/2022 21:38:34 - INFO - __main__ - save last model!
06/24/2022 21:38:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 21:38:35 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 21:38:35 - INFO - __main__ - Printing 3 examples
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 21:38:35 - INFO - __main__ - ['not_duplicate']
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 21:38:35 - INFO - __main__ - ['not_duplicate']
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:38:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:38:35 - INFO - __main__ - Printing 3 examples
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:38:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:38:35 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 21:38:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:38:35 - INFO - __main__ - Printing 3 examples
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 21:38:35 - INFO - __main__ - ['duplicate']
06/24/2022 21:38:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:38:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:38:35 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 21:38:40 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:38:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 21:38:40 - INFO - __main__ - Starting training!
06/24/2022 21:38:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:39:36 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 21:57:16 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_13_0.4_8_predictions.txt
06/24/2022 21:57:16 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 21:57:16 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.4, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 21:57:16 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.3, bsz=8 ...
06/24/2022 21:57:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:57:17 - INFO - __main__ - Printing 3 examples
06/24/2022 21:57:17 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 21:57:17 - INFO - __main__ - ['duplicate']
06/24/2022 21:57:17 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 21:57:17 - INFO - __main__ - ['duplicate']
06/24/2022 21:57:17 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 21:57:17 - INFO - __main__ - ['duplicate']
06/24/2022 21:57:17 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:57:17 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:57:17 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 21:57:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 21:57:17 - INFO - __main__ - Printing 3 examples
06/24/2022 21:57:17 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 21:57:17 - INFO - __main__ - ['duplicate']
06/24/2022 21:57:17 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 21:57:17 - INFO - __main__ - ['duplicate']
06/24/2022 21:57:17 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 21:57:17 - INFO - __main__ - ['duplicate']
06/24/2022 21:57:17 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:57:17 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:57:17 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 21:57:23 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:57:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 21:57:23 - INFO - __main__ - Starting training!
06/24/2022 21:57:24 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=4
06/24/2022 21:57:26 - INFO - __main__ - Step 20 Global step 20 Train loss 6.45 on epoch=9
06/24/2022 21:57:27 - INFO - __main__ - Step 30 Global step 30 Train loss 6.12 on epoch=14
06/24/2022 21:57:28 - INFO - __main__ - Step 40 Global step 40 Train loss 6.03 on epoch=19
06/24/2022 21:57:29 - INFO - __main__ - Step 50 Global step 50 Train loss 5.92 on epoch=24
06/24/2022 21:57:31 - INFO - __main__ - Global step 50 Train loss 6.22 ACC 0.0 on epoch=24
06/24/2022 21:57:31 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 21:57:32 - INFO - __main__ - Step 60 Global step 60 Train loss 5.70 on epoch=29
06/24/2022 21:57:33 - INFO - __main__ - Step 70 Global step 70 Train loss 5.49 on epoch=34
06/24/2022 21:57:35 - INFO - __main__ - Step 80 Global step 80 Train loss 5.33 on epoch=39
06/24/2022 21:57:36 - INFO - __main__ - Step 90 Global step 90 Train loss 5.22 on epoch=44
06/24/2022 21:57:37 - INFO - __main__ - Step 100 Global step 100 Train loss 5.08 on epoch=49
06/24/2022 21:57:38 - INFO - __main__ - Global step 100 Train loss 5.36 ACC 0.0 on epoch=49
06/24/2022 21:57:40 - INFO - __main__ - Step 110 Global step 110 Train loss 4.95 on epoch=54
06/24/2022 21:57:41 - INFO - __main__ - Step 120 Global step 120 Train loss 4.95 on epoch=59
06/24/2022 21:57:42 - INFO - __main__ - Step 130 Global step 130 Train loss 4.94 on epoch=64
06/24/2022 21:57:43 - INFO - __main__ - Step 140 Global step 140 Train loss 4.94 on epoch=69
06/24/2022 21:57:45 - INFO - __main__ - Step 150 Global step 150 Train loss 4.80 on epoch=74
06/24/2022 21:57:46 - INFO - __main__ - Global step 150 Train loss 4.91 ACC 0.0 on epoch=74
06/24/2022 21:57:48 - INFO - __main__ - Step 160 Global step 160 Train loss 4.80 on epoch=79
06/24/2022 21:57:49 - INFO - __main__ - Step 170 Global step 170 Train loss 4.63 on epoch=84
06/24/2022 21:57:50 - INFO - __main__ - Step 180 Global step 180 Train loss 4.61 on epoch=89
06/24/2022 21:57:51 - INFO - __main__ - Step 190 Global step 190 Train loss 4.60 on epoch=94
06/24/2022 21:57:53 - INFO - __main__ - Step 200 Global step 200 Train loss 4.59 on epoch=99
06/24/2022 21:57:54 - INFO - __main__ - Global step 200 Train loss 4.65 ACC 0.0 on epoch=99
06/24/2022 21:57:55 - INFO - __main__ - Step 210 Global step 210 Train loss 4.61 on epoch=104
06/24/2022 21:57:57 - INFO - __main__ - Step 220 Global step 220 Train loss 4.56 on epoch=109
06/24/2022 21:57:58 - INFO - __main__ - Step 230 Global step 230 Train loss 4.47 on epoch=114
06/24/2022 21:57:59 - INFO - __main__ - Step 240 Global step 240 Train loss 4.40 on epoch=119
06/24/2022 21:58:00 - INFO - __main__ - Step 250 Global step 250 Train loss 4.44 on epoch=124
06/24/2022 21:58:02 - INFO - __main__ - Global step 250 Train loss 4.50 ACC 0.0 on epoch=124
06/24/2022 21:58:03 - INFO - __main__ - Step 260 Global step 260 Train loss 4.35 on epoch=129
06/24/2022 21:58:04 - INFO - __main__ - Step 270 Global step 270 Train loss 4.30 on epoch=134
06/24/2022 21:58:06 - INFO - __main__ - Step 280 Global step 280 Train loss 4.24 on epoch=139
06/24/2022 21:58:07 - INFO - __main__ - Step 290 Global step 290 Train loss 4.21 on epoch=144
06/24/2022 21:58:08 - INFO - __main__ - Step 300 Global step 300 Train loss 4.05 on epoch=149
06/24/2022 21:58:10 - INFO - __main__ - Global step 300 Train loss 4.23 ACC 0.0 on epoch=149
06/24/2022 21:58:12 - INFO - __main__ - Step 310 Global step 310 Train loss 4.01 on epoch=154
06/24/2022 21:58:13 - INFO - __main__ - Step 320 Global step 320 Train loss 4.04 on epoch=159
06/24/2022 21:58:14 - INFO - __main__ - Step 330 Global step 330 Train loss 3.92 on epoch=164
06/24/2022 21:58:15 - INFO - __main__ - Step 340 Global step 340 Train loss 3.86 on epoch=169
06/24/2022 21:58:17 - INFO - __main__ - Step 350 Global step 350 Train loss 3.81 on epoch=174
06/24/2022 21:58:18 - INFO - __main__ - Global step 350 Train loss 3.93 ACC 0.0 on epoch=174
06/24/2022 21:58:19 - INFO - __main__ - Step 360 Global step 360 Train loss 3.77 on epoch=179
06/24/2022 21:58:20 - INFO - __main__ - Step 370 Global step 370 Train loss 3.82 on epoch=184
06/24/2022 21:58:22 - INFO - __main__ - Step 380 Global step 380 Train loss 3.70 on epoch=189
06/24/2022 21:58:23 - INFO - __main__ - Step 390 Global step 390 Train loss 3.52 on epoch=194
06/24/2022 21:58:24 - INFO - __main__ - Step 400 Global step 400 Train loss 3.52 on epoch=199
06/24/2022 21:58:26 - INFO - __main__ - Global step 400 Train loss 3.67 ACC 0.0 on epoch=199
06/24/2022 21:58:27 - INFO - __main__ - Step 410 Global step 410 Train loss 3.48 on epoch=204
06/24/2022 21:58:29 - INFO - __main__ - Step 420 Global step 420 Train loss 3.46 on epoch=209
06/24/2022 21:58:30 - INFO - __main__ - Step 430 Global step 430 Train loss 3.34 on epoch=214
06/24/2022 21:58:31 - INFO - __main__ - Step 440 Global step 440 Train loss 3.44 on epoch=219
06/24/2022 21:58:32 - INFO - __main__ - Step 450 Global step 450 Train loss 3.45 on epoch=224
06/24/2022 21:58:35 - INFO - __main__ - Global step 450 Train loss 3.43 ACC 0.0 on epoch=224
06/24/2022 21:58:36 - INFO - __main__ - Step 460 Global step 460 Train loss 3.27 on epoch=229
06/24/2022 21:58:37 - INFO - __main__ - Step 470 Global step 470 Train loss 3.28 on epoch=234
06/24/2022 21:58:39 - INFO - __main__ - Step 480 Global step 480 Train loss 3.32 on epoch=239
06/24/2022 21:58:40 - INFO - __main__ - Step 490 Global step 490 Train loss 3.31 on epoch=244
06/24/2022 21:58:41 - INFO - __main__ - Step 500 Global step 500 Train loss 3.19 on epoch=249
06/24/2022 21:58:47 - INFO - __main__ - Global step 500 Train loss 3.28 ACC 0.0 on epoch=249
06/24/2022 21:58:48 - INFO - __main__ - Step 510 Global step 510 Train loss 3.11 on epoch=254
06/24/2022 21:58:49 - INFO - __main__ - Step 520 Global step 520 Train loss 3.03 on epoch=259
06/24/2022 21:58:51 - INFO - __main__ - Step 530 Global step 530 Train loss 2.98 on epoch=264
06/24/2022 21:58:52 - INFO - __main__ - Step 540 Global step 540 Train loss 2.98 on epoch=269
06/24/2022 21:58:53 - INFO - __main__ - Step 550 Global step 550 Train loss 2.90 on epoch=274
06/24/2022 21:58:55 - INFO - __main__ - Global step 550 Train loss 3.00 ACC 0.15625 on epoch=274
06/24/2022 21:58:55 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.15625 on epoch=274, global_step=550
06/24/2022 21:58:56 - INFO - __main__ - Step 560 Global step 560 Train loss 2.81 on epoch=279
06/24/2022 21:58:57 - INFO - __main__ - Step 570 Global step 570 Train loss 2.81 on epoch=284
06/24/2022 21:58:58 - INFO - __main__ - Step 580 Global step 580 Train loss 2.69 on epoch=289
06/24/2022 21:59:00 - INFO - __main__ - Step 590 Global step 590 Train loss 2.65 on epoch=294
06/24/2022 21:59:01 - INFO - __main__ - Step 600 Global step 600 Train loss 2.65 on epoch=299
06/24/2022 21:59:02 - INFO - __main__ - Global step 600 Train loss 2.72 ACC 0.46875 on epoch=299
06/24/2022 21:59:02 - INFO - __main__ - Saving model with best ACC: 0.15625 -> 0.46875 on epoch=299, global_step=600
06/24/2022 21:59:04 - INFO - __main__ - Step 610 Global step 610 Train loss 2.61 on epoch=304
06/24/2022 21:59:05 - INFO - __main__ - Step 620 Global step 620 Train loss 2.50 on epoch=309
06/24/2022 21:59:06 - INFO - __main__ - Step 630 Global step 630 Train loss 2.59 on epoch=314
06/24/2022 21:59:07 - INFO - __main__ - Step 640 Global step 640 Train loss 2.53 on epoch=319
06/24/2022 21:59:09 - INFO - __main__ - Step 650 Global step 650 Train loss 2.38 on epoch=324
06/24/2022 21:59:10 - INFO - __main__ - Global step 650 Train loss 2.52 ACC 0.5 on epoch=324
06/24/2022 21:59:10 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=324, global_step=650
06/24/2022 21:59:11 - INFO - __main__ - Step 660 Global step 660 Train loss 2.47 on epoch=329
06/24/2022 21:59:13 - INFO - __main__ - Step 670 Global step 670 Train loss 2.41 on epoch=334
06/24/2022 21:59:14 - INFO - __main__ - Step 680 Global step 680 Train loss 2.44 on epoch=339
06/24/2022 21:59:15 - INFO - __main__ - Step 690 Global step 690 Train loss 2.31 on epoch=344
06/24/2022 21:59:16 - INFO - __main__ - Step 700 Global step 700 Train loss 2.14 on epoch=349
06/24/2022 21:59:17 - INFO - __main__ - Global step 700 Train loss 2.36 ACC 0.5 on epoch=349
06/24/2022 21:59:19 - INFO - __main__ - Step 710 Global step 710 Train loss 2.25 on epoch=354
06/24/2022 21:59:20 - INFO - __main__ - Step 720 Global step 720 Train loss 2.23 on epoch=359
06/24/2022 21:59:21 - INFO - __main__ - Step 730 Global step 730 Train loss 2.16 on epoch=364
06/24/2022 21:59:22 - INFO - __main__ - Step 740 Global step 740 Train loss 2.10 on epoch=369
06/24/2022 21:59:24 - INFO - __main__ - Step 750 Global step 750 Train loss 2.09 on epoch=374
06/24/2022 21:59:29 - INFO - __main__ - Global step 750 Train loss 2.17 ACC 0.375 on epoch=374
06/24/2022 21:59:31 - INFO - __main__ - Step 760 Global step 760 Train loss 2.20 on epoch=379
06/24/2022 21:59:32 - INFO - __main__ - Step 770 Global step 770 Train loss 2.08 on epoch=384
06/24/2022 21:59:33 - INFO - __main__ - Step 780 Global step 780 Train loss 2.04 on epoch=389
06/24/2022 21:59:34 - INFO - __main__ - Step 790 Global step 790 Train loss 2.01 on epoch=394
06/24/2022 21:59:36 - INFO - __main__ - Step 800 Global step 800 Train loss 2.03 on epoch=399
06/24/2022 21:59:45 - INFO - __main__ - Global step 800 Train loss 2.07 ACC 0.4375 on epoch=399
06/24/2022 21:59:47 - INFO - __main__ - Step 810 Global step 810 Train loss 2.03 on epoch=404
06/24/2022 21:59:48 - INFO - __main__ - Step 820 Global step 820 Train loss 2.02 on epoch=409
06/24/2022 21:59:49 - INFO - __main__ - Step 830 Global step 830 Train loss 1.87 on epoch=414
06/24/2022 21:59:50 - INFO - __main__ - Step 840 Global step 840 Train loss 1.99 on epoch=419
06/24/2022 21:59:52 - INFO - __main__ - Step 850 Global step 850 Train loss 1.92 on epoch=424
06/24/2022 22:00:02 - INFO - __main__ - Global step 850 Train loss 1.97 ACC 0.40625 on epoch=424
06/24/2022 22:00:03 - INFO - __main__ - Step 860 Global step 860 Train loss 1.78 on epoch=429
06/24/2022 22:00:04 - INFO - __main__ - Step 870 Global step 870 Train loss 1.79 on epoch=434
06/24/2022 22:00:05 - INFO - __main__ - Step 880 Global step 880 Train loss 1.77 on epoch=439
06/24/2022 22:00:07 - INFO - __main__ - Step 890 Global step 890 Train loss 1.68 on epoch=444
06/24/2022 22:00:08 - INFO - __main__ - Step 900 Global step 900 Train loss 1.93 on epoch=449
06/24/2022 22:00:11 - INFO - __main__ - Global step 900 Train loss 1.79 ACC 0.46875 on epoch=449
06/24/2022 22:00:13 - INFO - __main__ - Step 910 Global step 910 Train loss 1.64 on epoch=454
06/24/2022 22:00:14 - INFO - __main__ - Step 920 Global step 920 Train loss 1.70 on epoch=459
06/24/2022 22:00:15 - INFO - __main__ - Step 930 Global step 930 Train loss 1.60 on epoch=464
06/24/2022 22:00:16 - INFO - __main__ - Step 940 Global step 940 Train loss 1.62 on epoch=469
06/24/2022 22:00:18 - INFO - __main__ - Step 950 Global step 950 Train loss 1.62 on epoch=474
06/24/2022 22:00:19 - INFO - __main__ - Global step 950 Train loss 1.64 ACC 0.5 on epoch=474
06/24/2022 22:00:20 - INFO - __main__ - Step 960 Global step 960 Train loss 1.74 on epoch=479
06/24/2022 22:00:22 - INFO - __main__ - Step 970 Global step 970 Train loss 1.64 on epoch=484
06/24/2022 22:00:23 - INFO - __main__ - Step 980 Global step 980 Train loss 1.44 on epoch=489
06/24/2022 22:00:24 - INFO - __main__ - Step 990 Global step 990 Train loss 1.53 on epoch=494
06/24/2022 22:00:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.49 on epoch=499
06/24/2022 22:00:32 - INFO - __main__ - Global step 1000 Train loss 1.57 ACC 0.5 on epoch=499
06/24/2022 22:00:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=504
06/24/2022 22:00:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.44 on epoch=509
06/24/2022 22:00:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.32 on epoch=514
06/24/2022 22:00:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.42 on epoch=519
06/24/2022 22:00:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.31 on epoch=524
06/24/2022 22:00:43 - INFO - __main__ - Global step 1050 Train loss 1.38 ACC 0.5 on epoch=524
06/24/2022 22:00:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.38 on epoch=529
06/24/2022 22:00:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.33 on epoch=534
06/24/2022 22:00:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.31 on epoch=539
06/24/2022 22:00:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.27 on epoch=544
06/24/2022 22:00:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.13 on epoch=549
06/24/2022 22:00:50 - INFO - __main__ - Global step 1100 Train loss 1.28 ACC 0.5 on epoch=549
06/24/2022 22:00:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.18 on epoch=554
06/24/2022 22:00:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.19 on epoch=559
06/24/2022 22:00:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.13 on epoch=564
06/24/2022 22:00:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.01 on epoch=569
06/24/2022 22:00:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.15 on epoch=574
06/24/2022 22:00:57 - INFO - __main__ - Global step 1150 Train loss 1.13 ACC 0.5 on epoch=574
06/24/2022 22:00:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.02 on epoch=579
06/24/2022 22:01:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.07 on epoch=584
06/24/2022 22:01:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.04 on epoch=589
06/24/2022 22:01:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.00 on epoch=594
06/24/2022 22:01:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.93 on epoch=599
06/24/2022 22:01:04 - INFO - __main__ - Global step 1200 Train loss 1.01 ACC 0.5 on epoch=599
06/24/2022 22:01:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.90 on epoch=604
06/24/2022 22:01:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.05 on epoch=609
06/24/2022 22:01:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.97 on epoch=614
06/24/2022 22:01:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.95 on epoch=619
06/24/2022 22:01:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.97 on epoch=624
06/24/2022 22:01:11 - INFO - __main__ - Global step 1250 Train loss 0.97 ACC 0.5 on epoch=624
06/24/2022 22:01:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.86 on epoch=629
06/24/2022 22:01:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.93 on epoch=634
06/24/2022 22:01:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.89 on epoch=639
06/24/2022 22:01:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.92 on epoch=644
06/24/2022 22:01:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.78 on epoch=649
06/24/2022 22:01:18 - INFO - __main__ - Global step 1300 Train loss 0.87 ACC 0.5 on epoch=649
06/24/2022 22:01:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.83 on epoch=654
06/24/2022 22:01:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.96 on epoch=659
06/24/2022 22:01:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.94 on epoch=664
06/24/2022 22:01:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.88 on epoch=669
06/24/2022 22:01:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.89 on epoch=674
06/24/2022 22:01:24 - INFO - __main__ - Global step 1350 Train loss 0.90 ACC 0.5 on epoch=674
06/24/2022 22:01:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.98 on epoch=679
06/24/2022 22:01:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.84 on epoch=684
06/24/2022 22:01:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.84 on epoch=689
06/24/2022 22:01:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.82 on epoch=694
06/24/2022 22:01:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.87 on epoch=699
06/24/2022 22:01:31 - INFO - __main__ - Global step 1400 Train loss 0.87 ACC 0.5 on epoch=699
06/24/2022 22:01:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.80 on epoch=704
06/24/2022 22:01:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.73 on epoch=709
06/24/2022 22:01:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.89 on epoch=714
06/24/2022 22:01:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.73 on epoch=719
06/24/2022 22:01:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.71 on epoch=724
06/24/2022 22:01:38 - INFO - __main__ - Global step 1450 Train loss 0.77 ACC 0.5 on epoch=724
06/24/2022 22:01:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.91 on epoch=729
06/24/2022 22:01:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.72 on epoch=734
06/24/2022 22:01:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.76 on epoch=739
06/24/2022 22:01:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.75 on epoch=744
06/24/2022 22:01:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.74 on epoch=749
06/24/2022 22:01:45 - INFO - __main__ - Global step 1500 Train loss 0.78 ACC 0.5 on epoch=749
06/24/2022 22:01:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.71 on epoch=754
06/24/2022 22:01:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.74 on epoch=759
06/24/2022 22:01:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.67 on epoch=764
06/24/2022 22:01:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.68 on epoch=769
06/24/2022 22:01:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.81 on epoch=774
06/24/2022 22:01:52 - INFO - __main__ - Global step 1550 Train loss 0.72 ACC 0.5 on epoch=774
06/24/2022 22:01:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.72 on epoch=779
06/24/2022 22:01:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.71 on epoch=784
06/24/2022 22:01:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.66 on epoch=789
06/24/2022 22:01:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.59 on epoch=794
06/24/2022 22:01:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.66 on epoch=799
06/24/2022 22:01:58 - INFO - __main__ - Global step 1600 Train loss 0.67 ACC 0.5 on epoch=799
06/24/2022 22:01:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.57 on epoch=804
06/24/2022 22:02:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.65 on epoch=809
06/24/2022 22:02:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.68 on epoch=814
06/24/2022 22:02:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.75 on epoch=819
06/24/2022 22:02:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.64 on epoch=824
06/24/2022 22:02:05 - INFO - __main__ - Global step 1650 Train loss 0.66 ACC 0.5 on epoch=824
06/24/2022 22:02:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.71 on epoch=829
06/24/2022 22:02:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.62 on epoch=834
06/24/2022 22:02:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.62 on epoch=839
06/24/2022 22:02:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.69 on epoch=844
06/24/2022 22:02:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.58 on epoch=849
06/24/2022 22:02:12 - INFO - __main__ - Global step 1700 Train loss 0.64 ACC 0.5 on epoch=849
06/24/2022 22:02:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.69 on epoch=854
06/24/2022 22:02:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.58 on epoch=859
06/24/2022 22:02:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.68 on epoch=864
06/24/2022 22:02:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.63 on epoch=869
06/24/2022 22:02:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.58 on epoch=874
06/24/2022 22:02:18 - INFO - __main__ - Global step 1750 Train loss 0.63 ACC 0.5 on epoch=874
06/24/2022 22:02:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.61 on epoch=879
06/24/2022 22:02:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.58 on epoch=884
06/24/2022 22:02:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.55 on epoch=889
06/24/2022 22:02:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.59 on epoch=894
06/24/2022 22:02:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.66 on epoch=899
06/24/2022 22:02:25 - INFO - __main__ - Global step 1800 Train loss 0.60 ACC 0.5 on epoch=899
06/24/2022 22:02:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.57 on epoch=904
06/24/2022 22:02:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.66 on epoch=909
06/24/2022 22:02:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.57 on epoch=914
06/24/2022 22:02:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.49 on epoch=919
06/24/2022 22:02:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.56 on epoch=924
06/24/2022 22:02:32 - INFO - __main__ - Global step 1850 Train loss 0.57 ACC 0.5 on epoch=924
06/24/2022 22:02:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.58 on epoch=929
06/24/2022 22:02:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.54 on epoch=934
06/24/2022 22:02:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.61 on epoch=939
06/24/2022 22:02:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.58 on epoch=944
06/24/2022 22:02:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.57 on epoch=949
06/24/2022 22:02:38 - INFO - __main__ - Global step 1900 Train loss 0.58 ACC 0.5 on epoch=949
06/24/2022 22:02:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.64 on epoch=954
06/24/2022 22:02:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.57 on epoch=959
06/24/2022 22:02:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.47 on epoch=964
06/24/2022 22:02:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.48 on epoch=969
06/24/2022 22:02:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.53 on epoch=974
06/24/2022 22:02:45 - INFO - __main__ - Global step 1950 Train loss 0.54 ACC 0.5 on epoch=974
06/24/2022 22:02:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.53 on epoch=979
06/24/2022 22:02:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.52 on epoch=984
06/24/2022 22:02:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.51 on epoch=989
06/24/2022 22:02:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.53 on epoch=994
06/24/2022 22:02:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.46 on epoch=999
06/24/2022 22:02:52 - INFO - __main__ - Global step 2000 Train loss 0.51 ACC 0.5 on epoch=999
06/24/2022 22:02:52 - INFO - __main__ - save last model!
06/24/2022 22:02:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:02:52 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 22:02:52 - INFO - __main__ - Printing 3 examples
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 22:02:52 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 22:02:52 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:02:52 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:02:52 - INFO - __main__ - Printing 3 examples
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:02:52 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:02:52 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:02:52 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:02:52 - INFO - __main__ - Printing 3 examples
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 22:02:52 - INFO - __main__ - ['duplicate']
06/24/2022 22:02:52 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:02:52 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:02:53 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:02:58 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:02:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:02:58 - INFO - __main__ - Starting training!
06/24/2022 22:03:10 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:03:51 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 22:10:52 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_13_0.3_8_predictions.txt
06/24/2022 22:10:52 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 22:10:52 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.3, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 22:10:52 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.2, bsz=8 ...
06/24/2022 22:10:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:10:53 - INFO - __main__ - Printing 3 examples
06/24/2022 22:10:53 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 22:10:53 - INFO - __main__ - ['duplicate']
06/24/2022 22:10:53 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 22:10:53 - INFO - __main__ - ['duplicate']
06/24/2022 22:10:53 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 22:10:53 - INFO - __main__ - ['duplicate']
06/24/2022 22:10:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:10:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:10:53 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:10:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:10:53 - INFO - __main__ - Printing 3 examples
06/24/2022 22:10:53 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 22:10:53 - INFO - __main__ - ['duplicate']
06/24/2022 22:10:53 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 22:10:53 - INFO - __main__ - ['duplicate']
06/24/2022 22:10:53 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 22:10:53 - INFO - __main__ - ['duplicate']
06/24/2022 22:10:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:10:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:10:53 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:10:58 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:10:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:10:59 - INFO - __main__ - Starting training!
06/24/2022 22:11:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.51 on epoch=4
06/24/2022 22:11:01 - INFO - __main__ - Step 20 Global step 20 Train loss 6.50 on epoch=9
06/24/2022 22:11:02 - INFO - __main__ - Step 30 Global step 30 Train loss 6.39 on epoch=14
06/24/2022 22:11:04 - INFO - __main__ - Step 40 Global step 40 Train loss 6.14 on epoch=19
06/24/2022 22:11:05 - INFO - __main__ - Step 50 Global step 50 Train loss 6.14 on epoch=24
06/24/2022 22:11:10 - INFO - __main__ - Global step 50 Train loss 6.34 ACC 0.0 on epoch=24
06/24/2022 22:11:10 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 22:11:11 - INFO - __main__ - Step 60 Global step 60 Train loss 6.14 on epoch=29
06/24/2022 22:11:13 - INFO - __main__ - Step 70 Global step 70 Train loss 6.09 on epoch=34
06/24/2022 22:11:14 - INFO - __main__ - Step 80 Global step 80 Train loss 6.21 on epoch=39
06/24/2022 22:11:15 - INFO - __main__ - Step 90 Global step 90 Train loss 6.09 on epoch=44
06/24/2022 22:11:16 - INFO - __main__ - Step 100 Global step 100 Train loss 6.01 on epoch=49
06/24/2022 22:11:19 - INFO - __main__ - Global step 100 Train loss 6.11 ACC 0.0 on epoch=49
06/24/2022 22:11:20 - INFO - __main__ - Step 110 Global step 110 Train loss 5.98 on epoch=54
06/24/2022 22:11:21 - INFO - __main__ - Step 120 Global step 120 Train loss 5.88 on epoch=59
06/24/2022 22:11:22 - INFO - __main__ - Step 130 Global step 130 Train loss 5.83 on epoch=64
06/24/2022 22:11:23 - INFO - __main__ - Step 140 Global step 140 Train loss 5.80 on epoch=69
06/24/2022 22:11:25 - INFO - __main__ - Step 150 Global step 150 Train loss 5.78 on epoch=74
06/24/2022 22:11:27 - INFO - __main__ - Global step 150 Train loss 5.85 ACC 0.0 on epoch=74
06/24/2022 22:11:29 - INFO - __main__ - Step 160 Global step 160 Train loss 5.74 on epoch=79
06/24/2022 22:11:30 - INFO - __main__ - Step 170 Global step 170 Train loss 5.54 on epoch=84
06/24/2022 22:11:31 - INFO - __main__ - Step 180 Global step 180 Train loss 5.49 on epoch=89
06/24/2022 22:11:32 - INFO - __main__ - Step 190 Global step 190 Train loss 5.48 on epoch=94
06/24/2022 22:11:33 - INFO - __main__ - Step 200 Global step 200 Train loss 5.43 on epoch=99
06/24/2022 22:11:35 - INFO - __main__ - Global step 200 Train loss 5.53 ACC 0.0 on epoch=99
06/24/2022 22:11:37 - INFO - __main__ - Step 210 Global step 210 Train loss 5.37 on epoch=104
06/24/2022 22:11:38 - INFO - __main__ - Step 220 Global step 220 Train loss 5.24 on epoch=109
06/24/2022 22:11:39 - INFO - __main__ - Step 230 Global step 230 Train loss 5.25 on epoch=114
06/24/2022 22:11:40 - INFO - __main__ - Step 240 Global step 240 Train loss 5.10 on epoch=119
06/24/2022 22:11:41 - INFO - __main__ - Step 250 Global step 250 Train loss 4.99 on epoch=124
06/24/2022 22:11:43 - INFO - __main__ - Global step 250 Train loss 5.19 ACC 0.0 on epoch=124
06/24/2022 22:11:44 - INFO - __main__ - Step 260 Global step 260 Train loss 4.92 on epoch=129
06/24/2022 22:11:45 - INFO - __main__ - Step 270 Global step 270 Train loss 4.87 on epoch=134
06/24/2022 22:11:47 - INFO - __main__ - Step 280 Global step 280 Train loss 4.81 on epoch=139
06/24/2022 22:11:48 - INFO - __main__ - Step 290 Global step 290 Train loss 4.80 on epoch=144
06/24/2022 22:11:49 - INFO - __main__ - Step 300 Global step 300 Train loss 4.78 on epoch=149
06/24/2022 22:11:51 - INFO - __main__ - Global step 300 Train loss 4.83 ACC 0.0 on epoch=149
06/24/2022 22:11:52 - INFO - __main__ - Step 310 Global step 310 Train loss 4.59 on epoch=154
06/24/2022 22:11:53 - INFO - __main__ - Step 320 Global step 320 Train loss 4.65 on epoch=159
06/24/2022 22:11:55 - INFO - __main__ - Step 330 Global step 330 Train loss 4.41 on epoch=164
06/24/2022 22:11:56 - INFO - __main__ - Step 340 Global step 340 Train loss 4.47 on epoch=169
06/24/2022 22:11:57 - INFO - __main__ - Step 350 Global step 350 Train loss 4.44 on epoch=174
06/24/2022 22:12:00 - INFO - __main__ - Global step 350 Train loss 4.51 ACC 0.0 on epoch=174
06/24/2022 22:12:01 - INFO - __main__ - Step 360 Global step 360 Train loss 4.34 on epoch=179
06/24/2022 22:12:02 - INFO - __main__ - Step 370 Global step 370 Train loss 4.22 on epoch=184
06/24/2022 22:12:04 - INFO - __main__ - Step 380 Global step 380 Train loss 4.11 on epoch=189
06/24/2022 22:12:05 - INFO - __main__ - Step 390 Global step 390 Train loss 4.11 on epoch=194
06/24/2022 22:12:06 - INFO - __main__ - Step 400 Global step 400 Train loss 4.00 on epoch=199
06/24/2022 22:12:08 - INFO - __main__ - Global step 400 Train loss 4.16 ACC 0.0 on epoch=199
06/24/2022 22:12:09 - INFO - __main__ - Step 410 Global step 410 Train loss 3.94 on epoch=204
06/24/2022 22:12:11 - INFO - __main__ - Step 420 Global step 420 Train loss 3.89 on epoch=209
06/24/2022 22:12:12 - INFO - __main__ - Step 430 Global step 430 Train loss 3.85 on epoch=214
06/24/2022 22:12:13 - INFO - __main__ - Step 440 Global step 440 Train loss 3.72 on epoch=219
06/24/2022 22:12:15 - INFO - __main__ - Step 450 Global step 450 Train loss 3.50 on epoch=224
06/24/2022 22:12:16 - INFO - __main__ - Global step 450 Train loss 3.78 ACC 0.0 on epoch=224
06/24/2022 22:12:17 - INFO - __main__ - Step 460 Global step 460 Train loss 3.52 on epoch=229
06/24/2022 22:12:19 - INFO - __main__ - Step 470 Global step 470 Train loss 3.44 on epoch=234
06/24/2022 22:12:20 - INFO - __main__ - Step 480 Global step 480 Train loss 3.30 on epoch=239
06/24/2022 22:12:21 - INFO - __main__ - Step 490 Global step 490 Train loss 3.52 on epoch=244
06/24/2022 22:12:22 - INFO - __main__ - Step 500 Global step 500 Train loss 3.36 on epoch=249
06/24/2022 22:12:24 - INFO - __main__ - Global step 500 Train loss 3.43 ACC 0.0 on epoch=249
06/24/2022 22:12:25 - INFO - __main__ - Step 510 Global step 510 Train loss 3.38 on epoch=254
06/24/2022 22:12:26 - INFO - __main__ - Step 520 Global step 520 Train loss 3.14 on epoch=259
06/24/2022 22:12:28 - INFO - __main__ - Step 530 Global step 530 Train loss 3.12 on epoch=264
06/24/2022 22:12:29 - INFO - __main__ - Step 540 Global step 540 Train loss 3.00 on epoch=269
06/24/2022 22:12:30 - INFO - __main__ - Step 550 Global step 550 Train loss 3.02 on epoch=274
06/24/2022 22:12:32 - INFO - __main__ - Global step 550 Train loss 3.13 ACC 0.0 on epoch=274
06/24/2022 22:12:33 - INFO - __main__ - Step 560 Global step 560 Train loss 3.08 on epoch=279
06/24/2022 22:12:34 - INFO - __main__ - Step 570 Global step 570 Train loss 3.02 on epoch=284
06/24/2022 22:12:35 - INFO - __main__ - Step 580 Global step 580 Train loss 3.06 on epoch=289
06/24/2022 22:12:37 - INFO - __main__ - Step 590 Global step 590 Train loss 2.81 on epoch=294
06/24/2022 22:12:38 - INFO - __main__ - Step 600 Global step 600 Train loss 2.84 on epoch=299
06/24/2022 22:12:39 - INFO - __main__ - Global step 600 Train loss 2.96 ACC 0.0 on epoch=299
06/24/2022 22:12:40 - INFO - __main__ - Step 610 Global step 610 Train loss 2.78 on epoch=304
06/24/2022 22:12:42 - INFO - __main__ - Step 620 Global step 620 Train loss 2.73 on epoch=309
06/24/2022 22:12:43 - INFO - __main__ - Step 630 Global step 630 Train loss 2.66 on epoch=314
06/24/2022 22:12:44 - INFO - __main__ - Step 640 Global step 640 Train loss 2.60 on epoch=319
06/24/2022 22:12:45 - INFO - __main__ - Step 650 Global step 650 Train loss 2.64 on epoch=324
06/24/2022 22:12:46 - INFO - __main__ - Global step 650 Train loss 2.68 ACC 0.03125 on epoch=324
06/24/2022 22:12:46 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=324, global_step=650
06/24/2022 22:12:48 - INFO - __main__ - Step 660 Global step 660 Train loss 2.71 on epoch=329
06/24/2022 22:12:49 - INFO - __main__ - Step 670 Global step 670 Train loss 2.64 on epoch=334
06/24/2022 22:12:50 - INFO - __main__ - Step 680 Global step 680 Train loss 2.61 on epoch=339
06/24/2022 22:12:52 - INFO - __main__ - Step 690 Global step 690 Train loss 2.54 on epoch=344
06/24/2022 22:12:53 - INFO - __main__ - Step 700 Global step 700 Train loss 2.51 on epoch=349
06/24/2022 22:12:54 - INFO - __main__ - Global step 700 Train loss 2.60 ACC 0.03125 on epoch=349
06/24/2022 22:12:55 - INFO - __main__ - Step 710 Global step 710 Train loss 2.54 on epoch=354
06/24/2022 22:12:56 - INFO - __main__ - Step 720 Global step 720 Train loss 2.50 on epoch=359
06/24/2022 22:12:57 - INFO - __main__ - Step 730 Global step 730 Train loss 2.41 on epoch=364
06/24/2022 22:12:59 - INFO - __main__ - Step 740 Global step 740 Train loss 2.39 on epoch=369
06/24/2022 22:13:00 - INFO - __main__ - Step 750 Global step 750 Train loss 2.27 on epoch=374
06/24/2022 22:13:01 - INFO - __main__ - Global step 750 Train loss 2.42 ACC 0.46875 on epoch=374
06/24/2022 22:13:01 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.46875 on epoch=374, global_step=750
06/24/2022 22:13:02 - INFO - __main__ - Step 760 Global step 760 Train loss 2.36 on epoch=379
06/24/2022 22:13:03 - INFO - __main__ - Step 770 Global step 770 Train loss 2.34 on epoch=384
06/24/2022 22:13:04 - INFO - __main__ - Step 780 Global step 780 Train loss 2.25 on epoch=389
06/24/2022 22:13:06 - INFO - __main__ - Step 790 Global step 790 Train loss 2.32 on epoch=394
06/24/2022 22:13:07 - INFO - __main__ - Step 800 Global step 800 Train loss 2.18 on epoch=399
06/24/2022 22:13:08 - INFO - __main__ - Global step 800 Train loss 2.29 ACC 0.40625 on epoch=399
06/24/2022 22:13:09 - INFO - __main__ - Step 810 Global step 810 Train loss 2.23 on epoch=404
06/24/2022 22:13:10 - INFO - __main__ - Step 820 Global step 820 Train loss 2.17 on epoch=409
06/24/2022 22:13:12 - INFO - __main__ - Step 830 Global step 830 Train loss 2.12 on epoch=414
06/24/2022 22:13:13 - INFO - __main__ - Step 840 Global step 840 Train loss 2.08 on epoch=419
06/24/2022 22:13:14 - INFO - __main__ - Step 850 Global step 850 Train loss 2.29 on epoch=424
06/24/2022 22:13:15 - INFO - __main__ - Global step 850 Train loss 2.18 ACC 0.4375 on epoch=424
06/24/2022 22:13:17 - INFO - __main__ - Step 860 Global step 860 Train loss 2.00 on epoch=429
06/24/2022 22:13:18 - INFO - __main__ - Step 870 Global step 870 Train loss 2.13 on epoch=434
06/24/2022 22:13:19 - INFO - __main__ - Step 880 Global step 880 Train loss 2.06 on epoch=439
06/24/2022 22:13:20 - INFO - __main__ - Step 890 Global step 890 Train loss 2.00 on epoch=444
06/24/2022 22:13:22 - INFO - __main__ - Step 900 Global step 900 Train loss 1.96 on epoch=449
06/24/2022 22:13:23 - INFO - __main__ - Global step 900 Train loss 2.03 ACC 0.46875 on epoch=449
06/24/2022 22:13:24 - INFO - __main__ - Step 910 Global step 910 Train loss 2.04 on epoch=454
06/24/2022 22:13:25 - INFO - __main__ - Step 920 Global step 920 Train loss 1.95 on epoch=459
06/24/2022 22:13:27 - INFO - __main__ - Step 930 Global step 930 Train loss 1.91 on epoch=464
06/24/2022 22:13:28 - INFO - __main__ - Step 940 Global step 940 Train loss 1.97 on epoch=469
06/24/2022 22:13:29 - INFO - __main__ - Step 950 Global step 950 Train loss 2.03 on epoch=474
06/24/2022 22:13:30 - INFO - __main__ - Global step 950 Train loss 1.98 ACC 0.5 on epoch=474
06/24/2022 22:13:30 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=474, global_step=950
06/24/2022 22:13:31 - INFO - __main__ - Step 960 Global step 960 Train loss 1.87 on epoch=479
06/24/2022 22:13:33 - INFO - __main__ - Step 970 Global step 970 Train loss 1.93 on epoch=484
06/24/2022 22:13:34 - INFO - __main__ - Step 980 Global step 980 Train loss 1.84 on epoch=489
06/24/2022 22:13:35 - INFO - __main__ - Step 990 Global step 990 Train loss 1.96 on epoch=494
06/24/2022 22:13:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.90 on epoch=499
06/24/2022 22:13:37 - INFO - __main__ - Global step 1000 Train loss 1.90 ACC 0.5 on epoch=499
06/24/2022 22:13:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.83 on epoch=504
06/24/2022 22:13:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.74 on epoch=509
06/24/2022 22:13:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.76 on epoch=514
06/24/2022 22:13:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.69 on epoch=519
06/24/2022 22:13:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.82 on epoch=524
06/24/2022 22:13:49 - INFO - __main__ - Global step 1050 Train loss 1.77 ACC 0.5 on epoch=524
06/24/2022 22:13:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.72 on epoch=529
06/24/2022 22:13:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.86 on epoch=534
06/24/2022 22:13:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.72 on epoch=539
06/24/2022 22:13:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.69 on epoch=544
06/24/2022 22:13:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.72 on epoch=549
06/24/2022 22:13:56 - INFO - __main__ - Global step 1100 Train loss 1.74 ACC 0.5 on epoch=549
06/24/2022 22:13:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.56 on epoch=554
06/24/2022 22:13:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.62 on epoch=559
06/24/2022 22:14:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.68 on epoch=564
06/24/2022 22:14:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.63 on epoch=569
06/24/2022 22:14:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.58 on epoch=574
06/24/2022 22:14:04 - INFO - __main__ - Global step 1150 Train loss 1.61 ACC 0.5 on epoch=574
06/24/2022 22:14:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.58 on epoch=579
06/24/2022 22:14:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=584
06/24/2022 22:14:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.51 on epoch=589
06/24/2022 22:14:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.64 on epoch=594
06/24/2022 22:14:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.59 on epoch=599
06/24/2022 22:14:12 - INFO - __main__ - Global step 1200 Train loss 1.59 ACC 0.5 on epoch=599
06/24/2022 22:14:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.61 on epoch=604
06/24/2022 22:14:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.54 on epoch=609
06/24/2022 22:14:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.46 on epoch=614
06/24/2022 22:14:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.58 on epoch=619
06/24/2022 22:14:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.48 on epoch=624
06/24/2022 22:14:23 - INFO - __main__ - Global step 1250 Train loss 1.53 ACC 0.5 on epoch=624
06/24/2022 22:14:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.54 on epoch=629
06/24/2022 22:14:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.44 on epoch=634
06/24/2022 22:14:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.45 on epoch=639
06/24/2022 22:14:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.33 on epoch=644
06/24/2022 22:14:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.44 on epoch=649
06/24/2022 22:14:34 - INFO - __main__ - Global step 1300 Train loss 1.44 ACC 0.5 on epoch=649
06/24/2022 22:14:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.44 on epoch=654
06/24/2022 22:14:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.34 on epoch=659
06/24/2022 22:14:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.34 on epoch=664
06/24/2022 22:14:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.31 on epoch=669
06/24/2022 22:14:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.31 on epoch=674
06/24/2022 22:14:42 - INFO - __main__ - Global step 1350 Train loss 1.35 ACC 0.5 on epoch=674
06/24/2022 22:14:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.34 on epoch=679
06/24/2022 22:14:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.25 on epoch=684
06/24/2022 22:14:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.27 on epoch=689
06/24/2022 22:14:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.18 on epoch=694
06/24/2022 22:14:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.33 on epoch=699
06/24/2022 22:14:50 - INFO - __main__ - Global step 1400 Train loss 1.27 ACC 0.5 on epoch=699
06/24/2022 22:14:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.22 on epoch=704
06/24/2022 22:14:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.23 on epoch=709
06/24/2022 22:14:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.15 on epoch=714
06/24/2022 22:14:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.12 on epoch=719
06/24/2022 22:14:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=724
06/24/2022 22:14:56 - INFO - __main__ - Global step 1450 Train loss 1.16 ACC 0.5 on epoch=724
06/24/2022 22:14:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.19 on epoch=729
06/24/2022 22:14:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.99 on epoch=734
06/24/2022 22:15:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.06 on epoch=739
06/24/2022 22:15:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.09 on epoch=744
06/24/2022 22:15:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.99 on epoch=749
06/24/2022 22:15:03 - INFO - __main__ - Global step 1500 Train loss 1.06 ACC 0.5 on epoch=749
06/24/2022 22:15:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.95 on epoch=754
06/24/2022 22:15:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.00 on epoch=759
06/24/2022 22:15:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.03 on epoch=764
06/24/2022 22:15:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.01 on epoch=769
06/24/2022 22:15:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.97 on epoch=774
06/24/2022 22:15:10 - INFO - __main__ - Global step 1550 Train loss 0.99 ACC 0.5 on epoch=774
06/24/2022 22:15:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=779
06/24/2022 22:15:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.88 on epoch=784
06/24/2022 22:15:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.85 on epoch=789
06/24/2022 22:15:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.89 on epoch=794
06/24/2022 22:15:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.82 on epoch=799
06/24/2022 22:15:16 - INFO - __main__ - Global step 1600 Train loss 0.87 ACC 0.5 on epoch=799
06/24/2022 22:15:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.83 on epoch=804
06/24/2022 22:15:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.76 on epoch=809
06/24/2022 22:15:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.89 on epoch=814
06/24/2022 22:15:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.80 on epoch=819
06/24/2022 22:15:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.81 on epoch=824
06/24/2022 22:15:23 - INFO - __main__ - Global step 1650 Train loss 0.82 ACC 0.5 on epoch=824
06/24/2022 22:15:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.88 on epoch=829
06/24/2022 22:15:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.84 on epoch=834
06/24/2022 22:15:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.82 on epoch=839
06/24/2022 22:15:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.83 on epoch=844
06/24/2022 22:15:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.77 on epoch=849
06/24/2022 22:15:30 - INFO - __main__ - Global step 1700 Train loss 0.83 ACC 0.5 on epoch=849
06/24/2022 22:15:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.78 on epoch=854
06/24/2022 22:15:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.71 on epoch=859
06/24/2022 22:15:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.78 on epoch=864
06/24/2022 22:15:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.72 on epoch=869
06/24/2022 22:15:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.80 on epoch=874
06/24/2022 22:15:36 - INFO - __main__ - Global step 1750 Train loss 0.76 ACC 0.5 on epoch=874
06/24/2022 22:15:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.79 on epoch=879
06/24/2022 22:15:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.78 on epoch=884
06/24/2022 22:15:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.80 on epoch=889
06/24/2022 22:15:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.67 on epoch=894
06/24/2022 22:15:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.70 on epoch=899
06/24/2022 22:15:43 - INFO - __main__ - Global step 1800 Train loss 0.75 ACC 0.5 on epoch=899
06/24/2022 22:15:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.68 on epoch=904
06/24/2022 22:15:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.73 on epoch=909
06/24/2022 22:15:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.73 on epoch=914
06/24/2022 22:15:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.69 on epoch=919
06/24/2022 22:15:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.69 on epoch=924
06/24/2022 22:15:49 - INFO - __main__ - Global step 1850 Train loss 0.71 ACC 0.5 on epoch=924
06/24/2022 22:15:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.68 on epoch=929
06/24/2022 22:15:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.65 on epoch=934
06/24/2022 22:15:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.72 on epoch=939
06/24/2022 22:15:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.74 on epoch=944
06/24/2022 22:15:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.67 on epoch=949
06/24/2022 22:15:56 - INFO - __main__ - Global step 1900 Train loss 0.69 ACC 0.5 on epoch=949
06/24/2022 22:15:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.80 on epoch=954
06/24/2022 22:15:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.63 on epoch=959
06/24/2022 22:15:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.68 on epoch=964
06/24/2022 22:16:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.63 on epoch=969
06/24/2022 22:16:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.73 on epoch=974
06/24/2022 22:16:02 - INFO - __main__ - Global step 1950 Train loss 0.69 ACC 0.5 on epoch=974
06/24/2022 22:16:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.65 on epoch=979
06/24/2022 22:16:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.69 on epoch=984
06/24/2022 22:16:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.75 on epoch=989
06/24/2022 22:16:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.61 on epoch=994
06/24/2022 22:16:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.66 on epoch=999
06/24/2022 22:16:09 - INFO - __main__ - Global step 2000 Train loss 0.67 ACC 0.5 on epoch=999
06/24/2022 22:16:09 - INFO - __main__ - save last model!
06/24/2022 22:16:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:16:09 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 22:16:09 - INFO - __main__ - Printing 3 examples
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 22:16:09 - INFO - __main__ - ['duplicate']
06/24/2022 22:16:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:16:09 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:16:09 - INFO - __main__ - Printing 3 examples
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:16:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:16:09 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:16:09 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:16:09 - INFO - __main__ - Printing 3 examples
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 22:16:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:16:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:16:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:16:09 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:16:15 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:16:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:16:15 - INFO - __main__ - Starting training!
06/24/2022 22:16:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:17:08 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 22:25:39 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_13_0.2_8_predictions.txt
06/24/2022 22:25:40 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 22:25:40 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.2, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 22:25:40 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.5, bsz=8 ...
06/24/2022 22:25:41 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:25:41 - INFO - __main__ - Printing 3 examples
06/24/2022 22:25:41 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 22:25:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:25:41 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 22:25:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:25:41 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 22:25:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:25:41 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:25:41 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:25:41 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:25:41 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:25:41 - INFO - __main__ - Printing 3 examples
06/24/2022 22:25:41 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 22:25:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:25:41 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 22:25:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:25:41 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 22:25:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:25:41 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:25:41 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:25:41 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:25:46 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:25:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:25:46 - INFO - __main__ - Starting training!
06/24/2022 22:25:48 - INFO - __main__ - Step 10 Global step 10 Train loss 6.29 on epoch=4
06/24/2022 22:25:49 - INFO - __main__ - Step 20 Global step 20 Train loss 6.09 on epoch=9
06/24/2022 22:25:50 - INFO - __main__ - Step 30 Global step 30 Train loss 5.91 on epoch=14
06/24/2022 22:25:51 - INFO - __main__ - Step 40 Global step 40 Train loss 5.77 on epoch=19
06/24/2022 22:25:53 - INFO - __main__ - Step 50 Global step 50 Train loss 5.51 on epoch=24
06/24/2022 22:25:54 - INFO - __main__ - Global step 50 Train loss 5.91 ACC 0.0 on epoch=24
06/24/2022 22:25:54 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 22:25:56 - INFO - __main__ - Step 60 Global step 60 Train loss 5.23 on epoch=29
06/24/2022 22:25:57 - INFO - __main__ - Step 70 Global step 70 Train loss 5.12 on epoch=34
06/24/2022 22:25:58 - INFO - __main__ - Step 80 Global step 80 Train loss 5.02 on epoch=39
06/24/2022 22:25:59 - INFO - __main__ - Step 90 Global step 90 Train loss 4.74 on epoch=44
06/24/2022 22:26:00 - INFO - __main__ - Step 100 Global step 100 Train loss 4.69 on epoch=49
06/24/2022 22:26:02 - INFO - __main__ - Global step 100 Train loss 4.96 ACC 0.0 on epoch=49
06/24/2022 22:26:03 - INFO - __main__ - Step 110 Global step 110 Train loss 4.42 on epoch=54
06/24/2022 22:26:04 - INFO - __main__ - Step 120 Global step 120 Train loss 4.24 on epoch=59
06/24/2022 22:26:06 - INFO - __main__ - Step 130 Global step 130 Train loss 4.13 on epoch=64
06/24/2022 22:26:07 - INFO - __main__ - Step 140 Global step 140 Train loss 3.86 on epoch=69
06/24/2022 22:26:08 - INFO - __main__ - Step 150 Global step 150 Train loss 3.75 on epoch=74
06/24/2022 22:26:09 - INFO - __main__ - Global step 150 Train loss 4.08 ACC 0.0 on epoch=74
06/24/2022 22:26:10 - INFO - __main__ - Step 160 Global step 160 Train loss 3.65 on epoch=79
06/24/2022 22:26:11 - INFO - __main__ - Step 170 Global step 170 Train loss 3.42 on epoch=84
06/24/2022 22:26:13 - INFO - __main__ - Step 180 Global step 180 Train loss 3.49 on epoch=89
06/24/2022 22:26:14 - INFO - __main__ - Step 190 Global step 190 Train loss 3.34 on epoch=94
06/24/2022 22:26:15 - INFO - __main__ - Step 200 Global step 200 Train loss 3.20 on epoch=99
06/24/2022 22:26:16 - INFO - __main__ - Global step 200 Train loss 3.42 ACC 0.03125 on epoch=99
06/24/2022 22:26:16 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=99, global_step=200
06/24/2022 22:26:17 - INFO - __main__ - Step 210 Global step 210 Train loss 3.16 on epoch=104
06/24/2022 22:26:19 - INFO - __main__ - Step 220 Global step 220 Train loss 3.16 on epoch=109
06/24/2022 22:26:20 - INFO - __main__ - Step 230 Global step 230 Train loss 3.01 on epoch=114
06/24/2022 22:26:21 - INFO - __main__ - Step 240 Global step 240 Train loss 2.80 on epoch=119
06/24/2022 22:26:22 - INFO - __main__ - Step 250 Global step 250 Train loss 2.80 on epoch=124
06/24/2022 22:26:25 - INFO - __main__ - Global step 250 Train loss 2.99 ACC 0.0625 on epoch=124
06/24/2022 22:26:25 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.0625 on epoch=124, global_step=250
06/24/2022 22:26:27 - INFO - __main__ - Step 260 Global step 260 Train loss 2.79 on epoch=129
06/24/2022 22:26:28 - INFO - __main__ - Step 270 Global step 270 Train loss 2.67 on epoch=134
06/24/2022 22:26:29 - INFO - __main__ - Step 280 Global step 280 Train loss 2.69 on epoch=139
06/24/2022 22:26:30 - INFO - __main__ - Step 290 Global step 290 Train loss 2.47 on epoch=144
06/24/2022 22:26:32 - INFO - __main__ - Step 300 Global step 300 Train loss 2.43 on epoch=149
06/24/2022 22:26:38 - INFO - __main__ - Global step 300 Train loss 2.61 ACC 0.0625 on epoch=149
06/24/2022 22:26:40 - INFO - __main__ - Step 310 Global step 310 Train loss 2.43 on epoch=154
06/24/2022 22:26:41 - INFO - __main__ - Step 320 Global step 320 Train loss 2.30 on epoch=159
06/24/2022 22:26:42 - INFO - __main__ - Step 330 Global step 330 Train loss 2.15 on epoch=164
06/24/2022 22:26:43 - INFO - __main__ - Step 340 Global step 340 Train loss 2.13 on epoch=169
06/24/2022 22:26:44 - INFO - __main__ - Step 350 Global step 350 Train loss 2.22 on epoch=174
06/24/2022 22:26:55 - INFO - __main__ - Global step 350 Train loss 2.25 ACC 0.34375 on epoch=174
06/24/2022 22:26:55 - INFO - __main__ - Saving model with best ACC: 0.0625 -> 0.34375 on epoch=174, global_step=350
06/24/2022 22:26:56 - INFO - __main__ - Step 360 Global step 360 Train loss 2.12 on epoch=179
06/24/2022 22:26:57 - INFO - __main__ - Step 370 Global step 370 Train loss 2.06 on epoch=184
06/24/2022 22:26:58 - INFO - __main__ - Step 380 Global step 380 Train loss 2.00 on epoch=189
06/24/2022 22:26:59 - INFO - __main__ - Step 390 Global step 390 Train loss 2.16 on epoch=194
06/24/2022 22:27:01 - INFO - __main__ - Step 400 Global step 400 Train loss 2.01 on epoch=199
06/24/2022 22:27:03 - INFO - __main__ - Global step 400 Train loss 2.07 ACC 0.53125 on epoch=199
06/24/2022 22:27:03 - INFO - __main__ - Saving model with best ACC: 0.34375 -> 0.53125 on epoch=199, global_step=400
06/24/2022 22:27:04 - INFO - __main__ - Step 410 Global step 410 Train loss 1.94 on epoch=204
06/24/2022 22:27:05 - INFO - __main__ - Step 420 Global step 420 Train loss 1.86 on epoch=209
06/24/2022 22:27:07 - INFO - __main__ - Step 430 Global step 430 Train loss 1.79 on epoch=214
06/24/2022 22:27:08 - INFO - __main__ - Step 440 Global step 440 Train loss 1.86 on epoch=219
06/24/2022 22:27:09 - INFO - __main__ - Step 450 Global step 450 Train loss 1.78 on epoch=224
06/24/2022 22:27:10 - INFO - __main__ - Global step 450 Train loss 1.85 ACC 0.25 on epoch=224
06/24/2022 22:27:11 - INFO - __main__ - Step 460 Global step 460 Train loss 1.75 on epoch=229
06/24/2022 22:27:12 - INFO - __main__ - Step 470 Global step 470 Train loss 1.65 on epoch=234
06/24/2022 22:27:13 - INFO - __main__ - Step 480 Global step 480 Train loss 1.64 on epoch=239
06/24/2022 22:27:15 - INFO - __main__ - Step 490 Global step 490 Train loss 1.64 on epoch=244
06/24/2022 22:27:16 - INFO - __main__ - Step 500 Global step 500 Train loss 1.60 on epoch=249
06/24/2022 22:27:17 - INFO - __main__ - Global step 500 Train loss 1.66 ACC 0.46875 on epoch=249
06/24/2022 22:27:18 - INFO - __main__ - Step 510 Global step 510 Train loss 1.56 on epoch=254
06/24/2022 22:27:19 - INFO - __main__ - Step 520 Global step 520 Train loss 1.50 on epoch=259
06/24/2022 22:27:21 - INFO - __main__ - Step 530 Global step 530 Train loss 1.58 on epoch=264
06/24/2022 22:27:22 - INFO - __main__ - Step 540 Global step 540 Train loss 1.35 on epoch=269
06/24/2022 22:27:23 - INFO - __main__ - Step 550 Global step 550 Train loss 1.36 on epoch=274
06/24/2022 22:27:24 - INFO - __main__ - Global step 550 Train loss 1.47 ACC 0.5 on epoch=274
06/24/2022 22:27:25 - INFO - __main__ - Step 560 Global step 560 Train loss 1.30 on epoch=279
06/24/2022 22:27:26 - INFO - __main__ - Step 570 Global step 570 Train loss 1.36 on epoch=284
06/24/2022 22:27:28 - INFO - __main__ - Step 580 Global step 580 Train loss 1.19 on epoch=289
06/24/2022 22:27:29 - INFO - __main__ - Step 590 Global step 590 Train loss 1.10 on epoch=294
06/24/2022 22:27:30 - INFO - __main__ - Step 600 Global step 600 Train loss 1.23 on epoch=299
06/24/2022 22:27:32 - INFO - __main__ - Global step 600 Train loss 1.24 ACC 0.5 on epoch=299
06/24/2022 22:27:33 - INFO - __main__ - Step 610 Global step 610 Train loss 1.15 on epoch=304
06/24/2022 22:27:34 - INFO - __main__ - Step 620 Global step 620 Train loss 1.10 on epoch=309
06/24/2022 22:27:35 - INFO - __main__ - Step 630 Global step 630 Train loss 1.07 on epoch=314
06/24/2022 22:27:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.98 on epoch=319
06/24/2022 22:27:38 - INFO - __main__ - Step 650 Global step 650 Train loss 1.08 on epoch=324
06/24/2022 22:27:39 - INFO - __main__ - Global step 650 Train loss 1.08 ACC 0.5 on epoch=324
06/24/2022 22:27:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.91 on epoch=329
06/24/2022 22:27:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.88 on epoch=334
06/24/2022 22:27:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.81 on epoch=339
06/24/2022 22:27:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.85 on epoch=344
06/24/2022 22:27:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.77 on epoch=349
06/24/2022 22:27:45 - INFO - __main__ - Global step 700 Train loss 0.84 ACC 0.5 on epoch=349
06/24/2022 22:27:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.71 on epoch=354
06/24/2022 22:27:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.73 on epoch=359
06/24/2022 22:27:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.70 on epoch=364
06/24/2022 22:27:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.63 on epoch=369
06/24/2022 22:27:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.73 on epoch=374
06/24/2022 22:27:52 - INFO - __main__ - Global step 750 Train loss 0.70 ACC 0.5 on epoch=374
06/24/2022 22:27:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.67 on epoch=379
06/24/2022 22:27:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.69 on epoch=384
06/24/2022 22:27:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.66 on epoch=389
06/24/2022 22:27:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.69 on epoch=394
06/24/2022 22:27:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.62 on epoch=399
06/24/2022 22:27:59 - INFO - __main__ - Global step 800 Train loss 0.66 ACC 0.5 on epoch=399
06/24/2022 22:28:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.63 on epoch=404
06/24/2022 22:28:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.64 on epoch=409
06/24/2022 22:28:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.64 on epoch=414
06/24/2022 22:28:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.61 on epoch=419
06/24/2022 22:28:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.62 on epoch=424
06/24/2022 22:28:05 - INFO - __main__ - Global step 850 Train loss 0.63 ACC 0.5 on epoch=424
06/24/2022 22:28:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.54 on epoch=429
06/24/2022 22:28:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.58 on epoch=434
06/24/2022 22:28:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.51 on epoch=439
06/24/2022 22:28:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.52 on epoch=444
06/24/2022 22:28:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.54 on epoch=449
06/24/2022 22:28:12 - INFO - __main__ - Global step 900 Train loss 0.54 ACC 0.5 on epoch=449
06/24/2022 22:28:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.54 on epoch=454
06/24/2022 22:28:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.51 on epoch=459
06/24/2022 22:28:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.50 on epoch=464
06/24/2022 22:28:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.47 on epoch=469
06/24/2022 22:28:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.52 on epoch=474
06/24/2022 22:28:19 - INFO - __main__ - Global step 950 Train loss 0.51 ACC 0.5 on epoch=474
06/24/2022 22:28:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.56 on epoch=479
06/24/2022 22:28:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.55 on epoch=484
06/24/2022 22:28:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.59 on epoch=489
06/24/2022 22:28:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.50 on epoch=494
06/24/2022 22:28:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.49 on epoch=499
06/24/2022 22:28:25 - INFO - __main__ - Global step 1000 Train loss 0.54 ACC 0.5 on epoch=499
06/24/2022 22:28:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.50 on epoch=504
06/24/2022 22:28:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.47 on epoch=509
06/24/2022 22:28:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.52 on epoch=514
06/24/2022 22:28:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.50 on epoch=519
06/24/2022 22:28:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.53 on epoch=524
06/24/2022 22:28:32 - INFO - __main__ - Global step 1050 Train loss 0.50 ACC 0.5 on epoch=524
06/24/2022 22:28:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.44 on epoch=529
06/24/2022 22:28:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.44 on epoch=534
06/24/2022 22:28:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.43 on epoch=539
06/24/2022 22:28:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.47 on epoch=544
06/24/2022 22:28:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.42 on epoch=549
06/24/2022 22:28:38 - INFO - __main__ - Global step 1100 Train loss 0.44 ACC 0.5 on epoch=549
06/24/2022 22:28:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.47 on epoch=554
06/24/2022 22:28:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.43 on epoch=559
06/24/2022 22:28:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.47 on epoch=564
06/24/2022 22:28:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.41 on epoch=569
06/24/2022 22:28:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.43 on epoch=574
06/24/2022 22:28:45 - INFO - __main__ - Global step 1150 Train loss 0.44 ACC 0.5 on epoch=574
06/24/2022 22:28:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.52 on epoch=579
06/24/2022 22:28:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.46 on epoch=584
06/24/2022 22:28:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.43 on epoch=589
06/24/2022 22:28:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.48 on epoch=594
06/24/2022 22:28:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.38 on epoch=599
06/24/2022 22:28:52 - INFO - __main__ - Global step 1200 Train loss 0.45 ACC 0.5 on epoch=599
06/24/2022 22:28:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.42 on epoch=604
06/24/2022 22:28:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.43 on epoch=609
06/24/2022 22:28:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.41 on epoch=614
06/24/2022 22:28:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.39 on epoch=619
06/24/2022 22:28:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.45 on epoch=624
06/24/2022 22:28:59 - INFO - __main__ - Global step 1250 Train loss 0.42 ACC 0.5 on epoch=624
06/24/2022 22:29:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.43 on epoch=629
06/24/2022 22:29:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.38 on epoch=634
06/24/2022 22:29:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.39 on epoch=639
06/24/2022 22:29:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.37 on epoch=644
06/24/2022 22:29:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.41 on epoch=649
06/24/2022 22:29:05 - INFO - __main__ - Global step 1300 Train loss 0.40 ACC 0.5 on epoch=649
06/24/2022 22:29:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.38 on epoch=654
06/24/2022 22:29:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.49 on epoch=659
06/24/2022 22:29:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.41 on epoch=664
06/24/2022 22:29:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.42 on epoch=669
06/24/2022 22:29:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.42 on epoch=674
06/24/2022 22:29:12 - INFO - __main__ - Global step 1350 Train loss 0.43 ACC 0.5 on epoch=674
06/24/2022 22:29:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.50 on epoch=679
06/24/2022 22:29:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.45 on epoch=684
06/24/2022 22:29:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.43 on epoch=689
06/24/2022 22:29:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.39 on epoch=694
06/24/2022 22:29:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.43 on epoch=699
06/24/2022 22:29:19 - INFO - __main__ - Global step 1400 Train loss 0.44 ACC 0.5 on epoch=699
06/24/2022 22:29:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.36 on epoch=704
06/24/2022 22:29:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.44 on epoch=709
06/24/2022 22:29:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.43 on epoch=714
06/24/2022 22:29:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.35 on epoch=719
06/24/2022 22:29:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.38 on epoch=724
06/24/2022 22:29:25 - INFO - __main__ - Global step 1450 Train loss 0.39 ACC 0.5 on epoch=724
06/24/2022 22:29:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.47 on epoch=729
06/24/2022 22:29:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.35 on epoch=734
06/24/2022 22:29:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.36 on epoch=739
06/24/2022 22:29:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.34 on epoch=744
06/24/2022 22:29:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.39 on epoch=749
06/24/2022 22:29:32 - INFO - __main__ - Global step 1500 Train loss 0.38 ACC 0.5 on epoch=749
06/24/2022 22:29:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.37 on epoch=754
06/24/2022 22:29:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.36 on epoch=759
06/24/2022 22:29:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.44 on epoch=764
06/24/2022 22:29:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.39 on epoch=769
06/24/2022 22:29:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.46 on epoch=774
06/24/2022 22:29:39 - INFO - __main__ - Global step 1550 Train loss 0.41 ACC 0.5 on epoch=774
06/24/2022 22:29:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.38 on epoch=779
06/24/2022 22:29:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.35 on epoch=784
06/24/2022 22:29:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.34 on epoch=789
06/24/2022 22:29:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.37 on epoch=794
06/24/2022 22:29:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.41 on epoch=799
06/24/2022 22:29:45 - INFO - __main__ - Global step 1600 Train loss 0.37 ACC 0.5 on epoch=799
06/24/2022 22:29:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.39 on epoch=804
06/24/2022 22:29:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.40 on epoch=809
06/24/2022 22:29:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.36 on epoch=814
06/24/2022 22:29:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.37 on epoch=819
06/24/2022 22:29:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.43 on epoch=824
06/24/2022 22:29:52 - INFO - __main__ - Global step 1650 Train loss 0.39 ACC 0.5 on epoch=824
06/24/2022 22:29:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.33 on epoch=829
06/24/2022 22:29:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.37 on epoch=834
06/24/2022 22:29:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.39 on epoch=839
06/24/2022 22:29:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.34 on epoch=844
06/24/2022 22:29:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.37 on epoch=849
06/24/2022 22:29:59 - INFO - __main__ - Global step 1700 Train loss 0.36 ACC 0.5 on epoch=849
06/24/2022 22:30:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.38 on epoch=854
06/24/2022 22:30:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.28 on epoch=859
06/24/2022 22:30:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.39 on epoch=864
06/24/2022 22:30:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.33 on epoch=869
06/24/2022 22:30:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.37 on epoch=874
06/24/2022 22:30:05 - INFO - __main__ - Global step 1750 Train loss 0.35 ACC 0.5 on epoch=874
06/24/2022 22:30:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.38 on epoch=879
06/24/2022 22:30:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.36 on epoch=884
06/24/2022 22:30:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.30 on epoch=889
06/24/2022 22:30:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.37 on epoch=894
06/24/2022 22:30:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.42 on epoch=899
06/24/2022 22:30:12 - INFO - __main__ - Global step 1800 Train loss 0.37 ACC 0.5 on epoch=899
06/24/2022 22:30:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.31 on epoch=904
06/24/2022 22:30:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.37 on epoch=909
06/24/2022 22:30:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.30 on epoch=914
06/24/2022 22:30:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.33 on epoch=919
06/24/2022 22:30:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.32 on epoch=924
06/24/2022 22:30:19 - INFO - __main__ - Global step 1850 Train loss 0.33 ACC 0.5 on epoch=924
06/24/2022 22:30:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.35 on epoch=929
06/24/2022 22:30:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.36 on epoch=934
06/24/2022 22:30:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.28 on epoch=939
06/24/2022 22:30:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.29 on epoch=944
06/24/2022 22:30:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.33 on epoch=949
06/24/2022 22:30:25 - INFO - __main__ - Global step 1900 Train loss 0.32 ACC 0.5 on epoch=949
06/24/2022 22:30:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.29 on epoch=954
06/24/2022 22:30:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.30 on epoch=959
06/24/2022 22:30:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.27 on epoch=964
06/24/2022 22:30:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.34 on epoch=969
06/24/2022 22:30:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.30 on epoch=974
06/24/2022 22:30:32 - INFO - __main__ - Global step 1950 Train loss 0.30 ACC 0.5 on epoch=974
06/24/2022 22:30:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.32 on epoch=979
06/24/2022 22:30:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.26 on epoch=984
06/24/2022 22:30:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.29 on epoch=989
06/24/2022 22:30:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.38 on epoch=994
06/24/2022 22:30:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.30 on epoch=999
06/24/2022 22:30:38 - INFO - __main__ - Global step 2000 Train loss 0.31 ACC 0.5 on epoch=999
06/24/2022 22:30:38 - INFO - __main__ - save last model!
06/24/2022 22:30:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:30:39 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 22:30:39 - INFO - __main__ - Printing 3 examples
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 22:30:39 - INFO - __main__ - ['duplicate']
06/24/2022 22:30:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:30:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:30:39 - INFO - __main__ - Printing 3 examples
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:30:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:30:39 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:30:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:30:39 - INFO - __main__ - Printing 3 examples
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 22:30:39 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:30:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:30:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:30:39 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:30:44 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:30:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:30:45 - INFO - __main__ - Starting training!
06/24/2022 22:30:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:31:38 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 22:43:40 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_21_0.5_8_predictions.txt
06/24/2022 22:43:41 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 22:43:41 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.5, bsz=8, dev_performance=0.53125, test_performance=0.36816720257234725
06/24/2022 22:43:41 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.4, bsz=8 ...
06/24/2022 22:43:42 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:43:42 - INFO - __main__ - Printing 3 examples
06/24/2022 22:43:42 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 22:43:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:43:42 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 22:43:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:43:42 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 22:43:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:43:42 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:43:42 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:43:42 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:43:42 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:43:42 - INFO - __main__ - Printing 3 examples
06/24/2022 22:43:42 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 22:43:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:43:42 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 22:43:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:43:42 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 22:43:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:43:42 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:43:42 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:43:42 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:43:48 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:43:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:43:48 - INFO - __main__ - Starting training!
06/24/2022 22:43:50 - INFO - __main__ - Step 10 Global step 10 Train loss 6.28 on epoch=4
06/24/2022 22:43:51 - INFO - __main__ - Step 20 Global step 20 Train loss 6.09 on epoch=9
06/24/2022 22:43:52 - INFO - __main__ - Step 30 Global step 30 Train loss 5.89 on epoch=14
06/24/2022 22:43:54 - INFO - __main__ - Step 40 Global step 40 Train loss 5.66 on epoch=19
06/24/2022 22:43:55 - INFO - __main__ - Step 50 Global step 50 Train loss 5.52 on epoch=24
06/24/2022 22:43:57 - INFO - __main__ - Global step 50 Train loss 5.89 ACC 0.0 on epoch=24
06/24/2022 22:43:57 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 22:43:58 - INFO - __main__ - Step 60 Global step 60 Train loss 5.36 on epoch=29
06/24/2022 22:43:59 - INFO - __main__ - Step 70 Global step 70 Train loss 5.22 on epoch=34
06/24/2022 22:44:00 - INFO - __main__ - Step 80 Global step 80 Train loss 5.05 on epoch=39
06/24/2022 22:44:02 - INFO - __main__ - Step 90 Global step 90 Train loss 4.81 on epoch=44
06/24/2022 22:44:03 - INFO - __main__ - Step 100 Global step 100 Train loss 4.73 on epoch=49
06/24/2022 22:44:04 - INFO - __main__ - Global step 100 Train loss 5.03 ACC 0.0 on epoch=49
06/24/2022 22:44:06 - INFO - __main__ - Step 110 Global step 110 Train loss 4.70 on epoch=54
06/24/2022 22:44:07 - INFO - __main__ - Step 120 Global step 120 Train loss 4.45 on epoch=59
06/24/2022 22:44:08 - INFO - __main__ - Step 130 Global step 130 Train loss 4.48 on epoch=64
06/24/2022 22:44:10 - INFO - __main__ - Step 140 Global step 140 Train loss 4.19 on epoch=69
06/24/2022 22:44:11 - INFO - __main__ - Step 150 Global step 150 Train loss 4.05 on epoch=74
06/24/2022 22:44:12 - INFO - __main__ - Global step 150 Train loss 4.38 ACC 0.0 on epoch=74
06/24/2022 22:44:13 - INFO - __main__ - Step 160 Global step 160 Train loss 3.95 on epoch=79
06/24/2022 22:44:15 - INFO - __main__ - Step 170 Global step 170 Train loss 3.91 on epoch=84
06/24/2022 22:44:16 - INFO - __main__ - Step 180 Global step 180 Train loss 3.96 on epoch=89
06/24/2022 22:44:17 - INFO - __main__ - Step 190 Global step 190 Train loss 3.69 on epoch=94
06/24/2022 22:44:19 - INFO - __main__ - Step 200 Global step 200 Train loss 3.61 on epoch=99
06/24/2022 22:44:20 - INFO - __main__ - Global step 200 Train loss 3.82 ACC 0.0 on epoch=99
06/24/2022 22:44:21 - INFO - __main__ - Step 210 Global step 210 Train loss 3.43 on epoch=104
06/24/2022 22:44:23 - INFO - __main__ - Step 220 Global step 220 Train loss 3.33 on epoch=109
06/24/2022 22:44:24 - INFO - __main__ - Step 230 Global step 230 Train loss 3.32 on epoch=114
06/24/2022 22:44:25 - INFO - __main__ - Step 240 Global step 240 Train loss 3.45 on epoch=119
06/24/2022 22:44:27 - INFO - __main__ - Step 250 Global step 250 Train loss 3.12 on epoch=124
06/24/2022 22:44:28 - INFO - __main__ - Global step 250 Train loss 3.33 ACC 0.0 on epoch=124
06/24/2022 22:44:29 - INFO - __main__ - Step 260 Global step 260 Train loss 2.98 on epoch=129
06/24/2022 22:44:30 - INFO - __main__ - Step 270 Global step 270 Train loss 3.08 on epoch=134
06/24/2022 22:44:32 - INFO - __main__ - Step 280 Global step 280 Train loss 2.92 on epoch=139
06/24/2022 22:44:33 - INFO - __main__ - Step 290 Global step 290 Train loss 2.90 on epoch=144
06/24/2022 22:44:34 - INFO - __main__ - Step 300 Global step 300 Train loss 2.80 on epoch=149
06/24/2022 22:44:35 - INFO - __main__ - Global step 300 Train loss 2.93 ACC 0.03125 on epoch=149
06/24/2022 22:44:35 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=149, global_step=300
06/24/2022 22:44:36 - INFO - __main__ - Step 310 Global step 310 Train loss 2.72 on epoch=154
06/24/2022 22:44:38 - INFO - __main__ - Step 320 Global step 320 Train loss 2.67 on epoch=159
06/24/2022 22:44:39 - INFO - __main__ - Step 330 Global step 330 Train loss 2.66 on epoch=164
06/24/2022 22:44:40 - INFO - __main__ - Step 340 Global step 340 Train loss 2.60 on epoch=169
06/24/2022 22:44:42 - INFO - __main__ - Step 350 Global step 350 Train loss 2.48 on epoch=174
06/24/2022 22:44:47 - INFO - __main__ - Global step 350 Train loss 2.63 ACC 0.125 on epoch=174
06/24/2022 22:44:47 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.125 on epoch=174, global_step=350
06/24/2022 22:44:48 - INFO - __main__ - Step 360 Global step 360 Train loss 2.30 on epoch=179
06/24/2022 22:44:49 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=184
06/24/2022 22:44:50 - INFO - __main__ - Step 380 Global step 380 Train loss 2.32 on epoch=189
06/24/2022 22:44:52 - INFO - __main__ - Step 390 Global step 390 Train loss 2.34 on epoch=194
06/24/2022 22:44:53 - INFO - __main__ - Step 400 Global step 400 Train loss 2.13 on epoch=199
06/24/2022 22:44:56 - INFO - __main__ - Global step 400 Train loss 2.28 ACC 0.15625 on epoch=199
06/24/2022 22:44:56 - INFO - __main__ - Saving model with best ACC: 0.125 -> 0.15625 on epoch=199, global_step=400
06/24/2022 22:44:57 - INFO - __main__ - Step 410 Global step 410 Train loss 2.20 on epoch=204
06/24/2022 22:44:58 - INFO - __main__ - Step 420 Global step 420 Train loss 2.11 on epoch=209
06/24/2022 22:45:00 - INFO - __main__ - Step 430 Global step 430 Train loss 2.03 on epoch=214
06/24/2022 22:45:01 - INFO - __main__ - Step 440 Global step 440 Train loss 1.97 on epoch=219
06/24/2022 22:45:02 - INFO - __main__ - Step 450 Global step 450 Train loss 1.91 on epoch=224
06/24/2022 22:45:03 - INFO - __main__ - Global step 450 Train loss 2.05 ACC 0.4375 on epoch=224
06/24/2022 22:45:03 - INFO - __main__ - Saving model with best ACC: 0.15625 -> 0.4375 on epoch=224, global_step=450
06/24/2022 22:45:04 - INFO - __main__ - Step 460 Global step 460 Train loss 1.91 on epoch=229
06/24/2022 22:45:06 - INFO - __main__ - Step 470 Global step 470 Train loss 1.86 on epoch=234
06/24/2022 22:45:07 - INFO - __main__ - Step 480 Global step 480 Train loss 2.00 on epoch=239
06/24/2022 22:45:08 - INFO - __main__ - Step 490 Global step 490 Train loss 1.82 on epoch=244
06/24/2022 22:45:10 - INFO - __main__ - Step 500 Global step 500 Train loss 1.76 on epoch=249
06/24/2022 22:45:20 - INFO - __main__ - Global step 500 Train loss 1.87 ACC 0.21875 on epoch=249
06/24/2022 22:45:21 - INFO - __main__ - Step 510 Global step 510 Train loss 1.77 on epoch=254
06/24/2022 22:45:22 - INFO - __main__ - Step 520 Global step 520 Train loss 1.66 on epoch=259
06/24/2022 22:45:24 - INFO - __main__ - Step 530 Global step 530 Train loss 1.69 on epoch=264
06/24/2022 22:45:25 - INFO - __main__ - Step 540 Global step 540 Train loss 1.62 on epoch=269
06/24/2022 22:45:26 - INFO - __main__ - Step 550 Global step 550 Train loss 1.60 on epoch=274
06/24/2022 22:45:28 - INFO - __main__ - Global step 550 Train loss 1.67 ACC 0.375 on epoch=274
06/24/2022 22:45:30 - INFO - __main__ - Step 560 Global step 560 Train loss 1.53 on epoch=279
06/24/2022 22:45:31 - INFO - __main__ - Step 570 Global step 570 Train loss 1.55 on epoch=284
06/24/2022 22:45:32 - INFO - __main__ - Step 580 Global step 580 Train loss 1.48 on epoch=289
06/24/2022 22:45:33 - INFO - __main__ - Step 590 Global step 590 Train loss 1.48 on epoch=294
06/24/2022 22:45:35 - INFO - __main__ - Step 600 Global step 600 Train loss 1.41 on epoch=299
06/24/2022 22:45:41 - INFO - __main__ - Global step 600 Train loss 1.49 ACC 0.46875 on epoch=299
06/24/2022 22:45:41 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=299, global_step=600
06/24/2022 22:45:42 - INFO - __main__ - Step 610 Global step 610 Train loss 1.35 on epoch=304
06/24/2022 22:45:43 - INFO - __main__ - Step 620 Global step 620 Train loss 1.31 on epoch=309
06/24/2022 22:45:45 - INFO - __main__ - Step 630 Global step 630 Train loss 1.33 on epoch=314
06/24/2022 22:45:46 - INFO - __main__ - Step 640 Global step 640 Train loss 1.39 on epoch=319
06/24/2022 22:45:47 - INFO - __main__ - Step 650 Global step 650 Train loss 1.36 on epoch=324
06/24/2022 22:45:49 - INFO - __main__ - Global step 650 Train loss 1.35 ACC 0.5 on epoch=324
06/24/2022 22:45:49 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=324, global_step=650
06/24/2022 22:45:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.25 on epoch=329
06/24/2022 22:45:52 - INFO - __main__ - Step 670 Global step 670 Train loss 1.30 on epoch=334
06/24/2022 22:45:53 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=339
06/24/2022 22:45:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.22 on epoch=344
06/24/2022 22:45:56 - INFO - __main__ - Step 700 Global step 700 Train loss 1.18 on epoch=349
06/24/2022 22:45:56 - INFO - __main__ - Global step 700 Train loss 1.23 ACC 0.5 on epoch=349
06/24/2022 22:45:58 - INFO - __main__ - Step 710 Global step 710 Train loss 1.10 on epoch=354
06/24/2022 22:45:59 - INFO - __main__ - Step 720 Global step 720 Train loss 1.15 on epoch=359
06/24/2022 22:46:00 - INFO - __main__ - Step 730 Global step 730 Train loss 1.14 on epoch=364
06/24/2022 22:46:01 - INFO - __main__ - Step 740 Global step 740 Train loss 1.11 on epoch=369
06/24/2022 22:46:03 - INFO - __main__ - Step 750 Global step 750 Train loss 1.15 on epoch=374
06/24/2022 22:46:03 - INFO - __main__ - Global step 750 Train loss 1.13 ACC 0.5 on epoch=374
06/24/2022 22:46:05 - INFO - __main__ - Step 760 Global step 760 Train loss 1.14 on epoch=379
06/24/2022 22:46:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.99 on epoch=384
06/24/2022 22:46:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.97 on epoch=389
06/24/2022 22:46:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.90 on epoch=394
06/24/2022 22:46:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.96 on epoch=399
06/24/2022 22:46:15 - INFO - __main__ - Global step 800 Train loss 0.99 ACC 0.5 on epoch=399
06/24/2022 22:46:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.92 on epoch=404
06/24/2022 22:46:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.95 on epoch=409
06/24/2022 22:46:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.91 on epoch=414
06/24/2022 22:46:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.96 on epoch=419
06/24/2022 22:46:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.85 on epoch=424
06/24/2022 22:46:23 - INFO - __main__ - Global step 850 Train loss 0.92 ACC 0.5 on epoch=424
06/24/2022 22:46:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.87 on epoch=429
06/24/2022 22:46:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.79 on epoch=434
06/24/2022 22:46:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.80 on epoch=439
06/24/2022 22:46:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.82 on epoch=444
06/24/2022 22:46:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.82 on epoch=449
06/24/2022 22:46:37 - INFO - __main__ - Global step 900 Train loss 0.82 ACC 0.5 on epoch=449
06/24/2022 22:46:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.76 on epoch=454
06/24/2022 22:46:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.78 on epoch=459
06/24/2022 22:46:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.73 on epoch=464
06/24/2022 22:46:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.70 on epoch=469
06/24/2022 22:46:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.78 on epoch=474
06/24/2022 22:46:45 - INFO - __main__ - Global step 950 Train loss 0.75 ACC 0.5 on epoch=474
06/24/2022 22:46:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.68 on epoch=479
06/24/2022 22:46:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.71 on epoch=484
06/24/2022 22:46:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.70 on epoch=489
06/24/2022 22:46:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.69 on epoch=494
06/24/2022 22:46:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.62 on epoch=499
06/24/2022 22:46:53 - INFO - __main__ - Global step 1000 Train loss 0.68 ACC 0.5 on epoch=499
06/24/2022 22:46:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.61 on epoch=504
06/24/2022 22:46:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.54 on epoch=509
06/24/2022 22:46:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.63 on epoch=514
06/24/2022 22:46:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.62 on epoch=519
06/24/2022 22:47:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.48 on epoch=524
06/24/2022 22:47:01 - INFO - __main__ - Global step 1050 Train loss 0.58 ACC 0.5 on epoch=524
06/24/2022 22:47:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.67 on epoch=529
06/24/2022 22:47:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.62 on epoch=534
06/24/2022 22:47:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.58 on epoch=539
06/24/2022 22:47:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.53 on epoch=544
06/24/2022 22:47:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.46 on epoch=549
06/24/2022 22:47:09 - INFO - __main__ - Global step 1100 Train loss 0.57 ACC 0.5 on epoch=549
06/24/2022 22:47:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.52 on epoch=554
06/24/2022 22:47:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.54 on epoch=559
06/24/2022 22:47:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.60 on epoch=564
06/24/2022 22:47:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.60 on epoch=569
06/24/2022 22:47:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.58 on epoch=574
06/24/2022 22:47:17 - INFO - __main__ - Global step 1150 Train loss 0.57 ACC 0.5 on epoch=574
06/24/2022 22:47:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.50 on epoch=579
06/24/2022 22:47:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.51 on epoch=584
06/24/2022 22:47:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.48 on epoch=589
06/24/2022 22:47:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.45 on epoch=594
06/24/2022 22:47:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.46 on epoch=599
06/24/2022 22:47:25 - INFO - __main__ - Global step 1200 Train loss 0.48 ACC 0.5 on epoch=599
06/24/2022 22:47:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.61 on epoch=604
06/24/2022 22:47:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.49 on epoch=609
06/24/2022 22:47:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.51 on epoch=614
06/24/2022 22:47:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.49 on epoch=619
06/24/2022 22:47:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.47 on epoch=624
06/24/2022 22:47:33 - INFO - __main__ - Global step 1250 Train loss 0.51 ACC 0.5 on epoch=624
06/24/2022 22:47:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.43 on epoch=629
06/24/2022 22:47:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.43 on epoch=634
06/24/2022 22:47:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.54 on epoch=639
06/24/2022 22:47:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.46 on epoch=644
06/24/2022 22:47:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.55 on epoch=649
06/24/2022 22:47:40 - INFO - __main__ - Global step 1300 Train loss 0.48 ACC 0.5 on epoch=649
06/24/2022 22:47:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.46 on epoch=654
06/24/2022 22:47:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.45 on epoch=659
06/24/2022 22:47:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.47 on epoch=664
06/24/2022 22:47:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.51 on epoch=669
06/24/2022 22:47:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.52 on epoch=674
06/24/2022 22:47:47 - INFO - __main__ - Global step 1350 Train loss 0.48 ACC 0.5 on epoch=674
06/24/2022 22:47:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.48 on epoch=679
06/24/2022 22:47:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.44 on epoch=684
06/24/2022 22:47:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.41 on epoch=689
06/24/2022 22:47:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.37 on epoch=694
06/24/2022 22:47:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.38 on epoch=699
06/24/2022 22:47:54 - INFO - __main__ - Global step 1400 Train loss 0.42 ACC 0.5 on epoch=699
06/24/2022 22:47:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.47 on epoch=704
06/24/2022 22:47:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.44 on epoch=709
06/24/2022 22:47:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.40 on epoch=714
06/24/2022 22:47:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.43 on epoch=719
06/24/2022 22:48:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.39 on epoch=724
06/24/2022 22:48:01 - INFO - __main__ - Global step 1450 Train loss 0.43 ACC 0.5 on epoch=724
06/24/2022 22:48:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.42 on epoch=729
06/24/2022 22:48:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.45 on epoch=734
06/24/2022 22:48:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.43 on epoch=739
06/24/2022 22:48:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.47 on epoch=744
06/24/2022 22:48:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.38 on epoch=749
06/24/2022 22:48:08 - INFO - __main__ - Global step 1500 Train loss 0.43 ACC 0.5 on epoch=749
06/24/2022 22:48:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.46 on epoch=754
06/24/2022 22:48:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.40 on epoch=759
06/24/2022 22:48:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.41 on epoch=764
06/24/2022 22:48:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.39 on epoch=769
06/24/2022 22:48:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.49 on epoch=774
06/24/2022 22:48:16 - INFO - __main__ - Global step 1550 Train loss 0.43 ACC 0.5 on epoch=774
06/24/2022 22:48:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.43 on epoch=779
06/24/2022 22:48:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.38 on epoch=784
06/24/2022 22:48:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.40 on epoch=789
06/24/2022 22:48:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.37 on epoch=794
06/24/2022 22:48:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.43 on epoch=799
06/24/2022 22:48:23 - INFO - __main__ - Global step 1600 Train loss 0.40 ACC 0.5 on epoch=799
06/24/2022 22:48:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.40 on epoch=804
06/24/2022 22:48:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.40 on epoch=809
06/24/2022 22:48:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.38 on epoch=814
06/24/2022 22:48:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.39 on epoch=819
06/24/2022 22:48:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.37 on epoch=824
06/24/2022 22:48:30 - INFO - __main__ - Global step 1650 Train loss 0.39 ACC 0.5 on epoch=824
06/24/2022 22:48:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.40 on epoch=829
06/24/2022 22:48:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.39 on epoch=834
06/24/2022 22:48:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.43 on epoch=839
06/24/2022 22:48:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.30 on epoch=844
06/24/2022 22:48:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.44 on epoch=849
06/24/2022 22:48:38 - INFO - __main__ - Global step 1700 Train loss 0.39 ACC 0.5 on epoch=849
06/24/2022 22:48:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.35 on epoch=854
06/24/2022 22:48:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.35 on epoch=859
06/24/2022 22:48:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.43 on epoch=864
06/24/2022 22:48:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.37 on epoch=869
06/24/2022 22:48:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.42 on epoch=874
06/24/2022 22:48:46 - INFO - __main__ - Global step 1750 Train loss 0.38 ACC 0.5 on epoch=874
06/24/2022 22:48:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.42 on epoch=879
06/24/2022 22:48:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.41 on epoch=884
06/24/2022 22:48:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.36 on epoch=889
06/24/2022 22:48:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.37 on epoch=894
06/24/2022 22:48:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.36 on epoch=899
06/24/2022 22:48:53 - INFO - __main__ - Global step 1800 Train loss 0.38 ACC 0.53125 on epoch=899
06/24/2022 22:48:53 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=899, global_step=1800
06/24/2022 22:48:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.37 on epoch=904
06/24/2022 22:48:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.40 on epoch=909
06/24/2022 22:48:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.41 on epoch=914
06/24/2022 22:48:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.41 on epoch=919
06/24/2022 22:48:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.32 on epoch=924
06/24/2022 22:49:00 - INFO - __main__ - Global step 1850 Train loss 0.38 ACC 0.5 on epoch=924
06/24/2022 22:49:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.42 on epoch=929
06/24/2022 22:49:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.41 on epoch=934
06/24/2022 22:49:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.30 on epoch=939
06/24/2022 22:49:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.36 on epoch=944
06/24/2022 22:49:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.38 on epoch=949
06/24/2022 22:49:07 - INFO - __main__ - Global step 1900 Train loss 0.37 ACC 0.5 on epoch=949
06/24/2022 22:49:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.37 on epoch=954
06/24/2022 22:49:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.33 on epoch=959
06/24/2022 22:49:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.32 on epoch=964
06/24/2022 22:49:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.32 on epoch=969
06/24/2022 22:49:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.36 on epoch=974
06/24/2022 22:49:14 - INFO - __main__ - Global step 1950 Train loss 0.34 ACC 0.5 on epoch=974
06/24/2022 22:49:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.33 on epoch=979
06/24/2022 22:49:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.37 on epoch=984
06/24/2022 22:49:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.38 on epoch=989
06/24/2022 22:49:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.35 on epoch=994
06/24/2022 22:49:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.37 on epoch=999
06/24/2022 22:49:21 - INFO - __main__ - Global step 2000 Train loss 0.36 ACC 0.5 on epoch=999
06/24/2022 22:49:21 - INFO - __main__ - save last model!
06/24/2022 22:49:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:49:21 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 22:49:21 - INFO - __main__ - Printing 3 examples
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 22:49:21 - INFO - __main__ - ['duplicate']
06/24/2022 22:49:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:49:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:49:21 - INFO - __main__ - Printing 3 examples
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:49:21 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:49:21 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 22:49:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 22:49:21 - INFO - __main__ - Printing 3 examples
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 22:49:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 22:49:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:49:21 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:49:21 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 22:49:27 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:49:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 22:49:27 - INFO - __main__ - Starting training!
06/24/2022 22:49:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:50:21 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 23:03:01 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_21_0.4_8_predictions.txt
06/24/2022 23:03:01 - INFO - __main__ - ACC on test data: 0.3686
06/24/2022 23:03:01 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.4, bsz=8, dev_performance=0.53125, test_performance=0.36856294830571357
06/24/2022 23:03:01 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.3, bsz=8 ...
06/24/2022 23:03:02 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:03:02 - INFO - __main__ - Printing 3 examples
06/24/2022 23:03:02 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 23:03:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:03:02 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 23:03:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:03:02 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 23:03:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:03:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:03:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:03:02 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:03:02 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:03:02 - INFO - __main__ - Printing 3 examples
06/24/2022 23:03:02 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 23:03:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:03:02 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 23:03:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:03:02 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 23:03:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:03:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:03:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:03:02 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:03:08 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:03:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:03:09 - INFO - __main__ - Starting training!
06/24/2022 23:03:10 - INFO - __main__ - Step 10 Global step 10 Train loss 6.33 on epoch=4
06/24/2022 23:03:11 - INFO - __main__ - Step 20 Global step 20 Train loss 6.20 on epoch=9
06/24/2022 23:03:13 - INFO - __main__ - Step 30 Global step 30 Train loss 6.04 on epoch=14
06/24/2022 23:03:14 - INFO - __main__ - Step 40 Global step 40 Train loss 5.94 on epoch=19
06/24/2022 23:03:15 - INFO - __main__ - Step 50 Global step 50 Train loss 5.71 on epoch=24
06/24/2022 23:03:18 - INFO - __main__ - Global step 50 Train loss 6.04 ACC 0.0 on epoch=24
06/24/2022 23:03:18 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 23:03:19 - INFO - __main__ - Step 60 Global step 60 Train loss 5.68 on epoch=29
06/24/2022 23:03:21 - INFO - __main__ - Step 70 Global step 70 Train loss 5.54 on epoch=34
06/24/2022 23:03:22 - INFO - __main__ - Step 80 Global step 80 Train loss 5.42 on epoch=39
06/24/2022 23:03:23 - INFO - __main__ - Step 90 Global step 90 Train loss 5.33 on epoch=44
06/24/2022 23:03:24 - INFO - __main__ - Step 100 Global step 100 Train loss 5.26 on epoch=49
06/24/2022 23:03:26 - INFO - __main__ - Global step 100 Train loss 5.44 ACC 0.0 on epoch=49
06/24/2022 23:03:27 - INFO - __main__ - Step 110 Global step 110 Train loss 5.08 on epoch=54
06/24/2022 23:03:29 - INFO - __main__ - Step 120 Global step 120 Train loss 5.05 on epoch=59
06/24/2022 23:03:30 - INFO - __main__ - Step 130 Global step 130 Train loss 5.04 on epoch=64
06/24/2022 23:03:31 - INFO - __main__ - Step 140 Global step 140 Train loss 4.97 on epoch=69
06/24/2022 23:03:32 - INFO - __main__ - Step 150 Global step 150 Train loss 4.99 on epoch=74
06/24/2022 23:03:33 - INFO - __main__ - Global step 150 Train loss 5.02 ACC 0.0 on epoch=74
06/24/2022 23:03:35 - INFO - __main__ - Step 160 Global step 160 Train loss 4.72 on epoch=79
06/24/2022 23:03:36 - INFO - __main__ - Step 170 Global step 170 Train loss 4.68 on epoch=84
06/24/2022 23:03:37 - INFO - __main__ - Step 180 Global step 180 Train loss 4.65 on epoch=89
06/24/2022 23:03:38 - INFO - __main__ - Step 190 Global step 190 Train loss 4.57 on epoch=94
06/24/2022 23:03:40 - INFO - __main__ - Step 200 Global step 200 Train loss 4.56 on epoch=99
06/24/2022 23:03:42 - INFO - __main__ - Global step 200 Train loss 4.64 ACC 0.0 on epoch=99
06/24/2022 23:03:43 - INFO - __main__ - Step 210 Global step 210 Train loss 4.51 on epoch=104
06/24/2022 23:03:44 - INFO - __main__ - Step 220 Global step 220 Train loss 4.32 on epoch=109
06/24/2022 23:03:45 - INFO - __main__ - Step 230 Global step 230 Train loss 4.18 on epoch=114
06/24/2022 23:03:47 - INFO - __main__ - Step 240 Global step 240 Train loss 4.08 on epoch=119
06/24/2022 23:03:48 - INFO - __main__ - Step 250 Global step 250 Train loss 4.11 on epoch=124
06/24/2022 23:03:51 - INFO - __main__ - Global step 250 Train loss 4.24 ACC 0.0 on epoch=124
06/24/2022 23:03:52 - INFO - __main__ - Step 260 Global step 260 Train loss 3.98 on epoch=129
06/24/2022 23:03:53 - INFO - __main__ - Step 270 Global step 270 Train loss 3.92 on epoch=134
06/24/2022 23:03:54 - INFO - __main__ - Step 280 Global step 280 Train loss 3.91 on epoch=139
06/24/2022 23:03:56 - INFO - __main__ - Step 290 Global step 290 Train loss 3.87 on epoch=144
06/24/2022 23:03:57 - INFO - __main__ - Step 300 Global step 300 Train loss 3.80 on epoch=149
06/24/2022 23:04:00 - INFO - __main__ - Global step 300 Train loss 3.90 ACC 0.0 on epoch=149
06/24/2022 23:04:01 - INFO - __main__ - Step 310 Global step 310 Train loss 3.83 on epoch=154
06/24/2022 23:04:02 - INFO - __main__ - Step 320 Global step 320 Train loss 3.68 on epoch=159
06/24/2022 23:04:03 - INFO - __main__ - Step 330 Global step 330 Train loss 3.59 on epoch=164
06/24/2022 23:04:05 - INFO - __main__ - Step 340 Global step 340 Train loss 3.59 on epoch=169
06/24/2022 23:04:06 - INFO - __main__ - Step 350 Global step 350 Train loss 3.50 on epoch=174
06/24/2022 23:04:07 - INFO - __main__ - Global step 350 Train loss 3.64 ACC 0.0 on epoch=174
06/24/2022 23:04:08 - INFO - __main__ - Step 360 Global step 360 Train loss 3.47 on epoch=179
06/24/2022 23:04:10 - INFO - __main__ - Step 370 Global step 370 Train loss 3.46 on epoch=184
06/24/2022 23:04:11 - INFO - __main__ - Step 380 Global step 380 Train loss 3.42 on epoch=189
06/24/2022 23:04:12 - INFO - __main__ - Step 390 Global step 390 Train loss 3.44 on epoch=194
06/24/2022 23:04:13 - INFO - __main__ - Step 400 Global step 400 Train loss 3.29 on epoch=199
06/24/2022 23:04:14 - INFO - __main__ - Global step 400 Train loss 3.42 ACC 0.0 on epoch=199
06/24/2022 23:04:16 - INFO - __main__ - Step 410 Global step 410 Train loss 3.28 on epoch=204
06/24/2022 23:04:17 - INFO - __main__ - Step 420 Global step 420 Train loss 3.21 on epoch=209
06/24/2022 23:04:18 - INFO - __main__ - Step 430 Global step 430 Train loss 3.16 on epoch=214
06/24/2022 23:04:19 - INFO - __main__ - Step 440 Global step 440 Train loss 3.13 on epoch=219
06/24/2022 23:04:21 - INFO - __main__ - Step 450 Global step 450 Train loss 3.11 on epoch=224
06/24/2022 23:04:22 - INFO - __main__ - Global step 450 Train loss 3.18 ACC 0.0 on epoch=224
06/24/2022 23:04:23 - INFO - __main__ - Step 460 Global step 460 Train loss 2.99 on epoch=229
06/24/2022 23:04:25 - INFO - __main__ - Step 470 Global step 470 Train loss 2.95 on epoch=234
06/24/2022 23:04:26 - INFO - __main__ - Step 480 Global step 480 Train loss 2.88 on epoch=239
06/24/2022 23:04:27 - INFO - __main__ - Step 490 Global step 490 Train loss 2.99 on epoch=244
06/24/2022 23:04:28 - INFO - __main__ - Step 500 Global step 500 Train loss 2.84 on epoch=249
06/24/2022 23:04:30 - INFO - __main__ - Global step 500 Train loss 2.93 ACC 0.0 on epoch=249
06/24/2022 23:04:31 - INFO - __main__ - Step 510 Global step 510 Train loss 2.78 on epoch=254
06/24/2022 23:04:32 - INFO - __main__ - Step 520 Global step 520 Train loss 2.70 on epoch=259
06/24/2022 23:04:33 - INFO - __main__ - Step 530 Global step 530 Train loss 2.67 on epoch=264
06/24/2022 23:04:35 - INFO - __main__ - Step 540 Global step 540 Train loss 2.59 on epoch=269
06/24/2022 23:04:36 - INFO - __main__ - Step 550 Global step 550 Train loss 2.63 on epoch=274
06/24/2022 23:04:38 - INFO - __main__ - Global step 550 Train loss 2.68 ACC 0.0 on epoch=274
06/24/2022 23:04:39 - INFO - __main__ - Step 560 Global step 560 Train loss 2.57 on epoch=279
06/24/2022 23:04:41 - INFO - __main__ - Step 570 Global step 570 Train loss 2.51 on epoch=284
06/24/2022 23:04:42 - INFO - __main__ - Step 580 Global step 580 Train loss 2.52 on epoch=289
06/24/2022 23:04:43 - INFO - __main__ - Step 590 Global step 590 Train loss 2.50 on epoch=294
06/24/2022 23:04:44 - INFO - __main__ - Step 600 Global step 600 Train loss 2.46 on epoch=299
06/24/2022 23:04:45 - INFO - __main__ - Global step 600 Train loss 2.51 ACC 0.0 on epoch=299
06/24/2022 23:04:47 - INFO - __main__ - Step 610 Global step 610 Train loss 2.31 on epoch=304
06/24/2022 23:04:48 - INFO - __main__ - Step 620 Global step 620 Train loss 2.24 on epoch=309
06/24/2022 23:04:49 - INFO - __main__ - Step 630 Global step 630 Train loss 2.27 on epoch=314
06/24/2022 23:04:51 - INFO - __main__ - Step 640 Global step 640 Train loss 2.34 on epoch=319
06/24/2022 23:04:52 - INFO - __main__ - Step 650 Global step 650 Train loss 2.22 on epoch=324
06/24/2022 23:04:53 - INFO - __main__ - Global step 650 Train loss 2.28 ACC 0.40625 on epoch=324
06/24/2022 23:04:53 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.40625 on epoch=324, global_step=650
06/24/2022 23:04:55 - INFO - __main__ - Step 660 Global step 660 Train loss 2.25 on epoch=329
06/24/2022 23:04:56 - INFO - __main__ - Step 670 Global step 670 Train loss 2.24 on epoch=334
06/24/2022 23:04:57 - INFO - __main__ - Step 680 Global step 680 Train loss 2.24 on epoch=339
06/24/2022 23:04:58 - INFO - __main__ - Step 690 Global step 690 Train loss 2.08 on epoch=344
06/24/2022 23:05:00 - INFO - __main__ - Step 700 Global step 700 Train loss 2.01 on epoch=349
06/24/2022 23:05:06 - INFO - __main__ - Global step 700 Train loss 2.16 ACC 0.34375 on epoch=349
06/24/2022 23:05:07 - INFO - __main__ - Step 710 Global step 710 Train loss 2.19 on epoch=354
06/24/2022 23:05:09 - INFO - __main__ - Step 720 Global step 720 Train loss 2.01 on epoch=359
06/24/2022 23:05:10 - INFO - __main__ - Step 730 Global step 730 Train loss 2.05 on epoch=364
06/24/2022 23:05:11 - INFO - __main__ - Step 740 Global step 740 Train loss 1.94 on epoch=369
06/24/2022 23:05:13 - INFO - __main__ - Step 750 Global step 750 Train loss 2.02 on epoch=374
06/24/2022 23:05:14 - INFO - __main__ - Global step 750 Train loss 2.04 ACC 0.4375 on epoch=374
06/24/2022 23:05:14 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.4375 on epoch=374, global_step=750
06/24/2022 23:05:15 - INFO - __main__ - Step 760 Global step 760 Train loss 1.96 on epoch=379
06/24/2022 23:05:16 - INFO - __main__ - Step 770 Global step 770 Train loss 1.88 on epoch=384
06/24/2022 23:05:18 - INFO - __main__ - Step 780 Global step 780 Train loss 1.86 on epoch=389
06/24/2022 23:05:19 - INFO - __main__ - Step 790 Global step 790 Train loss 1.82 on epoch=394
06/24/2022 23:05:20 - INFO - __main__ - Step 800 Global step 800 Train loss 1.82 on epoch=399
06/24/2022 23:05:26 - INFO - __main__ - Global step 800 Train loss 1.87 ACC 0.46875 on epoch=399
06/24/2022 23:05:26 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=399, global_step=800
06/24/2022 23:05:27 - INFO - __main__ - Step 810 Global step 810 Train loss 1.82 on epoch=404
06/24/2022 23:05:28 - INFO - __main__ - Step 820 Global step 820 Train loss 1.71 on epoch=409
06/24/2022 23:05:30 - INFO - __main__ - Step 830 Global step 830 Train loss 1.74 on epoch=414
06/24/2022 23:05:31 - INFO - __main__ - Step 840 Global step 840 Train loss 1.77 on epoch=419
06/24/2022 23:05:32 - INFO - __main__ - Step 850 Global step 850 Train loss 1.66 on epoch=424
06/24/2022 23:05:34 - INFO - __main__ - Global step 850 Train loss 1.74 ACC 0.5 on epoch=424
06/24/2022 23:05:34 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=424, global_step=850
06/24/2022 23:05:36 - INFO - __main__ - Step 860 Global step 860 Train loss 1.59 on epoch=429
06/24/2022 23:05:37 - INFO - __main__ - Step 870 Global step 870 Train loss 1.59 on epoch=434
06/24/2022 23:05:38 - INFO - __main__ - Step 880 Global step 880 Train loss 1.64 on epoch=439
06/24/2022 23:05:39 - INFO - __main__ - Step 890 Global step 890 Train loss 1.58 on epoch=444
06/24/2022 23:05:41 - INFO - __main__ - Step 900 Global step 900 Train loss 1.50 on epoch=449
06/24/2022 23:05:42 - INFO - __main__ - Global step 900 Train loss 1.58 ACC 0.5 on epoch=449
06/24/2022 23:05:44 - INFO - __main__ - Step 910 Global step 910 Train loss 1.45 on epoch=454
06/24/2022 23:05:45 - INFO - __main__ - Step 920 Global step 920 Train loss 1.59 on epoch=459
06/24/2022 23:05:46 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=464
06/24/2022 23:05:47 - INFO - __main__ - Step 940 Global step 940 Train loss 1.43 on epoch=469
06/24/2022 23:05:49 - INFO - __main__ - Step 950 Global step 950 Train loss 1.41 on epoch=474
06/24/2022 23:05:50 - INFO - __main__ - Global step 950 Train loss 1.48 ACC 0.5 on epoch=474
06/24/2022 23:05:51 - INFO - __main__ - Step 960 Global step 960 Train loss 1.52 on epoch=479
06/24/2022 23:05:52 - INFO - __main__ - Step 970 Global step 970 Train loss 1.42 on epoch=484
06/24/2022 23:05:54 - INFO - __main__ - Step 980 Global step 980 Train loss 1.42 on epoch=489
06/24/2022 23:05:55 - INFO - __main__ - Step 990 Global step 990 Train loss 1.36 on epoch=494
06/24/2022 23:05:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.28 on epoch=499
06/24/2022 23:05:57 - INFO - __main__ - Global step 1000 Train loss 1.40 ACC 0.5 on epoch=499
06/24/2022 23:05:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.28 on epoch=504
06/24/2022 23:06:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.23 on epoch=509
06/24/2022 23:06:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.13 on epoch=514
06/24/2022 23:06:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=519
06/24/2022 23:06:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.20 on epoch=524
06/24/2022 23:06:04 - INFO - __main__ - Global step 1050 Train loss 1.22 ACC 0.5 on epoch=524
06/24/2022 23:06:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.24 on epoch=529
06/24/2022 23:06:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.09 on epoch=534
06/24/2022 23:06:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.21 on epoch=539
06/24/2022 23:06:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.16 on epoch=544
06/24/2022 23:06:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.08 on epoch=549
06/24/2022 23:06:11 - INFO - __main__ - Global step 1100 Train loss 1.15 ACC 0.5 on epoch=549
06/24/2022 23:06:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.02 on epoch=554
06/24/2022 23:06:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.95 on epoch=559
06/24/2022 23:06:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.06 on epoch=564
06/24/2022 23:06:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.02 on epoch=569
06/24/2022 23:06:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.95 on epoch=574
06/24/2022 23:06:18 - INFO - __main__ - Global step 1150 Train loss 1.00 ACC 0.5 on epoch=574
06/24/2022 23:06:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.93 on epoch=579
06/24/2022 23:06:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.92 on epoch=584
06/24/2022 23:06:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.94 on epoch=589
06/24/2022 23:06:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.93 on epoch=594
06/24/2022 23:06:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.88 on epoch=599
06/24/2022 23:06:25 - INFO - __main__ - Global step 1200 Train loss 0.92 ACC 0.5 on epoch=599
06/24/2022 23:06:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.86 on epoch=604
06/24/2022 23:06:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.94 on epoch=609
06/24/2022 23:06:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.78 on epoch=614
06/24/2022 23:06:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.89 on epoch=619
06/24/2022 23:06:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.79 on epoch=624
06/24/2022 23:06:32 - INFO - __main__ - Global step 1250 Train loss 0.85 ACC 0.5 on epoch=624
06/24/2022 23:06:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.89 on epoch=629
06/24/2022 23:06:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.78 on epoch=634
06/24/2022 23:06:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.88 on epoch=639
06/24/2022 23:06:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.84 on epoch=644
06/24/2022 23:06:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.83 on epoch=649
06/24/2022 23:06:39 - INFO - __main__ - Global step 1300 Train loss 0.84 ACC 0.5 on epoch=649
06/24/2022 23:06:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.79 on epoch=654
06/24/2022 23:06:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.89 on epoch=659
06/24/2022 23:06:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.75 on epoch=664
06/24/2022 23:06:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.76 on epoch=669
06/24/2022 23:06:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.80 on epoch=674
06/24/2022 23:06:46 - INFO - __main__ - Global step 1350 Train loss 0.80 ACC 0.5 on epoch=674
06/24/2022 23:06:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.84 on epoch=679
06/24/2022 23:06:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.74 on epoch=684
06/24/2022 23:06:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.66 on epoch=689
06/24/2022 23:06:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.73 on epoch=694
06/24/2022 23:06:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.77 on epoch=699
06/24/2022 23:06:53 - INFO - __main__ - Global step 1400 Train loss 0.75 ACC 0.5 on epoch=699
06/24/2022 23:06:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.68 on epoch=704
06/24/2022 23:06:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.63 on epoch=709
06/24/2022 23:06:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.79 on epoch=714
06/24/2022 23:06:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.77 on epoch=719
06/24/2022 23:06:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=724
06/24/2022 23:07:00 - INFO - __main__ - Global step 1450 Train loss 0.72 ACC 0.5 on epoch=724
06/24/2022 23:07:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.78 on epoch=729
06/24/2022 23:07:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.79 on epoch=734
06/24/2022 23:07:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.69 on epoch=739
06/24/2022 23:07:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.68 on epoch=744
06/24/2022 23:07:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.66 on epoch=749
06/24/2022 23:07:07 - INFO - __main__ - Global step 1500 Train loss 0.72 ACC 0.5 on epoch=749
06/24/2022 23:07:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.72 on epoch=754
06/24/2022 23:07:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.66 on epoch=759
06/24/2022 23:07:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.66 on epoch=764
06/24/2022 23:07:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.71 on epoch=769
06/24/2022 23:07:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.73 on epoch=774
06/24/2022 23:07:14 - INFO - __main__ - Global step 1550 Train loss 0.70 ACC 0.5 on epoch=774
06/24/2022 23:07:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.59 on epoch=779
06/24/2022 23:07:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.78 on epoch=784
06/24/2022 23:07:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.71 on epoch=789
06/24/2022 23:07:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.61 on epoch=794
06/24/2022 23:07:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.57 on epoch=799
06/24/2022 23:07:21 - INFO - __main__ - Global step 1600 Train loss 0.65 ACC 0.5 on epoch=799
06/24/2022 23:07:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.63 on epoch=804
06/24/2022 23:07:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.62 on epoch=809
06/24/2022 23:07:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.56 on epoch=814
06/24/2022 23:07:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.60 on epoch=819
06/24/2022 23:07:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.55 on epoch=824
06/24/2022 23:07:28 - INFO - __main__ - Global step 1650 Train loss 0.59 ACC 0.5 on epoch=824
06/24/2022 23:07:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.66 on epoch=829
06/24/2022 23:07:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.64 on epoch=834
06/24/2022 23:07:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.58 on epoch=839
06/24/2022 23:07:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.71 on epoch=844
06/24/2022 23:07:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.82 on epoch=849
06/24/2022 23:07:35 - INFO - __main__ - Global step 1700 Train loss 0.68 ACC 0.5 on epoch=849
06/24/2022 23:07:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.60 on epoch=854
06/24/2022 23:07:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.57 on epoch=859
06/24/2022 23:07:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.55 on epoch=864
06/24/2022 23:07:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.58 on epoch=869
06/24/2022 23:07:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.58 on epoch=874
06/24/2022 23:07:41 - INFO - __main__ - Global step 1750 Train loss 0.58 ACC 0.5 on epoch=874
06/24/2022 23:07:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.55 on epoch=879
06/24/2022 23:07:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.58 on epoch=884
06/24/2022 23:07:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.56 on epoch=889
06/24/2022 23:07:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.56 on epoch=894
06/24/2022 23:07:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.50 on epoch=899
06/24/2022 23:07:48 - INFO - __main__ - Global step 1800 Train loss 0.55 ACC 0.5 on epoch=899
06/24/2022 23:07:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.54 on epoch=904
06/24/2022 23:07:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.53 on epoch=909
06/24/2022 23:07:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.48 on epoch=914
06/24/2022 23:07:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.55 on epoch=919
06/24/2022 23:07:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.55 on epoch=924
06/24/2022 23:07:55 - INFO - __main__ - Global step 1850 Train loss 0.53 ACC 0.5 on epoch=924
06/24/2022 23:07:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.45 on epoch=929
06/24/2022 23:07:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.57 on epoch=934
06/24/2022 23:07:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.56 on epoch=939
06/24/2022 23:08:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.54 on epoch=944
06/24/2022 23:08:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.51 on epoch=949
06/24/2022 23:08:01 - INFO - __main__ - Global step 1900 Train loss 0.53 ACC 0.5 on epoch=949
06/24/2022 23:08:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.56 on epoch=954
06/24/2022 23:08:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.50 on epoch=959
06/24/2022 23:08:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.50 on epoch=964
06/24/2022 23:08:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.51 on epoch=969
06/24/2022 23:08:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.52 on epoch=974
06/24/2022 23:08:08 - INFO - __main__ - Global step 1950 Train loss 0.52 ACC 0.5 on epoch=974
06/24/2022 23:08:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.54 on epoch=979
06/24/2022 23:08:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.48 on epoch=984
06/24/2022 23:08:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.56 on epoch=989
06/24/2022 23:08:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.50 on epoch=994
06/24/2022 23:08:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.47 on epoch=999
06/24/2022 23:08:15 - INFO - __main__ - Global step 2000 Train loss 0.51 ACC 0.5 on epoch=999
06/24/2022 23:08:15 - INFO - __main__ - save last model!
06/24/2022 23:08:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 23:08:15 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 23:08:15 - INFO - __main__ - Printing 3 examples
06/24/2022 23:08:15 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 23:08:15 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:15 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 23:08:15 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:15 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 23:08:15 - INFO - __main__ - ['duplicate']
06/24/2022 23:08:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:08:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:08:15 - INFO - __main__ - Printing 3 examples
06/24/2022 23:08:15 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 23:08:15 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:15 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 23:08:15 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:15 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 23:08:15 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:08:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:08:16 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:08:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:08:16 - INFO - __main__ - Printing 3 examples
06/24/2022 23:08:16 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 23:08:16 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:16 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 23:08:16 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:16 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 23:08:16 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:08:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:08:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:08:16 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:08:21 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:08:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:08:21 - INFO - __main__ - Starting training!
06/24/2022 23:08:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:09:15 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 23:20:21 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_21_0.3_8_predictions.txt
06/24/2022 23:20:21 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 23:20:21 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.3, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 23:20:21 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.2, bsz=8 ...
06/24/2022 23:20:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:20:22 - INFO - __main__ - Printing 3 examples
06/24/2022 23:20:22 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 23:20:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:20:22 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 23:20:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:20:22 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 23:20:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:20:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:20:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:20:22 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:20:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:20:22 - INFO - __main__ - Printing 3 examples
06/24/2022 23:20:22 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 23:20:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:20:22 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 23:20:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:20:22 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 23:20:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:20:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:20:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:20:22 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:20:28 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:20:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:20:29 - INFO - __main__ - Starting training!
06/24/2022 23:20:30 - INFO - __main__ - Step 10 Global step 10 Train loss 6.34 on epoch=4
06/24/2022 23:20:31 - INFO - __main__ - Step 20 Global step 20 Train loss 6.20 on epoch=9
06/24/2022 23:20:32 - INFO - __main__ - Step 30 Global step 30 Train loss 6.06 on epoch=14
06/24/2022 23:20:34 - INFO - __main__ - Step 40 Global step 40 Train loss 6.01 on epoch=19
06/24/2022 23:20:35 - INFO - __main__ - Step 50 Global step 50 Train loss 5.93 on epoch=24
06/24/2022 23:20:39 - INFO - __main__ - Global step 50 Train loss 6.11 ACC 0.0 on epoch=24
06/24/2022 23:20:39 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 23:20:40 - INFO - __main__ - Step 60 Global step 60 Train loss 5.81 on epoch=29
06/24/2022 23:20:41 - INFO - __main__ - Step 70 Global step 70 Train loss 5.70 on epoch=34
06/24/2022 23:20:43 - INFO - __main__ - Step 80 Global step 80 Train loss 5.60 on epoch=39
06/24/2022 23:20:44 - INFO - __main__ - Step 90 Global step 90 Train loss 5.50 on epoch=44
06/24/2022 23:20:45 - INFO - __main__ - Step 100 Global step 100 Train loss 5.65 on epoch=49
06/24/2022 23:20:47 - INFO - __main__ - Global step 100 Train loss 5.65 ACC 0.0 on epoch=49
06/24/2022 23:20:48 - INFO - __main__ - Step 110 Global step 110 Train loss 5.47 on epoch=54
06/24/2022 23:20:49 - INFO - __main__ - Step 120 Global step 120 Train loss 5.33 on epoch=59
06/24/2022 23:20:50 - INFO - __main__ - Step 130 Global step 130 Train loss 5.31 on epoch=64
06/24/2022 23:20:52 - INFO - __main__ - Step 140 Global step 140 Train loss 5.37 on epoch=69
06/24/2022 23:20:53 - INFO - __main__ - Step 150 Global step 150 Train loss 5.22 on epoch=74
06/24/2022 23:20:54 - INFO - __main__ - Global step 150 Train loss 5.34 ACC 0.0 on epoch=74
06/24/2022 23:20:56 - INFO - __main__ - Step 160 Global step 160 Train loss 5.21 on epoch=79
06/24/2022 23:20:57 - INFO - __main__ - Step 170 Global step 170 Train loss 5.25 on epoch=84
06/24/2022 23:20:58 - INFO - __main__ - Step 180 Global step 180 Train loss 5.08 on epoch=89
06/24/2022 23:20:59 - INFO - __main__ - Step 190 Global step 190 Train loss 5.10 on epoch=94
06/24/2022 23:21:01 - INFO - __main__ - Step 200 Global step 200 Train loss 4.95 on epoch=99
06/24/2022 23:21:02 - INFO - __main__ - Global step 200 Train loss 5.12 ACC 0.0 on epoch=99
06/24/2022 23:21:03 - INFO - __main__ - Step 210 Global step 210 Train loss 4.90 on epoch=104
06/24/2022 23:21:05 - INFO - __main__ - Step 220 Global step 220 Train loss 4.89 on epoch=109
06/24/2022 23:21:06 - INFO - __main__ - Step 230 Global step 230 Train loss 4.80 on epoch=114
06/24/2022 23:21:07 - INFO - __main__ - Step 240 Global step 240 Train loss 4.71 on epoch=119
06/24/2022 23:21:08 - INFO - __main__ - Step 250 Global step 250 Train loss 4.64 on epoch=124
06/24/2022 23:21:10 - INFO - __main__ - Global step 250 Train loss 4.79 ACC 0.0 on epoch=124
06/24/2022 23:21:11 - INFO - __main__ - Step 260 Global step 260 Train loss 4.57 on epoch=129
06/24/2022 23:21:12 - INFO - __main__ - Step 270 Global step 270 Train loss 4.58 on epoch=134
06/24/2022 23:21:14 - INFO - __main__ - Step 280 Global step 280 Train loss 4.43 on epoch=139
06/24/2022 23:21:15 - INFO - __main__ - Step 290 Global step 290 Train loss 4.35 on epoch=144
06/24/2022 23:21:16 - INFO - __main__ - Step 300 Global step 300 Train loss 4.39 on epoch=149
06/24/2022 23:21:18 - INFO - __main__ - Global step 300 Train loss 4.46 ACC 0.0 on epoch=149
06/24/2022 23:21:19 - INFO - __main__ - Step 310 Global step 310 Train loss 4.25 on epoch=154
06/24/2022 23:21:20 - INFO - __main__ - Step 320 Global step 320 Train loss 4.24 on epoch=159
06/24/2022 23:21:21 - INFO - __main__ - Step 330 Global step 330 Train loss 4.12 on epoch=164
06/24/2022 23:21:23 - INFO - __main__ - Step 340 Global step 340 Train loss 4.06 on epoch=169
06/24/2022 23:21:24 - INFO - __main__ - Step 350 Global step 350 Train loss 3.90 on epoch=174
06/24/2022 23:21:29 - INFO - __main__ - Global step 350 Train loss 4.11 ACC 0.0 on epoch=174
06/24/2022 23:21:30 - INFO - __main__ - Step 360 Global step 360 Train loss 3.94 on epoch=179
06/24/2022 23:21:31 - INFO - __main__ - Step 370 Global step 370 Train loss 3.94 on epoch=184
06/24/2022 23:21:33 - INFO - __main__ - Step 380 Global step 380 Train loss 3.72 on epoch=189
06/24/2022 23:21:34 - INFO - __main__ - Step 390 Global step 390 Train loss 3.80 on epoch=194
06/24/2022 23:21:35 - INFO - __main__ - Step 400 Global step 400 Train loss 3.69 on epoch=199
06/24/2022 23:21:36 - INFO - __main__ - Global step 400 Train loss 3.82 ACC 0.0 on epoch=199
06/24/2022 23:21:38 - INFO - __main__ - Step 410 Global step 410 Train loss 3.57 on epoch=204
06/24/2022 23:21:39 - INFO - __main__ - Step 420 Global step 420 Train loss 3.57 on epoch=209
06/24/2022 23:21:40 - INFO - __main__ - Step 430 Global step 430 Train loss 3.36 on epoch=214
06/24/2022 23:21:41 - INFO - __main__ - Step 440 Global step 440 Train loss 3.34 on epoch=219
06/24/2022 23:21:42 - INFO - __main__ - Step 450 Global step 450 Train loss 3.24 on epoch=224
06/24/2022 23:21:43 - INFO - __main__ - Global step 450 Train loss 3.42 ACC 0.0 on epoch=224
06/24/2022 23:21:45 - INFO - __main__ - Step 460 Global step 460 Train loss 3.24 on epoch=229
06/24/2022 23:21:46 - INFO - __main__ - Step 470 Global step 470 Train loss 3.24 on epoch=234
06/24/2022 23:21:47 - INFO - __main__ - Step 480 Global step 480 Train loss 3.32 on epoch=239
06/24/2022 23:21:48 - INFO - __main__ - Step 490 Global step 490 Train loss 3.00 on epoch=244
06/24/2022 23:21:50 - INFO - __main__ - Step 500 Global step 500 Train loss 3.23 on epoch=249
06/24/2022 23:21:51 - INFO - __main__ - Global step 500 Train loss 3.21 ACC 0.0 on epoch=249
06/24/2022 23:21:52 - INFO - __main__ - Step 510 Global step 510 Train loss 2.99 on epoch=254
06/24/2022 23:21:53 - INFO - __main__ - Step 520 Global step 520 Train loss 3.02 on epoch=259
06/24/2022 23:21:55 - INFO - __main__ - Step 530 Global step 530 Train loss 3.03 on epoch=264
06/24/2022 23:21:56 - INFO - __main__ - Step 540 Global step 540 Train loss 2.92 on epoch=269
06/24/2022 23:21:57 - INFO - __main__ - Step 550 Global step 550 Train loss 2.87 on epoch=274
06/24/2022 23:21:58 - INFO - __main__ - Global step 550 Train loss 2.96 ACC 0.0 on epoch=274
06/24/2022 23:21:59 - INFO - __main__ - Step 560 Global step 560 Train loss 2.75 on epoch=279
06/24/2022 23:22:01 - INFO - __main__ - Step 570 Global step 570 Train loss 2.80 on epoch=284
06/24/2022 23:22:02 - INFO - __main__ - Step 580 Global step 580 Train loss 2.78 on epoch=289
06/24/2022 23:22:03 - INFO - __main__ - Step 590 Global step 590 Train loss 2.68 on epoch=294
06/24/2022 23:22:04 - INFO - __main__ - Step 600 Global step 600 Train loss 2.59 on epoch=299
06/24/2022 23:22:05 - INFO - __main__ - Global step 600 Train loss 2.72 ACC 0.03125 on epoch=299
06/24/2022 23:22:05 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=299, global_step=600
06/24/2022 23:22:07 - INFO - __main__ - Step 610 Global step 610 Train loss 2.67 on epoch=304
06/24/2022 23:22:08 - INFO - __main__ - Step 620 Global step 620 Train loss 2.61 on epoch=309
06/24/2022 23:22:09 - INFO - __main__ - Step 630 Global step 630 Train loss 2.64 on epoch=314
06/24/2022 23:22:10 - INFO - __main__ - Step 640 Global step 640 Train loss 2.42 on epoch=319
06/24/2022 23:22:12 - INFO - __main__ - Step 650 Global step 650 Train loss 2.56 on epoch=324
06/24/2022 23:22:13 - INFO - __main__ - Global step 650 Train loss 2.58 ACC 0.15625 on epoch=324
06/24/2022 23:22:13 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.15625 on epoch=324, global_step=650
06/24/2022 23:22:14 - INFO - __main__ - Step 660 Global step 660 Train loss 2.50 on epoch=329
06/24/2022 23:22:15 - INFO - __main__ - Step 670 Global step 670 Train loss 2.53 on epoch=334
06/24/2022 23:22:16 - INFO - __main__ - Step 680 Global step 680 Train loss 2.42 on epoch=339
06/24/2022 23:22:18 - INFO - __main__ - Step 690 Global step 690 Train loss 2.37 on epoch=344
06/24/2022 23:22:19 - INFO - __main__ - Step 700 Global step 700 Train loss 2.37 on epoch=349
06/24/2022 23:22:20 - INFO - __main__ - Global step 700 Train loss 2.44 ACC 0.46875 on epoch=349
06/24/2022 23:22:20 - INFO - __main__ - Saving model with best ACC: 0.15625 -> 0.46875 on epoch=349, global_step=700
06/24/2022 23:22:22 - INFO - __main__ - Step 710 Global step 710 Train loss 2.30 on epoch=354
06/24/2022 23:22:23 - INFO - __main__ - Step 720 Global step 720 Train loss 2.36 on epoch=359
06/24/2022 23:22:24 - INFO - __main__ - Step 730 Global step 730 Train loss 2.22 on epoch=364
06/24/2022 23:22:25 - INFO - __main__ - Step 740 Global step 740 Train loss 2.30 on epoch=369
06/24/2022 23:22:27 - INFO - __main__ - Step 750 Global step 750 Train loss 2.25 on epoch=374
06/24/2022 23:22:28 - INFO - __main__ - Global step 750 Train loss 2.28 ACC 0.5 on epoch=374
06/24/2022 23:22:28 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=374, global_step=750
06/24/2022 23:22:29 - INFO - __main__ - Step 760 Global step 760 Train loss 2.23 on epoch=379
06/24/2022 23:22:31 - INFO - __main__ - Step 770 Global step 770 Train loss 2.22 on epoch=384
06/24/2022 23:22:32 - INFO - __main__ - Step 780 Global step 780 Train loss 2.23 on epoch=389
06/24/2022 23:22:33 - INFO - __main__ - Step 790 Global step 790 Train loss 2.08 on epoch=394
06/24/2022 23:22:34 - INFO - __main__ - Step 800 Global step 800 Train loss 2.18 on epoch=399
06/24/2022 23:22:36 - INFO - __main__ - Global step 800 Train loss 2.19 ACC 0.5 on epoch=399
06/24/2022 23:22:37 - INFO - __main__ - Step 810 Global step 810 Train loss 2.20 on epoch=404
06/24/2022 23:22:38 - INFO - __main__ - Step 820 Global step 820 Train loss 2.08 on epoch=409
06/24/2022 23:22:40 - INFO - __main__ - Step 830 Global step 830 Train loss 2.01 on epoch=414
06/24/2022 23:22:41 - INFO - __main__ - Step 840 Global step 840 Train loss 2.01 on epoch=419
06/24/2022 23:22:42 - INFO - __main__ - Step 850 Global step 850 Train loss 2.00 on epoch=424
06/24/2022 23:22:45 - INFO - __main__ - Global step 850 Train loss 2.06 ACC 0.5 on epoch=424
06/24/2022 23:22:46 - INFO - __main__ - Step 860 Global step 860 Train loss 1.95 on epoch=429
06/24/2022 23:22:47 - INFO - __main__ - Step 870 Global step 870 Train loss 1.87 on epoch=434
06/24/2022 23:22:48 - INFO - __main__ - Step 880 Global step 880 Train loss 1.92 on epoch=439
06/24/2022 23:22:50 - INFO - __main__ - Step 890 Global step 890 Train loss 1.92 on epoch=444
06/24/2022 23:22:51 - INFO - __main__ - Step 900 Global step 900 Train loss 1.83 on epoch=449
06/24/2022 23:22:54 - INFO - __main__ - Global step 900 Train loss 1.90 ACC 0.46875 on epoch=449
06/24/2022 23:22:56 - INFO - __main__ - Step 910 Global step 910 Train loss 1.81 on epoch=454
06/24/2022 23:22:57 - INFO - __main__ - Step 920 Global step 920 Train loss 1.96 on epoch=459
06/24/2022 23:22:58 - INFO - __main__ - Step 930 Global step 930 Train loss 1.77 on epoch=464
06/24/2022 23:22:59 - INFO - __main__ - Step 940 Global step 940 Train loss 1.85 on epoch=469
06/24/2022 23:23:01 - INFO - __main__ - Step 950 Global step 950 Train loss 1.75 on epoch=474
06/24/2022 23:23:04 - INFO - __main__ - Global step 950 Train loss 1.83 ACC 0.5 on epoch=474
06/24/2022 23:23:05 - INFO - __main__ - Step 960 Global step 960 Train loss 1.73 on epoch=479
06/24/2022 23:23:06 - INFO - __main__ - Step 970 Global step 970 Train loss 1.70 on epoch=484
06/24/2022 23:23:07 - INFO - __main__ - Step 980 Global step 980 Train loss 1.66 on epoch=489
06/24/2022 23:23:09 - INFO - __main__ - Step 990 Global step 990 Train loss 1.62 on epoch=494
06/24/2022 23:23:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.70 on epoch=499
06/24/2022 23:23:13 - INFO - __main__ - Global step 1000 Train loss 1.68 ACC 0.5 on epoch=499
06/24/2022 23:23:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.63 on epoch=504
06/24/2022 23:23:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.65 on epoch=509
06/24/2022 23:23:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.63 on epoch=514
06/24/2022 23:23:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.55 on epoch=519
06/24/2022 23:23:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.55 on epoch=524
06/24/2022 23:23:21 - INFO - __main__ - Global step 1050 Train loss 1.60 ACC 0.5 on epoch=524
06/24/2022 23:23:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.52 on epoch=529
06/24/2022 23:23:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.56 on epoch=534
06/24/2022 23:23:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.56 on epoch=539
06/24/2022 23:23:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.51 on epoch=544
06/24/2022 23:23:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.41 on epoch=549
06/24/2022 23:23:30 - INFO - __main__ - Global step 1100 Train loss 1.51 ACC 0.5 on epoch=549
06/24/2022 23:23:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.44 on epoch=554
06/24/2022 23:23:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.48 on epoch=559
06/24/2022 23:23:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.40 on epoch=564
06/24/2022 23:23:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.39 on epoch=569
06/24/2022 23:23:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.34 on epoch=574
06/24/2022 23:23:38 - INFO - __main__ - Global step 1150 Train loss 1.41 ACC 0.5 on epoch=574
06/24/2022 23:23:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.47 on epoch=579
06/24/2022 23:23:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.31 on epoch=584
06/24/2022 23:23:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=589
06/24/2022 23:23:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.34 on epoch=594
06/24/2022 23:23:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.33 on epoch=599
06/24/2022 23:23:46 - INFO - __main__ - Global step 1200 Train loss 1.35 ACC 0.5 on epoch=599
06/24/2022 23:23:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.22 on epoch=604
06/24/2022 23:23:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.35 on epoch=609
06/24/2022 23:23:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.38 on epoch=614
06/24/2022 23:23:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.29 on epoch=619
06/24/2022 23:23:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.31 on epoch=624
06/24/2022 23:23:53 - INFO - __main__ - Global step 1250 Train loss 1.31 ACC 0.5 on epoch=624
06/24/2022 23:23:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.31 on epoch=629
06/24/2022 23:23:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.26 on epoch=634
06/24/2022 23:23:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.25 on epoch=639
06/24/2022 23:23:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.23 on epoch=644
06/24/2022 23:24:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.17 on epoch=649
06/24/2022 23:24:01 - INFO - __main__ - Global step 1300 Train loss 1.25 ACC 0.5 on epoch=649
06/24/2022 23:24:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.34 on epoch=654
06/24/2022 23:24:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.25 on epoch=659
06/24/2022 23:24:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.07 on epoch=664
06/24/2022 23:24:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.09 on epoch=669
06/24/2022 23:24:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.24 on epoch=674
06/24/2022 23:24:09 - INFO - __main__ - Global step 1350 Train loss 1.20 ACC 0.5 on epoch=674
06/24/2022 23:24:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.03 on epoch=679
06/24/2022 23:24:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.16 on epoch=684
06/24/2022 23:24:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.14 on epoch=689
06/24/2022 23:24:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.02 on epoch=694
06/24/2022 23:24:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.21 on epoch=699
06/24/2022 23:24:16 - INFO - __main__ - Global step 1400 Train loss 1.11 ACC 0.5 on epoch=699
06/24/2022 23:24:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.06 on epoch=704
06/24/2022 23:24:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.08 on epoch=709
06/24/2022 23:24:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=714
06/24/2022 23:24:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.08 on epoch=719
06/24/2022 23:24:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=724
06/24/2022 23:24:24 - INFO - __main__ - Global step 1450 Train loss 1.09 ACC 0.5 on epoch=724
06/24/2022 23:24:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.08 on epoch=729
06/24/2022 23:24:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.06 on epoch=734
06/24/2022 23:24:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.03 on epoch=739
06/24/2022 23:24:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.00 on epoch=744
06/24/2022 23:24:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.96 on epoch=749
06/24/2022 23:24:31 - INFO - __main__ - Global step 1500 Train loss 1.03 ACC 0.5 on epoch=749
06/24/2022 23:24:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=754
06/24/2022 23:24:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.93 on epoch=759
06/24/2022 23:24:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.95 on epoch=764
06/24/2022 23:24:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.86 on epoch=769
06/24/2022 23:24:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.90 on epoch=774
06/24/2022 23:24:38 - INFO - __main__ - Global step 1550 Train loss 0.93 ACC 0.5 on epoch=774
06/24/2022 23:24:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.87 on epoch=779
06/24/2022 23:24:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.84 on epoch=784
06/24/2022 23:24:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.90 on epoch=789
06/24/2022 23:24:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.84 on epoch=794
06/24/2022 23:24:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.85 on epoch=799
06/24/2022 23:24:45 - INFO - __main__ - Global step 1600 Train loss 0.86 ACC 0.5 on epoch=799
06/24/2022 23:24:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.76 on epoch=804
06/24/2022 23:24:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.86 on epoch=809
06/24/2022 23:24:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.96 on epoch=814
06/24/2022 23:24:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.79 on epoch=819
06/24/2022 23:24:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.90 on epoch=824
06/24/2022 23:24:52 - INFO - __main__ - Global step 1650 Train loss 0.85 ACC 0.5 on epoch=824
06/24/2022 23:24:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.74 on epoch=829
06/24/2022 23:24:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.76 on epoch=834
06/24/2022 23:24:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.88 on epoch=839
06/24/2022 23:24:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.71 on epoch=844
06/24/2022 23:24:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.87 on epoch=849
06/24/2022 23:24:59 - INFO - __main__ - Global step 1700 Train loss 0.79 ACC 0.5 on epoch=849
06/24/2022 23:25:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.74 on epoch=854
06/24/2022 23:25:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.69 on epoch=859
06/24/2022 23:25:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.76 on epoch=864
06/24/2022 23:25:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.84 on epoch=869
06/24/2022 23:25:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.75 on epoch=874
06/24/2022 23:25:05 - INFO - __main__ - Global step 1750 Train loss 0.76 ACC 0.5 on epoch=874
06/24/2022 23:25:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=879
06/24/2022 23:25:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.75 on epoch=884
06/24/2022 23:25:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.76 on epoch=889
06/24/2022 23:25:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.79 on epoch=894
06/24/2022 23:25:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.67 on epoch=899
06/24/2022 23:25:12 - INFO - __main__ - Global step 1800 Train loss 0.73 ACC 0.5 on epoch=899
06/24/2022 23:25:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.73 on epoch=904
06/24/2022 23:25:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.75 on epoch=909
06/24/2022 23:25:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.71 on epoch=914
06/24/2022 23:25:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.66 on epoch=919
06/24/2022 23:25:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.68 on epoch=924
06/24/2022 23:25:19 - INFO - __main__ - Global step 1850 Train loss 0.70 ACC 0.5 on epoch=924
06/24/2022 23:25:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.68 on epoch=929
06/24/2022 23:25:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.73 on epoch=934
06/24/2022 23:25:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.74 on epoch=939
06/24/2022 23:25:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.79 on epoch=944
06/24/2022 23:25:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.70 on epoch=949
06/24/2022 23:25:26 - INFO - __main__ - Global step 1900 Train loss 0.73 ACC 0.5 on epoch=949
06/24/2022 23:25:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.74 on epoch=954
06/24/2022 23:25:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.74 on epoch=959
06/24/2022 23:25:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.63 on epoch=964
06/24/2022 23:25:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.66 on epoch=969
06/24/2022 23:25:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.72 on epoch=974
06/24/2022 23:25:33 - INFO - __main__ - Global step 1950 Train loss 0.70 ACC 0.5 on epoch=974
06/24/2022 23:25:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.62 on epoch=979
06/24/2022 23:25:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.68 on epoch=984
06/24/2022 23:25:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.61 on epoch=989
06/24/2022 23:25:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.63 on epoch=994
06/24/2022 23:25:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.65 on epoch=999
06/24/2022 23:25:39 - INFO - __main__ - Global step 2000 Train loss 0.64 ACC 0.5 on epoch=999
06/24/2022 23:25:39 - INFO - __main__ - save last model!
06/24/2022 23:25:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 23:25:40 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 23:25:40 - INFO - __main__ - Printing 3 examples
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 23:25:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 23:25:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:25:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:25:40 - INFO - __main__ - Printing 3 examples
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:25:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:25:40 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:25:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:25:40 - INFO - __main__ - Printing 3 examples
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 23:25:40 - INFO - __main__ - ['duplicate']
06/24/2022 23:25:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:25:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:25:40 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:25:45 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:25:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:25:46 - INFO - __main__ - Starting training!
06/24/2022 23:25:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:26:39 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 23:37:57 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_21_0.2_8_predictions.txt
06/24/2022 23:37:57 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 23:37:57 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.2, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 23:37:57 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.5, bsz=8 ...
06/24/2022 23:37:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:37:58 - INFO - __main__ - Printing 3 examples
06/24/2022 23:37:58 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 23:37:58 - INFO - __main__ - ['duplicate']
06/24/2022 23:37:58 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 23:37:58 - INFO - __main__ - ['duplicate']
06/24/2022 23:37:58 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 23:37:58 - INFO - __main__ - ['duplicate']
06/24/2022 23:37:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:37:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:37:58 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:37:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:37:58 - INFO - __main__ - Printing 3 examples
06/24/2022 23:37:58 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 23:37:58 - INFO - __main__ - ['duplicate']
06/24/2022 23:37:58 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 23:37:58 - INFO - __main__ - ['duplicate']
06/24/2022 23:37:58 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 23:37:58 - INFO - __main__ - ['duplicate']
06/24/2022 23:37:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:37:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:37:58 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:38:04 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:38:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:38:04 - INFO - __main__ - Starting training!
06/24/2022 23:38:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.55 on epoch=4
06/24/2022 23:38:07 - INFO - __main__ - Step 20 Global step 20 Train loss 6.36 on epoch=9
06/24/2022 23:38:08 - INFO - __main__ - Step 30 Global step 30 Train loss 5.91 on epoch=14
06/24/2022 23:38:09 - INFO - __main__ - Step 40 Global step 40 Train loss 5.76 on epoch=19
06/24/2022 23:38:10 - INFO - __main__ - Step 50 Global step 50 Train loss 5.33 on epoch=24
06/24/2022 23:38:12 - INFO - __main__ - Global step 50 Train loss 5.98 ACC 0.0 on epoch=24
06/24/2022 23:38:12 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 23:38:13 - INFO - __main__ - Step 60 Global step 60 Train loss 5.08 on epoch=29
06/24/2022 23:38:14 - INFO - __main__ - Step 70 Global step 70 Train loss 5.00 on epoch=34
06/24/2022 23:38:15 - INFO - __main__ - Step 80 Global step 80 Train loss 4.75 on epoch=39
06/24/2022 23:38:17 - INFO - __main__ - Step 90 Global step 90 Train loss 4.64 on epoch=44
06/24/2022 23:38:18 - INFO - __main__ - Step 100 Global step 100 Train loss 4.58 on epoch=49
06/24/2022 23:38:20 - INFO - __main__ - Global step 100 Train loss 4.81 ACC 0.0 on epoch=49
06/24/2022 23:38:21 - INFO - __main__ - Step 110 Global step 110 Train loss 4.53 on epoch=54
06/24/2022 23:38:22 - INFO - __main__ - Step 120 Global step 120 Train loss 4.25 on epoch=59
06/24/2022 23:38:23 - INFO - __main__ - Step 130 Global step 130 Train loss 4.21 on epoch=64
06/24/2022 23:38:24 - INFO - __main__ - Step 140 Global step 140 Train loss 4.07 on epoch=69
06/24/2022 23:38:26 - INFO - __main__ - Step 150 Global step 150 Train loss 3.95 on epoch=74
06/24/2022 23:38:27 - INFO - __main__ - Global step 150 Train loss 4.20 ACC 0.0 on epoch=74
06/24/2022 23:38:28 - INFO - __main__ - Step 160 Global step 160 Train loss 3.82 on epoch=79
06/24/2022 23:38:29 - INFO - __main__ - Step 170 Global step 170 Train loss 3.62 on epoch=84
06/24/2022 23:38:31 - INFO - __main__ - Step 180 Global step 180 Train loss 3.57 on epoch=89
06/24/2022 23:38:32 - INFO - __main__ - Step 190 Global step 190 Train loss 3.39 on epoch=94
06/24/2022 23:38:33 - INFO - __main__ - Step 200 Global step 200 Train loss 3.38 on epoch=99
06/24/2022 23:38:34 - INFO - __main__ - Global step 200 Train loss 3.56 ACC 0.0 on epoch=99
06/24/2022 23:38:35 - INFO - __main__ - Step 210 Global step 210 Train loss 3.22 on epoch=104
06/24/2022 23:38:36 - INFO - __main__ - Step 220 Global step 220 Train loss 3.25 on epoch=109
06/24/2022 23:38:38 - INFO - __main__ - Step 230 Global step 230 Train loss 3.00 on epoch=114
06/24/2022 23:38:39 - INFO - __main__ - Step 240 Global step 240 Train loss 2.87 on epoch=119
06/24/2022 23:38:40 - INFO - __main__ - Step 250 Global step 250 Train loss 2.75 on epoch=124
06/24/2022 23:38:43 - INFO - __main__ - Global step 250 Train loss 3.02 ACC 0.03125 on epoch=124
06/24/2022 23:38:43 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=124, global_step=250
06/24/2022 23:38:44 - INFO - __main__ - Step 260 Global step 260 Train loss 2.65 on epoch=129
06/24/2022 23:38:45 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=134
06/24/2022 23:38:47 - INFO - __main__ - Step 280 Global step 280 Train loss 2.43 on epoch=139
06/24/2022 23:38:48 - INFO - __main__ - Step 290 Global step 290 Train loss 2.48 on epoch=144
06/24/2022 23:38:49 - INFO - __main__ - Step 300 Global step 300 Train loss 2.41 on epoch=149
06/24/2022 23:38:50 - INFO - __main__ - Global step 300 Train loss 2.51 ACC 0.5 on epoch=149
06/24/2022 23:38:50 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.5 on epoch=149, global_step=300
06/24/2022 23:38:51 - INFO - __main__ - Step 310 Global step 310 Train loss 2.22 on epoch=154
06/24/2022 23:38:53 - INFO - __main__ - Step 320 Global step 320 Train loss 2.12 on epoch=159
06/24/2022 23:38:54 - INFO - __main__ - Step 330 Global step 330 Train loss 2.11 on epoch=164
06/24/2022 23:38:55 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=169
06/24/2022 23:38:56 - INFO - __main__ - Step 350 Global step 350 Train loss 2.07 on epoch=174
06/24/2022 23:38:58 - INFO - __main__ - Global step 350 Train loss 2.11 ACC 0.4375 on epoch=174
06/24/2022 23:38:59 - INFO - __main__ - Step 360 Global step 360 Train loss 1.99 on epoch=179
06/24/2022 23:39:01 - INFO - __main__ - Step 370 Global step 370 Train loss 1.92 on epoch=184
06/24/2022 23:39:02 - INFO - __main__ - Step 380 Global step 380 Train loss 1.92 on epoch=189
06/24/2022 23:39:03 - INFO - __main__ - Step 390 Global step 390 Train loss 1.80 on epoch=194
06/24/2022 23:39:04 - INFO - __main__ - Step 400 Global step 400 Train loss 1.82 on epoch=199
06/24/2022 23:39:05 - INFO - __main__ - Global step 400 Train loss 1.89 ACC 0.5 on epoch=199
06/24/2022 23:39:07 - INFO - __main__ - Step 410 Global step 410 Train loss 1.66 on epoch=204
06/24/2022 23:39:08 - INFO - __main__ - Step 420 Global step 420 Train loss 1.67 on epoch=209
06/24/2022 23:39:09 - INFO - __main__ - Step 430 Global step 430 Train loss 1.63 on epoch=214
06/24/2022 23:39:10 - INFO - __main__ - Step 440 Global step 440 Train loss 1.60 on epoch=219
06/24/2022 23:39:11 - INFO - __main__ - Step 450 Global step 450 Train loss 1.57 on epoch=224
06/24/2022 23:39:13 - INFO - __main__ - Global step 450 Train loss 1.62 ACC 0.5 on epoch=224
06/24/2022 23:39:15 - INFO - __main__ - Step 460 Global step 460 Train loss 1.50 on epoch=229
06/24/2022 23:39:16 - INFO - __main__ - Step 470 Global step 470 Train loss 1.44 on epoch=234
06/24/2022 23:39:17 - INFO - __main__ - Step 480 Global step 480 Train loss 1.46 on epoch=239
06/24/2022 23:39:18 - INFO - __main__ - Step 490 Global step 490 Train loss 1.37 on epoch=244
06/24/2022 23:39:19 - INFO - __main__ - Step 500 Global step 500 Train loss 1.37 on epoch=249
06/24/2022 23:39:21 - INFO - __main__ - Global step 500 Train loss 1.43 ACC 0.5 on epoch=249
06/24/2022 23:39:22 - INFO - __main__ - Step 510 Global step 510 Train loss 1.38 on epoch=254
06/24/2022 23:39:23 - INFO - __main__ - Step 520 Global step 520 Train loss 1.35 on epoch=259
06/24/2022 23:39:25 - INFO - __main__ - Step 530 Global step 530 Train loss 1.34 on epoch=264
06/24/2022 23:39:26 - INFO - __main__ - Step 540 Global step 540 Train loss 1.19 on epoch=269
06/24/2022 23:39:27 - INFO - __main__ - Step 550 Global step 550 Train loss 1.26 on epoch=274
06/24/2022 23:39:28 - INFO - __main__ - Global step 550 Train loss 1.31 ACC 0.5 on epoch=274
06/24/2022 23:39:30 - INFO - __main__ - Step 560 Global step 560 Train loss 1.22 on epoch=279
06/24/2022 23:39:31 - INFO - __main__ - Step 570 Global step 570 Train loss 1.16 on epoch=284
06/24/2022 23:39:32 - INFO - __main__ - Step 580 Global step 580 Train loss 1.13 on epoch=289
06/24/2022 23:39:33 - INFO - __main__ - Step 590 Global step 590 Train loss 1.13 on epoch=294
06/24/2022 23:39:34 - INFO - __main__ - Step 600 Global step 600 Train loss 1.11 on epoch=299
06/24/2022 23:39:36 - INFO - __main__ - Global step 600 Train loss 1.15 ACC 0.5 on epoch=299
06/24/2022 23:39:37 - INFO - __main__ - Step 610 Global step 610 Train loss 1.19 on epoch=304
06/24/2022 23:39:38 - INFO - __main__ - Step 620 Global step 620 Train loss 1.05 on epoch=309
06/24/2022 23:39:39 - INFO - __main__ - Step 630 Global step 630 Train loss 1.03 on epoch=314
06/24/2022 23:39:40 - INFO - __main__ - Step 640 Global step 640 Train loss 1.03 on epoch=319
06/24/2022 23:39:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.82 on epoch=324
06/24/2022 23:39:43 - INFO - __main__ - Global step 650 Train loss 1.02 ACC 0.5 on epoch=324
06/24/2022 23:39:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.98 on epoch=329
06/24/2022 23:39:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.93 on epoch=334
06/24/2022 23:39:47 - INFO - __main__ - Step 680 Global step 680 Train loss 1.00 on epoch=339
06/24/2022 23:39:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.90 on epoch=344
06/24/2022 23:39:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.93 on epoch=349
06/24/2022 23:39:50 - INFO - __main__ - Global step 700 Train loss 0.95 ACC 0.5 on epoch=349
06/24/2022 23:39:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.88 on epoch=354
06/24/2022 23:39:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.89 on epoch=359
06/24/2022 23:39:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.90 on epoch=364
06/24/2022 23:39:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.84 on epoch=369
06/24/2022 23:39:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.87 on epoch=374
06/24/2022 23:39:56 - INFO - __main__ - Global step 750 Train loss 0.87 ACC 0.5 on epoch=374
06/24/2022 23:39:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.86 on epoch=379
06/24/2022 23:39:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.85 on epoch=384
06/24/2022 23:40:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.77 on epoch=389
06/24/2022 23:40:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.72 on epoch=394
06/24/2022 23:40:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.74 on epoch=399
06/24/2022 23:40:03 - INFO - __main__ - Global step 800 Train loss 0.79 ACC 0.5 on epoch=399
06/24/2022 23:40:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.70 on epoch=404
06/24/2022 23:40:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.73 on epoch=409
06/24/2022 23:40:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.72 on epoch=414
06/24/2022 23:40:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.78 on epoch=419
06/24/2022 23:40:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.81 on epoch=424
06/24/2022 23:40:10 - INFO - __main__ - Global step 850 Train loss 0.75 ACC 0.5 on epoch=424
06/24/2022 23:40:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.79 on epoch=429
06/24/2022 23:40:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.66 on epoch=434
06/24/2022 23:40:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.72 on epoch=439
06/24/2022 23:40:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.67 on epoch=444
06/24/2022 23:40:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.66 on epoch=449
06/24/2022 23:40:16 - INFO - __main__ - Global step 900 Train loss 0.70 ACC 0.5 on epoch=449
06/24/2022 23:40:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.67 on epoch=454
06/24/2022 23:40:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.65 on epoch=459
06/24/2022 23:40:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.60 on epoch=464
06/24/2022 23:40:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.62 on epoch=469
06/24/2022 23:40:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.73 on epoch=474
06/24/2022 23:40:23 - INFO - __main__ - Global step 950 Train loss 0.65 ACC 0.5 on epoch=474
06/24/2022 23:40:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.63 on epoch=479
06/24/2022 23:40:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.61 on epoch=484
06/24/2022 23:40:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.61 on epoch=489
06/24/2022 23:40:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.60 on epoch=494
06/24/2022 23:40:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.58 on epoch=499
06/24/2022 23:40:29 - INFO - __main__ - Global step 1000 Train loss 0.61 ACC 0.5 on epoch=499
06/24/2022 23:40:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.60 on epoch=504
06/24/2022 23:40:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.66 on epoch=509
06/24/2022 23:40:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.60 on epoch=514
06/24/2022 23:40:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.50 on epoch=519
06/24/2022 23:40:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.54 on epoch=524
06/24/2022 23:40:36 - INFO - __main__ - Global step 1050 Train loss 0.58 ACC 0.5 on epoch=524
06/24/2022 23:40:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.56 on epoch=529
06/24/2022 23:40:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.45 on epoch=534
06/24/2022 23:40:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.49 on epoch=539
06/24/2022 23:40:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.51 on epoch=544
06/24/2022 23:40:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.51 on epoch=549
06/24/2022 23:40:43 - INFO - __main__ - Global step 1100 Train loss 0.50 ACC 0.5 on epoch=549
06/24/2022 23:40:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.57 on epoch=554
06/24/2022 23:40:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.55 on epoch=559
06/24/2022 23:40:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.56 on epoch=564
06/24/2022 23:40:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.46 on epoch=569
06/24/2022 23:40:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.38 on epoch=574
06/24/2022 23:40:49 - INFO - __main__ - Global step 1150 Train loss 0.50 ACC 0.5 on epoch=574
06/24/2022 23:40:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.51 on epoch=579
06/24/2022 23:40:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.45 on epoch=584
06/24/2022 23:40:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.50 on epoch=589
06/24/2022 23:40:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.46 on epoch=594
06/24/2022 23:40:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.61 on epoch=599
06/24/2022 23:40:56 - INFO - __main__ - Global step 1200 Train loss 0.50 ACC 0.5 on epoch=599
06/24/2022 23:40:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.64 on epoch=604
06/24/2022 23:40:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.61 on epoch=609
06/24/2022 23:41:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.55 on epoch=614
06/24/2022 23:41:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.63 on epoch=619
06/24/2022 23:41:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.53 on epoch=624
06/24/2022 23:41:03 - INFO - __main__ - Global step 1250 Train loss 0.59 ACC 0.5 on epoch=624
06/24/2022 23:41:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.64 on epoch=629
06/24/2022 23:41:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.47 on epoch=634
06/24/2022 23:41:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.55 on epoch=639
06/24/2022 23:41:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.50 on epoch=644
06/24/2022 23:41:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.48 on epoch=649
06/24/2022 23:41:09 - INFO - __main__ - Global step 1300 Train loss 0.53 ACC 0.5 on epoch=649
06/24/2022 23:41:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.52 on epoch=654
06/24/2022 23:41:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.46 on epoch=659
06/24/2022 23:41:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.44 on epoch=664
06/24/2022 23:41:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.46 on epoch=669
06/24/2022 23:41:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.56 on epoch=674
06/24/2022 23:41:16 - INFO - __main__ - Global step 1350 Train loss 0.49 ACC 0.5 on epoch=674
06/24/2022 23:41:17 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.47 on epoch=679
06/24/2022 23:41:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.53 on epoch=684
06/24/2022 23:41:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.49 on epoch=689
06/24/2022 23:41:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.42 on epoch=694
06/24/2022 23:41:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.46 on epoch=699
06/24/2022 23:41:23 - INFO - __main__ - Global step 1400 Train loss 0.47 ACC 0.5 on epoch=699
06/24/2022 23:41:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.41 on epoch=704
06/24/2022 23:41:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.41 on epoch=709
06/24/2022 23:41:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.52 on epoch=714
06/24/2022 23:41:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.47 on epoch=719
06/24/2022 23:41:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.55 on epoch=724
06/24/2022 23:41:29 - INFO - __main__ - Global step 1450 Train loss 0.47 ACC 0.5 on epoch=724
06/24/2022 23:41:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.42 on epoch=729
06/24/2022 23:41:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.43 on epoch=734
06/24/2022 23:41:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.41 on epoch=739
06/24/2022 23:41:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.41 on epoch=744
06/24/2022 23:41:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.44 on epoch=749
06/24/2022 23:41:36 - INFO - __main__ - Global step 1500 Train loss 0.42 ACC 0.5 on epoch=749
06/24/2022 23:41:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.47 on epoch=754
06/24/2022 23:41:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.42 on epoch=759
06/24/2022 23:41:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.48 on epoch=764
06/24/2022 23:41:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.45 on epoch=769
06/24/2022 23:41:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.42 on epoch=774
06/24/2022 23:41:42 - INFO - __main__ - Global step 1550 Train loss 0.45 ACC 0.5 on epoch=774
06/24/2022 23:41:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.38 on epoch=779
06/24/2022 23:41:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.42 on epoch=784
06/24/2022 23:41:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.38 on epoch=789
06/24/2022 23:41:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.38 on epoch=794
06/24/2022 23:41:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.45 on epoch=799
06/24/2022 23:41:49 - INFO - __main__ - Global step 1600 Train loss 0.40 ACC 0.5 on epoch=799
06/24/2022 23:41:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.42 on epoch=804
06/24/2022 23:41:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.40 on epoch=809
06/24/2022 23:41:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.41 on epoch=814
06/24/2022 23:41:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.42 on epoch=819
06/24/2022 23:41:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.42 on epoch=824
06/24/2022 23:41:56 - INFO - __main__ - Global step 1650 Train loss 0.42 ACC 0.5 on epoch=824
06/24/2022 23:41:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.41 on epoch=829
06/24/2022 23:41:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.42 on epoch=834
06/24/2022 23:41:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.38 on epoch=839
06/24/2022 23:42:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.50 on epoch=844
06/24/2022 23:42:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.39 on epoch=849
06/24/2022 23:42:02 - INFO - __main__ - Global step 1700 Train loss 0.42 ACC 0.5 on epoch=849
06/24/2022 23:42:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.39 on epoch=854
06/24/2022 23:42:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.44 on epoch=859
06/24/2022 23:42:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.38 on epoch=864
06/24/2022 23:42:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.44 on epoch=869
06/24/2022 23:42:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.42 on epoch=874
06/24/2022 23:42:09 - INFO - __main__ - Global step 1750 Train loss 0.41 ACC 0.5 on epoch=874
06/24/2022 23:42:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.43 on epoch=879
06/24/2022 23:42:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.41 on epoch=884
06/24/2022 23:42:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.45 on epoch=889
06/24/2022 23:42:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.37 on epoch=894
06/24/2022 23:42:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.37 on epoch=899
06/24/2022 23:42:15 - INFO - __main__ - Global step 1800 Train loss 0.41 ACC 0.5 on epoch=899
06/24/2022 23:42:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.40 on epoch=904
06/24/2022 23:42:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.32 on epoch=909
06/24/2022 23:42:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.38 on epoch=914
06/24/2022 23:42:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.42 on epoch=919
06/24/2022 23:42:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.42 on epoch=924
06/24/2022 23:42:22 - INFO - __main__ - Global step 1850 Train loss 0.39 ACC 0.5 on epoch=924
06/24/2022 23:42:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.41 on epoch=929
06/24/2022 23:42:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.30 on epoch=934
06/24/2022 23:42:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.36 on epoch=939
06/24/2022 23:42:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.40 on epoch=944
06/24/2022 23:42:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.38 on epoch=949
06/24/2022 23:42:28 - INFO - __main__ - Global step 1900 Train loss 0.37 ACC 0.5 on epoch=949
06/24/2022 23:42:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.34 on epoch=954
06/24/2022 23:42:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.41 on epoch=959
06/24/2022 23:42:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.43 on epoch=964
06/24/2022 23:42:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.37 on epoch=969
06/24/2022 23:42:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.40 on epoch=974
06/24/2022 23:42:35 - INFO - __main__ - Global step 1950 Train loss 0.39 ACC 0.5 on epoch=974
06/24/2022 23:42:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.31 on epoch=979
06/24/2022 23:42:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.31 on epoch=984
06/24/2022 23:42:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.36 on epoch=989
06/24/2022 23:42:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.34 on epoch=994
06/24/2022 23:42:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.35 on epoch=999
06/24/2022 23:42:41 - INFO - __main__ - Global step 2000 Train loss 0.33 ACC 0.5 on epoch=999
06/24/2022 23:42:41 - INFO - __main__ - save last model!
06/24/2022 23:42:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 23:42:41 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 23:42:41 - INFO - __main__ - Printing 3 examples
06/24/2022 23:42:41 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 23:42:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:42:41 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 23:42:41 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:42:41 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 23:42:41 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:41 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:42:42 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:42:42 - INFO - __main__ - Printing 3 examples
06/24/2022 23:42:42 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 23:42:42 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:42 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 23:42:42 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:42 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 23:42:42 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:42 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:42:42 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:42:42 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:42:42 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:42:42 - INFO - __main__ - Printing 3 examples
06/24/2022 23:42:42 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 23:42:42 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:42 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 23:42:42 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:42 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 23:42:42 - INFO - __main__ - ['duplicate']
06/24/2022 23:42:42 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:42:42 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:42:42 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:42:47 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:42:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:42:48 - INFO - __main__ - Starting training!
06/24/2022 23:42:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:43:40 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 23:50:47 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_42_0.5_8_predictions.txt
06/24/2022 23:50:48 - INFO - __main__ - ACC on test data: 0.3682
06/24/2022 23:50:48 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.5, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/24/2022 23:50:48 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.4, bsz=8 ...
06/24/2022 23:50:49 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:50:49 - INFO - __main__ - Printing 3 examples
06/24/2022 23:50:49 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 23:50:49 - INFO - __main__ - ['duplicate']
06/24/2022 23:50:49 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 23:50:49 - INFO - __main__ - ['duplicate']
06/24/2022 23:50:49 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 23:50:49 - INFO - __main__ - ['duplicate']
06/24/2022 23:50:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:50:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:50:49 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:50:49 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:50:49 - INFO - __main__ - Printing 3 examples
06/24/2022 23:50:49 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 23:50:49 - INFO - __main__ - ['duplicate']
06/24/2022 23:50:49 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 23:50:49 - INFO - __main__ - ['duplicate']
06/24/2022 23:50:49 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 23:50:49 - INFO - __main__ - ['duplicate']
06/24/2022 23:50:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:50:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:50:49 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:50:54 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:50:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:50:54 - INFO - __main__ - Starting training!
06/24/2022 23:50:56 - INFO - __main__ - Step 10 Global step 10 Train loss 6.49 on epoch=4
06/24/2022 23:50:57 - INFO - __main__ - Step 20 Global step 20 Train loss 6.31 on epoch=9
06/24/2022 23:50:58 - INFO - __main__ - Step 30 Global step 30 Train loss 6.02 on epoch=14
06/24/2022 23:50:59 - INFO - __main__ - Step 40 Global step 40 Train loss 5.93 on epoch=19
06/24/2022 23:51:01 - INFO - __main__ - Step 50 Global step 50 Train loss 5.56 on epoch=24
06/24/2022 23:51:02 - INFO - __main__ - Global step 50 Train loss 6.06 ACC 0.0 on epoch=24
06/24/2022 23:51:02 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 23:51:03 - INFO - __main__ - Step 60 Global step 60 Train loss 5.35 on epoch=29
06/24/2022 23:51:05 - INFO - __main__ - Step 70 Global step 70 Train loss 5.19 on epoch=34
06/24/2022 23:51:06 - INFO - __main__ - Step 80 Global step 80 Train loss 5.05 on epoch=39
06/24/2022 23:51:07 - INFO - __main__ - Step 90 Global step 90 Train loss 4.85 on epoch=44
06/24/2022 23:51:08 - INFO - __main__ - Step 100 Global step 100 Train loss 4.71 on epoch=49
06/24/2022 23:51:10 - INFO - __main__ - Global step 100 Train loss 5.03 ACC 0.0 on epoch=49
06/24/2022 23:51:11 - INFO - __main__ - Step 110 Global step 110 Train loss 4.63 on epoch=54
06/24/2022 23:51:12 - INFO - __main__ - Step 120 Global step 120 Train loss 4.55 on epoch=59
06/24/2022 23:51:14 - INFO - __main__ - Step 130 Global step 130 Train loss 4.49 on epoch=64
06/24/2022 23:51:15 - INFO - __main__ - Step 140 Global step 140 Train loss 4.49 on epoch=69
06/24/2022 23:51:16 - INFO - __main__ - Step 150 Global step 150 Train loss 4.29 on epoch=74
06/24/2022 23:51:17 - INFO - __main__ - Global step 150 Train loss 4.49 ACC 0.0 on epoch=74
06/24/2022 23:51:19 - INFO - __main__ - Step 160 Global step 160 Train loss 4.35 on epoch=79
06/24/2022 23:51:20 - INFO - __main__ - Step 170 Global step 170 Train loss 4.13 on epoch=84
06/24/2022 23:51:21 - INFO - __main__ - Step 180 Global step 180 Train loss 4.06 on epoch=89
06/24/2022 23:51:22 - INFO - __main__ - Step 190 Global step 190 Train loss 3.97 on epoch=94
06/24/2022 23:51:24 - INFO - __main__ - Step 200 Global step 200 Train loss 3.55 on epoch=99
06/24/2022 23:51:25 - INFO - __main__ - Global step 200 Train loss 4.01 ACC 0.03125 on epoch=99
06/24/2022 23:51:25 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=99, global_step=200
06/24/2022 23:51:26 - INFO - __main__ - Step 210 Global step 210 Train loss 3.66 on epoch=104
06/24/2022 23:51:27 - INFO - __main__ - Step 220 Global step 220 Train loss 3.53 on epoch=109
06/24/2022 23:51:28 - INFO - __main__ - Step 230 Global step 230 Train loss 3.42 on epoch=114
06/24/2022 23:51:29 - INFO - __main__ - Step 240 Global step 240 Train loss 3.22 on epoch=119
06/24/2022 23:51:31 - INFO - __main__ - Step 250 Global step 250 Train loss 3.28 on epoch=124
06/24/2022 23:51:32 - INFO - __main__ - Global step 250 Train loss 3.42 ACC 0.03125 on epoch=124
06/24/2022 23:51:33 - INFO - __main__ - Step 260 Global step 260 Train loss 3.02 on epoch=129
06/24/2022 23:51:34 - INFO - __main__ - Step 270 Global step 270 Train loss 3.08 on epoch=134
06/24/2022 23:51:36 - INFO - __main__ - Step 280 Global step 280 Train loss 2.96 on epoch=139
06/24/2022 23:51:37 - INFO - __main__ - Step 290 Global step 290 Train loss 2.73 on epoch=144
06/24/2022 23:51:38 - INFO - __main__ - Step 300 Global step 300 Train loss 2.79 on epoch=149
06/24/2022 23:51:39 - INFO - __main__ - Global step 300 Train loss 2.92 ACC 0.1875 on epoch=149
06/24/2022 23:51:39 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.1875 on epoch=149, global_step=300
06/24/2022 23:51:40 - INFO - __main__ - Step 310 Global step 310 Train loss 2.81 on epoch=154
06/24/2022 23:51:42 - INFO - __main__ - Step 320 Global step 320 Train loss 2.67 on epoch=159
06/24/2022 23:51:43 - INFO - __main__ - Step 330 Global step 330 Train loss 2.57 on epoch=164
06/24/2022 23:51:44 - INFO - __main__ - Step 340 Global step 340 Train loss 2.49 on epoch=169
06/24/2022 23:51:45 - INFO - __main__ - Step 350 Global step 350 Train loss 2.46 on epoch=174
06/24/2022 23:51:47 - INFO - __main__ - Global step 350 Train loss 2.60 ACC 0.375 on epoch=174
06/24/2022 23:51:47 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.375 on epoch=174, global_step=350
06/24/2022 23:51:48 - INFO - __main__ - Step 360 Global step 360 Train loss 2.49 on epoch=179
06/24/2022 23:51:49 - INFO - __main__ - Step 370 Global step 370 Train loss 2.37 on epoch=184
06/24/2022 23:51:51 - INFO - __main__ - Step 380 Global step 380 Train loss 2.42 on epoch=189
06/24/2022 23:51:52 - INFO - __main__ - Step 390 Global step 390 Train loss 2.36 on epoch=194
06/24/2022 23:51:53 - INFO - __main__ - Step 400 Global step 400 Train loss 2.25 on epoch=199
06/24/2022 23:51:55 - INFO - __main__ - Global step 400 Train loss 2.38 ACC 0.5 on epoch=199
06/24/2022 23:51:55 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.5 on epoch=199, global_step=400
06/24/2022 23:51:56 - INFO - __main__ - Step 410 Global step 410 Train loss 2.27 on epoch=204
06/24/2022 23:51:57 - INFO - __main__ - Step 420 Global step 420 Train loss 2.17 on epoch=209
06/24/2022 23:51:58 - INFO - __main__ - Step 430 Global step 430 Train loss 2.29 on epoch=214
06/24/2022 23:51:59 - INFO - __main__ - Step 440 Global step 440 Train loss 2.20 on epoch=219
06/24/2022 23:52:01 - INFO - __main__ - Step 450 Global step 450 Train loss 2.15 on epoch=224
06/24/2022 23:52:02 - INFO - __main__ - Global step 450 Train loss 2.21 ACC 0.5 on epoch=224
06/24/2022 23:52:03 - INFO - __main__ - Step 460 Global step 460 Train loss 2.06 on epoch=229
06/24/2022 23:52:05 - INFO - __main__ - Step 470 Global step 470 Train loss 1.96 on epoch=234
06/24/2022 23:52:06 - INFO - __main__ - Step 480 Global step 480 Train loss 2.02 on epoch=239
06/24/2022 23:52:07 - INFO - __main__ - Step 490 Global step 490 Train loss 1.95 on epoch=244
06/24/2022 23:52:08 - INFO - __main__ - Step 500 Global step 500 Train loss 1.89 on epoch=249
06/24/2022 23:52:15 - INFO - __main__ - Global step 500 Train loss 1.98 ACC 0.5 on epoch=249
06/24/2022 23:52:16 - INFO - __main__ - Step 510 Global step 510 Train loss 1.80 on epoch=254
06/24/2022 23:52:17 - INFO - __main__ - Step 520 Global step 520 Train loss 1.88 on epoch=259
06/24/2022 23:52:18 - INFO - __main__ - Step 530 Global step 530 Train loss 1.87 on epoch=264
06/24/2022 23:52:20 - INFO - __main__ - Step 540 Global step 540 Train loss 1.82 on epoch=269
06/24/2022 23:52:21 - INFO - __main__ - Step 550 Global step 550 Train loss 1.77 on epoch=274
06/24/2022 23:52:26 - INFO - __main__ - Global step 550 Train loss 1.83 ACC 0.46875 on epoch=274
06/24/2022 23:52:28 - INFO - __main__ - Step 560 Global step 560 Train loss 1.73 on epoch=279
06/24/2022 23:52:29 - INFO - __main__ - Step 570 Global step 570 Train loss 1.76 on epoch=284
06/24/2022 23:52:30 - INFO - __main__ - Step 580 Global step 580 Train loss 1.73 on epoch=289
06/24/2022 23:52:31 - INFO - __main__ - Step 590 Global step 590 Train loss 1.65 on epoch=294
06/24/2022 23:52:32 - INFO - __main__ - Step 600 Global step 600 Train loss 1.58 on epoch=299
06/24/2022 23:52:34 - INFO - __main__ - Global step 600 Train loss 1.69 ACC 0.5 on epoch=299
06/24/2022 23:52:35 - INFO - __main__ - Step 610 Global step 610 Train loss 1.59 on epoch=304
06/24/2022 23:52:37 - INFO - __main__ - Step 620 Global step 620 Train loss 1.66 on epoch=309
06/24/2022 23:52:38 - INFO - __main__ - Step 630 Global step 630 Train loss 1.51 on epoch=314
06/24/2022 23:52:39 - INFO - __main__ - Step 640 Global step 640 Train loss 1.45 on epoch=319
06/24/2022 23:52:40 - INFO - __main__ - Step 650 Global step 650 Train loss 1.52 on epoch=324
06/24/2022 23:52:42 - INFO - __main__ - Global step 650 Train loss 1.55 ACC 0.5 on epoch=324
06/24/2022 23:52:43 - INFO - __main__ - Step 660 Global step 660 Train loss 1.39 on epoch=329
06/24/2022 23:52:44 - INFO - __main__ - Step 670 Global step 670 Train loss 1.44 on epoch=334
06/24/2022 23:52:46 - INFO - __main__ - Step 680 Global step 680 Train loss 1.48 on epoch=339
06/24/2022 23:52:47 - INFO - __main__ - Step 690 Global step 690 Train loss 1.45 on epoch=344
06/24/2022 23:52:48 - INFO - __main__ - Step 700 Global step 700 Train loss 1.39 on epoch=349
06/24/2022 23:52:50 - INFO - __main__ - Global step 700 Train loss 1.43 ACC 0.5 on epoch=349
06/24/2022 23:52:51 - INFO - __main__ - Step 710 Global step 710 Train loss 1.41 on epoch=354
06/24/2022 23:52:52 - INFO - __main__ - Step 720 Global step 720 Train loss 1.33 on epoch=359
06/24/2022 23:52:53 - INFO - __main__ - Step 730 Global step 730 Train loss 1.32 on epoch=364
06/24/2022 23:52:55 - INFO - __main__ - Step 740 Global step 740 Train loss 1.35 on epoch=369
06/24/2022 23:52:56 - INFO - __main__ - Step 750 Global step 750 Train loss 1.24 on epoch=374
06/24/2022 23:52:57 - INFO - __main__ - Global step 750 Train loss 1.33 ACC 0.5 on epoch=374
06/24/2022 23:52:59 - INFO - __main__ - Step 760 Global step 760 Train loss 1.32 on epoch=379
06/24/2022 23:53:00 - INFO - __main__ - Step 770 Global step 770 Train loss 1.19 on epoch=384
06/24/2022 23:53:01 - INFO - __main__ - Step 780 Global step 780 Train loss 1.21 on epoch=389
06/24/2022 23:53:02 - INFO - __main__ - Step 790 Global step 790 Train loss 1.16 on epoch=394
06/24/2022 23:53:04 - INFO - __main__ - Step 800 Global step 800 Train loss 1.15 on epoch=399
06/24/2022 23:53:05 - INFO - __main__ - Global step 800 Train loss 1.21 ACC 0.5 on epoch=399
06/24/2022 23:53:06 - INFO - __main__ - Step 810 Global step 810 Train loss 1.13 on epoch=404
06/24/2022 23:53:08 - INFO - __main__ - Step 820 Global step 820 Train loss 1.15 on epoch=409
06/24/2022 23:53:09 - INFO - __main__ - Step 830 Global step 830 Train loss 1.04 on epoch=414
06/24/2022 23:53:10 - INFO - __main__ - Step 840 Global step 840 Train loss 1.01 on epoch=419
06/24/2022 23:53:11 - INFO - __main__ - Step 850 Global step 850 Train loss 1.03 on epoch=424
06/24/2022 23:53:13 - INFO - __main__ - Global step 850 Train loss 1.08 ACC 0.5 on epoch=424
06/24/2022 23:53:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.99 on epoch=429
06/24/2022 23:53:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.99 on epoch=434
06/24/2022 23:53:17 - INFO - __main__ - Step 880 Global step 880 Train loss 1.05 on epoch=439
06/24/2022 23:53:18 - INFO - __main__ - Step 890 Global step 890 Train loss 1.03 on epoch=444
06/24/2022 23:53:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.93 on epoch=449
06/24/2022 23:53:21 - INFO - __main__ - Global step 900 Train loss 1.00 ACC 0.5 on epoch=449
06/24/2022 23:53:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.96 on epoch=454
06/24/2022 23:53:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.97 on epoch=459
06/24/2022 23:53:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.95 on epoch=464
06/24/2022 23:53:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.89 on epoch=469
06/24/2022 23:53:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.97 on epoch=474
06/24/2022 23:53:29 - INFO - __main__ - Global step 950 Train loss 0.95 ACC 0.5 on epoch=474
06/24/2022 23:53:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.91 on epoch=479
06/24/2022 23:53:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.91 on epoch=484
06/24/2022 23:53:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.88 on epoch=489
06/24/2022 23:53:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.92 on epoch=494
06/24/2022 23:53:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.91 on epoch=499
06/24/2022 23:53:36 - INFO - __main__ - Global step 1000 Train loss 0.91 ACC 0.5 on epoch=499
06/24/2022 23:53:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.88 on epoch=504
06/24/2022 23:53:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.74 on epoch=509
06/24/2022 23:53:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.80 on epoch=514
06/24/2022 23:53:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.80 on epoch=519
06/24/2022 23:53:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.83 on epoch=524
06/24/2022 23:53:44 - INFO - __main__ - Global step 1050 Train loss 0.81 ACC 0.5 on epoch=524
06/24/2022 23:53:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.81 on epoch=529
06/24/2022 23:53:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.76 on epoch=534
06/24/2022 23:53:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.77 on epoch=539
06/24/2022 23:53:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.77 on epoch=544
06/24/2022 23:53:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.71 on epoch=549
06/24/2022 23:53:51 - INFO - __main__ - Global step 1100 Train loss 0.77 ACC 0.5 on epoch=549
06/24/2022 23:53:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.76 on epoch=554
06/24/2022 23:53:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.86 on epoch=559
06/24/2022 23:53:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.76 on epoch=564
06/24/2022 23:53:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.69 on epoch=569
06/24/2022 23:53:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.58 on epoch=574
06/24/2022 23:53:59 - INFO - __main__ - Global step 1150 Train loss 0.73 ACC 0.5 on epoch=574
06/24/2022 23:54:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.65 on epoch=579
06/24/2022 23:54:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.63 on epoch=584
06/24/2022 23:54:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.60 on epoch=589
06/24/2022 23:54:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.67 on epoch=594
06/24/2022 23:54:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.66 on epoch=599
06/24/2022 23:54:07 - INFO - __main__ - Global step 1200 Train loss 0.64 ACC 0.5 on epoch=599
06/24/2022 23:54:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.64 on epoch=604
06/24/2022 23:54:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.55 on epoch=609
06/24/2022 23:54:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.61 on epoch=614
06/24/2022 23:54:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.53 on epoch=619
06/24/2022 23:54:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.55 on epoch=624
06/24/2022 23:54:15 - INFO - __main__ - Global step 1250 Train loss 0.58 ACC 0.5 on epoch=624
06/24/2022 23:54:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.61 on epoch=629
06/24/2022 23:54:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.56 on epoch=634
06/24/2022 23:54:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.57 on epoch=639
06/24/2022 23:54:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.67 on epoch=644
06/24/2022 23:54:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.57 on epoch=649
06/24/2022 23:54:24 - INFO - __main__ - Global step 1300 Train loss 0.60 ACC 0.5 on epoch=649
06/24/2022 23:54:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.58 on epoch=654
06/24/2022 23:54:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.52 on epoch=659
06/24/2022 23:54:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.58 on epoch=664
06/24/2022 23:54:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.66 on epoch=669
06/24/2022 23:54:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.52 on epoch=674
06/24/2022 23:54:32 - INFO - __main__ - Global step 1350 Train loss 0.57 ACC 0.5 on epoch=674
06/24/2022 23:54:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.54 on epoch=679
06/24/2022 23:54:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.61 on epoch=684
06/24/2022 23:54:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.50 on epoch=689
06/24/2022 23:54:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.53 on epoch=694
06/24/2022 23:54:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.45 on epoch=699
06/24/2022 23:54:40 - INFO - __main__ - Global step 1400 Train loss 0.53 ACC 0.5 on epoch=699
06/24/2022 23:54:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.56 on epoch=704
06/24/2022 23:54:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.48 on epoch=709
06/24/2022 23:54:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.49 on epoch=714
06/24/2022 23:54:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.57 on epoch=719
06/24/2022 23:54:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.48 on epoch=724
06/24/2022 23:54:50 - INFO - __main__ - Global step 1450 Train loss 0.52 ACC 0.5 on epoch=724
06/24/2022 23:54:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.50 on epoch=729
06/24/2022 23:54:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.48 on epoch=734
06/24/2022 23:54:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.48 on epoch=739
06/24/2022 23:54:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.50 on epoch=744
06/24/2022 23:54:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.51 on epoch=749
06/24/2022 23:55:00 - INFO - __main__ - Global step 1500 Train loss 0.49 ACC 0.5 on epoch=749
06/24/2022 23:55:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.42 on epoch=754
06/24/2022 23:55:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.49 on epoch=759
06/24/2022 23:55:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.46 on epoch=764
06/24/2022 23:55:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.48 on epoch=769
06/24/2022 23:55:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.49 on epoch=774
06/24/2022 23:55:10 - INFO - __main__ - Global step 1550 Train loss 0.47 ACC 0.5 on epoch=774
06/24/2022 23:55:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.52 on epoch=779
06/24/2022 23:55:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.46 on epoch=784
06/24/2022 23:55:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.46 on epoch=789
06/24/2022 23:55:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.50 on epoch=794
06/24/2022 23:55:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.48 on epoch=799
06/24/2022 23:55:19 - INFO - __main__ - Global step 1600 Train loss 0.48 ACC 0.5 on epoch=799
06/24/2022 23:55:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.43 on epoch=804
06/24/2022 23:55:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.43 on epoch=809
06/24/2022 23:55:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.43 on epoch=814
06/24/2022 23:55:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.47 on epoch=819
06/24/2022 23:55:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.37 on epoch=824
06/24/2022 23:55:29 - INFO - __main__ - Global step 1650 Train loss 0.43 ACC 0.5 on epoch=824
06/24/2022 23:55:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.37 on epoch=829
06/24/2022 23:55:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.38 on epoch=834
06/24/2022 23:55:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.46 on epoch=839
06/24/2022 23:55:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.41 on epoch=844
06/24/2022 23:55:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.42 on epoch=849
06/24/2022 23:55:39 - INFO - __main__ - Global step 1700 Train loss 0.41 ACC 0.5 on epoch=849
06/24/2022 23:55:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.39 on epoch=854
06/24/2022 23:55:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.46 on epoch=859
06/24/2022 23:55:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.51 on epoch=864
06/24/2022 23:55:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.37 on epoch=869
06/24/2022 23:55:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.36 on epoch=874
06/24/2022 23:55:49 - INFO - __main__ - Global step 1750 Train loss 0.42 ACC 0.5 on epoch=874
06/24/2022 23:55:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.43 on epoch=879
06/24/2022 23:55:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.46 on epoch=884
06/24/2022 23:55:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.41 on epoch=889
06/24/2022 23:55:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.37 on epoch=894
06/24/2022 23:55:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.42 on epoch=899
06/24/2022 23:55:58 - INFO - __main__ - Global step 1800 Train loss 0.42 ACC 0.5 on epoch=899
06/24/2022 23:56:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.41 on epoch=904
06/24/2022 23:56:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.46 on epoch=909
06/24/2022 23:56:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.44 on epoch=914
06/24/2022 23:56:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.46 on epoch=919
06/24/2022 23:56:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.46 on epoch=924
06/24/2022 23:56:09 - INFO - __main__ - Global step 1850 Train loss 0.44 ACC 0.5 on epoch=924
06/24/2022 23:56:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.38 on epoch=929
06/24/2022 23:56:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.42 on epoch=934
06/24/2022 23:56:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.40 on epoch=939
06/24/2022 23:56:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.42 on epoch=944
06/24/2022 23:56:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.37 on epoch=949
06/24/2022 23:56:18 - INFO - __main__ - Global step 1900 Train loss 0.40 ACC 0.5 on epoch=949
06/24/2022 23:56:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.41 on epoch=954
06/24/2022 23:56:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.38 on epoch=959
06/24/2022 23:56:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.46 on epoch=964
06/24/2022 23:56:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.45 on epoch=969
06/24/2022 23:56:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.41 on epoch=974
06/24/2022 23:56:27 - INFO - __main__ - Global step 1950 Train loss 0.42 ACC 0.5 on epoch=974
06/24/2022 23:56:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.40 on epoch=979
06/24/2022 23:56:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.42 on epoch=984
06/24/2022 23:56:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.37 on epoch=989
06/24/2022 23:56:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.42 on epoch=994
06/24/2022 23:56:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.45 on epoch=999
06/24/2022 23:56:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:56:35 - INFO - __main__ - Printing 3 examples
06/24/2022 23:56:35 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 23:56:35 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:35 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 23:56:35 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:35 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 23:56:35 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:56:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:56:35 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 23:56:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 23:56:35 - INFO - __main__ - Printing 3 examples
06/24/2022 23:56:35 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 23:56:35 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:35 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 23:56:35 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:35 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 23:56:35 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:56:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:56:35 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 23:56:36 - INFO - __main__ - Global step 2000 Train loss 0.41 ACC 0.5 on epoch=999
06/24/2022 23:56:36 - INFO - __main__ - save last model!
06/24/2022 23:56:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 23:56:36 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 23:56:36 - INFO - __main__ - Printing 3 examples
06/24/2022 23:56:36 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 23:56:36 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:56:36 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 23:56:36 - INFO - __main__ - ['not_duplicate']
06/24/2022 23:56:36 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 23:56:36 - INFO - __main__ - ['duplicate']
06/24/2022 23:56:36 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:56:40 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:56:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 23:56:40 - INFO - __main__ - Starting training!
06/24/2022 23:56:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:57:35 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 00:58:32 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_42_0.4_8_predictions.txt
06/25/2022 00:58:32 - INFO - __main__ - ACC on test data: 0.3682
06/25/2022 00:58:32 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.4, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/25/2022 00:58:32 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.3, bsz=8 ...
06/25/2022 00:58:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 00:58:33 - INFO - __main__ - Printing 3 examples
06/25/2022 00:58:33 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/25/2022 00:58:33 - INFO - __main__ - ['duplicate']
06/25/2022 00:58:33 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/25/2022 00:58:33 - INFO - __main__ - ['duplicate']
06/25/2022 00:58:33 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/25/2022 00:58:33 - INFO - __main__ - ['duplicate']
06/25/2022 00:58:33 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:58:33 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:58:33 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 00:58:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 00:58:33 - INFO - __main__ - Printing 3 examples
06/25/2022 00:58:33 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/25/2022 00:58:33 - INFO - __main__ - ['duplicate']
06/25/2022 00:58:33 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/25/2022 00:58:33 - INFO - __main__ - ['duplicate']
06/25/2022 00:58:33 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/25/2022 00:58:33 - INFO - __main__ - ['duplicate']
06/25/2022 00:58:33 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:58:33 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:58:33 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 00:58:39 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:58:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 00:58:40 - INFO - __main__ - Starting training!
06/25/2022 00:58:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.61 on epoch=4
06/25/2022 00:58:43 - INFO - __main__ - Step 20 Global step 20 Train loss 6.39 on epoch=9
06/25/2022 00:58:44 - INFO - __main__ - Step 30 Global step 30 Train loss 6.30 on epoch=14
06/25/2022 00:58:45 - INFO - __main__ - Step 40 Global step 40 Train loss 6.07 on epoch=19
06/25/2022 00:58:46 - INFO - __main__ - Step 50 Global step 50 Train loss 5.89 on epoch=24
06/25/2022 00:58:48 - INFO - __main__ - Global step 50 Train loss 6.25 ACC 0.0 on epoch=24
06/25/2022 00:58:48 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/25/2022 00:58:49 - INFO - __main__ - Step 60 Global step 60 Train loss 5.63 on epoch=29
06/25/2022 00:58:51 - INFO - __main__ - Step 70 Global step 70 Train loss 5.47 on epoch=34
06/25/2022 00:58:52 - INFO - __main__ - Step 80 Global step 80 Train loss 5.40 on epoch=39
06/25/2022 00:58:53 - INFO - __main__ - Step 90 Global step 90 Train loss 5.29 on epoch=44
06/25/2022 00:58:55 - INFO - __main__ - Step 100 Global step 100 Train loss 5.02 on epoch=49
06/25/2022 00:58:57 - INFO - __main__ - Global step 100 Train loss 5.36 ACC 0.0 on epoch=49
06/25/2022 00:58:58 - INFO - __main__ - Step 110 Global step 110 Train loss 5.01 on epoch=54
06/25/2022 00:58:59 - INFO - __main__ - Step 120 Global step 120 Train loss 4.87 on epoch=59
06/25/2022 00:59:00 - INFO - __main__ - Step 130 Global step 130 Train loss 4.87 on epoch=64
06/25/2022 00:59:02 - INFO - __main__ - Step 140 Global step 140 Train loss 4.99 on epoch=69
06/25/2022 00:59:03 - INFO - __main__ - Step 150 Global step 150 Train loss 4.64 on epoch=74
06/25/2022 00:59:04 - INFO - __main__ - Global step 150 Train loss 4.88 ACC 0.0 on epoch=74
06/25/2022 00:59:06 - INFO - __main__ - Step 160 Global step 160 Train loss 4.74 on epoch=79
06/25/2022 00:59:07 - INFO - __main__ - Step 170 Global step 170 Train loss 4.71 on epoch=84
06/25/2022 00:59:08 - INFO - __main__ - Step 180 Global step 180 Train loss 4.60 on epoch=89
06/25/2022 00:59:09 - INFO - __main__ - Step 190 Global step 190 Train loss 4.42 on epoch=94
06/25/2022 00:59:11 - INFO - __main__ - Step 200 Global step 200 Train loss 4.44 on epoch=99
06/25/2022 00:59:12 - INFO - __main__ - Global step 200 Train loss 4.58 ACC 0.0 on epoch=99
06/25/2022 00:59:13 - INFO - __main__ - Step 210 Global step 210 Train loss 4.44 on epoch=104
06/25/2022 00:59:14 - INFO - __main__ - Step 220 Global step 220 Train loss 4.28 on epoch=109
06/25/2022 00:59:16 - INFO - __main__ - Step 230 Global step 230 Train loss 4.30 on epoch=114
06/25/2022 00:59:17 - INFO - __main__ - Step 240 Global step 240 Train loss 4.17 on epoch=119
06/25/2022 00:59:18 - INFO - __main__ - Step 250 Global step 250 Train loss 4.09 on epoch=124
06/25/2022 00:59:19 - INFO - __main__ - Global step 250 Train loss 4.26 ACC 0.0 on epoch=124
06/25/2022 00:59:21 - INFO - __main__ - Step 260 Global step 260 Train loss 4.11 on epoch=129
06/25/2022 00:59:22 - INFO - __main__ - Step 270 Global step 270 Train loss 4.09 on epoch=134
06/25/2022 00:59:23 - INFO - __main__ - Step 280 Global step 280 Train loss 3.76 on epoch=139
06/25/2022 00:59:24 - INFO - __main__ - Step 290 Global step 290 Train loss 3.64 on epoch=144
06/25/2022 00:59:26 - INFO - __main__ - Step 300 Global step 300 Train loss 3.60 on epoch=149
06/25/2022 00:59:27 - INFO - __main__ - Global step 300 Train loss 3.84 ACC 0.0 on epoch=149
06/25/2022 00:59:28 - INFO - __main__ - Step 310 Global step 310 Train loss 3.57 on epoch=154
06/25/2022 00:59:30 - INFO - __main__ - Step 320 Global step 320 Train loss 3.51 on epoch=159
06/25/2022 00:59:31 - INFO - __main__ - Step 330 Global step 330 Train loss 3.40 on epoch=164
06/25/2022 00:59:32 - INFO - __main__ - Step 340 Global step 340 Train loss 3.35 on epoch=169
06/25/2022 00:59:33 - INFO - __main__ - Step 350 Global step 350 Train loss 3.36 on epoch=174
06/25/2022 00:59:39 - INFO - __main__ - Global step 350 Train loss 3.44 ACC 0.0 on epoch=174
06/25/2022 00:59:40 - INFO - __main__ - Step 360 Global step 360 Train loss 3.38 on epoch=179
06/25/2022 00:59:42 - INFO - __main__ - Step 370 Global step 370 Train loss 3.09 on epoch=184
06/25/2022 00:59:43 - INFO - __main__ - Step 380 Global step 380 Train loss 3.12 on epoch=189
06/25/2022 00:59:44 - INFO - __main__ - Step 390 Global step 390 Train loss 3.05 on epoch=194
06/25/2022 00:59:45 - INFO - __main__ - Step 400 Global step 400 Train loss 3.16 on epoch=199
06/25/2022 00:59:48 - INFO - __main__ - Global step 400 Train loss 3.16 ACC 0.0 on epoch=199
06/25/2022 00:59:49 - INFO - __main__ - Step 410 Global step 410 Train loss 3.05 on epoch=204
06/25/2022 00:59:51 - INFO - __main__ - Step 420 Global step 420 Train loss 3.07 on epoch=209
06/25/2022 00:59:52 - INFO - __main__ - Step 430 Global step 430 Train loss 3.00 on epoch=214
06/25/2022 00:59:53 - INFO - __main__ - Step 440 Global step 440 Train loss 2.89 on epoch=219
06/25/2022 00:59:55 - INFO - __main__ - Step 450 Global step 450 Train loss 2.99 on epoch=224
06/25/2022 01:00:04 - INFO - __main__ - Global step 450 Train loss 3.00 ACC 0.09375 on epoch=224
06/25/2022 01:00:04 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.09375 on epoch=224, global_step=450
06/25/2022 01:00:05 - INFO - __main__ - Step 460 Global step 460 Train loss 2.79 on epoch=229
06/25/2022 01:00:07 - INFO - __main__ - Step 470 Global step 470 Train loss 2.74 on epoch=234
06/25/2022 01:00:08 - INFO - __main__ - Step 480 Global step 480 Train loss 2.68 on epoch=239
06/25/2022 01:00:09 - INFO - __main__ - Step 490 Global step 490 Train loss 2.60 on epoch=244
06/25/2022 01:00:11 - INFO - __main__ - Step 500 Global step 500 Train loss 2.58 on epoch=249
06/25/2022 01:00:21 - INFO - __main__ - Global step 500 Train loss 2.68 ACC 0.0625 on epoch=249
06/25/2022 01:00:22 - INFO - __main__ - Step 510 Global step 510 Train loss 2.58 on epoch=254
06/25/2022 01:00:23 - INFO - __main__ - Step 520 Global step 520 Train loss 2.61 on epoch=259
06/25/2022 01:00:25 - INFO - __main__ - Step 530 Global step 530 Train loss 2.53 on epoch=264
06/25/2022 01:00:26 - INFO - __main__ - Step 540 Global step 540 Train loss 2.35 on epoch=269
06/25/2022 01:00:27 - INFO - __main__ - Step 550 Global step 550 Train loss 2.40 on epoch=274
06/25/2022 01:00:37 - INFO - __main__ - Global step 550 Train loss 2.49 ACC 0.21875 on epoch=274
06/25/2022 01:00:37 - INFO - __main__ - Saving model with best ACC: 0.09375 -> 0.21875 on epoch=274, global_step=550
06/25/2022 01:00:38 - INFO - __main__ - Step 560 Global step 560 Train loss 2.36 on epoch=279
06/25/2022 01:00:40 - INFO - __main__ - Step 570 Global step 570 Train loss 2.26 on epoch=284
06/25/2022 01:00:41 - INFO - __main__ - Step 580 Global step 580 Train loss 2.25 on epoch=289
06/25/2022 01:00:42 - INFO - __main__ - Step 590 Global step 590 Train loss 2.10 on epoch=294
06/25/2022 01:00:44 - INFO - __main__ - Step 600 Global step 600 Train loss 2.13 on epoch=299
06/25/2022 01:00:53 - INFO - __main__ - Global step 600 Train loss 2.22 ACC 0.40625 on epoch=299
06/25/2022 01:00:53 - INFO - __main__ - Saving model with best ACC: 0.21875 -> 0.40625 on epoch=299, global_step=600
06/25/2022 01:00:54 - INFO - __main__ - Step 610 Global step 610 Train loss 2.07 on epoch=304
06/25/2022 01:00:55 - INFO - __main__ - Step 620 Global step 620 Train loss 2.28 on epoch=309
06/25/2022 01:00:57 - INFO - __main__ - Step 630 Global step 630 Train loss 2.04 on epoch=314
06/25/2022 01:00:58 - INFO - __main__ - Step 640 Global step 640 Train loss 2.09 on epoch=319
06/25/2022 01:00:59 - INFO - __main__ - Step 650 Global step 650 Train loss 1.93 on epoch=324
06/25/2022 01:01:02 - INFO - __main__ - Global step 650 Train loss 2.08 ACC 0.46875 on epoch=324
06/25/2022 01:01:02 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.46875 on epoch=324, global_step=650
06/25/2022 01:01:03 - INFO - __main__ - Step 660 Global step 660 Train loss 1.98 on epoch=329
06/25/2022 01:01:04 - INFO - __main__ - Step 670 Global step 670 Train loss 1.93 on epoch=334
06/25/2022 01:01:06 - INFO - __main__ - Step 680 Global step 680 Train loss 1.89 on epoch=339
06/25/2022 01:01:07 - INFO - __main__ - Step 690 Global step 690 Train loss 1.89 on epoch=344
06/25/2022 01:01:08 - INFO - __main__ - Step 700 Global step 700 Train loss 1.81 on epoch=349
06/25/2022 01:01:10 - INFO - __main__ - Global step 700 Train loss 1.90 ACC 0.4375 on epoch=349
06/25/2022 01:01:11 - INFO - __main__ - Step 710 Global step 710 Train loss 1.83 on epoch=354
06/25/2022 01:01:13 - INFO - __main__ - Step 720 Global step 720 Train loss 1.83 on epoch=359
06/25/2022 01:01:14 - INFO - __main__ - Step 730 Global step 730 Train loss 1.77 on epoch=364
06/25/2022 01:01:15 - INFO - __main__ - Step 740 Global step 740 Train loss 1.83 on epoch=369
06/25/2022 01:01:17 - INFO - __main__ - Step 750 Global step 750 Train loss 1.74 on epoch=374
06/25/2022 01:01:18 - INFO - __main__ - Global step 750 Train loss 1.80 ACC 0.5 on epoch=374
06/25/2022 01:01:18 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=374, global_step=750
06/25/2022 01:01:20 - INFO - __main__ - Step 760 Global step 760 Train loss 1.73 on epoch=379
06/25/2022 01:01:21 - INFO - __main__ - Step 770 Global step 770 Train loss 1.65 on epoch=384
06/25/2022 01:01:22 - INFO - __main__ - Step 780 Global step 780 Train loss 1.64 on epoch=389
06/25/2022 01:01:24 - INFO - __main__ - Step 790 Global step 790 Train loss 1.55 on epoch=394
06/25/2022 01:01:25 - INFO - __main__ - Step 800 Global step 800 Train loss 1.45 on epoch=399
06/25/2022 01:01:27 - INFO - __main__ - Global step 800 Train loss 1.60 ACC 0.5 on epoch=399
06/25/2022 01:01:28 - INFO - __main__ - Step 810 Global step 810 Train loss 1.49 on epoch=404
06/25/2022 01:01:29 - INFO - __main__ - Step 820 Global step 820 Train loss 1.43 on epoch=409
06/25/2022 01:01:30 - INFO - __main__ - Step 830 Global step 830 Train loss 1.43 on epoch=414
06/25/2022 01:01:32 - INFO - __main__ - Step 840 Global step 840 Train loss 1.43 on epoch=419
06/25/2022 01:01:33 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=424
06/25/2022 01:01:35 - INFO - __main__ - Global step 850 Train loss 1.44 ACC 0.5 on epoch=424
06/25/2022 01:01:36 - INFO - __main__ - Step 860 Global step 860 Train loss 1.34 on epoch=429
06/25/2022 01:01:38 - INFO - __main__ - Step 870 Global step 870 Train loss 1.33 on epoch=434
06/25/2022 01:01:39 - INFO - __main__ - Step 880 Global step 880 Train loss 1.23 on epoch=439
06/25/2022 01:01:40 - INFO - __main__ - Step 890 Global step 890 Train loss 1.28 on epoch=444
06/25/2022 01:01:41 - INFO - __main__ - Step 900 Global step 900 Train loss 1.27 on epoch=449
06/25/2022 01:01:44 - INFO - __main__ - Global step 900 Train loss 1.29 ACC 0.5 on epoch=449
06/25/2022 01:01:45 - INFO - __main__ - Step 910 Global step 910 Train loss 1.28 on epoch=454
06/25/2022 01:01:46 - INFO - __main__ - Step 920 Global step 920 Train loss 1.28 on epoch=459
06/25/2022 01:01:48 - INFO - __main__ - Step 930 Global step 930 Train loss 1.27 on epoch=464
06/25/2022 01:01:49 - INFO - __main__ - Step 940 Global step 940 Train loss 1.35 on epoch=469
06/25/2022 01:01:50 - INFO - __main__ - Step 950 Global step 950 Train loss 1.19 on epoch=474
06/25/2022 01:01:52 - INFO - __main__ - Global step 950 Train loss 1.27 ACC 0.5 on epoch=474
06/25/2022 01:01:54 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=479
06/25/2022 01:01:55 - INFO - __main__ - Step 970 Global step 970 Train loss 1.19 on epoch=484
06/25/2022 01:01:56 - INFO - __main__ - Step 980 Global step 980 Train loss 1.19 on epoch=489
06/25/2022 01:01:57 - INFO - __main__ - Step 990 Global step 990 Train loss 1.14 on epoch=494
06/25/2022 01:01:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.15 on epoch=499
06/25/2022 01:02:01 - INFO - __main__ - Global step 1000 Train loss 1.20 ACC 0.5 on epoch=499
06/25/2022 01:02:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.10 on epoch=504
06/25/2022 01:02:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.11 on epoch=509
06/25/2022 01:02:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.06 on epoch=514
06/25/2022 01:02:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.99 on epoch=519
06/25/2022 01:02:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.98 on epoch=524
06/25/2022 01:02:09 - INFO - __main__ - Global step 1050 Train loss 1.05 ACC 0.5 on epoch=524
06/25/2022 01:02:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.06 on epoch=529
06/25/2022 01:02:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=534
06/25/2022 01:02:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.92 on epoch=539
06/25/2022 01:02:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.95 on epoch=544
06/25/2022 01:02:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.95 on epoch=549
06/25/2022 01:02:17 - INFO - __main__ - Global step 1100 Train loss 1.00 ACC 0.5 on epoch=549
06/25/2022 01:02:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.88 on epoch=554
06/25/2022 01:02:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.90 on epoch=559
06/25/2022 01:02:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.81 on epoch=564
06/25/2022 01:02:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.83 on epoch=569
06/25/2022 01:02:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.82 on epoch=574
06/25/2022 01:02:25 - INFO - __main__ - Global step 1150 Train loss 0.85 ACC 0.5 on epoch=574
06/25/2022 01:02:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.76 on epoch=579
06/25/2022 01:02:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.82 on epoch=584
06/25/2022 01:02:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.79 on epoch=589
06/25/2022 01:02:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.83 on epoch=594
06/25/2022 01:02:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.82 on epoch=599
06/25/2022 01:02:33 - INFO - __main__ - Global step 1200 Train loss 0.80 ACC 0.5 on epoch=599
06/25/2022 01:02:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.79 on epoch=604
06/25/2022 01:02:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.81 on epoch=609
06/25/2022 01:02:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.82 on epoch=614
06/25/2022 01:02:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.77 on epoch=619
06/25/2022 01:02:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.74 on epoch=624
06/25/2022 01:02:41 - INFO - __main__ - Global step 1250 Train loss 0.79 ACC 0.5 on epoch=624
06/25/2022 01:02:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.71 on epoch=629
06/25/2022 01:02:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.72 on epoch=634
06/25/2022 01:02:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.67 on epoch=639
06/25/2022 01:02:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.71 on epoch=644
06/25/2022 01:02:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.70 on epoch=649
06/25/2022 01:02:48 - INFO - __main__ - Global step 1300 Train loss 0.70 ACC 0.5 on epoch=649
06/25/2022 01:02:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.63 on epoch=654
06/25/2022 01:02:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.68 on epoch=659
06/25/2022 01:02:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.66 on epoch=664
06/25/2022 01:02:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.64 on epoch=669
06/25/2022 01:02:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.67 on epoch=674
06/25/2022 01:02:55 - INFO - __main__ - Global step 1350 Train loss 0.66 ACC 0.5 on epoch=674
06/25/2022 01:02:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.64 on epoch=679
06/25/2022 01:02:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.66 on epoch=684
06/25/2022 01:02:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.64 on epoch=689
06/25/2022 01:03:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.71 on epoch=694
06/25/2022 01:03:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.60 on epoch=699
06/25/2022 01:03:03 - INFO - __main__ - Global step 1400 Train loss 0.65 ACC 0.5 on epoch=699
06/25/2022 01:03:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.64 on epoch=704
06/25/2022 01:03:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.59 on epoch=709
06/25/2022 01:03:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.63 on epoch=714
06/25/2022 01:03:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.56 on epoch=719
06/25/2022 01:03:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.61 on epoch=724
06/25/2022 01:03:10 - INFO - __main__ - Global step 1450 Train loss 0.61 ACC 0.5 on epoch=724
06/25/2022 01:03:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.54 on epoch=729
06/25/2022 01:03:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.56 on epoch=734
06/25/2022 01:03:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.52 on epoch=739
06/25/2022 01:03:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.56 on epoch=744
06/25/2022 01:03:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.56 on epoch=749
06/25/2022 01:03:17 - INFO - __main__ - Global step 1500 Train loss 0.55 ACC 0.5 on epoch=749
06/25/2022 01:03:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.60 on epoch=754
06/25/2022 01:03:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.56 on epoch=759
06/25/2022 01:03:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.56 on epoch=764
06/25/2022 01:03:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.54 on epoch=769
06/25/2022 01:03:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.58 on epoch=774
06/25/2022 01:03:24 - INFO - __main__ - Global step 1550 Train loss 0.57 ACC 0.5 on epoch=774
06/25/2022 01:03:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.60 on epoch=779
06/25/2022 01:03:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.50 on epoch=784
06/25/2022 01:03:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.54 on epoch=789
06/25/2022 01:03:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.51 on epoch=794
06/25/2022 01:03:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.58 on epoch=799
06/25/2022 01:03:31 - INFO - __main__ - Global step 1600 Train loss 0.55 ACC 0.5 on epoch=799
06/25/2022 01:03:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.53 on epoch=804
06/25/2022 01:03:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.55 on epoch=809
06/25/2022 01:03:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.54 on epoch=814
06/25/2022 01:03:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.46 on epoch=819
06/25/2022 01:03:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.59 on epoch=824
06/25/2022 01:03:38 - INFO - __main__ - Global step 1650 Train loss 0.53 ACC 0.5 on epoch=824
06/25/2022 01:03:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.47 on epoch=829
06/25/2022 01:03:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.47 on epoch=834
06/25/2022 01:03:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.50 on epoch=839
06/25/2022 01:03:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.49 on epoch=844
06/25/2022 01:03:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.51 on epoch=849
06/25/2022 01:03:45 - INFO - __main__ - Global step 1700 Train loss 0.49 ACC 0.5 on epoch=849
06/25/2022 01:03:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.50 on epoch=854
06/25/2022 01:03:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.51 on epoch=859
06/25/2022 01:03:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.53 on epoch=864
06/25/2022 01:03:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.49 on epoch=869
06/25/2022 01:03:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.50 on epoch=874
06/25/2022 01:03:52 - INFO - __main__ - Global step 1750 Train loss 0.51 ACC 0.5 on epoch=874
06/25/2022 01:03:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.52 on epoch=879
06/25/2022 01:03:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.49 on epoch=884
06/25/2022 01:03:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.40 on epoch=889
06/25/2022 01:03:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.44 on epoch=894
06/25/2022 01:03:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.51 on epoch=899
06/25/2022 01:03:59 - INFO - __main__ - Global step 1800 Train loss 0.47 ACC 0.5 on epoch=899
06/25/2022 01:04:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.59 on epoch=904
06/25/2022 01:04:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.42 on epoch=909
06/25/2022 01:04:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.52 on epoch=914
06/25/2022 01:04:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.50 on epoch=919
06/25/2022 01:04:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.50 on epoch=924
06/25/2022 01:04:06 - INFO - __main__ - Global step 1850 Train loss 0.50 ACC 0.5 on epoch=924
06/25/2022 01:04:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.47 on epoch=929
06/25/2022 01:04:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.44 on epoch=934
06/25/2022 01:04:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.47 on epoch=939
06/25/2022 01:04:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.47 on epoch=944
06/25/2022 01:04:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.36 on epoch=949
06/25/2022 01:04:13 - INFO - __main__ - Global step 1900 Train loss 0.44 ACC 0.5 on epoch=949
06/25/2022 01:04:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.51 on epoch=954
06/25/2022 01:04:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.55 on epoch=959
06/25/2022 01:04:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.55 on epoch=964
06/25/2022 01:04:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.46 on epoch=969
06/25/2022 01:04:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.43 on epoch=974
06/25/2022 01:04:20 - INFO - __main__ - Global step 1950 Train loss 0.50 ACC 0.5 on epoch=974
06/25/2022 01:04:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.47 on epoch=979
06/25/2022 01:04:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.40 on epoch=984
06/25/2022 01:04:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.40 on epoch=989
06/25/2022 01:04:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.45 on epoch=994
06/25/2022 01:04:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.37 on epoch=999
06/25/2022 01:04:27 - INFO - __main__ - Global step 2000 Train loss 0.42 ACC 0.5 on epoch=999
06/25/2022 01:04:27 - INFO - __main__ - save last model!
06/25/2022 01:04:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:04:27 - INFO - __main__ - Start tokenizing ... 40430 instances
06/25/2022 01:04:27 - INFO - __main__ - Printing 3 examples
06/25/2022 01:04:27 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/25/2022 01:04:27 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:04:27 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/25/2022 01:04:27 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:04:27 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/25/2022 01:04:27 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:27 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:04:28 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:04:28 - INFO - __main__ - Printing 3 examples
06/25/2022 01:04:28 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/25/2022 01:04:28 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:28 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/25/2022 01:04:28 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:28 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/25/2022 01:04:28 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:28 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:04:28 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:04:28 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:04:28 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:04:28 - INFO - __main__ - Printing 3 examples
06/25/2022 01:04:28 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/25/2022 01:04:28 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:28 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/25/2022 01:04:28 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:28 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/25/2022 01:04:28 - INFO - __main__ - ['duplicate']
06/25/2022 01:04:28 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:04:28 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:04:28 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:04:33 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:04:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:04:33 - INFO - __main__ - Starting training!
06/25/2022 01:04:46 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:05:27 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 01:14:49 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_42_0.3_8_predictions.txt
06/25/2022 01:14:49 - INFO - __main__ - ACC on test data: 0.3682
06/25/2022 01:14:49 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.3, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/25/2022 01:14:49 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.2, bsz=8 ...
06/25/2022 01:14:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:14:50 - INFO - __main__ - Printing 3 examples
06/25/2022 01:14:50 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/25/2022 01:14:50 - INFO - __main__ - ['duplicate']
06/25/2022 01:14:50 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/25/2022 01:14:50 - INFO - __main__ - ['duplicate']
06/25/2022 01:14:50 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/25/2022 01:14:50 - INFO - __main__ - ['duplicate']
06/25/2022 01:14:50 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:14:50 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:14:50 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:14:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:14:50 - INFO - __main__ - Printing 3 examples
06/25/2022 01:14:50 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/25/2022 01:14:50 - INFO - __main__ - ['duplicate']
06/25/2022 01:14:50 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/25/2022 01:14:50 - INFO - __main__ - ['duplicate']
06/25/2022 01:14:50 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/25/2022 01:14:50 - INFO - __main__ - ['duplicate']
06/25/2022 01:14:50 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:14:50 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:14:50 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:14:56 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:14:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:14:56 - INFO - __main__ - Starting training!
06/25/2022 01:14:57 - INFO - __main__ - Step 10 Global step 10 Train loss 6.53 on epoch=4
06/25/2022 01:14:59 - INFO - __main__ - Step 20 Global step 20 Train loss 6.43 on epoch=9
06/25/2022 01:15:00 - INFO - __main__ - Step 30 Global step 30 Train loss 6.29 on epoch=14
06/25/2022 01:15:01 - INFO - __main__ - Step 40 Global step 40 Train loss 6.30 on epoch=19
06/25/2022 01:15:02 - INFO - __main__ - Step 50 Global step 50 Train loss 6.05 on epoch=24
06/25/2022 01:15:08 - INFO - __main__ - Global step 50 Train loss 6.32 ACC 0.0 on epoch=24
06/25/2022 01:15:08 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/25/2022 01:15:10 - INFO - __main__ - Step 60 Global step 60 Train loss 6.09 on epoch=29
06/25/2022 01:15:11 - INFO - __main__ - Step 70 Global step 70 Train loss 6.00 on epoch=34
06/25/2022 01:15:12 - INFO - __main__ - Step 80 Global step 80 Train loss 5.90 on epoch=39
06/25/2022 01:15:13 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=44
06/25/2022 01:15:15 - INFO - __main__ - Step 100 Global step 100 Train loss 5.75 on epoch=49
06/25/2022 01:15:16 - INFO - __main__ - Global step 100 Train loss 5.90 ACC 0.0 on epoch=49
06/25/2022 01:15:17 - INFO - __main__ - Step 110 Global step 110 Train loss 5.64 on epoch=54
06/25/2022 01:15:19 - INFO - __main__ - Step 120 Global step 120 Train loss 5.52 on epoch=59
06/25/2022 01:15:20 - INFO - __main__ - Step 130 Global step 130 Train loss 5.46 on epoch=64
06/25/2022 01:15:21 - INFO - __main__ - Step 140 Global step 140 Train loss 5.43 on epoch=69
06/25/2022 01:15:22 - INFO - __main__ - Step 150 Global step 150 Train loss 5.31 on epoch=74
06/25/2022 01:15:24 - INFO - __main__ - Global step 150 Train loss 5.47 ACC 0.0 on epoch=74
06/25/2022 01:15:25 - INFO - __main__ - Step 160 Global step 160 Train loss 5.24 on epoch=79
06/25/2022 01:15:26 - INFO - __main__ - Step 170 Global step 170 Train loss 5.16 on epoch=84
06/25/2022 01:15:28 - INFO - __main__ - Step 180 Global step 180 Train loss 5.11 on epoch=89
06/25/2022 01:15:29 - INFO - __main__ - Step 190 Global step 190 Train loss 5.02 on epoch=94
06/25/2022 01:15:30 - INFO - __main__ - Step 200 Global step 200 Train loss 4.97 on epoch=99
06/25/2022 01:15:32 - INFO - __main__ - Global step 200 Train loss 5.10 ACC 0.0 on epoch=99
06/25/2022 01:15:33 - INFO - __main__ - Step 210 Global step 210 Train loss 4.91 on epoch=104
06/25/2022 01:15:35 - INFO - __main__ - Step 220 Global step 220 Train loss 4.77 on epoch=109
06/25/2022 01:15:36 - INFO - __main__ - Step 230 Global step 230 Train loss 4.81 on epoch=114
06/25/2022 01:15:37 - INFO - __main__ - Step 240 Global step 240 Train loss 4.69 on epoch=119
06/25/2022 01:15:38 - INFO - __main__ - Step 250 Global step 250 Train loss 4.64 on epoch=124
06/25/2022 01:15:40 - INFO - __main__ - Global step 250 Train loss 4.76 ACC 0.0 on epoch=124
06/25/2022 01:15:41 - INFO - __main__ - Step 260 Global step 260 Train loss 4.62 on epoch=129
06/25/2022 01:15:42 - INFO - __main__ - Step 270 Global step 270 Train loss 4.71 on epoch=134
06/25/2022 01:15:43 - INFO - __main__ - Step 280 Global step 280 Train loss 4.51 on epoch=139
06/25/2022 01:15:45 - INFO - __main__ - Step 290 Global step 290 Train loss 4.51 on epoch=144
06/25/2022 01:15:46 - INFO - __main__ - Step 300 Global step 300 Train loss 4.65 on epoch=149
06/25/2022 01:15:47 - INFO - __main__ - Global step 300 Train loss 4.60 ACC 0.0 on epoch=149
06/25/2022 01:15:48 - INFO - __main__ - Step 310 Global step 310 Train loss 4.46 on epoch=154
06/25/2022 01:15:50 - INFO - __main__ - Step 320 Global step 320 Train loss 4.41 on epoch=159
06/25/2022 01:15:51 - INFO - __main__ - Step 330 Global step 330 Train loss 4.46 on epoch=164
06/25/2022 01:15:52 - INFO - __main__ - Step 340 Global step 340 Train loss 4.47 on epoch=169
06/25/2022 01:15:53 - INFO - __main__ - Step 350 Global step 350 Train loss 4.30 on epoch=174
06/25/2022 01:15:55 - INFO - __main__ - Global step 350 Train loss 4.42 ACC 0.0 on epoch=174
06/25/2022 01:15:56 - INFO - __main__ - Step 360 Global step 360 Train loss 4.22 on epoch=179
06/25/2022 01:15:57 - INFO - __main__ - Step 370 Global step 370 Train loss 4.13 on epoch=184
06/25/2022 01:15:59 - INFO - __main__ - Step 380 Global step 380 Train loss 4.18 on epoch=189
06/25/2022 01:16:00 - INFO - __main__ - Step 390 Global step 390 Train loss 4.21 on epoch=194
06/25/2022 01:16:01 - INFO - __main__ - Step 400 Global step 400 Train loss 4.11 on epoch=199
06/25/2022 01:16:02 - INFO - __main__ - Global step 400 Train loss 4.17 ACC 0.0 on epoch=199
06/25/2022 01:16:04 - INFO - __main__ - Step 410 Global step 410 Train loss 4.02 on epoch=204
06/25/2022 01:16:05 - INFO - __main__ - Step 420 Global step 420 Train loss 4.03 on epoch=209
06/25/2022 01:16:06 - INFO - __main__ - Step 430 Global step 430 Train loss 3.87 on epoch=214
06/25/2022 01:16:07 - INFO - __main__ - Step 440 Global step 440 Train loss 3.95 on epoch=219
06/25/2022 01:16:09 - INFO - __main__ - Step 450 Global step 450 Train loss 3.63 on epoch=224
06/25/2022 01:16:11 - INFO - __main__ - Global step 450 Train loss 3.90 ACC 0.0 on epoch=224
06/25/2022 01:16:12 - INFO - __main__ - Step 460 Global step 460 Train loss 3.86 on epoch=229
06/25/2022 01:16:13 - INFO - __main__ - Step 470 Global step 470 Train loss 3.56 on epoch=234
06/25/2022 01:16:15 - INFO - __main__ - Step 480 Global step 480 Train loss 3.61 on epoch=239
06/25/2022 01:16:16 - INFO - __main__ - Step 490 Global step 490 Train loss 3.58 on epoch=244
06/25/2022 01:16:17 - INFO - __main__ - Step 500 Global step 500 Train loss 3.50 on epoch=249
06/25/2022 01:16:19 - INFO - __main__ - Global step 500 Train loss 3.62 ACC 0.0 on epoch=249
06/25/2022 01:16:20 - INFO - __main__ - Step 510 Global step 510 Train loss 3.54 on epoch=254
06/25/2022 01:16:21 - INFO - __main__ - Step 520 Global step 520 Train loss 3.57 on epoch=259
06/25/2022 01:16:23 - INFO - __main__ - Step 530 Global step 530 Train loss 3.51 on epoch=264
06/25/2022 01:16:24 - INFO - __main__ - Step 540 Global step 540 Train loss 3.46 on epoch=269
06/25/2022 01:16:25 - INFO - __main__ - Step 550 Global step 550 Train loss 3.37 on epoch=274
06/25/2022 01:16:27 - INFO - __main__ - Global step 550 Train loss 3.49 ACC 0.0 on epoch=274
06/25/2022 01:16:28 - INFO - __main__ - Step 560 Global step 560 Train loss 3.46 on epoch=279
06/25/2022 01:16:30 - INFO - __main__ - Step 570 Global step 570 Train loss 3.41 on epoch=284
06/25/2022 01:16:31 - INFO - __main__ - Step 580 Global step 580 Train loss 3.27 on epoch=289
06/25/2022 01:16:32 - INFO - __main__ - Step 590 Global step 590 Train loss 3.28 on epoch=294
06/25/2022 01:16:33 - INFO - __main__ - Step 600 Global step 600 Train loss 3.23 on epoch=299
06/25/2022 01:16:35 - INFO - __main__ - Global step 600 Train loss 3.33 ACC 0.03125 on epoch=299
06/25/2022 01:16:35 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=299, global_step=600
06/25/2022 01:16:36 - INFO - __main__ - Step 610 Global step 610 Train loss 3.23 on epoch=304
06/25/2022 01:16:37 - INFO - __main__ - Step 620 Global step 620 Train loss 3.18 on epoch=309
06/25/2022 01:16:39 - INFO - __main__ - Step 630 Global step 630 Train loss 3.12 on epoch=314
06/25/2022 01:16:40 - INFO - __main__ - Step 640 Global step 640 Train loss 3.00 on epoch=319
06/25/2022 01:16:41 - INFO - __main__ - Step 650 Global step 650 Train loss 3.04 on epoch=324
06/25/2022 01:16:42 - INFO - __main__ - Global step 650 Train loss 3.12 ACC 0.0 on epoch=324
06/25/2022 01:16:43 - INFO - __main__ - Step 660 Global step 660 Train loss 3.17 on epoch=329
06/25/2022 01:16:45 - INFO - __main__ - Step 670 Global step 670 Train loss 2.96 on epoch=334
06/25/2022 01:16:46 - INFO - __main__ - Step 680 Global step 680 Train loss 2.87 on epoch=339
06/25/2022 01:16:47 - INFO - __main__ - Step 690 Global step 690 Train loss 2.83 on epoch=344
06/25/2022 01:16:48 - INFO - __main__ - Step 700 Global step 700 Train loss 2.96 on epoch=349
06/25/2022 01:16:58 - INFO - __main__ - Global step 700 Train loss 2.95 ACC 0.09375 on epoch=349
06/25/2022 01:16:58 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.09375 on epoch=349, global_step=700
06/25/2022 01:16:59 - INFO - __main__ - Step 710 Global step 710 Train loss 2.78 on epoch=354
06/25/2022 01:17:01 - INFO - __main__ - Step 720 Global step 720 Train loss 2.89 on epoch=359
06/25/2022 01:17:02 - INFO - __main__ - Step 730 Global step 730 Train loss 2.72 on epoch=364
06/25/2022 01:17:03 - INFO - __main__ - Step 740 Global step 740 Train loss 2.78 on epoch=369
06/25/2022 01:17:04 - INFO - __main__ - Step 750 Global step 750 Train loss 2.69 on epoch=374
06/25/2022 01:17:14 - INFO - __main__ - Global step 750 Train loss 2.77 ACC 0.1875 on epoch=374
06/25/2022 01:17:14 - INFO - __main__ - Saving model with best ACC: 0.09375 -> 0.1875 on epoch=374, global_step=750
06/25/2022 01:17:16 - INFO - __main__ - Step 760 Global step 760 Train loss 2.70 on epoch=379
06/25/2022 01:17:17 - INFO - __main__ - Step 770 Global step 770 Train loss 2.69 on epoch=384
06/25/2022 01:17:18 - INFO - __main__ - Step 780 Global step 780 Train loss 2.64 on epoch=389
06/25/2022 01:17:19 - INFO - __main__ - Step 790 Global step 790 Train loss 2.64 on epoch=394
06/25/2022 01:17:21 - INFO - __main__ - Step 800 Global step 800 Train loss 2.66 on epoch=399
06/25/2022 01:17:30 - INFO - __main__ - Global step 800 Train loss 2.67 ACC 0.25 on epoch=399
06/25/2022 01:17:30 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.25 on epoch=399, global_step=800
06/25/2022 01:17:31 - INFO - __main__ - Step 810 Global step 810 Train loss 2.57 on epoch=404
06/25/2022 01:17:33 - INFO - __main__ - Step 820 Global step 820 Train loss 2.52 on epoch=409
06/25/2022 01:17:34 - INFO - __main__ - Step 830 Global step 830 Train loss 2.51 on epoch=414
06/25/2022 01:17:35 - INFO - __main__ - Step 840 Global step 840 Train loss 2.44 on epoch=419
06/25/2022 01:17:36 - INFO - __main__ - Step 850 Global step 850 Train loss 2.47 on epoch=424
06/25/2022 01:17:46 - INFO - __main__ - Global step 850 Train loss 2.50 ACC 0.375 on epoch=424
06/25/2022 01:17:46 - INFO - __main__ - Saving model with best ACC: 0.25 -> 0.375 on epoch=424, global_step=850
06/25/2022 01:17:47 - INFO - __main__ - Step 860 Global step 860 Train loss 2.46 on epoch=429
06/25/2022 01:17:49 - INFO - __main__ - Step 870 Global step 870 Train loss 2.48 on epoch=434
06/25/2022 01:17:50 - INFO - __main__ - Step 880 Global step 880 Train loss 2.32 on epoch=439
06/25/2022 01:17:51 - INFO - __main__ - Step 890 Global step 890 Train loss 2.31 on epoch=444
06/25/2022 01:17:53 - INFO - __main__ - Step 900 Global step 900 Train loss 2.19 on epoch=449
06/25/2022 01:17:58 - INFO - __main__ - Global step 900 Train loss 2.35 ACC 0.5 on epoch=449
06/25/2022 01:17:58 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.5 on epoch=449, global_step=900
06/25/2022 01:18:00 - INFO - __main__ - Step 910 Global step 910 Train loss 2.19 on epoch=454
06/25/2022 01:18:01 - INFO - __main__ - Step 920 Global step 920 Train loss 2.26 on epoch=459
06/25/2022 01:18:02 - INFO - __main__ - Step 930 Global step 930 Train loss 2.20 on epoch=464
06/25/2022 01:18:04 - INFO - __main__ - Step 940 Global step 940 Train loss 2.29 on epoch=469
06/25/2022 01:18:05 - INFO - __main__ - Step 950 Global step 950 Train loss 2.26 on epoch=474
06/25/2022 01:18:06 - INFO - __main__ - Global step 950 Train loss 2.24 ACC 0.5 on epoch=474
06/25/2022 01:18:08 - INFO - __main__ - Step 960 Global step 960 Train loss 2.11 on epoch=479
06/25/2022 01:18:09 - INFO - __main__ - Step 970 Global step 970 Train loss 2.21 on epoch=484
06/25/2022 01:18:10 - INFO - __main__ - Step 980 Global step 980 Train loss 2.14 on epoch=489
06/25/2022 01:18:11 - INFO - __main__ - Step 990 Global step 990 Train loss 2.21 on epoch=494
06/25/2022 01:18:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.07 on epoch=499
06/25/2022 01:18:14 - INFO - __main__ - Global step 1000 Train loss 2.15 ACC 0.5 on epoch=499
06/25/2022 01:18:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.14 on epoch=504
06/25/2022 01:18:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.12 on epoch=509
06/25/2022 01:18:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.98 on epoch=514
06/25/2022 01:18:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.93 on epoch=519
06/25/2022 01:18:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.10 on epoch=524
06/25/2022 01:18:22 - INFO - __main__ - Global step 1050 Train loss 2.05 ACC 0.5 on epoch=524
06/25/2022 01:18:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.98 on epoch=529
06/25/2022 01:18:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.00 on epoch=534
06/25/2022 01:18:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.97 on epoch=539
06/25/2022 01:18:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.00 on epoch=544
06/25/2022 01:18:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.96 on epoch=549
06/25/2022 01:18:34 - INFO - __main__ - Global step 1100 Train loss 1.98 ACC 0.4375 on epoch=549
06/25/2022 01:18:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.92 on epoch=554
06/25/2022 01:18:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.93 on epoch=559
06/25/2022 01:18:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.81 on epoch=564
06/25/2022 01:18:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.85 on epoch=569
06/25/2022 01:18:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.83 on epoch=574
06/25/2022 01:18:43 - INFO - __main__ - Global step 1150 Train loss 1.87 ACC 0.46875 on epoch=574
06/25/2022 01:18:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.87 on epoch=579
06/25/2022 01:18:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.83 on epoch=584
06/25/2022 01:18:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.97 on epoch=589
06/25/2022 01:18:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.80 on epoch=594
06/25/2022 01:18:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.83 on epoch=599
06/25/2022 01:18:55 - INFO - __main__ - Global step 1200 Train loss 1.86 ACC 0.4375 on epoch=599
06/25/2022 01:18:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.84 on epoch=604
06/25/2022 01:18:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.79 on epoch=609
06/25/2022 01:18:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.70 on epoch=614
06/25/2022 01:19:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.62 on epoch=619
06/25/2022 01:19:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.80 on epoch=624
06/25/2022 01:19:04 - INFO - __main__ - Global step 1250 Train loss 1.75 ACC 0.375 on epoch=624
06/25/2022 01:19:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.70 on epoch=629
06/25/2022 01:19:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.73 on epoch=634
06/25/2022 01:19:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.70 on epoch=639
06/25/2022 01:19:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.72 on epoch=644
06/25/2022 01:19:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.77 on epoch=649
06/25/2022 01:19:12 - INFO - __main__ - Global step 1300 Train loss 1.72 ACC 0.5 on epoch=649
06/25/2022 01:19:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.70 on epoch=654
06/25/2022 01:19:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.60 on epoch=659
06/25/2022 01:19:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.59 on epoch=664
06/25/2022 01:19:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.58 on epoch=669
06/25/2022 01:19:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.58 on epoch=674
06/25/2022 01:19:21 - INFO - __main__ - Global step 1350 Train loss 1.61 ACC 0.46875 on epoch=674
06/25/2022 01:19:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.60 on epoch=679
06/25/2022 01:19:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.56 on epoch=684
06/25/2022 01:19:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.59 on epoch=689
06/25/2022 01:19:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.54 on epoch=694
06/25/2022 01:19:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.38 on epoch=699
06/25/2022 01:19:29 - INFO - __main__ - Global step 1400 Train loss 1.53 ACC 0.5 on epoch=699
06/25/2022 01:19:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.58 on epoch=704
06/25/2022 01:19:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.65 on epoch=709
06/25/2022 01:19:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.59 on epoch=714
06/25/2022 01:19:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.40 on epoch=719
06/25/2022 01:19:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.41 on epoch=724
06/25/2022 01:19:37 - INFO - __main__ - Global step 1450 Train loss 1.53 ACC 0.5 on epoch=724
06/25/2022 01:19:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.43 on epoch=729
06/25/2022 01:19:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.35 on epoch=734
06/25/2022 01:19:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.48 on epoch=739
06/25/2022 01:19:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.38 on epoch=744
06/25/2022 01:19:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.35 on epoch=749
06/25/2022 01:19:45 - INFO - __main__ - Global step 1500 Train loss 1.40 ACC 0.5 on epoch=749
06/25/2022 01:19:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.41 on epoch=754
06/25/2022 01:19:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.29 on epoch=759
06/25/2022 01:19:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.33 on epoch=764
06/25/2022 01:19:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.27 on epoch=769
06/25/2022 01:19:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.18 on epoch=774
06/25/2022 01:19:52 - INFO - __main__ - Global step 1550 Train loss 1.30 ACC 0.46875 on epoch=774
06/25/2022 01:19:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.25 on epoch=779
06/25/2022 01:19:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.17 on epoch=784
06/25/2022 01:19:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.27 on epoch=789
06/25/2022 01:19:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.15 on epoch=794
06/25/2022 01:19:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.20 on epoch=799
06/25/2022 01:20:00 - INFO - __main__ - Global step 1600 Train loss 1.21 ACC 0.5 on epoch=799
06/25/2022 01:20:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.10 on epoch=804
06/25/2022 01:20:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.17 on epoch=809
06/25/2022 01:20:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.15 on epoch=814
06/25/2022 01:20:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.14 on epoch=819
06/25/2022 01:20:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.12 on epoch=824
06/25/2022 01:20:07 - INFO - __main__ - Global step 1650 Train loss 1.14 ACC 0.5 on epoch=824
06/25/2022 01:20:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.03 on epoch=829
06/25/2022 01:20:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.04 on epoch=834
06/25/2022 01:20:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.00 on epoch=839
06/25/2022 01:20:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=844
06/25/2022 01:20:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.09 on epoch=849
06/25/2022 01:20:14 - INFO - __main__ - Global step 1700 Train loss 1.05 ACC 0.5 on epoch=849
06/25/2022 01:20:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.07 on epoch=854
06/25/2022 01:20:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.04 on epoch=859
06/25/2022 01:20:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.08 on epoch=864
06/25/2022 01:20:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.99 on epoch=869
06/25/2022 01:20:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=874
06/25/2022 01:20:21 - INFO - __main__ - Global step 1750 Train loss 1.04 ACC 0.5 on epoch=874
06/25/2022 01:20:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=879
06/25/2022 01:20:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=884
06/25/2022 01:20:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.06 on epoch=889
06/25/2022 01:20:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=894
06/25/2022 01:20:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=899
06/25/2022 01:20:28 - INFO - __main__ - Global step 1800 Train loss 0.98 ACC 0.5 on epoch=899
06/25/2022 01:20:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.93 on epoch=904
06/25/2022 01:20:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=909
06/25/2022 01:20:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.03 on epoch=914
06/25/2022 01:20:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.96 on epoch=919
06/25/2022 01:20:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.95 on epoch=924
06/25/2022 01:20:35 - INFO - __main__ - Global step 1850 Train loss 0.97 ACC 0.5 on epoch=924
06/25/2022 01:20:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.04 on epoch=929
06/25/2022 01:20:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=934
06/25/2022 01:20:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.94 on epoch=939
06/25/2022 01:20:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.92 on epoch=944
06/25/2022 01:20:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.89 on epoch=949
06/25/2022 01:20:42 - INFO - __main__ - Global step 1900 Train loss 0.93 ACC 0.5 on epoch=949
06/25/2022 01:20:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.92 on epoch=954
06/25/2022 01:20:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.94 on epoch=959
06/25/2022 01:20:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.96 on epoch=964
06/25/2022 01:20:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.89 on epoch=969
06/25/2022 01:20:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.94 on epoch=974
06/25/2022 01:20:49 - INFO - __main__ - Global step 1950 Train loss 0.93 ACC 0.5 on epoch=974
06/25/2022 01:20:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.91 on epoch=979
06/25/2022 01:20:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.89 on epoch=984
06/25/2022 01:20:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.84 on epoch=989
06/25/2022 01:20:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.85 on epoch=994
06/25/2022 01:20:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.86 on epoch=999
06/25/2022 01:20:56 - INFO - __main__ - Global step 2000 Train loss 0.87 ACC 0.46875 on epoch=999
06/25/2022 01:20:56 - INFO - __main__ - save last model!
06/25/2022 01:20:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:20:56 - INFO - __main__ - Start tokenizing ... 40430 instances
06/25/2022 01:20:56 - INFO - __main__ - Printing 3 examples
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/25/2022 01:20:56 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/25/2022 01:20:56 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:20:56 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:20:56 - INFO - __main__ - Printing 3 examples
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:20:56 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:20:56 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:20:56 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:20:56 - INFO - __main__ - Printing 3 examples
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 01:20:56 - INFO - __main__ - ['duplicate']
06/25/2022 01:20:56 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:20:56 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:20:56 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:21:02 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:21:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:21:02 - INFO - __main__ - Starting training!
06/25/2022 01:21:14 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:21:56 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 01:35:24 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_42_0.2_8_predictions.txt
06/25/2022 01:35:24 - INFO - __main__ - ACC on test data: 0.3689
06/25/2022 01:35:25 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.2, bsz=8, dev_performance=0.5, test_performance=0.3689092258224091
06/25/2022 01:35:25 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.5, bsz=8 ...
06/25/2022 01:35:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:35:26 - INFO - __main__ - Printing 3 examples
06/25/2022 01:35:26 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:35:26 - INFO - __main__ - ['duplicate']
06/25/2022 01:35:26 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 01:35:26 - INFO - __main__ - ['duplicate']
06/25/2022 01:35:26 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:35:26 - INFO - __main__ - ['duplicate']
06/25/2022 01:35:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:35:26 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:35:26 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:35:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:35:26 - INFO - __main__ - Printing 3 examples
06/25/2022 01:35:26 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 01:35:26 - INFO - __main__ - ['duplicate']
06/25/2022 01:35:26 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 01:35:26 - INFO - __main__ - ['duplicate']
06/25/2022 01:35:26 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 01:35:26 - INFO - __main__ - ['duplicate']
06/25/2022 01:35:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:35:26 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:35:26 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:35:32 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:35:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:35:32 - INFO - __main__ - Starting training!
06/25/2022 01:35:34 - INFO - __main__ - Step 10 Global step 10 Train loss 6.52 on epoch=4
06/25/2022 01:35:35 - INFO - __main__ - Step 20 Global step 20 Train loss 6.36 on epoch=9
06/25/2022 01:35:36 - INFO - __main__ - Step 30 Global step 30 Train loss 5.88 on epoch=14
06/25/2022 01:35:37 - INFO - __main__ - Step 40 Global step 40 Train loss 5.55 on epoch=19
06/25/2022 01:35:39 - INFO - __main__ - Step 50 Global step 50 Train loss 5.30 on epoch=24
06/25/2022 01:35:41 - INFO - __main__ - Global step 50 Train loss 5.92 ACC 0.0 on epoch=24
06/25/2022 01:35:41 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/25/2022 01:35:42 - INFO - __main__ - Step 60 Global step 60 Train loss 5.06 on epoch=29
06/25/2022 01:35:43 - INFO - __main__ - Step 70 Global step 70 Train loss 4.88 on epoch=34
06/25/2022 01:35:44 - INFO - __main__ - Step 80 Global step 80 Train loss 4.60 on epoch=39
06/25/2022 01:35:46 - INFO - __main__ - Step 90 Global step 90 Train loss 4.56 on epoch=44
06/25/2022 01:35:47 - INFO - __main__ - Step 100 Global step 100 Train loss 4.43 on epoch=49
06/25/2022 01:35:48 - INFO - __main__ - Global step 100 Train loss 4.71 ACC 0.0 on epoch=49
06/25/2022 01:35:50 - INFO - __main__ - Step 110 Global step 110 Train loss 4.44 on epoch=54
06/25/2022 01:35:51 - INFO - __main__ - Step 120 Global step 120 Train loss 4.28 on epoch=59
06/25/2022 01:35:52 - INFO - __main__ - Step 130 Global step 130 Train loss 3.95 on epoch=64
06/25/2022 01:35:53 - INFO - __main__ - Step 140 Global step 140 Train loss 3.79 on epoch=69
06/25/2022 01:35:54 - INFO - __main__ - Step 150 Global step 150 Train loss 3.88 on epoch=74
06/25/2022 01:35:56 - INFO - __main__ - Global step 150 Train loss 4.07 ACC 0.0 on epoch=74
06/25/2022 01:35:57 - INFO - __main__ - Step 160 Global step 160 Train loss 3.69 on epoch=79
06/25/2022 01:35:58 - INFO - __main__ - Step 170 Global step 170 Train loss 3.59 on epoch=84
06/25/2022 01:35:59 - INFO - __main__ - Step 180 Global step 180 Train loss 3.63 on epoch=89
06/25/2022 01:36:00 - INFO - __main__ - Step 190 Global step 190 Train loss 3.46 on epoch=94
06/25/2022 01:36:02 - INFO - __main__ - Step 200 Global step 200 Train loss 3.30 on epoch=99
06/25/2022 01:36:04 - INFO - __main__ - Global step 200 Train loss 3.53 ACC 0.0625 on epoch=99
06/25/2022 01:36:04 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.0625 on epoch=99, global_step=200
06/25/2022 01:36:06 - INFO - __main__ - Step 210 Global step 210 Train loss 3.28 on epoch=104
06/25/2022 01:36:07 - INFO - __main__ - Step 220 Global step 220 Train loss 3.15 on epoch=109
06/25/2022 01:36:08 - INFO - __main__ - Step 230 Global step 230 Train loss 3.11 on epoch=114
06/25/2022 01:36:09 - INFO - __main__ - Step 240 Global step 240 Train loss 2.88 on epoch=119
06/25/2022 01:36:11 - INFO - __main__ - Step 250 Global step 250 Train loss 2.84 on epoch=124
06/25/2022 01:36:12 - INFO - __main__ - Global step 250 Train loss 3.05 ACC 0.0 on epoch=124
06/25/2022 01:36:13 - INFO - __main__ - Step 260 Global step 260 Train loss 2.93 on epoch=129
06/25/2022 01:36:14 - INFO - __main__ - Step 270 Global step 270 Train loss 2.82 on epoch=134
06/25/2022 01:36:15 - INFO - __main__ - Step 280 Global step 280 Train loss 2.62 on epoch=139
06/25/2022 01:36:17 - INFO - __main__ - Step 290 Global step 290 Train loss 2.54 on epoch=144
06/25/2022 01:36:18 - INFO - __main__ - Step 300 Global step 300 Train loss 2.42 on epoch=149
06/25/2022 01:36:21 - INFO - __main__ - Global step 300 Train loss 2.67 ACC 0.4375 on epoch=149
06/25/2022 01:36:21 - INFO - __main__ - Saving model with best ACC: 0.0625 -> 0.4375 on epoch=149, global_step=300
06/25/2022 01:36:22 - INFO - __main__ - Step 310 Global step 310 Train loss 2.31 on epoch=154
06/25/2022 01:36:23 - INFO - __main__ - Step 320 Global step 320 Train loss 2.26 on epoch=159
06/25/2022 01:36:24 - INFO - __main__ - Step 330 Global step 330 Train loss 2.21 on epoch=164
06/25/2022 01:36:26 - INFO - __main__ - Step 340 Global step 340 Train loss 2.16 on epoch=169
06/25/2022 01:36:27 - INFO - __main__ - Step 350 Global step 350 Train loss 2.17 on epoch=174
06/25/2022 01:36:29 - INFO - __main__ - Global step 350 Train loss 2.22 ACC 0.34375 on epoch=174
06/25/2022 01:36:31 - INFO - __main__ - Step 360 Global step 360 Train loss 2.09 on epoch=179
06/25/2022 01:36:32 - INFO - __main__ - Step 370 Global step 370 Train loss 2.06 on epoch=184
06/25/2022 01:36:33 - INFO - __main__ - Step 380 Global step 380 Train loss 1.94 on epoch=189
06/25/2022 01:36:34 - INFO - __main__ - Step 390 Global step 390 Train loss 1.74 on epoch=194
06/25/2022 01:36:35 - INFO - __main__ - Step 400 Global step 400 Train loss 1.81 on epoch=199
06/25/2022 01:36:42 - INFO - __main__ - Global step 400 Train loss 1.93 ACC 0.46875 on epoch=199
06/25/2022 01:36:42 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=199, global_step=400
06/25/2022 01:36:43 - INFO - __main__ - Step 410 Global step 410 Train loss 1.81 on epoch=204
06/25/2022 01:36:44 - INFO - __main__ - Step 420 Global step 420 Train loss 1.66 on epoch=209
06/25/2022 01:36:46 - INFO - __main__ - Step 430 Global step 430 Train loss 1.57 on epoch=214
06/25/2022 01:36:47 - INFO - __main__ - Step 440 Global step 440 Train loss 1.48 on epoch=219
06/25/2022 01:36:48 - INFO - __main__ - Step 450 Global step 450 Train loss 1.63 on epoch=224
06/25/2022 01:36:49 - INFO - __main__ - Global step 450 Train loss 1.63 ACC 0.5 on epoch=224
06/25/2022 01:36:49 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=224, global_step=450
06/25/2022 01:36:51 - INFO - __main__ - Step 460 Global step 460 Train loss 1.42 on epoch=229
06/25/2022 01:36:52 - INFO - __main__ - Step 470 Global step 470 Train loss 1.38 on epoch=234
06/25/2022 01:36:53 - INFO - __main__ - Step 480 Global step 480 Train loss 1.37 on epoch=239
06/25/2022 01:36:54 - INFO - __main__ - Step 490 Global step 490 Train loss 1.30 on epoch=244
06/25/2022 01:36:56 - INFO - __main__ - Step 500 Global step 500 Train loss 1.07 on epoch=249
06/25/2022 01:36:56 - INFO - __main__ - Global step 500 Train loss 1.31 ACC 0.5 on epoch=249
06/25/2022 01:36:57 - INFO - __main__ - Step 510 Global step 510 Train loss 1.19 on epoch=254
06/25/2022 01:36:59 - INFO - __main__ - Step 520 Global step 520 Train loss 1.21 on epoch=259
06/25/2022 01:37:00 - INFO - __main__ - Step 530 Global step 530 Train loss 1.16 on epoch=264
06/25/2022 01:37:01 - INFO - __main__ - Step 540 Global step 540 Train loss 1.07 on epoch=269
06/25/2022 01:37:02 - INFO - __main__ - Step 550 Global step 550 Train loss 1.01 on epoch=274
06/25/2022 01:37:03 - INFO - __main__ - Global step 550 Train loss 1.13 ACC 0.5 on epoch=274
06/25/2022 01:37:04 - INFO - __main__ - Step 560 Global step 560 Train loss 1.05 on epoch=279
06/25/2022 01:37:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.92 on epoch=284
06/25/2022 01:37:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.96 on epoch=289
06/25/2022 01:37:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.91 on epoch=294
06/25/2022 01:37:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.89 on epoch=299
06/25/2022 01:37:09 - INFO - __main__ - Global step 600 Train loss 0.95 ACC 0.5 on epoch=299
06/25/2022 01:37:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.93 on epoch=304
06/25/2022 01:37:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.97 on epoch=309
06/25/2022 01:37:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.88 on epoch=314
06/25/2022 01:37:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.84 on epoch=319
06/25/2022 01:37:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.87 on epoch=324
06/25/2022 01:37:16 - INFO - __main__ - Global step 650 Train loss 0.90 ACC 0.5 on epoch=324
06/25/2022 01:37:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.94 on epoch=329
06/25/2022 01:37:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.88 on epoch=334
06/25/2022 01:37:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.79 on epoch=339
06/25/2022 01:37:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.93 on epoch=344
06/25/2022 01:37:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.85 on epoch=349
06/25/2022 01:37:23 - INFO - __main__ - Global step 700 Train loss 0.88 ACC 0.5 on epoch=349
06/25/2022 01:37:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.81 on epoch=354
06/25/2022 01:37:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.81 on epoch=359
06/25/2022 01:37:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.75 on epoch=364
06/25/2022 01:37:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.72 on epoch=369
06/25/2022 01:37:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.80 on epoch=374
06/25/2022 01:37:29 - INFO - __main__ - Global step 750 Train loss 0.78 ACC 0.5 on epoch=374
06/25/2022 01:37:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.67 on epoch=379
06/25/2022 01:37:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.76 on epoch=384
06/25/2022 01:37:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.67 on epoch=389
06/25/2022 01:37:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.78 on epoch=394
06/25/2022 01:37:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.78 on epoch=399
06/25/2022 01:37:36 - INFO - __main__ - Global step 800 Train loss 0.73 ACC 0.5 on epoch=399
06/25/2022 01:37:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.78 on epoch=404
06/25/2022 01:37:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.74 on epoch=409
06/25/2022 01:37:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.73 on epoch=414
06/25/2022 01:37:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.65 on epoch=419
06/25/2022 01:37:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.77 on epoch=424
06/25/2022 01:37:43 - INFO - __main__ - Global step 850 Train loss 0.73 ACC 0.5 on epoch=424
06/25/2022 01:37:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.76 on epoch=429
06/25/2022 01:37:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.70 on epoch=434
06/25/2022 01:37:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.66 on epoch=439
06/25/2022 01:37:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.65 on epoch=444
06/25/2022 01:37:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.72 on epoch=449
06/25/2022 01:37:49 - INFO - __main__ - Global step 900 Train loss 0.70 ACC 0.5 on epoch=449
06/25/2022 01:37:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.73 on epoch=454
06/25/2022 01:37:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.73 on epoch=459
06/25/2022 01:37:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.65 on epoch=464
06/25/2022 01:37:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.67 on epoch=469
06/25/2022 01:37:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.63 on epoch=474
06/25/2022 01:37:56 - INFO - __main__ - Global step 950 Train loss 0.68 ACC 0.5 on epoch=474
06/25/2022 01:37:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.57 on epoch=479
06/25/2022 01:37:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.60 on epoch=484
06/25/2022 01:38:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.61 on epoch=489
06/25/2022 01:38:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.61 on epoch=494
06/25/2022 01:38:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.56 on epoch=499
06/25/2022 01:38:03 - INFO - __main__ - Global step 1000 Train loss 0.59 ACC 0.5 on epoch=499
06/25/2022 01:38:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.53 on epoch=504
06/25/2022 01:38:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.51 on epoch=509
06/25/2022 01:38:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.62 on epoch=514
06/25/2022 01:38:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.58 on epoch=519
06/25/2022 01:38:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.66 on epoch=524
06/25/2022 01:38:09 - INFO - __main__ - Global step 1050 Train loss 0.58 ACC 0.5 on epoch=524
06/25/2022 01:38:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.53 on epoch=529
06/25/2022 01:38:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.59 on epoch=534
06/25/2022 01:38:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.58 on epoch=539
06/25/2022 01:38:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.58 on epoch=544
06/25/2022 01:38:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.51 on epoch=549
06/25/2022 01:38:16 - INFO - __main__ - Global step 1100 Train loss 0.56 ACC 0.5 on epoch=549
06/25/2022 01:38:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.48 on epoch=554
06/25/2022 01:38:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.52 on epoch=559
06/25/2022 01:38:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.51 on epoch=564
06/25/2022 01:38:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.42 on epoch=569
06/25/2022 01:38:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.46 on epoch=574
06/25/2022 01:38:23 - INFO - __main__ - Global step 1150 Train loss 0.48 ACC 0.5 on epoch=574
06/25/2022 01:38:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.50 on epoch=579
06/25/2022 01:38:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.58 on epoch=584
06/25/2022 01:38:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.48 on epoch=589
06/25/2022 01:38:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.62 on epoch=594
06/25/2022 01:38:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.62 on epoch=599
06/25/2022 01:38:29 - INFO - __main__ - Global step 1200 Train loss 0.56 ACC 0.5 on epoch=599
06/25/2022 01:38:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.47 on epoch=604
06/25/2022 01:38:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.42 on epoch=609
06/25/2022 01:38:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.43 on epoch=614
06/25/2022 01:38:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.52 on epoch=619
06/25/2022 01:38:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.44 on epoch=624
06/25/2022 01:38:36 - INFO - __main__ - Global step 1250 Train loss 0.46 ACC 0.5 on epoch=624
06/25/2022 01:38:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.51 on epoch=629
06/25/2022 01:38:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.51 on epoch=634
06/25/2022 01:38:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.60 on epoch=639
06/25/2022 01:38:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.48 on epoch=644
06/25/2022 01:38:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.54 on epoch=649
06/25/2022 01:38:42 - INFO - __main__ - Global step 1300 Train loss 0.53 ACC 0.5 on epoch=649
06/25/2022 01:38:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.39 on epoch=654
06/25/2022 01:38:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.55 on epoch=659
06/25/2022 01:38:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.38 on epoch=664
06/25/2022 01:38:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.45 on epoch=669
06/25/2022 01:38:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.51 on epoch=674
06/25/2022 01:38:49 - INFO - __main__ - Global step 1350 Train loss 0.46 ACC 0.5 on epoch=674
06/25/2022 01:38:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.56 on epoch=679
06/25/2022 01:38:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.54 on epoch=684
06/25/2022 01:38:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.44 on epoch=689
06/25/2022 01:38:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.46 on epoch=694
06/25/2022 01:38:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.43 on epoch=699
06/25/2022 01:38:56 - INFO - __main__ - Global step 1400 Train loss 0.49 ACC 0.5 on epoch=699
06/25/2022 01:38:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.49 on epoch=704
06/25/2022 01:38:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.44 on epoch=709
06/25/2022 01:38:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.42 on epoch=714
06/25/2022 01:39:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.52 on epoch=719
06/25/2022 01:39:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.44 on epoch=724
06/25/2022 01:39:02 - INFO - __main__ - Global step 1450 Train loss 0.46 ACC 0.5 on epoch=724
06/25/2022 01:39:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.42 on epoch=729
06/25/2022 01:39:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.46 on epoch=734
06/25/2022 01:39:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.41 on epoch=739
06/25/2022 01:39:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.52 on epoch=744
06/25/2022 01:39:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.48 on epoch=749
06/25/2022 01:39:09 - INFO - __main__ - Global step 1500 Train loss 0.46 ACC 0.5 on epoch=749
06/25/2022 01:39:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.38 on epoch=754
06/25/2022 01:39:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.46 on epoch=759
06/25/2022 01:39:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.43 on epoch=764
06/25/2022 01:39:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.53 on epoch=769
06/25/2022 01:39:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.40 on epoch=774
06/25/2022 01:39:15 - INFO - __main__ - Global step 1550 Train loss 0.44 ACC 0.5 on epoch=774
06/25/2022 01:39:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.43 on epoch=779
06/25/2022 01:39:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.42 on epoch=784
06/25/2022 01:39:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.43 on epoch=789
06/25/2022 01:39:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.42 on epoch=794
06/25/2022 01:39:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.50 on epoch=799
06/25/2022 01:39:22 - INFO - __main__ - Global step 1600 Train loss 0.44 ACC 0.5 on epoch=799
06/25/2022 01:39:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.51 on epoch=804
06/25/2022 01:39:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.41 on epoch=809
06/25/2022 01:39:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.45 on epoch=814
06/25/2022 01:39:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.36 on epoch=819
06/25/2022 01:39:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.39 on epoch=824
06/25/2022 01:39:28 - INFO - __main__ - Global step 1650 Train loss 0.42 ACC 0.5 on epoch=824
06/25/2022 01:39:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.44 on epoch=829
06/25/2022 01:39:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.43 on epoch=834
06/25/2022 01:39:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.39 on epoch=839
06/25/2022 01:39:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.39 on epoch=844
06/25/2022 01:39:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.50 on epoch=849
06/25/2022 01:39:35 - INFO - __main__ - Global step 1700 Train loss 0.43 ACC 0.5 on epoch=849
06/25/2022 01:39:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.37 on epoch=854
06/25/2022 01:39:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.44 on epoch=859
06/25/2022 01:39:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.40 on epoch=864
06/25/2022 01:39:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.45 on epoch=869
06/25/2022 01:39:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.39 on epoch=874
06/25/2022 01:39:42 - INFO - __main__ - Global step 1750 Train loss 0.41 ACC 0.5 on epoch=874
06/25/2022 01:39:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.51 on epoch=879
06/25/2022 01:39:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.41 on epoch=884
06/25/2022 01:39:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.37 on epoch=889
06/25/2022 01:39:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.43 on epoch=894
06/25/2022 01:39:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.47 on epoch=899
06/25/2022 01:39:48 - INFO - __main__ - Global step 1800 Train loss 0.44 ACC 0.5 on epoch=899
06/25/2022 01:39:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.47 on epoch=904
06/25/2022 01:39:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.47 on epoch=909
06/25/2022 01:39:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.43 on epoch=914
06/25/2022 01:39:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.41 on epoch=919
06/25/2022 01:39:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.44 on epoch=924
06/25/2022 01:39:55 - INFO - __main__ - Global step 1850 Train loss 0.44 ACC 0.5 on epoch=924
06/25/2022 01:39:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.31 on epoch=929
06/25/2022 01:39:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.40 on epoch=934
06/25/2022 01:39:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.43 on epoch=939
06/25/2022 01:40:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.36 on epoch=944
06/25/2022 01:40:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.39 on epoch=949
06/25/2022 01:40:02 - INFO - __main__ - Global step 1900 Train loss 0.38 ACC 0.5 on epoch=949
06/25/2022 01:40:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.37 on epoch=954
06/25/2022 01:40:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.42 on epoch=959
06/25/2022 01:40:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.54 on epoch=964
06/25/2022 01:40:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.41 on epoch=969
06/25/2022 01:40:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.41 on epoch=974
06/25/2022 01:40:08 - INFO - __main__ - Global step 1950 Train loss 0.43 ACC 0.5 on epoch=974
06/25/2022 01:40:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.39 on epoch=979
06/25/2022 01:40:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.38 on epoch=984
06/25/2022 01:40:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.38 on epoch=989
06/25/2022 01:40:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.38 on epoch=994
06/25/2022 01:40:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.36 on epoch=999
06/25/2022 01:40:14 - INFO - __main__ - Global step 2000 Train loss 0.38 ACC 0.5 on epoch=999
06/25/2022 01:40:14 - INFO - __main__ - save last model!
06/25/2022 01:40:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:40:15 - INFO - __main__ - Start tokenizing ... 40430 instances
06/25/2022 01:40:15 - INFO - __main__ - Printing 3 examples
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/25/2022 01:40:15 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/25/2022 01:40:15 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:40:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:40:15 - INFO - __main__ - Printing 3 examples
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:40:15 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:40:15 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:40:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:40:15 - INFO - __main__ - Printing 3 examples
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 01:40:15 - INFO - __main__ - ['duplicate']
06/25/2022 01:40:15 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:40:15 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:40:15 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:40:21 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:40:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:40:22 - INFO - __main__ - Starting training!
06/25/2022 01:40:33 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:41:14 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 01:48:50 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_87_0.5_8_predictions.txt
06/25/2022 01:48:50 - INFO - __main__ - ACC on test data: 0.3682
06/25/2022 01:48:51 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.5, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/25/2022 01:48:51 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.4, bsz=8 ...
06/25/2022 01:48:52 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:48:52 - INFO - __main__ - Printing 3 examples
06/25/2022 01:48:52 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:48:52 - INFO - __main__ - ['duplicate']
06/25/2022 01:48:52 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 01:48:52 - INFO - __main__ - ['duplicate']
06/25/2022 01:48:52 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:48:52 - INFO - __main__ - ['duplicate']
06/25/2022 01:48:52 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:48:52 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:48:52 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:48:52 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:48:52 - INFO - __main__ - Printing 3 examples
06/25/2022 01:48:52 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 01:48:52 - INFO - __main__ - ['duplicate']
06/25/2022 01:48:52 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 01:48:52 - INFO - __main__ - ['duplicate']
06/25/2022 01:48:52 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 01:48:52 - INFO - __main__ - ['duplicate']
06/25/2022 01:48:52 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:48:52 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:48:52 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:48:57 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:48:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:48:57 - INFO - __main__ - Starting training!
06/25/2022 01:48:59 - INFO - __main__ - Step 10 Global step 10 Train loss 6.56 on epoch=4
06/25/2022 01:49:00 - INFO - __main__ - Step 20 Global step 20 Train loss 6.28 on epoch=9
06/25/2022 01:49:01 - INFO - __main__ - Step 30 Global step 30 Train loss 6.15 on epoch=14
06/25/2022 01:49:03 - INFO - __main__ - Step 40 Global step 40 Train loss 5.84 on epoch=19
06/25/2022 01:49:04 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=24
06/25/2022 01:49:06 - INFO - __main__ - Global step 50 Train loss 6.12 ACC 0.0 on epoch=24
06/25/2022 01:49:06 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/25/2022 01:49:07 - INFO - __main__ - Step 60 Global step 60 Train loss 5.49 on epoch=29
06/25/2022 01:49:08 - INFO - __main__ - Step 70 Global step 70 Train loss 5.27 on epoch=34
06/25/2022 01:49:10 - INFO - __main__ - Step 80 Global step 80 Train loss 5.19 on epoch=39
06/25/2022 01:49:11 - INFO - __main__ - Step 90 Global step 90 Train loss 4.95 on epoch=44
06/25/2022 01:49:12 - INFO - __main__ - Step 100 Global step 100 Train loss 4.93 on epoch=49
06/25/2022 01:49:14 - INFO - __main__ - Global step 100 Train loss 5.17 ACC 0.0 on epoch=49
06/25/2022 01:49:15 - INFO - __main__ - Step 110 Global step 110 Train loss 4.80 on epoch=54
06/25/2022 01:49:16 - INFO - __main__ - Step 120 Global step 120 Train loss 4.53 on epoch=59
06/25/2022 01:49:17 - INFO - __main__ - Step 130 Global step 130 Train loss 4.47 on epoch=64
06/25/2022 01:49:19 - INFO - __main__ - Step 140 Global step 140 Train loss 4.25 on epoch=69
06/25/2022 01:49:20 - INFO - __main__ - Step 150 Global step 150 Train loss 4.28 on epoch=74
06/25/2022 01:49:21 - INFO - __main__ - Global step 150 Train loss 4.46 ACC 0.0 on epoch=74
06/25/2022 01:49:23 - INFO - __main__ - Step 160 Global step 160 Train loss 3.96 on epoch=79
06/25/2022 01:49:24 - INFO - __main__ - Step 170 Global step 170 Train loss 4.05 on epoch=84
06/25/2022 01:49:25 - INFO - __main__ - Step 180 Global step 180 Train loss 3.95 on epoch=89
06/25/2022 01:49:26 - INFO - __main__ - Step 190 Global step 190 Train loss 3.69 on epoch=94
06/25/2022 01:49:28 - INFO - __main__ - Step 200 Global step 200 Train loss 3.55 on epoch=99
06/25/2022 01:49:29 - INFO - __main__ - Global step 200 Train loss 3.84 ACC 0.0 on epoch=99
06/25/2022 01:49:30 - INFO - __main__ - Step 210 Global step 210 Train loss 3.50 on epoch=104
06/25/2022 01:49:31 - INFO - __main__ - Step 220 Global step 220 Train loss 3.31 on epoch=109
06/25/2022 01:49:33 - INFO - __main__ - Step 230 Global step 230 Train loss 3.35 on epoch=114
06/25/2022 01:49:34 - INFO - __main__ - Step 240 Global step 240 Train loss 2.92 on epoch=119
06/25/2022 01:49:35 - INFO - __main__ - Step 250 Global step 250 Train loss 2.99 on epoch=124
06/25/2022 01:49:36 - INFO - __main__ - Global step 250 Train loss 3.21 ACC 0.0 on epoch=124
06/25/2022 01:49:38 - INFO - __main__ - Step 260 Global step 260 Train loss 2.90 on epoch=129
06/25/2022 01:49:39 - INFO - __main__ - Step 270 Global step 270 Train loss 2.70 on epoch=134
06/25/2022 01:49:40 - INFO - __main__ - Step 280 Global step 280 Train loss 2.57 on epoch=139
06/25/2022 01:49:41 - INFO - __main__ - Step 290 Global step 290 Train loss 2.56 on epoch=144
06/25/2022 01:49:43 - INFO - __main__ - Step 300 Global step 300 Train loss 2.50 on epoch=149
06/25/2022 01:49:44 - INFO - __main__ - Global step 300 Train loss 2.65 ACC 0.09375 on epoch=149
06/25/2022 01:49:44 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.09375 on epoch=149, global_step=300
06/25/2022 01:49:45 - INFO - __main__ - Step 310 Global step 310 Train loss 2.51 on epoch=154
06/25/2022 01:49:46 - INFO - __main__ - Step 320 Global step 320 Train loss 2.51 on epoch=159
06/25/2022 01:49:48 - INFO - __main__ - Step 330 Global step 330 Train loss 2.34 on epoch=164
06/25/2022 01:49:49 - INFO - __main__ - Step 340 Global step 340 Train loss 2.32 on epoch=169
06/25/2022 01:49:50 - INFO - __main__ - Step 350 Global step 350 Train loss 2.22 on epoch=174
06/25/2022 01:49:50 - INFO - __main__ - Global step 350 Train loss 2.38 ACC 0.4375 on epoch=174
06/25/2022 01:49:50 - INFO - __main__ - Saving model with best ACC: 0.09375 -> 0.4375 on epoch=174, global_step=350
06/25/2022 01:49:52 - INFO - __main__ - Step 360 Global step 360 Train loss 2.19 on epoch=179
06/25/2022 01:49:53 - INFO - __main__ - Step 370 Global step 370 Train loss 2.13 on epoch=184
06/25/2022 01:49:54 - INFO - __main__ - Step 380 Global step 380 Train loss 2.10 on epoch=189
06/25/2022 01:49:56 - INFO - __main__ - Step 390 Global step 390 Train loss 2.23 on epoch=194
06/25/2022 01:49:57 - INFO - __main__ - Step 400 Global step 400 Train loss 2.24 on epoch=199
06/25/2022 01:49:58 - INFO - __main__ - Global step 400 Train loss 2.18 ACC 0.34375 on epoch=199
06/25/2022 01:49:59 - INFO - __main__ - Step 410 Global step 410 Train loss 2.04 on epoch=204
06/25/2022 01:50:00 - INFO - __main__ - Step 420 Global step 420 Train loss 1.98 on epoch=209
06/25/2022 01:50:02 - INFO - __main__ - Step 430 Global step 430 Train loss 2.00 on epoch=214
06/25/2022 01:50:03 - INFO - __main__ - Step 440 Global step 440 Train loss 1.96 on epoch=219
06/25/2022 01:50:04 - INFO - __main__ - Step 450 Global step 450 Train loss 1.82 on epoch=224
06/25/2022 01:50:05 - INFO - __main__ - Global step 450 Train loss 1.96 ACC 0.5 on epoch=224
06/25/2022 01:50:05 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.5 on epoch=224, global_step=450
06/25/2022 01:50:06 - INFO - __main__ - Step 460 Global step 460 Train loss 1.89 on epoch=229
06/25/2022 01:50:08 - INFO - __main__ - Step 470 Global step 470 Train loss 1.77 on epoch=234
06/25/2022 01:50:09 - INFO - __main__ - Step 480 Global step 480 Train loss 1.70 on epoch=239
06/25/2022 01:50:10 - INFO - __main__ - Step 490 Global step 490 Train loss 1.76 on epoch=244
06/25/2022 01:50:11 - INFO - __main__ - Step 500 Global step 500 Train loss 1.71 on epoch=249
06/25/2022 01:50:12 - INFO - __main__ - Global step 500 Train loss 1.77 ACC 0.5 on epoch=249
06/25/2022 01:50:13 - INFO - __main__ - Step 510 Global step 510 Train loss 1.91 on epoch=254
06/25/2022 01:50:14 - INFO - __main__ - Step 520 Global step 520 Train loss 1.76 on epoch=259
06/25/2022 01:50:16 - INFO - __main__ - Step 530 Global step 530 Train loss 1.63 on epoch=264
06/25/2022 01:50:17 - INFO - __main__ - Step 540 Global step 540 Train loss 1.70 on epoch=269
06/25/2022 01:50:18 - INFO - __main__ - Step 550 Global step 550 Train loss 1.53 on epoch=274
06/25/2022 01:50:19 - INFO - __main__ - Global step 550 Train loss 1.70 ACC 0.5 on epoch=274
06/25/2022 01:50:20 - INFO - __main__ - Step 560 Global step 560 Train loss 1.45 on epoch=279
06/25/2022 01:50:21 - INFO - __main__ - Step 570 Global step 570 Train loss 1.46 on epoch=284
06/25/2022 01:50:23 - INFO - __main__ - Step 580 Global step 580 Train loss 1.49 on epoch=289
06/25/2022 01:50:24 - INFO - __main__ - Step 590 Global step 590 Train loss 1.29 on epoch=294
06/25/2022 01:50:25 - INFO - __main__ - Step 600 Global step 600 Train loss 1.41 on epoch=299
06/25/2022 01:50:26 - INFO - __main__ - Global step 600 Train loss 1.42 ACC 0.5 on epoch=299
06/25/2022 01:50:27 - INFO - __main__ - Step 610 Global step 610 Train loss 1.34 on epoch=304
06/25/2022 01:50:28 - INFO - __main__ - Step 620 Global step 620 Train loss 1.37 on epoch=309
06/25/2022 01:50:30 - INFO - __main__ - Step 630 Global step 630 Train loss 1.27 on epoch=314
06/25/2022 01:50:31 - INFO - __main__ - Step 640 Global step 640 Train loss 1.25 on epoch=319
06/25/2022 01:50:32 - INFO - __main__ - Step 650 Global step 650 Train loss 1.27 on epoch=324
06/25/2022 01:50:34 - INFO - __main__ - Global step 650 Train loss 1.30 ACC 0.5 on epoch=324
06/25/2022 01:50:35 - INFO - __main__ - Step 660 Global step 660 Train loss 1.24 on epoch=329
06/25/2022 01:50:36 - INFO - __main__ - Step 670 Global step 670 Train loss 1.25 on epoch=334
06/25/2022 01:50:37 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=339
06/25/2022 01:50:39 - INFO - __main__ - Step 690 Global step 690 Train loss 1.15 on epoch=344
06/25/2022 01:50:40 - INFO - __main__ - Step 700 Global step 700 Train loss 1.15 on epoch=349
06/25/2022 01:50:41 - INFO - __main__ - Global step 700 Train loss 1.20 ACC 0.5 on epoch=349
06/25/2022 01:50:42 - INFO - __main__ - Step 710 Global step 710 Train loss 1.03 on epoch=354
06/25/2022 01:50:43 - INFO - __main__ - Step 720 Global step 720 Train loss 1.08 on epoch=359
06/25/2022 01:50:45 - INFO - __main__ - Step 730 Global step 730 Train loss 1.09 on epoch=364
06/25/2022 01:50:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.95 on epoch=369
06/25/2022 01:50:47 - INFO - __main__ - Step 750 Global step 750 Train loss 1.00 on epoch=374
06/25/2022 01:50:49 - INFO - __main__ - Global step 750 Train loss 1.03 ACC 0.5 on epoch=374
06/25/2022 01:50:50 - INFO - __main__ - Step 760 Global step 760 Train loss 1.05 on epoch=379
06/25/2022 01:50:52 - INFO - __main__ - Step 770 Global step 770 Train loss 1.13 on epoch=384
06/25/2022 01:50:53 - INFO - __main__ - Step 780 Global step 780 Train loss 1.07 on epoch=389
06/25/2022 01:50:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.92 on epoch=394
06/25/2022 01:50:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.92 on epoch=399
06/25/2022 01:51:05 - INFO - __main__ - Global step 800 Train loss 1.02 ACC 0.5 on epoch=399
06/25/2022 01:51:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.94 on epoch=404
06/25/2022 01:51:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.92 on epoch=409
06/25/2022 01:51:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.89 on epoch=414
06/25/2022 01:51:10 - INFO - __main__ - Step 840 Global step 840 Train loss 1.00 on epoch=419
06/25/2022 01:51:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.82 on epoch=424
06/25/2022 01:51:13 - INFO - __main__ - Global step 850 Train loss 0.91 ACC 0.5 on epoch=424
06/25/2022 01:51:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.95 on epoch=429
06/25/2022 01:51:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.72 on epoch=434
06/25/2022 01:51:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.77 on epoch=439
06/25/2022 01:51:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.85 on epoch=444
06/25/2022 01:51:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.85 on epoch=449
06/25/2022 01:51:22 - INFO - __main__ - Global step 900 Train loss 0.83 ACC 0.5 on epoch=449
06/25/2022 01:51:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.83 on epoch=454
06/25/2022 01:51:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.69 on epoch=459
06/25/2022 01:51:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.74 on epoch=464
06/25/2022 01:51:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.84 on epoch=469
06/25/2022 01:51:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.78 on epoch=474
06/25/2022 01:51:30 - INFO - __main__ - Global step 950 Train loss 0.78 ACC 0.5 on epoch=474
06/25/2022 01:51:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.76 on epoch=479
06/25/2022 01:51:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.68 on epoch=484
06/25/2022 01:51:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.61 on epoch=489
06/25/2022 01:51:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.80 on epoch=494
06/25/2022 01:51:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.64 on epoch=499
06/25/2022 01:51:37 - INFO - __main__ - Global step 1000 Train loss 0.70 ACC 0.5 on epoch=499
06/25/2022 01:51:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.83 on epoch=504
06/25/2022 01:51:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.75 on epoch=509
06/25/2022 01:51:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.70 on epoch=514
06/25/2022 01:51:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.60 on epoch=519
06/25/2022 01:51:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.68 on epoch=524
06/25/2022 01:51:43 - INFO - __main__ - Global step 1050 Train loss 0.71 ACC 0.5 on epoch=524
06/25/2022 01:51:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.63 on epoch=529
06/25/2022 01:51:46 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.58 on epoch=534
06/25/2022 01:51:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.71 on epoch=539
06/25/2022 01:51:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.61 on epoch=544
06/25/2022 01:51:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.58 on epoch=549
06/25/2022 01:51:50 - INFO - __main__ - Global step 1100 Train loss 0.62 ACC 0.5 on epoch=549
06/25/2022 01:51:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.61 on epoch=554
06/25/2022 01:51:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.61 on epoch=559
06/25/2022 01:51:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.54 on epoch=564
06/25/2022 01:51:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.63 on epoch=569
06/25/2022 01:51:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.60 on epoch=574
06/25/2022 01:51:57 - INFO - __main__ - Global step 1150 Train loss 0.60 ACC 0.5 on epoch=574
06/25/2022 01:51:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.63 on epoch=579
06/25/2022 01:52:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.57 on epoch=584
06/25/2022 01:52:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.58 on epoch=589
06/25/2022 01:52:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.60 on epoch=594
06/25/2022 01:52:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.54 on epoch=599
06/25/2022 01:52:04 - INFO - __main__ - Global step 1200 Train loss 0.58 ACC 0.5 on epoch=599
06/25/2022 01:52:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.60 on epoch=604
06/25/2022 01:52:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.53 on epoch=609
06/25/2022 01:52:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.53 on epoch=614
06/25/2022 01:52:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.55 on epoch=619
06/25/2022 01:52:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.66 on epoch=624
06/25/2022 01:52:11 - INFO - __main__ - Global step 1250 Train loss 0.57 ACC 0.5 on epoch=624
06/25/2022 01:52:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.47 on epoch=629
06/25/2022 01:52:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.58 on epoch=634
06/25/2022 01:52:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.55 on epoch=639
06/25/2022 01:52:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.56 on epoch=644
06/25/2022 01:52:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.47 on epoch=649
06/25/2022 01:52:18 - INFO - __main__ - Global step 1300 Train loss 0.53 ACC 0.5 on epoch=649
06/25/2022 01:52:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.47 on epoch=654
06/25/2022 01:52:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.55 on epoch=659
06/25/2022 01:52:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.39 on epoch=664
06/25/2022 01:52:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.47 on epoch=669
06/25/2022 01:52:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.52 on epoch=674
06/25/2022 01:52:25 - INFO - __main__ - Global step 1350 Train loss 0.48 ACC 0.5 on epoch=674
06/25/2022 01:52:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.51 on epoch=679
06/25/2022 01:52:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.51 on epoch=684
06/25/2022 01:52:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.49 on epoch=689
06/25/2022 01:52:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.49 on epoch=694
06/25/2022 01:52:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.47 on epoch=699
06/25/2022 01:52:32 - INFO - __main__ - Global step 1400 Train loss 0.49 ACC 0.5 on epoch=699
06/25/2022 01:52:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.52 on epoch=704
06/25/2022 01:52:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.45 on epoch=709
06/25/2022 01:52:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.43 on epoch=714
06/25/2022 01:52:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.46 on epoch=719
06/25/2022 01:52:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.49 on epoch=724
06/25/2022 01:52:39 - INFO - __main__ - Global step 1450 Train loss 0.47 ACC 0.5 on epoch=724
06/25/2022 01:52:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.44 on epoch=729
06/25/2022 01:52:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.46 on epoch=734
06/25/2022 01:52:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.47 on epoch=739
06/25/2022 01:52:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.41 on epoch=744
06/25/2022 01:52:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.42 on epoch=749
06/25/2022 01:52:46 - INFO - __main__ - Global step 1500 Train loss 0.44 ACC 0.5 on epoch=749
06/25/2022 01:52:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.50 on epoch=754
06/25/2022 01:52:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.46 on epoch=759
06/25/2022 01:52:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.52 on epoch=764
06/25/2022 01:52:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.48 on epoch=769
06/25/2022 01:52:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.48 on epoch=774
06/25/2022 01:52:53 - INFO - __main__ - Global step 1550 Train loss 0.49 ACC 0.5 on epoch=774
06/25/2022 01:52:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.53 on epoch=779
06/25/2022 01:52:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.49 on epoch=784
06/25/2022 01:52:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.44 on epoch=789
06/25/2022 01:52:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.41 on epoch=794
06/25/2022 01:52:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.44 on epoch=799
06/25/2022 01:52:59 - INFO - __main__ - Global step 1600 Train loss 0.46 ACC 0.5 on epoch=799
06/25/2022 01:53:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.51 on epoch=804
06/25/2022 01:53:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.41 on epoch=809
06/25/2022 01:53:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.44 on epoch=814
06/25/2022 01:53:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.46 on epoch=819
06/25/2022 01:53:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.44 on epoch=824
06/25/2022 01:53:06 - INFO - __main__ - Global step 1650 Train loss 0.45 ACC 0.5 on epoch=824
06/25/2022 01:53:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.44 on epoch=829
06/25/2022 01:53:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.46 on epoch=834
06/25/2022 01:53:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.43 on epoch=839
06/25/2022 01:53:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.47 on epoch=844
06/25/2022 01:53:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.40 on epoch=849
06/25/2022 01:53:13 - INFO - __main__ - Global step 1700 Train loss 0.44 ACC 0.5 on epoch=849
06/25/2022 01:53:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.47 on epoch=854
06/25/2022 01:53:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.47 on epoch=859
06/25/2022 01:53:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.41 on epoch=864
06/25/2022 01:53:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.51 on epoch=869
06/25/2022 01:53:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.39 on epoch=874
06/25/2022 01:53:20 - INFO - __main__ - Global step 1750 Train loss 0.45 ACC 0.5 on epoch=874
06/25/2022 01:53:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.43 on epoch=879
06/25/2022 01:53:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.42 on epoch=884
06/25/2022 01:53:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.41 on epoch=889
06/25/2022 01:53:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.49 on epoch=894
06/25/2022 01:53:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.43 on epoch=899
06/25/2022 01:53:27 - INFO - __main__ - Global step 1800 Train loss 0.44 ACC 0.5 on epoch=899
06/25/2022 01:53:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.37 on epoch=904
06/25/2022 01:53:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.41 on epoch=909
06/25/2022 01:53:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.45 on epoch=914
06/25/2022 01:53:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.39 on epoch=919
06/25/2022 01:53:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.38 on epoch=924
06/25/2022 01:53:34 - INFO - __main__ - Global step 1850 Train loss 0.40 ACC 0.5 on epoch=924
06/25/2022 01:53:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.37 on epoch=929
06/25/2022 01:53:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.39 on epoch=934
06/25/2022 01:53:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.45 on epoch=939
06/25/2022 01:53:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.49 on epoch=944
06/25/2022 01:53:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.46 on epoch=949
06/25/2022 01:53:41 - INFO - __main__ - Global step 1900 Train loss 0.43 ACC 0.5 on epoch=949
06/25/2022 01:53:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.39 on epoch=954
06/25/2022 01:53:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.49 on epoch=959
06/25/2022 01:53:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.40 on epoch=964
06/25/2022 01:53:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.39 on epoch=969
06/25/2022 01:53:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.39 on epoch=974
06/25/2022 01:53:48 - INFO - __main__ - Global step 1950 Train loss 0.41 ACC 0.5 on epoch=974
06/25/2022 01:53:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.41 on epoch=979
06/25/2022 01:53:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.36 on epoch=984
06/25/2022 01:53:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.39 on epoch=989
06/25/2022 01:53:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.42 on epoch=994
06/25/2022 01:53:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.45 on epoch=999
06/25/2022 01:53:55 - INFO - __main__ - Global step 2000 Train loss 0.41 ACC 0.5 on epoch=999
06/25/2022 01:53:55 - INFO - __main__ - save last model!
06/25/2022 01:53:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:53:55 - INFO - __main__ - Start tokenizing ... 40430 instances
06/25/2022 01:53:55 - INFO - __main__ - Printing 3 examples
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/25/2022 01:53:55 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/25/2022 01:53:55 - INFO - __main__ - ['not_duplicate']
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:53:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:53:55 - INFO - __main__ - Printing 3 examples
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:53:55 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:53:55 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 01:53:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 01:53:55 - INFO - __main__ - Printing 3 examples
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 01:53:55 - INFO - __main__ - ['duplicate']
06/25/2022 01:53:55 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:53:55 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:53:55 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 01:54:01 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:54:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 01:54:02 - INFO - __main__ - Starting training!
06/25/2022 01:54:13 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:54:55 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 02:07:04 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_87_0.4_8_predictions.txt
06/25/2022 02:07:04 - INFO - __main__ - ACC on test data: 0.3682
06/25/2022 02:07:04 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.4, bsz=8, dev_performance=0.5, test_performance=0.3681919366806827
06/25/2022 02:07:04 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.3, bsz=8 ...
06/25/2022 02:07:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 02:07:05 - INFO - __main__ - Printing 3 examples
06/25/2022 02:07:05 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 02:07:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:07:05 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 02:07:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:07:05 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 02:07:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:07:05 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:07:05 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:07:05 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 02:07:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 02:07:05 - INFO - __main__ - Printing 3 examples
06/25/2022 02:07:05 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 02:07:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:07:05 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 02:07:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:07:05 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 02:07:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:07:05 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:07:05 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:07:05 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 02:07:10 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:07:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 02:07:11 - INFO - __main__ - Starting training!
06/25/2022 02:07:12 - INFO - __main__ - Step 10 Global step 10 Train loss 6.51 on epoch=4
06/25/2022 02:07:13 - INFO - __main__ - Step 20 Global step 20 Train loss 6.44 on epoch=9
06/25/2022 02:07:15 - INFO - __main__ - Step 30 Global step 30 Train loss 6.23 on epoch=14
06/25/2022 02:07:16 - INFO - __main__ - Step 40 Global step 40 Train loss 6.02 on epoch=19
06/25/2022 02:07:17 - INFO - __main__ - Step 50 Global step 50 Train loss 5.81 on epoch=24
06/25/2022 02:07:19 - INFO - __main__ - Global step 50 Train loss 6.20 ACC 0.0 on epoch=24
06/25/2022 02:07:19 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/25/2022 02:07:20 - INFO - __main__ - Step 60 Global step 60 Train loss 5.49 on epoch=29
06/25/2022 02:07:21 - INFO - __main__ - Step 70 Global step 70 Train loss 5.40 on epoch=34
06/25/2022 02:07:22 - INFO - __main__ - Step 80 Global step 80 Train loss 5.47 on epoch=39
06/25/2022 02:07:24 - INFO - __main__ - Step 90 Global step 90 Train loss 5.42 on epoch=44
06/25/2022 02:07:25 - INFO - __main__ - Step 100 Global step 100 Train loss 5.19 on epoch=49
06/25/2022 02:07:26 - INFO - __main__ - Global step 100 Train loss 5.39 ACC 0.0 on epoch=49
06/25/2022 02:07:27 - INFO - __main__ - Step 110 Global step 110 Train loss 5.32 on epoch=54
06/25/2022 02:07:29 - INFO - __main__ - Step 120 Global step 120 Train loss 5.23 on epoch=59
06/25/2022 02:07:30 - INFO - __main__ - Step 130 Global step 130 Train loss 5.24 on epoch=64
06/25/2022 02:07:31 - INFO - __main__ - Step 140 Global step 140 Train loss 5.13 on epoch=69
06/25/2022 02:07:32 - INFO - __main__ - Step 150 Global step 150 Train loss 5.16 on epoch=74
06/25/2022 02:07:34 - INFO - __main__ - Global step 150 Train loss 5.22 ACC 0.0 on epoch=74
06/25/2022 02:07:35 - INFO - __main__ - Step 160 Global step 160 Train loss 4.99 on epoch=79
06/25/2022 02:07:36 - INFO - __main__ - Step 170 Global step 170 Train loss 5.03 on epoch=84
06/25/2022 02:07:38 - INFO - __main__ - Step 180 Global step 180 Train loss 4.96 on epoch=89
06/25/2022 02:07:39 - INFO - __main__ - Step 190 Global step 190 Train loss 5.05 on epoch=94
06/25/2022 02:07:40 - INFO - __main__ - Step 200 Global step 200 Train loss 4.80 on epoch=99
06/25/2022 02:07:42 - INFO - __main__ - Global step 200 Train loss 4.96 ACC 0.0 on epoch=99
06/25/2022 02:07:43 - INFO - __main__ - Step 210 Global step 210 Train loss 4.79 on epoch=104
06/25/2022 02:07:44 - INFO - __main__ - Step 220 Global step 220 Train loss 4.69 on epoch=109
06/25/2022 02:07:45 - INFO - __main__ - Step 230 Global step 230 Train loss 4.62 on epoch=114
06/25/2022 02:07:47 - INFO - __main__ - Step 240 Global step 240 Train loss 4.65 on epoch=119
06/25/2022 02:07:48 - INFO - __main__ - Step 250 Global step 250 Train loss 4.36 on epoch=124
06/25/2022 02:07:49 - INFO - __main__ - Global step 250 Train loss 4.62 ACC 0.0 on epoch=124
06/25/2022 02:07:50 - INFO - __main__ - Step 260 Global step 260 Train loss 4.54 on epoch=129
06/25/2022 02:07:52 - INFO - __main__ - Step 270 Global step 270 Train loss 4.43 on epoch=134
06/25/2022 02:07:53 - INFO - __main__ - Step 280 Global step 280 Train loss 4.40 on epoch=139
06/25/2022 02:07:54 - INFO - __main__ - Step 290 Global step 290 Train loss 4.23 on epoch=144
06/25/2022 02:07:55 - INFO - __main__ - Step 300 Global step 300 Train loss 4.02 on epoch=149
06/25/2022 02:07:57 - INFO - __main__ - Global step 300 Train loss 4.32 ACC 0.0 on epoch=149
06/25/2022 02:07:58 - INFO - __main__ - Step 310 Global step 310 Train loss 4.16 on epoch=154
06/25/2022 02:07:59 - INFO - __main__ - Step 320 Global step 320 Train loss 3.97 on epoch=159
06/25/2022 02:08:00 - INFO - __main__ - Step 330 Global step 330 Train loss 3.91 on epoch=164
06/25/2022 02:08:02 - INFO - __main__ - Step 340 Global step 340 Train loss 3.86 on epoch=169
06/25/2022 02:08:03 - INFO - __main__ - Step 350 Global step 350 Train loss 3.78 on epoch=174
06/25/2022 02:08:04 - INFO - __main__ - Global step 350 Train loss 3.94 ACC 0.0 on epoch=174
06/25/2022 02:08:05 - INFO - __main__ - Step 360 Global step 360 Train loss 3.74 on epoch=179
06/25/2022 02:08:07 - INFO - __main__ - Step 370 Global step 370 Train loss 3.61 on epoch=184
06/25/2022 02:08:08 - INFO - __main__ - Step 380 Global step 380 Train loss 3.48 on epoch=189
06/25/2022 02:08:09 - INFO - __main__ - Step 390 Global step 390 Train loss 3.48 on epoch=194
06/25/2022 02:08:10 - INFO - __main__ - Step 400 Global step 400 Train loss 3.35 on epoch=199
06/25/2022 02:08:11 - INFO - __main__ - Global step 400 Train loss 3.53 ACC 0.0 on epoch=199
06/25/2022 02:08:13 - INFO - __main__ - Step 410 Global step 410 Train loss 3.45 on epoch=204
06/25/2022 02:08:14 - INFO - __main__ - Step 420 Global step 420 Train loss 3.21 on epoch=209
06/25/2022 02:08:15 - INFO - __main__ - Step 430 Global step 430 Train loss 3.23 on epoch=214
06/25/2022 02:08:17 - INFO - __main__ - Step 440 Global step 440 Train loss 3.12 on epoch=219
06/25/2022 02:08:18 - INFO - __main__ - Step 450 Global step 450 Train loss 3.05 on epoch=224
06/25/2022 02:08:20 - INFO - __main__ - Global step 450 Train loss 3.21 ACC 0.0 on epoch=224
06/25/2022 02:08:21 - INFO - __main__ - Step 460 Global step 460 Train loss 2.77 on epoch=229
06/25/2022 02:08:22 - INFO - __main__ - Step 470 Global step 470 Train loss 2.94 on epoch=234
06/25/2022 02:08:24 - INFO - __main__ - Step 480 Global step 480 Train loss 2.93 on epoch=239
06/25/2022 02:08:25 - INFO - __main__ - Step 490 Global step 490 Train loss 2.90 on epoch=244
06/25/2022 02:08:26 - INFO - __main__ - Step 500 Global step 500 Train loss 2.83 on epoch=249
06/25/2022 02:08:28 - INFO - __main__ - Global step 500 Train loss 2.87 ACC 0.0 on epoch=249
06/25/2022 02:08:30 - INFO - __main__ - Step 510 Global step 510 Train loss 2.63 on epoch=254
06/25/2022 02:08:31 - INFO - __main__ - Step 520 Global step 520 Train loss 2.59 on epoch=259
06/25/2022 02:08:32 - INFO - __main__ - Step 530 Global step 530 Train loss 2.64 on epoch=264
06/25/2022 02:08:33 - INFO - __main__ - Step 540 Global step 540 Train loss 2.53 on epoch=269
06/25/2022 02:08:34 - INFO - __main__ - Step 550 Global step 550 Train loss 2.57 on epoch=274
06/25/2022 02:08:45 - INFO - __main__ - Global step 550 Train loss 2.59 ACC 0.1875 on epoch=274
06/25/2022 02:08:45 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.1875 on epoch=274, global_step=550
06/25/2022 02:08:46 - INFO - __main__ - Step 560 Global step 560 Train loss 2.61 on epoch=279
06/25/2022 02:08:47 - INFO - __main__ - Step 570 Global step 570 Train loss 2.54 on epoch=284
06/25/2022 02:08:49 - INFO - __main__ - Step 580 Global step 580 Train loss 2.49 on epoch=289
06/25/2022 02:08:50 - INFO - __main__ - Step 590 Global step 590 Train loss 2.48 on epoch=294
06/25/2022 02:08:51 - INFO - __main__ - Step 600 Global step 600 Train loss 2.37 on epoch=299
06/25/2022 02:08:54 - INFO - __main__ - Global step 600 Train loss 2.50 ACC 0.375 on epoch=299
06/25/2022 02:08:54 - INFO - __main__ - Saving model with best ACC: 0.1875 -> 0.375 on epoch=299, global_step=600
06/25/2022 02:08:56 - INFO - __main__ - Step 610 Global step 610 Train loss 2.44 on epoch=304
06/25/2022 02:08:57 - INFO - __main__ - Step 620 Global step 620 Train loss 2.40 on epoch=309
06/25/2022 02:08:58 - INFO - __main__ - Step 630 Global step 630 Train loss 2.43 on epoch=314
06/25/2022 02:08:59 - INFO - __main__ - Step 640 Global step 640 Train loss 2.31 on epoch=319
06/25/2022 02:09:01 - INFO - __main__ - Step 650 Global step 650 Train loss 2.30 on epoch=324
06/25/2022 02:09:07 - INFO - __main__ - Global step 650 Train loss 2.38 ACC 0.375 on epoch=324
06/25/2022 02:09:08 - INFO - __main__ - Step 660 Global step 660 Train loss 2.24 on epoch=329
06/25/2022 02:09:09 - INFO - __main__ - Step 670 Global step 670 Train loss 2.28 on epoch=334
06/25/2022 02:09:11 - INFO - __main__ - Step 680 Global step 680 Train loss 2.08 on epoch=339
06/25/2022 02:09:12 - INFO - __main__ - Step 690 Global step 690 Train loss 2.08 on epoch=344
06/25/2022 02:09:13 - INFO - __main__ - Step 700 Global step 700 Train loss 2.01 on epoch=349
06/25/2022 02:09:20 - INFO - __main__ - Global step 700 Train loss 2.14 ACC 0.40625 on epoch=349
06/25/2022 02:09:20 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.40625 on epoch=349, global_step=700
06/25/2022 02:09:21 - INFO - __main__ - Step 710 Global step 710 Train loss 2.06 on epoch=354
06/25/2022 02:09:22 - INFO - __main__ - Step 720 Global step 720 Train loss 1.90 on epoch=359
06/25/2022 02:09:24 - INFO - __main__ - Step 730 Global step 730 Train loss 2.04 on epoch=364
06/25/2022 02:09:25 - INFO - __main__ - Step 740 Global step 740 Train loss 1.84 on epoch=369
06/25/2022 02:09:26 - INFO - __main__ - Step 750 Global step 750 Train loss 1.93 on epoch=374
06/25/2022 02:09:33 - INFO - __main__ - Global step 750 Train loss 1.96 ACC 0.4375 on epoch=374
06/25/2022 02:09:33 - INFO - __main__ - Saving model with best ACC: 0.40625 -> 0.4375 on epoch=374, global_step=750
06/25/2022 02:09:34 - INFO - __main__ - Step 760 Global step 760 Train loss 1.87 on epoch=379
06/25/2022 02:09:35 - INFO - __main__ - Step 770 Global step 770 Train loss 1.81 on epoch=384
06/25/2022 02:09:36 - INFO - __main__ - Step 780 Global step 780 Train loss 1.89 on epoch=389
06/25/2022 02:09:38 - INFO - __main__ - Step 790 Global step 790 Train loss 1.79 on epoch=394
06/25/2022 02:09:39 - INFO - __main__ - Step 800 Global step 800 Train loss 1.64 on epoch=399
06/25/2022 02:09:44 - INFO - __main__ - Global step 800 Train loss 1.80 ACC 0.46875 on epoch=399
06/25/2022 02:09:44 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=399, global_step=800
06/25/2022 02:09:45 - INFO - __main__ - Step 810 Global step 810 Train loss 1.65 on epoch=404
06/25/2022 02:09:47 - INFO - __main__ - Step 820 Global step 820 Train loss 1.59 on epoch=409
06/25/2022 02:09:48 - INFO - __main__ - Step 830 Global step 830 Train loss 1.68 on epoch=414
06/25/2022 02:09:49 - INFO - __main__ - Step 840 Global step 840 Train loss 1.53 on epoch=419
06/25/2022 02:09:50 - INFO - __main__ - Step 850 Global step 850 Train loss 1.56 on epoch=424
06/25/2022 02:09:51 - INFO - __main__ - Global step 850 Train loss 1.60 ACC 0.5 on epoch=424
06/25/2022 02:09:51 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=424, global_step=850
06/25/2022 02:09:52 - INFO - __main__ - Step 860 Global step 860 Train loss 1.48 on epoch=429
06/25/2022 02:09:54 - INFO - __main__ - Step 870 Global step 870 Train loss 1.49 on epoch=434
06/25/2022 02:09:55 - INFO - __main__ - Step 880 Global step 880 Train loss 1.47 on epoch=439
06/25/2022 02:09:56 - INFO - __main__ - Step 890 Global step 890 Train loss 1.51 on epoch=444
06/25/2022 02:09:57 - INFO - __main__ - Step 900 Global step 900 Train loss 1.44 on epoch=449
06/25/2022 02:09:58 - INFO - __main__ - Global step 900 Train loss 1.48 ACC 0.5 on epoch=449
06/25/2022 02:09:59 - INFO - __main__ - Step 910 Global step 910 Train loss 1.31 on epoch=454
06/25/2022 02:10:00 - INFO - __main__ - Step 920 Global step 920 Train loss 1.33 on epoch=459
06/25/2022 02:10:02 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=464
06/25/2022 02:10:03 - INFO - __main__ - Step 940 Global step 940 Train loss 1.33 on epoch=469
06/25/2022 02:10:04 - INFO - __main__ - Step 950 Global step 950 Train loss 1.27 on epoch=474
06/25/2022 02:10:05 - INFO - __main__ - Global step 950 Train loss 1.30 ACC 0.5 on epoch=474
06/25/2022 02:10:06 - INFO - __main__ - Step 960 Global step 960 Train loss 1.14 on epoch=479
06/25/2022 02:10:07 - INFO - __main__ - Step 970 Global step 970 Train loss 1.22 on epoch=484
06/25/2022 02:10:09 - INFO - __main__ - Step 980 Global step 980 Train loss 1.18 on epoch=489
06/25/2022 02:10:10 - INFO - __main__ - Step 990 Global step 990 Train loss 1.10 on epoch=494
06/25/2022 02:10:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.23 on epoch=499
06/25/2022 02:10:12 - INFO - __main__ - Global step 1000 Train loss 1.18 ACC 0.5 on epoch=499
06/25/2022 02:10:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.15 on epoch=504
06/25/2022 02:10:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.10 on epoch=509
06/25/2022 02:10:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.15 on epoch=514
06/25/2022 02:10:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.12 on epoch=519
06/25/2022 02:10:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.15 on epoch=524
06/25/2022 02:10:19 - INFO - __main__ - Global step 1050 Train loss 1.13 ACC 0.5 on epoch=524
06/25/2022 02:10:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=529
06/25/2022 02:10:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.08 on epoch=534
06/25/2022 02:10:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.08 on epoch=539
06/25/2022 02:10:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.99 on epoch=544
06/25/2022 02:10:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.05 on epoch=549
06/25/2022 02:10:25 - INFO - __main__ - Global step 1100 Train loss 1.06 ACC 0.5 on epoch=549
06/25/2022 02:10:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.96 on epoch=554
06/25/2022 02:10:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.97 on epoch=559
06/25/2022 02:10:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.99 on epoch=564
06/25/2022 02:10:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.95 on epoch=569
06/25/2022 02:10:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.00 on epoch=574
06/25/2022 02:10:32 - INFO - __main__ - Global step 1150 Train loss 0.98 ACC 0.5 on epoch=574
06/25/2022 02:10:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.03 on epoch=579
06/25/2022 02:10:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.91 on epoch=584
06/25/2022 02:10:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.97 on epoch=589
06/25/2022 02:10:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.89 on epoch=594
06/25/2022 02:10:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.90 on epoch=599
06/25/2022 02:10:39 - INFO - __main__ - Global step 1200 Train loss 0.94 ACC 0.5 on epoch=599
06/25/2022 02:10:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.86 on epoch=604
06/25/2022 02:10:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.84 on epoch=609
06/25/2022 02:10:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.82 on epoch=614
06/25/2022 02:10:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.84 on epoch=619
06/25/2022 02:10:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.80 on epoch=624
06/25/2022 02:10:46 - INFO - __main__ - Global step 1250 Train loss 0.83 ACC 0.5 on epoch=624
06/25/2022 02:10:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.89 on epoch=629
06/25/2022 02:10:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.76 on epoch=634
06/25/2022 02:10:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.85 on epoch=639
06/25/2022 02:10:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.76 on epoch=644
06/25/2022 02:10:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.69 on epoch=649
06/25/2022 02:10:52 - INFO - __main__ - Global step 1300 Train loss 0.79 ACC 0.5 on epoch=649
06/25/2022 02:10:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.76 on epoch=654
06/25/2022 02:10:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.76 on epoch=659
06/25/2022 02:10:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.75 on epoch=664
06/25/2022 02:10:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.72 on epoch=669
06/25/2022 02:10:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.76 on epoch=674
06/25/2022 02:10:59 - INFO - __main__ - Global step 1350 Train loss 0.75 ACC 0.5 on epoch=674
06/25/2022 02:11:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.78 on epoch=679
06/25/2022 02:11:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.76 on epoch=684
06/25/2022 02:11:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.68 on epoch=689
06/25/2022 02:11:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.67 on epoch=694
06/25/2022 02:11:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.72 on epoch=699
06/25/2022 02:11:06 - INFO - __main__ - Global step 1400 Train loss 0.72 ACC 0.5 on epoch=699
06/25/2022 02:11:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.69 on epoch=704
06/25/2022 02:11:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.63 on epoch=709
06/25/2022 02:11:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.68 on epoch=714
06/25/2022 02:11:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.71 on epoch=719
06/25/2022 02:11:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.68 on epoch=724
06/25/2022 02:11:12 - INFO - __main__ - Global step 1450 Train loss 0.68 ACC 0.5 on epoch=724
06/25/2022 02:11:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.63 on epoch=729
06/25/2022 02:11:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.75 on epoch=734
06/25/2022 02:11:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.71 on epoch=739
06/25/2022 02:11:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.67 on epoch=744
06/25/2022 02:11:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.61 on epoch=749
06/25/2022 02:11:19 - INFO - __main__ - Global step 1500 Train loss 0.67 ACC 0.5 on epoch=749
06/25/2022 02:11:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.69 on epoch=754
06/25/2022 02:11:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.56 on epoch=759
06/25/2022 02:11:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.63 on epoch=764
06/25/2022 02:11:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.63 on epoch=769
06/25/2022 02:11:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.56 on epoch=774
06/25/2022 02:11:25 - INFO - __main__ - Global step 1550 Train loss 0.61 ACC 0.5 on epoch=774
06/25/2022 02:11:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.65 on epoch=779
06/25/2022 02:11:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.58 on epoch=784
06/25/2022 02:11:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.55 on epoch=789
06/25/2022 02:11:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.55 on epoch=794
06/25/2022 02:11:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.61 on epoch=799
06/25/2022 02:11:32 - INFO - __main__ - Global step 1600 Train loss 0.59 ACC 0.5 on epoch=799
06/25/2022 02:11:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.60 on epoch=804
06/25/2022 02:11:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.59 on epoch=809
06/25/2022 02:11:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.61 on epoch=814
06/25/2022 02:11:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.63 on epoch=819
06/25/2022 02:11:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.54 on epoch=824
06/25/2022 02:11:39 - INFO - __main__ - Global step 1650 Train loss 0.59 ACC 0.5 on epoch=824
06/25/2022 02:11:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.61 on epoch=829
06/25/2022 02:11:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.56 on epoch=834
06/25/2022 02:11:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.57 on epoch=839
06/25/2022 02:11:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.53 on epoch=844
06/25/2022 02:11:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.63 on epoch=849
06/25/2022 02:11:45 - INFO - __main__ - Global step 1700 Train loss 0.58 ACC 0.5 on epoch=849
06/25/2022 02:11:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.58 on epoch=854
06/25/2022 02:11:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.52 on epoch=859
06/25/2022 02:11:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.50 on epoch=864
06/25/2022 02:11:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.59 on epoch=869
06/25/2022 02:11:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.64 on epoch=874
06/25/2022 02:11:52 - INFO - __main__ - Global step 1750 Train loss 0.57 ACC 0.5 on epoch=874
06/25/2022 02:11:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.48 on epoch=879
06/25/2022 02:11:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.48 on epoch=884
06/25/2022 02:11:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.52 on epoch=889
06/25/2022 02:11:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.46 on epoch=894
06/25/2022 02:11:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.54 on epoch=899
06/25/2022 02:11:59 - INFO - __main__ - Global step 1800 Train loss 0.50 ACC 0.5 on epoch=899
06/25/2022 02:12:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.51 on epoch=904
06/25/2022 02:12:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.61 on epoch=909
06/25/2022 02:12:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.49 on epoch=914
06/25/2022 02:12:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.50 on epoch=919
06/25/2022 02:12:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.49 on epoch=924
06/25/2022 02:12:06 - INFO - __main__ - Global step 1850 Train loss 0.52 ACC 0.5 on epoch=924
06/25/2022 02:12:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.55 on epoch=929
06/25/2022 02:12:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.48 on epoch=934
06/25/2022 02:12:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.45 on epoch=939
06/25/2022 02:12:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.50 on epoch=944
06/25/2022 02:12:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.52 on epoch=949
06/25/2022 02:12:12 - INFO - __main__ - Global step 1900 Train loss 0.50 ACC 0.5 on epoch=949
06/25/2022 02:12:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.51 on epoch=954
06/25/2022 02:12:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.47 on epoch=959
06/25/2022 02:12:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.48 on epoch=964
06/25/2022 02:12:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.48 on epoch=969
06/25/2022 02:12:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.42 on epoch=974
06/25/2022 02:12:19 - INFO - __main__ - Global step 1950 Train loss 0.47 ACC 0.5 on epoch=974
06/25/2022 02:12:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.54 on epoch=979
06/25/2022 02:12:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.60 on epoch=984
06/25/2022 02:12:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.43 on epoch=989
06/25/2022 02:12:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.54 on epoch=994
06/25/2022 02:12:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.45 on epoch=999
06/25/2022 02:12:25 - INFO - __main__ - Global step 2000 Train loss 0.51 ACC 0.5 on epoch=999
06/25/2022 02:12:25 - INFO - __main__ - save last model!
06/25/2022 02:12:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 02:12:26 - INFO - __main__ - Start tokenizing ... 40430 instances
06/25/2022 02:12:26 - INFO - __main__ - Printing 3 examples
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/25/2022 02:12:26 - INFO - __main__ - ['not_duplicate']
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/25/2022 02:12:26 - INFO - __main__ - ['not_duplicate']
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:12:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 02:12:26 - INFO - __main__ - Printing 3 examples
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:12:26 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:12:26 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 02:12:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 02:12:26 - INFO - __main__ - Printing 3 examples
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 02:12:26 - INFO - __main__ - ['duplicate']
06/25/2022 02:12:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:12:26 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:12:26 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 02:12:32 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:12:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 02:12:32 - INFO - __main__ - Starting training!
06/25/2022 02:12:44 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:13:25 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 02:22:25 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_87_0.3_8_predictions.txt
06/25/2022 02:22:25 - INFO - __main__ - ACC on test data: 0.3682
06/25/2022 02:22:26 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.3, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
06/25/2022 02:22:26 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.2, bsz=8 ...
06/25/2022 02:22:27 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 02:22:27 - INFO - __main__ - Printing 3 examples
06/25/2022 02:22:27 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 02:22:27 - INFO - __main__ - ['duplicate']
06/25/2022 02:22:27 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/25/2022 02:22:27 - INFO - __main__ - ['duplicate']
06/25/2022 02:22:27 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/25/2022 02:22:27 - INFO - __main__ - ['duplicate']
06/25/2022 02:22:27 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:22:27 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:22:27 - INFO - __main__ - Loaded 32 examples from train data
06/25/2022 02:22:27 - INFO - __main__ - Start tokenizing ... 32 instances
06/25/2022 02:22:27 - INFO - __main__ - Printing 3 examples
06/25/2022 02:22:27 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/25/2022 02:22:27 - INFO - __main__ - ['duplicate']
06/25/2022 02:22:27 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/25/2022 02:22:27 - INFO - __main__ - ['duplicate']
06/25/2022 02:22:27 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/25/2022 02:22:27 - INFO - __main__ - ['duplicate']
06/25/2022 02:22:27 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:22:27 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:22:27 - INFO - __main__ - Loaded 32 examples from dev data
06/25/2022 02:22:32 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:22:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/25/2022 02:22:33 - INFO - __main__ - Starting training!
06/25/2022 02:22:34 - INFO - __main__ - Step 10 Global step 10 Train loss 6.55 on epoch=4
06/25/2022 02:22:35 - INFO - __main__ - Step 20 Global step 20 Train loss 6.46 on epoch=9
06/25/2022 02:22:37 - INFO - __main__ - Step 30 Global step 30 Train loss 6.31 on epoch=14
06/25/2022 02:22:38 - INFO - __main__ - Step 40 Global step 40 Train loss 6.10 on epoch=19
06/25/2022 02:22:39 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=24
06/25/2022 02:22:42 - INFO - __main__ - Global step 50 Train loss 6.27 ACC 0.0 on epoch=24
06/25/2022 02:22:42 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/25/2022 02:22:43 - INFO - __main__ - Step 60 Global step 60 Train loss 6.01 on epoch=29
06/25/2022 02:22:45 - INFO - __main__ - Step 70 Global step 70 Train loss 5.89 on epoch=34
06/25/2022 02:22:46 - INFO - __main__ - Step 80 Global step 80 Train loss 5.82 on epoch=39
06/25/2022 02:22:47 - INFO - __main__ - Step 90 Global step 90 Train loss 5.80 on epoch=44
06/25/2022 02:22:48 - INFO - __main__ - Step 100 Global step 100 Train loss 5.61 on epoch=49
06/25/2022 02:22:50 - INFO - __main__ - Global step 100 Train loss 5.83 ACC 0.0 on epoch=49
06/25/2022 02:22:51 - INFO - __main__ - Step 110 Global step 110 Train loss 5.56 on epoch=54
06/25/2022 02:22:52 - INFO - __main__ - Step 120 Global step 120 Train loss 5.45 on epoch=59
06/25/2022 02:22:54 - INFO - __main__ - Step 130 Global step 130 Train loss 5.34 on epoch=64
06/25/2022 02:22:55 - INFO - __main__ - Step 140 Global step 140 Train loss 5.20 on epoch=69
06/25/2022 02:22:56 - INFO - __main__ - Step 150 Global step 150 Train loss 5.09 on epoch=74
06/25/2022 02:22:57 - INFO - __main__ - Global step 150 Train loss 5.33 ACC 0.0 on epoch=74
06/25/2022 02:22:59 - INFO - __main__ - Step 160 Global step 160 Train loss 5.10 on epoch=79
06/25/2022 02:23:00 - INFO - __main__ - Step 170 Global step 170 Train loss 5.05 on epoch=84
06/25/2022 02:23:01 - INFO - __main__ - Step 180 Global step 180 Train loss 4.90 on epoch=89
06/25/2022 02:23:02 - INFO - __main__ - Step 190 Global step 190 Train loss 4.95 on epoch=94
06/25/2022 02:23:04 - INFO - __main__ - Step 200 Global step 200 Train loss 4.88 on epoch=99
06/25/2022 02:23:06 - INFO - __main__ - Global step 200 Train loss 4.98 ACC 0.0 on epoch=99
06/25/2022 02:23:07 - INFO - __main__ - Step 210 Global step 210 Train loss 4.72 on epoch=104
06/25/2022 02:23:09 - INFO - __main__ - Step 220 Global step 220 Train loss 4.78 on epoch=109
06/25/2022 02:23:10 - INFO - __main__ - Step 230 Global step 230 Train loss 4.66 on epoch=114
06/25/2022 02:23:11 - INFO - __main__ - Step 240 Global step 240 Train loss 4.59 on epoch=119
06/25/2022 02:23:12 - INFO - __main__ - Step 250 Global step 250 Train loss 4.60 on epoch=124
06/25/2022 02:23:18 - INFO - __main__ - Global step 250 Train loss 4.67 ACC 0.0 on epoch=124
06/25/2022 02:23:19 - INFO - __main__ - Step 260 Global step 260 Train loss 4.56 on epoch=129
06/25/2022 02:23:21 - INFO - __main__ - Step 270 Global step 270 Train loss 4.41 on epoch=134
06/25/2022 02:23:22 - INFO - __main__ - Step 280 Global step 280 Train loss 4.30 on epoch=139
06/25/2022 02:23:23 - INFO - __main__ - Step 290 Global step 290 Train loss 4.43 on epoch=144
06/25/2022 02:23:24 - INFO - __main__ - Step 300 Global step 300 Train loss 4.39 on epoch=149
06/25/2022 02:23:26 - INFO - __main__ - Global step 300 Train loss 4.42 ACC 0.0 on epoch=149
06/25/2022 02:23:27 - INFO - __main__ - Step 310 Global step 310 Train loss 4.43 on epoch=154
06/25/2022 02:23:28 - INFO - __main__ - Step 320 Global step 320 Train loss 4.30 on epoch=159
06/25/2022 02:23:30 - INFO - __main__ - Step 330 Global step 330 Train loss 4.27 on epoch=164
06/25/2022 02:23:31 - INFO - __main__ - Step 340 Global step 340 Train loss 4.09 on epoch=169
06/25/2022 02:23:32 - INFO - __main__ - Step 350 Global step 350 Train loss 4.09 on epoch=174
06/25/2022 02:23:33 - INFO - __main__ - Global step 350 Train loss 4.24 ACC 0.0 on epoch=174
06/25/2022 02:23:35 - INFO - __main__ - Step 360 Global step 360 Train loss 4.05 on epoch=179
06/25/2022 02:23:36 - INFO - __main__ - Step 370 Global step 370 Train loss 3.96 on epoch=184
06/25/2022 02:23:37 - INFO - __main__ - Step 380 Global step 380 Train loss 3.83 on epoch=189
06/25/2022 02:23:38 - INFO - __main__ - Step 390 Global step 390 Train loss 3.97 on epoch=194
06/25/2022 02:23:39 - INFO - __main__ - Step 400 Global step 400 Train loss 3.90 on epoch=199
06/25/2022 02:23:42 - INFO - __main__ - Global step 400 Train loss 3.94 ACC 0.0 on epoch=199
06/25/2022 02:23:43 - INFO - __main__ - Step 410 Global step 410 Train loss 3.84 on epoch=204
06/25/2022 02:23:44 - INFO - __main__ - Step 420 Global step 420 Train loss 3.71 on epoch=209
06/25/2022 02:23:46 - INFO - __main__ - Step 430 Global step 430 Train loss 3.83 on epoch=214
06/25/2022 02:23:47 - INFO - __main__ - Step 440 Global step 440 Train loss 3.82 on epoch=219
06/25/2022 02:23:48 - INFO - __main__ - Step 450 Global step 450 Train loss 3.67 on epoch=224
06/25/2022 02:23:49 - INFO - __main__ - Global step 450 Train loss 3.77 ACC 0.0 on epoch=224
06/25/2022 02:23:50 - INFO - __main__ - Step 460 Global step 460 Train loss 3.58 on epoch=229
06/25/2022 02:23:52 - INFO - __main__ - Step 470 Global step 470 Train loss 3.56 on epoch=234
06/25/2022 02:23:53 - INFO - __main__ - Step 480 Global step 480 Train loss 3.49 on epoch=239
06/25/2022 02:23:54 - INFO - __main__ - Step 490 Global step 490 Train loss 3.44 on epoch=244
06/25/2022 02:23:55 - INFO - __main__ - Step 500 Global step 500 Train loss 3.31 on epoch=249
06/25/2022 02:23:58 - INFO - __main__ - Global step 500 Train loss 3.48 ACC 0.0 on epoch=249
06/25/2022 02:23:59 - INFO - __main__ - Step 510 Global step 510 Train loss 3.41 on epoch=254
06/25/2022 02:24:00 - INFO - __main__ - Step 520 Global step 520 Train loss 3.37 on epoch=259
06/25/2022 02:24:02 - INFO - __main__ - Step 530 Global step 530 Train loss 3.26 on epoch=264
06/25/2022 02:24:03 - INFO - __main__ - Step 540 Global step 540 Train loss 3.27 on epoch=269
06/25/2022 02:24:04 - INFO - __main__ - Step 550 Global step 550 Train loss 3.14 on epoch=274
06/25/2022 02:24:07 - INFO - __main__ - Global step 550 Train loss 3.29 ACC 0.0 on epoch=274
06/25/2022 02:24:09 - INFO - __main__ - Step 560 Global step 560 Train loss 3.08 on epoch=279
06/25/2022 02:24:10 - INFO - __main__ - Step 570 Global step 570 Train loss 2.97 on epoch=284
06/25/2022 02:24:11 - INFO - __main__ - Step 580 Global step 580 Train loss 3.08 on epoch=289
06/25/2022 02:24:12 - INFO - __main__ - Step 590 Global step 590 Train loss 3.11 on epoch=294
06/25/2022 02:24:14 - INFO - __main__ - Step 600 Global step 600 Train loss 2.87 on epoch=299
06/25/2022 02:24:15 - INFO - __main__ - Global step 600 Train loss 3.02 ACC 0.0 on epoch=299
06/25/2022 02:24:16 - INFO - __main__ - Step 610 Global step 610 Train loss 2.87 on epoch=304
06/25/2022 02:24:18 - INFO - __main__ - Step 620 Global step 620 Train loss 2.91 on epoch=309
06/25/2022 02:24:19 - INFO - __main__ - Step 630 Global step 630 Train loss 2.93 on epoch=314
06/25/2022 02:24:20 - INFO - __main__ - Step 640 Global step 640 Train loss 2.82 on epoch=319
06/25/2022 02:24:21 - INFO - __main__ - Step 650 Global step 650 Train loss 2.90 on epoch=324
06/25/2022 02:24:23 - INFO - __main__ - Global step 650 Train loss 2.89 ACC 0.03125 on epoch=324
06/25/2022 02:24:23 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.03125 on epoch=324, global_step=650
06/25/2022 02:24:25 - INFO - __main__ - Step 660 Global step 660 Train loss 2.75 on epoch=329
06/25/2022 02:24:26 - INFO - __main__ - Step 670 Global step 670 Train loss 2.80 on epoch=334
06/25/2022 02:24:27 - INFO - __main__ - Step 680 Global step 680 Train loss 2.66 on epoch=339
06/25/2022 02:24:28 - INFO - __main__ - Step 690 Global step 690 Train loss 2.70 on epoch=344
06/25/2022 02:24:30 - INFO - __main__ - Step 700 Global step 700 Train loss 2.60 on epoch=349
06/25/2022 02:24:31 - INFO - __main__ - Global step 700 Train loss 2.70 ACC 0.03125 on epoch=349
06/25/2022 02:24:32 - INFO - __main__ - Step 710 Global step 710 Train loss 2.55 on epoch=354
06/25/2022 02:24:34 - INFO - __main__ - Step 720 Global step 720 Train loss 2.69 on epoch=359
06/25/2022 02:24:35 - INFO - __main__ - Step 730 Global step 730 Train loss 2.59 on epoch=364
06/25/2022 02:24:36 - INFO - __main__ - Step 740 Global step 740 Train loss 2.55 on epoch=369
06/25/2022 02:24:37 - INFO - __main__ - Step 750 Global step 750 Train loss 2.56 on epoch=374
06/25/2022 02:24:39 - INFO - __main__ - Global step 750 Train loss 2.59 ACC 0.0 on epoch=374
06/25/2022 02:24:40 - INFO - __main__ - Step 760 Global step 760 Train loss 2.51 on epoch=379
06/25/2022 02:24:41 - INFO - __main__ - Step 770 Global step 770 Train loss 2.45 on epoch=384
06/25/2022 02:24:43 - INFO - __main__ - Step 780 Global step 780 Train loss 2.40 on epoch=389
06/25/2022 02:24:44 - INFO - __main__ - Step 790 Global step 790 Train loss 2.38 on epoch=394
06/25/2022 02:24:45 - INFO - __main__ - Step 800 Global step 800 Train loss 2.24 on epoch=399
06/25/2022 02:24:51 - INFO - __main__ - Global step 800 Train loss 2.39 ACC 0.0625 on epoch=399
06/25/2022 02:24:51 - INFO - __main__ - Saving model with best ACC: 0.03125 -> 0.0625 on epoch=399, global_step=800
06/25/2022 02:24:52 - INFO - __main__ - Step 810 Global step 810 Train loss 2.36 on epoch=404
06/25/2022 02:24:54 - INFO - __main__ - Step 820 Global step 820 Train loss 2.28 on epoch=409
06/25/2022 02:24:55 - INFO - __main__ - Step 830 Global step 830 Train loss 2.30 on epoch=414
06/25/2022 02:24:56 - INFO - __main__ - Step 840 Global step 840 Train loss 2.31 on epoch=419
06/25/2022 02:24:57 - INFO - __main__ - Step 850 Global step 850 Train loss 2.22 on epoch=424
06/25/2022 02:25:03 - INFO - __main__ - Global step 850 Train loss 2.29 ACC 0.03125 on epoch=424
06/25/2022 02:25:04 - INFO - __main__ - Step 860 Global step 860 Train loss 2.14 on epoch=429
06/25/2022 02:25:05 - INFO - __main__ - Step 870 Global step 870 Train loss 2.18 on epoch=434
06/25/2022 02:25:07 - INFO - __main__ - Step 880 Global step 880 Train loss 2.17 on epoch=439
06/25/2022 02:25:08 - INFO - __main__ - Step 890 Global step 890 Train loss 2.09 on epoch=444
06/25/2022 02:25:09 - INFO - __main__ - Step 900 Global step 900 Train loss 2.14 on epoch=449
06/25/2022 02:25:10 - INFO - __main__ - Global step 900 Train loss 2.14 ACC 0.09375 on epoch=449
06/25/2022 02:25:10 - INFO - __main__ - Saving model with best ACC: 0.0625 -> 0.09375 on epoch=449, global_step=900
06/25/2022 02:25:12 - INFO - __main__ - Step 910 Global step 910 Train loss 2.07 on epoch=454
06/25/2022 02:25:13 - INFO - __main__ - Step 920 Global step 920 Train loss 2.05 on epoch=459
06/25/2022 02:25:14 - INFO - __main__ - Step 930 Global step 930 Train loss 2.13 on epoch=464
06/25/2022 02:25:15 - INFO - __main__ - Step 940 Global step 940 Train loss 1.97 on epoch=469
06/25/2022 02:25:16 - INFO - __main__ - Step 950 Global step 950 Train loss 2.11 on epoch=474
06/25/2022 02:25:22 - INFO - __main__ - Global step 950 Train loss 2.06 ACC 0.375 on epoch=474
06/25/2022 02:25:22 - INFO - __main__ - Saving model with best ACC: 0.09375 -> 0.375 on epoch=474, global_step=950
06/25/2022 02:25:23 - INFO - __main__ - Step 960 Global step 960 Train loss 1.98 on epoch=479
06/25/2022 02:25:24 - INFO - __main__ - Step 970 Global step 970 Train loss 1.96 on epoch=484
06/25/2022 02:25:26 - INFO - __main__ - Step 980 Global step 980 Train loss 1.86 on epoch=489
06/25/2022 02:25:27 - INFO - __main__ - Step 990 Global step 990 Train loss 1.87 on epoch=494
06/25/2022 02:25:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.88 on epoch=499
06/25/2022 02:25:30 - INFO - __main__ - Global step 1000 Train loss 1.91 ACC 0.28125 on epoch=499
06/25/2022 02:25:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.85 on epoch=504
06/25/2022 02:25:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.90 on epoch=509
06/25/2022 02:25:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.01 on epoch=514
06/25/2022 02:25:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.88 on epoch=519
06/25/2022 02:25:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.88 on epoch=524
06/25/2022 02:25:42 - INFO - __main__ - Global step 1050 Train loss 1.90 ACC 0.34375 on epoch=524
06/25/2022 02:25:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.98 on epoch=529
06/25/2022 02:25:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.76 on epoch=534
06/25/2022 02:25:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.81 on epoch=539
06/25/2022 02:25:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.70 on epoch=544
06/25/2022 02:25:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.76 on epoch=549
06/25/2022 02:25:51 - INFO - __main__ - Global step 1100 Train loss 1.80 ACC 0.4375 on epoch=549
06/25/2022 02:25:51 - INFO - __main__ - Saving model with best ACC: 0.375 -> 0.4375 on epoch=549, global_step=1100
06/25/2022 02:25:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.72 on epoch=554
06/25/2022 02:25:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.69 on epoch=559
06/25/2022 02:25:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.75 on epoch=564
06/25/2022 02:25:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.71 on epoch=569
06/25/2022 02:25:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.73 on epoch=574
06/25/2022 02:25:59 - INFO - __main__ - Global step 1150 Train loss 1.72 ACC 0.4375 on epoch=574
06/25/2022 02:26:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.74 on epoch=579
06/25/2022 02:26:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.62 on epoch=584
06/25/2022 02:26:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.62 on epoch=589
06/25/2022 02:26:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.69 on epoch=594
06/25/2022 02:26:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.42 on epoch=599
06/25/2022 02:26:07 - INFO - __main__ - Global step 1200 Train loss 1.62 ACC 0.46875 on epoch=599
06/25/2022 02:26:07 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=599, global_step=1200
06/25/2022 02:26:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.56 on epoch=604
06/25/2022 02:26:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.68 on epoch=609
06/25/2022 02:26:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.54 on epoch=614
06/25/2022 02:26:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.57 on epoch=619
06/25/2022 02:26:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.49 on epoch=624
06/25/2022 02:26:16 - INFO - __main__ - Global step 1250 Train loss 1.57 ACC 0.46875 on epoch=624
06/25/2022 02:26:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.50 on epoch=629
06/25/2022 02:26:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.43 on epoch=634
06/25/2022 02:26:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.46 on epoch=639
06/25/2022 02:26:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.44 on epoch=644
06/25/2022 02:26:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.34 on epoch=649
06/25/2022 02:26:27 - INFO - __main__ - Global step 1300 Train loss 1.43 ACC 0.5 on epoch=649
06/25/2022 02:26:27 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=649, global_step=1300
06/25/2022 02:26:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.39 on epoch=654
06/25/2022 02:26:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.33 on epoch=659
06/25/2022 02:26:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.35 on epoch=664
06/25/2022 02:26:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.33 on epoch=669
06/25/2022 02:26:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.23 on epoch=674
06/25/2022 02:26:34 - INFO - __main__ - Global step 1350 Train loss 1.33 ACC 0.5 on epoch=674
06/25/2022 02:26:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.35 on epoch=679
06/25/2022 02:26:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.25 on epoch=684
06/25/2022 02:26:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.28 on epoch=689
06/25/2022 02:26:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.27 on epoch=694
06/25/2022 02:26:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.19 on epoch=699
06/25/2022 02:26:42 - INFO - __main__ - Global step 1400 Train loss 1.27 ACC 0.5 on epoch=699
06/25/2022 02:26:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.20 on epoch=704
06/25/2022 02:26:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.15 on epoch=709
06/25/2022 02:26:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.27 on epoch=714
06/25/2022 02:26:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=719
06/25/2022 02:26:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.24 on epoch=724
06/25/2022 02:26:49 - INFO - __main__ - Global step 1450 Train loss 1.20 ACC 0.5 on epoch=724
06/25/2022 02:26:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.09 on epoch=729
06/25/2022 02:26:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=734
06/25/2022 02:26:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=739
06/25/2022 02:26:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.06 on epoch=744
06/25/2022 02:26:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.17 on epoch=749
06/25/2022 02:26:56 - INFO - __main__ - Global step 1500 Train loss 1.11 ACC 0.5 on epoch=749
06/25/2022 02:26:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=754
06/25/2022 02:26:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=759
06/25/2022 02:26:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.03 on epoch=764
06/25/2022 02:27:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=769
06/25/2022 02:27:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.11 on epoch=774
06/25/2022 02:27:02 - INFO - __main__ - Global step 1550 Train loss 1.04 ACC 0.5 on epoch=774
06/25/2022 02:27:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.95 on epoch=779
06/25/2022 02:27:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.06 on epoch=784
06/25/2022 02:27:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.03 on epoch=789
06/25/2022 02:27:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.89 on epoch=794
06/25/2022 02:27:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.92 on epoch=799
06/25/2022 02:27:09 - INFO - __main__ - Global step 1600 Train loss 0.97 ACC 0.5 on epoch=799
06/25/2022 02:27:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.88 on epoch=804
06/25/2022 02:27:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.90 on epoch=809
06/25/2022 02:27:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.86 on epoch=814
06/25/2022 02:27:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.04 on epoch=819
06/25/2022 02:27:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.95 on epoch=824
06/25/2022 02:27:16 - INFO - __main__ - Global step 1650 Train loss 0.93 ACC 0.5 on epoch=824
06/25/2022 02:27:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.84 on epoch=829
06/25/2022 02:27:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.89 on epoch=834
06/25/2022 02:27:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=839
06/25/2022 02:27:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.86 on epoch=844
06/25/2022 02:27:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.91 on epoch=849
06/25/2022 02:27:23 - INFO - __main__ - Global step 1700 Train loss 0.89 ACC 0.5 on epoch=849
06/25/2022 02:27:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.85 on epoch=854
06/25/2022 02:27:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.78 on epoch=859
06/25/2022 02:27:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.89 on epoch=864
06/25/2022 02:27:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.82 on epoch=869
06/25/2022 02:27:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.85 on epoch=874
06/25/2022 02:27:30 - INFO - __main__ - Global step 1750 Train loss 0.84 ACC 0.5 on epoch=874
06/25/2022 02:27:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.84 on epoch=879
06/25/2022 02:27:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.77 on epoch=884
06/25/2022 02:27:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.78 on epoch=889
06/25/2022 02:27:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.74 on epoch=894
06/25/2022 02:27:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.80 on epoch=899
06/25/2022 02:27:37 - INFO - __main__ - Global step 1800 Train loss 0.79 ACC 0.5 on epoch=899
06/25/2022 02:27:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.80 on epoch=904
06/25/2022 02:27:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.85 on epoch=909
06/25/2022 02:27:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.81 on epoch=914
06/25/2022 02:27:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.75 on epoch=919
06/25/2022 02:27:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.71 on epoch=924
06/25/2022 02:27:44 - INFO - __main__ - Global step 1850 Train loss 0.78 ACC 0.5 on epoch=924
06/25/2022 02:27:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.76 on epoch=929
06/25/2022 02:27:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.77 on epoch=934
06/25/2022 02:27:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.71 on epoch=939
06/25/2022 02:27:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.89 on epoch=944
06/25/2022 02:27:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.71 on epoch=949
06/25/2022 02:27:51 - INFO - __main__ - Global step 1900 Train loss 0.77 ACC 0.5 on epoch=949
06/25/2022 02:27:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.64 on epoch=954
06/25/2022 02:27:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.71 on epoch=959
06/25/2022 02:27:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.75 on epoch=964
06/25/2022 02:27:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.73 on epoch=969
06/25/2022 02:27:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.74 on epoch=974
06/25/2022 02:27:58 - INFO - __main__ - Global step 1950 Train loss 0.72 ACC 0.5 on epoch=974
06/25/2022 02:27:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.75 on epoch=979
06/25/2022 02:28:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.66 on epoch=984
06/25/2022 02:28:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.74 on epoch=989
06/25/2022 02:28:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.66 on epoch=994
06/25/2022 02:28:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.68 on epoch=999
06/25/2022 02:28:05 - INFO - __main__ - Global step 2000 Train loss 0.70 ACC 0.5 on epoch=999
06/25/2022 02:28:05 - INFO - __main__ - save last model!
06/25/2022 02:28:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 02:28:05 - INFO - __main__ - Start tokenizing ... 40430 instances
06/25/2022 02:28:05 - INFO - __main__ - Printing 3 examples
06/25/2022 02:28:05 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/25/2022 02:28:05 - INFO - __main__ - ['not_duplicate']
06/25/2022 02:28:05 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/25/2022 02:28:05 - INFO - __main__ - ['not_duplicate']
06/25/2022 02:28:05 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/25/2022 02:28:05 - INFO - __main__ - ['duplicate']
06/25/2022 02:28:05 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:28:23 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:29:04 - INFO - __main__ - Loaded 40430 examples from test data
06/25/2022 02:42:15 - INFO - __main__ - Saved prediction in models/T5-base-maml-nopara2para-3e-5-2-5000-5e-1/singletask-glue-qqp/glue-qqp_16_87_0.2_8_predictions.txt
06/25/2022 02:42:15 - INFO - __main__ - ACC on test data: 0.3682
06/25/2022 02:42:15 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.2, bsz=8, dev_performance=0.5, test_performance=0.36816720257234725
