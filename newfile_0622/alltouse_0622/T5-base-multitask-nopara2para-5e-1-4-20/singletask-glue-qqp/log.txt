05/15/2022 19:00:15 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-multitask-nopara2para-5e-1-4-20', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/glue-qqp/', task_name='glue-qqp', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
05/15/2022 19:00:15 - INFO - __main__ - models/T5-large-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp
06/22/2022 05:39:25 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-multitask-nopara2para-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-nopara2para-5e-1-4-20-t5base/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
06/22/2022 05:39:25 - INFO - __main__ - models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp
06/22/2022 05:39:25 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-multitask-nopara2para-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-nopara2para-5e-1-4-20-t5base/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
06/22/2022 05:39:25 - INFO - __main__ - models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp
06/22/2022 05:39:27 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/22/2022 05:39:27 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/22/2022 05:39:27 - INFO - __main__ - args.device: cuda:1
06/22/2022 05:39:27 - INFO - __main__ - args.device: cuda:0
06/22/2022 05:39:27 - INFO - __main__ - Using 2 gpus
06/22/2022 05:39:27 - INFO - __main__ - Using 2 gpus
06/22/2022 05:39:27 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/22/2022 05:39:27 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/22/2022 05:39:31 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.5, bsz=8 ...
06/22/2022 05:39:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:39:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:39:32 - INFO - __main__ - Printing 3 examples
06/22/2022 05:39:32 - INFO - __main__ - Printing 3 examples
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:39:32 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 05:39:32 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 05:39:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:39:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:39:32 - INFO - __main__ - Printing 3 examples
06/22/2022 05:39:32 - INFO - __main__ - Printing 3 examples
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 05:39:32 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:39:32 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:39:32 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 05:39:32 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 05:39:38 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 05:39:38 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 05:39:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 05:39:39 - INFO - __main__ - Starting training!
06/22/2022 05:39:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 05:39:44 - INFO - __main__ - Starting training!
06/22/2022 05:39:46 - INFO - __main__ - Step 10 Global step 10 Train loss 5.50 on epoch=4
06/22/2022 05:39:47 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=9
06/22/2022 05:39:48 - INFO - __main__ - Step 30 Global step 30 Train loss 2.33 on epoch=14
06/22/2022 05:39:49 - INFO - __main__ - Step 40 Global step 40 Train loss 1.46 on epoch=19
06/22/2022 05:39:50 - INFO - __main__ - Step 50 Global step 50 Train loss 0.83 on epoch=24
06/22/2022 05:39:51 - INFO - __main__ - Global step 50 Train loss 2.70 ACC 0.5 on epoch=24
06/22/2022 05:39:51 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 05:39:52 - INFO - __main__ - Step 60 Global step 60 Train loss 0.62 on epoch=29
06/22/2022 05:39:53 - INFO - __main__ - Step 70 Global step 70 Train loss 0.45 on epoch=34
06/22/2022 05:39:55 - INFO - __main__ - Step 80 Global step 80 Train loss 0.49 on epoch=39
06/22/2022 05:39:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.41 on epoch=44
06/22/2022 05:39:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.35 on epoch=49
06/22/2022 05:39:58 - INFO - __main__ - Global step 100 Train loss 0.47 ACC 0.5 on epoch=49
06/22/2022 05:39:59 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
06/22/2022 05:40:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.34 on epoch=59
06/22/2022 05:40:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=64
06/22/2022 05:40:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.29 on epoch=69
06/22/2022 05:40:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.32 on epoch=74
06/22/2022 05:40:04 - INFO - __main__ - Global step 150 Train loss 0.33 ACC 0.5 on epoch=74
06/22/2022 05:40:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.34 on epoch=79
06/22/2022 05:40:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=84
06/22/2022 05:40:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=89
06/22/2022 05:40:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=94
06/22/2022 05:40:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=99
06/22/2022 05:40:11 - INFO - __main__ - Global step 200 Train loss 0.28 ACC 0.5 on epoch=99
06/22/2022 05:40:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=104
06/22/2022 05:40:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=109
06/22/2022 05:40:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=114
06/22/2022 05:40:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=119
06/22/2022 05:40:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=124
06/22/2022 05:40:17 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.5 on epoch=124
06/22/2022 05:40:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=129
06/22/2022 05:40:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=134
06/22/2022 05:40:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=139
06/22/2022 05:40:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/22/2022 05:40:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/22/2022 05:40:24 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5 on epoch=149
06/22/2022 05:40:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/22/2022 05:40:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
06/22/2022 05:40:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=164
06/22/2022 05:40:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/22/2022 05:40:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/22/2022 05:40:31 - INFO - __main__ - Global step 350 Train loss 0.23 ACC 0.5 on epoch=174
06/22/2022 05:40:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=179
06/22/2022 05:40:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=184
06/22/2022 05:40:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=189
06/22/2022 05:40:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=194
06/22/2022 05:40:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/22/2022 05:40:37 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.5 on epoch=199
06/22/2022 05:40:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=204
06/22/2022 05:40:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=209
06/22/2022 05:40:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
06/22/2022 05:40:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=219
06/22/2022 05:40:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=224
06/22/2022 05:40:44 - INFO - __main__ - Global step 450 Train loss 0.22 ACC 0.59375 on epoch=224
06/22/2022 05:40:44 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=224, global_step=450
06/22/2022 05:40:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/22/2022 05:40:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=234
06/22/2022 05:40:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=239
06/22/2022 05:40:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=244
06/22/2022 05:40:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=249
06/22/2022 05:40:51 - INFO - __main__ - Global step 500 Train loss 0.21 ACC 0.5625 on epoch=249
06/22/2022 05:40:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=254
06/22/2022 05:40:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=259
06/22/2022 05:40:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/22/2022 05:40:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=269
06/22/2022 05:40:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=274
06/22/2022 05:40:57 - INFO - __main__ - Global step 550 Train loss 0.18 ACC 0.6875 on epoch=274
06/22/2022 05:40:57 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.6875 on epoch=274, global_step=550
06/22/2022 05:40:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=279
06/22/2022 05:41:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=284
06/22/2022 05:41:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=289
06/22/2022 05:41:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=294
06/22/2022 05:41:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=299
06/22/2022 05:41:04 - INFO - __main__ - Global step 600 Train loss 0.17 ACC 0.59375 on epoch=299
06/22/2022 05:41:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=304
06/22/2022 05:41:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=309
06/22/2022 05:41:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=314
06/22/2022 05:41:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=319
06/22/2022 05:41:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=324
06/22/2022 05:41:10 - INFO - __main__ - Global step 650 Train loss 0.15 ACC 0.65625 on epoch=324
06/22/2022 05:41:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=329
06/22/2022 05:41:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=334
06/22/2022 05:41:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=339
06/22/2022 05:41:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=344
06/22/2022 05:41:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=349
06/22/2022 05:41:17 - INFO - __main__ - Global step 700 Train loss 0.13 ACC 0.59375 on epoch=349
06/22/2022 05:41:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=354
06/22/2022 05:41:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/22/2022 05:41:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=364
06/22/2022 05:41:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=369
06/22/2022 05:41:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=374
06/22/2022 05:41:24 - INFO - __main__ - Global step 750 Train loss 0.10 ACC 0.6875 on epoch=374
06/22/2022 05:41:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=379
06/22/2022 05:41:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=384
06/22/2022 05:41:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=389
06/22/2022 05:41:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=394
06/22/2022 05:41:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=399
06/22/2022 05:41:30 - INFO - __main__ - Global step 800 Train loss 0.09 ACC 0.71875 on epoch=399
06/22/2022 05:41:30 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=399, global_step=800
06/22/2022 05:41:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=404
06/22/2022 05:41:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=409
06/22/2022 05:41:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=414
06/22/2022 05:41:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/22/2022 05:41:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
06/22/2022 05:41:37 - INFO - __main__ - Global step 850 Train loss 0.06 ACC 0.625 on epoch=424
06/22/2022 05:41:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
06/22/2022 05:41:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=434
06/22/2022 05:41:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
06/22/2022 05:41:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
06/22/2022 05:41:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/22/2022 05:41:44 - INFO - __main__ - Global step 900 Train loss 0.04 ACC 0.625 on epoch=449
06/22/2022 05:41:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/22/2022 05:41:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=459
06/22/2022 05:41:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=464
06/22/2022 05:41:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/22/2022 05:41:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=474
06/22/2022 05:41:50 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.59375 on epoch=474
06/22/2022 05:41:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/22/2022 05:41:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
06/22/2022 05:41:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/22/2022 05:41:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/22/2022 05:41:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/22/2022 05:41:57 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.59375 on epoch=499
06/22/2022 05:41:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/22/2022 05:41:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/22/2022 05:42:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 05:42:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
06/22/2022 05:42:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
06/22/2022 05:42:03 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.59375 on epoch=524
06/22/2022 05:42:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/22/2022 05:42:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 05:42:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/22/2022 05:42:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/22/2022 05:42:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/22/2022 05:42:10 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.625 on epoch=549
06/22/2022 05:42:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
06/22/2022 05:42:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/22/2022 05:42:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 05:42:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/22/2022 05:42:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/22/2022 05:42:17 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.625 on epoch=574
06/22/2022 05:42:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
06/22/2022 05:42:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/22/2022 05:42:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
06/22/2022 05:42:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=594
06/22/2022 05:42:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
06/22/2022 05:42:23 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.65625 on epoch=599
06/22/2022 05:42:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/22/2022 05:42:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
06/22/2022 05:42:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 05:42:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 05:42:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/22/2022 05:42:30 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.625 on epoch=624
06/22/2022 05:42:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/22/2022 05:42:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/22/2022 05:42:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
06/22/2022 05:42:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/22/2022 05:42:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 05:42:36 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.6875 on epoch=649
06/22/2022 05:42:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/22/2022 05:42:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/22/2022 05:42:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/22/2022 05:42:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/22/2022 05:42:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/22/2022 05:42:43 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.625 on epoch=674
06/22/2022 05:42:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 05:42:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 05:42:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/22/2022 05:42:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 05:42:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 05:42:50 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.625 on epoch=699
06/22/2022 05:42:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/22/2022 05:42:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/22/2022 05:42:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 05:42:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/22/2022 05:42:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 05:42:56 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.6875 on epoch=724
06/22/2022 05:42:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 05:42:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 05:43:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/22/2022 05:43:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/22/2022 05:43:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/22/2022 05:43:03 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
06/22/2022 05:43:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 05:43:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/22/2022 05:43:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/22/2022 05:43:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/22/2022 05:43:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 05:43:10 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
06/22/2022 05:43:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/22/2022 05:43:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 05:43:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 05:43:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 05:43:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/22/2022 05:43:16 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.59375 on epoch=799
06/22/2022 05:43:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 05:43:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/22/2022 05:43:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
06/22/2022 05:43:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 05:43:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/22/2022 05:43:23 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.65625 on epoch=824
06/22/2022 05:43:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/22/2022 05:43:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 05:43:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/22/2022 05:43:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/22/2022 05:43:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 05:43:30 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.625 on epoch=849
06/22/2022 05:43:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 05:43:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 05:43:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 05:43:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 05:43:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/22/2022 05:43:36 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.53125 on epoch=874
06/22/2022 05:43:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 05:43:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 05:43:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 05:43:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 05:43:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 05:43:43 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5625 on epoch=899
06/22/2022 05:43:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 05:43:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 05:43:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/22/2022 05:43:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 05:43:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 05:43:49 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.625 on epoch=924
06/22/2022 05:43:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/22/2022 05:43:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 05:43:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 05:43:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 05:43:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 05:43:56 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.6875 on epoch=949
06/22/2022 05:43:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 05:43:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 05:44:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=964
06/22/2022 05:44:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 05:44:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
06/22/2022 05:44:03 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.65625 on epoch=974
06/22/2022 05:44:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
06/22/2022 05:44:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=984
06/22/2022 05:44:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/22/2022 05:44:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 05:44:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 05:44:09 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.65625 on epoch=999
06/22/2022 05:44:09 - INFO - __main__ - save last model!
06/22/2022 05:44:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 05:44:09 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 05:44:09 - INFO - __main__ - Printing 3 examples
06/22/2022 05:44:09 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 05:44:09 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:09 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 05:44:09 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:09 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 05:44:09 - INFO - __main__ - ['duplicate']
06/22/2022 05:44:10 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:44:10 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:44:10 - INFO - __main__ - Printing 3 examples
06/22/2022 05:44:10 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 05:44:10 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:10 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 05:44:10 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:10 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 05:44:10 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:10 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:44:10 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:44:10 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 05:44:10 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:44:10 - INFO - __main__ - Printing 3 examples
06/22/2022 05:44:10 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 05:44:10 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:10 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 05:44:10 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:10 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 05:44:10 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:44:10 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:44:10 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:44:10 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 05:44:16 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 05:44:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 05:44:16 - INFO - __main__ - Starting training!
06/22/2022 05:44:27 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:45:08 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 05:57:54 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.5_8_predictions.txt
06/22/2022 05:57:54 - INFO - __main__ - ACC on test data: 0.5326
06/22/2022 05:57:54 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.5, bsz=8, dev_performance=0.71875, test_performance=0.5326242888943854
06/22/2022 05:57:54 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.4, bsz=8 ...
06/22/2022 05:57:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:57:55 - INFO - __main__ - Printing 3 examples
06/22/2022 05:57:55 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 05:57:55 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:57:55 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 05:57:55 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:57:55 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 05:57:55 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:57:55 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:57:55 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:57:55 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 05:57:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 05:57:55 - INFO - __main__ - Printing 3 examples
06/22/2022 05:57:55 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 05:57:55 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:57:55 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 05:57:55 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:57:55 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 05:57:55 - INFO - __main__ - ['not_duplicate']
06/22/2022 05:57:55 - INFO - __main__ - Tokenizing Input ...
06/22/2022 05:57:55 - INFO - __main__ - Tokenizing Output ...
06/22/2022 05:57:55 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 05:58:01 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 05:58:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 05:58:01 - INFO - __main__ - Starting training!
06/22/2022 05:58:03 - INFO - __main__ - Step 10 Global step 10 Train loss 5.87 on epoch=4
06/22/2022 05:58:04 - INFO - __main__ - Step 20 Global step 20 Train loss 3.93 on epoch=9
06/22/2022 05:58:05 - INFO - __main__ - Step 30 Global step 30 Train loss 2.99 on epoch=14
06/22/2022 05:58:06 - INFO - __main__ - Step 40 Global step 40 Train loss 2.09 on epoch=19
06/22/2022 05:58:07 - INFO - __main__ - Step 50 Global step 50 Train loss 1.43 on epoch=24
06/22/2022 05:58:08 - INFO - __main__ - Global step 50 Train loss 3.26 ACC 0.5 on epoch=24
06/22/2022 05:58:08 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 05:58:09 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=29
06/22/2022 05:58:10 - INFO - __main__ - Step 70 Global step 70 Train loss 0.64 on epoch=34
06/22/2022 05:58:12 - INFO - __main__ - Step 80 Global step 80 Train loss 0.63 on epoch=39
06/22/2022 05:58:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.52 on epoch=44
06/22/2022 05:58:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.47 on epoch=49
06/22/2022 05:58:15 - INFO - __main__ - Global step 100 Train loss 0.65 ACC 0.5 on epoch=49
06/22/2022 05:58:16 - INFO - __main__ - Step 110 Global step 110 Train loss 0.40 on epoch=54
06/22/2022 05:58:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
06/22/2022 05:58:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/22/2022 05:58:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.30 on epoch=69
06/22/2022 05:58:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.30 on epoch=74
06/22/2022 05:58:21 - INFO - __main__ - Global step 150 Train loss 0.34 ACC 0.5 on epoch=74
06/22/2022 05:58:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
06/22/2022 05:58:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.35 on epoch=84
06/22/2022 05:58:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.31 on epoch=89
06/22/2022 05:58:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.33 on epoch=94
06/22/2022 05:58:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=99
06/22/2022 05:58:28 - INFO - __main__ - Global step 200 Train loss 0.32 ACC 0.5 on epoch=99
06/22/2022 05:58:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.34 on epoch=104
06/22/2022 05:58:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
06/22/2022 05:58:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/22/2022 05:58:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=119
06/22/2022 05:58:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=124
06/22/2022 05:58:34 - INFO - __main__ - Global step 250 Train loss 0.29 ACC 0.5 on epoch=124
06/22/2022 05:58:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/22/2022 05:58:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=134
06/22/2022 05:58:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=139
06/22/2022 05:58:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/22/2022 05:58:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=149
06/22/2022 05:58:41 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.5 on epoch=149
06/22/2022 05:58:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=154
06/22/2022 05:58:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/22/2022 05:58:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=164
06/22/2022 05:58:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/22/2022 05:58:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=174
06/22/2022 05:58:48 - INFO - __main__ - Global step 350 Train loss 0.27 ACC 0.5 on epoch=174
06/22/2022 05:58:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=179
06/22/2022 05:58:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=184
06/22/2022 05:58:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=189
06/22/2022 05:58:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=194
06/22/2022 05:58:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=199
06/22/2022 05:58:54 - INFO - __main__ - Global step 400 Train loss 0.25 ACC 0.5 on epoch=199
06/22/2022 05:58:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/22/2022 05:58:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=209
06/22/2022 05:58:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=214
06/22/2022 05:58:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/22/2022 05:59:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=224
06/22/2022 05:59:01 - INFO - __main__ - Global step 450 Train loss 0.23 ACC 0.5 on epoch=224
06/22/2022 05:59:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/22/2022 05:59:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=234
06/22/2022 05:59:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=239
06/22/2022 05:59:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=244
06/22/2022 05:59:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=249
06/22/2022 05:59:07 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/22/2022 05:59:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=254
06/22/2022 05:59:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=259
06/22/2022 05:59:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=264
06/22/2022 05:59:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=269
06/22/2022 05:59:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=274
06/22/2022 05:59:14 - INFO - __main__ - Global step 550 Train loss 0.20 ACC 0.46875 on epoch=274
06/22/2022 05:59:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=279
06/22/2022 05:59:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=284
06/22/2022 05:59:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=289
06/22/2022 05:59:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=294
06/22/2022 05:59:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=299
06/22/2022 05:59:21 - INFO - __main__ - Global step 600 Train loss 0.21 ACC 0.46875 on epoch=299
06/22/2022 05:59:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=304
06/22/2022 05:59:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/22/2022 05:59:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=314
06/22/2022 05:59:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=319
06/22/2022 05:59:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=324
06/22/2022 05:59:27 - INFO - __main__ - Global step 650 Train loss 0.18 ACC 0.53125 on epoch=324
06/22/2022 05:59:27 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=324, global_step=650
06/22/2022 05:59:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=329
06/22/2022 05:59:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=334
06/22/2022 05:59:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=339
06/22/2022 05:59:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=344
06/22/2022 05:59:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=349
06/22/2022 05:59:34 - INFO - __main__ - Global step 700 Train loss 0.16 ACC 0.5 on epoch=349
06/22/2022 05:59:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=354
06/22/2022 05:59:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=359
06/22/2022 05:59:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=364
06/22/2022 05:59:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=369
06/22/2022 05:59:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=374
06/22/2022 05:59:41 - INFO - __main__ - Global step 750 Train loss 0.13 ACC 0.625 on epoch=374
06/22/2022 05:59:41 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=374, global_step=750
06/22/2022 05:59:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=379
06/22/2022 05:59:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=384
06/22/2022 05:59:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=389
06/22/2022 05:59:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=394
06/22/2022 05:59:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=399
06/22/2022 05:59:47 - INFO - __main__ - Global step 800 Train loss 0.09 ACC 0.65625 on epoch=399
06/22/2022 05:59:47 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=399, global_step=800
06/22/2022 05:59:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=404
06/22/2022 05:59:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=409
06/22/2022 05:59:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=414
06/22/2022 05:59:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=419
06/22/2022 05:59:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=424
06/22/2022 05:59:54 - INFO - __main__ - Global step 850 Train loss 0.07 ACC 0.625 on epoch=424
06/22/2022 05:59:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=429
06/22/2022 05:59:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
06/22/2022 05:59:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=439
06/22/2022 05:59:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=444
06/22/2022 06:00:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
06/22/2022 06:00:01 - INFO - __main__ - Global step 900 Train loss 0.06 ACC 0.53125 on epoch=449
06/22/2022 06:00:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=454
06/22/2022 06:00:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
06/22/2022 06:00:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=464
06/22/2022 06:00:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
06/22/2022 06:00:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
06/22/2022 06:00:07 - INFO - __main__ - Global step 950 Train loss 0.05 ACC 0.53125 on epoch=474
06/22/2022 06:00:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
06/22/2022 06:00:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
06/22/2022 06:00:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=489
06/22/2022 06:00:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/22/2022 06:00:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=499
06/22/2022 06:00:14 - INFO - __main__ - Global step 1000 Train loss 0.03 ACC 0.53125 on epoch=499
06/22/2022 06:00:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/22/2022 06:00:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/22/2022 06:00:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=514
06/22/2022 06:00:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/22/2022 06:00:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/22/2022 06:00:21 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.5625 on epoch=524
06/22/2022 06:00:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/22/2022 06:00:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
06/22/2022 06:00:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/22/2022 06:00:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
06/22/2022 06:00:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/22/2022 06:00:27 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5625 on epoch=549
06/22/2022 06:00:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
06/22/2022 06:00:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
06/22/2022 06:00:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
06/22/2022 06:00:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/22/2022 06:00:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/22/2022 06:00:34 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.59375 on epoch=574
06/22/2022 06:00:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/22/2022 06:00:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/22/2022 06:00:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/22/2022 06:00:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
06/22/2022 06:00:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/22/2022 06:00:41 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.53125 on epoch=599
06/22/2022 06:00:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/22/2022 06:00:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 06:00:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/22/2022 06:00:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/22/2022 06:00:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/22/2022 06:00:47 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.59375 on epoch=624
06/22/2022 06:00:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/22/2022 06:00:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=634
06/22/2022 06:00:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/22/2022 06:00:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/22/2022 06:00:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
06/22/2022 06:00:54 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.625 on epoch=649
06/22/2022 06:00:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 06:00:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
06/22/2022 06:00:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 06:00:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
06/22/2022 06:01:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
06/22/2022 06:01:01 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.59375 on epoch=674
06/22/2022 06:01:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/22/2022 06:01:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 06:01:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/22/2022 06:01:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/22/2022 06:01:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 06:01:07 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/22/2022 06:01:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=704
06/22/2022 06:01:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/22/2022 06:01:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 06:01:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 06:01:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/22/2022 06:01:14 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5 on epoch=724
06/22/2022 06:01:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/22/2022 06:01:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 06:01:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/22/2022 06:01:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 06:01:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/22/2022 06:01:21 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.53125 on epoch=749
06/22/2022 06:01:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 06:01:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/22/2022 06:01:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/22/2022 06:01:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/22/2022 06:01:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 06:01:28 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
06/22/2022 06:01:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/22/2022 06:01:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 06:01:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 06:01:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 06:01:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 06:01:34 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5625 on epoch=799
06/22/2022 06:01:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
06/22/2022 06:01:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/22/2022 06:01:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 06:01:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 06:01:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/22/2022 06:01:41 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
06/22/2022 06:01:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 06:01:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 06:01:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/22/2022 06:01:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 06:01:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 06:01:48 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.59375 on epoch=849
06/22/2022 06:01:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/22/2022 06:01:50 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 06:01:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 06:01:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 06:01:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 06:01:54 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.59375 on epoch=874
06/22/2022 06:01:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=879
06/22/2022 06:01:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 06:01:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 06:01:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 06:02:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 06:02:01 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.59375 on epoch=899
06/22/2022 06:02:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
06/22/2022 06:02:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 06:02:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 06:02:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 06:02:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 06:02:08 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.625 on epoch=924
06/22/2022 06:02:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 06:02:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 06:02:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 06:02:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=944
06/22/2022 06:02:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/22/2022 06:02:14 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.59375 on epoch=949
06/22/2022 06:02:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/22/2022 06:02:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 06:02:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/22/2022 06:02:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 06:02:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
06/22/2022 06:02:21 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.53125 on epoch=974
06/22/2022 06:02:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
06/22/2022 06:02:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 06:02:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 06:02:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 06:02:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 06:02:28 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
06/22/2022 06:02:28 - INFO - __main__ - save last model!
06/22/2022 06:02:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 06:02:28 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 06:02:28 - INFO - __main__ - Printing 3 examples
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 06:02:28 - INFO - __main__ - ['duplicate']
06/22/2022 06:02:28 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:02:28 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:02:28 - INFO - __main__ - Printing 3 examples
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:02:28 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:02:28 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:02:28 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:02:28 - INFO - __main__ - Printing 3 examples
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 06:02:28 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:02:28 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:02:28 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:02:28 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:02:34 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:02:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:02:34 - INFO - __main__ - Starting training!
06/22/2022 06:02:46 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:03:26 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 06:16:14 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.4_8_predictions.txt
06/22/2022 06:16:14 - INFO - __main__ - ACC on test data: 0.5411
06/22/2022 06:16:15 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.4, bsz=8, dev_performance=0.65625, test_performance=0.5411080880534257
06/22/2022 06:16:15 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.3, bsz=8 ...
06/22/2022 06:16:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:16:16 - INFO - __main__ - Printing 3 examples
06/22/2022 06:16:16 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 06:16:16 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:16:16 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 06:16:16 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:16:16 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 06:16:16 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:16:16 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:16:16 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:16:16 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:16:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:16:16 - INFO - __main__ - Printing 3 examples
06/22/2022 06:16:16 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 06:16:16 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:16:16 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 06:16:16 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:16:16 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 06:16:16 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:16:16 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:16:16 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:16:16 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:16:21 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:16:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:16:22 - INFO - __main__ - Starting training!
06/22/2022 06:16:23 - INFO - __main__ - Step 10 Global step 10 Train loss 6.29 on epoch=4
06/22/2022 06:16:24 - INFO - __main__ - Step 20 Global step 20 Train loss 4.61 on epoch=9
06/22/2022 06:16:25 - INFO - __main__ - Step 30 Global step 30 Train loss 3.58 on epoch=14
06/22/2022 06:16:27 - INFO - __main__ - Step 40 Global step 40 Train loss 2.73 on epoch=19
06/22/2022 06:16:28 - INFO - __main__ - Step 50 Global step 50 Train loss 2.07 on epoch=24
06/22/2022 06:16:28 - INFO - __main__ - Global step 50 Train loss 3.86 ACC 0.0 on epoch=24
06/22/2022 06:16:28 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 06:16:30 - INFO - __main__ - Step 60 Global step 60 Train loss 1.62 on epoch=29
06/22/2022 06:16:31 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=34
06/22/2022 06:16:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=39
06/22/2022 06:16:33 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=44
06/22/2022 06:16:34 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=49
06/22/2022 06:16:35 - INFO - __main__ - Global step 100 Train loss 1.03 ACC 0.5 on epoch=49
06/22/2022 06:16:35 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 06:16:36 - INFO - __main__ - Step 110 Global step 110 Train loss 0.65 on epoch=54
06/22/2022 06:16:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.51 on epoch=59
06/22/2022 06:16:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.42 on epoch=64
06/22/2022 06:16:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.43 on epoch=69
06/22/2022 06:16:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.32 on epoch=74
06/22/2022 06:16:41 - INFO - __main__ - Global step 150 Train loss 0.47 ACC 0.5 on epoch=74
06/22/2022 06:16:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.38 on epoch=79
06/22/2022 06:16:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.35 on epoch=84
06/22/2022 06:16:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.34 on epoch=89
06/22/2022 06:16:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=94
06/22/2022 06:16:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=99
06/22/2022 06:16:48 - INFO - __main__ - Global step 200 Train loss 0.35 ACC 0.5 on epoch=99
06/22/2022 06:16:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=104
06/22/2022 06:16:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
06/22/2022 06:16:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=114
06/22/2022 06:16:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/22/2022 06:16:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/22/2022 06:16:55 - INFO - __main__ - Global step 250 Train loss 0.27 ACC 0.5 on epoch=124
06/22/2022 06:16:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/22/2022 06:16:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=134
06/22/2022 06:16:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/22/2022 06:16:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=144
06/22/2022 06:17:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=149
06/22/2022 06:17:01 - INFO - __main__ - Global step 300 Train loss 0.27 ACC 0.5 on epoch=149
06/22/2022 06:17:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=154
06/22/2022 06:17:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/22/2022 06:17:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=164
06/22/2022 06:17:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=169
06/22/2022 06:17:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=174
06/22/2022 06:17:08 - INFO - __main__ - Global step 350 Train loss 0.27 ACC 0.5 on epoch=174
06/22/2022 06:17:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=179
06/22/2022 06:17:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=184
06/22/2022 06:17:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=189
06/22/2022 06:17:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=194
06/22/2022 06:17:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/22/2022 06:17:14 - INFO - __main__ - Global step 400 Train loss 0.26 ACC 0.53125 on epoch=199
06/22/2022 06:17:14 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=199, global_step=400
06/22/2022 06:17:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/22/2022 06:17:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=209
06/22/2022 06:17:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/22/2022 06:17:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=219
06/22/2022 06:17:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/22/2022 06:17:21 - INFO - __main__ - Global step 450 Train loss 0.28 ACC 0.5 on epoch=224
06/22/2022 06:17:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=229
06/22/2022 06:17:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=234
06/22/2022 06:17:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=239
06/22/2022 06:17:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=244
06/22/2022 06:17:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=249
06/22/2022 06:17:28 - INFO - __main__ - Global step 500 Train loss 0.25 ACC 0.46875 on epoch=249
06/22/2022 06:17:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=254
06/22/2022 06:17:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=259
06/22/2022 06:17:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=264
06/22/2022 06:17:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=269
06/22/2022 06:17:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=274
06/22/2022 06:17:34 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.5 on epoch=274
06/22/2022 06:17:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/22/2022 06:17:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=284
06/22/2022 06:17:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=289
06/22/2022 06:17:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=294
06/22/2022 06:17:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=299
06/22/2022 06:17:41 - INFO - __main__ - Global step 600 Train loss 0.22 ACC 0.5 on epoch=299
06/22/2022 06:17:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=304
06/22/2022 06:17:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/22/2022 06:17:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=314
06/22/2022 06:17:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=319
06/22/2022 06:17:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=324
06/22/2022 06:17:47 - INFO - __main__ - Global step 650 Train loss 0.20 ACC 0.53125 on epoch=324
06/22/2022 06:17:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=329
06/22/2022 06:17:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/22/2022 06:17:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=339
06/22/2022 06:17:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=344
06/22/2022 06:17:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=349
06/22/2022 06:17:54 - INFO - __main__ - Global step 700 Train loss 0.21 ACC 0.5 on epoch=349
06/22/2022 06:17:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=354
06/22/2022 06:17:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=359
06/22/2022 06:17:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=364
06/22/2022 06:17:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=369
06/22/2022 06:18:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=374
06/22/2022 06:18:01 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.46875 on epoch=374
06/22/2022 06:18:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=379
06/22/2022 06:18:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=384
06/22/2022 06:18:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/22/2022 06:18:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=394
06/22/2022 06:18:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=399
06/22/2022 06:18:07 - INFO - __main__ - Global step 800 Train loss 0.20 ACC 0.5 on epoch=399
06/22/2022 06:18:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=404
06/22/2022 06:18:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=409
06/22/2022 06:18:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=414
06/22/2022 06:18:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=419
06/22/2022 06:18:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=424
06/22/2022 06:18:14 - INFO - __main__ - Global step 850 Train loss 0.19 ACC 0.5 on epoch=424
06/22/2022 06:18:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=429
06/22/2022 06:18:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=434
06/22/2022 06:18:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/22/2022 06:18:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=444
06/22/2022 06:18:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=449
06/22/2022 06:18:21 - INFO - __main__ - Global step 900 Train loss 0.16 ACC 0.5 on epoch=449
06/22/2022 06:18:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=454
06/22/2022 06:18:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=459
06/22/2022 06:18:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=464
06/22/2022 06:18:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=469
06/22/2022 06:18:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=474
06/22/2022 06:18:27 - INFO - __main__ - Global step 950 Train loss 0.15 ACC 0.625 on epoch=474
06/22/2022 06:18:27 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=474, global_step=950
06/22/2022 06:18:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=479
06/22/2022 06:18:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=484
06/22/2022 06:18:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=489
06/22/2022 06:18:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=494
06/22/2022 06:18:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=499
06/22/2022 06:18:34 - INFO - __main__ - Global step 1000 Train loss 0.13 ACC 0.5625 on epoch=499
06/22/2022 06:18:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=504
06/22/2022 06:18:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=509
06/22/2022 06:18:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=514
06/22/2022 06:18:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=519
06/22/2022 06:18:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=524
06/22/2022 06:18:41 - INFO - __main__ - Global step 1050 Train loss 0.12 ACC 0.59375 on epoch=524
06/22/2022 06:18:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=529
06/22/2022 06:18:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=534
06/22/2022 06:18:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=539
06/22/2022 06:18:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=544
06/22/2022 06:18:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=549
06/22/2022 06:18:47 - INFO - __main__ - Global step 1100 Train loss 0.10 ACC 0.46875 on epoch=549
06/22/2022 06:18:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=554
06/22/2022 06:18:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=559
06/22/2022 06:18:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=564
06/22/2022 06:18:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=569
06/22/2022 06:18:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=574
06/22/2022 06:18:54 - INFO - __main__ - Global step 1150 Train loss 0.10 ACC 0.5 on epoch=574
06/22/2022 06:18:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=579
06/22/2022 06:18:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=584
06/22/2022 06:18:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=589
06/22/2022 06:18:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
06/22/2022 06:19:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=599
06/22/2022 06:19:01 - INFO - __main__ - Global step 1200 Train loss 0.09 ACC 0.46875 on epoch=599
06/22/2022 06:19:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=604
06/22/2022 06:19:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=609
06/22/2022 06:19:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=614
06/22/2022 06:19:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=619
06/22/2022 06:19:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=624
06/22/2022 06:19:07 - INFO - __main__ - Global step 1250 Train loss 0.07 ACC 0.5 on epoch=624
06/22/2022 06:19:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=629
06/22/2022 06:19:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=634
06/22/2022 06:19:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=639
06/22/2022 06:19:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=644
06/22/2022 06:19:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=649
06/22/2022 06:19:14 - INFO - __main__ - Global step 1300 Train loss 0.08 ACC 0.59375 on epoch=649
06/22/2022 06:19:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=654
06/22/2022 06:19:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
06/22/2022 06:19:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=664
06/22/2022 06:19:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=669
06/22/2022 06:19:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=674
06/22/2022 06:19:21 - INFO - __main__ - Global step 1350 Train loss 0.06 ACC 0.53125 on epoch=674
06/22/2022 06:19:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=679
06/22/2022 06:19:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=684
06/22/2022 06:19:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/22/2022 06:19:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=694
06/22/2022 06:19:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=699
06/22/2022 06:19:27 - INFO - __main__ - Global step 1400 Train loss 0.06 ACC 0.59375 on epoch=699
06/22/2022 06:19:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=704
06/22/2022 06:19:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=709
06/22/2022 06:19:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=714
06/22/2022 06:19:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=719
06/22/2022 06:19:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=724
06/22/2022 06:19:34 - INFO - __main__ - Global step 1450 Train loss 0.06 ACC 0.46875 on epoch=724
06/22/2022 06:19:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=729
06/22/2022 06:19:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=734
06/22/2022 06:19:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=739
06/22/2022 06:19:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
06/22/2022 06:19:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=749
06/22/2022 06:19:41 - INFO - __main__ - Global step 1500 Train loss 0.04 ACC 0.5625 on epoch=749
06/22/2022 06:19:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=754
06/22/2022 06:19:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
06/22/2022 06:19:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=764
06/22/2022 06:19:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/22/2022 06:19:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
06/22/2022 06:19:47 - INFO - __main__ - Global step 1550 Train loss 0.04 ACC 0.5625 on epoch=774
06/22/2022 06:19:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=779
06/22/2022 06:19:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
06/22/2022 06:19:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=789
06/22/2022 06:19:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=794
06/22/2022 06:19:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=799
06/22/2022 06:19:54 - INFO - __main__ - Global step 1600 Train loss 0.03 ACC 0.5 on epoch=799
06/22/2022 06:19:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=804
06/22/2022 06:19:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/22/2022 06:19:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=814
06/22/2022 06:19:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 06:20:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
06/22/2022 06:20:01 - INFO - __main__ - Global step 1650 Train loss 0.03 ACC 0.46875 on epoch=824
06/22/2022 06:20:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/22/2022 06:20:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
06/22/2022 06:20:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/22/2022 06:20:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=844
06/22/2022 06:20:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=849
06/22/2022 06:20:07 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.46875 on epoch=849
06/22/2022 06:20:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
06/22/2022 06:20:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
06/22/2022 06:20:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
06/22/2022 06:20:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/22/2022 06:20:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
06/22/2022 06:20:14 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.5 on epoch=874
06/22/2022 06:20:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/22/2022 06:20:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/22/2022 06:20:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 06:20:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=894
06/22/2022 06:20:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 06:20:21 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.53125 on epoch=899
06/22/2022 06:20:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
06/22/2022 06:20:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/22/2022 06:20:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 06:20:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=919
06/22/2022 06:20:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=924
06/22/2022 06:20:27 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.46875 on epoch=924
06/22/2022 06:20:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/22/2022 06:20:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/22/2022 06:20:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
06/22/2022 06:20:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 06:20:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
06/22/2022 06:20:34 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/22/2022 06:20:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
06/22/2022 06:20:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
06/22/2022 06:20:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=964
06/22/2022 06:20:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
06/22/2022 06:20:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=974
06/22/2022 06:20:41 - INFO - __main__ - Global step 1950 Train loss 0.02 ACC 0.5625 on epoch=974
06/22/2022 06:20:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/22/2022 06:20:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/22/2022 06:20:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
06/22/2022 06:20:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/22/2022 06:20:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
06/22/2022 06:20:47 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.59375 on epoch=999
06/22/2022 06:20:47 - INFO - __main__ - save last model!
06/22/2022 06:20:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 06:20:47 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 06:20:47 - INFO - __main__ - Printing 3 examples
06/22/2022 06:20:47 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 06:20:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 06:20:48 - INFO - __main__ - ['duplicate']
06/22/2022 06:20:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:20:48 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:20:48 - INFO - __main__ - Printing 3 examples
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:20:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:20:48 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:20:48 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:20:48 - INFO - __main__ - Printing 3 examples
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 06:20:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:20:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:20:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:20:48 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:20:53 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:20:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:20:54 - INFO - __main__ - Starting training!
06/22/2022 06:21:05 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:21:46 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 06:34:29 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.3_8_predictions.txt
06/22/2022 06:34:30 - INFO - __main__ - ACC on test data: 0.4601
06/22/2022 06:34:30 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.3, bsz=8, dev_performance=0.625, test_performance=0.4600544150383379
06/22/2022 06:34:30 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.2, bsz=8 ...
06/22/2022 06:34:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:34:31 - INFO - __main__ - Printing 3 examples
06/22/2022 06:34:31 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/22/2022 06:34:31 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:34:31 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/22/2022 06:34:31 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:34:31 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/22/2022 06:34:31 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:34:31 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:34:31 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:34:31 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:34:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:34:31 - INFO - __main__ - Printing 3 examples
06/22/2022 06:34:31 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/22/2022 06:34:31 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:34:31 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/22/2022 06:34:31 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:34:31 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/22/2022 06:34:31 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:34:31 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:34:31 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:34:31 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:34:36 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:34:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:34:37 - INFO - __main__ - Starting training!
06/22/2022 06:34:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.25 on epoch=4
06/22/2022 06:34:39 - INFO - __main__ - Step 20 Global step 20 Train loss 5.19 on epoch=9
06/22/2022 06:34:40 - INFO - __main__ - Step 30 Global step 30 Train loss 4.39 on epoch=14
06/22/2022 06:34:42 - INFO - __main__ - Step 40 Global step 40 Train loss 3.65 on epoch=19
06/22/2022 06:34:43 - INFO - __main__ - Step 50 Global step 50 Train loss 3.31 on epoch=24
06/22/2022 06:34:44 - INFO - __main__ - Global step 50 Train loss 4.56 ACC 0.0 on epoch=24
06/22/2022 06:34:44 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 06:34:45 - INFO - __main__ - Step 60 Global step 60 Train loss 2.65 on epoch=29
06/22/2022 06:34:46 - INFO - __main__ - Step 70 Global step 70 Train loss 2.18 on epoch=34
06/22/2022 06:34:47 - INFO - __main__ - Step 80 Global step 80 Train loss 1.70 on epoch=39
06/22/2022 06:34:48 - INFO - __main__ - Step 90 Global step 90 Train loss 1.45 on epoch=44
06/22/2022 06:34:50 - INFO - __main__ - Step 100 Global step 100 Train loss 1.15 on epoch=49
06/22/2022 06:34:50 - INFO - __main__ - Global step 100 Train loss 1.83 ACC 0.5 on epoch=49
06/22/2022 06:34:50 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 06:34:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=54
06/22/2022 06:34:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=59
06/22/2022 06:34:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=64
06/22/2022 06:34:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=69
06/22/2022 06:34:56 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=74
06/22/2022 06:34:57 - INFO - __main__ - Global step 150 Train loss 0.78 ACC 0.5 on epoch=74
06/22/2022 06:34:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.47 on epoch=79
06/22/2022 06:34:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=84
06/22/2022 06:35:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=89
06/22/2022 06:35:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=94
06/22/2022 06:35:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.41 on epoch=99
06/22/2022 06:35:03 - INFO - __main__ - Global step 200 Train loss 0.46 ACC 0.5 on epoch=99
06/22/2022 06:35:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/22/2022 06:35:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=109
06/22/2022 06:35:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=114
06/22/2022 06:35:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.39 on epoch=119
06/22/2022 06:35:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=124
06/22/2022 06:35:10 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.5 on epoch=124
06/22/2022 06:35:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=129
06/22/2022 06:35:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=134
06/22/2022 06:35:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=139
06/22/2022 06:35:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=144
06/22/2022 06:35:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=149
06/22/2022 06:35:16 - INFO - __main__ - Global step 300 Train loss 0.34 ACC 0.5 on epoch=149
06/22/2022 06:35:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/22/2022 06:35:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=159
06/22/2022 06:35:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=164
06/22/2022 06:35:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=169
06/22/2022 06:35:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=174
06/22/2022 06:35:23 - INFO - __main__ - Global step 350 Train loss 0.31 ACC 0.5 on epoch=174
06/22/2022 06:35:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=179
06/22/2022 06:35:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=184
06/22/2022 06:35:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=189
06/22/2022 06:35:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=194
06/22/2022 06:35:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=199
06/22/2022 06:35:30 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/22/2022 06:35:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=204
06/22/2022 06:35:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=209
06/22/2022 06:35:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/22/2022 06:35:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=219
06/22/2022 06:35:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=224
06/22/2022 06:35:36 - INFO - __main__ - Global step 450 Train loss 0.28 ACC 0.5 on epoch=224
06/22/2022 06:35:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=229
06/22/2022 06:35:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=234
06/22/2022 06:35:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=239
06/22/2022 06:35:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=244
06/22/2022 06:35:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=249
06/22/2022 06:35:43 - INFO - __main__ - Global step 500 Train loss 0.26 ACC 0.5 on epoch=249
06/22/2022 06:35:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=254
06/22/2022 06:35:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=259
06/22/2022 06:35:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=264
06/22/2022 06:35:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=269
06/22/2022 06:35:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=274
06/22/2022 06:35:50 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.5 on epoch=274
06/22/2022 06:35:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=279
06/22/2022 06:35:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=284
06/22/2022 06:35:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=289
06/22/2022 06:35:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=294
06/22/2022 06:35:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=299
06/22/2022 06:35:56 - INFO - __main__ - Global step 600 Train loss 0.26 ACC 0.5 on epoch=299
06/22/2022 06:35:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/22/2022 06:35:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=309
06/22/2022 06:36:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=314
06/22/2022 06:36:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=319
06/22/2022 06:36:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=324
06/22/2022 06:36:03 - INFO - __main__ - Global step 650 Train loss 0.24 ACC 0.46875 on epoch=324
06/22/2022 06:36:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=329
06/22/2022 06:36:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/22/2022 06:36:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=339
06/22/2022 06:36:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=344
06/22/2022 06:36:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=349
06/22/2022 06:36:09 - INFO - __main__ - Global step 700 Train loss 0.23 ACC 0.5 on epoch=349
06/22/2022 06:36:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=354
06/22/2022 06:36:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/22/2022 06:36:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=364
06/22/2022 06:36:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=369
06/22/2022 06:36:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=374
06/22/2022 06:36:16 - INFO - __main__ - Global step 750 Train loss 0.23 ACC 0.5 on epoch=374
06/22/2022 06:36:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=379
06/22/2022 06:36:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=384
06/22/2022 06:36:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=389
06/22/2022 06:36:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=394
06/22/2022 06:36:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=399
06/22/2022 06:36:23 - INFO - __main__ - Global step 800 Train loss 0.23 ACC 0.53125 on epoch=399
06/22/2022 06:36:23 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=399, global_step=800
06/22/2022 06:36:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=404
06/22/2022 06:36:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=409
06/22/2022 06:36:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=414
06/22/2022 06:36:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=419
06/22/2022 06:36:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=424
06/22/2022 06:36:29 - INFO - __main__ - Global step 850 Train loss 0.22 ACC 0.5 on epoch=424
06/22/2022 06:36:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=429
06/22/2022 06:36:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=434
06/22/2022 06:36:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/22/2022 06:36:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=444
06/22/2022 06:36:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=449
06/22/2022 06:36:36 - INFO - __main__ - Global step 900 Train loss 0.20 ACC 0.5 on epoch=449
06/22/2022 06:36:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=454
06/22/2022 06:36:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=459
06/22/2022 06:36:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=464
06/22/2022 06:36:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=469
06/22/2022 06:36:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=474
06/22/2022 06:36:43 - INFO - __main__ - Global step 950 Train loss 0.20 ACC 0.4375 on epoch=474
06/22/2022 06:36:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=479
06/22/2022 06:36:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=484
06/22/2022 06:36:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=489
06/22/2022 06:36:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=494
06/22/2022 06:36:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=499
06/22/2022 06:36:49 - INFO - __main__ - Global step 1000 Train loss 0.20 ACC 0.46875 on epoch=499
06/22/2022 06:36:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=504
06/22/2022 06:36:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=509
06/22/2022 06:36:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=514
06/22/2022 06:36:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=519
06/22/2022 06:36:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=524
06/22/2022 06:36:56 - INFO - __main__ - Global step 1050 Train loss 0.18 ACC 0.5 on epoch=524
06/22/2022 06:36:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=529
06/22/2022 06:36:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=534
06/22/2022 06:37:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=539
06/22/2022 06:37:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=544
06/22/2022 06:37:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=549
06/22/2022 06:37:03 - INFO - __main__ - Global step 1100 Train loss 0.19 ACC 0.53125 on epoch=549
06/22/2022 06:37:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=554
06/22/2022 06:37:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=559
06/22/2022 06:37:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=564
06/22/2022 06:37:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=569
06/22/2022 06:37:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=574
06/22/2022 06:37:10 - INFO - __main__ - Global step 1150 Train loss 0.17 ACC 0.5625 on epoch=574
06/22/2022 06:37:10 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=574, global_step=1150
06/22/2022 06:37:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=579
06/22/2022 06:37:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=584
06/22/2022 06:37:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=589
06/22/2022 06:37:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=594
06/22/2022 06:37:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=599
06/22/2022 06:37:16 - INFO - __main__ - Global step 1200 Train loss 0.16 ACC 0.53125 on epoch=599
06/22/2022 06:37:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=604
06/22/2022 06:37:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=609
06/22/2022 06:37:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=614
06/22/2022 06:37:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=619
06/22/2022 06:37:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=624
06/22/2022 06:37:23 - INFO - __main__ - Global step 1250 Train loss 0.16 ACC 0.5625 on epoch=624
06/22/2022 06:37:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=629
06/22/2022 06:37:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=634
06/22/2022 06:37:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=639
06/22/2022 06:37:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=644
06/22/2022 06:37:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=649
06/22/2022 06:37:30 - INFO - __main__ - Global step 1300 Train loss 0.16 ACC 0.59375 on epoch=649
06/22/2022 06:37:30 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=649, global_step=1300
06/22/2022 06:37:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=654
06/22/2022 06:37:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=659
06/22/2022 06:37:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=664
06/22/2022 06:37:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=669
06/22/2022 06:37:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=674
06/22/2022 06:37:36 - INFO - __main__ - Global step 1350 Train loss 0.12 ACC 0.59375 on epoch=674
06/22/2022 06:37:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=679
06/22/2022 06:37:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=684
06/22/2022 06:37:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=689
06/22/2022 06:37:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=694
06/22/2022 06:37:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=699
06/22/2022 06:37:43 - INFO - __main__ - Global step 1400 Train loss 0.13 ACC 0.59375 on epoch=699
06/22/2022 06:37:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=704
06/22/2022 06:37:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=709
06/22/2022 06:37:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=714
06/22/2022 06:37:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=719
06/22/2022 06:37:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=724
06/22/2022 06:37:50 - INFO - __main__ - Global step 1450 Train loss 0.11 ACC 0.625 on epoch=724
06/22/2022 06:37:50 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=724, global_step=1450
06/22/2022 06:37:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=729
06/22/2022 06:37:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=734
06/22/2022 06:37:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=739
06/22/2022 06:37:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=744
06/22/2022 06:37:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=749
06/22/2022 06:37:56 - INFO - __main__ - Global step 1500 Train loss 0.10 ACC 0.53125 on epoch=749
06/22/2022 06:37:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=754
06/22/2022 06:37:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=759
06/22/2022 06:38:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=764
06/22/2022 06:38:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=769
06/22/2022 06:38:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=774
06/22/2022 06:38:03 - INFO - __main__ - Global step 1550 Train loss 0.11 ACC 0.5 on epoch=774
06/22/2022 06:38:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=779
06/22/2022 06:38:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=784
06/22/2022 06:38:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=789
06/22/2022 06:38:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=794
06/22/2022 06:38:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=799
06/22/2022 06:38:10 - INFO - __main__ - Global step 1600 Train loss 0.09 ACC 0.5 on epoch=799
06/22/2022 06:38:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=804
06/22/2022 06:38:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=809
06/22/2022 06:38:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=814
06/22/2022 06:38:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=819
06/22/2022 06:38:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=824
06/22/2022 06:38:17 - INFO - __main__ - Global step 1650 Train loss 0.09 ACC 0.53125 on epoch=824
06/22/2022 06:38:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=829
06/22/2022 06:38:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=834
06/22/2022 06:38:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=839
06/22/2022 06:38:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=844
06/22/2022 06:38:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=849
06/22/2022 06:38:23 - INFO - __main__ - Global step 1700 Train loss 0.07 ACC 0.5 on epoch=849
06/22/2022 06:38:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=854
06/22/2022 06:38:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=859
06/22/2022 06:38:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
06/22/2022 06:38:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=869
06/22/2022 06:38:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=874
06/22/2022 06:38:30 - INFO - __main__ - Global step 1750 Train loss 0.05 ACC 0.40625 on epoch=874
06/22/2022 06:38:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=879
06/22/2022 06:38:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=884
06/22/2022 06:38:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
06/22/2022 06:38:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
06/22/2022 06:38:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=899
06/22/2022 06:38:37 - INFO - __main__ - Global step 1800 Train loss 0.07 ACC 0.5 on epoch=899
06/22/2022 06:38:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=904
06/22/2022 06:38:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=909
06/22/2022 06:38:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=914
06/22/2022 06:38:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=919
06/22/2022 06:38:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=924
06/22/2022 06:38:44 - INFO - __main__ - Global step 1850 Train loss 0.06 ACC 0.53125 on epoch=924
06/22/2022 06:38:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=929
06/22/2022 06:38:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=934
06/22/2022 06:38:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=939
06/22/2022 06:38:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=944
06/22/2022 06:38:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=949
06/22/2022 06:38:50 - INFO - __main__ - Global step 1900 Train loss 0.05 ACC 0.5 on epoch=949
06/22/2022 06:38:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=954
06/22/2022 06:38:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=959
06/22/2022 06:38:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=964
06/22/2022 06:38:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=969
06/22/2022 06:38:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=974
06/22/2022 06:38:57 - INFO - __main__ - Global step 1950 Train loss 0.05 ACC 0.375 on epoch=974
06/22/2022 06:38:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=979
06/22/2022 06:39:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=984
06/22/2022 06:39:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/22/2022 06:39:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=994
06/22/2022 06:39:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=999
06/22/2022 06:39:04 - INFO - __main__ - Global step 2000 Train loss 0.04 ACC 0.375 on epoch=999
06/22/2022 06:39:04 - INFO - __main__ - save last model!
06/22/2022 06:39:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 06:39:04 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 06:39:04 - INFO - __main__ - Printing 3 examples
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 06:39:04 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 06:39:04 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:39:04 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:39:04 - INFO - __main__ - Printing 3 examples
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:39:04 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:39:04 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:39:04 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:39:04 - INFO - __main__ - Printing 3 examples
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 06:39:04 - INFO - __main__ - ['duplicate']
06/22/2022 06:39:04 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:39:04 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:39:04 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:39:10 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:39:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:39:10 - INFO - __main__ - Starting training!
06/22/2022 06:39:22 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:40:02 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 06:52:49 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.2_8_predictions.txt
06/22/2022 06:52:49 - INFO - __main__ - ACC on test data: 0.5134
06/22/2022 06:52:50 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.513356418501113
06/22/2022 06:52:50 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.5, bsz=8 ...
06/22/2022 06:52:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:52:51 - INFO - __main__ - Printing 3 examples
06/22/2022 06:52:51 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 06:52:51 - INFO - __main__ - ['duplicate']
06/22/2022 06:52:51 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 06:52:51 - INFO - __main__ - ['duplicate']
06/22/2022 06:52:51 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 06:52:51 - INFO - __main__ - ['duplicate']
06/22/2022 06:52:51 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:52:51 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:52:51 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:52:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:52:51 - INFO - __main__ - Printing 3 examples
06/22/2022 06:52:51 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 06:52:51 - INFO - __main__ - ['duplicate']
06/22/2022 06:52:51 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 06:52:51 - INFO - __main__ - ['duplicate']
06/22/2022 06:52:51 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 06:52:51 - INFO - __main__ - ['duplicate']
06/22/2022 06:52:51 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:52:51 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:52:51 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:52:56 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:52:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:52:56 - INFO - __main__ - Starting training!
06/22/2022 06:52:58 - INFO - __main__ - Step 10 Global step 10 Train loss 5.58 on epoch=4
06/22/2022 06:52:59 - INFO - __main__ - Step 20 Global step 20 Train loss 3.81 on epoch=9
06/22/2022 06:53:00 - INFO - __main__ - Step 30 Global step 30 Train loss 2.39 on epoch=14
06/22/2022 06:53:01 - INFO - __main__ - Step 40 Global step 40 Train loss 1.55 on epoch=19
06/22/2022 06:53:02 - INFO - __main__ - Step 50 Global step 50 Train loss 0.92 on epoch=24
06/22/2022 06:53:03 - INFO - __main__ - Global step 50 Train loss 2.85 ACC 0.5 on epoch=24
06/22/2022 06:53:03 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 06:53:04 - INFO - __main__ - Step 60 Global step 60 Train loss 0.71 on epoch=29
06/22/2022 06:53:05 - INFO - __main__ - Step 70 Global step 70 Train loss 0.61 on epoch=34
06/22/2022 06:53:07 - INFO - __main__ - Step 80 Global step 80 Train loss 0.50 on epoch=39
06/22/2022 06:53:08 - INFO - __main__ - Step 90 Global step 90 Train loss 0.41 on epoch=44
06/22/2022 06:53:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
06/22/2022 06:53:10 - INFO - __main__ - Global step 100 Train loss 0.53 ACC 0.5 on epoch=49
06/22/2022 06:53:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.44 on epoch=54
06/22/2022 06:53:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.40 on epoch=59
06/22/2022 06:53:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.38 on epoch=64
06/22/2022 06:53:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=69
06/22/2022 06:53:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
06/22/2022 06:53:16 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.5 on epoch=74
06/22/2022 06:53:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=79
06/22/2022 06:53:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=84
06/22/2022 06:53:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=89
06/22/2022 06:53:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.27 on epoch=94
06/22/2022 06:53:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=99
06/22/2022 06:53:23 - INFO - __main__ - Global step 200 Train loss 0.28 ACC 0.5 on epoch=99
06/22/2022 06:53:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.31 on epoch=104
06/22/2022 06:53:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=109
06/22/2022 06:53:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=114
06/22/2022 06:53:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.30 on epoch=119
06/22/2022 06:53:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=124
06/22/2022 06:53:29 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/22/2022 06:53:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=129
06/22/2022 06:53:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/22/2022 06:53:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=139
06/22/2022 06:53:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=144
06/22/2022 06:53:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=149
06/22/2022 06:53:36 - INFO - __main__ - Global step 300 Train loss 0.22 ACC 0.53125 on epoch=149
06/22/2022 06:53:36 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=149, global_step=300
06/22/2022 06:53:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/22/2022 06:53:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
06/22/2022 06:53:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=164
06/22/2022 06:53:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/22/2022 06:53:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=174
06/22/2022 06:53:42 - INFO - __main__ - Global step 350 Train loss 0.22 ACC 0.5625 on epoch=174
06/22/2022 06:53:42 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=174, global_step=350
06/22/2022 06:53:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=179
06/22/2022 06:53:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=184
06/22/2022 06:53:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=189
06/22/2022 06:53:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=194
06/22/2022 06:53:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=199
06/22/2022 06:53:49 - INFO - __main__ - Global step 400 Train loss 0.18 ACC 0.625 on epoch=199
06/22/2022 06:53:49 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=199, global_step=400
06/22/2022 06:53:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=204
06/22/2022 06:53:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=209
06/22/2022 06:53:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=214
06/22/2022 06:53:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=219
06/22/2022 06:53:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=224
06/22/2022 06:53:55 - INFO - __main__ - Global step 450 Train loss 0.16 ACC 0.625 on epoch=224
06/22/2022 06:53:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
06/22/2022 06:53:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=234
06/22/2022 06:53:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=239
06/22/2022 06:54:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=244
06/22/2022 06:54:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
06/22/2022 06:54:02 - INFO - __main__ - Global step 500 Train loss 0.12 ACC 0.5625 on epoch=249
06/22/2022 06:54:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=254
06/22/2022 06:54:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
06/22/2022 06:54:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
06/22/2022 06:54:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
06/22/2022 06:54:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=274
06/22/2022 06:54:09 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.53125 on epoch=274
06/22/2022 06:54:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=279
06/22/2022 06:54:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=284
06/22/2022 06:54:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
06/22/2022 06:54:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/22/2022 06:54:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=299
06/22/2022 06:54:15 - INFO - __main__ - Global step 600 Train loss 0.07 ACC 0.5 on epoch=299
06/22/2022 06:54:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=304
06/22/2022 06:54:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
06/22/2022 06:54:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
06/22/2022 06:54:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=319
06/22/2022 06:54:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/22/2022 06:54:22 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.5 on epoch=324
06/22/2022 06:54:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
06/22/2022 06:54:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
06/22/2022 06:54:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
06/22/2022 06:54:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=344
06/22/2022 06:54:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
06/22/2022 06:54:28 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.53125 on epoch=349
06/22/2022 06:54:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/22/2022 06:54:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
06/22/2022 06:54:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
06/22/2022 06:54:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
06/22/2022 06:54:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
06/22/2022 06:54:35 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5625 on epoch=374
06/22/2022 06:54:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/22/2022 06:54:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
06/22/2022 06:54:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/22/2022 06:54:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
06/22/2022 06:54:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
06/22/2022 06:54:42 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.5 on epoch=399
06/22/2022 06:54:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
06/22/2022 06:54:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
06/22/2022 06:54:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
06/22/2022 06:54:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
06/22/2022 06:54:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/22/2022 06:54:48 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.5 on epoch=424
06/22/2022 06:54:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/22/2022 06:54:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/22/2022 06:54:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/22/2022 06:54:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/22/2022 06:54:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/22/2022 06:54:55 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
06/22/2022 06:54:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/22/2022 06:54:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/22/2022 06:54:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
06/22/2022 06:55:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/22/2022 06:55:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/22/2022 06:55:01 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.53125 on epoch=474
06/22/2022 06:55:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/22/2022 06:55:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/22/2022 06:55:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/22/2022 06:55:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/22/2022 06:55:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/22/2022 06:55:08 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.5 on epoch=499
06/22/2022 06:55:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
06/22/2022 06:55:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
06/22/2022 06:55:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 06:55:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/22/2022 06:55:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
06/22/2022 06:55:15 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.46875 on epoch=524
06/22/2022 06:55:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/22/2022 06:55:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/22/2022 06:55:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/22/2022 06:55:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/22/2022 06:55:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/22/2022 06:55:21 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.5 on epoch=549
06/22/2022 06:55:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/22/2022 06:55:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/22/2022 06:55:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/22/2022 06:55:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/22/2022 06:55:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 06:55:28 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.46875 on epoch=574
06/22/2022 06:55:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 06:55:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/22/2022 06:55:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 06:55:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/22/2022 06:55:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 06:55:35 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.46875 on epoch=599
06/22/2022 06:55:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 06:55:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 06:55:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/22/2022 06:55:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/22/2022 06:55:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 06:55:41 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.5 on epoch=624
06/22/2022 06:55:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/22/2022 06:55:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 06:55:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
06/22/2022 06:55:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 06:55:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 06:55:48 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.5 on epoch=649
06/22/2022 06:55:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 06:55:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/22/2022 06:55:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
06/22/2022 06:55:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/22/2022 06:55:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/22/2022 06:55:55 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.5 on epoch=674
06/22/2022 06:55:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 06:55:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 06:55:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/22/2022 06:55:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 06:56:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/22/2022 06:56:01 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.5 on epoch=699
06/22/2022 06:56:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 06:56:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/22/2022 06:56:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 06:56:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 06:56:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/22/2022 06:56:08 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.46875 on epoch=724
06/22/2022 06:56:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 06:56:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 06:56:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 06:56:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 06:56:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 06:56:14 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.53125 on epoch=749
06/22/2022 06:56:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 06:56:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 06:56:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 06:56:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 06:56:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 06:56:21 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
06/22/2022 06:56:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 06:56:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 06:56:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 06:56:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 06:56:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 06:56:28 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5 on epoch=799
06/22/2022 06:56:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/22/2022 06:56:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 06:56:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 06:56:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 06:56:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 06:56:34 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.46875 on epoch=824
06/22/2022 06:56:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 06:56:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 06:56:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 06:56:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 06:56:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 06:56:41 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.46875 on epoch=849
06/22/2022 06:56:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 06:56:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 06:56:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
06/22/2022 06:56:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 06:56:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 06:56:48 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.46875 on epoch=874
06/22/2022 06:56:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 06:56:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 06:56:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 06:56:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 06:56:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 06:56:54 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5 on epoch=899
06/22/2022 06:56:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/22/2022 06:56:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 06:56:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 06:56:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 06:57:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 06:57:01 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.46875 on epoch=924
06/22/2022 06:57:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=929
06/22/2022 06:57:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 06:57:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
06/22/2022 06:57:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 06:57:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 06:57:08 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/22/2022 06:57:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/22/2022 06:57:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 06:57:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 06:57:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 06:57:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 06:57:14 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.46875 on epoch=974
06/22/2022 06:57:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 06:57:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 06:57:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 06:57:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 06:57:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 06:57:21 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.46875 on epoch=999
06/22/2022 06:57:21 - INFO - __main__ - save last model!
06/22/2022 06:57:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 06:57:21 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 06:57:21 - INFO - __main__ - Printing 3 examples
06/22/2022 06:57:21 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 06:57:21 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:57:21 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 06:57:21 - INFO - __main__ - ['not_duplicate']
06/22/2022 06:57:21 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 06:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:21 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:57:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:57:21 - INFO - __main__ - Printing 3 examples
06/22/2022 06:57:21 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 06:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:21 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 06:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:21 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 06:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:21 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:57:21 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:57:22 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 06:57:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 06:57:22 - INFO - __main__ - Printing 3 examples
06/22/2022 06:57:22 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 06:57:22 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:22 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 06:57:22 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:22 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 06:57:22 - INFO - __main__ - ['duplicate']
06/22/2022 06:57:22 - INFO - __main__ - Tokenizing Input ...
06/22/2022 06:57:22 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:57:22 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 06:57:27 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 06:57:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 06:57:27 - INFO - __main__ - Starting training!
06/22/2022 06:57:39 - INFO - __main__ - Tokenizing Output ...
06/22/2022 06:58:20 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 07:11:24 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.5_8_predictions.txt
06/22/2022 07:11:24 - INFO - __main__ - ACC on test data: 0.6101
06/22/2022 07:11:24 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.5, bsz=8, dev_performance=0.625, test_performance=0.6101409844175117
06/22/2022 07:11:24 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.4, bsz=8 ...
06/22/2022 07:11:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:11:25 - INFO - __main__ - Printing 3 examples
06/22/2022 07:11:25 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 07:11:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:11:25 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 07:11:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:11:25 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 07:11:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:11:25 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:11:25 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:11:25 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 07:11:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:11:25 - INFO - __main__ - Printing 3 examples
06/22/2022 07:11:25 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 07:11:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:11:25 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 07:11:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:11:25 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 07:11:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:11:25 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:11:25 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:11:25 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 07:11:30 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 07:11:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 07:11:31 - INFO - __main__ - Starting training!
06/22/2022 07:11:32 - INFO - __main__ - Step 10 Global step 10 Train loss 5.92 on epoch=4
06/22/2022 07:11:33 - INFO - __main__ - Step 20 Global step 20 Train loss 4.12 on epoch=9
06/22/2022 07:11:34 - INFO - __main__ - Step 30 Global step 30 Train loss 3.10 on epoch=14
06/22/2022 07:11:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.17 on epoch=19
06/22/2022 07:11:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.51 on epoch=24
06/22/2022 07:11:37 - INFO - __main__ - Global step 50 Train loss 3.36 ACC 0.5 on epoch=24
06/22/2022 07:11:37 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 07:11:39 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=29
06/22/2022 07:11:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
06/22/2022 07:11:41 - INFO - __main__ - Step 80 Global step 80 Train loss 0.60 on epoch=39
06/22/2022 07:11:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.49 on epoch=44
06/22/2022 07:11:43 - INFO - __main__ - Step 100 Global step 100 Train loss 0.46 on epoch=49
06/22/2022 07:11:44 - INFO - __main__ - Global step 100 Train loss 0.66 ACC 0.5 on epoch=49
06/22/2022 07:11:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.39 on epoch=54
06/22/2022 07:11:46 - INFO - __main__ - Step 120 Global step 120 Train loss 0.43 on epoch=59
06/22/2022 07:11:48 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/22/2022 07:11:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.34 on epoch=69
06/22/2022 07:11:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.35 on epoch=74
06/22/2022 07:11:50 - INFO - __main__ - Global step 150 Train loss 0.37 ACC 0.5 on epoch=74
06/22/2022 07:11:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.41 on epoch=79
06/22/2022 07:11:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/22/2022 07:11:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.31 on epoch=89
06/22/2022 07:11:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=94
06/22/2022 07:11:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.34 on epoch=99
06/22/2022 07:11:57 - INFO - __main__ - Global step 200 Train loss 0.33 ACC 0.5 on epoch=99
06/22/2022 07:11:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.28 on epoch=104
06/22/2022 07:11:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
06/22/2022 07:12:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=114
06/22/2022 07:12:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=119
06/22/2022 07:12:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=124
06/22/2022 07:12:04 - INFO - __main__ - Global step 250 Train loss 0.29 ACC 0.53125 on epoch=124
06/22/2022 07:12:04 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=124, global_step=250
06/22/2022 07:12:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=129
06/22/2022 07:12:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/22/2022 07:12:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/22/2022 07:12:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=144
06/22/2022 07:12:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=149
06/22/2022 07:12:10 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5625 on epoch=149
06/22/2022 07:12:10 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=149, global_step=300
06/22/2022 07:12:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/22/2022 07:12:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/22/2022 07:12:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=164
06/22/2022 07:12:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/22/2022 07:12:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/22/2022 07:12:17 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.625 on epoch=174
06/22/2022 07:12:17 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=174, global_step=350
06/22/2022 07:12:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=179
06/22/2022 07:12:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=184
06/22/2022 07:12:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=189
06/22/2022 07:12:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=194
06/22/2022 07:12:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=199
06/22/2022 07:12:23 - INFO - __main__ - Global step 400 Train loss 0.19 ACC 0.59375 on epoch=199
06/22/2022 07:12:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=204
06/22/2022 07:12:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=209
06/22/2022 07:12:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=214
06/22/2022 07:12:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=219
06/22/2022 07:12:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=224
06/22/2022 07:12:30 - INFO - __main__ - Global step 450 Train loss 0.17 ACC 0.625 on epoch=224
06/22/2022 07:12:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=229
06/22/2022 07:12:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=234
06/22/2022 07:12:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=239
06/22/2022 07:12:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=244
06/22/2022 07:12:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=249
06/22/2022 07:12:37 - INFO - __main__ - Global step 500 Train loss 0.11 ACC 0.59375 on epoch=249
06/22/2022 07:12:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=254
06/22/2022 07:12:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=259
06/22/2022 07:12:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
06/22/2022 07:12:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
06/22/2022 07:12:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
06/22/2022 07:12:43 - INFO - __main__ - Global step 550 Train loss 0.07 ACC 0.59375 on epoch=274
06/22/2022 07:12:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
06/22/2022 07:12:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
06/22/2022 07:12:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
06/22/2022 07:12:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
06/22/2022 07:12:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=299
06/22/2022 07:12:50 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.59375 on epoch=299
06/22/2022 07:12:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
06/22/2022 07:12:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
06/22/2022 07:12:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
06/22/2022 07:12:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
06/22/2022 07:12:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/22/2022 07:12:57 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.59375 on epoch=324
06/22/2022 07:12:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
06/22/2022 07:12:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/22/2022 07:13:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
06/22/2022 07:13:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
06/22/2022 07:13:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
06/22/2022 07:13:03 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.625 on epoch=349
06/22/2022 07:13:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
06/22/2022 07:13:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=359
06/22/2022 07:13:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
06/22/2022 07:13:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/22/2022 07:13:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
06/22/2022 07:13:10 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.59375 on epoch=374
06/22/2022 07:13:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/22/2022 07:13:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
06/22/2022 07:13:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/22/2022 07:13:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/22/2022 07:13:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=399
06/22/2022 07:13:16 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.53125 on epoch=399
06/22/2022 07:13:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=404
06/22/2022 07:13:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/22/2022 07:13:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
06/22/2022 07:13:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
06/22/2022 07:13:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
06/22/2022 07:13:23 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.53125 on epoch=424
06/22/2022 07:13:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/22/2022 07:13:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
06/22/2022 07:13:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/22/2022 07:13:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/22/2022 07:13:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/22/2022 07:13:30 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5625 on epoch=449
06/22/2022 07:13:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/22/2022 07:13:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/22/2022 07:13:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/22/2022 07:13:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/22/2022 07:13:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/22/2022 07:13:36 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.53125 on epoch=474
06/22/2022 07:13:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
06/22/2022 07:13:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
06/22/2022 07:13:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/22/2022 07:13:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/22/2022 07:13:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/22/2022 07:13:43 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
06/22/2022 07:13:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/22/2022 07:13:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/22/2022 07:13:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 07:13:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/22/2022 07:13:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/22/2022 07:13:50 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.59375 on epoch=524
06/22/2022 07:13:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
06/22/2022 07:13:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 07:13:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/22/2022 07:13:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/22/2022 07:13:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
06/22/2022 07:13:56 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.625 on epoch=549
06/22/2022 07:13:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/22/2022 07:13:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/22/2022 07:14:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 07:14:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/22/2022 07:14:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/22/2022 07:14:03 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.59375 on epoch=574
06/22/2022 07:14:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/22/2022 07:14:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/22/2022 07:14:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
06/22/2022 07:14:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/22/2022 07:14:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 07:14:09 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.5625 on epoch=599
06/22/2022 07:14:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 07:14:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 07:14:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 07:14:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/22/2022 07:14:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/22/2022 07:14:16 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/22/2022 07:14:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/22/2022 07:14:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 07:14:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/22/2022 07:14:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 07:14:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 07:14:23 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
06/22/2022 07:14:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 07:14:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/22/2022 07:14:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/22/2022 07:14:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 07:14:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/22/2022 07:14:29 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.59375 on epoch=674
06/22/2022 07:14:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 07:14:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 07:14:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/22/2022 07:14:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 07:14:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/22/2022 07:14:36 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.53125 on epoch=699
06/22/2022 07:14:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 07:14:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 07:14:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 07:14:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 07:14:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 07:14:42 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.625 on epoch=724
06/22/2022 07:14:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 07:14:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 07:14:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/22/2022 07:14:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 07:14:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 07:14:49 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.625 on epoch=749
06/22/2022 07:14:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
06/22/2022 07:14:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 07:14:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 07:14:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/22/2022 07:14:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 07:14:56 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5625 on epoch=774
06/22/2022 07:14:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 07:14:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 07:14:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 07:15:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 07:15:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 07:15:02 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.625 on epoch=799
06/22/2022 07:15:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/22/2022 07:15:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 07:15:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 07:15:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 07:15:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 07:15:09 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.59375 on epoch=824
06/22/2022 07:15:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/22/2022 07:15:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 07:15:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/22/2022 07:15:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 07:15:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 07:15:15 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.59375 on epoch=849
06/22/2022 07:15:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 07:15:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 07:15:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 07:15:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/22/2022 07:15:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 07:15:22 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.53125 on epoch=874
06/22/2022 07:15:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 07:15:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 07:15:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 07:15:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 07:15:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 07:15:29 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/22/2022 07:15:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 07:15:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 07:15:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 07:15:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 07:15:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 07:15:35 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5625 on epoch=924
06/22/2022 07:15:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/22/2022 07:15:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 07:15:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 07:15:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 07:15:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 07:15:42 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.625 on epoch=949
06/22/2022 07:15:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/22/2022 07:15:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 07:15:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 07:15:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 07:15:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 07:15:49 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.46875 on epoch=974
06/22/2022 07:15:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 07:15:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 07:15:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 07:15:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 07:15:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 07:15:55 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.65625 on epoch=999
06/22/2022 07:15:55 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=999, global_step=2000
06/22/2022 07:15:55 - INFO - __main__ - save last model!
06/22/2022 07:15:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 07:15:56 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 07:15:56 - INFO - __main__ - Printing 3 examples
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 07:15:56 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 07:15:56 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:15:56 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:15:56 - INFO - __main__ - Printing 3 examples
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:15:56 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:15:56 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 07:15:56 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:15:56 - INFO - __main__ - Printing 3 examples
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 07:15:56 - INFO - __main__ - ['duplicate']
06/22/2022 07:15:56 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:15:56 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:15:56 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 07:16:01 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 07:16:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 07:16:01 - INFO - __main__ - Starting training!
06/22/2022 07:16:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:16:54 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 07:29:53 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.4_8_predictions.txt
06/22/2022 07:29:53 - INFO - __main__ - ACC on test data: 0.6062
06/22/2022 07:29:54 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.4, bsz=8, dev_performance=0.65625, test_performance=0.6061835270838486
06/22/2022 07:29:54 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.3, bsz=8 ...
06/22/2022 07:29:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:29:55 - INFO - __main__ - Printing 3 examples
06/22/2022 07:29:55 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 07:29:55 - INFO - __main__ - ['duplicate']
06/22/2022 07:29:55 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 07:29:55 - INFO - __main__ - ['duplicate']
06/22/2022 07:29:55 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 07:29:55 - INFO - __main__ - ['duplicate']
06/22/2022 07:29:55 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:29:55 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:29:55 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 07:29:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:29:55 - INFO - __main__ - Printing 3 examples
06/22/2022 07:29:55 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 07:29:55 - INFO - __main__ - ['duplicate']
06/22/2022 07:29:55 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 07:29:55 - INFO - __main__ - ['duplicate']
06/22/2022 07:29:55 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 07:29:55 - INFO - __main__ - ['duplicate']
06/22/2022 07:29:55 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:29:55 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:29:55 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 07:30:00 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 07:30:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 07:30:00 - INFO - __main__ - Starting training!
06/22/2022 07:30:02 - INFO - __main__ - Step 10 Global step 10 Train loss 5.92 on epoch=4
06/22/2022 07:30:03 - INFO - __main__ - Step 20 Global step 20 Train loss 4.63 on epoch=9
06/22/2022 07:30:04 - INFO - __main__ - Step 30 Global step 30 Train loss 3.52 on epoch=14
06/22/2022 07:30:05 - INFO - __main__ - Step 40 Global step 40 Train loss 2.80 on epoch=19
06/22/2022 07:30:07 - INFO - __main__ - Step 50 Global step 50 Train loss 2.05 on epoch=24
06/22/2022 07:30:07 - INFO - __main__ - Global step 50 Train loss 3.78 ACC 0.0 on epoch=24
06/22/2022 07:30:07 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 07:30:08 - INFO - __main__ - Step 60 Global step 60 Train loss 1.61 on epoch=29
06/22/2022 07:30:10 - INFO - __main__ - Step 70 Global step 70 Train loss 1.12 on epoch=34
06/22/2022 07:30:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.88 on epoch=39
06/22/2022 07:30:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.70 on epoch=44
06/22/2022 07:30:13 - INFO - __main__ - Step 100 Global step 100 Train loss 0.59 on epoch=49
06/22/2022 07:30:14 - INFO - __main__ - Global step 100 Train loss 0.98 ACC 0.5 on epoch=49
06/22/2022 07:30:14 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 07:30:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.44 on epoch=54
06/22/2022 07:30:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.40 on epoch=59
06/22/2022 07:30:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.47 on epoch=64
06/22/2022 07:30:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=69
06/22/2022 07:30:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.38 on epoch=74
06/22/2022 07:30:20 - INFO - __main__ - Global step 150 Train loss 0.44 ACC 0.5 on epoch=74
06/22/2022 07:30:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
06/22/2022 07:30:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=84
06/22/2022 07:30:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=89
06/22/2022 07:30:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.32 on epoch=94
06/22/2022 07:30:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.37 on epoch=99
06/22/2022 07:30:27 - INFO - __main__ - Global step 200 Train loss 0.37 ACC 0.5 on epoch=99
06/22/2022 07:30:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=104
06/22/2022 07:30:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.38 on epoch=109
06/22/2022 07:30:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=114
06/22/2022 07:30:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=119
06/22/2022 07:30:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=124
06/22/2022 07:30:33 - INFO - __main__ - Global step 250 Train loss 0.35 ACC 0.5 on epoch=124
06/22/2022 07:30:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/22/2022 07:30:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/22/2022 07:30:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=139
06/22/2022 07:30:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/22/2022 07:30:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=149
06/22/2022 07:30:40 - INFO - __main__ - Global step 300 Train loss 0.30 ACC 0.5 on epoch=149
06/22/2022 07:30:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=154
06/22/2022 07:30:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=159
06/22/2022 07:30:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=164
06/22/2022 07:30:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/22/2022 07:30:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=174
06/22/2022 07:30:47 - INFO - __main__ - Global step 350 Train loss 0.26 ACC 0.53125 on epoch=174
06/22/2022 07:30:47 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/22/2022 07:30:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/22/2022 07:30:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=184
06/22/2022 07:30:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=189
06/22/2022 07:30:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=194
06/22/2022 07:30:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/22/2022 07:30:53 - INFO - __main__ - Global step 400 Train loss 0.26 ACC 0.53125 on epoch=199
06/22/2022 07:30:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=204
06/22/2022 07:30:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=209
06/22/2022 07:30:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
06/22/2022 07:30:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/22/2022 07:30:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/22/2022 07:31:00 - INFO - __main__ - Global step 450 Train loss 0.24 ACC 0.5625 on epoch=224
06/22/2022 07:31:00 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=224, global_step=450
06/22/2022 07:31:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=229
06/22/2022 07:31:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=234
06/22/2022 07:31:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=239
06/22/2022 07:31:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=244
06/22/2022 07:31:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=249
06/22/2022 07:31:06 - INFO - __main__ - Global step 500 Train loss 0.22 ACC 0.65625 on epoch=249
06/22/2022 07:31:06 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.65625 on epoch=249, global_step=500
06/22/2022 07:31:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=254
06/22/2022 07:31:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=259
06/22/2022 07:31:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/22/2022 07:31:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=269
06/22/2022 07:31:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=274
06/22/2022 07:31:13 - INFO - __main__ - Global step 550 Train loss 0.20 ACC 0.40625 on epoch=274
06/22/2022 07:31:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=279
06/22/2022 07:31:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=284
06/22/2022 07:31:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=289
06/22/2022 07:31:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=294
06/22/2022 07:31:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=299
06/22/2022 07:31:20 - INFO - __main__ - Global step 600 Train loss 0.16 ACC 0.4375 on epoch=299
06/22/2022 07:31:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=304
06/22/2022 07:31:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=309
06/22/2022 07:31:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=314
06/22/2022 07:31:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=319
06/22/2022 07:31:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=324
06/22/2022 07:31:26 - INFO - __main__ - Global step 650 Train loss 0.13 ACC 0.40625 on epoch=324
06/22/2022 07:31:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=329
06/22/2022 07:31:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=334
06/22/2022 07:31:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=339
06/22/2022 07:31:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=344
06/22/2022 07:31:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
06/22/2022 07:31:33 - INFO - __main__ - Global step 700 Train loss 0.11 ACC 0.46875 on epoch=349
06/22/2022 07:31:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=354
06/22/2022 07:31:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=359
06/22/2022 07:31:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=364
06/22/2022 07:31:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=369
06/22/2022 07:31:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
06/22/2022 07:31:39 - INFO - __main__ - Global step 750 Train loss 0.08 ACC 0.5 on epoch=374
06/22/2022 07:31:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
06/22/2022 07:31:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
06/22/2022 07:31:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
06/22/2022 07:31:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=394
06/22/2022 07:31:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
06/22/2022 07:31:46 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.59375 on epoch=399
06/22/2022 07:31:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
06/22/2022 07:31:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=409
06/22/2022 07:31:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
06/22/2022 07:31:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=419
06/22/2022 07:31:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
06/22/2022 07:31:53 - INFO - __main__ - Global step 850 Train loss 0.05 ACC 0.5625 on epoch=424
06/22/2022 07:31:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
06/22/2022 07:31:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=434
06/22/2022 07:31:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/22/2022 07:31:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/22/2022 07:31:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/22/2022 07:31:59 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.53125 on epoch=449
06/22/2022 07:32:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/22/2022 07:32:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=459
06/22/2022 07:32:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
06/22/2022 07:32:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/22/2022 07:32:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/22/2022 07:32:06 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.46875 on epoch=474
06/22/2022 07:32:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
06/22/2022 07:32:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
06/22/2022 07:32:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/22/2022 07:32:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/22/2022 07:32:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/22/2022 07:32:12 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.5625 on epoch=499
06/22/2022 07:32:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/22/2022 07:32:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
06/22/2022 07:32:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
06/22/2022 07:32:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/22/2022 07:32:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/22/2022 07:32:19 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
06/22/2022 07:32:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/22/2022 07:32:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 07:32:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/22/2022 07:32:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/22/2022 07:32:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/22/2022 07:32:26 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5 on epoch=549
06/22/2022 07:32:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/22/2022 07:32:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/22/2022 07:32:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 07:32:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/22/2022 07:32:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 07:32:32 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.53125 on epoch=574
06/22/2022 07:32:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 07:32:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/22/2022 07:32:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 07:32:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/22/2022 07:32:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 07:32:39 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.5 on epoch=599
06/22/2022 07:32:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/22/2022 07:32:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 07:32:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/22/2022 07:32:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 07:32:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/22/2022 07:32:45 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
06/22/2022 07:32:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/22/2022 07:32:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/22/2022 07:32:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/22/2022 07:32:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 07:32:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/22/2022 07:32:52 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.5 on epoch=649
06/22/2022 07:32:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/22/2022 07:32:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/22/2022 07:32:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/22/2022 07:32:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/22/2022 07:32:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/22/2022 07:32:59 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.53125 on epoch=674
06/22/2022 07:33:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/22/2022 07:33:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 07:33:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/22/2022 07:33:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/22/2022 07:33:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/22/2022 07:33:06 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/22/2022 07:33:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/22/2022 07:33:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 07:33:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 07:33:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 07:33:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/22/2022 07:33:12 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
06/22/2022 07:33:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 07:33:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 07:33:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
06/22/2022 07:33:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/22/2022 07:33:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 07:33:19 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.53125 on epoch=749
06/22/2022 07:33:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 07:33:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 07:33:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 07:33:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/22/2022 07:33:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 07:33:25 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
06/22/2022 07:33:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 07:33:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 07:33:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 07:33:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 07:33:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 07:33:32 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.59375 on epoch=799
06/22/2022 07:33:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/22/2022 07:33:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
06/22/2022 07:33:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 07:33:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 07:33:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 07:33:39 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
06/22/2022 07:33:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 07:33:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
06/22/2022 07:33:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 07:33:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 07:33:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/22/2022 07:33:45 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
06/22/2022 07:33:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 07:33:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/22/2022 07:33:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 07:33:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 07:33:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 07:33:52 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
06/22/2022 07:33:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/22/2022 07:33:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/22/2022 07:33:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 07:33:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 07:33:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 07:33:59 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.53125 on epoch=899
06/22/2022 07:34:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/22/2022 07:34:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 07:34:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=914
06/22/2022 07:34:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=919
06/22/2022 07:34:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 07:34:05 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.5625 on epoch=924
06/22/2022 07:34:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 07:34:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 07:34:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 07:34:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 07:34:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 07:34:12 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.5625 on epoch=949
06/22/2022 07:34:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
06/22/2022 07:34:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 07:34:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 07:34:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 07:34:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 07:34:18 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5625 on epoch=974
06/22/2022 07:34:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 07:34:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/22/2022 07:34:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 07:34:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/22/2022 07:34:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
06/22/2022 07:34:25 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5625 on epoch=999
06/22/2022 07:34:25 - INFO - __main__ - save last model!
06/22/2022 07:34:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 07:34:25 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 07:34:25 - INFO - __main__ - Printing 3 examples
06/22/2022 07:34:25 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 07:34:25 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:34:25 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 07:34:25 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:34:25 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 07:34:25 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:25 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:34:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:34:26 - INFO - __main__ - Printing 3 examples
06/22/2022 07:34:26 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 07:34:26 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:26 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 07:34:26 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:26 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 07:34:26 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:34:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:34:26 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 07:34:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:34:26 - INFO - __main__ - Printing 3 examples
06/22/2022 07:34:26 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 07:34:26 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:26 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 07:34:26 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:26 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 07:34:26 - INFO - __main__ - ['duplicate']
06/22/2022 07:34:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:34:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:34:26 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 07:34:31 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 07:34:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 07:34:31 - INFO - __main__ - Starting training!
06/22/2022 07:34:43 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:35:24 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 07:48:16 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.3_8_predictions.txt
06/22/2022 07:48:16 - INFO - __main__ - ACC on test data: 0.5875
06/22/2022 07:48:16 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.3, bsz=8, dev_performance=0.65625, test_performance=0.5874845411822904
06/22/2022 07:48:16 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.2, bsz=8 ...
06/22/2022 07:48:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:48:17 - INFO - __main__ - Printing 3 examples
06/22/2022 07:48:17 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/22/2022 07:48:17 - INFO - __main__ - ['duplicate']
06/22/2022 07:48:17 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/22/2022 07:48:17 - INFO - __main__ - ['duplicate']
06/22/2022 07:48:17 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/22/2022 07:48:17 - INFO - __main__ - ['duplicate']
06/22/2022 07:48:17 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:48:17 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:48:17 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 07:48:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:48:17 - INFO - __main__ - Printing 3 examples
06/22/2022 07:48:17 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/22/2022 07:48:17 - INFO - __main__ - ['duplicate']
06/22/2022 07:48:17 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/22/2022 07:48:17 - INFO - __main__ - ['duplicate']
06/22/2022 07:48:17 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/22/2022 07:48:17 - INFO - __main__ - ['duplicate']
06/22/2022 07:48:17 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:48:17 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:48:17 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 07:48:23 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 07:48:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 07:48:23 - INFO - __main__ - Starting training!
06/22/2022 07:48:24 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=4
06/22/2022 07:48:26 - INFO - __main__ - Step 20 Global step 20 Train loss 5.31 on epoch=9
06/22/2022 07:48:27 - INFO - __main__ - Step 30 Global step 30 Train loss 4.39 on epoch=14
06/22/2022 07:48:28 - INFO - __main__ - Step 40 Global step 40 Train loss 3.77 on epoch=19
06/22/2022 07:48:29 - INFO - __main__ - Step 50 Global step 50 Train loss 3.10 on epoch=24
06/22/2022 07:48:30 - INFO - __main__ - Global step 50 Train loss 4.62 ACC 0.0 on epoch=24
06/22/2022 07:48:30 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 07:48:31 - INFO - __main__ - Step 60 Global step 60 Train loss 2.66 on epoch=29
06/22/2022 07:48:32 - INFO - __main__ - Step 70 Global step 70 Train loss 2.35 on epoch=34
06/22/2022 07:48:34 - INFO - __main__ - Step 80 Global step 80 Train loss 1.90 on epoch=39
06/22/2022 07:48:35 - INFO - __main__ - Step 90 Global step 90 Train loss 1.42 on epoch=44
06/22/2022 07:48:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.26 on epoch=49
06/22/2022 07:48:36 - INFO - __main__ - Global step 100 Train loss 1.92 ACC 0.5 on epoch=49
06/22/2022 07:48:36 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 07:48:38 - INFO - __main__ - Step 110 Global step 110 Train loss 1.04 on epoch=54
06/22/2022 07:48:39 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=59
06/22/2022 07:48:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=64
06/22/2022 07:48:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=69
06/22/2022 07:48:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=74
06/22/2022 07:48:43 - INFO - __main__ - Global step 150 Train loss 0.79 ACC 0.5 on epoch=74
06/22/2022 07:48:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=79
06/22/2022 07:48:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=84
06/22/2022 07:48:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=89
06/22/2022 07:48:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.36 on epoch=94
06/22/2022 07:48:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=99
06/22/2022 07:48:50 - INFO - __main__ - Global step 200 Train loss 0.46 ACC 0.5 on epoch=99
06/22/2022 07:48:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/22/2022 07:48:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=109
06/22/2022 07:48:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=114
06/22/2022 07:48:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=119
06/22/2022 07:48:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/22/2022 07:48:56 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.5 on epoch=124
06/22/2022 07:48:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=129
06/22/2022 07:48:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=134
06/22/2022 07:49:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=139
06/22/2022 07:49:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=144
06/22/2022 07:49:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=149
06/22/2022 07:49:03 - INFO - __main__ - Global step 300 Train loss 0.35 ACC 0.5 on epoch=149
06/22/2022 07:49:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=154
06/22/2022 07:49:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=159
06/22/2022 07:49:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=164
06/22/2022 07:49:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=169
06/22/2022 07:49:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=174
06/22/2022 07:49:09 - INFO - __main__ - Global step 350 Train loss 0.36 ACC 0.5 on epoch=174
06/22/2022 07:49:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=179
06/22/2022 07:49:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=184
06/22/2022 07:49:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=189
06/22/2022 07:49:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=194
06/22/2022 07:49:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/22/2022 07:49:16 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/22/2022 07:49:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=204
06/22/2022 07:49:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=209
06/22/2022 07:49:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=214
06/22/2022 07:49:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=219
06/22/2022 07:49:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=224
06/22/2022 07:49:22 - INFO - __main__ - Global step 450 Train loss 0.33 ACC 0.5 on epoch=224
06/22/2022 07:49:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=229
06/22/2022 07:49:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=234
06/22/2022 07:49:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=239
06/22/2022 07:49:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=244
06/22/2022 07:49:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=249
06/22/2022 07:49:29 - INFO - __main__ - Global step 500 Train loss 0.28 ACC 0.5 on epoch=249
06/22/2022 07:49:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=254
06/22/2022 07:49:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=259
06/22/2022 07:49:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=264
06/22/2022 07:49:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=269
06/22/2022 07:49:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=274
06/22/2022 07:49:35 - INFO - __main__ - Global step 550 Train loss 0.28 ACC 0.5 on epoch=274
06/22/2022 07:49:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=279
06/22/2022 07:49:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=284
06/22/2022 07:49:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=289
06/22/2022 07:49:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=294
06/22/2022 07:49:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=299
06/22/2022 07:49:42 - INFO - __main__ - Global step 600 Train loss 0.24 ACC 0.53125 on epoch=299
06/22/2022 07:49:42 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=299, global_step=600
06/22/2022 07:49:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/22/2022 07:49:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=309
06/22/2022 07:49:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=314
06/22/2022 07:49:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=319
06/22/2022 07:49:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=324
06/22/2022 07:49:48 - INFO - __main__ - Global step 650 Train loss 0.21 ACC 0.5625 on epoch=324
06/22/2022 07:49:49 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=324, global_step=650
06/22/2022 07:49:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=329
06/22/2022 07:49:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=334
06/22/2022 07:49:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=339
06/22/2022 07:49:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=344
06/22/2022 07:49:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=349
06/22/2022 07:49:55 - INFO - __main__ - Global step 700 Train loss 0.23 ACC 0.59375 on epoch=349
06/22/2022 07:49:55 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=349, global_step=700
06/22/2022 07:49:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=354
06/22/2022 07:49:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=359
06/22/2022 07:49:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=364
06/22/2022 07:50:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=369
06/22/2022 07:50:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=374
06/22/2022 07:50:02 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.59375 on epoch=374
06/22/2022 07:50:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=379
06/22/2022 07:50:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=384
06/22/2022 07:50:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=389
06/22/2022 07:50:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=394
06/22/2022 07:50:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=399
06/22/2022 07:50:08 - INFO - __main__ - Global step 800 Train loss 0.18 ACC 0.625 on epoch=399
06/22/2022 07:50:08 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=399, global_step=800
06/22/2022 07:50:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=404
06/22/2022 07:50:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=409
06/22/2022 07:50:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=414
06/22/2022 07:50:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=419
06/22/2022 07:50:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=424
06/22/2022 07:50:15 - INFO - __main__ - Global step 850 Train loss 0.18 ACC 0.59375 on epoch=424
06/22/2022 07:50:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=429
06/22/2022 07:50:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=434
06/22/2022 07:50:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=439
06/22/2022 07:50:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=444
06/22/2022 07:50:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=449
06/22/2022 07:50:21 - INFO - __main__ - Global step 900 Train loss 0.14 ACC 0.5625 on epoch=449
06/22/2022 07:50:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=454
06/22/2022 07:50:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=459
06/22/2022 07:50:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=464
06/22/2022 07:50:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=469
06/22/2022 07:50:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=474
06/22/2022 07:50:28 - INFO - __main__ - Global step 950 Train loss 0.13 ACC 0.5 on epoch=474
06/22/2022 07:50:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=479
06/22/2022 07:50:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=484
06/22/2022 07:50:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=489
06/22/2022 07:50:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=494
06/22/2022 07:50:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=499
06/22/2022 07:50:35 - INFO - __main__ - Global step 1000 Train loss 0.10 ACC 0.53125 on epoch=499
06/22/2022 07:50:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=504
06/22/2022 07:50:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=509
06/22/2022 07:50:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=514
06/22/2022 07:50:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=519
06/22/2022 07:50:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=524
06/22/2022 07:50:41 - INFO - __main__ - Global step 1050 Train loss 0.09 ACC 0.53125 on epoch=524
06/22/2022 07:50:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/22/2022 07:50:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=534
06/22/2022 07:50:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/22/2022 07:50:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
06/22/2022 07:50:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=549
06/22/2022 07:50:48 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.53125 on epoch=549
06/22/2022 07:50:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=554
06/22/2022 07:50:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=559
06/22/2022 07:50:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=564
06/22/2022 07:50:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=569
06/22/2022 07:50:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
06/22/2022 07:50:54 - INFO - __main__ - Global step 1150 Train loss 0.06 ACC 0.5625 on epoch=574
06/22/2022 07:50:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=579
06/22/2022 07:50:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=584
06/22/2022 07:50:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
06/22/2022 07:50:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=594
06/22/2022 07:51:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=599
06/22/2022 07:51:01 - INFO - __main__ - Global step 1200 Train loss 0.05 ACC 0.5625 on epoch=599
06/22/2022 07:51:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/22/2022 07:51:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=609
06/22/2022 07:51:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=614
06/22/2022 07:51:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=619
06/22/2022 07:51:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/22/2022 07:51:08 - INFO - __main__ - Global step 1250 Train loss 0.04 ACC 0.5625 on epoch=624
06/22/2022 07:51:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=629
06/22/2022 07:51:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/22/2022 07:51:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=639
06/22/2022 07:51:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
06/22/2022 07:51:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
06/22/2022 07:51:14 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.5625 on epoch=649
06/22/2022 07:51:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 07:51:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
06/22/2022 07:51:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
06/22/2022 07:51:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/22/2022 07:51:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/22/2022 07:51:21 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.5625 on epoch=674
06/22/2022 07:51:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
06/22/2022 07:51:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 07:51:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/22/2022 07:51:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/22/2022 07:51:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/22/2022 07:51:27 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.5625 on epoch=699
06/22/2022 07:51:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
06/22/2022 07:51:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=709
06/22/2022 07:51:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 07:51:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/22/2022 07:51:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/22/2022 07:51:34 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5625 on epoch=724
06/22/2022 07:51:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 07:51:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=734
06/22/2022 07:51:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=739
06/22/2022 07:51:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/22/2022 07:51:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=749
06/22/2022 07:51:41 - INFO - __main__ - Global step 1500 Train loss 0.03 ACC 0.5625 on epoch=749
06/22/2022 07:51:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
06/22/2022 07:51:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/22/2022 07:51:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=764
06/22/2022 07:51:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/22/2022 07:51:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 07:51:47 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
06/22/2022 07:51:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/22/2022 07:51:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/22/2022 07:51:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 07:51:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 07:51:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/22/2022 07:51:54 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.59375 on epoch=799
06/22/2022 07:51:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/22/2022 07:51:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/22/2022 07:51:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
06/22/2022 07:51:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
06/22/2022 07:52:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/22/2022 07:52:01 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
06/22/2022 07:52:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/22/2022 07:52:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=834
06/22/2022 07:52:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/22/2022 07:52:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=844
06/22/2022 07:52:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/22/2022 07:52:07 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.5625 on epoch=849
06/22/2022 07:52:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 07:52:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/22/2022 07:52:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 07:52:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
06/22/2022 07:52:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 07:52:14 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.53125 on epoch=874
06/22/2022 07:52:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/22/2022 07:52:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/22/2022 07:52:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
06/22/2022 07:52:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=894
06/22/2022 07:52:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 07:52:21 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.5 on epoch=899
06/22/2022 07:52:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/22/2022 07:52:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
06/22/2022 07:52:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/22/2022 07:52:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 07:52:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
06/22/2022 07:52:27 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.5 on epoch=924
06/22/2022 07:52:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/22/2022 07:52:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/22/2022 07:52:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 07:52:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 07:52:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/22/2022 07:52:34 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/22/2022 07:52:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/22/2022 07:52:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 07:52:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/22/2022 07:52:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
06/22/2022 07:52:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/22/2022 07:52:41 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.59375 on epoch=974
06/22/2022 07:52:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 07:52:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/22/2022 07:52:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/22/2022 07:52:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 07:52:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 07:52:47 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
06/22/2022 07:52:47 - INFO - __main__ - save last model!
06/22/2022 07:52:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 07:52:47 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 07:52:47 - INFO - __main__ - Printing 3 examples
06/22/2022 07:52:47 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 07:52:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:47 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 07:52:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:47 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 07:52:47 - INFO - __main__ - ['duplicate']
06/22/2022 07:52:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:52:48 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:52:48 - INFO - __main__ - Printing 3 examples
06/22/2022 07:52:48 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 07:52:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:48 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 07:52:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:48 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 07:52:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:52:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:52:48 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 07:52:48 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 07:52:48 - INFO - __main__ - Printing 3 examples
06/22/2022 07:52:48 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 07:52:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:48 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 07:52:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:48 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 07:52:48 - INFO - __main__ - ['not_duplicate']
06/22/2022 07:52:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 07:52:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:52:48 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 07:52:53 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 07:52:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 07:52:53 - INFO - __main__ - Starting training!
06/22/2022 07:53:05 - INFO - __main__ - Tokenizing Output ...
06/22/2022 07:53:46 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 08:06:40 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.2_8_predictions.txt
06/22/2022 08:06:40 - INFO - __main__ - ACC on test data: 0.5899
06/22/2022 08:06:40 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.5898837496908237
06/22/2022 08:06:40 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.5, bsz=8 ...
06/22/2022 08:06:41 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:06:41 - INFO - __main__ - Printing 3 examples
06/22/2022 08:06:41 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 08:06:41 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:06:41 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 08:06:41 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:06:41 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 08:06:41 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:06:41 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:06:41 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:06:41 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 08:06:41 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:06:41 - INFO - __main__ - Printing 3 examples
06/22/2022 08:06:41 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 08:06:41 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:06:41 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 08:06:41 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:06:41 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 08:06:41 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:06:41 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:06:41 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:06:41 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 08:06:47 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 08:06:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 08:06:47 - INFO - __main__ - Starting training!
06/22/2022 08:06:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.78 on epoch=4
06/22/2022 08:06:50 - INFO - __main__ - Step 20 Global step 20 Train loss 3.59 on epoch=9
06/22/2022 08:06:51 - INFO - __main__ - Step 30 Global step 30 Train loss 2.45 on epoch=14
06/22/2022 08:06:52 - INFO - __main__ - Step 40 Global step 40 Train loss 1.62 on epoch=19
06/22/2022 08:06:53 - INFO - __main__ - Step 50 Global step 50 Train loss 1.03 on epoch=24
06/22/2022 08:06:54 - INFO - __main__ - Global step 50 Train loss 2.89 ACC 0.5 on epoch=24
06/22/2022 08:06:54 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 08:06:55 - INFO - __main__ - Step 60 Global step 60 Train loss 0.73 on epoch=29
06/22/2022 08:06:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.56 on epoch=34
06/22/2022 08:06:57 - INFO - __main__ - Step 80 Global step 80 Train loss 0.43 on epoch=39
06/22/2022 08:06:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=44
06/22/2022 08:07:00 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
06/22/2022 08:07:00 - INFO - __main__ - Global step 100 Train loss 0.50 ACC 0.5 on epoch=49
06/22/2022 08:07:02 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=54
06/22/2022 08:07:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=59
06/22/2022 08:07:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
06/22/2022 08:07:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=69
06/22/2022 08:07:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
06/22/2022 08:07:07 - INFO - __main__ - Global step 150 Train loss 0.30 ACC 0.5 on epoch=74
06/22/2022 08:07:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.28 on epoch=79
06/22/2022 08:07:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=84
06/22/2022 08:07:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
06/22/2022 08:07:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.19 on epoch=94
06/22/2022 08:07:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=99
06/22/2022 08:07:13 - INFO - __main__ - Global step 200 Train loss 0.24 ACC 0.5 on epoch=99
06/22/2022 08:07:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.26 on epoch=104
06/22/2022 08:07:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.19 on epoch=109
06/22/2022 08:07:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=114
06/22/2022 08:07:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.20 on epoch=119
06/22/2022 08:07:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=124
06/22/2022 08:07:20 - INFO - __main__ - Global step 250 Train loss 0.22 ACC 0.53125 on epoch=124
06/22/2022 08:07:20 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=124, global_step=250
06/22/2022 08:07:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.18 on epoch=129
06/22/2022 08:07:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.20 on epoch=134
06/22/2022 08:07:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=139
06/22/2022 08:07:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.20 on epoch=144
06/22/2022 08:07:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=149
06/22/2022 08:07:27 - INFO - __main__ - Global step 300 Train loss 0.19 ACC 0.6875 on epoch=149
06/22/2022 08:07:27 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.6875 on epoch=149, global_step=300
06/22/2022 08:07:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.18 on epoch=154
06/22/2022 08:07:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=159
06/22/2022 08:07:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
06/22/2022 08:07:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.12 on epoch=169
06/22/2022 08:07:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.14 on epoch=174
06/22/2022 08:07:33 - INFO - __main__ - Global step 350 Train loss 0.15 ACC 0.65625 on epoch=174
06/22/2022 08:07:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.14 on epoch=179
06/22/2022 08:07:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
06/22/2022 08:07:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.09 on epoch=189
06/22/2022 08:07:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=194
06/22/2022 08:07:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
06/22/2022 08:07:40 - INFO - __main__ - Global step 400 Train loss 0.10 ACC 0.53125 on epoch=199
06/22/2022 08:07:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
06/22/2022 08:07:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=209
06/22/2022 08:07:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=214
06/22/2022 08:07:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
06/22/2022 08:07:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
06/22/2022 08:07:47 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.53125 on epoch=224
06/22/2022 08:07:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
06/22/2022 08:07:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
06/22/2022 08:07:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=239
06/22/2022 08:07:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
06/22/2022 08:07:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
06/22/2022 08:07:53 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.59375 on epoch=249
06/22/2022 08:07:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
06/22/2022 08:07:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
06/22/2022 08:07:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
06/22/2022 08:07:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
06/22/2022 08:07:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
06/22/2022 08:08:00 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.5625 on epoch=274
06/22/2022 08:08:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
06/22/2022 08:08:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
06/22/2022 08:08:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
06/22/2022 08:08:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
06/22/2022 08:08:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
06/22/2022 08:08:07 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.53125 on epoch=299
06/22/2022 08:08:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/22/2022 08:08:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
06/22/2022 08:08:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
06/22/2022 08:08:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
06/22/2022 08:08:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
06/22/2022 08:08:13 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.46875 on epoch=324
06/22/2022 08:08:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
06/22/2022 08:08:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
06/22/2022 08:08:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/22/2022 08:08:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
06/22/2022 08:08:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/22/2022 08:08:20 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.46875 on epoch=349
06/22/2022 08:08:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/22/2022 08:08:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/22/2022 08:08:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
06/22/2022 08:08:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/22/2022 08:08:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
06/22/2022 08:08:26 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.46875 on epoch=374
06/22/2022 08:08:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/22/2022 08:08:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
06/22/2022 08:08:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
06/22/2022 08:08:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/22/2022 08:08:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
06/22/2022 08:08:33 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.53125 on epoch=399
06/22/2022 08:08:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/22/2022 08:08:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/22/2022 08:08:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
06/22/2022 08:08:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
06/22/2022 08:08:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/22/2022 08:08:40 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.40625 on epoch=424
06/22/2022 08:08:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/22/2022 08:08:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/22/2022 08:08:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/22/2022 08:08:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/22/2022 08:08:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/22/2022 08:08:46 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
06/22/2022 08:08:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
06/22/2022 08:08:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
06/22/2022 08:08:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/22/2022 08:08:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/22/2022 08:08:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/22/2022 08:08:53 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.53125 on epoch=474
06/22/2022 08:08:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/22/2022 08:08:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
06/22/2022 08:08:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
06/22/2022 08:08:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/22/2022 08:08:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/22/2022 08:09:00 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.53125 on epoch=499
06/22/2022 08:09:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
06/22/2022 08:09:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/22/2022 08:09:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
06/22/2022 08:09:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/22/2022 08:09:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/22/2022 08:09:06 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
06/22/2022 08:09:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
06/22/2022 08:09:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 08:09:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/22/2022 08:09:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/22/2022 08:09:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/22/2022 08:09:13 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.46875 on epoch=549
06/22/2022 08:09:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/22/2022 08:09:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/22/2022 08:09:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/22/2022 08:09:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
06/22/2022 08:09:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 08:09:20 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5 on epoch=574
06/22/2022 08:09:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 08:09:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/22/2022 08:09:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 08:09:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/22/2022 08:09:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 08:09:26 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.5625 on epoch=599
06/22/2022 08:09:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 08:09:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 08:09:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/22/2022 08:09:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 08:09:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 08:09:33 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.4375 on epoch=624
06/22/2022 08:09:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/22/2022 08:09:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 08:09:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/22/2022 08:09:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 08:09:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/22/2022 08:09:40 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.53125 on epoch=649
06/22/2022 08:09:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/22/2022 08:09:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=659
06/22/2022 08:09:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/22/2022 08:09:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 08:09:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/22/2022 08:09:46 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.46875 on epoch=674
06/22/2022 08:09:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/22/2022 08:09:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 08:09:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/22/2022 08:09:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/22/2022 08:09:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/22/2022 08:09:53 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5 on epoch=699
06/22/2022 08:09:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 08:09:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/22/2022 08:09:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/22/2022 08:09:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/22/2022 08:09:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 08:10:00 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.5 on epoch=724
06/22/2022 08:10:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 08:10:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 08:10:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 08:10:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/22/2022 08:10:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 08:10:06 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.5 on epoch=749
06/22/2022 08:10:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 08:10:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/22/2022 08:10:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 08:10:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 08:10:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 08:10:13 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
06/22/2022 08:10:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 08:10:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 08:10:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 08:10:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 08:10:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 08:10:20 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.53125 on epoch=799
06/22/2022 08:10:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 08:10:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 08:10:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 08:10:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 08:10:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 08:10:26 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.53125 on epoch=824
06/22/2022 08:10:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/22/2022 08:10:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 08:10:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 08:10:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/22/2022 08:10:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 08:10:33 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.5625 on epoch=849
06/22/2022 08:10:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/22/2022 08:10:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 08:10:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 08:10:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 08:10:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 08:10:40 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5 on epoch=874
06/22/2022 08:10:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 08:10:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 08:10:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 08:10:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 08:10:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 08:10:46 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.59375 on epoch=899
06/22/2022 08:10:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 08:10:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 08:10:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/22/2022 08:10:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 08:10:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/22/2022 08:10:53 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.53125 on epoch=924
06/22/2022 08:10:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/22/2022 08:10:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 08:10:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 08:10:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 08:10:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 08:11:00 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
06/22/2022 08:11:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 08:11:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 08:11:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 08:11:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 08:11:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/22/2022 08:11:06 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.53125 on epoch=974
06/22/2022 08:11:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 08:11:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 08:11:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 08:11:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 08:11:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 08:11:13 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5 on epoch=999
06/22/2022 08:11:13 - INFO - __main__ - save last model!
06/22/2022 08:11:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 08:11:13 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 08:11:13 - INFO - __main__ - Printing 3 examples
06/22/2022 08:11:13 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 08:11:13 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:13 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 08:11:13 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:13 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 08:11:13 - INFO - __main__ - ['duplicate']
06/22/2022 08:11:13 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:11:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:11:14 - INFO - __main__ - Printing 3 examples
06/22/2022 08:11:14 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 08:11:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:14 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 08:11:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:14 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 08:11:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:14 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:11:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:11:14 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 08:11:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:11:14 - INFO - __main__ - Printing 3 examples
06/22/2022 08:11:14 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 08:11:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:14 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 08:11:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:14 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 08:11:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:11:14 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:11:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:11:14 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 08:11:19 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 08:11:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 08:11:19 - INFO - __main__ - Starting training!
06/22/2022 08:11:31 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:12:12 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 08:25:13 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.5_8_predictions.txt
06/22/2022 08:25:14 - INFO - __main__ - ACC on test data: 0.5918
06/22/2022 08:25:14 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.5, bsz=8, dev_performance=0.6875, test_performance=0.591788276032649
06/22/2022 08:25:14 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.4, bsz=8 ...
06/22/2022 08:25:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:25:15 - INFO - __main__ - Printing 3 examples
06/22/2022 08:25:15 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 08:25:15 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:25:15 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 08:25:15 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:25:15 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 08:25:15 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:25:15 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:25:15 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:25:15 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 08:25:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:25:15 - INFO - __main__ - Printing 3 examples
06/22/2022 08:25:15 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 08:25:15 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:25:15 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 08:25:15 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:25:15 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 08:25:15 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:25:15 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:25:15 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:25:15 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 08:25:20 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 08:25:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 08:25:20 - INFO - __main__ - Starting training!
06/22/2022 08:25:22 - INFO - __main__ - Step 10 Global step 10 Train loss 5.64 on epoch=4
06/22/2022 08:25:23 - INFO - __main__ - Step 20 Global step 20 Train loss 4.00 on epoch=9
06/22/2022 08:25:24 - INFO - __main__ - Step 30 Global step 30 Train loss 2.82 on epoch=14
06/22/2022 08:25:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.90 on epoch=19
06/22/2022 08:25:27 - INFO - __main__ - Step 50 Global step 50 Train loss 1.41 on epoch=24
06/22/2022 08:25:27 - INFO - __main__ - Global step 50 Train loss 3.16 ACC 0.5 on epoch=24
06/22/2022 08:25:27 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 08:25:29 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=29
06/22/2022 08:25:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
06/22/2022 08:25:31 - INFO - __main__ - Step 80 Global step 80 Train loss 0.66 on epoch=39
06/22/2022 08:25:32 - INFO - __main__ - Step 90 Global step 90 Train loss 0.50 on epoch=44
06/22/2022 08:25:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
06/22/2022 08:25:34 - INFO - __main__ - Global step 100 Train loss 0.64 ACC 0.5 on epoch=49
06/22/2022 08:25:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.42 on epoch=54
06/22/2022 08:25:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=59
06/22/2022 08:25:38 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
06/22/2022 08:25:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
06/22/2022 08:25:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.34 on epoch=74
06/22/2022 08:25:41 - INFO - __main__ - Global step 150 Train loss 0.34 ACC 0.5 on epoch=74
06/22/2022 08:25:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=79
06/22/2022 08:25:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=84
06/22/2022 08:25:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.27 on epoch=89
06/22/2022 08:25:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=94
06/22/2022 08:25:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
06/22/2022 08:25:47 - INFO - __main__ - Global step 200 Train loss 0.29 ACC 0.5 on epoch=99
06/22/2022 08:25:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
06/22/2022 08:25:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
06/22/2022 08:25:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=114
06/22/2022 08:25:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=119
06/22/2022 08:25:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/22/2022 08:25:54 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.5 on epoch=124
06/22/2022 08:25:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=129
06/22/2022 08:25:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=134
06/22/2022 08:25:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=139
06/22/2022 08:25:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.18 on epoch=144
06/22/2022 08:26:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=149
06/22/2022 08:26:00 - INFO - __main__ - Global step 300 Train loss 0.22 ACC 0.5 on epoch=149
06/22/2022 08:26:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=154
06/22/2022 08:26:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
06/22/2022 08:26:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=164
06/22/2022 08:26:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=169
06/22/2022 08:26:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=174
06/22/2022 08:26:07 - INFO - __main__ - Global step 350 Train loss 0.18 ACC 0.625 on epoch=174
06/22/2022 08:26:07 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.625 on epoch=174, global_step=350
06/22/2022 08:26:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.13 on epoch=179
06/22/2022 08:26:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=184
06/22/2022 08:26:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.14 on epoch=189
06/22/2022 08:26:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=194
06/22/2022 08:26:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=199
06/22/2022 08:26:13 - INFO - __main__ - Global step 400 Train loss 0.15 ACC 0.59375 on epoch=199
06/22/2022 08:26:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=204
06/22/2022 08:26:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=209
06/22/2022 08:26:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=214
06/22/2022 08:26:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=219
06/22/2022 08:26:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=224
06/22/2022 08:26:20 - INFO - __main__ - Global step 450 Train loss 0.12 ACC 0.5625 on epoch=224
06/22/2022 08:26:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=229
06/22/2022 08:26:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=234
06/22/2022 08:26:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=239
06/22/2022 08:26:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=244
06/22/2022 08:26:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=249
06/22/2022 08:26:27 - INFO - __main__ - Global step 500 Train loss 0.11 ACC 0.5625 on epoch=249
06/22/2022 08:26:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=254
06/22/2022 08:26:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
06/22/2022 08:26:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
06/22/2022 08:26:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=269
06/22/2022 08:26:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
06/22/2022 08:26:33 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.6875 on epoch=274
06/22/2022 08:26:33 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=274, global_step=550
06/22/2022 08:26:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=279
06/22/2022 08:26:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
06/22/2022 08:26:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
06/22/2022 08:26:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/22/2022 08:26:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
06/22/2022 08:26:40 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.65625 on epoch=299
06/22/2022 08:26:41 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=304
06/22/2022 08:26:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
06/22/2022 08:26:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
06/22/2022 08:26:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=319
06/22/2022 08:26:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
06/22/2022 08:26:47 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.6875 on epoch=324
06/22/2022 08:26:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
06/22/2022 08:26:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/22/2022 08:26:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/22/2022 08:26:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
06/22/2022 08:26:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/22/2022 08:26:53 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.6875 on epoch=349
06/22/2022 08:26:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=354
06/22/2022 08:26:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=359
06/22/2022 08:26:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/22/2022 08:26:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
06/22/2022 08:26:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
06/22/2022 08:27:00 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.5625 on epoch=374
06/22/2022 08:27:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
06/22/2022 08:27:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
06/22/2022 08:27:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/22/2022 08:27:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
06/22/2022 08:27:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/22/2022 08:27:07 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.5625 on epoch=399
06/22/2022 08:27:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/22/2022 08:27:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/22/2022 08:27:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/22/2022 08:27:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
06/22/2022 08:27:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
06/22/2022 08:27:13 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.59375 on epoch=424
06/22/2022 08:27:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
06/22/2022 08:27:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
06/22/2022 08:27:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/22/2022 08:27:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/22/2022 08:27:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/22/2022 08:27:20 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.59375 on epoch=449
06/22/2022 08:27:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/22/2022 08:27:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/22/2022 08:27:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
06/22/2022 08:27:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/22/2022 08:27:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/22/2022 08:27:26 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.59375 on epoch=474
06/22/2022 08:27:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/22/2022 08:27:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
06/22/2022 08:27:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/22/2022 08:27:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/22/2022 08:27:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/22/2022 08:27:33 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
06/22/2022 08:27:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/22/2022 08:27:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/22/2022 08:27:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
06/22/2022 08:27:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/22/2022 08:27:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/22/2022 08:27:40 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5625 on epoch=524
06/22/2022 08:27:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/22/2022 08:27:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/22/2022 08:27:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/22/2022 08:27:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/22/2022 08:27:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/22/2022 08:27:47 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.59375 on epoch=549
06/22/2022 08:27:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/22/2022 08:27:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
06/22/2022 08:27:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 08:27:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/22/2022 08:27:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 08:27:53 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.65625 on epoch=574
06/22/2022 08:27:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 08:27:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/22/2022 08:27:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/22/2022 08:27:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/22/2022 08:27:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 08:28:00 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.59375 on epoch=599
06/22/2022 08:28:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/22/2022 08:28:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/22/2022 08:28:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 08:28:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 08:28:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 08:28:07 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.59375 on epoch=624
06/22/2022 08:28:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/22/2022 08:28:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/22/2022 08:28:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
06/22/2022 08:28:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 08:28:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 08:28:13 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.59375 on epoch=649
06/22/2022 08:28:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/22/2022 08:28:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/22/2022 08:28:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 08:28:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 08:28:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/22/2022 08:28:20 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.65625 on epoch=674
06/22/2022 08:28:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/22/2022 08:28:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 08:28:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/22/2022 08:28:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 08:28:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=699
06/22/2022 08:28:27 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.625 on epoch=699
06/22/2022 08:28:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/22/2022 08:28:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 08:28:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 08:28:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 08:28:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 08:28:33 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.5625 on epoch=724
06/22/2022 08:28:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 08:28:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 08:28:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/22/2022 08:28:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 08:28:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 08:28:40 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.625 on epoch=749
06/22/2022 08:28:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/22/2022 08:28:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 08:28:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 08:28:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 08:28:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 08:28:47 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
06/22/2022 08:28:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 08:28:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 08:28:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 08:28:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 08:28:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 08:28:53 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.59375 on epoch=799
06/22/2022 08:28:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 08:28:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 08:28:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 08:28:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 08:28:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 08:29:00 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.625 on epoch=824
06/22/2022 08:29:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 08:29:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 08:29:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 08:29:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 08:29:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 08:29:07 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.53125 on epoch=849
06/22/2022 08:29:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/22/2022 08:29:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 08:29:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 08:29:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/22/2022 08:29:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 08:29:13 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
06/22/2022 08:29:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 08:29:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 08:29:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 08:29:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 08:29:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 08:29:20 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/22/2022 08:29:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 08:29:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 08:29:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 08:29:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 08:29:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/22/2022 08:29:27 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.59375 on epoch=924
06/22/2022 08:29:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 08:29:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 08:29:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 08:29:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 08:29:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 08:29:33 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/22/2022 08:29:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 08:29:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 08:29:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 08:29:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=969
06/22/2022 08:29:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 08:29:40 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.625 on epoch=974
06/22/2022 08:29:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=979
06/22/2022 08:29:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 08:29:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 08:29:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 08:29:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/22/2022 08:29:47 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5625 on epoch=999
06/22/2022 08:29:47 - INFO - __main__ - save last model!
06/22/2022 08:29:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 08:29:47 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 08:29:47 - INFO - __main__ - Printing 3 examples
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 08:29:47 - INFO - __main__ - ['duplicate']
06/22/2022 08:29:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:29:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:29:47 - INFO - __main__ - Printing 3 examples
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:29:47 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:29:47 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 08:29:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:29:47 - INFO - __main__ - Printing 3 examples
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 08:29:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:29:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:29:47 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:29:47 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 08:29:52 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 08:29:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 08:29:53 - INFO - __main__ - Starting training!
06/22/2022 08:30:05 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:30:46 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 08:43:45 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.4_8_predictions.txt
06/22/2022 08:43:46 - INFO - __main__ - ACC on test data: 0.5624
06/22/2022 08:43:46 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.4, bsz=8, dev_performance=0.6875, test_performance=0.5624288894385358
06/22/2022 08:43:46 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.3, bsz=8 ...
06/22/2022 08:43:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:43:47 - INFO - __main__ - Printing 3 examples
06/22/2022 08:43:47 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 08:43:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:43:47 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 08:43:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:43:47 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 08:43:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:43:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:43:47 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:43:47 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 08:43:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:43:47 - INFO - __main__ - Printing 3 examples
06/22/2022 08:43:47 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 08:43:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:43:47 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 08:43:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:43:47 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 08:43:47 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:43:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:43:47 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:43:47 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 08:43:52 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 08:43:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 08:43:52 - INFO - __main__ - Starting training!
06/22/2022 08:43:54 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=4
06/22/2022 08:43:55 - INFO - __main__ - Step 20 Global step 20 Train loss 4.70 on epoch=9
06/22/2022 08:43:56 - INFO - __main__ - Step 30 Global step 30 Train loss 3.68 on epoch=14
06/22/2022 08:43:58 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=19
06/22/2022 08:43:59 - INFO - __main__ - Step 50 Global step 50 Train loss 2.18 on epoch=24
06/22/2022 08:43:59 - INFO - __main__ - Global step 50 Train loss 4.00 ACC 0.0 on epoch=24
06/22/2022 08:43:59 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 08:44:01 - INFO - __main__ - Step 60 Global step 60 Train loss 1.59 on epoch=29
06/22/2022 08:44:02 - INFO - __main__ - Step 70 Global step 70 Train loss 1.25 on epoch=34
06/22/2022 08:44:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=39
06/22/2022 08:44:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.76 on epoch=44
06/22/2022 08:44:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=49
06/22/2022 08:44:06 - INFO - __main__ - Global step 100 Train loss 1.04 ACC 0.5 on epoch=49
06/22/2022 08:44:06 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 08:44:07 - INFO - __main__ - Step 110 Global step 110 Train loss 0.50 on epoch=54
06/22/2022 08:44:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=59
06/22/2022 08:44:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=64
06/22/2022 08:44:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.40 on epoch=69
06/22/2022 08:44:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.40 on epoch=74
06/22/2022 08:44:13 - INFO - __main__ - Global step 150 Train loss 0.44 ACC 0.5 on epoch=74
06/22/2022 08:44:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.37 on epoch=79
06/22/2022 08:44:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/22/2022 08:44:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.32 on epoch=89
06/22/2022 08:44:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/22/2022 08:44:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.33 on epoch=99
06/22/2022 08:44:19 - INFO - __main__ - Global step 200 Train loss 0.34 ACC 0.5 on epoch=99
06/22/2022 08:44:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/22/2022 08:44:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=109
06/22/2022 08:44:23 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/22/2022 08:44:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=119
06/22/2022 08:44:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/22/2022 08:44:26 - INFO - __main__ - Global step 250 Train loss 0.31 ACC 0.5 on epoch=124
06/22/2022 08:44:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=129
06/22/2022 08:44:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/22/2022 08:44:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/22/2022 08:44:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/22/2022 08:44:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=149
06/22/2022 08:44:33 - INFO - __main__ - Global step 300 Train loss 0.27 ACC 0.5 on epoch=149
06/22/2022 08:44:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=154
06/22/2022 08:44:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=159
06/22/2022 08:44:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=164
06/22/2022 08:44:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=169
06/22/2022 08:44:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=174
06/22/2022 08:44:39 - INFO - __main__ - Global step 350 Train loss 0.23 ACC 0.46875 on epoch=174
06/22/2022 08:44:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/22/2022 08:44:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=184
06/22/2022 08:44:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/22/2022 08:44:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=194
06/22/2022 08:44:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=199
06/22/2022 08:44:46 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.46875 on epoch=199
06/22/2022 08:44:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/22/2022 08:44:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=209
06/22/2022 08:44:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=214
06/22/2022 08:44:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=219
06/22/2022 08:44:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=224
06/22/2022 08:44:52 - INFO - __main__ - Global step 450 Train loss 0.20 ACC 0.5 on epoch=224
06/22/2022 08:44:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
06/22/2022 08:44:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=234
06/22/2022 08:44:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=239
06/22/2022 08:44:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=244
06/22/2022 08:44:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=249
06/22/2022 08:44:59 - INFO - __main__ - Global step 500 Train loss 0.19 ACC 0.5 on epoch=249
06/22/2022 08:45:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=254
06/22/2022 08:45:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=259
06/22/2022 08:45:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=264
06/22/2022 08:45:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=269
06/22/2022 08:45:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=274
06/22/2022 08:45:06 - INFO - __main__ - Global step 550 Train loss 0.14 ACC 0.59375 on epoch=274
06/22/2022 08:45:06 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=274, global_step=550
06/22/2022 08:45:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/22/2022 08:45:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=284
06/22/2022 08:45:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=289
06/22/2022 08:45:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=294
06/22/2022 08:45:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=299
06/22/2022 08:45:12 - INFO - __main__ - Global step 600 Train loss 0.14 ACC 0.5625 on epoch=299
06/22/2022 08:45:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=304
06/22/2022 08:45:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=309
06/22/2022 08:45:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=314
06/22/2022 08:45:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=319
06/22/2022 08:45:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=324
06/22/2022 08:45:19 - INFO - __main__ - Global step 650 Train loss 0.11 ACC 0.53125 on epoch=324
06/22/2022 08:45:20 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=329
06/22/2022 08:45:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=334
06/22/2022 08:45:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=339
06/22/2022 08:45:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=344
06/22/2022 08:45:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
06/22/2022 08:45:25 - INFO - __main__ - Global step 700 Train loss 0.08 ACC 0.53125 on epoch=349
06/22/2022 08:45:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=354
06/22/2022 08:45:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=359
06/22/2022 08:45:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=364
06/22/2022 08:45:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
06/22/2022 08:45:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
06/22/2022 08:45:32 - INFO - __main__ - Global step 750 Train loss 0.06 ACC 0.5 on epoch=374
06/22/2022 08:45:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=379
06/22/2022 08:45:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=384
06/22/2022 08:45:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
06/22/2022 08:45:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/22/2022 08:45:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
06/22/2022 08:45:39 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.46875 on epoch=399
06/22/2022 08:45:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=404
06/22/2022 08:45:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
06/22/2022 08:45:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/22/2022 08:45:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/22/2022 08:45:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=424
06/22/2022 08:45:45 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.40625 on epoch=424
06/22/2022 08:45:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
06/22/2022 08:45:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
06/22/2022 08:45:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/22/2022 08:45:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
06/22/2022 08:45:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/22/2022 08:45:52 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.5 on epoch=449
06/22/2022 08:45:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=454
06/22/2022 08:45:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/22/2022 08:45:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
06/22/2022 08:45:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=469
06/22/2022 08:45:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/22/2022 08:45:59 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.5625 on epoch=474
06/22/2022 08:46:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/22/2022 08:46:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
06/22/2022 08:46:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/22/2022 08:46:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=494
06/22/2022 08:46:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/22/2022 08:46:05 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.4375 on epoch=499
06/22/2022 08:46:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/22/2022 08:46:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/22/2022 08:46:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
06/22/2022 08:46:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/22/2022 08:46:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/22/2022 08:46:12 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5 on epoch=524
06/22/2022 08:46:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
06/22/2022 08:46:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
06/22/2022 08:46:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/22/2022 08:46:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/22/2022 08:46:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/22/2022 08:46:18 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5 on epoch=549
06/22/2022 08:46:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
06/22/2022 08:46:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/22/2022 08:46:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
06/22/2022 08:46:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/22/2022 08:46:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 08:46:25 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.53125 on epoch=574
06/22/2022 08:46:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/22/2022 08:46:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/22/2022 08:46:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 08:46:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/22/2022 08:46:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/22/2022 08:46:32 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.46875 on epoch=599
06/22/2022 08:46:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/22/2022 08:46:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 08:46:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 08:46:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/22/2022 08:46:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/22/2022 08:46:38 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5 on epoch=624
06/22/2022 08:46:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/22/2022 08:46:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/22/2022 08:46:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
06/22/2022 08:46:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
06/22/2022 08:46:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
06/22/2022 08:46:45 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.46875 on epoch=649
06/22/2022 08:46:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 08:46:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/22/2022 08:46:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/22/2022 08:46:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/22/2022 08:46:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/22/2022 08:46:52 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.46875 on epoch=674
06/22/2022 08:46:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 08:46:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 08:46:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/22/2022 08:46:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/22/2022 08:46:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 08:46:58 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.4375 on epoch=699
06/22/2022 08:46:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/22/2022 08:47:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/22/2022 08:47:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 08:47:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/22/2022 08:47:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/22/2022 08:47:05 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.375 on epoch=724
06/22/2022 08:47:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/22/2022 08:47:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 08:47:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 08:47:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/22/2022 08:47:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 08:47:12 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.34375 on epoch=749
06/22/2022 08:47:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 08:47:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 08:47:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/22/2022 08:47:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 08:47:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 08:47:18 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.46875 on epoch=774
06/22/2022 08:47:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 08:47:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 08:47:22 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 08:47:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 08:47:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 08:47:25 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.46875 on epoch=799
06/22/2022 08:47:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 08:47:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 08:47:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 08:47:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
06/22/2022 08:47:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/22/2022 08:47:32 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5 on epoch=824
06/22/2022 08:47:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/22/2022 08:47:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 08:47:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 08:47:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 08:47:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 08:47:38 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.40625 on epoch=849
06/22/2022 08:47:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 08:47:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/22/2022 08:47:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 08:47:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/22/2022 08:47:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 08:47:45 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.4375 on epoch=874
06/22/2022 08:47:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 08:47:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 08:47:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 08:47:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 08:47:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 08:47:51 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.375 on epoch=899
06/22/2022 08:47:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 08:47:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 08:47:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 08:47:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 08:47:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 08:47:58 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5 on epoch=924
06/22/2022 08:47:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/22/2022 08:48:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 08:48:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 08:48:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 08:48:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 08:48:05 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
06/22/2022 08:48:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 08:48:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 08:48:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/22/2022 08:48:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 08:48:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=974
06/22/2022 08:48:11 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5 on epoch=974
06/22/2022 08:48:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 08:48:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/22/2022 08:48:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/22/2022 08:48:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 08:48:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=999
06/22/2022 08:48:18 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.4375 on epoch=999
06/22/2022 08:48:18 - INFO - __main__ - save last model!
06/22/2022 08:48:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 08:48:18 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 08:48:18 - INFO - __main__ - Printing 3 examples
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 08:48:18 - INFO - __main__ - ['duplicate']
06/22/2022 08:48:18 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:48:18 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:48:18 - INFO - __main__ - Printing 3 examples
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:48:18 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:48:18 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 08:48:18 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 08:48:18 - INFO - __main__ - Printing 3 examples
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 08:48:18 - INFO - __main__ - ['not_duplicate']
06/22/2022 08:48:18 - INFO - __main__ - Tokenizing Input ...
06/22/2022 08:48:18 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:48:19 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 08:48:24 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 08:48:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 08:48:24 - INFO - __main__ - Starting training!
06/22/2022 08:48:36 - INFO - __main__ - Tokenizing Output ...
06/22/2022 08:49:17 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 09:02:12 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.3_8_predictions.txt
06/22/2022 09:02:13 - INFO - __main__ - ACC on test data: 0.4599
06/22/2022 09:02:13 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.3, bsz=8, dev_performance=0.59375, test_performance=0.4598812762799901
06/22/2022 09:02:13 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.2, bsz=8 ...
06/22/2022 09:02:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:02:14 - INFO - __main__ - Printing 3 examples
06/22/2022 09:02:14 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/22/2022 09:02:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:02:14 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/22/2022 09:02:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:02:14 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/22/2022 09:02:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:02:14 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:02:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:02:14 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:02:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:02:14 - INFO - __main__ - Printing 3 examples
06/22/2022 09:02:14 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/22/2022 09:02:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:02:14 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/22/2022 09:02:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:02:14 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/22/2022 09:02:14 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:02:14 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:02:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:02:14 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:02:19 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:02:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:02:19 - INFO - __main__ - Starting training!
06/22/2022 09:02:21 - INFO - __main__ - Step 10 Global step 10 Train loss 6.46 on epoch=4
06/22/2022 09:02:22 - INFO - __main__ - Step 20 Global step 20 Train loss 5.29 on epoch=9
06/22/2022 09:02:23 - INFO - __main__ - Step 30 Global step 30 Train loss 4.46 on epoch=14
06/22/2022 09:02:24 - INFO - __main__ - Step 40 Global step 40 Train loss 3.78 on epoch=19
06/22/2022 09:02:26 - INFO - __main__ - Step 50 Global step 50 Train loss 3.17 on epoch=24
06/22/2022 09:02:26 - INFO - __main__ - Global step 50 Train loss 4.63 ACC 0.0 on epoch=24
06/22/2022 09:02:26 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 09:02:28 - INFO - __main__ - Step 60 Global step 60 Train loss 2.70 on epoch=29
06/22/2022 09:02:29 - INFO - __main__ - Step 70 Global step 70 Train loss 2.22 on epoch=34
06/22/2022 09:02:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.86 on epoch=39
06/22/2022 09:02:31 - INFO - __main__ - Step 90 Global step 90 Train loss 1.63 on epoch=44
06/22/2022 09:02:32 - INFO - __main__ - Step 100 Global step 100 Train loss 1.30 on epoch=49
06/22/2022 09:02:33 - INFO - __main__ - Global step 100 Train loss 1.94 ACC 0.5 on epoch=49
06/22/2022 09:02:33 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 09:02:34 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=54
06/22/2022 09:02:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=59
06/22/2022 09:02:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=64
06/22/2022 09:02:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=69
06/22/2022 09:02:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=74
06/22/2022 09:02:39 - INFO - __main__ - Global step 150 Train loss 0.79 ACC 0.5 on epoch=74
06/22/2022 09:02:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=79
06/22/2022 09:02:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=84
06/22/2022 09:02:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=89
06/22/2022 09:02:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=94
06/22/2022 09:02:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=99
06/22/2022 09:02:46 - INFO - __main__ - Global step 200 Train loss 0.47 ACC 0.5 on epoch=99
06/22/2022 09:02:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=104
06/22/2022 09:02:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=109
06/22/2022 09:02:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=114
06/22/2022 09:02:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=119
06/22/2022 09:02:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=124
06/22/2022 09:02:53 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.5 on epoch=124
06/22/2022 09:02:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=129
06/22/2022 09:02:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=134
06/22/2022 09:02:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=139
06/22/2022 09:02:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/22/2022 09:02:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=149
06/22/2022 09:02:59 - INFO - __main__ - Global step 300 Train loss 0.32 ACC 0.5 on epoch=149
06/22/2022 09:03:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/22/2022 09:03:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=159
06/22/2022 09:03:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/22/2022 09:03:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=169
06/22/2022 09:03:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=174
06/22/2022 09:03:06 - INFO - __main__ - Global step 350 Train loss 0.30 ACC 0.5 on epoch=174
06/22/2022 09:03:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=179
06/22/2022 09:03:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=184
06/22/2022 09:03:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=189
06/22/2022 09:03:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=194
06/22/2022 09:03:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=199
06/22/2022 09:03:12 - INFO - __main__ - Global step 400 Train loss 0.28 ACC 0.5 on epoch=199
06/22/2022 09:03:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/22/2022 09:03:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/22/2022 09:03:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/22/2022 09:03:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=219
06/22/2022 09:03:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=224
06/22/2022 09:03:19 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.5 on epoch=224
06/22/2022 09:03:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=229
06/22/2022 09:03:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=234
06/22/2022 09:03:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=239
06/22/2022 09:03:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=244
06/22/2022 09:03:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=249
06/22/2022 09:03:25 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/22/2022 09:03:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=254
06/22/2022 09:03:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=259
06/22/2022 09:03:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/22/2022 09:03:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=269
06/22/2022 09:03:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/22/2022 09:03:32 - INFO - __main__ - Global step 550 Train loss 0.23 ACC 0.5 on epoch=274
06/22/2022 09:03:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/22/2022 09:03:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=284
06/22/2022 09:03:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=289
06/22/2022 09:03:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=294
06/22/2022 09:03:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=299
06/22/2022 09:03:39 - INFO - __main__ - Global step 600 Train loss 0.20 ACC 0.53125 on epoch=299
06/22/2022 09:03:39 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=299, global_step=600
06/22/2022 09:03:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=304
06/22/2022 09:03:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=309
06/22/2022 09:03:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=314
06/22/2022 09:03:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=319
06/22/2022 09:03:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=324
06/22/2022 09:03:45 - INFO - __main__ - Global step 650 Train loss 0.20 ACC 0.625 on epoch=324
06/22/2022 09:03:45 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=324, global_step=650
06/22/2022 09:03:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=329
06/22/2022 09:03:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=334
06/22/2022 09:03:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=339
06/22/2022 09:03:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=344
06/22/2022 09:03:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=349
06/22/2022 09:03:52 - INFO - __main__ - Global step 700 Train loss 0.17 ACC 0.625 on epoch=349
06/22/2022 09:03:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=354
06/22/2022 09:03:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=359
06/22/2022 09:03:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=364
06/22/2022 09:03:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=369
06/22/2022 09:03:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=374
06/22/2022 09:03:58 - INFO - __main__ - Global step 750 Train loss 0.15 ACC 0.625 on epoch=374
06/22/2022 09:04:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=379
06/22/2022 09:04:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=384
06/22/2022 09:04:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=389
06/22/2022 09:04:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=394
06/22/2022 09:04:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=399
06/22/2022 09:04:05 - INFO - __main__ - Global step 800 Train loss 0.12 ACC 0.625 on epoch=399
06/22/2022 09:04:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=404
06/22/2022 09:04:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=409
06/22/2022 09:04:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=414
06/22/2022 09:04:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=419
06/22/2022 09:04:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=424
06/22/2022 09:04:12 - INFO - __main__ - Global step 850 Train loss 0.10 ACC 0.5625 on epoch=424
06/22/2022 09:04:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=429
06/22/2022 09:04:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=434
06/22/2022 09:04:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=439
06/22/2022 09:04:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=444
06/22/2022 09:04:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=449
06/22/2022 09:04:18 - INFO - __main__ - Global step 900 Train loss 0.09 ACC 0.59375 on epoch=449
06/22/2022 09:04:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=454
06/22/2022 09:04:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=459
06/22/2022 09:04:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=464
06/22/2022 09:04:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=469
06/22/2022 09:04:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=474
06/22/2022 09:04:25 - INFO - __main__ - Global step 950 Train loss 0.08 ACC 0.53125 on epoch=474
06/22/2022 09:04:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=479
06/22/2022 09:04:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
06/22/2022 09:04:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=489
06/22/2022 09:04:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=494
06/22/2022 09:04:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=499
06/22/2022 09:04:32 - INFO - __main__ - Global step 1000 Train loss 0.06 ACC 0.59375 on epoch=499
06/22/2022 09:04:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=504
06/22/2022 09:04:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=509
06/22/2022 09:04:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
06/22/2022 09:04:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=519
06/22/2022 09:04:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=524
06/22/2022 09:04:38 - INFO - __main__ - Global step 1050 Train loss 0.06 ACC 0.46875 on epoch=524
06/22/2022 09:04:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/22/2022 09:04:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
06/22/2022 09:04:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/22/2022 09:04:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=544
06/22/2022 09:04:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=549
06/22/2022 09:04:45 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.5 on epoch=549
06/22/2022 09:04:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
06/22/2022 09:04:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/22/2022 09:04:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
06/22/2022 09:04:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/22/2022 09:04:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
06/22/2022 09:04:52 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.5 on epoch=574
06/22/2022 09:04:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
06/22/2022 09:04:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/22/2022 09:04:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
06/22/2022 09:04:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
06/22/2022 09:04:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=599
06/22/2022 09:04:58 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.5 on epoch=599
06/22/2022 09:04:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/22/2022 09:05:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/22/2022 09:05:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
06/22/2022 09:05:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=619
06/22/2022 09:05:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/22/2022 09:05:05 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.5625 on epoch=624
06/22/2022 09:05:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=629
06/22/2022 09:05:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
06/22/2022 09:05:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/22/2022 09:05:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
06/22/2022 09:05:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
06/22/2022 09:05:12 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.5625 on epoch=649
06/22/2022 09:05:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=654
06/22/2022 09:05:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=659
06/22/2022 09:05:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/22/2022 09:05:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/22/2022 09:05:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/22/2022 09:05:18 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.53125 on epoch=674
06/22/2022 09:05:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 09:05:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/22/2022 09:05:22 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/22/2022 09:05:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/22/2022 09:05:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 09:05:25 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.53125 on epoch=699
06/22/2022 09:05:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
06/22/2022 09:05:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/22/2022 09:05:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 09:05:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=719
06/22/2022 09:05:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=724
06/22/2022 09:05:32 - INFO - __main__ - Global step 1450 Train loss 0.03 ACC 0.5 on epoch=724
06/22/2022 09:05:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/22/2022 09:05:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/22/2022 09:05:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
06/22/2022 09:05:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
06/22/2022 09:05:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/22/2022 09:05:38 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.46875 on epoch=749
06/22/2022 09:05:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=754
06/22/2022 09:05:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/22/2022 09:05:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/22/2022 09:05:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/22/2022 09:05:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 09:05:45 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.4375 on epoch=774
06/22/2022 09:05:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/22/2022 09:05:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
06/22/2022 09:05:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
06/22/2022 09:05:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=794
06/22/2022 09:05:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
06/22/2022 09:05:52 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.5 on epoch=799
06/22/2022 09:05:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
06/22/2022 09:05:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/22/2022 09:05:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=814
06/22/2022 09:05:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 09:05:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/22/2022 09:05:58 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.46875 on epoch=824
06/22/2022 09:06:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/22/2022 09:06:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 09:06:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/22/2022 09:06:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/22/2022 09:06:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/22/2022 09:06:05 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.46875 on epoch=849
06/22/2022 09:06:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=854
06/22/2022 09:06:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/22/2022 09:06:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 09:06:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
06/22/2022 09:06:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/22/2022 09:06:12 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.4375 on epoch=874
06/22/2022 09:06:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/22/2022 09:06:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/22/2022 09:06:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 09:06:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 09:06:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 09:06:18 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.46875 on epoch=899
06/22/2022 09:06:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/22/2022 09:06:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/22/2022 09:06:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/22/2022 09:06:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 09:06:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 09:06:25 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.46875 on epoch=924
06/22/2022 09:06:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/22/2022 09:06:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
06/22/2022 09:06:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 09:06:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 09:06:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=949
06/22/2022 09:06:32 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
06/22/2022 09:06:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/22/2022 09:06:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
06/22/2022 09:06:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/22/2022 09:06:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 09:06:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 09:06:38 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.46875 on epoch=974
06/22/2022 09:06:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 09:06:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/22/2022 09:06:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/22/2022 09:06:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/22/2022 09:06:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/22/2022 09:06:45 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.40625 on epoch=999
06/22/2022 09:06:45 - INFO - __main__ - save last model!
06/22/2022 09:06:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 09:06:45 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 09:06:45 - INFO - __main__ - Printing 3 examples
06/22/2022 09:06:45 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 09:06:45 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:06:45 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 09:06:45 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:06:45 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 09:06:45 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:45 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:06:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:06:45 - INFO - __main__ - Printing 3 examples
06/22/2022 09:06:45 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 09:06:45 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:45 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 09:06:45 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:45 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 09:06:45 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:45 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:06:45 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:06:46 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:06:46 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:06:46 - INFO - __main__ - Printing 3 examples
06/22/2022 09:06:46 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 09:06:46 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:46 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 09:06:46 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:46 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 09:06:46 - INFO - __main__ - ['duplicate']
06/22/2022 09:06:46 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:06:46 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:06:46 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:06:51 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:06:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:06:51 - INFO - __main__ - Starting training!
06/22/2022 09:07:03 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:07:44 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 09:20:31 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.2_8_predictions.txt
06/22/2022 09:20:31 - INFO - __main__ - ACC on test data: 0.4470
06/22/2022 09:20:32 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.44704427405392033
06/22/2022 09:20:32 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.5, bsz=8 ...
06/22/2022 09:20:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:20:33 - INFO - __main__ - Printing 3 examples
06/22/2022 09:20:33 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 09:20:33 - INFO - __main__ - ['duplicate']
06/22/2022 09:20:33 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 09:20:33 - INFO - __main__ - ['duplicate']
06/22/2022 09:20:33 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 09:20:33 - INFO - __main__ - ['duplicate']
06/22/2022 09:20:33 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:20:33 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:20:33 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:20:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:20:33 - INFO - __main__ - Printing 3 examples
06/22/2022 09:20:33 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 09:20:33 - INFO - __main__ - ['duplicate']
06/22/2022 09:20:33 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 09:20:33 - INFO - __main__ - ['duplicate']
06/22/2022 09:20:33 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 09:20:33 - INFO - __main__ - ['duplicate']
06/22/2022 09:20:33 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:20:33 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:20:33 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:20:38 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:20:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:20:38 - INFO - __main__ - Starting training!
06/22/2022 09:20:40 - INFO - __main__ - Step 10 Global step 10 Train loss 5.84 on epoch=4
06/22/2022 09:20:41 - INFO - __main__ - Step 20 Global step 20 Train loss 3.85 on epoch=9
06/22/2022 09:20:42 - INFO - __main__ - Step 30 Global step 30 Train loss 2.51 on epoch=14
06/22/2022 09:20:43 - INFO - __main__ - Step 40 Global step 40 Train loss 1.61 on epoch=19
06/22/2022 09:20:45 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=24
06/22/2022 09:20:45 - INFO - __main__ - Global step 50 Train loss 2.97 ACC 0.5 on epoch=24
06/22/2022 09:20:45 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 09:20:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.66 on epoch=29
06/22/2022 09:20:48 - INFO - __main__ - Step 70 Global step 70 Train loss 0.49 on epoch=34
06/22/2022 09:20:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.49 on epoch=39
06/22/2022 09:20:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.46 on epoch=44
06/22/2022 09:20:51 - INFO - __main__ - Step 100 Global step 100 Train loss 0.38 on epoch=49
06/22/2022 09:20:52 - INFO - __main__ - Global step 100 Train loss 0.49 ACC 0.5 on epoch=49
06/22/2022 09:20:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=54
06/22/2022 09:20:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
06/22/2022 09:20:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.39 on epoch=64
06/22/2022 09:20:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
06/22/2022 09:20:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.36 on epoch=74
06/22/2022 09:20:58 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.5 on epoch=74
06/22/2022 09:21:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.34 on epoch=79
06/22/2022 09:21:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=84
06/22/2022 09:21:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=89
06/22/2022 09:21:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/22/2022 09:21:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=99
06/22/2022 09:21:05 - INFO - __main__ - Global step 200 Train loss 0.32 ACC 0.5 on epoch=99
06/22/2022 09:21:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=104
06/22/2022 09:21:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=109
06/22/2022 09:21:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=114
06/22/2022 09:21:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/22/2022 09:21:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=124
06/22/2022 09:21:11 - INFO - __main__ - Global step 250 Train loss 0.30 ACC 0.5 on epoch=124
06/22/2022 09:21:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/22/2022 09:21:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/22/2022 09:21:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=139
06/22/2022 09:21:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=144
06/22/2022 09:21:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/22/2022 09:21:18 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.53125 on epoch=149
06/22/2022 09:21:18 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=149, global_step=300
06/22/2022 09:21:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/22/2022 09:21:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/22/2022 09:21:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=164
06/22/2022 09:21:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=169
06/22/2022 09:21:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=174
06/22/2022 09:21:25 - INFO - __main__ - Global step 350 Train loss 0.20 ACC 0.6875 on epoch=174
06/22/2022 09:21:25 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.6875 on epoch=174, global_step=350
06/22/2022 09:21:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=179
06/22/2022 09:21:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=184
06/22/2022 09:21:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=189
06/22/2022 09:21:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=194
06/22/2022 09:21:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
06/22/2022 09:21:31 - INFO - __main__ - Global step 400 Train loss 0.13 ACC 0.625 on epoch=199
06/22/2022 09:21:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=204
06/22/2022 09:21:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=209
06/22/2022 09:21:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
06/22/2022 09:21:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=219
06/22/2022 09:21:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=224
06/22/2022 09:21:38 - INFO - __main__ - Global step 450 Train loss 0.09 ACC 0.65625 on epoch=224
06/22/2022 09:21:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
06/22/2022 09:21:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=234
06/22/2022 09:21:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
06/22/2022 09:21:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
06/22/2022 09:21:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
06/22/2022 09:21:45 - INFO - __main__ - Global step 500 Train loss 0.06 ACC 0.5625 on epoch=249
06/22/2022 09:21:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
06/22/2022 09:21:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
06/22/2022 09:21:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
06/22/2022 09:21:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
06/22/2022 09:21:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
06/22/2022 09:21:51 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.5625 on epoch=274
06/22/2022 09:21:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
06/22/2022 09:21:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
06/22/2022 09:21:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
06/22/2022 09:21:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
06/22/2022 09:21:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
06/22/2022 09:21:58 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.5625 on epoch=299
06/22/2022 09:21:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/22/2022 09:22:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
06/22/2022 09:22:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
06/22/2022 09:22:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
06/22/2022 09:22:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
06/22/2022 09:22:05 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.53125 on epoch=324
06/22/2022 09:22:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
06/22/2022 09:22:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/22/2022 09:22:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
06/22/2022 09:22:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
06/22/2022 09:22:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/22/2022 09:22:12 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.5625 on epoch=349
06/22/2022 09:22:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.00 on epoch=354
06/22/2022 09:22:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/22/2022 09:22:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=364
06/22/2022 09:22:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/22/2022 09:22:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
06/22/2022 09:22:19 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5 on epoch=374
06/22/2022 09:22:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/22/2022 09:22:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
06/22/2022 09:22:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=389
06/22/2022 09:22:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
06/22/2022 09:22:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/22/2022 09:22:25 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.53125 on epoch=399
06/22/2022 09:22:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
06/22/2022 09:22:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/22/2022 09:22:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
06/22/2022 09:22:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
06/22/2022 09:22:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/22/2022 09:22:32 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.53125 on epoch=424
06/22/2022 09:22:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
06/22/2022 09:22:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
06/22/2022 09:22:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
06/22/2022 09:22:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=444
06/22/2022 09:22:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/22/2022 09:22:39 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.46875 on epoch=449
06/22/2022 09:22:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
06/22/2022 09:22:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/22/2022 09:22:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
06/22/2022 09:22:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
06/22/2022 09:22:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
06/22/2022 09:22:45 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.5 on epoch=474
06/22/2022 09:22:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
06/22/2022 09:22:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
06/22/2022 09:22:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/22/2022 09:22:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/22/2022 09:22:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/22/2022 09:22:52 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.625 on epoch=499
06/22/2022 09:22:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/22/2022 09:22:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
06/22/2022 09:22:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
06/22/2022 09:22:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/22/2022 09:22:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
06/22/2022 09:22:59 - INFO - __main__ - Global step 1050 Train loss 0.00 ACC 0.59375 on epoch=524
06/22/2022 09:23:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
06/22/2022 09:23:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 09:23:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/22/2022 09:23:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/22/2022 09:23:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/22/2022 09:23:05 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.65625 on epoch=549
06/22/2022 09:23:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/22/2022 09:23:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/22/2022 09:23:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 09:23:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/22/2022 09:23:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
06/22/2022 09:23:12 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.59375 on epoch=574
06/22/2022 09:23:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 09:23:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/22/2022 09:23:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
06/22/2022 09:23:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/22/2022 09:23:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 09:23:18 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.625 on epoch=599
06/22/2022 09:23:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 09:23:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 09:23:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/22/2022 09:23:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/22/2022 09:23:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/22/2022 09:23:25 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.625 on epoch=624
06/22/2022 09:23:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/22/2022 09:23:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 09:23:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/22/2022 09:23:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 09:23:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 09:23:32 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
06/22/2022 09:23:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/22/2022 09:23:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/22/2022 09:23:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 09:23:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 09:23:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/22/2022 09:23:38 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.625 on epoch=674
06/22/2022 09:23:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
06/22/2022 09:23:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 09:23:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/22/2022 09:23:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 09:23:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/22/2022 09:23:45 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.65625 on epoch=699
06/22/2022 09:23:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 09:23:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 09:23:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/22/2022 09:23:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 09:23:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/22/2022 09:23:52 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.59375 on epoch=724
06/22/2022 09:23:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 09:23:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 09:23:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 09:23:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/22/2022 09:23:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 09:23:58 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.59375 on epoch=749
06/22/2022 09:23:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/22/2022 09:24:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/22/2022 09:24:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/22/2022 09:24:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 09:24:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 09:24:05 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.71875 on epoch=774
06/22/2022 09:24:05 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=774, global_step=1550
06/22/2022 09:24:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 09:24:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 09:24:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 09:24:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 09:24:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 09:24:12 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.625 on epoch=799
06/22/2022 09:24:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 09:24:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 09:24:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 09:24:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 09:24:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/22/2022 09:24:18 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.71875 on epoch=824
06/22/2022 09:24:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 09:24:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 09:24:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 09:24:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 09:24:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 09:24:25 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.71875 on epoch=849
06/22/2022 09:24:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 09:24:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 09:24:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 09:24:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 09:24:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 09:24:32 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.6875 on epoch=874
06/22/2022 09:24:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 09:24:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 09:24:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 09:24:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 09:24:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 09:24:38 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.65625 on epoch=899
06/22/2022 09:24:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 09:24:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 09:24:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 09:24:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 09:24:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 09:24:45 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.65625 on epoch=924
06/22/2022 09:24:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 09:24:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 09:24:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 09:24:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 09:24:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 09:24:52 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.6875 on epoch=949
06/22/2022 09:24:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 09:24:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 09:24:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 09:24:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 09:24:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 09:24:58 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.6875 on epoch=974
06/22/2022 09:24:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 09:25:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 09:25:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 09:25:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 09:25:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 09:25:05 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.625 on epoch=999
06/22/2022 09:25:05 - INFO - __main__ - save last model!
06/22/2022 09:25:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 09:25:05 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 09:25:05 - INFO - __main__ - Printing 3 examples
06/22/2022 09:25:05 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 09:25:05 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:25:05 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 09:25:05 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:25:05 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 09:25:05 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:05 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:25:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:25:05 - INFO - __main__ - Printing 3 examples
06/22/2022 09:25:05 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 09:25:05 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:05 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 09:25:05 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:05 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 09:25:05 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:05 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:25:05 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:25:06 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:25:06 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:25:06 - INFO - __main__ - Printing 3 examples
06/22/2022 09:25:06 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 09:25:06 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:06 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 09:25:06 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:06 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 09:25:06 - INFO - __main__ - ['duplicate']
06/22/2022 09:25:06 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:25:06 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:25:06 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:25:11 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:25:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:25:11 - INFO - __main__ - Starting training!
06/22/2022 09:25:23 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:26:04 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 09:38:48 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.5_8_predictions.txt
06/22/2022 09:38:49 - INFO - __main__ - ACC on test data: 0.5482
06/22/2022 09:38:49 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.5, bsz=8, dev_performance=0.71875, test_performance=0.5481573089290132
06/22/2022 09:38:49 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.4, bsz=8 ...
06/22/2022 09:38:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:38:50 - INFO - __main__ - Printing 3 examples
06/22/2022 09:38:50 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 09:38:50 - INFO - __main__ - ['duplicate']
06/22/2022 09:38:50 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 09:38:50 - INFO - __main__ - ['duplicate']
06/22/2022 09:38:50 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 09:38:50 - INFO - __main__ - ['duplicate']
06/22/2022 09:38:50 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:38:50 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:38:50 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:38:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:38:50 - INFO - __main__ - Printing 3 examples
06/22/2022 09:38:50 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 09:38:50 - INFO - __main__ - ['duplicate']
06/22/2022 09:38:50 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 09:38:50 - INFO - __main__ - ['duplicate']
06/22/2022 09:38:50 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 09:38:50 - INFO - __main__ - ['duplicate']
06/22/2022 09:38:50 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:38:50 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:38:50 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:38:55 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:38:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:38:55 - INFO - __main__ - Starting training!
06/22/2022 09:38:57 - INFO - __main__ - Step 10 Global step 10 Train loss 5.99 on epoch=4
06/22/2022 09:38:58 - INFO - __main__ - Step 20 Global step 20 Train loss 4.28 on epoch=9
06/22/2022 09:38:59 - INFO - __main__ - Step 30 Global step 30 Train loss 2.92 on epoch=14
06/22/2022 09:39:00 - INFO - __main__ - Step 40 Global step 40 Train loss 2.09 on epoch=19
06/22/2022 09:39:02 - INFO - __main__ - Step 50 Global step 50 Train loss 1.40 on epoch=24
06/22/2022 09:39:02 - INFO - __main__ - Global step 50 Train loss 3.33 ACC 0.5 on epoch=24
06/22/2022 09:39:02 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 09:39:03 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=29
06/22/2022 09:39:05 - INFO - __main__ - Step 70 Global step 70 Train loss 0.72 on epoch=34
06/22/2022 09:39:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.59 on epoch=39
06/22/2022 09:39:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.47 on epoch=44
06/22/2022 09:39:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.44 on epoch=49
06/22/2022 09:39:09 - INFO - __main__ - Global step 100 Train loss 0.62 ACC 0.5 on epoch=49
06/22/2022 09:39:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=54
06/22/2022 09:39:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.49 on epoch=59
06/22/2022 09:39:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/22/2022 09:39:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.34 on epoch=69
06/22/2022 09:39:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.38 on epoch=74
06/22/2022 09:39:15 - INFO - __main__ - Global step 150 Train loss 0.38 ACC 0.5 on epoch=74
06/22/2022 09:39:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.39 on epoch=79
06/22/2022 09:39:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/22/2022 09:39:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=89
06/22/2022 09:39:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.30 on epoch=94
06/22/2022 09:39:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=99
06/22/2022 09:39:22 - INFO - __main__ - Global step 200 Train loss 0.35 ACC 0.5 on epoch=99
06/22/2022 09:39:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.30 on epoch=104
06/22/2022 09:39:24 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=109
06/22/2022 09:39:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.31 on epoch=114
06/22/2022 09:39:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=119
06/22/2022 09:39:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=124
06/22/2022 09:39:28 - INFO - __main__ - Global step 250 Train loss 0.33 ACC 0.5 on epoch=124
06/22/2022 09:39:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=129
06/22/2022 09:39:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=134
06/22/2022 09:39:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=139
06/22/2022 09:39:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=144
06/22/2022 09:39:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=149
06/22/2022 09:39:35 - INFO - __main__ - Global step 300 Train loss 0.30 ACC 0.5 on epoch=149
06/22/2022 09:39:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/22/2022 09:39:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=159
06/22/2022 09:39:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=164
06/22/2022 09:39:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=169
06/22/2022 09:39:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=174
06/22/2022 09:39:42 - INFO - __main__ - Global step 350 Train loss 0.22 ACC 0.53125 on epoch=174
06/22/2022 09:39:42 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/22/2022 09:39:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=179
06/22/2022 09:39:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=184
06/22/2022 09:39:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=189
06/22/2022 09:39:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=194
06/22/2022 09:39:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=199
06/22/2022 09:39:48 - INFO - __main__ - Global step 400 Train loss 0.19 ACC 0.59375 on epoch=199
06/22/2022 09:39:48 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=199, global_step=400
06/22/2022 09:39:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=204
06/22/2022 09:39:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=209
06/22/2022 09:39:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=214
06/22/2022 09:39:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=219
06/22/2022 09:39:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=224
06/22/2022 09:39:55 - INFO - __main__ - Global step 450 Train loss 0.14 ACC 0.625 on epoch=224
06/22/2022 09:39:55 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=224, global_step=450
06/22/2022 09:39:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=229
06/22/2022 09:39:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
06/22/2022 09:39:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=239
06/22/2022 09:40:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
06/22/2022 09:40:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=249
06/22/2022 09:40:02 - INFO - __main__ - Global step 500 Train loss 0.09 ACC 0.5 on epoch=249
06/22/2022 09:40:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.09 on epoch=254
06/22/2022 09:40:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
06/22/2022 09:40:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=264
06/22/2022 09:40:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=269
06/22/2022 09:40:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
06/22/2022 09:40:08 - INFO - __main__ - Global step 550 Train loss 0.09 ACC 0.59375 on epoch=274
06/22/2022 09:40:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
06/22/2022 09:40:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
06/22/2022 09:40:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
06/22/2022 09:40:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=294
06/22/2022 09:40:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=299
06/22/2022 09:40:15 - INFO - __main__ - Global step 600 Train loss 0.05 ACC 0.625 on epoch=299
06/22/2022 09:40:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/22/2022 09:40:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
06/22/2022 09:40:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
06/22/2022 09:40:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
06/22/2022 09:40:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/22/2022 09:40:22 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.625 on epoch=324
06/22/2022 09:40:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
06/22/2022 09:40:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/22/2022 09:40:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
06/22/2022 09:40:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
06/22/2022 09:40:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
06/22/2022 09:40:28 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.53125 on epoch=349
06/22/2022 09:40:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
06/22/2022 09:40:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
06/22/2022 09:40:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
06/22/2022 09:40:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/22/2022 09:40:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
06/22/2022 09:40:35 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5 on epoch=374
06/22/2022 09:40:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/22/2022 09:40:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
06/22/2022 09:40:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/22/2022 09:40:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/22/2022 09:40:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/22/2022 09:40:41 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.625 on epoch=399
06/22/2022 09:40:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
06/22/2022 09:40:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/22/2022 09:40:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
06/22/2022 09:40:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/22/2022 09:40:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
06/22/2022 09:40:48 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.5 on epoch=424
06/22/2022 09:40:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
06/22/2022 09:40:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/22/2022 09:40:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/22/2022 09:40:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
06/22/2022 09:40:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/22/2022 09:40:55 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.6875 on epoch=449
06/22/2022 09:40:55 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=449, global_step=900
06/22/2022 09:40:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/22/2022 09:40:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/22/2022 09:40:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/22/2022 09:41:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/22/2022 09:41:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/22/2022 09:41:01 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.59375 on epoch=474
06/22/2022 09:41:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/22/2022 09:41:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/22/2022 09:41:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/22/2022 09:41:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=494
06/22/2022 09:41:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/22/2022 09:41:08 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.625 on epoch=499
06/22/2022 09:41:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/22/2022 09:41:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/22/2022 09:41:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 09:41:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/22/2022 09:41:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=524
06/22/2022 09:41:15 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5625 on epoch=524
06/22/2022 09:41:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/22/2022 09:41:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/22/2022 09:41:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/22/2022 09:41:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
06/22/2022 09:41:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/22/2022 09:41:21 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5625 on epoch=549
06/22/2022 09:41:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/22/2022 09:41:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/22/2022 09:41:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 09:41:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/22/2022 09:41:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/22/2022 09:41:28 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.6875 on epoch=574
06/22/2022 09:41:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 09:41:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/22/2022 09:41:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 09:41:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/22/2022 09:41:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 09:41:35 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.59375 on epoch=599
06/22/2022 09:41:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 09:41:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 09:41:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/22/2022 09:41:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/22/2022 09:41:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 09:41:41 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.6875 on epoch=624
06/22/2022 09:41:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/22/2022 09:41:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 09:41:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/22/2022 09:41:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 09:41:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 09:41:48 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
06/22/2022 09:41:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/22/2022 09:41:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/22/2022 09:41:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=664
06/22/2022 09:41:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 09:41:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/22/2022 09:41:55 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.625 on epoch=674
06/22/2022 09:41:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 09:41:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 09:41:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/22/2022 09:41:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 09:42:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 09:42:01 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.6875 on epoch=699
06/22/2022 09:42:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 09:42:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 09:42:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 09:42:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/22/2022 09:42:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 09:42:08 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.65625 on epoch=724
06/22/2022 09:42:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 09:42:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 09:42:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 09:42:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 09:42:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 09:42:15 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.65625 on epoch=749
06/22/2022 09:42:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 09:42:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 09:42:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 09:42:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 09:42:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 09:42:21 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.65625 on epoch=774
06/22/2022 09:42:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 09:42:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 09:42:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 09:42:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 09:42:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 09:42:28 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.6875 on epoch=799
06/22/2022 09:42:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 09:42:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 09:42:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 09:42:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 09:42:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/22/2022 09:42:35 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.625 on epoch=824
06/22/2022 09:42:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 09:42:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 09:42:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 09:42:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 09:42:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 09:42:41 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.6875 on epoch=849
06/22/2022 09:42:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 09:42:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 09:42:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 09:42:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 09:42:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/22/2022 09:42:48 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.6875 on epoch=874
06/22/2022 09:42:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 09:42:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 09:42:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 09:42:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 09:42:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 09:42:55 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.65625 on epoch=899
06/22/2022 09:42:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 09:42:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 09:42:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 09:42:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 09:43:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 09:43:01 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.6875 on epoch=924
06/22/2022 09:43:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 09:43:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 09:43:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 09:43:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 09:43:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 09:43:08 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.65625 on epoch=949
06/22/2022 09:43:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 09:43:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 09:43:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 09:43:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 09:43:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=974
06/22/2022 09:43:15 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.6875 on epoch=974
06/22/2022 09:43:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 09:43:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 09:43:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 09:43:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 09:43:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 09:43:21 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.6875 on epoch=999
06/22/2022 09:43:21 - INFO - __main__ - save last model!
06/22/2022 09:43:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 09:43:22 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 09:43:22 - INFO - __main__ - Printing 3 examples
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 09:43:22 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 09:43:22 - INFO - __main__ - ['not_duplicate']
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:43:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:43:22 - INFO - __main__ - Printing 3 examples
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:43:22 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:43:22 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:43:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:43:22 - INFO - __main__ - Printing 3 examples
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 09:43:22 - INFO - __main__ - ['duplicate']
06/22/2022 09:43:22 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:43:22 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:43:22 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:43:27 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:43:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:43:27 - INFO - __main__ - Starting training!
06/22/2022 09:43:40 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:44:20 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 09:57:20 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.4_8_predictions.txt
06/22/2022 09:57:20 - INFO - __main__ - ACC on test data: 0.5876
06/22/2022 09:57:21 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.4, bsz=8, dev_performance=0.6875, test_performance=0.5875587435072965
06/22/2022 09:57:21 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.3, bsz=8 ...
06/22/2022 09:57:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:57:21 - INFO - __main__ - Printing 3 examples
06/22/2022 09:57:21 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 09:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 09:57:21 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 09:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 09:57:21 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 09:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 09:57:21 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:57:21 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:57:21 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 09:57:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 09:57:21 - INFO - __main__ - Printing 3 examples
06/22/2022 09:57:21 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 09:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 09:57:21 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 09:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 09:57:21 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 09:57:21 - INFO - __main__ - ['duplicate']
06/22/2022 09:57:21 - INFO - __main__ - Tokenizing Input ...
06/22/2022 09:57:22 - INFO - __main__ - Tokenizing Output ...
06/22/2022 09:57:22 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 09:57:27 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 09:57:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 09:57:27 - INFO - __main__ - Starting training!
06/22/2022 09:57:28 - INFO - __main__ - Step 10 Global step 10 Train loss 6.35 on epoch=4
06/22/2022 09:57:30 - INFO - __main__ - Step 20 Global step 20 Train loss 4.90 on epoch=9
06/22/2022 09:57:31 - INFO - __main__ - Step 30 Global step 30 Train loss 3.72 on epoch=14
06/22/2022 09:57:32 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=19
06/22/2022 09:57:33 - INFO - __main__ - Step 50 Global step 50 Train loss 2.26 on epoch=24
06/22/2022 09:57:34 - INFO - __main__ - Global step 50 Train loss 4.02 ACC 0.0 on epoch=24
06/22/2022 09:57:34 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 09:57:35 - INFO - __main__ - Step 60 Global step 60 Train loss 1.67 on epoch=29
06/22/2022 09:57:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.27 on epoch=34
06/22/2022 09:57:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=39
06/22/2022 09:57:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=44
06/22/2022 09:57:40 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=49
06/22/2022 09:57:41 - INFO - __main__ - Global step 100 Train loss 1.06 ACC 0.5 on epoch=49
06/22/2022 09:57:41 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 09:57:42 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=54
06/22/2022 09:57:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=59
06/22/2022 09:57:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=64
06/22/2022 09:57:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.41 on epoch=69
06/22/2022 09:57:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.41 on epoch=74
06/22/2022 09:57:47 - INFO - __main__ - Global step 150 Train loss 0.45 ACC 0.5 on epoch=74
06/22/2022 09:57:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.35 on epoch=79
06/22/2022 09:57:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=84
06/22/2022 09:57:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=89
06/22/2022 09:57:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.41 on epoch=94
06/22/2022 09:57:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=99
06/22/2022 09:57:54 - INFO - __main__ - Global step 200 Train loss 0.39 ACC 0.5 on epoch=99
06/22/2022 09:57:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=104
06/22/2022 09:57:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=109
06/22/2022 09:57:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=114
06/22/2022 09:57:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=119
06/22/2022 09:58:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/22/2022 09:58:00 - INFO - __main__ - Global step 250 Train loss 0.33 ACC 0.5 on epoch=124
06/22/2022 09:58:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/22/2022 09:58:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.30 on epoch=134
06/22/2022 09:58:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=139
06/22/2022 09:58:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=144
06/22/2022 09:58:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=149
06/22/2022 09:58:07 - INFO - __main__ - Global step 300 Train loss 0.31 ACC 0.5 on epoch=149
06/22/2022 09:58:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/22/2022 09:58:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=159
06/22/2022 09:58:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=164
06/22/2022 09:58:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=169
06/22/2022 09:58:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=174
06/22/2022 09:58:13 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.5 on epoch=174
06/22/2022 09:58:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/22/2022 09:58:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=184
06/22/2022 09:58:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=189
06/22/2022 09:58:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=194
06/22/2022 09:58:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=199
06/22/2022 09:58:20 - INFO - __main__ - Global step 400 Train loss 0.29 ACC 0.53125 on epoch=199
06/22/2022 09:58:20 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=199, global_step=400
06/22/2022 09:58:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/22/2022 09:58:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/22/2022 09:58:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=214
06/22/2022 09:58:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=219
06/22/2022 09:58:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/22/2022 09:58:27 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.5 on epoch=224
06/22/2022 09:58:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/22/2022 09:58:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=234
06/22/2022 09:58:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=239
06/22/2022 09:58:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=244
06/22/2022 09:58:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=249
06/22/2022 09:58:33 - INFO - __main__ - Global step 500 Train loss 0.22 ACC 0.625 on epoch=249
06/22/2022 09:58:33 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=249, global_step=500
06/22/2022 09:58:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/22/2022 09:58:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=259
06/22/2022 09:58:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=264
06/22/2022 09:58:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=269
06/22/2022 09:58:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=274
06/22/2022 09:58:40 - INFO - __main__ - Global step 550 Train loss 0.18 ACC 0.65625 on epoch=274
06/22/2022 09:58:40 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=274, global_step=550
06/22/2022 09:58:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=279
06/22/2022 09:58:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=284
06/22/2022 09:58:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=289
06/22/2022 09:58:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=294
06/22/2022 09:58:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=299
06/22/2022 09:58:46 - INFO - __main__ - Global step 600 Train loss 0.16 ACC 0.625 on epoch=299
06/22/2022 09:58:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=304
06/22/2022 09:58:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=309
06/22/2022 09:58:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=314
06/22/2022 09:58:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=319
06/22/2022 09:58:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=324
06/22/2022 09:58:53 - INFO - __main__ - Global step 650 Train loss 0.10 ACC 0.59375 on epoch=324
06/22/2022 09:58:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=329
06/22/2022 09:58:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=334
06/22/2022 09:58:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=339
06/22/2022 09:58:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=344
06/22/2022 09:58:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=349
06/22/2022 09:59:00 - INFO - __main__ - Global step 700 Train loss 0.09 ACC 0.625 on epoch=349
06/22/2022 09:59:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=354
06/22/2022 09:59:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/22/2022 09:59:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=364
06/22/2022 09:59:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
06/22/2022 09:59:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=374
06/22/2022 09:59:06 - INFO - __main__ - Global step 750 Train loss 0.08 ACC 0.625 on epoch=374
06/22/2022 09:59:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
06/22/2022 09:59:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
06/22/2022 09:59:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
06/22/2022 09:59:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=394
06/22/2022 09:59:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=399
06/22/2022 09:59:13 - INFO - __main__ - Global step 800 Train loss 0.06 ACC 0.6875 on epoch=399
06/22/2022 09:59:13 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=399, global_step=800
06/22/2022 09:59:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=404
06/22/2022 09:59:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/22/2022 09:59:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/22/2022 09:59:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/22/2022 09:59:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
06/22/2022 09:59:20 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.6875 on epoch=424
06/22/2022 09:59:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
06/22/2022 09:59:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
06/22/2022 09:59:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/22/2022 09:59:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/22/2022 09:59:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/22/2022 09:59:26 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.71875 on epoch=449
06/22/2022 09:59:26 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=449, global_step=900
06/22/2022 09:59:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/22/2022 09:59:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
06/22/2022 09:59:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
06/22/2022 09:59:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
06/22/2022 09:59:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
06/22/2022 09:59:33 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.71875 on epoch=474
06/22/2022 09:59:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/22/2022 09:59:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
06/22/2022 09:59:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/22/2022 09:59:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/22/2022 09:59:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/22/2022 09:59:40 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.59375 on epoch=499
06/22/2022 09:59:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
06/22/2022 09:59:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/22/2022 09:59:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 09:59:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/22/2022 09:59:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/22/2022 09:59:46 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.71875 on epoch=524
06/22/2022 09:59:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/22/2022 09:59:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
06/22/2022 09:59:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/22/2022 09:59:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
06/22/2022 09:59:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/22/2022 09:59:53 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.65625 on epoch=549
06/22/2022 09:59:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
06/22/2022 09:59:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/22/2022 09:59:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
06/22/2022 09:59:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/22/2022 09:59:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 09:59:59 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.65625 on epoch=574
06/22/2022 10:00:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/22/2022 10:00:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/22/2022 10:00:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 10:00:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/22/2022 10:00:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/22/2022 10:00:06 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.65625 on epoch=599
06/22/2022 10:00:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/22/2022 10:00:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 10:00:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 10:00:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 10:00:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
06/22/2022 10:00:13 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/22/2022 10:00:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/22/2022 10:00:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/22/2022 10:00:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/22/2022 10:00:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/22/2022 10:00:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 10:00:19 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
06/22/2022 10:00:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 10:00:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/22/2022 10:00:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 10:00:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 10:00:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/22/2022 10:00:26 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.6875 on epoch=674
06/22/2022 10:00:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/22/2022 10:00:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/22/2022 10:00:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/22/2022 10:00:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/22/2022 10:00:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 10:00:33 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.71875 on epoch=699
06/22/2022 10:00:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 10:00:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/22/2022 10:00:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/22/2022 10:00:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/22/2022 10:00:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 10:00:39 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.65625 on epoch=724
06/22/2022 10:00:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 10:00:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=734
06/22/2022 10:00:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 10:00:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/22/2022 10:00:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 10:00:46 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.71875 on epoch=749
06/22/2022 10:00:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 10:00:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 10:00:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/22/2022 10:00:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/22/2022 10:00:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 10:00:53 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.71875 on epoch=774
06/22/2022 10:00:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
06/22/2022 10:00:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 10:00:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 10:00:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 10:00:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 10:00:59 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.71875 on epoch=799
06/22/2022 10:01:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/22/2022 10:01:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/22/2022 10:01:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 10:01:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 10:01:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/22/2022 10:01:06 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.65625 on epoch=824
06/22/2022 10:01:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/22/2022 10:01:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 10:01:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 10:01:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 10:01:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/22/2022 10:01:13 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.6875 on epoch=849
06/22/2022 10:01:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=854
06/22/2022 10:01:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 10:01:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 10:01:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 10:01:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/22/2022 10:01:19 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.59375 on epoch=874
06/22/2022 10:01:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/22/2022 10:01:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 10:01:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 10:01:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=894
06/22/2022 10:01:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 10:01:26 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.625 on epoch=899
06/22/2022 10:01:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 10:01:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 10:01:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 10:01:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 10:01:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 10:01:33 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.59375 on epoch=924
06/22/2022 10:01:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 10:01:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 10:01:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 10:01:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 10:01:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/22/2022 10:01:39 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.65625 on epoch=949
06/22/2022 10:01:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
06/22/2022 10:01:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 10:01:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 10:01:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 10:01:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 10:01:46 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.6875 on epoch=974
06/22/2022 10:01:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 10:01:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 10:01:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/22/2022 10:01:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 10:01:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 10:01:53 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.6875 on epoch=999
06/22/2022 10:01:53 - INFO - __main__ - save last model!
06/22/2022 10:01:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 10:01:53 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 10:01:53 - INFO - __main__ - Printing 3 examples
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 10:01:53 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 10:01:53 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:01:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:01:53 - INFO - __main__ - Printing 3 examples
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:01:53 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:01:53 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:01:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:01:53 - INFO - __main__ - Printing 3 examples
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 10:01:53 - INFO - __main__ - ['duplicate']
06/22/2022 10:01:53 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:01:53 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:01:53 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:01:59 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:01:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:01:59 - INFO - __main__ - Starting training!
06/22/2022 10:02:11 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:02:52 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 10:15:53 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.3_8_predictions.txt
06/22/2022 10:15:53 - INFO - __main__ - ACC on test data: 0.5545
06/22/2022 10:15:53 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.3, bsz=8, dev_performance=0.71875, test_performance=0.5544892406628741
06/22/2022 10:15:53 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.2, bsz=8 ...
06/22/2022 10:15:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:15:54 - INFO - __main__ - Printing 3 examples
06/22/2022 10:15:54 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/22/2022 10:15:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:15:54 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/22/2022 10:15:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:15:54 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/22/2022 10:15:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:15:54 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:15:54 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:15:54 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:15:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:15:54 - INFO - __main__ - Printing 3 examples
06/22/2022 10:15:54 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/22/2022 10:15:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:15:54 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/22/2022 10:15:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:15:54 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/22/2022 10:15:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:15:54 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:15:54 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:15:54 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:15:59 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:16:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:16:00 - INFO - __main__ - Starting training!
06/22/2022 10:16:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.45 on epoch=4
06/22/2022 10:16:02 - INFO - __main__ - Step 20 Global step 20 Train loss 5.22 on epoch=9
06/22/2022 10:16:04 - INFO - __main__ - Step 30 Global step 30 Train loss 4.43 on epoch=14
06/22/2022 10:16:05 - INFO - __main__ - Step 40 Global step 40 Train loss 3.90 on epoch=19
06/22/2022 10:16:06 - INFO - __main__ - Step 50 Global step 50 Train loss 3.16 on epoch=24
06/22/2022 10:16:07 - INFO - __main__ - Global step 50 Train loss 4.63 ACC 0.0 on epoch=24
06/22/2022 10:16:07 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 10:16:08 - INFO - __main__ - Step 60 Global step 60 Train loss 2.72 on epoch=29
06/22/2022 10:16:09 - INFO - __main__ - Step 70 Global step 70 Train loss 2.16 on epoch=34
06/22/2022 10:16:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.90 on epoch=39
06/22/2022 10:16:12 - INFO - __main__ - Step 90 Global step 90 Train loss 1.51 on epoch=44
06/22/2022 10:16:13 - INFO - __main__ - Step 100 Global step 100 Train loss 1.27 on epoch=49
06/22/2022 10:16:13 - INFO - __main__ - Global step 100 Train loss 1.91 ACC 0.5 on epoch=49
06/22/2022 10:16:13 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 10:16:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=54
06/22/2022 10:16:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=59
06/22/2022 10:16:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=64
06/22/2022 10:16:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=69
06/22/2022 10:16:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=74
06/22/2022 10:16:20 - INFO - __main__ - Global step 150 Train loss 0.78 ACC 0.5 on epoch=74
06/22/2022 10:16:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=79
06/22/2022 10:16:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=84
06/22/2022 10:16:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=89
06/22/2022 10:16:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=94
06/22/2022 10:16:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.54 on epoch=99
06/22/2022 10:16:26 - INFO - __main__ - Global step 200 Train loss 0.51 ACC 0.5 on epoch=99
06/22/2022 10:16:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.45 on epoch=104
06/22/2022 10:16:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=109
06/22/2022 10:16:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=114
06/22/2022 10:16:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=119
06/22/2022 10:16:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/22/2022 10:16:33 - INFO - __main__ - Global step 250 Train loss 0.39 ACC 0.5 on epoch=124
06/22/2022 10:16:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/22/2022 10:16:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=134
06/22/2022 10:16:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=139
06/22/2022 10:16:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=144
06/22/2022 10:16:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=149
06/22/2022 10:16:40 - INFO - __main__ - Global step 300 Train loss 0.36 ACC 0.5 on epoch=149
06/22/2022 10:16:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/22/2022 10:16:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=159
06/22/2022 10:16:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=164
06/22/2022 10:16:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=169
06/22/2022 10:16:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=174
06/22/2022 10:16:46 - INFO - __main__ - Global step 350 Train loss 0.32 ACC 0.5 on epoch=174
06/22/2022 10:16:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=179
06/22/2022 10:16:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=184
06/22/2022 10:16:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=189
06/22/2022 10:16:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=194
06/22/2022 10:16:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/22/2022 10:16:53 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/22/2022 10:16:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=204
06/22/2022 10:16:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=209
06/22/2022 10:16:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=214
06/22/2022 10:16:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=219
06/22/2022 10:16:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=224
06/22/2022 10:16:59 - INFO - __main__ - Global step 450 Train loss 0.29 ACC 0.5 on epoch=224
06/22/2022 10:17:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=229
06/22/2022 10:17:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=234
06/22/2022 10:17:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=239
06/22/2022 10:17:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=244
06/22/2022 10:17:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=249
06/22/2022 10:17:06 - INFO - __main__ - Global step 500 Train loss 0.28 ACC 0.5 on epoch=249
06/22/2022 10:17:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=254
06/22/2022 10:17:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=259
06/22/2022 10:17:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=264
06/22/2022 10:17:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=269
06/22/2022 10:17:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=274
06/22/2022 10:17:12 - INFO - __main__ - Global step 550 Train loss 0.30 ACC 0.5 on epoch=274
06/22/2022 10:17:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=279
06/22/2022 10:17:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=284
06/22/2022 10:17:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=289
06/22/2022 10:17:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=294
06/22/2022 10:17:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=299
06/22/2022 10:17:19 - INFO - __main__ - Global step 600 Train loss 0.28 ACC 0.53125 on epoch=299
06/22/2022 10:17:19 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=299, global_step=600
06/22/2022 10:17:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=304
06/22/2022 10:17:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/22/2022 10:17:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=314
06/22/2022 10:17:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=319
06/22/2022 10:17:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=324
06/22/2022 10:17:26 - INFO - __main__ - Global step 650 Train loss 0.25 ACC 0.53125 on epoch=324
06/22/2022 10:17:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=329
06/22/2022 10:17:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/22/2022 10:17:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=339
06/22/2022 10:17:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=344
06/22/2022 10:17:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=349
06/22/2022 10:17:32 - INFO - __main__ - Global step 700 Train loss 0.24 ACC 0.5625 on epoch=349
06/22/2022 10:17:32 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=349, global_step=700
06/22/2022 10:17:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=354
06/22/2022 10:17:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=359
06/22/2022 10:17:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=364
06/22/2022 10:17:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=369
06/22/2022 10:17:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=374
06/22/2022 10:17:39 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.53125 on epoch=374
06/22/2022 10:17:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=379
06/22/2022 10:17:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=384
06/22/2022 10:17:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/22/2022 10:17:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=394
06/22/2022 10:17:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=399
06/22/2022 10:17:46 - INFO - __main__ - Global step 800 Train loss 0.22 ACC 0.625 on epoch=399
06/22/2022 10:17:46 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=399, global_step=800
06/22/2022 10:17:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=404
06/22/2022 10:17:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=409
06/22/2022 10:17:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=414
06/22/2022 10:17:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=419
06/22/2022 10:17:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=424
06/22/2022 10:17:52 - INFO - __main__ - Global step 850 Train loss 0.20 ACC 0.625 on epoch=424
06/22/2022 10:17:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=429
06/22/2022 10:17:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=434
06/22/2022 10:17:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/22/2022 10:17:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=444
06/22/2022 10:17:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=449
06/22/2022 10:17:59 - INFO - __main__ - Global step 900 Train loss 0.16 ACC 0.6875 on epoch=449
06/22/2022 10:17:59 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=449, global_step=900
06/22/2022 10:18:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=454
06/22/2022 10:18:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=459
06/22/2022 10:18:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=464
06/22/2022 10:18:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=469
06/22/2022 10:18:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=474
06/22/2022 10:18:06 - INFO - __main__ - Global step 950 Train loss 0.12 ACC 0.6875 on epoch=474
06/22/2022 10:18:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=479
06/22/2022 10:18:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=484
06/22/2022 10:18:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=489
06/22/2022 10:18:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=494
06/22/2022 10:18:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=499
06/22/2022 10:18:12 - INFO - __main__ - Global step 1000 Train loss 0.10 ACC 0.625 on epoch=499
06/22/2022 10:18:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=504
06/22/2022 10:18:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=509
06/22/2022 10:18:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=514
06/22/2022 10:18:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=519
06/22/2022 10:18:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=524
06/22/2022 10:18:19 - INFO - __main__ - Global step 1050 Train loss 0.08 ACC 0.71875 on epoch=524
06/22/2022 10:18:19 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=524, global_step=1050
06/22/2022 10:18:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
06/22/2022 10:18:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=534
06/22/2022 10:18:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/22/2022 10:18:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
06/22/2022 10:18:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=549
06/22/2022 10:18:26 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.71875 on epoch=549
06/22/2022 10:18:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
06/22/2022 10:18:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=559
06/22/2022 10:18:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=564
06/22/2022 10:18:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/22/2022 10:18:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
06/22/2022 10:18:32 - INFO - __main__ - Global step 1150 Train loss 0.05 ACC 0.6875 on epoch=574
06/22/2022 10:18:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=579
06/22/2022 10:18:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=584
06/22/2022 10:18:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=589
06/22/2022 10:18:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
06/22/2022 10:18:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
06/22/2022 10:18:39 - INFO - __main__ - Global step 1200 Train loss 0.05 ACC 0.65625 on epoch=599
06/22/2022 10:18:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/22/2022 10:18:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/22/2022 10:18:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=614
06/22/2022 10:18:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 10:18:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=624
06/22/2022 10:18:46 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.625 on epoch=624
06/22/2022 10:18:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=629
06/22/2022 10:18:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/22/2022 10:18:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/22/2022 10:18:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
06/22/2022 10:18:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/22/2022 10:18:52 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.65625 on epoch=649
06/22/2022 10:18:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=654
06/22/2022 10:18:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
06/22/2022 10:18:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/22/2022 10:18:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/22/2022 10:18:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/22/2022 10:18:59 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.65625 on epoch=674
06/22/2022 10:19:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
06/22/2022 10:19:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=684
06/22/2022 10:19:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/22/2022 10:19:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/22/2022 10:19:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/22/2022 10:19:05 - INFO - __main__ - Global step 1400 Train loss 0.03 ACC 0.71875 on epoch=699
06/22/2022 10:19:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=704
06/22/2022 10:19:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=709
06/22/2022 10:19:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=714
06/22/2022 10:19:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/22/2022 10:19:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/22/2022 10:19:12 - INFO - __main__ - Global step 1450 Train loss 0.03 ACC 0.59375 on epoch=724
06/22/2022 10:19:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 10:19:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 10:19:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=739
06/22/2022 10:19:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/22/2022 10:19:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/22/2022 10:19:19 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.59375 on epoch=749
06/22/2022 10:19:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/22/2022 10:19:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
06/22/2022 10:19:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 10:19:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/22/2022 10:19:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 10:19:25 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.65625 on epoch=774
06/22/2022 10:19:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
06/22/2022 10:19:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/22/2022 10:19:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 10:19:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
06/22/2022 10:19:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/22/2022 10:19:32 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.6875 on epoch=799
06/22/2022 10:19:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
06/22/2022 10:19:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=809
06/22/2022 10:19:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=814
06/22/2022 10:19:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 10:19:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
06/22/2022 10:19:39 - INFO - __main__ - Global step 1650 Train loss 0.03 ACC 0.625 on epoch=824
06/22/2022 10:19:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=829
06/22/2022 10:19:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 10:19:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=839
06/22/2022 10:19:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/22/2022 10:19:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/22/2022 10:19:45 - INFO - __main__ - Global step 1700 Train loss 0.03 ACC 0.625 on epoch=849
06/22/2022 10:19:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=854
06/22/2022 10:19:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/22/2022 10:19:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 10:19:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/22/2022 10:19:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/22/2022 10:19:52 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.53125 on epoch=874
06/22/2022 10:19:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/22/2022 10:19:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/22/2022 10:19:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 10:19:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 10:19:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
06/22/2022 10:19:59 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.59375 on epoch=899
06/22/2022 10:20:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/22/2022 10:20:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/22/2022 10:20:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 10:20:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=919
06/22/2022 10:20:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/22/2022 10:20:05 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.5625 on epoch=924
06/22/2022 10:20:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/22/2022 10:20:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/22/2022 10:20:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 10:20:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 10:20:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
06/22/2022 10:20:12 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.625 on epoch=949
06/22/2022 10:20:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 10:20:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/22/2022 10:20:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 10:20:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 10:20:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/22/2022 10:20:19 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
06/22/2022 10:20:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/22/2022 10:20:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
06/22/2022 10:20:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/22/2022 10:20:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 10:20:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/22/2022 10:20:25 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5625 on epoch=999
06/22/2022 10:20:25 - INFO - __main__ - save last model!
06/22/2022 10:20:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 10:20:26 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 10:20:26 - INFO - __main__ - Printing 3 examples
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 10:20:26 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 10:20:26 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:20:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:20:26 - INFO - __main__ - Printing 3 examples
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:20:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:20:26 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:20:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:20:26 - INFO - __main__ - Printing 3 examples
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 10:20:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:20:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:20:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:20:26 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:20:31 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:20:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:20:31 - INFO - __main__ - Starting training!
06/22/2022 10:20:44 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:21:24 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 10:34:22 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.2_8_predictions.txt
06/22/2022 10:34:22 - INFO - __main__ - ACC on test data: 0.5307
06/22/2022 10:34:22 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.2, bsz=8, dev_performance=0.71875, test_performance=0.5307197625525599
06/22/2022 10:34:22 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.5, bsz=8 ...
06/22/2022 10:34:23 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:34:23 - INFO - __main__ - Printing 3 examples
06/22/2022 10:34:23 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:34:23 - INFO - __main__ - ['duplicate']
06/22/2022 10:34:23 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 10:34:23 - INFO - __main__ - ['duplicate']
06/22/2022 10:34:23 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:34:23 - INFO - __main__ - ['duplicate']
06/22/2022 10:34:23 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:34:23 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:34:23 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:34:23 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:34:23 - INFO - __main__ - Printing 3 examples
06/22/2022 10:34:23 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 10:34:23 - INFO - __main__ - ['duplicate']
06/22/2022 10:34:23 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 10:34:23 - INFO - __main__ - ['duplicate']
06/22/2022 10:34:23 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 10:34:23 - INFO - __main__ - ['duplicate']
06/22/2022 10:34:23 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:34:23 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:34:23 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:34:29 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:34:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:34:29 - INFO - __main__ - Starting training!
06/22/2022 10:34:30 - INFO - __main__ - Step 10 Global step 10 Train loss 5.69 on epoch=4
06/22/2022 10:34:32 - INFO - __main__ - Step 20 Global step 20 Train loss 3.76 on epoch=9
06/22/2022 10:34:33 - INFO - __main__ - Step 30 Global step 30 Train loss 2.54 on epoch=14
06/22/2022 10:34:34 - INFO - __main__ - Step 40 Global step 40 Train loss 1.54 on epoch=19
06/22/2022 10:34:35 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=24
06/22/2022 10:34:36 - INFO - __main__ - Global step 50 Train loss 2.90 ACC 0.5 on epoch=24
06/22/2022 10:34:36 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 10:34:37 - INFO - __main__ - Step 60 Global step 60 Train loss 0.66 on epoch=29
06/22/2022 10:34:38 - INFO - __main__ - Step 70 Global step 70 Train loss 0.51 on epoch=34
06/22/2022 10:34:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.46 on epoch=39
06/22/2022 10:34:40 - INFO - __main__ - Step 90 Global step 90 Train loss 0.37 on epoch=44
06/22/2022 10:34:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.34 on epoch=49
06/22/2022 10:34:42 - INFO - __main__ - Global step 100 Train loss 0.47 ACC 0.5 on epoch=49
06/22/2022 10:34:43 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=54
06/22/2022 10:34:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.37 on epoch=59
06/22/2022 10:34:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
06/22/2022 10:34:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
06/22/2022 10:34:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.35 on epoch=74
06/22/2022 10:34:49 - INFO - __main__ - Global step 150 Train loss 0.35 ACC 0.5 on epoch=74
06/22/2022 10:34:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=79
06/22/2022 10:34:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.33 on epoch=84
06/22/2022 10:34:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=89
06/22/2022 10:34:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.29 on epoch=94
06/22/2022 10:34:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.31 on epoch=99
06/22/2022 10:34:55 - INFO - __main__ - Global step 200 Train loss 0.31 ACC 0.5 on epoch=99
06/22/2022 10:34:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
06/22/2022 10:34:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=109
06/22/2022 10:34:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=114
06/22/2022 10:35:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.21 on epoch=119
06/22/2022 10:35:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=124
06/22/2022 10:35:02 - INFO - __main__ - Global step 250 Train loss 0.23 ACC 0.5 on epoch=124
06/22/2022 10:35:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=129
06/22/2022 10:35:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.18 on epoch=134
06/22/2022 10:35:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=139
06/22/2022 10:35:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=144
06/22/2022 10:35:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.18 on epoch=149
06/22/2022 10:35:08 - INFO - __main__ - Global step 300 Train loss 0.20 ACC 0.59375 on epoch=149
06/22/2022 10:35:08 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=149, global_step=300
06/22/2022 10:35:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=154
06/22/2022 10:35:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.17 on epoch=159
06/22/2022 10:35:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
06/22/2022 10:35:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.14 on epoch=169
06/22/2022 10:35:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=174
06/22/2022 10:35:15 - INFO - __main__ - Global step 350 Train loss 0.16 ACC 0.5625 on epoch=174
06/22/2022 10:35:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.11 on epoch=179
06/22/2022 10:35:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
06/22/2022 10:35:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=189
06/22/2022 10:35:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=194
06/22/2022 10:35:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=199
06/22/2022 10:35:22 - INFO - __main__ - Global step 400 Train loss 0.11 ACC 0.5625 on epoch=199
06/22/2022 10:35:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.07 on epoch=204
06/22/2022 10:35:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
06/22/2022 10:35:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
06/22/2022 10:35:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
06/22/2022 10:35:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=224
06/22/2022 10:35:28 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.5625 on epoch=224
06/22/2022 10:35:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
06/22/2022 10:35:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
06/22/2022 10:35:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
06/22/2022 10:35:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
06/22/2022 10:35:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
06/22/2022 10:35:35 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.53125 on epoch=249
06/22/2022 10:35:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
06/22/2022 10:35:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
06/22/2022 10:35:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
06/22/2022 10:35:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
06/22/2022 10:35:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
06/22/2022 10:35:42 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.5625 on epoch=274
06/22/2022 10:35:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
06/22/2022 10:35:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
06/22/2022 10:35:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
06/22/2022 10:35:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
06/22/2022 10:35:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
06/22/2022 10:35:48 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.5625 on epoch=299
06/22/2022 10:35:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/22/2022 10:35:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=309
06/22/2022 10:35:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
06/22/2022 10:35:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
06/22/2022 10:35:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/22/2022 10:35:55 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.5625 on epoch=324
06/22/2022 10:35:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
06/22/2022 10:35:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
06/22/2022 10:35:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/22/2022 10:35:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
06/22/2022 10:36:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
06/22/2022 10:36:01 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.5625 on epoch=349
06/22/2022 10:36:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/22/2022 10:36:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/22/2022 10:36:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
06/22/2022 10:36:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
06/22/2022 10:36:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
06/22/2022 10:36:08 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5625 on epoch=374
06/22/2022 10:36:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/22/2022 10:36:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=384
06/22/2022 10:36:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/22/2022 10:36:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
06/22/2022 10:36:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
06/22/2022 10:36:14 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.59375 on epoch=399
06/22/2022 10:36:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/22/2022 10:36:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/22/2022 10:36:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
06/22/2022 10:36:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
06/22/2022 10:36:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
06/22/2022 10:36:21 - INFO - __main__ - Global step 850 Train loss 0.00 ACC 0.625 on epoch=424
06/22/2022 10:36:21 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=424, global_step=850
06/22/2022 10:36:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/22/2022 10:36:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
06/22/2022 10:36:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/22/2022 10:36:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/22/2022 10:36:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/22/2022 10:36:28 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5625 on epoch=449
06/22/2022 10:36:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/22/2022 10:36:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/22/2022 10:36:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/22/2022 10:36:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/22/2022 10:36:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/22/2022 10:36:34 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.625 on epoch=474
06/22/2022 10:36:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/22/2022 10:36:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/22/2022 10:36:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
06/22/2022 10:36:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/22/2022 10:36:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/22/2022 10:36:41 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
06/22/2022 10:36:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
06/22/2022 10:36:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=509
06/22/2022 10:36:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
06/22/2022 10:36:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/22/2022 10:36:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/22/2022 10:36:47 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.59375 on epoch=524
06/22/2022 10:36:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/22/2022 10:36:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/22/2022 10:36:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/22/2022 10:36:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/22/2022 10:36:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/22/2022 10:36:54 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.625 on epoch=549
06/22/2022 10:36:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/22/2022 10:36:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/22/2022 10:36:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/22/2022 10:36:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/22/2022 10:37:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
06/22/2022 10:37:01 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.625 on epoch=574
06/22/2022 10:37:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/22/2022 10:37:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/22/2022 10:37:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 10:37:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/22/2022 10:37:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 10:37:07 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.59375 on epoch=599
06/22/2022 10:37:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 10:37:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/22/2022 10:37:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/22/2022 10:37:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/22/2022 10:37:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 10:37:14 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.625 on epoch=624
06/22/2022 10:37:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/22/2022 10:37:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 10:37:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/22/2022 10:37:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 10:37:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 10:37:21 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.625 on epoch=649
06/22/2022 10:37:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/22/2022 10:37:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/22/2022 10:37:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 10:37:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 10:37:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/22/2022 10:37:27 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.65625 on epoch=674
06/22/2022 10:37:27 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=674, global_step=1350
06/22/2022 10:37:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/22/2022 10:37:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 10:37:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/22/2022 10:37:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/22/2022 10:37:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/22/2022 10:37:34 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.59375 on epoch=699
06/22/2022 10:37:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 10:37:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 10:37:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 10:37:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 10:37:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/22/2022 10:37:40 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.5625 on epoch=724
06/22/2022 10:37:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 10:37:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 10:37:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 10:37:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 10:37:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=749
06/22/2022 10:37:47 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.59375 on epoch=749
06/22/2022 10:37:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 10:37:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 10:37:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 10:37:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 10:37:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/22/2022 10:37:54 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.625 on epoch=774
06/22/2022 10:37:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/22/2022 10:37:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 10:37:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 10:37:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 10:38:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 10:38:00 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.59375 on epoch=799
06/22/2022 10:38:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/22/2022 10:38:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/22/2022 10:38:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 10:38:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 10:38:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 10:38:07 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.625 on epoch=824
06/22/2022 10:38:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/22/2022 10:38:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 10:38:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/22/2022 10:38:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 10:38:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 10:38:14 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.625 on epoch=849
06/22/2022 10:38:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 10:38:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 10:38:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 10:38:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 10:38:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 10:38:20 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.59375 on epoch=874
06/22/2022 10:38:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/22/2022 10:38:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 10:38:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 10:38:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 10:38:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/22/2022 10:38:27 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5625 on epoch=899
06/22/2022 10:38:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 10:38:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/22/2022 10:38:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/22/2022 10:38:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 10:38:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 10:38:34 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.625 on epoch=924
06/22/2022 10:38:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 10:38:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 10:38:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 10:38:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 10:38:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/22/2022 10:38:40 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/22/2022 10:38:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 10:38:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/22/2022 10:38:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/22/2022 10:38:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 10:38:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 10:38:47 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
06/22/2022 10:38:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 10:38:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 10:38:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 10:38:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 10:38:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 10:38:53 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
06/22/2022 10:38:53 - INFO - __main__ - save last model!
06/22/2022 10:38:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 10:38:54 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 10:38:54 - INFO - __main__ - Printing 3 examples
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 10:38:54 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 10:38:54 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:38:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:38:54 - INFO - __main__ - Printing 3 examples
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:38:54 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:38:54 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:38:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:38:54 - INFO - __main__ - Printing 3 examples
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 10:38:54 - INFO - __main__ - ['duplicate']
06/22/2022 10:38:54 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:38:54 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:38:54 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:38:59 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:38:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:38:59 - INFO - __main__ - Starting training!
06/22/2022 10:39:12 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:39:52 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 10:52:53 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.5_8_predictions.txt
06/22/2022 10:52:54 - INFO - __main__ - ACC on test data: 0.5557
06/22/2022 10:52:54 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.5, bsz=8, dev_performance=0.65625, test_performance=0.5557012119713084
06/22/2022 10:52:54 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.4, bsz=8 ...
06/22/2022 10:52:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:52:55 - INFO - __main__ - Printing 3 examples
06/22/2022 10:52:55 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:52:55 - INFO - __main__ - ['duplicate']
06/22/2022 10:52:55 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 10:52:55 - INFO - __main__ - ['duplicate']
06/22/2022 10:52:55 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:52:55 - INFO - __main__ - ['duplicate']
06/22/2022 10:52:55 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:52:55 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:52:55 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:52:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:52:55 - INFO - __main__ - Printing 3 examples
06/22/2022 10:52:55 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 10:52:55 - INFO - __main__ - ['duplicate']
06/22/2022 10:52:55 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 10:52:55 - INFO - __main__ - ['duplicate']
06/22/2022 10:52:55 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 10:52:55 - INFO - __main__ - ['duplicate']
06/22/2022 10:52:55 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:52:55 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:52:55 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:53:00 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:53:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:53:00 - INFO - __main__ - Starting training!
06/22/2022 10:53:02 - INFO - __main__ - Step 10 Global step 10 Train loss 6.29 on epoch=4
06/22/2022 10:53:03 - INFO - __main__ - Step 20 Global step 20 Train loss 4.11 on epoch=9
06/22/2022 10:53:04 - INFO - __main__ - Step 30 Global step 30 Train loss 2.97 on epoch=14
06/22/2022 10:53:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.91 on epoch=19
06/22/2022 10:53:07 - INFO - __main__ - Step 50 Global step 50 Train loss 1.34 on epoch=24
06/22/2022 10:53:07 - INFO - __main__ - Global step 50 Train loss 3.32 ACC 0.5 on epoch=24
06/22/2022 10:53:07 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/22/2022 10:53:09 - INFO - __main__ - Step 60 Global step 60 Train loss 1.07 on epoch=29
06/22/2022 10:53:10 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
06/22/2022 10:53:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.58 on epoch=39
06/22/2022 10:53:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.56 on epoch=44
06/22/2022 10:53:13 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=49
06/22/2022 10:53:14 - INFO - __main__ - Global step 100 Train loss 0.69 ACC 0.5 on epoch=49
06/22/2022 10:53:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
06/22/2022 10:53:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.38 on epoch=59
06/22/2022 10:53:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=64
06/22/2022 10:53:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.33 on epoch=69
06/22/2022 10:53:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.46 on epoch=74
06/22/2022 10:53:20 - INFO - __main__ - Global step 150 Train loss 0.37 ACC 0.5 on epoch=74
06/22/2022 10:53:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=79
06/22/2022 10:53:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/22/2022 10:53:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.39 on epoch=89
06/22/2022 10:53:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=94
06/22/2022 10:53:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=99
06/22/2022 10:53:27 - INFO - __main__ - Global step 200 Train loss 0.33 ACC 0.5 on epoch=99
06/22/2022 10:53:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=104
06/22/2022 10:53:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
06/22/2022 10:53:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=114
06/22/2022 10:53:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=119
06/22/2022 10:53:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=124
06/22/2022 10:53:34 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/22/2022 10:53:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/22/2022 10:53:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/22/2022 10:53:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=139
06/22/2022 10:53:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/22/2022 10:53:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=149
06/22/2022 10:53:40 - INFO - __main__ - Global step 300 Train loss 0.28 ACC 0.5 on epoch=149
06/22/2022 10:53:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/22/2022 10:53:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=159
06/22/2022 10:53:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/22/2022 10:53:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/22/2022 10:53:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/22/2022 10:53:47 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.53125 on epoch=174
06/22/2022 10:53:47 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/22/2022 10:53:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=179
06/22/2022 10:53:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=184
06/22/2022 10:53:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=189
06/22/2022 10:53:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=194
06/22/2022 10:53:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=199
06/22/2022 10:53:53 - INFO - __main__ - Global step 400 Train loss 0.20 ACC 0.625 on epoch=199
06/22/2022 10:53:53 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=199, global_step=400
06/22/2022 10:53:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=204
06/22/2022 10:53:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=209
06/22/2022 10:53:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=214
06/22/2022 10:53:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=219
06/22/2022 10:53:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=224
06/22/2022 10:54:00 - INFO - __main__ - Global step 450 Train loss 0.15 ACC 0.59375 on epoch=224
06/22/2022 10:54:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
06/22/2022 10:54:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
06/22/2022 10:54:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=239
06/22/2022 10:54:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=244
06/22/2022 10:54:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
06/22/2022 10:54:07 - INFO - __main__ - Global step 500 Train loss 0.12 ACC 0.59375 on epoch=249
06/22/2022 10:54:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=254
06/22/2022 10:54:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
06/22/2022 10:54:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=264
06/22/2022 10:54:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
06/22/2022 10:54:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=274
06/22/2022 10:54:13 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.59375 on epoch=274
06/22/2022 10:54:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
06/22/2022 10:54:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=284
06/22/2022 10:54:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
06/22/2022 10:54:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/22/2022 10:54:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
06/22/2022 10:54:20 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.59375 on epoch=299
06/22/2022 10:54:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=304
06/22/2022 10:54:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
06/22/2022 10:54:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
06/22/2022 10:54:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
06/22/2022 10:54:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/22/2022 10:54:27 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.5625 on epoch=324
06/22/2022 10:54:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=329
06/22/2022 10:54:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
06/22/2022 10:54:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/22/2022 10:54:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
06/22/2022 10:54:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/22/2022 10:54:33 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.5625 on epoch=349
06/22/2022 10:54:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=354
06/22/2022 10:54:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
06/22/2022 10:54:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/22/2022 10:54:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
06/22/2022 10:54:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
06/22/2022 10:54:40 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.53125 on epoch=374
06/22/2022 10:54:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/22/2022 10:54:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
06/22/2022 10:54:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
06/22/2022 10:54:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
06/22/2022 10:54:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/22/2022 10:54:46 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.59375 on epoch=399
06/22/2022 10:54:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
06/22/2022 10:54:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/22/2022 10:54:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
06/22/2022 10:54:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
06/22/2022 10:54:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/22/2022 10:54:53 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.53125 on epoch=424
06/22/2022 10:54:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/22/2022 10:54:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/22/2022 10:54:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
06/22/2022 10:54:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/22/2022 10:54:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/22/2022 10:55:00 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
06/22/2022 10:55:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/22/2022 10:55:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/22/2022 10:55:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/22/2022 10:55:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/22/2022 10:55:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/22/2022 10:55:06 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.5625 on epoch=474
06/22/2022 10:55:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/22/2022 10:55:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
06/22/2022 10:55:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
06/22/2022 10:55:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
06/22/2022 10:55:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
06/22/2022 10:55:13 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.5625 on epoch=499
06/22/2022 10:55:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
06/22/2022 10:55:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
06/22/2022 10:55:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 10:55:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/22/2022 10:55:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/22/2022 10:55:20 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.53125 on epoch=524
06/22/2022 10:55:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
06/22/2022 10:55:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 10:55:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/22/2022 10:55:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/22/2022 10:55:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/22/2022 10:55:26 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5625 on epoch=549
06/22/2022 10:55:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/22/2022 10:55:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/22/2022 10:55:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/22/2022 10:55:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/22/2022 10:55:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 10:55:33 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.53125 on epoch=574
06/22/2022 10:55:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/22/2022 10:55:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/22/2022 10:55:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/22/2022 10:55:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/22/2022 10:55:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/22/2022 10:55:40 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.59375 on epoch=599
06/22/2022 10:55:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/22/2022 10:55:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/22/2022 10:55:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 10:55:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 10:55:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 10:55:46 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
06/22/2022 10:55:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/22/2022 10:55:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/22/2022 10:55:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/22/2022 10:55:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/22/2022 10:55:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/22/2022 10:55:53 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.59375 on epoch=649
06/22/2022 10:55:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/22/2022 10:55:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/22/2022 10:55:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 10:55:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/22/2022 10:55:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/22/2022 10:56:00 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.5625 on epoch=674
06/22/2022 10:56:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 10:56:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/22/2022 10:56:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/22/2022 10:56:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 10:56:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/22/2022 10:56:06 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5625 on epoch=699
06/22/2022 10:56:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/22/2022 10:56:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 10:56:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/22/2022 10:56:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/22/2022 10:56:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/22/2022 10:56:13 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.53125 on epoch=724
06/22/2022 10:56:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/22/2022 10:56:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/22/2022 10:56:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 10:56:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/22/2022 10:56:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 10:56:19 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.5625 on epoch=749
06/22/2022 10:56:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/22/2022 10:56:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 10:56:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/22/2022 10:56:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/22/2022 10:56:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 10:56:26 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.59375 on epoch=774
06/22/2022 10:56:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=779
06/22/2022 10:56:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/22/2022 10:56:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 10:56:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/22/2022 10:56:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/22/2022 10:56:33 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.59375 on epoch=799
06/22/2022 10:56:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
06/22/2022 10:56:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/22/2022 10:56:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/22/2022 10:56:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 10:56:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 10:56:39 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.59375 on epoch=824
06/22/2022 10:56:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/22/2022 10:56:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 10:56:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 10:56:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/22/2022 10:56:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/22/2022 10:56:46 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.5625 on epoch=849
06/22/2022 10:56:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 10:56:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 10:56:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/22/2022 10:56:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/22/2022 10:56:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 10:56:53 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.625 on epoch=874
06/22/2022 10:56:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/22/2022 10:56:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 10:56:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 10:56:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/22/2022 10:56:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 10:56:59 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/22/2022 10:57:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 10:57:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 10:57:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=914
06/22/2022 10:57:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/22/2022 10:57:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 10:57:06 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.625 on epoch=924
06/22/2022 10:57:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 10:57:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/22/2022 10:57:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/22/2022 10:57:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/22/2022 10:57:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 10:57:13 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/22/2022 10:57:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 10:57:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 10:57:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/22/2022 10:57:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 10:57:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 10:57:19 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.59375 on epoch=974
06/22/2022 10:57:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 10:57:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 10:57:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 10:57:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/22/2022 10:57:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 10:57:26 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5625 on epoch=999
06/22/2022 10:57:26 - INFO - __main__ - save last model!
06/22/2022 10:57:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 10:57:26 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 10:57:26 - INFO - __main__ - Printing 3 examples
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 10:57:26 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 10:57:26 - INFO - __main__ - ['not_duplicate']
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:57:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:57:26 - INFO - __main__ - Printing 3 examples
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:57:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:57:26 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 10:57:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 10:57:26 - INFO - __main__ - Printing 3 examples
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 10:57:26 - INFO - __main__ - ['duplicate']
06/22/2022 10:57:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 10:57:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:57:26 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 10:57:32 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 10:57:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 10:57:32 - INFO - __main__ - Starting training!
06/22/2022 10:57:44 - INFO - __main__ - Tokenizing Output ...
06/22/2022 10:58:24 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 11:11:25 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.4_8_predictions.txt
06/22/2022 11:11:25 - INFO - __main__ - ACC on test data: 0.5505
06/22/2022 11:11:25 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.4, bsz=8, dev_performance=0.625, test_performance=0.5504575810042048
06/22/2022 11:11:25 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.3, bsz=8 ...
06/22/2022 11:11:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 11:11:26 - INFO - __main__ - Printing 3 examples
06/22/2022 11:11:26 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 11:11:26 - INFO - __main__ - ['duplicate']
06/22/2022 11:11:26 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 11:11:26 - INFO - __main__ - ['duplicate']
06/22/2022 11:11:26 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 11:11:26 - INFO - __main__ - ['duplicate']
06/22/2022 11:11:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:11:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:11:26 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 11:11:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 11:11:26 - INFO - __main__ - Printing 3 examples
06/22/2022 11:11:26 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 11:11:26 - INFO - __main__ - ['duplicate']
06/22/2022 11:11:26 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 11:11:26 - INFO - __main__ - ['duplicate']
06/22/2022 11:11:26 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 11:11:26 - INFO - __main__ - ['duplicate']
06/22/2022 11:11:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:11:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:11:26 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 11:11:31 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 11:11:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 11:11:32 - INFO - __main__ - Starting training!
06/22/2022 11:11:33 - INFO - __main__ - Step 10 Global step 10 Train loss 5.80 on epoch=4
06/22/2022 11:11:34 - INFO - __main__ - Step 20 Global step 20 Train loss 4.75 on epoch=9
06/22/2022 11:11:35 - INFO - __main__ - Step 30 Global step 30 Train loss 3.61 on epoch=14
06/22/2022 11:11:37 - INFO - __main__ - Step 40 Global step 40 Train loss 2.76 on epoch=19
06/22/2022 11:11:38 - INFO - __main__ - Step 50 Global step 50 Train loss 2.18 on epoch=24
06/22/2022 11:11:38 - INFO - __main__ - Global step 50 Train loss 3.82 ACC 0.0625 on epoch=24
06/22/2022 11:11:38 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0625 on epoch=24, global_step=50
06/22/2022 11:11:40 - INFO - __main__ - Step 60 Global step 60 Train loss 1.52 on epoch=29
06/22/2022 11:11:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.22 on epoch=34
06/22/2022 11:11:42 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=39
06/22/2022 11:11:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=44
06/22/2022 11:11:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.58 on epoch=49
06/22/2022 11:11:45 - INFO - __main__ - Global step 100 Train loss 1.01 ACC 0.5 on epoch=49
06/22/2022 11:11:45 - INFO - __main__ - Saving model with best ACC: 0.0625 -> 0.5 on epoch=49, global_step=100
06/22/2022 11:11:46 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=54
06/22/2022 11:11:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.44 on epoch=59
06/22/2022 11:11:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.47 on epoch=64
06/22/2022 11:11:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.46 on epoch=69
06/22/2022 11:11:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=74
06/22/2022 11:11:52 - INFO - __main__ - Global step 150 Train loss 0.47 ACC 0.5 on epoch=74
06/22/2022 11:11:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
06/22/2022 11:11:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=84
06/22/2022 11:11:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=89
06/22/2022 11:11:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/22/2022 11:11:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=99
06/22/2022 11:11:58 - INFO - __main__ - Global step 200 Train loss 0.36 ACC 0.5 on epoch=99
06/22/2022 11:11:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=104
06/22/2022 11:12:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=109
06/22/2022 11:12:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=114
06/22/2022 11:12:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=119
06/22/2022 11:12:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=124
06/22/2022 11:12:05 - INFO - __main__ - Global step 250 Train loss 0.33 ACC 0.5 on epoch=124
06/22/2022 11:12:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/22/2022 11:12:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/22/2022 11:12:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=139
06/22/2022 11:12:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=144
06/22/2022 11:12:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=149
06/22/2022 11:12:11 - INFO - __main__ - Global step 300 Train loss 0.32 ACC 0.5 on epoch=149
06/22/2022 11:12:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=154
06/22/2022 11:12:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=159
06/22/2022 11:12:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=164
06/22/2022 11:12:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/22/2022 11:12:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=174
06/22/2022 11:12:18 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.5 on epoch=174
06/22/2022 11:12:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=179
06/22/2022 11:12:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=184
06/22/2022 11:12:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=189
06/22/2022 11:12:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=194
06/22/2022 11:12:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=199
06/22/2022 11:12:24 - INFO - __main__ - Global step 400 Train loss 0.27 ACC 0.5 on epoch=199
06/22/2022 11:12:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=204
06/22/2022 11:12:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=209
06/22/2022 11:12:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
06/22/2022 11:12:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=219
06/22/2022 11:12:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=224
06/22/2022 11:12:31 - INFO - __main__ - Global step 450 Train loss 0.21 ACC 0.625 on epoch=224
06/22/2022 11:12:31 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.625 on epoch=224, global_step=450
06/22/2022 11:12:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/22/2022 11:12:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=234
06/22/2022 11:12:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=239
06/22/2022 11:12:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=244
06/22/2022 11:12:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=249
06/22/2022 11:12:38 - INFO - __main__ - Global step 500 Train loss 0.18 ACC 0.65625 on epoch=249
06/22/2022 11:12:38 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=249, global_step=500
06/22/2022 11:12:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=254
06/22/2022 11:12:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=259
06/22/2022 11:12:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=264
06/22/2022 11:12:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=269
06/22/2022 11:12:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=274
06/22/2022 11:12:44 - INFO - __main__ - Global step 550 Train loss 0.15 ACC 0.5625 on epoch=274
06/22/2022 11:12:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=279
06/22/2022 11:12:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=284
06/22/2022 11:12:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=289
06/22/2022 11:12:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=294
06/22/2022 11:12:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=299
06/22/2022 11:12:51 - INFO - __main__ - Global step 600 Train loss 0.10 ACC 0.59375 on epoch=299
06/22/2022 11:12:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=304
06/22/2022 11:12:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=309
06/22/2022 11:12:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=314
06/22/2022 11:12:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=319
06/22/2022 11:12:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=324
06/22/2022 11:12:58 - INFO - __main__ - Global step 650 Train loss 0.09 ACC 0.59375 on epoch=324
06/22/2022 11:12:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=329
06/22/2022 11:13:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=334
06/22/2022 11:13:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=339
06/22/2022 11:13:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=344
06/22/2022 11:13:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=349
06/22/2022 11:13:04 - INFO - __main__ - Global step 700 Train loss 0.06 ACC 0.53125 on epoch=349
06/22/2022 11:13:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=354
06/22/2022 11:13:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/22/2022 11:13:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/22/2022 11:13:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
06/22/2022 11:13:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
06/22/2022 11:13:11 - INFO - __main__ - Global step 750 Train loss 0.07 ACC 0.5625 on epoch=374
06/22/2022 11:13:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/22/2022 11:13:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=384
06/22/2022 11:13:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
06/22/2022 11:13:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/22/2022 11:13:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
06/22/2022 11:13:17 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.53125 on epoch=399
06/22/2022 11:13:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=404
06/22/2022 11:13:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
06/22/2022 11:13:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
06/22/2022 11:13:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
06/22/2022 11:13:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=424
06/22/2022 11:13:24 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.65625 on epoch=424
06/22/2022 11:13:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/22/2022 11:13:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
06/22/2022 11:13:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=439
06/22/2022 11:13:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/22/2022 11:13:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/22/2022 11:13:31 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.59375 on epoch=449
06/22/2022 11:13:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
06/22/2022 11:13:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
06/22/2022 11:13:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
06/22/2022 11:13:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/22/2022 11:13:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/22/2022 11:13:37 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.625 on epoch=474
06/22/2022 11:13:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/22/2022 11:13:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/22/2022 11:13:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
06/22/2022 11:13:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
06/22/2022 11:13:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=499
06/22/2022 11:13:44 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.625 on epoch=499
06/22/2022 11:13:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/22/2022 11:13:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/22/2022 11:13:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/22/2022 11:13:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/22/2022 11:13:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/22/2022 11:13:51 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
06/22/2022 11:13:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
06/22/2022 11:13:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/22/2022 11:13:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/22/2022 11:13:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/22/2022 11:13:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
06/22/2022 11:13:57 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5625 on epoch=549
06/22/2022 11:13:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/22/2022 11:14:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/22/2022 11:14:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
06/22/2022 11:14:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
06/22/2022 11:14:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/22/2022 11:14:04 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5 on epoch=574
06/22/2022 11:14:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/22/2022 11:14:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/22/2022 11:14:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/22/2022 11:14:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/22/2022 11:14:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/22/2022 11:14:10 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.625 on epoch=599
06/22/2022 11:14:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
06/22/2022 11:14:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/22/2022 11:14:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/22/2022 11:14:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/22/2022 11:14:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/22/2022 11:14:17 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/22/2022 11:14:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
06/22/2022 11:14:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/22/2022 11:14:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/22/2022 11:14:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/22/2022 11:14:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/22/2022 11:14:24 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.53125 on epoch=649
06/22/2022 11:14:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/22/2022 11:14:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
06/22/2022 11:14:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/22/2022 11:14:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/22/2022 11:14:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/22/2022 11:14:30 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.5 on epoch=674
06/22/2022 11:14:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 11:14:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/22/2022 11:14:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/22/2022 11:14:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/22/2022 11:14:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/22/2022 11:14:37 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/22/2022 11:14:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/22/2022 11:14:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/22/2022 11:14:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 11:14:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/22/2022 11:14:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/22/2022 11:14:43 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
06/22/2022 11:14:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 11:14:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/22/2022 11:14:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/22/2022 11:14:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/22/2022 11:14:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/22/2022 11:14:50 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
06/22/2022 11:14:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/22/2022 11:14:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/22/2022 11:14:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/22/2022 11:14:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/22/2022 11:14:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 11:14:57 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
06/22/2022 11:14:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/22/2022 11:14:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/22/2022 11:15:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/22/2022 11:15:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 11:15:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/22/2022 11:15:03 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.625 on epoch=799
06/22/2022 11:15:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
06/22/2022 11:15:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/22/2022 11:15:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
06/22/2022 11:15:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/22/2022 11:15:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/22/2022 11:15:10 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.53125 on epoch=824
06/22/2022 11:15:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/22/2022 11:15:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/22/2022 11:15:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/22/2022 11:15:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/22/2022 11:15:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/22/2022 11:15:17 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
06/22/2022 11:15:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 11:15:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/22/2022 11:15:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 11:15:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/22/2022 11:15:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 11:15:23 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.625 on epoch=874
06/22/2022 11:15:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/22/2022 11:15:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/22/2022 11:15:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/22/2022 11:15:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 11:15:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/22/2022 11:15:30 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.625 on epoch=899
06/22/2022 11:15:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/22/2022 11:15:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 11:15:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/22/2022 11:15:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 11:15:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 11:15:37 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.59375 on epoch=924
06/22/2022 11:15:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 11:15:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
06/22/2022 11:15:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 11:15:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 11:15:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/22/2022 11:15:43 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.59375 on epoch=949
06/22/2022 11:15:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/22/2022 11:15:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/22/2022 11:15:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/22/2022 11:15:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 11:15:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/22/2022 11:15:50 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.59375 on epoch=974
06/22/2022 11:15:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/22/2022 11:15:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 11:15:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/22/2022 11:15:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/22/2022 11:15:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/22/2022 11:15:57 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5625 on epoch=999
06/22/2022 11:15:57 - INFO - __main__ - save last model!
06/22/2022 11:15:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 11:15:57 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 11:15:57 - INFO - __main__ - Printing 3 examples
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 11:15:57 - INFO - __main__ - ['not_duplicate']
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 11:15:57 - INFO - __main__ - ['not_duplicate']
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:15:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 11:15:57 - INFO - __main__ - Printing 3 examples
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:15:57 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:15:57 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 11:15:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 11:15:57 - INFO - __main__ - Printing 3 examples
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 11:15:57 - INFO - __main__ - ['duplicate']
06/22/2022 11:15:57 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:15:57 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:15:57 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 11:16:02 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 11:16:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 11:16:03 - INFO - __main__ - Starting training!
06/22/2022 11:16:15 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:16:56 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 11:30:02 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.3_8_predictions.txt
06/22/2022 11:30:02 - INFO - __main__ - ACC on test data: 0.5654
06/22/2022 11:30:02 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.3, bsz=8, dev_performance=0.65625, test_performance=0.5653722483304476
06/22/2022 11:30:02 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.2, bsz=8 ...
06/22/2022 11:30:03 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 11:30:03 - INFO - __main__ - Printing 3 examples
06/22/2022 11:30:03 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 11:30:03 - INFO - __main__ - ['duplicate']
06/22/2022 11:30:03 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/22/2022 11:30:03 - INFO - __main__ - ['duplicate']
06/22/2022 11:30:03 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/22/2022 11:30:03 - INFO - __main__ - ['duplicate']
06/22/2022 11:30:03 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:30:03 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:30:03 - INFO - __main__ - Loaded 32 examples from train data
06/22/2022 11:30:03 - INFO - __main__ - Start tokenizing ... 32 instances
06/22/2022 11:30:03 - INFO - __main__ - Printing 3 examples
06/22/2022 11:30:03 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/22/2022 11:30:03 - INFO - __main__ - ['duplicate']
06/22/2022 11:30:03 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/22/2022 11:30:03 - INFO - __main__ - ['duplicate']
06/22/2022 11:30:03 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/22/2022 11:30:03 - INFO - __main__ - ['duplicate']
06/22/2022 11:30:03 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:30:03 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:30:03 - INFO - __main__ - Loaded 32 examples from dev data
06/22/2022 11:30:09 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 11:30:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/22/2022 11:30:09 - INFO - __main__ - Starting training!
06/22/2022 11:30:11 - INFO - __main__ - Step 10 Global step 10 Train loss 6.65 on epoch=4
06/22/2022 11:30:12 - INFO - __main__ - Step 20 Global step 20 Train loss 5.46 on epoch=9
06/22/2022 11:30:13 - INFO - __main__ - Step 30 Global step 30 Train loss 4.57 on epoch=14
06/22/2022 11:30:14 - INFO - __main__ - Step 40 Global step 40 Train loss 3.89 on epoch=19
06/22/2022 11:30:15 - INFO - __main__ - Step 50 Global step 50 Train loss 3.45 on epoch=24
06/22/2022 11:30:16 - INFO - __main__ - Global step 50 Train loss 4.80 ACC 0.0 on epoch=24
06/22/2022 11:30:16 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/22/2022 11:30:17 - INFO - __main__ - Step 60 Global step 60 Train loss 2.61 on epoch=29
06/22/2022 11:30:18 - INFO - __main__ - Step 70 Global step 70 Train loss 2.28 on epoch=34
06/22/2022 11:30:20 - INFO - __main__ - Step 80 Global step 80 Train loss 1.96 on epoch=39
06/22/2022 11:30:21 - INFO - __main__ - Step 90 Global step 90 Train loss 1.51 on epoch=44
06/22/2022 11:30:22 - INFO - __main__ - Step 100 Global step 100 Train loss 1.33 on epoch=49
06/22/2022 11:30:23 - INFO - __main__ - Global step 100 Train loss 1.94 ACC 0.5 on epoch=49
06/22/2022 11:30:23 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/22/2022 11:30:24 - INFO - __main__ - Step 110 Global step 110 Train loss 1.06 on epoch=54
06/22/2022 11:30:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=59
06/22/2022 11:30:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=64
06/22/2022 11:30:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=69
06/22/2022 11:30:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=74
06/22/2022 11:30:29 - INFO - __main__ - Global step 150 Train loss 0.83 ACC 0.5 on epoch=74
06/22/2022 11:30:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=79
06/22/2022 11:30:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.51 on epoch=84
06/22/2022 11:30:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.46 on epoch=89
06/22/2022 11:30:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.43 on epoch=94
06/22/2022 11:30:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=99
06/22/2022 11:30:36 - INFO - __main__ - Global step 200 Train loss 0.48 ACC 0.5 on epoch=99
06/22/2022 11:30:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/22/2022 11:30:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=109
06/22/2022 11:30:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=114
06/22/2022 11:30:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=119
06/22/2022 11:30:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/22/2022 11:30:42 - INFO - __main__ - Global step 250 Train loss 0.40 ACC 0.5 on epoch=124
06/22/2022 11:30:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=129
06/22/2022 11:30:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=134
06/22/2022 11:30:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=139
06/22/2022 11:30:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=144
06/22/2022 11:30:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=149
06/22/2022 11:30:49 - INFO - __main__ - Global step 300 Train loss 0.34 ACC 0.5 on epoch=149
06/22/2022 11:30:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/22/2022 11:30:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=159
06/22/2022 11:30:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=164
06/22/2022 11:30:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=169
06/22/2022 11:30:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=174
06/22/2022 11:30:55 - INFO - __main__ - Global step 350 Train loss 0.33 ACC 0.5 on epoch=174
06/22/2022 11:30:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=179
06/22/2022 11:30:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=184
06/22/2022 11:30:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=189
06/22/2022 11:31:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=194
06/22/2022 11:31:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/22/2022 11:31:02 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/22/2022 11:31:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=204
06/22/2022 11:31:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/22/2022 11:31:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=214
06/22/2022 11:31:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=219
06/22/2022 11:31:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=224
06/22/2022 11:31:08 - INFO - __main__ - Global step 450 Train loss 0.28 ACC 0.5 on epoch=224
06/22/2022 11:31:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=229
06/22/2022 11:31:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=234
06/22/2022 11:31:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=239
06/22/2022 11:31:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=244
06/22/2022 11:31:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=249
06/22/2022 11:31:15 - INFO - __main__ - Global step 500 Train loss 0.29 ACC 0.5 on epoch=249
06/22/2022 11:31:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=254
06/22/2022 11:31:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=259
06/22/2022 11:31:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=264
06/22/2022 11:31:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=269
06/22/2022 11:31:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=274
06/22/2022 11:31:22 - INFO - __main__ - Global step 550 Train loss 0.28 ACC 0.5 on epoch=274
06/22/2022 11:31:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=279
06/22/2022 11:31:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=284
06/22/2022 11:31:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=289
06/22/2022 11:31:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=294
06/22/2022 11:31:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=299
06/22/2022 11:31:28 - INFO - __main__ - Global step 600 Train loss 0.25 ACC 0.5625 on epoch=299
06/22/2022 11:31:28 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=299, global_step=600
06/22/2022 11:31:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/22/2022 11:31:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=309
06/22/2022 11:31:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=314
06/22/2022 11:31:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=319
06/22/2022 11:31:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=324
06/22/2022 11:31:35 - INFO - __main__ - Global step 650 Train loss 0.21 ACC 0.625 on epoch=324
06/22/2022 11:31:35 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=324, global_step=650
06/22/2022 11:31:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=329
06/22/2022 11:31:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=334
06/22/2022 11:31:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=339
06/22/2022 11:31:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=344
06/22/2022 11:31:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=349
06/22/2022 11:31:41 - INFO - __main__ - Global step 700 Train loss 0.18 ACC 0.5625 on epoch=349
06/22/2022 11:31:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=354
06/22/2022 11:31:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/22/2022 11:31:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=364
06/22/2022 11:31:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=369
06/22/2022 11:31:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=374
06/22/2022 11:31:48 - INFO - __main__ - Global step 750 Train loss 0.17 ACC 0.5625 on epoch=374
06/22/2022 11:31:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=379
06/22/2022 11:31:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=384
06/22/2022 11:31:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/22/2022 11:31:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=394
06/22/2022 11:31:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=399
06/22/2022 11:31:55 - INFO - __main__ - Global step 800 Train loss 0.15 ACC 0.5 on epoch=399
06/22/2022 11:31:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=404
06/22/2022 11:31:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=409
06/22/2022 11:31:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=414
06/22/2022 11:31:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=419
06/22/2022 11:32:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=424
06/22/2022 11:32:01 - INFO - __main__ - Global step 850 Train loss 0.12 ACC 0.5625 on epoch=424
06/22/2022 11:32:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=429
06/22/2022 11:32:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=434
06/22/2022 11:32:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=439
06/22/2022 11:32:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=444
06/22/2022 11:32:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=449
06/22/2022 11:32:08 - INFO - __main__ - Global step 900 Train loss 0.11 ACC 0.5625 on epoch=449
06/22/2022 11:32:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=454
06/22/2022 11:32:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=459
06/22/2022 11:32:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=464
06/22/2022 11:32:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=469
06/22/2022 11:32:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=474
06/22/2022 11:32:15 - INFO - __main__ - Global step 950 Train loss 0.08 ACC 0.625 on epoch=474
06/22/2022 11:32:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=479
06/22/2022 11:32:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=484
06/22/2022 11:32:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=489
06/22/2022 11:32:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=494
06/22/2022 11:32:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=499
06/22/2022 11:32:21 - INFO - __main__ - Global step 1000 Train loss 0.07 ACC 0.65625 on epoch=499
06/22/2022 11:32:21 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=499, global_step=1000
06/22/2022 11:32:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=504
06/22/2022 11:32:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=509
06/22/2022 11:32:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=514
06/22/2022 11:32:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=519
06/22/2022 11:32:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=524
06/22/2022 11:32:28 - INFO - __main__ - Global step 1050 Train loss 0.06 ACC 0.59375 on epoch=524
06/22/2022 11:32:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/22/2022 11:32:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=534
06/22/2022 11:32:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/22/2022 11:32:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
06/22/2022 11:32:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
06/22/2022 11:32:35 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.59375 on epoch=549
06/22/2022 11:32:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
06/22/2022 11:32:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=559
06/22/2022 11:32:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=564
06/22/2022 11:32:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/22/2022 11:32:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=574
06/22/2022 11:32:42 - INFO - __main__ - Global step 1150 Train loss 0.04 ACC 0.5625 on epoch=574
06/22/2022 11:32:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
06/22/2022 11:32:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=584
06/22/2022 11:32:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=589
06/22/2022 11:32:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=594
06/22/2022 11:32:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
06/22/2022 11:32:48 - INFO - __main__ - Global step 1200 Train loss 0.06 ACC 0.5625 on epoch=599
06/22/2022 11:32:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/22/2022 11:32:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/22/2022 11:32:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/22/2022 11:32:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=619
06/22/2022 11:32:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/22/2022 11:32:55 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.5625 on epoch=624
06/22/2022 11:32:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
06/22/2022 11:32:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
06/22/2022 11:32:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=639
06/22/2022 11:33:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
06/22/2022 11:33:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/22/2022 11:33:02 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.59375 on epoch=649
06/22/2022 11:33:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/22/2022 11:33:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
06/22/2022 11:33:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/22/2022 11:33:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
06/22/2022 11:33:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
06/22/2022 11:33:09 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.53125 on epoch=674
06/22/2022 11:33:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/22/2022 11:33:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/22/2022 11:33:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/22/2022 11:33:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/22/2022 11:33:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/22/2022 11:33:15 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.59375 on epoch=699
06/22/2022 11:33:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
06/22/2022 11:33:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/22/2022 11:33:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/22/2022 11:33:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/22/2022 11:33:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/22/2022 11:33:22 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5625 on epoch=724
06/22/2022 11:33:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/22/2022 11:33:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/22/2022 11:33:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=739
06/22/2022 11:33:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/22/2022 11:33:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
06/22/2022 11:33:28 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.59375 on epoch=749
06/22/2022 11:33:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
06/22/2022 11:33:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/22/2022 11:33:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/22/2022 11:33:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/22/2022 11:33:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/22/2022 11:33:35 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.59375 on epoch=774
06/22/2022 11:33:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/22/2022 11:33:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
06/22/2022 11:33:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/22/2022 11:33:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/22/2022 11:33:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/22/2022 11:33:42 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.59375 on epoch=799
06/22/2022 11:33:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/22/2022 11:33:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/22/2022 11:33:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
06/22/2022 11:33:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/22/2022 11:33:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/22/2022 11:33:48 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.625 on epoch=824
06/22/2022 11:33:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/22/2022 11:33:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/22/2022 11:33:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/22/2022 11:33:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/22/2022 11:33:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/22/2022 11:33:55 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.625 on epoch=849
06/22/2022 11:33:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/22/2022 11:33:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
06/22/2022 11:33:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/22/2022 11:34:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
06/22/2022 11:34:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/22/2022 11:34:02 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.625 on epoch=874
06/22/2022 11:34:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/22/2022 11:34:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
06/22/2022 11:34:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/22/2022 11:34:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/22/2022 11:34:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
06/22/2022 11:34:08 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.625 on epoch=899
06/22/2022 11:34:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/22/2022 11:34:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/22/2022 11:34:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=914
06/22/2022 11:34:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/22/2022 11:34:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/22/2022 11:34:15 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.625 on epoch=924
06/22/2022 11:34:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/22/2022 11:34:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/22/2022 11:34:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/22/2022 11:34:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/22/2022 11:34:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/22/2022 11:34:22 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.625 on epoch=949
06/22/2022 11:34:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/22/2022 11:34:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/22/2022 11:34:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/22/2022 11:34:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/22/2022 11:34:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/22/2022 11:34:28 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.625 on epoch=974
06/22/2022 11:34:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/22/2022 11:34:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/22/2022 11:34:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/22/2022 11:34:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/22/2022 11:34:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/22/2022 11:34:35 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.625 on epoch=999
06/22/2022 11:34:35 - INFO - __main__ - save last model!
06/22/2022 11:34:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 11:34:35 - INFO - __main__ - Start tokenizing ... 40430 instances
06/22/2022 11:34:35 - INFO - __main__ - Printing 3 examples
06/22/2022 11:34:35 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/22/2022 11:34:35 - INFO - __main__ - ['not_duplicate']
06/22/2022 11:34:35 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/22/2022 11:34:35 - INFO - __main__ - ['not_duplicate']
06/22/2022 11:34:35 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/22/2022 11:34:35 - INFO - __main__ - ['duplicate']
06/22/2022 11:34:35 - INFO - __main__ - Tokenizing Input ...
06/22/2022 11:34:53 - INFO - __main__ - Tokenizing Output ...
06/22/2022 11:35:34 - INFO - __main__ - Loaded 40430 examples from test data
06/22/2022 11:48:48 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.2_8_predictions.txt
06/22/2022 11:48:48 - INFO - __main__ - ACC on test data: 0.5176
06/22/2022 11:48:48 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.2, bsz=8, dev_performance=0.65625, test_performance=0.5175612169181301
06/24/2022 06:21:39 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-multitask-nopara2para-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-nopara2para-5e-1-4-20-t5base/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
06/24/2022 06:21:39 - INFO - __main__ - models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp
06/24/2022 06:21:39 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-multitask-nopara2para-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-nopara2para-5e-1-4-20-t5base/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
06/24/2022 06:21:39 - INFO - __main__ - models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp
06/24/2022 06:21:40 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/24/2022 06:21:40 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/24/2022 06:21:40 - INFO - __main__ - args.device: cuda:0
06/24/2022 06:21:40 - INFO - __main__ - Using 2 gpus
06/24/2022 06:21:40 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/24/2022 06:21:40 - INFO - __main__ - args.device: cuda:1
06/24/2022 06:21:40 - INFO - __main__ - Using 2 gpus
06/24/2022 06:21:40 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/24/2022 06:21:45 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.5, bsz=8 ...
06/24/2022 06:21:46 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:21:46 - INFO - __main__ - Printing 3 examples
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:21:46 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:21:46 - INFO - __main__ - Printing 3 examples
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:21:46 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:21:46 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:21:46 - INFO - __main__ - Printing 3 examples
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:21:46 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:21:46 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:21:46 - INFO - __main__ - Printing 3 examples
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:21:46 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:21:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:21:46 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:21:46 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:21:52 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 06:21:52 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 06:21:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:21:52 - INFO - __main__ - Starting training!
06/24/2022 06:21:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:21:58 - INFO - __main__ - Starting training!
06/24/2022 06:21:59 - INFO - __main__ - Step 10 Global step 10 Train loss 5.50 on epoch=4
06/24/2022 06:22:01 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=9
06/24/2022 06:22:02 - INFO - __main__ - Step 30 Global step 30 Train loss 2.33 on epoch=14
06/24/2022 06:22:03 - INFO - __main__ - Step 40 Global step 40 Train loss 1.46 on epoch=19
06/24/2022 06:22:04 - INFO - __main__ - Step 50 Global step 50 Train loss 0.83 on epoch=24
06/24/2022 06:22:05 - INFO - __main__ - Global step 50 Train loss 2.70 ACC 0.5 on epoch=24
06/24/2022 06:22:05 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 06:22:06 - INFO - __main__ - Step 60 Global step 60 Train loss 0.62 on epoch=29
06/24/2022 06:22:07 - INFO - __main__ - Step 70 Global step 70 Train loss 0.45 on epoch=34
06/24/2022 06:22:08 - INFO - __main__ - Step 80 Global step 80 Train loss 0.49 on epoch=39
06/24/2022 06:22:10 - INFO - __main__ - Step 90 Global step 90 Train loss 0.41 on epoch=44
06/24/2022 06:22:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.35 on epoch=49
06/24/2022 06:22:11 - INFO - __main__ - Global step 100 Train loss 0.47 ACC 0.5 on epoch=49
06/24/2022 06:22:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
06/24/2022 06:22:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.34 on epoch=59
06/24/2022 06:22:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=64
06/24/2022 06:22:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.29 on epoch=69
06/24/2022 06:22:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.32 on epoch=74
06/24/2022 06:22:18 - INFO - __main__ - Global step 150 Train loss 0.33 ACC 0.5 on epoch=74
06/24/2022 06:22:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.34 on epoch=79
06/24/2022 06:22:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=84
06/24/2022 06:22:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=89
06/24/2022 06:22:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=94
06/24/2022 06:22:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=99
06/24/2022 06:22:24 - INFO - __main__ - Global step 200 Train loss 0.28 ACC 0.5 on epoch=99
06/24/2022 06:22:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=104
06/24/2022 06:22:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=109
06/24/2022 06:22:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=114
06/24/2022 06:22:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=119
06/24/2022 06:22:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=124
06/24/2022 06:22:31 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.5 on epoch=124
06/24/2022 06:22:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=129
06/24/2022 06:22:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=134
06/24/2022 06:22:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=139
06/24/2022 06:22:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/24/2022 06:22:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/24/2022 06:22:37 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5 on epoch=149
06/24/2022 06:22:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 06:22:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
06/24/2022 06:22:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=164
06/24/2022 06:22:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/24/2022 06:22:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/24/2022 06:22:44 - INFO - __main__ - Global step 350 Train loss 0.23 ACC 0.5 on epoch=174
06/24/2022 06:22:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=179
06/24/2022 06:22:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=184
06/24/2022 06:22:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=189
06/24/2022 06:22:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=194
06/24/2022 06:22:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/24/2022 06:22:51 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.5 on epoch=199
06/24/2022 06:22:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=204
06/24/2022 06:22:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=209
06/24/2022 06:22:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
06/24/2022 06:22:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=219
06/24/2022 06:22:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=224
06/24/2022 06:22:57 - INFO - __main__ - Global step 450 Train loss 0.22 ACC 0.59375 on epoch=224
06/24/2022 06:22:57 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=224, global_step=450
06/24/2022 06:22:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 06:23:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=234
06/24/2022 06:23:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=239
06/24/2022 06:23:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=244
06/24/2022 06:23:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=249
06/24/2022 06:23:04 - INFO - __main__ - Global step 500 Train loss 0.21 ACC 0.5625 on epoch=249
06/24/2022 06:23:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=254
06/24/2022 06:23:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=259
06/24/2022 06:23:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 06:23:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=269
06/24/2022 06:23:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=274
06/24/2022 06:23:10 - INFO - __main__ - Global step 550 Train loss 0.18 ACC 0.6875 on epoch=274
06/24/2022 06:23:10 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.6875 on epoch=274, global_step=550
06/24/2022 06:23:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=279
06/24/2022 06:23:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=284
06/24/2022 06:23:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=289
06/24/2022 06:23:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=294
06/24/2022 06:23:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=299
06/24/2022 06:23:17 - INFO - __main__ - Global step 600 Train loss 0.17 ACC 0.59375 on epoch=299
06/24/2022 06:23:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=304
06/24/2022 06:23:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=309
06/24/2022 06:23:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=314
06/24/2022 06:23:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=319
06/24/2022 06:23:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=324
06/24/2022 06:23:24 - INFO - __main__ - Global step 650 Train loss 0.15 ACC 0.65625 on epoch=324
06/24/2022 06:23:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=329
06/24/2022 06:23:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=334
06/24/2022 06:23:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=339
06/24/2022 06:23:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=344
06/24/2022 06:23:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=349
06/24/2022 06:23:30 - INFO - __main__ - Global step 700 Train loss 0.13 ACC 0.59375 on epoch=349
06/24/2022 06:23:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=354
06/24/2022 06:23:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/24/2022 06:23:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=364
06/24/2022 06:23:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=369
06/24/2022 06:23:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=374
06/24/2022 06:23:37 - INFO - __main__ - Global step 750 Train loss 0.10 ACC 0.6875 on epoch=374
06/24/2022 06:23:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=379
06/24/2022 06:23:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=384
06/24/2022 06:23:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=389
06/24/2022 06:23:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=394
06/24/2022 06:23:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=399
06/24/2022 06:23:43 - INFO - __main__ - Global step 800 Train loss 0.09 ACC 0.71875 on epoch=399
06/24/2022 06:23:43 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=399, global_step=800
06/24/2022 06:23:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=404
06/24/2022 06:23:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=409
06/24/2022 06:23:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=414
06/24/2022 06:23:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/24/2022 06:23:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
06/24/2022 06:23:50 - INFO - __main__ - Global step 850 Train loss 0.06 ACC 0.625 on epoch=424
06/24/2022 06:23:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
06/24/2022 06:23:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=434
06/24/2022 06:23:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=439
06/24/2022 06:23:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
06/24/2022 06:23:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/24/2022 06:23:56 - INFO - __main__ - Global step 900 Train loss 0.04 ACC 0.625 on epoch=449
06/24/2022 06:23:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/24/2022 06:23:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=459
06/24/2022 06:24:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=464
06/24/2022 06:24:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/24/2022 06:24:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=474
06/24/2022 06:24:03 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.59375 on epoch=474
06/24/2022 06:24:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/24/2022 06:24:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
06/24/2022 06:24:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/24/2022 06:24:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/24/2022 06:24:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 06:24:09 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.59375 on epoch=499
06/24/2022 06:24:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/24/2022 06:24:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/24/2022 06:24:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 06:24:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
06/24/2022 06:24:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
06/24/2022 06:24:16 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.59375 on epoch=524
06/24/2022 06:24:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/24/2022 06:24:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 06:24:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/24/2022 06:24:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 06:24:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/24/2022 06:24:23 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.625 on epoch=549
06/24/2022 06:24:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
06/24/2022 06:24:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/24/2022 06:24:26 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 06:24:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/24/2022 06:24:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/24/2022 06:24:29 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.625 on epoch=574
06/24/2022 06:24:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
06/24/2022 06:24:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 06:24:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
06/24/2022 06:24:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=594
06/24/2022 06:24:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
06/24/2022 06:24:36 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.65625 on epoch=599
06/24/2022 06:24:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 06:24:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
06/24/2022 06:24:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 06:24:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 06:24:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/24/2022 06:24:42 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.625 on epoch=624
06/24/2022 06:24:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 06:24:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/24/2022 06:24:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
06/24/2022 06:24:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/24/2022 06:24:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 06:24:49 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.6875 on epoch=649
06/24/2022 06:24:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/24/2022 06:24:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 06:24:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 06:24:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 06:24:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 06:24:55 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.625 on epoch=674
06/24/2022 06:24:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 06:24:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 06:24:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/24/2022 06:25:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 06:25:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 06:25:02 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.625 on epoch=699
06/24/2022 06:25:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 06:25:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 06:25:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 06:25:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/24/2022 06:25:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 06:25:08 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.6875 on epoch=724
06/24/2022 06:25:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 06:25:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 06:25:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/24/2022 06:25:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 06:25:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/24/2022 06:25:15 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
06/24/2022 06:25:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 06:25:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/24/2022 06:25:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/24/2022 06:25:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/24/2022 06:25:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 06:25:21 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
06/24/2022 06:25:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 06:25:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 06:25:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 06:25:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 06:25:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 06:25:28 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.59375 on epoch=799
06/24/2022 06:25:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 06:25:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/24/2022 06:25:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
06/24/2022 06:25:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 06:25:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 06:25:35 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.65625 on epoch=824
06/24/2022 06:25:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 06:25:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 06:25:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/24/2022 06:25:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/24/2022 06:25:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 06:25:41 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.625 on epoch=849
06/24/2022 06:25:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 06:25:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 06:25:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 06:25:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 06:25:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 06:25:48 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.53125 on epoch=874
06/24/2022 06:25:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 06:25:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 06:25:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 06:25:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 06:25:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 06:25:54 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5625 on epoch=899
06/24/2022 06:25:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 06:25:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 06:25:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 06:25:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 06:26:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 06:26:01 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.625 on epoch=924
06/24/2022 06:26:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/24/2022 06:26:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 06:26:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 06:26:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 06:26:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 06:26:07 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.6875 on epoch=949
06/24/2022 06:26:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 06:26:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 06:26:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=964
06/24/2022 06:26:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 06:26:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
06/24/2022 06:26:14 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.65625 on epoch=974
06/24/2022 06:26:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
06/24/2022 06:26:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=984
06/24/2022 06:26:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/24/2022 06:26:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 06:26:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 06:26:21 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.65625 on epoch=999
06/24/2022 06:26:21 - INFO - __main__ - save last model!
06/24/2022 06:26:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 06:26:21 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 06:26:21 - INFO - __main__ - Printing 3 examples
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 06:26:21 - INFO - __main__ - ['duplicate']
06/24/2022 06:26:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:26:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:26:21 - INFO - __main__ - Printing 3 examples
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:26:21 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:26:21 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:26:21 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:26:21 - INFO - __main__ - Printing 3 examples
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:26:21 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:26:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:26:21 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:26:21 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:26:27 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 06:26:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:26:27 - INFO - __main__ - Starting training!
06/24/2022 06:26:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:27:20 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 06:39:59 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.5_8_predictions.txt
06/24/2022 06:39:59 - INFO - __main__ - ACC on test data: 0.5326
06/24/2022 06:40:00 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.5, bsz=8, dev_performance=0.71875, test_performance=0.5326242888943854
06/24/2022 06:40:00 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.4, bsz=8 ...
06/24/2022 06:40:01 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:40:01 - INFO - __main__ - Printing 3 examples
06/24/2022 06:40:01 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:40:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:40:01 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:40:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:40:01 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:40:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:40:01 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:40:01 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:40:01 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:40:01 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:40:01 - INFO - __main__ - Printing 3 examples
06/24/2022 06:40:01 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:40:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:40:01 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:40:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:40:01 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:40:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:40:01 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:40:01 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:40:01 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:40:06 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 06:40:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:40:07 - INFO - __main__ - Starting training!
06/24/2022 06:40:08 - INFO - __main__ - Step 10 Global step 10 Train loss 5.87 on epoch=4
06/24/2022 06:40:09 - INFO - __main__ - Step 20 Global step 20 Train loss 3.93 on epoch=9
06/24/2022 06:40:10 - INFO - __main__ - Step 30 Global step 30 Train loss 2.99 on epoch=14
06/24/2022 06:40:12 - INFO - __main__ - Step 40 Global step 40 Train loss 2.09 on epoch=19
06/24/2022 06:40:13 - INFO - __main__ - Step 50 Global step 50 Train loss 1.43 on epoch=24
06/24/2022 06:40:13 - INFO - __main__ - Global step 50 Train loss 3.26 ACC 0.5 on epoch=24
06/24/2022 06:40:14 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 06:40:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=29
06/24/2022 06:40:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.64 on epoch=34
06/24/2022 06:40:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.63 on epoch=39
06/24/2022 06:40:18 - INFO - __main__ - Step 90 Global step 90 Train loss 0.52 on epoch=44
06/24/2022 06:40:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.47 on epoch=49
06/24/2022 06:40:20 - INFO - __main__ - Global step 100 Train loss 0.65 ACC 0.5 on epoch=49
06/24/2022 06:40:21 - INFO - __main__ - Step 110 Global step 110 Train loss 0.40 on epoch=54
06/24/2022 06:40:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
06/24/2022 06:40:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/24/2022 06:40:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.30 on epoch=69
06/24/2022 06:40:26 - INFO - __main__ - Step 150 Global step 150 Train loss 0.30 on epoch=74
06/24/2022 06:40:27 - INFO - __main__ - Global step 150 Train loss 0.34 ACC 0.5 on epoch=74
06/24/2022 06:40:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
06/24/2022 06:40:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.35 on epoch=84
06/24/2022 06:40:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.31 on epoch=89
06/24/2022 06:40:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.33 on epoch=94
06/24/2022 06:40:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=99
06/24/2022 06:40:33 - INFO - __main__ - Global step 200 Train loss 0.32 ACC 0.5 on epoch=99
06/24/2022 06:40:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.34 on epoch=104
06/24/2022 06:40:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
06/24/2022 06:40:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/24/2022 06:40:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=119
06/24/2022 06:40:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=124
06/24/2022 06:40:40 - INFO - __main__ - Global step 250 Train loss 0.29 ACC 0.5 on epoch=124
06/24/2022 06:40:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/24/2022 06:40:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=134
06/24/2022 06:40:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=139
06/24/2022 06:40:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 06:40:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=149
06/24/2022 06:40:47 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.5 on epoch=149
06/24/2022 06:40:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=154
06/24/2022 06:40:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/24/2022 06:40:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=164
06/24/2022 06:40:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/24/2022 06:40:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=174
06/24/2022 06:40:53 - INFO - __main__ - Global step 350 Train loss 0.27 ACC 0.5 on epoch=174
06/24/2022 06:40:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=179
06/24/2022 06:40:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=184
06/24/2022 06:40:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=189
06/24/2022 06:40:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=194
06/24/2022 06:40:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=199
06/24/2022 06:41:00 - INFO - __main__ - Global step 400 Train loss 0.25 ACC 0.5 on epoch=199
06/24/2022 06:41:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/24/2022 06:41:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=209
06/24/2022 06:41:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=214
06/24/2022 06:41:05 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/24/2022 06:41:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=224
06/24/2022 06:41:07 - INFO - __main__ - Global step 450 Train loss 0.23 ACC 0.5 on epoch=224
06/24/2022 06:41:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 06:41:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=234
06/24/2022 06:41:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=239
06/24/2022 06:41:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=244
06/24/2022 06:41:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=249
06/24/2022 06:41:13 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/24/2022 06:41:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=254
06/24/2022 06:41:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=259
06/24/2022 06:41:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=264
06/24/2022 06:41:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=269
06/24/2022 06:41:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=274
06/24/2022 06:41:20 - INFO - __main__ - Global step 550 Train loss 0.20 ACC 0.46875 on epoch=274
06/24/2022 06:41:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=279
06/24/2022 06:41:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=284
06/24/2022 06:41:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=289
06/24/2022 06:41:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=294
06/24/2022 06:41:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=299
06/24/2022 06:41:26 - INFO - __main__ - Global step 600 Train loss 0.21 ACC 0.46875 on epoch=299
06/24/2022 06:41:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=304
06/24/2022 06:41:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/24/2022 06:41:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=314
06/24/2022 06:41:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=319
06/24/2022 06:41:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=324
06/24/2022 06:41:33 - INFO - __main__ - Global step 650 Train loss 0.18 ACC 0.53125 on epoch=324
06/24/2022 06:41:33 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=324, global_step=650
06/24/2022 06:41:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=329
06/24/2022 06:41:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=334
06/24/2022 06:41:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=339
06/24/2022 06:41:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=344
06/24/2022 06:41:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=349
06/24/2022 06:41:40 - INFO - __main__ - Global step 700 Train loss 0.16 ACC 0.5 on epoch=349
06/24/2022 06:41:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=354
06/24/2022 06:41:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=359
06/24/2022 06:41:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=364
06/24/2022 06:41:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=369
06/24/2022 06:41:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=374
06/24/2022 06:41:46 - INFO - __main__ - Global step 750 Train loss 0.13 ACC 0.625 on epoch=374
06/24/2022 06:41:46 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=374, global_step=750
06/24/2022 06:41:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=379
06/24/2022 06:41:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=384
06/24/2022 06:41:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=389
06/24/2022 06:41:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=394
06/24/2022 06:41:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=399
06/24/2022 06:41:53 - INFO - __main__ - Global step 800 Train loss 0.09 ACC 0.65625 on epoch=399
06/24/2022 06:41:53 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=399, global_step=800
06/24/2022 06:41:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=404
06/24/2022 06:41:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=409
06/24/2022 06:41:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=414
06/24/2022 06:41:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=419
06/24/2022 06:41:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=424
06/24/2022 06:41:59 - INFO - __main__ - Global step 850 Train loss 0.07 ACC 0.625 on epoch=424
06/24/2022 06:42:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=429
06/24/2022 06:42:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=434
06/24/2022 06:42:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=439
06/24/2022 06:42:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=444
06/24/2022 06:42:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=449
06/24/2022 06:42:06 - INFO - __main__ - Global step 900 Train loss 0.06 ACC 0.53125 on epoch=449
06/24/2022 06:42:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=454
06/24/2022 06:42:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
06/24/2022 06:42:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=464
06/24/2022 06:42:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
06/24/2022 06:42:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=474
06/24/2022 06:42:12 - INFO - __main__ - Global step 950 Train loss 0.05 ACC 0.53125 on epoch=474
06/24/2022 06:42:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
06/24/2022 06:42:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
06/24/2022 06:42:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=489
06/24/2022 06:42:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/24/2022 06:42:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=499
06/24/2022 06:42:19 - INFO - __main__ - Global step 1000 Train loss 0.03 ACC 0.53125 on epoch=499
06/24/2022 06:42:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 06:42:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/24/2022 06:42:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=514
06/24/2022 06:42:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/24/2022 06:42:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/24/2022 06:42:26 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.5625 on epoch=524
06/24/2022 06:42:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/24/2022 06:42:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
06/24/2022 06:42:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/24/2022 06:42:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
06/24/2022 06:42:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/24/2022 06:42:32 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5625 on epoch=549
06/24/2022 06:42:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
06/24/2022 06:42:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
06/24/2022 06:42:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
06/24/2022 06:42:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/24/2022 06:42:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/24/2022 06:42:39 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.59375 on epoch=574
06/24/2022 06:42:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 06:42:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/24/2022 06:42:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/24/2022 06:42:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
06/24/2022 06:42:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/24/2022 06:42:45 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.53125 on epoch=599
06/24/2022 06:42:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 06:42:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 06:42:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/24/2022 06:42:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/24/2022 06:42:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/24/2022 06:42:52 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.59375 on epoch=624
06/24/2022 06:42:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 06:42:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=634
06/24/2022 06:42:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 06:42:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/24/2022 06:42:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
06/24/2022 06:42:59 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.625 on epoch=649
06/24/2022 06:43:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 06:43:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
06/24/2022 06:43:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 06:43:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
06/24/2022 06:43:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
06/24/2022 06:43:05 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.59375 on epoch=674
06/24/2022 06:43:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 06:43:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 06:43:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/24/2022 06:43:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/24/2022 06:43:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 06:43:12 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/24/2022 06:43:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=704
06/24/2022 06:43:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/24/2022 06:43:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 06:43:17 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 06:43:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/24/2022 06:43:18 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5 on epoch=724
06/24/2022 06:43:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/24/2022 06:43:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 06:43:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/24/2022 06:43:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 06:43:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/24/2022 06:43:25 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.53125 on epoch=749
06/24/2022 06:43:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 06:43:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/24/2022 06:43:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/24/2022 06:43:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 06:43:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 06:43:31 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
06/24/2022 06:43:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 06:43:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 06:43:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 06:43:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 06:43:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 06:43:38 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5625 on epoch=799
06/24/2022 06:43:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
06/24/2022 06:43:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/24/2022 06:43:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 06:43:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 06:43:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/24/2022 06:43:45 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
06/24/2022 06:43:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 06:43:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 06:43:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 06:43:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 06:43:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 06:43:51 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.59375 on epoch=849
06/24/2022 06:43:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/24/2022 06:43:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 06:43:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 06:43:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 06:43:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 06:43:58 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.59375 on epoch=874
06/24/2022 06:43:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=879
06/24/2022 06:44:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 06:44:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 06:44:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 06:44:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 06:44:04 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.59375 on epoch=899
06/24/2022 06:44:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
06/24/2022 06:44:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 06:44:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 06:44:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 06:44:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 06:44:11 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.625 on epoch=924
06/24/2022 06:44:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 06:44:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 06:44:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 06:44:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=944
06/24/2022 06:44:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 06:44:18 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.59375 on epoch=949
06/24/2022 06:44:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 06:44:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 06:44:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/24/2022 06:44:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 06:44:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=974
06/24/2022 06:44:24 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.53125 on epoch=974
06/24/2022 06:44:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
06/24/2022 06:44:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 06:44:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 06:44:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 06:44:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 06:44:31 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
06/24/2022 06:44:31 - INFO - __main__ - save last model!
06/24/2022 06:44:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 06:44:31 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 06:44:31 - INFO - __main__ - Printing 3 examples
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 06:44:31 - INFO - __main__ - ['duplicate']
06/24/2022 06:44:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:44:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:44:31 - INFO - __main__ - Printing 3 examples
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:44:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:44:31 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:44:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:44:31 - INFO - __main__ - Printing 3 examples
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:44:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:44:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:44:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:44:31 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:44:37 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 06:44:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:44:38 - INFO - __main__ - Starting training!
06/24/2022 06:44:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:45:30 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 06:58:21 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.4_8_predictions.txt
06/24/2022 06:58:21 - INFO - __main__ - ACC on test data: 0.5411
06/24/2022 06:58:21 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.4, bsz=8, dev_performance=0.65625, test_performance=0.5411080880534257
06/24/2022 06:58:22 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.3, bsz=8 ...
06/24/2022 06:58:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:58:22 - INFO - __main__ - Printing 3 examples
06/24/2022 06:58:22 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:58:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:58:22 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:58:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:58:22 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:58:22 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:58:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:58:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:58:23 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:58:23 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:58:23 - INFO - __main__ - Printing 3 examples
06/24/2022 06:58:23 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:58:23 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:58:23 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:58:23 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:58:23 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:58:23 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:58:23 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:58:23 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:58:23 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:58:28 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 06:58:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:58:28 - INFO - __main__ - Starting training!
06/24/2022 06:58:30 - INFO - __main__ - Step 10 Global step 10 Train loss 6.29 on epoch=4
06/24/2022 06:58:31 - INFO - __main__ - Step 20 Global step 20 Train loss 4.61 on epoch=9
06/24/2022 06:58:32 - INFO - __main__ - Step 30 Global step 30 Train loss 3.58 on epoch=14
06/24/2022 06:58:34 - INFO - __main__ - Step 40 Global step 40 Train loss 2.73 on epoch=19
06/24/2022 06:58:35 - INFO - __main__ - Step 50 Global step 50 Train loss 2.07 on epoch=24
06/24/2022 06:58:35 - INFO - __main__ - Global step 50 Train loss 3.86 ACC 0.0 on epoch=24
06/24/2022 06:58:35 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 06:58:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.62 on epoch=29
06/24/2022 06:58:38 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=34
06/24/2022 06:58:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=39
06/24/2022 06:58:41 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=44
06/24/2022 06:58:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=49
06/24/2022 06:58:42 - INFO - __main__ - Global step 100 Train loss 1.03 ACC 0.5 on epoch=49
06/24/2022 06:58:42 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 06:58:44 - INFO - __main__ - Step 110 Global step 110 Train loss 0.65 on epoch=54
06/24/2022 06:58:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.51 on epoch=59
06/24/2022 06:58:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.42 on epoch=64
06/24/2022 06:58:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.43 on epoch=69
06/24/2022 06:58:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.32 on epoch=74
06/24/2022 06:58:49 - INFO - __main__ - Global step 150 Train loss 0.47 ACC 0.5 on epoch=74
06/24/2022 06:58:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.38 on epoch=79
06/24/2022 06:58:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.35 on epoch=84
06/24/2022 06:58:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.34 on epoch=89
06/24/2022 06:58:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=94
06/24/2022 06:58:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=99
06/24/2022 06:58:57 - INFO - __main__ - Global step 200 Train loss 0.35 ACC 0.5 on epoch=99
06/24/2022 06:58:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=104
06/24/2022 06:58:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
06/24/2022 06:59:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=114
06/24/2022 06:59:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 06:59:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/24/2022 06:59:03 - INFO - __main__ - Global step 250 Train loss 0.27 ACC 0.5 on epoch=124
06/24/2022 06:59:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/24/2022 06:59:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=134
06/24/2022 06:59:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/24/2022 06:59:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=144
06/24/2022 06:59:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=149
06/24/2022 06:59:10 - INFO - __main__ - Global step 300 Train loss 0.27 ACC 0.5 on epoch=149
06/24/2022 06:59:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=154
06/24/2022 06:59:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/24/2022 06:59:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=164
06/24/2022 06:59:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=169
06/24/2022 06:59:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=174
06/24/2022 06:59:18 - INFO - __main__ - Global step 350 Train loss 0.27 ACC 0.5 on epoch=174
06/24/2022 06:59:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=179
06/24/2022 06:59:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=184
06/24/2022 06:59:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=189
06/24/2022 06:59:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=194
06/24/2022 06:59:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/24/2022 06:59:25 - INFO - __main__ - Global step 400 Train loss 0.26 ACC 0.53125 on epoch=199
06/24/2022 06:59:25 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=199, global_step=400
06/24/2022 06:59:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/24/2022 06:59:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=209
06/24/2022 06:59:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/24/2022 06:59:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=219
06/24/2022 06:59:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/24/2022 06:59:32 - INFO - __main__ - Global step 450 Train loss 0.28 ACC 0.5 on epoch=224
06/24/2022 06:59:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=229
06/24/2022 06:59:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=234
06/24/2022 06:59:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=239
06/24/2022 06:59:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=244
06/24/2022 06:59:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=249
06/24/2022 06:59:39 - INFO - __main__ - Global step 500 Train loss 0.25 ACC 0.46875 on epoch=249
06/24/2022 06:59:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=254
06/24/2022 06:59:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=259
06/24/2022 06:59:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=264
06/24/2022 06:59:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=269
06/24/2022 06:59:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=274
06/24/2022 06:59:46 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.5 on epoch=274
06/24/2022 06:59:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/24/2022 06:59:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=284
06/24/2022 06:59:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=289
06/24/2022 06:59:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=294
06/24/2022 06:59:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=299
06/24/2022 06:59:53 - INFO - __main__ - Global step 600 Train loss 0.22 ACC 0.5 on epoch=299
06/24/2022 06:59:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=304
06/24/2022 06:59:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/24/2022 06:59:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=314
06/24/2022 06:59:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=319
06/24/2022 06:59:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=324
06/24/2022 07:00:00 - INFO - __main__ - Global step 650 Train loss 0.20 ACC 0.53125 on epoch=324
06/24/2022 07:00:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=329
06/24/2022 07:00:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/24/2022 07:00:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=339
06/24/2022 07:00:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=344
06/24/2022 07:00:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=349
06/24/2022 07:00:07 - INFO - __main__ - Global step 700 Train loss 0.21 ACC 0.5 on epoch=349
06/24/2022 07:00:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=354
06/24/2022 07:00:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=359
06/24/2022 07:00:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=364
06/24/2022 07:00:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=369
06/24/2022 07:00:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=374
06/24/2022 07:00:14 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.46875 on epoch=374
06/24/2022 07:00:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=379
06/24/2022 07:00:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=384
06/24/2022 07:00:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/24/2022 07:00:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=394
06/24/2022 07:00:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=399
06/24/2022 07:00:20 - INFO - __main__ - Global step 800 Train loss 0.20 ACC 0.5 on epoch=399
06/24/2022 07:00:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=404
06/24/2022 07:00:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=409
06/24/2022 07:00:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=414
06/24/2022 07:00:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=419
06/24/2022 07:00:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=424
06/24/2022 07:00:27 - INFO - __main__ - Global step 850 Train loss 0.19 ACC 0.5 on epoch=424
06/24/2022 07:00:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=429
06/24/2022 07:00:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=434
06/24/2022 07:00:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/24/2022 07:00:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=444
06/24/2022 07:00:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=449
06/24/2022 07:00:33 - INFO - __main__ - Global step 900 Train loss 0.16 ACC 0.5 on epoch=449
06/24/2022 07:00:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=454
06/24/2022 07:00:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=459
06/24/2022 07:00:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=464
06/24/2022 07:00:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=469
06/24/2022 07:00:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=474
06/24/2022 07:00:40 - INFO - __main__ - Global step 950 Train loss 0.15 ACC 0.625 on epoch=474
06/24/2022 07:00:40 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=474, global_step=950
06/24/2022 07:00:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=479
06/24/2022 07:00:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=484
06/24/2022 07:00:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=489
06/24/2022 07:00:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=494
06/24/2022 07:00:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=499
06/24/2022 07:00:47 - INFO - __main__ - Global step 1000 Train loss 0.13 ACC 0.5625 on epoch=499
06/24/2022 07:00:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=504
06/24/2022 07:00:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=509
06/24/2022 07:00:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=514
06/24/2022 07:00:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=519
06/24/2022 07:00:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=524
06/24/2022 07:00:53 - INFO - __main__ - Global step 1050 Train loss 0.12 ACC 0.59375 on epoch=524
06/24/2022 07:00:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=529
06/24/2022 07:00:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=534
06/24/2022 07:00:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=539
06/24/2022 07:00:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=544
06/24/2022 07:00:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=549
06/24/2022 07:01:00 - INFO - __main__ - Global step 1100 Train loss 0.10 ACC 0.46875 on epoch=549
06/24/2022 07:01:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=554
06/24/2022 07:01:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=559
06/24/2022 07:01:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=564
06/24/2022 07:01:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=569
06/24/2022 07:01:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=574
06/24/2022 07:01:06 - INFO - __main__ - Global step 1150 Train loss 0.10 ACC 0.5 on epoch=574
06/24/2022 07:01:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=579
06/24/2022 07:01:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=584
06/24/2022 07:01:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=589
06/24/2022 07:01:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
06/24/2022 07:01:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=599
06/24/2022 07:01:13 - INFO - __main__ - Global step 1200 Train loss 0.09 ACC 0.46875 on epoch=599
06/24/2022 07:01:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=604
06/24/2022 07:01:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=609
06/24/2022 07:01:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=614
06/24/2022 07:01:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=619
06/24/2022 07:01:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=624
06/24/2022 07:01:19 - INFO - __main__ - Global step 1250 Train loss 0.07 ACC 0.5 on epoch=624
06/24/2022 07:01:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=629
06/24/2022 07:01:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=634
06/24/2022 07:01:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=639
06/24/2022 07:01:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=644
06/24/2022 07:01:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=649
06/24/2022 07:01:26 - INFO - __main__ - Global step 1300 Train loss 0.08 ACC 0.59375 on epoch=649
06/24/2022 07:01:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=654
06/24/2022 07:01:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
06/24/2022 07:01:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=664
06/24/2022 07:01:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=669
06/24/2022 07:01:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=674
06/24/2022 07:01:33 - INFO - __main__ - Global step 1350 Train loss 0.06 ACC 0.53125 on epoch=674
06/24/2022 07:01:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=679
06/24/2022 07:01:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=684
06/24/2022 07:01:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/24/2022 07:01:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=694
06/24/2022 07:01:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=699
06/24/2022 07:01:39 - INFO - __main__ - Global step 1400 Train loss 0.06 ACC 0.59375 on epoch=699
06/24/2022 07:01:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=704
06/24/2022 07:01:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=709
06/24/2022 07:01:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=714
06/24/2022 07:01:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=719
06/24/2022 07:01:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=724
06/24/2022 07:01:46 - INFO - __main__ - Global step 1450 Train loss 0.06 ACC 0.46875 on epoch=724
06/24/2022 07:01:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=729
06/24/2022 07:01:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=734
06/24/2022 07:01:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=739
06/24/2022 07:01:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
06/24/2022 07:01:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=749
06/24/2022 07:01:52 - INFO - __main__ - Global step 1500 Train loss 0.04 ACC 0.5625 on epoch=749
06/24/2022 07:01:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=754
06/24/2022 07:01:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
06/24/2022 07:01:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=764
06/24/2022 07:01:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/24/2022 07:01:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
06/24/2022 07:01:59 - INFO - __main__ - Global step 1550 Train loss 0.04 ACC 0.5625 on epoch=774
06/24/2022 07:02:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=779
06/24/2022 07:02:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
06/24/2022 07:02:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=789
06/24/2022 07:02:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=794
06/24/2022 07:02:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=799
06/24/2022 07:02:05 - INFO - __main__ - Global step 1600 Train loss 0.03 ACC 0.5 on epoch=799
06/24/2022 07:02:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=804
06/24/2022 07:02:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/24/2022 07:02:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=814
06/24/2022 07:02:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 07:02:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
06/24/2022 07:02:12 - INFO - __main__ - Global step 1650 Train loss 0.03 ACC 0.46875 on epoch=824
06/24/2022 07:02:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/24/2022 07:02:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
06/24/2022 07:02:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 07:02:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=844
06/24/2022 07:02:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=849
06/24/2022 07:02:19 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.46875 on epoch=849
06/24/2022 07:02:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
06/24/2022 07:02:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
06/24/2022 07:02:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
06/24/2022 07:02:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 07:02:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
06/24/2022 07:02:25 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.5 on epoch=874
06/24/2022 07:02:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/24/2022 07:02:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 07:02:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 07:02:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=894
06/24/2022 07:02:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 07:02:32 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.53125 on epoch=899
06/24/2022 07:02:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
06/24/2022 07:02:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/24/2022 07:02:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 07:02:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=919
06/24/2022 07:02:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=924
06/24/2022 07:02:38 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.46875 on epoch=924
06/24/2022 07:02:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/24/2022 07:02:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/24/2022 07:02:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
06/24/2022 07:02:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 07:02:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
06/24/2022 07:02:45 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/24/2022 07:02:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
06/24/2022 07:02:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
06/24/2022 07:02:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=964
06/24/2022 07:02:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
06/24/2022 07:02:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=974
06/24/2022 07:02:52 - INFO - __main__ - Global step 1950 Train loss 0.02 ACC 0.5625 on epoch=974
06/24/2022 07:02:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/24/2022 07:02:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 07:02:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
06/24/2022 07:02:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/24/2022 07:02:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
06/24/2022 07:02:58 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.59375 on epoch=999
06/24/2022 07:02:58 - INFO - __main__ - save last model!
06/24/2022 07:02:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:02:58 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:02:58 - INFO - __main__ - Printing 3 examples
06/24/2022 07:02:58 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:02:58 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:58 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:02:58 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:58 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:02:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:02:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:02:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:02:59 - INFO - __main__ - Printing 3 examples
06/24/2022 07:02:59 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 07:02:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:59 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 07:02:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:59 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 07:02:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:02:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:02:59 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:02:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:02:59 - INFO - __main__ - Printing 3 examples
06/24/2022 07:02:59 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 07:02:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:59 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 07:02:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:59 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 07:02:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:02:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:02:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:02:59 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:03:05 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:03:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:03:05 - INFO - __main__ - Starting training!
06/24/2022 07:03:17 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:03:59 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 07:16:43 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.3_8_predictions.txt
06/24/2022 07:16:43 - INFO - __main__ - ACC on test data: 0.4601
06/24/2022 07:16:44 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.3, bsz=8, dev_performance=0.625, test_performance=0.4600544150383379
06/24/2022 07:16:44 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.2, bsz=8 ...
06/24/2022 07:16:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:16:45 - INFO - __main__ - Printing 3 examples
06/24/2022 07:16:45 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 07:16:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:16:45 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 07:16:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:16:45 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 07:16:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:16:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:16:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:16:45 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:16:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:16:45 - INFO - __main__ - Printing 3 examples
06/24/2022 07:16:45 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 07:16:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:16:45 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 07:16:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:16:45 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 07:16:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:16:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:16:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:16:45 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:16:51 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:16:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:16:51 - INFO - __main__ - Starting training!
06/24/2022 07:16:53 - INFO - __main__ - Step 10 Global step 10 Train loss 6.25 on epoch=4
06/24/2022 07:16:54 - INFO - __main__ - Step 20 Global step 20 Train loss 5.19 on epoch=9
06/24/2022 07:16:55 - INFO - __main__ - Step 30 Global step 30 Train loss 4.39 on epoch=14
06/24/2022 07:16:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.65 on epoch=19
06/24/2022 07:16:58 - INFO - __main__ - Step 50 Global step 50 Train loss 3.31 on epoch=24
06/24/2022 07:16:58 - INFO - __main__ - Global step 50 Train loss 4.56 ACC 0.0 on epoch=24
06/24/2022 07:16:58 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 07:17:00 - INFO - __main__ - Step 60 Global step 60 Train loss 2.65 on epoch=29
06/24/2022 07:17:01 - INFO - __main__ - Step 70 Global step 70 Train loss 2.18 on epoch=34
06/24/2022 07:17:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.70 on epoch=39
06/24/2022 07:17:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.45 on epoch=44
06/24/2022 07:17:04 - INFO - __main__ - Step 100 Global step 100 Train loss 1.15 on epoch=49
06/24/2022 07:17:05 - INFO - __main__ - Global step 100 Train loss 1.83 ACC 0.5 on epoch=49
06/24/2022 07:17:05 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 07:17:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=54
06/24/2022 07:17:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=59
06/24/2022 07:17:09 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=64
06/24/2022 07:17:10 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=69
06/24/2022 07:17:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=74
06/24/2022 07:17:12 - INFO - __main__ - Global step 150 Train loss 0.78 ACC 0.5 on epoch=74
06/24/2022 07:17:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.47 on epoch=79
06/24/2022 07:17:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=84
06/24/2022 07:17:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=89
06/24/2022 07:17:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=94
06/24/2022 07:17:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.41 on epoch=99
06/24/2022 07:17:19 - INFO - __main__ - Global step 200 Train loss 0.46 ACC 0.5 on epoch=99
06/24/2022 07:17:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/24/2022 07:17:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=109
06/24/2022 07:17:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=114
06/24/2022 07:17:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.39 on epoch=119
06/24/2022 07:17:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=124
06/24/2022 07:17:25 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.5 on epoch=124
06/24/2022 07:17:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=129
06/24/2022 07:17:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=134
06/24/2022 07:17:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=139
06/24/2022 07:17:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=144
06/24/2022 07:17:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=149
06/24/2022 07:17:32 - INFO - __main__ - Global step 300 Train loss 0.34 ACC 0.5 on epoch=149
06/24/2022 07:17:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/24/2022 07:17:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=159
06/24/2022 07:17:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=164
06/24/2022 07:17:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=169
06/24/2022 07:17:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=174
06/24/2022 07:17:39 - INFO - __main__ - Global step 350 Train loss 0.31 ACC 0.5 on epoch=174
06/24/2022 07:17:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=179
06/24/2022 07:17:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=184
06/24/2022 07:17:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=189
06/24/2022 07:17:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=194
06/24/2022 07:17:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=199
06/24/2022 07:17:46 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/24/2022 07:17:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=204
06/24/2022 07:17:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=209
06/24/2022 07:17:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/24/2022 07:17:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=219
06/24/2022 07:17:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=224
06/24/2022 07:17:52 - INFO - __main__ - Global step 450 Train loss 0.28 ACC 0.5 on epoch=224
06/24/2022 07:17:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=229
06/24/2022 07:17:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=234
06/24/2022 07:17:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=239
06/24/2022 07:17:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=244
06/24/2022 07:17:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=249
06/24/2022 07:17:59 - INFO - __main__ - Global step 500 Train loss 0.26 ACC 0.5 on epoch=249
06/24/2022 07:18:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=254
06/24/2022 07:18:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=259
06/24/2022 07:18:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=264
06/24/2022 07:18:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=269
06/24/2022 07:18:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=274
06/24/2022 07:18:06 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.5 on epoch=274
06/24/2022 07:18:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=279
06/24/2022 07:18:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=284
06/24/2022 07:18:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=289
06/24/2022 07:18:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=294
06/24/2022 07:18:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=299
06/24/2022 07:18:13 - INFO - __main__ - Global step 600 Train loss 0.26 ACC 0.5 on epoch=299
06/24/2022 07:18:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/24/2022 07:18:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=309
06/24/2022 07:18:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=314
06/24/2022 07:18:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=319
06/24/2022 07:18:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=324
06/24/2022 07:18:19 - INFO - __main__ - Global step 650 Train loss 0.24 ACC 0.46875 on epoch=324
06/24/2022 07:18:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=329
06/24/2022 07:18:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/24/2022 07:18:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=339
06/24/2022 07:18:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=344
06/24/2022 07:18:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=349
06/24/2022 07:18:26 - INFO - __main__ - Global step 700 Train loss 0.23 ACC 0.5 on epoch=349
06/24/2022 07:18:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=354
06/24/2022 07:18:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/24/2022 07:18:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=364
06/24/2022 07:18:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=369
06/24/2022 07:18:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=374
06/24/2022 07:18:33 - INFO - __main__ - Global step 750 Train loss 0.23 ACC 0.5 on epoch=374
06/24/2022 07:18:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=379
06/24/2022 07:18:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=384
06/24/2022 07:18:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=389
06/24/2022 07:18:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=394
06/24/2022 07:18:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=399
06/24/2022 07:18:40 - INFO - __main__ - Global step 800 Train loss 0.23 ACC 0.53125 on epoch=399
06/24/2022 07:18:40 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=399, global_step=800
06/24/2022 07:18:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=404
06/24/2022 07:18:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=409
06/24/2022 07:18:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=414
06/24/2022 07:18:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=419
06/24/2022 07:18:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=424
06/24/2022 07:18:47 - INFO - __main__ - Global step 850 Train loss 0.22 ACC 0.5 on epoch=424
06/24/2022 07:18:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=429
06/24/2022 07:18:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=434
06/24/2022 07:18:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/24/2022 07:18:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=444
06/24/2022 07:18:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=449
06/24/2022 07:18:53 - INFO - __main__ - Global step 900 Train loss 0.20 ACC 0.5 on epoch=449
06/24/2022 07:18:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=454
06/24/2022 07:18:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=459
06/24/2022 07:18:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=464
06/24/2022 07:18:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=469
06/24/2022 07:19:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=474
06/24/2022 07:19:00 - INFO - __main__ - Global step 950 Train loss 0.20 ACC 0.4375 on epoch=474
06/24/2022 07:19:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=479
06/24/2022 07:19:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=484
06/24/2022 07:19:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=489
06/24/2022 07:19:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=494
06/24/2022 07:19:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=499
06/24/2022 07:19:07 - INFO - __main__ - Global step 1000 Train loss 0.20 ACC 0.46875 on epoch=499
06/24/2022 07:19:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=504
06/24/2022 07:19:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=509
06/24/2022 07:19:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=514
06/24/2022 07:19:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=519
06/24/2022 07:19:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=524
06/24/2022 07:19:14 - INFO - __main__ - Global step 1050 Train loss 0.18 ACC 0.5 on epoch=524
06/24/2022 07:19:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=529
06/24/2022 07:19:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=534
06/24/2022 07:19:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=539
06/24/2022 07:19:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=544
06/24/2022 07:19:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=549
06/24/2022 07:19:21 - INFO - __main__ - Global step 1100 Train loss 0.19 ACC 0.53125 on epoch=549
06/24/2022 07:19:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=554
06/24/2022 07:19:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=559
06/24/2022 07:19:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=564
06/24/2022 07:19:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=569
06/24/2022 07:19:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=574
06/24/2022 07:19:27 - INFO - __main__ - Global step 1150 Train loss 0.17 ACC 0.5625 on epoch=574
06/24/2022 07:19:27 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=574, global_step=1150
06/24/2022 07:19:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=579
06/24/2022 07:19:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=584
06/24/2022 07:19:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=589
06/24/2022 07:19:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=594
06/24/2022 07:19:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=599
06/24/2022 07:19:34 - INFO - __main__ - Global step 1200 Train loss 0.16 ACC 0.53125 on epoch=599
06/24/2022 07:19:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=604
06/24/2022 07:19:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=609
06/24/2022 07:19:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=614
06/24/2022 07:19:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=619
06/24/2022 07:19:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=624
06/24/2022 07:19:41 - INFO - __main__ - Global step 1250 Train loss 0.16 ACC 0.5625 on epoch=624
06/24/2022 07:19:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=629
06/24/2022 07:19:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=634
06/24/2022 07:19:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=639
06/24/2022 07:19:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=644
06/24/2022 07:19:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=649
06/24/2022 07:19:48 - INFO - __main__ - Global step 1300 Train loss 0.16 ACC 0.59375 on epoch=649
06/24/2022 07:19:48 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=649, global_step=1300
06/24/2022 07:19:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=654
06/24/2022 07:19:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=659
06/24/2022 07:19:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=664
06/24/2022 07:19:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=669
06/24/2022 07:19:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=674
06/24/2022 07:19:55 - INFO - __main__ - Global step 1350 Train loss 0.12 ACC 0.59375 on epoch=674
06/24/2022 07:19:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=679
06/24/2022 07:19:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=684
06/24/2022 07:19:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=689
06/24/2022 07:20:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=694
06/24/2022 07:20:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=699
06/24/2022 07:20:01 - INFO - __main__ - Global step 1400 Train loss 0.13 ACC 0.59375 on epoch=699
06/24/2022 07:20:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=704
06/24/2022 07:20:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=709
06/24/2022 07:20:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=714
06/24/2022 07:20:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=719
06/24/2022 07:20:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=724
06/24/2022 07:20:08 - INFO - __main__ - Global step 1450 Train loss 0.11 ACC 0.625 on epoch=724
06/24/2022 07:20:08 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=724, global_step=1450
06/24/2022 07:20:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=729
06/24/2022 07:20:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=734
06/24/2022 07:20:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=739
06/24/2022 07:20:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=744
06/24/2022 07:20:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=749
06/24/2022 07:20:15 - INFO - __main__ - Global step 1500 Train loss 0.10 ACC 0.53125 on epoch=749
06/24/2022 07:20:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=754
06/24/2022 07:20:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=759
06/24/2022 07:20:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=764
06/24/2022 07:20:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=769
06/24/2022 07:20:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=774
06/24/2022 07:20:22 - INFO - __main__ - Global step 1550 Train loss 0.11 ACC 0.5 on epoch=774
06/24/2022 07:20:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=779
06/24/2022 07:20:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=784
06/24/2022 07:20:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=789
06/24/2022 07:20:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=794
06/24/2022 07:20:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=799
06/24/2022 07:20:29 - INFO - __main__ - Global step 1600 Train loss 0.09 ACC 0.5 on epoch=799
06/24/2022 07:20:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=804
06/24/2022 07:20:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=809
06/24/2022 07:20:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=814
06/24/2022 07:20:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=819
06/24/2022 07:20:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=824
06/24/2022 07:20:36 - INFO - __main__ - Global step 1650 Train loss 0.09 ACC 0.53125 on epoch=824
06/24/2022 07:20:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=829
06/24/2022 07:20:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=834
06/24/2022 07:20:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=839
06/24/2022 07:20:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=844
06/24/2022 07:20:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=849
06/24/2022 07:20:42 - INFO - __main__ - Global step 1700 Train loss 0.07 ACC 0.5 on epoch=849
06/24/2022 07:20:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=854
06/24/2022 07:20:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=859
06/24/2022 07:20:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
06/24/2022 07:20:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=869
06/24/2022 07:20:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=874
06/24/2022 07:20:49 - INFO - __main__ - Global step 1750 Train loss 0.05 ACC 0.40625 on epoch=874
06/24/2022 07:20:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=879
06/24/2022 07:20:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=884
06/24/2022 07:20:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
06/24/2022 07:20:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
06/24/2022 07:20:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=899
06/24/2022 07:20:56 - INFO - __main__ - Global step 1800 Train loss 0.07 ACC 0.5 on epoch=899
06/24/2022 07:20:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=904
06/24/2022 07:20:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=909
06/24/2022 07:21:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=914
06/24/2022 07:21:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=919
06/24/2022 07:21:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=924
06/24/2022 07:21:03 - INFO - __main__ - Global step 1850 Train loss 0.06 ACC 0.53125 on epoch=924
06/24/2022 07:21:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=929
06/24/2022 07:21:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=934
06/24/2022 07:21:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=939
06/24/2022 07:21:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=944
06/24/2022 07:21:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=949
06/24/2022 07:21:09 - INFO - __main__ - Global step 1900 Train loss 0.05 ACC 0.5 on epoch=949
06/24/2022 07:21:11 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=954
06/24/2022 07:21:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=959
06/24/2022 07:21:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=964
06/24/2022 07:21:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=969
06/24/2022 07:21:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=974
06/24/2022 07:21:16 - INFO - __main__ - Global step 1950 Train loss 0.05 ACC 0.375 on epoch=974
06/24/2022 07:21:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=979
06/24/2022 07:21:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=984
06/24/2022 07:21:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/24/2022 07:21:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=994
06/24/2022 07:21:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=999
06/24/2022 07:21:23 - INFO - __main__ - Global step 2000 Train loss 0.04 ACC 0.375 on epoch=999
06/24/2022 07:21:23 - INFO - __main__ - save last model!
06/24/2022 07:21:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:21:23 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:21:23 - INFO - __main__ - Printing 3 examples
06/24/2022 07:21:23 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:21:23 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:21:23 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:21:23 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:21:23 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:21:23 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:23 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:21:24 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:21:24 - INFO - __main__ - Printing 3 examples
06/24/2022 07:21:24 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:21:24 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:24 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:21:24 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:24 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:21:24 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:21:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:21:24 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:21:24 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:21:24 - INFO - __main__ - Printing 3 examples
06/24/2022 07:21:24 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:21:24 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:24 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:21:24 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:24 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:21:24 - INFO - __main__ - ['duplicate']
06/24/2022 07:21:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:21:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:21:24 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:21:29 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:21:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:21:30 - INFO - __main__ - Starting training!
06/24/2022 07:21:41 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:22:22 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 07:35:20 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_100_0.2_8_predictions.txt
06/24/2022 07:35:21 - INFO - __main__ - ACC on test data: 0.5134
06/24/2022 07:35:21 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.513356418501113
06/24/2022 07:35:21 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.5, bsz=8 ...
06/24/2022 07:35:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:35:22 - INFO - __main__ - Printing 3 examples
06/24/2022 07:35:22 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:35:22 - INFO - __main__ - ['duplicate']
06/24/2022 07:35:22 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:35:22 - INFO - __main__ - ['duplicate']
06/24/2022 07:35:22 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:35:22 - INFO - __main__ - ['duplicate']
06/24/2022 07:35:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:35:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:35:22 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:35:22 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:35:22 - INFO - __main__ - Printing 3 examples
06/24/2022 07:35:22 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:35:22 - INFO - __main__ - ['duplicate']
06/24/2022 07:35:22 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:35:22 - INFO - __main__ - ['duplicate']
06/24/2022 07:35:22 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:35:22 - INFO - __main__ - ['duplicate']
06/24/2022 07:35:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:35:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:35:22 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:35:27 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:35:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:35:27 - INFO - __main__ - Starting training!
06/24/2022 07:35:29 - INFO - __main__ - Step 10 Global step 10 Train loss 5.58 on epoch=4
06/24/2022 07:35:30 - INFO - __main__ - Step 20 Global step 20 Train loss 3.81 on epoch=9
06/24/2022 07:35:31 - INFO - __main__ - Step 30 Global step 30 Train loss 2.39 on epoch=14
06/24/2022 07:35:33 - INFO - __main__ - Step 40 Global step 40 Train loss 1.55 on epoch=19
06/24/2022 07:35:34 - INFO - __main__ - Step 50 Global step 50 Train loss 0.92 on epoch=24
06/24/2022 07:35:35 - INFO - __main__ - Global step 50 Train loss 2.85 ACC 0.5 on epoch=24
06/24/2022 07:35:35 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 07:35:36 - INFO - __main__ - Step 60 Global step 60 Train loss 0.71 on epoch=29
06/24/2022 07:35:37 - INFO - __main__ - Step 70 Global step 70 Train loss 0.61 on epoch=34
06/24/2022 07:35:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.50 on epoch=39
06/24/2022 07:35:40 - INFO - __main__ - Step 90 Global step 90 Train loss 0.41 on epoch=44
06/24/2022 07:35:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
06/24/2022 07:35:42 - INFO - __main__ - Global step 100 Train loss 0.53 ACC 0.5 on epoch=49
06/24/2022 07:35:43 - INFO - __main__ - Step 110 Global step 110 Train loss 0.44 on epoch=54
06/24/2022 07:35:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.40 on epoch=59
06/24/2022 07:35:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.38 on epoch=64
06/24/2022 07:35:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=69
06/24/2022 07:35:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
06/24/2022 07:35:48 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.5 on epoch=74
06/24/2022 07:35:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=79
06/24/2022 07:35:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=84
06/24/2022 07:35:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=89
06/24/2022 07:35:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.27 on epoch=94
06/24/2022 07:35:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=99
06/24/2022 07:35:55 - INFO - __main__ - Global step 200 Train loss 0.28 ACC 0.5 on epoch=99
06/24/2022 07:35:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.31 on epoch=104
06/24/2022 07:35:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=109
06/24/2022 07:35:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=114
06/24/2022 07:36:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.30 on epoch=119
06/24/2022 07:36:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=124
06/24/2022 07:36:02 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/24/2022 07:36:04 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=129
06/24/2022 07:36:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/24/2022 07:36:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=139
06/24/2022 07:36:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=144
06/24/2022 07:36:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=149
06/24/2022 07:36:09 - INFO - __main__ - Global step 300 Train loss 0.22 ACC 0.53125 on epoch=149
06/24/2022 07:36:09 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=149, global_step=300
06/24/2022 07:36:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 07:36:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
06/24/2022 07:36:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=164
06/24/2022 07:36:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/24/2022 07:36:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=174
06/24/2022 07:36:16 - INFO - __main__ - Global step 350 Train loss 0.22 ACC 0.5625 on epoch=174
06/24/2022 07:36:17 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=174, global_step=350
06/24/2022 07:36:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=179
06/24/2022 07:36:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=184
06/24/2022 07:36:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=189
06/24/2022 07:36:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=194
06/24/2022 07:36:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=199
06/24/2022 07:36:24 - INFO - __main__ - Global step 400 Train loss 0.18 ACC 0.625 on epoch=199
06/24/2022 07:36:24 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=199, global_step=400
06/24/2022 07:36:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=204
06/24/2022 07:36:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=209
06/24/2022 07:36:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=214
06/24/2022 07:36:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=219
06/24/2022 07:36:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=224
06/24/2022 07:36:31 - INFO - __main__ - Global step 450 Train loss 0.16 ACC 0.625 on epoch=224
06/24/2022 07:36:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
06/24/2022 07:36:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=234
06/24/2022 07:36:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=239
06/24/2022 07:36:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=244
06/24/2022 07:36:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
06/24/2022 07:36:38 - INFO - __main__ - Global step 500 Train loss 0.12 ACC 0.5625 on epoch=249
06/24/2022 07:36:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=254
06/24/2022 07:36:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
06/24/2022 07:36:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
06/24/2022 07:36:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
06/24/2022 07:36:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=274
06/24/2022 07:36:45 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.53125 on epoch=274
06/24/2022 07:36:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=279
06/24/2022 07:36:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=284
06/24/2022 07:36:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
06/24/2022 07:36:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/24/2022 07:36:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=299
06/24/2022 07:36:52 - INFO - __main__ - Global step 600 Train loss 0.07 ACC 0.5 on epoch=299
06/24/2022 07:36:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=304
06/24/2022 07:36:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
06/24/2022 07:36:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
06/24/2022 07:36:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=319
06/24/2022 07:36:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/24/2022 07:36:59 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.5 on epoch=324
06/24/2022 07:37:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=329
06/24/2022 07:37:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
06/24/2022 07:37:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
06/24/2022 07:37:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=344
06/24/2022 07:37:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
06/24/2022 07:37:06 - INFO - __main__ - Global step 700 Train loss 0.04 ACC 0.53125 on epoch=349
06/24/2022 07:37:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/24/2022 07:37:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
06/24/2022 07:37:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=364
06/24/2022 07:37:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
06/24/2022 07:37:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
06/24/2022 07:37:13 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5625 on epoch=374
06/24/2022 07:37:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/24/2022 07:37:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
06/24/2022 07:37:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/24/2022 07:37:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
06/24/2022 07:37:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
06/24/2022 07:37:20 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.5 on epoch=399
06/24/2022 07:37:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
06/24/2022 07:37:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
06/24/2022 07:37:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
06/24/2022 07:37:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
06/24/2022 07:37:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/24/2022 07:37:27 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.5 on epoch=424
06/24/2022 07:37:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 07:37:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/24/2022 07:37:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/24/2022 07:37:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/24/2022 07:37:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/24/2022 07:37:34 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
06/24/2022 07:37:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/24/2022 07:37:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/24/2022 07:37:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
06/24/2022 07:37:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 07:37:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/24/2022 07:37:41 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.53125 on epoch=474
06/24/2022 07:37:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/24/2022 07:37:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/24/2022 07:37:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/24/2022 07:37:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/24/2022 07:37:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 07:37:48 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.5 on epoch=499
06/24/2022 07:37:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
06/24/2022 07:37:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
06/24/2022 07:37:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 07:37:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/24/2022 07:37:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
06/24/2022 07:37:55 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.46875 on epoch=524
06/24/2022 07:37:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/24/2022 07:37:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/24/2022 07:37:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/24/2022 07:38:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/24/2022 07:38:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 07:38:02 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.5 on epoch=549
06/24/2022 07:38:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/24/2022 07:38:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 07:38:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/24/2022 07:38:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 07:38:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 07:38:09 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.46875 on epoch=574
06/24/2022 07:38:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 07:38:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/24/2022 07:38:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 07:38:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/24/2022 07:38:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 07:38:16 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.46875 on epoch=599
06/24/2022 07:38:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 07:38:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 07:38:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/24/2022 07:38:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 07:38:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 07:38:23 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.5 on epoch=624
06/24/2022 07:38:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/24/2022 07:38:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 07:38:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
06/24/2022 07:38:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 07:38:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 07:38:30 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.5 on epoch=649
06/24/2022 07:38:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 07:38:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 07:38:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
06/24/2022 07:38:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 07:38:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 07:38:37 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.5 on epoch=674
06/24/2022 07:38:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 07:38:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 07:38:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 07:38:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 07:38:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 07:38:44 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.5 on epoch=699
06/24/2022 07:38:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 07:38:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/24/2022 07:38:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 07:38:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 07:38:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/24/2022 07:38:51 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.46875 on epoch=724
06/24/2022 07:38:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 07:38:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 07:38:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 07:38:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 07:38:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 07:38:58 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.53125 on epoch=749
06/24/2022 07:38:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 07:39:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 07:39:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 07:39:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 07:39:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 07:39:05 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
06/24/2022 07:39:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 07:39:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 07:39:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 07:39:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 07:39:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 07:39:12 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.5 on epoch=799
06/24/2022 07:39:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 07:39:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 07:39:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 07:39:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 07:39:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 07:39:19 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.46875 on epoch=824
06/24/2022 07:39:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 07:39:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 07:39:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 07:39:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 07:39:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 07:39:27 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.46875 on epoch=849
06/24/2022 07:39:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 07:39:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 07:39:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=864
06/24/2022 07:39:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 07:39:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 07:39:34 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.46875 on epoch=874
06/24/2022 07:39:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 07:39:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 07:39:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 07:39:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 07:39:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 07:39:41 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5 on epoch=899
06/24/2022 07:39:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 07:39:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 07:39:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 07:39:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 07:39:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 07:39:48 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.46875 on epoch=924
06/24/2022 07:39:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=929
06/24/2022 07:39:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 07:39:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
06/24/2022 07:39:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 07:39:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 07:39:55 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/24/2022 07:39:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 07:39:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 07:39:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 07:40:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 07:40:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 07:40:02 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.46875 on epoch=974
06/24/2022 07:40:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 07:40:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 07:40:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 07:40:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 07:40:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 07:40:09 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.46875 on epoch=999
06/24/2022 07:40:09 - INFO - __main__ - save last model!
06/24/2022 07:40:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:40:09 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:40:09 - INFO - __main__ - Printing 3 examples
06/24/2022 07:40:09 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:40:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:40:09 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:40:09 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:40:09 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:40:09 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:40:10 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:40:10 - INFO - __main__ - Printing 3 examples
06/24/2022 07:40:10 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:40:10 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:10 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:40:10 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:10 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:40:10 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:10 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:40:10 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:40:10 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:40:10 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:40:10 - INFO - __main__ - Printing 3 examples
06/24/2022 07:40:10 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:40:10 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:10 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:40:10 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:10 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:40:10 - INFO - __main__ - ['duplicate']
06/24/2022 07:40:10 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:40:10 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:40:10 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:40:16 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:40:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:40:16 - INFO - __main__ - Starting training!
06/24/2022 07:40:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:41:08 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 07:54:03 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.5_8_predictions.txt
06/24/2022 07:54:03 - INFO - __main__ - ACC on test data: 0.6101
06/24/2022 07:54:04 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.5, bsz=8, dev_performance=0.625, test_performance=0.6101409844175117
06/24/2022 07:54:04 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.4, bsz=8 ...
06/24/2022 07:54:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:54:05 - INFO - __main__ - Printing 3 examples
06/24/2022 07:54:05 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:54:05 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:05 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:54:05 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:05 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:54:05 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:05 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:54:05 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:54:05 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:54:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:54:05 - INFO - __main__ - Printing 3 examples
06/24/2022 07:54:05 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:54:05 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:05 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:54:05 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:05 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:54:05 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:05 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:54:05 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:54:05 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:54:11 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:54:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:54:11 - INFO - __main__ - Starting training!
06/24/2022 07:54:13 - INFO - __main__ - Step 10 Global step 10 Train loss 5.92 on epoch=4
06/24/2022 07:54:14 - INFO - __main__ - Step 20 Global step 20 Train loss 4.12 on epoch=9
06/24/2022 07:54:15 - INFO - __main__ - Step 30 Global step 30 Train loss 3.10 on epoch=14
06/24/2022 07:54:16 - INFO - __main__ - Step 40 Global step 40 Train loss 2.17 on epoch=19
06/24/2022 07:54:18 - INFO - __main__ - Step 50 Global step 50 Train loss 1.51 on epoch=24
06/24/2022 07:54:18 - INFO - __main__ - Global step 50 Train loss 3.36 ACC 0.5 on epoch=24
06/24/2022 07:54:18 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 07:54:20 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=29
06/24/2022 07:54:21 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
06/24/2022 07:54:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.60 on epoch=39
06/24/2022 07:54:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.49 on epoch=44
06/24/2022 07:54:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.46 on epoch=49
06/24/2022 07:54:25 - INFO - __main__ - Global step 100 Train loss 0.66 ACC 0.5 on epoch=49
06/24/2022 07:54:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.39 on epoch=54
06/24/2022 07:54:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.43 on epoch=59
06/24/2022 07:54:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/24/2022 07:54:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.34 on epoch=69
06/24/2022 07:54:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.35 on epoch=74
06/24/2022 07:54:32 - INFO - __main__ - Global step 150 Train loss 0.37 ACC 0.5 on epoch=74
06/24/2022 07:54:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.41 on epoch=79
06/24/2022 07:54:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/24/2022 07:54:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.31 on epoch=89
06/24/2022 07:54:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=94
06/24/2022 07:54:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.34 on epoch=99
06/24/2022 07:54:39 - INFO - __main__ - Global step 200 Train loss 0.33 ACC 0.5 on epoch=99
06/24/2022 07:54:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.28 on epoch=104
06/24/2022 07:54:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
06/24/2022 07:54:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=114
06/24/2022 07:54:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=119
06/24/2022 07:54:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=124
06/24/2022 07:54:46 - INFO - __main__ - Global step 250 Train loss 0.29 ACC 0.53125 on epoch=124
06/24/2022 07:54:46 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=124, global_step=250
06/24/2022 07:54:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=129
06/24/2022 07:54:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/24/2022 07:54:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/24/2022 07:54:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=144
06/24/2022 07:54:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=149
06/24/2022 07:54:53 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5625 on epoch=149
06/24/2022 07:54:53 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=149, global_step=300
06/24/2022 07:54:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/24/2022 07:54:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/24/2022 07:54:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=164
06/24/2022 07:54:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/24/2022 07:55:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/24/2022 07:55:00 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.625 on epoch=174
06/24/2022 07:55:00 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=174, global_step=350
06/24/2022 07:55:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=179
06/24/2022 07:55:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=184
06/24/2022 07:55:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=189
06/24/2022 07:55:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=194
06/24/2022 07:55:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=199
06/24/2022 07:55:07 - INFO - __main__ - Global step 400 Train loss 0.19 ACC 0.59375 on epoch=199
06/24/2022 07:55:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=204
06/24/2022 07:55:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=209
06/24/2022 07:55:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=214
06/24/2022 07:55:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=219
06/24/2022 07:55:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=224
06/24/2022 07:55:14 - INFO - __main__ - Global step 450 Train loss 0.17 ACC 0.625 on epoch=224
06/24/2022 07:55:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=229
06/24/2022 07:55:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=234
06/24/2022 07:55:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=239
06/24/2022 07:55:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=244
06/24/2022 07:55:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=249
06/24/2022 07:55:21 - INFO - __main__ - Global step 500 Train loss 0.11 ACC 0.59375 on epoch=249
06/24/2022 07:55:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=254
06/24/2022 07:55:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=259
06/24/2022 07:55:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=264
06/24/2022 07:55:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=269
06/24/2022 07:55:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=274
06/24/2022 07:55:28 - INFO - __main__ - Global step 550 Train loss 0.07 ACC 0.59375 on epoch=274
06/24/2022 07:55:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
06/24/2022 07:55:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
06/24/2022 07:55:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
06/24/2022 07:55:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
06/24/2022 07:55:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=299
06/24/2022 07:55:35 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.59375 on epoch=299
06/24/2022 07:55:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
06/24/2022 07:55:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
06/24/2022 07:55:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
06/24/2022 07:55:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
06/24/2022 07:55:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/24/2022 07:55:43 - INFO - __main__ - Global step 650 Train loss 0.04 ACC 0.59375 on epoch=324
06/24/2022 07:55:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
06/24/2022 07:55:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/24/2022 07:55:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=339
06/24/2022 07:55:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
06/24/2022 07:55:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=349
06/24/2022 07:55:50 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.625 on epoch=349
06/24/2022 07:55:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=354
06/24/2022 07:55:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=359
06/24/2022 07:55:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
06/24/2022 07:55:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/24/2022 07:55:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
06/24/2022 07:55:57 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.59375 on epoch=374
06/24/2022 07:55:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/24/2022 07:55:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
06/24/2022 07:56:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/24/2022 07:56:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/24/2022 07:56:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=399
06/24/2022 07:56:04 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.53125 on epoch=399
06/24/2022 07:56:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=404
06/24/2022 07:56:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/24/2022 07:56:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
06/24/2022 07:56:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
06/24/2022 07:56:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
06/24/2022 07:56:11 - INFO - __main__ - Global step 850 Train loss 0.03 ACC 0.53125 on epoch=424
06/24/2022 07:56:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 07:56:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
06/24/2022 07:56:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/24/2022 07:56:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/24/2022 07:56:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/24/2022 07:56:18 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5625 on epoch=449
06/24/2022 07:56:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/24/2022 07:56:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/24/2022 07:56:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 07:56:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/24/2022 07:56:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/24/2022 07:56:25 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.53125 on epoch=474
06/24/2022 07:56:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
06/24/2022 07:56:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
06/24/2022 07:56:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/24/2022 07:56:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/24/2022 07:56:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/24/2022 07:56:32 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
06/24/2022 07:56:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 07:56:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/24/2022 07:56:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 07:56:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/24/2022 07:56:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/24/2022 07:56:39 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.59375 on epoch=524
06/24/2022 07:56:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
06/24/2022 07:56:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 07:56:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/24/2022 07:56:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/24/2022 07:56:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
06/24/2022 07:56:46 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.625 on epoch=549
06/24/2022 07:56:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/24/2022 07:56:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 07:56:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 07:56:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/24/2022 07:56:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/24/2022 07:56:53 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.59375 on epoch=574
06/24/2022 07:56:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 07:56:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 07:56:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
06/24/2022 07:56:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/24/2022 07:57:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 07:57:00 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.5625 on epoch=599
06/24/2022 07:57:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 07:57:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 07:57:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 07:57:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 07:57:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/24/2022 07:57:07 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/24/2022 07:57:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/24/2022 07:57:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 07:57:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 07:57:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 07:57:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 07:57:14 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
06/24/2022 07:57:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 07:57:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 07:57:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 07:57:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 07:57:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 07:57:21 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.59375 on epoch=674
06/24/2022 07:57:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 07:57:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 07:57:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 07:57:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 07:57:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 07:57:29 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.53125 on epoch=699
06/24/2022 07:57:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 07:57:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 07:57:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 07:57:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 07:57:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 07:57:36 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.625 on epoch=724
06/24/2022 07:57:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 07:57:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 07:57:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/24/2022 07:57:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 07:57:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 07:57:43 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.625 on epoch=749
06/24/2022 07:57:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
06/24/2022 07:57:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 07:57:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 07:57:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 07:57:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 07:57:50 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5625 on epoch=774
06/24/2022 07:57:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 07:57:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 07:57:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 07:57:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 07:57:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 07:57:57 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.625 on epoch=799
06/24/2022 07:57:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 07:57:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 07:58:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 07:58:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 07:58:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 07:58:04 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.59375 on epoch=824
06/24/2022 07:58:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 07:58:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 07:58:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 07:58:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 07:58:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 07:58:11 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.59375 on epoch=849
06/24/2022 07:58:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 07:58:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 07:58:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 07:58:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 07:58:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 07:58:18 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.53125 on epoch=874
06/24/2022 07:58:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 07:58:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 07:58:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 07:58:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 07:58:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 07:58:25 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/24/2022 07:58:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 07:58:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 07:58:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 07:58:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 07:58:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 07:58:32 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5625 on epoch=924
06/24/2022 07:58:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 07:58:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 07:58:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 07:58:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 07:58:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 07:58:40 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.625 on epoch=949
06/24/2022 07:58:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 07:58:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 07:58:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 07:58:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 07:58:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 07:58:47 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.46875 on epoch=974
06/24/2022 07:58:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 07:58:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 07:58:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 07:58:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 07:58:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 07:58:54 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.65625 on epoch=999
06/24/2022 07:58:54 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=999, global_step=2000
06/24/2022 07:58:54 - INFO - __main__ - save last model!
06/24/2022 07:58:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:58:54 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:58:54 - INFO - __main__ - Printing 3 examples
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:58:54 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:58:54 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:58:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:58:54 - INFO - __main__ - Printing 3 examples
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:58:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:58:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:58:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:58:54 - INFO - __main__ - Printing 3 examples
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:58:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:58:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:58:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:58:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:59:00 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 07:59:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:59:00 - INFO - __main__ - Starting training!
06/24/2022 07:59:12 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:59:53 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 08:13:00 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.4_8_predictions.txt
06/24/2022 08:13:00 - INFO - __main__ - ACC on test data: 0.6062
06/24/2022 08:13:01 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.4, bsz=8, dev_performance=0.65625, test_performance=0.6061835270838486
06/24/2022 08:13:01 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.3, bsz=8 ...
06/24/2022 08:13:01 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:13:01 - INFO - __main__ - Printing 3 examples
06/24/2022 08:13:01 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 08:13:01 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:01 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 08:13:01 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:01 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 08:13:01 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:01 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:13:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:13:02 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:13:02 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:13:02 - INFO - __main__ - Printing 3 examples
06/24/2022 08:13:02 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 08:13:02 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:02 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 08:13:02 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:02 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 08:13:02 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:13:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:13:02 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:13:08 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 08:13:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:13:08 - INFO - __main__ - Starting training!
06/24/2022 08:13:10 - INFO - __main__ - Step 10 Global step 10 Train loss 5.92 on epoch=4
06/24/2022 08:13:11 - INFO - __main__ - Step 20 Global step 20 Train loss 4.63 on epoch=9
06/24/2022 08:13:12 - INFO - __main__ - Step 30 Global step 30 Train loss 3.52 on epoch=14
06/24/2022 08:13:13 - INFO - __main__ - Step 40 Global step 40 Train loss 2.80 on epoch=19
06/24/2022 08:13:14 - INFO - __main__ - Step 50 Global step 50 Train loss 2.05 on epoch=24
06/24/2022 08:13:15 - INFO - __main__ - Global step 50 Train loss 3.78 ACC 0.0 on epoch=24
06/24/2022 08:13:15 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 08:13:16 - INFO - __main__ - Step 60 Global step 60 Train loss 1.61 on epoch=29
06/24/2022 08:13:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.12 on epoch=34
06/24/2022 08:13:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.88 on epoch=39
06/24/2022 08:13:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.70 on epoch=44
06/24/2022 08:13:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.59 on epoch=49
06/24/2022 08:13:22 - INFO - __main__ - Global step 100 Train loss 0.98 ACC 0.5 on epoch=49
06/24/2022 08:13:22 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 08:13:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.44 on epoch=54
06/24/2022 08:13:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.40 on epoch=59
06/24/2022 08:13:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.47 on epoch=64
06/24/2022 08:13:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=69
06/24/2022 08:13:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.38 on epoch=74
06/24/2022 08:13:29 - INFO - __main__ - Global step 150 Train loss 0.44 ACC 0.5 on epoch=74
06/24/2022 08:13:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
06/24/2022 08:13:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.42 on epoch=84
06/24/2022 08:13:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=89
06/24/2022 08:13:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.32 on epoch=94
06/24/2022 08:13:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.37 on epoch=99
06/24/2022 08:13:35 - INFO - __main__ - Global step 200 Train loss 0.37 ACC 0.5 on epoch=99
06/24/2022 08:13:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=104
06/24/2022 08:13:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.38 on epoch=109
06/24/2022 08:13:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=114
06/24/2022 08:13:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=119
06/24/2022 08:13:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=124
06/24/2022 08:13:42 - INFO - __main__ - Global step 250 Train loss 0.35 ACC 0.5 on epoch=124
06/24/2022 08:13:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/24/2022 08:13:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/24/2022 08:13:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=139
06/24/2022 08:13:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 08:13:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=149
06/24/2022 08:13:49 - INFO - __main__ - Global step 300 Train loss 0.30 ACC 0.5 on epoch=149
06/24/2022 08:13:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=154
06/24/2022 08:13:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=159
06/24/2022 08:13:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=164
06/24/2022 08:13:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/24/2022 08:13:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=174
06/24/2022 08:13:56 - INFO - __main__ - Global step 350 Train loss 0.26 ACC 0.53125 on epoch=174
06/24/2022 08:13:56 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/24/2022 08:13:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 08:13:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=184
06/24/2022 08:13:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=189
06/24/2022 08:14:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=194
06/24/2022 08:14:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/24/2022 08:14:02 - INFO - __main__ - Global step 400 Train loss 0.26 ACC 0.53125 on epoch=199
06/24/2022 08:14:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=204
06/24/2022 08:14:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=209
06/24/2022 08:14:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
06/24/2022 08:14:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/24/2022 08:14:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/24/2022 08:14:09 - INFO - __main__ - Global step 450 Train loss 0.24 ACC 0.5625 on epoch=224
06/24/2022 08:14:09 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=224, global_step=450
06/24/2022 08:14:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=229
06/24/2022 08:14:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=234
06/24/2022 08:14:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=239
06/24/2022 08:14:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=244
06/24/2022 08:14:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=249
06/24/2022 08:14:16 - INFO - __main__ - Global step 500 Train loss 0.22 ACC 0.65625 on epoch=249
06/24/2022 08:14:16 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.65625 on epoch=249, global_step=500
06/24/2022 08:14:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=254
06/24/2022 08:14:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=259
06/24/2022 08:14:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 08:14:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=269
06/24/2022 08:14:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=274
06/24/2022 08:14:23 - INFO - __main__ - Global step 550 Train loss 0.20 ACC 0.40625 on epoch=274
06/24/2022 08:14:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=279
06/24/2022 08:14:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=284
06/24/2022 08:14:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=289
06/24/2022 08:14:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=294
06/24/2022 08:14:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=299
06/24/2022 08:14:30 - INFO - __main__ - Global step 600 Train loss 0.16 ACC 0.4375 on epoch=299
06/24/2022 08:14:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=304
06/24/2022 08:14:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=309
06/24/2022 08:14:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=314
06/24/2022 08:14:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=319
06/24/2022 08:14:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=324
06/24/2022 08:14:36 - INFO - __main__ - Global step 650 Train loss 0.13 ACC 0.40625 on epoch=324
06/24/2022 08:14:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=329
06/24/2022 08:14:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=334
06/24/2022 08:14:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=339
06/24/2022 08:14:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=344
06/24/2022 08:14:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
06/24/2022 08:14:43 - INFO - __main__ - Global step 700 Train loss 0.11 ACC 0.46875 on epoch=349
06/24/2022 08:14:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=354
06/24/2022 08:14:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=359
06/24/2022 08:14:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=364
06/24/2022 08:14:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=369
06/24/2022 08:14:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
06/24/2022 08:14:50 - INFO - __main__ - Global step 750 Train loss 0.08 ACC 0.5 on epoch=374
06/24/2022 08:14:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
06/24/2022 08:14:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
06/24/2022 08:14:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
06/24/2022 08:14:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=394
06/24/2022 08:14:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
06/24/2022 08:14:57 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.59375 on epoch=399
06/24/2022 08:14:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=404
06/24/2022 08:14:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=409
06/24/2022 08:15:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
06/24/2022 08:15:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=419
06/24/2022 08:15:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=424
06/24/2022 08:15:03 - INFO - __main__ - Global step 850 Train loss 0.05 ACC 0.5625 on epoch=424
06/24/2022 08:15:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=429
06/24/2022 08:15:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=434
06/24/2022 08:15:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/24/2022 08:15:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/24/2022 08:15:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/24/2022 08:15:10 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.53125 on epoch=449
06/24/2022 08:15:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/24/2022 08:15:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=459
06/24/2022 08:15:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
06/24/2022 08:15:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/24/2022 08:15:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/24/2022 08:15:17 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.46875 on epoch=474
06/24/2022 08:15:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
06/24/2022 08:15:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=484
06/24/2022 08:15:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/24/2022 08:15:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/24/2022 08:15:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 08:15:24 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.5625 on epoch=499
06/24/2022 08:15:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/24/2022 08:15:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
06/24/2022 08:15:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
06/24/2022 08:15:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/24/2022 08:15:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/24/2022 08:15:30 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
06/24/2022 08:15:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/24/2022 08:15:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 08:15:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/24/2022 08:15:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 08:15:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/24/2022 08:15:37 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5 on epoch=549
06/24/2022 08:15:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/24/2022 08:15:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/24/2022 08:15:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 08:15:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/24/2022 08:15:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 08:15:44 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.53125 on epoch=574
06/24/2022 08:15:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 08:15:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/24/2022 08:15:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 08:15:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 08:15:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 08:15:50 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.5 on epoch=599
06/24/2022 08:15:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 08:15:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 08:15:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/24/2022 08:15:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 08:15:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/24/2022 08:15:57 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
06/24/2022 08:15:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 08:15:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/24/2022 08:16:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 08:16:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 08:16:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 08:16:03 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.5 on epoch=649
06/24/2022 08:16:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/24/2022 08:16:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 08:16:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 08:16:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 08:16:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 08:16:10 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.53125 on epoch=674
06/24/2022 08:16:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 08:16:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 08:16:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 08:16:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 08:16:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 08:16:17 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/24/2022 08:16:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 08:16:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 08:16:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 08:16:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 08:16:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/24/2022 08:16:23 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
06/24/2022 08:16:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 08:16:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 08:16:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
06/24/2022 08:16:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/24/2022 08:16:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 08:16:30 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.53125 on epoch=749
06/24/2022 08:16:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 08:16:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 08:16:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 08:16:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/24/2022 08:16:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 08:16:37 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
06/24/2022 08:16:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 08:16:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 08:16:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 08:16:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 08:16:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 08:16:43 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.59375 on epoch=799
06/24/2022 08:16:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 08:16:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
06/24/2022 08:16:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 08:16:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 08:16:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 08:16:50 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
06/24/2022 08:16:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 08:16:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
06/24/2022 08:16:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 08:16:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 08:16:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/24/2022 08:16:56 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
06/24/2022 08:16:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 08:16:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 08:17:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 08:17:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 08:17:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 08:17:03 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
06/24/2022 08:17:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 08:17:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 08:17:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 08:17:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 08:17:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 08:17:10 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.53125 on epoch=899
06/24/2022 08:17:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 08:17:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 08:17:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=914
06/24/2022 08:17:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=919
06/24/2022 08:17:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 08:17:16 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.5625 on epoch=924
06/24/2022 08:17:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 08:17:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 08:17:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 08:17:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 08:17:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 08:17:23 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.5625 on epoch=949
06/24/2022 08:17:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
06/24/2022 08:17:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 08:17:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 08:17:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 08:17:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 08:17:30 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5625 on epoch=974
06/24/2022 08:17:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 08:17:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 08:17:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 08:17:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/24/2022 08:17:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
06/24/2022 08:17:36 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5625 on epoch=999
06/24/2022 08:17:36 - INFO - __main__ - save last model!
06/24/2022 08:17:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 08:17:36 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 08:17:36 - INFO - __main__ - Printing 3 examples
06/24/2022 08:17:36 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 08:17:36 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:36 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 08:17:36 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:36 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 08:17:36 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:36 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:17:37 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:17:37 - INFO - __main__ - Printing 3 examples
06/24/2022 08:17:37 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 08:17:37 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:37 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 08:17:37 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:37 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 08:17:37 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:17:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:17:37 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:17:37 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:17:37 - INFO - __main__ - Printing 3 examples
06/24/2022 08:17:37 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 08:17:37 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:37 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 08:17:37 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:37 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 08:17:37 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:17:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:17:37 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:17:42 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 08:17:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:17:43 - INFO - __main__ - Starting training!
06/24/2022 08:17:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:18:36 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 08:31:37 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.3_8_predictions.txt
06/24/2022 08:31:38 - INFO - __main__ - ACC on test data: 0.5875
06/24/2022 08:31:38 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.3, bsz=8, dev_performance=0.65625, test_performance=0.5874845411822904
06/24/2022 08:31:38 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.2, bsz=8 ...
06/24/2022 08:31:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:31:39 - INFO - __main__ - Printing 3 examples
06/24/2022 08:31:39 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 08:31:39 - INFO - __main__ - ['duplicate']
06/24/2022 08:31:39 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 08:31:39 - INFO - __main__ - ['duplicate']
06/24/2022 08:31:39 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 08:31:39 - INFO - __main__ - ['duplicate']
06/24/2022 08:31:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:31:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:31:39 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:31:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:31:39 - INFO - __main__ - Printing 3 examples
06/24/2022 08:31:39 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 08:31:39 - INFO - __main__ - ['duplicate']
06/24/2022 08:31:39 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 08:31:39 - INFO - __main__ - ['duplicate']
06/24/2022 08:31:39 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 08:31:39 - INFO - __main__ - ['duplicate']
06/24/2022 08:31:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:31:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:31:39 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:31:44 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 08:31:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:31:44 - INFO - __main__ - Starting training!
06/24/2022 08:31:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=4
06/24/2022 08:31:47 - INFO - __main__ - Step 20 Global step 20 Train loss 5.31 on epoch=9
06/24/2022 08:31:48 - INFO - __main__ - Step 30 Global step 30 Train loss 4.39 on epoch=14
06/24/2022 08:31:50 - INFO - __main__ - Step 40 Global step 40 Train loss 3.77 on epoch=19
06/24/2022 08:31:51 - INFO - __main__ - Step 50 Global step 50 Train loss 3.10 on epoch=24
06/24/2022 08:31:51 - INFO - __main__ - Global step 50 Train loss 4.62 ACC 0.0 on epoch=24
06/24/2022 08:31:51 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 08:31:53 - INFO - __main__ - Step 60 Global step 60 Train loss 2.66 on epoch=29
06/24/2022 08:31:54 - INFO - __main__ - Step 70 Global step 70 Train loss 2.35 on epoch=34
06/24/2022 08:31:55 - INFO - __main__ - Step 80 Global step 80 Train loss 1.90 on epoch=39
06/24/2022 08:31:56 - INFO - __main__ - Step 90 Global step 90 Train loss 1.42 on epoch=44
06/24/2022 08:31:57 - INFO - __main__ - Step 100 Global step 100 Train loss 1.26 on epoch=49
06/24/2022 08:31:58 - INFO - __main__ - Global step 100 Train loss 1.92 ACC 0.5 on epoch=49
06/24/2022 08:31:58 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 08:31:59 - INFO - __main__ - Step 110 Global step 110 Train loss 1.04 on epoch=54
06/24/2022 08:32:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=59
06/24/2022 08:32:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=64
06/24/2022 08:32:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=69
06/24/2022 08:32:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=74
06/24/2022 08:32:05 - INFO - __main__ - Global step 150 Train loss 0.79 ACC 0.5 on epoch=74
06/24/2022 08:32:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=79
06/24/2022 08:32:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=84
06/24/2022 08:32:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=89
06/24/2022 08:32:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.36 on epoch=94
06/24/2022 08:32:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=99
06/24/2022 08:32:11 - INFO - __main__ - Global step 200 Train loss 0.46 ACC 0.5 on epoch=99
06/24/2022 08:32:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/24/2022 08:32:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=109
06/24/2022 08:32:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=114
06/24/2022 08:32:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=119
06/24/2022 08:32:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/24/2022 08:32:18 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.5 on epoch=124
06/24/2022 08:32:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=129
06/24/2022 08:32:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=134
06/24/2022 08:32:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=139
06/24/2022 08:32:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=144
06/24/2022 08:32:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=149
06/24/2022 08:32:24 - INFO - __main__ - Global step 300 Train loss 0.35 ACC 0.5 on epoch=149
06/24/2022 08:32:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=154
06/24/2022 08:32:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=159
06/24/2022 08:32:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=164
06/24/2022 08:32:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=169
06/24/2022 08:32:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=174
06/24/2022 08:32:31 - INFO - __main__ - Global step 350 Train loss 0.36 ACC 0.5 on epoch=174
06/24/2022 08:32:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=179
06/24/2022 08:32:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=184
06/24/2022 08:32:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=189
06/24/2022 08:32:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=194
06/24/2022 08:32:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/24/2022 08:32:37 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/24/2022 08:32:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=204
06/24/2022 08:32:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=209
06/24/2022 08:32:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=214
06/24/2022 08:32:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=219
06/24/2022 08:32:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=224
06/24/2022 08:32:44 - INFO - __main__ - Global step 450 Train loss 0.33 ACC 0.5 on epoch=224
06/24/2022 08:32:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=229
06/24/2022 08:32:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=234
06/24/2022 08:32:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=239
06/24/2022 08:32:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=244
06/24/2022 08:32:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=249
06/24/2022 08:32:50 - INFO - __main__ - Global step 500 Train loss 0.28 ACC 0.5 on epoch=249
06/24/2022 08:32:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=254
06/24/2022 08:32:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=259
06/24/2022 08:32:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=264
06/24/2022 08:32:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=269
06/24/2022 08:32:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=274
06/24/2022 08:32:57 - INFO - __main__ - Global step 550 Train loss 0.28 ACC 0.5 on epoch=274
06/24/2022 08:32:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=279
06/24/2022 08:32:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=284
06/24/2022 08:33:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=289
06/24/2022 08:33:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=294
06/24/2022 08:33:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=299
06/24/2022 08:33:03 - INFO - __main__ - Global step 600 Train loss 0.24 ACC 0.53125 on epoch=299
06/24/2022 08:33:03 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=299, global_step=600
06/24/2022 08:33:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/24/2022 08:33:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=309
06/24/2022 08:33:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=314
06/24/2022 08:33:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=319
06/24/2022 08:33:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=324
06/24/2022 08:33:10 - INFO - __main__ - Global step 650 Train loss 0.21 ACC 0.5625 on epoch=324
06/24/2022 08:33:10 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=324, global_step=650
06/24/2022 08:33:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=329
06/24/2022 08:33:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=334
06/24/2022 08:33:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=339
06/24/2022 08:33:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=344
06/24/2022 08:33:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=349
06/24/2022 08:33:17 - INFO - __main__ - Global step 700 Train loss 0.23 ACC 0.59375 on epoch=349
06/24/2022 08:33:17 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=349, global_step=700
06/24/2022 08:33:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=354
06/24/2022 08:33:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=359
06/24/2022 08:33:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=364
06/24/2022 08:33:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=369
06/24/2022 08:33:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=374
06/24/2022 08:33:23 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.59375 on epoch=374
06/24/2022 08:33:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=379
06/24/2022 08:33:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=384
06/24/2022 08:33:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=389
06/24/2022 08:33:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=394
06/24/2022 08:33:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=399
06/24/2022 08:33:30 - INFO - __main__ - Global step 800 Train loss 0.18 ACC 0.625 on epoch=399
06/24/2022 08:33:30 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=399, global_step=800
06/24/2022 08:33:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=404
06/24/2022 08:33:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=409
06/24/2022 08:33:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=414
06/24/2022 08:33:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=419
06/24/2022 08:33:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=424
06/24/2022 08:33:36 - INFO - __main__ - Global step 850 Train loss 0.18 ACC 0.59375 on epoch=424
06/24/2022 08:33:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=429
06/24/2022 08:33:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=434
06/24/2022 08:33:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=439
06/24/2022 08:33:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=444
06/24/2022 08:33:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=449
06/24/2022 08:33:43 - INFO - __main__ - Global step 900 Train loss 0.14 ACC 0.5625 on epoch=449
06/24/2022 08:33:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=454
06/24/2022 08:33:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=459
06/24/2022 08:33:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=464
06/24/2022 08:33:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=469
06/24/2022 08:33:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=474
06/24/2022 08:33:50 - INFO - __main__ - Global step 950 Train loss 0.13 ACC 0.5 on epoch=474
06/24/2022 08:33:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=479
06/24/2022 08:33:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=484
06/24/2022 08:33:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=489
06/24/2022 08:33:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=494
06/24/2022 08:33:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=499
06/24/2022 08:33:56 - INFO - __main__ - Global step 1000 Train loss 0.10 ACC 0.53125 on epoch=499
06/24/2022 08:33:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=504
06/24/2022 08:33:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=509
06/24/2022 08:34:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=514
06/24/2022 08:34:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=519
06/24/2022 08:34:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=524
06/24/2022 08:34:03 - INFO - __main__ - Global step 1050 Train loss 0.09 ACC 0.53125 on epoch=524
06/24/2022 08:34:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/24/2022 08:34:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=534
06/24/2022 08:34:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/24/2022 08:34:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
06/24/2022 08:34:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=549
06/24/2022 08:34:09 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.53125 on epoch=549
06/24/2022 08:34:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=554
06/24/2022 08:34:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=559
06/24/2022 08:34:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=564
06/24/2022 08:34:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=569
06/24/2022 08:34:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
06/24/2022 08:34:16 - INFO - __main__ - Global step 1150 Train loss 0.06 ACC 0.5625 on epoch=574
06/24/2022 08:34:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=579
06/24/2022 08:34:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=584
06/24/2022 08:34:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
06/24/2022 08:34:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=594
06/24/2022 08:34:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=599
06/24/2022 08:34:22 - INFO - __main__ - Global step 1200 Train loss 0.05 ACC 0.5625 on epoch=599
06/24/2022 08:34:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 08:34:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=609
06/24/2022 08:34:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=614
06/24/2022 08:34:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=619
06/24/2022 08:34:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/24/2022 08:34:29 - INFO - __main__ - Global step 1250 Train loss 0.04 ACC 0.5625 on epoch=624
06/24/2022 08:34:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=629
06/24/2022 08:34:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/24/2022 08:34:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=639
06/24/2022 08:34:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
06/24/2022 08:34:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
06/24/2022 08:34:36 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.5625 on epoch=649
06/24/2022 08:34:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 08:34:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
06/24/2022 08:34:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
06/24/2022 08:34:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/24/2022 08:34:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 08:34:42 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.5625 on epoch=674
06/24/2022 08:34:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
06/24/2022 08:34:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 08:34:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/24/2022 08:34:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/24/2022 08:34:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/24/2022 08:34:49 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.5625 on epoch=699
06/24/2022 08:34:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
06/24/2022 08:34:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=709
06/24/2022 08:34:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 08:34:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/24/2022 08:34:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/24/2022 08:34:55 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5625 on epoch=724
06/24/2022 08:34:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 08:34:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=734
06/24/2022 08:34:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=739
06/24/2022 08:35:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 08:35:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=749
06/24/2022 08:35:02 - INFO - __main__ - Global step 1500 Train loss 0.03 ACC 0.5625 on epoch=749
06/24/2022 08:35:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
06/24/2022 08:35:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/24/2022 08:35:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=764
06/24/2022 08:35:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/24/2022 08:35:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 08:35:09 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
06/24/2022 08:35:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 08:35:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/24/2022 08:35:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 08:35:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 08:35:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 08:35:15 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.59375 on epoch=799
06/24/2022 08:35:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 08:35:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/24/2022 08:35:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
06/24/2022 08:35:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
06/24/2022 08:35:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 08:35:22 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5625 on epoch=824
06/24/2022 08:35:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 08:35:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=834
06/24/2022 08:35:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 08:35:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=844
06/24/2022 08:35:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/24/2022 08:35:28 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.5625 on epoch=849
06/24/2022 08:35:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 08:35:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 08:35:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 08:35:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
06/24/2022 08:35:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 08:35:35 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.53125 on epoch=874
06/24/2022 08:35:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 08:35:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 08:35:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=889
06/24/2022 08:35:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=894
06/24/2022 08:35:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 08:35:42 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.5 on epoch=899
06/24/2022 08:35:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 08:35:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
06/24/2022 08:35:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 08:35:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 08:35:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
06/24/2022 08:35:49 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.5 on epoch=924
06/24/2022 08:35:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/24/2022 08:35:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/24/2022 08:35:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 08:35:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 08:35:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 08:35:56 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/24/2022 08:35:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 08:35:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 08:36:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/24/2022 08:36:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
06/24/2022 08:36:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 08:36:03 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.59375 on epoch=974
06/24/2022 08:36:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 08:36:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 08:36:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 08:36:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 08:36:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 08:36:10 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
06/24/2022 08:36:10 - INFO - __main__ - save last model!
06/24/2022 08:36:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 08:36:10 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 08:36:10 - INFO - __main__ - Printing 3 examples
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 08:36:10 - INFO - __main__ - ['duplicate']
06/24/2022 08:36:10 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:36:10 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:36:10 - INFO - __main__ - Printing 3 examples
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:36:10 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:36:10 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:36:10 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:36:10 - INFO - __main__ - Printing 3 examples
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:36:10 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:36:10 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:36:10 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:36:10 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:36:16 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 08:36:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:36:16 - INFO - __main__ - Starting training!
06/24/2022 08:36:28 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:37:08 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 08:49:58 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_13_0.2_8_predictions.txt
06/24/2022 08:49:58 - INFO - __main__ - ACC on test data: 0.5899
06/24/2022 08:49:58 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.5898837496908237
06/24/2022 08:49:58 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.5, bsz=8 ...
06/24/2022 08:49:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:49:59 - INFO - __main__ - Printing 3 examples
06/24/2022 08:49:59 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:49:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:49:59 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:49:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:49:59 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:49:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:49:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:49:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:49:59 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:49:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:49:59 - INFO - __main__ - Printing 3 examples
06/24/2022 08:49:59 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:49:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:49:59 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:49:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:49:59 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:49:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:49:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:49:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:49:59 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:50:05 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 08:50:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:50:05 - INFO - __main__ - Starting training!
06/24/2022 08:50:07 - INFO - __main__ - Step 10 Global step 10 Train loss 5.78 on epoch=4
06/24/2022 08:50:08 - INFO - __main__ - Step 20 Global step 20 Train loss 3.59 on epoch=9
06/24/2022 08:50:09 - INFO - __main__ - Step 30 Global step 30 Train loss 2.45 on epoch=14
06/24/2022 08:50:10 - INFO - __main__ - Step 40 Global step 40 Train loss 1.62 on epoch=19
06/24/2022 08:50:11 - INFO - __main__ - Step 50 Global step 50 Train loss 1.03 on epoch=24
06/24/2022 08:50:12 - INFO - __main__ - Global step 50 Train loss 2.89 ACC 0.5 on epoch=24
06/24/2022 08:50:12 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 08:50:13 - INFO - __main__ - Step 60 Global step 60 Train loss 0.73 on epoch=29
06/24/2022 08:50:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.56 on epoch=34
06/24/2022 08:50:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.43 on epoch=39
06/24/2022 08:50:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=44
06/24/2022 08:50:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
06/24/2022 08:50:19 - INFO - __main__ - Global step 100 Train loss 0.50 ACC 0.5 on epoch=49
06/24/2022 08:50:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=54
06/24/2022 08:50:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=59
06/24/2022 08:50:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
06/24/2022 08:50:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=69
06/24/2022 08:50:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
06/24/2022 08:50:25 - INFO - __main__ - Global step 150 Train loss 0.30 ACC 0.5 on epoch=74
06/24/2022 08:50:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.28 on epoch=79
06/24/2022 08:50:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=84
06/24/2022 08:50:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
06/24/2022 08:50:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.19 on epoch=94
06/24/2022 08:50:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=99
06/24/2022 08:50:32 - INFO - __main__ - Global step 200 Train loss 0.24 ACC 0.5 on epoch=99
06/24/2022 08:50:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.26 on epoch=104
06/24/2022 08:50:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.19 on epoch=109
06/24/2022 08:50:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=114
06/24/2022 08:50:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.20 on epoch=119
06/24/2022 08:50:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=124
06/24/2022 08:50:38 - INFO - __main__ - Global step 250 Train loss 0.22 ACC 0.53125 on epoch=124
06/24/2022 08:50:38 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=124, global_step=250
06/24/2022 08:50:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.18 on epoch=129
06/24/2022 08:50:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.20 on epoch=134
06/24/2022 08:50:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=139
06/24/2022 08:50:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.20 on epoch=144
06/24/2022 08:50:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.15 on epoch=149
06/24/2022 08:50:45 - INFO - __main__ - Global step 300 Train loss 0.19 ACC 0.6875 on epoch=149
06/24/2022 08:50:45 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.6875 on epoch=149, global_step=300
06/24/2022 08:50:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.18 on epoch=154
06/24/2022 08:50:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=159
06/24/2022 08:50:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
06/24/2022 08:50:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.12 on epoch=169
06/24/2022 08:50:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.14 on epoch=174
06/24/2022 08:50:52 - INFO - __main__ - Global step 350 Train loss 0.15 ACC 0.65625 on epoch=174
06/24/2022 08:50:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.14 on epoch=179
06/24/2022 08:50:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
06/24/2022 08:50:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.09 on epoch=189
06/24/2022 08:50:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.08 on epoch=194
06/24/2022 08:50:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
06/24/2022 08:50:58 - INFO - __main__ - Global step 400 Train loss 0.10 ACC 0.53125 on epoch=199
06/24/2022 08:50:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=204
06/24/2022 08:51:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=209
06/24/2022 08:51:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=214
06/24/2022 08:51:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
06/24/2022 08:51:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.07 on epoch=224
06/24/2022 08:51:05 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.53125 on epoch=224
06/24/2022 08:51:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=229
06/24/2022 08:51:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
06/24/2022 08:51:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.06 on epoch=239
06/24/2022 08:51:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=244
06/24/2022 08:51:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
06/24/2022 08:51:11 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.59375 on epoch=249
06/24/2022 08:51:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=254
06/24/2022 08:51:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
06/24/2022 08:51:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=264
06/24/2022 08:51:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=269
06/24/2022 08:51:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=274
06/24/2022 08:51:18 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.5625 on epoch=274
06/24/2022 08:51:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=279
06/24/2022 08:51:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=284
06/24/2022 08:51:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=289
06/24/2022 08:51:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=294
06/24/2022 08:51:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
06/24/2022 08:51:25 - INFO - __main__ - Global step 600 Train loss 0.02 ACC 0.53125 on epoch=299
06/24/2022 08:51:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/24/2022 08:51:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=309
06/24/2022 08:51:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=314
06/24/2022 08:51:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
06/24/2022 08:51:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=324
06/24/2022 08:51:31 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.46875 on epoch=324
06/24/2022 08:51:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
06/24/2022 08:51:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=334
06/24/2022 08:51:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/24/2022 08:51:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
06/24/2022 08:51:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/24/2022 08:51:38 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.46875 on epoch=349
06/24/2022 08:51:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/24/2022 08:51:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/24/2022 08:51:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=364
06/24/2022 08:51:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/24/2022 08:51:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
06/24/2022 08:51:44 - INFO - __main__ - Global step 750 Train loss 0.01 ACC 0.46875 on epoch=374
06/24/2022 08:51:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/24/2022 08:51:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
06/24/2022 08:51:48 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
06/24/2022 08:51:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/24/2022 08:51:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
06/24/2022 08:51:51 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.53125 on epoch=399
06/24/2022 08:51:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/24/2022 08:51:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/24/2022 08:51:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
06/24/2022 08:51:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
06/24/2022 08:51:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/24/2022 08:51:58 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.40625 on epoch=424
06/24/2022 08:51:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 08:52:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/24/2022 08:52:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/24/2022 08:52:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/24/2022 08:52:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/24/2022 08:52:04 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
06/24/2022 08:52:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
06/24/2022 08:52:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=459
06/24/2022 08:52:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 08:52:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 08:52:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/24/2022 08:52:11 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.53125 on epoch=474
06/24/2022 08:52:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/24/2022 08:52:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
06/24/2022 08:52:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
06/24/2022 08:52:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/24/2022 08:52:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/24/2022 08:52:18 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.53125 on epoch=499
06/24/2022 08:52:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
06/24/2022 08:52:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/24/2022 08:52:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
06/24/2022 08:52:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/24/2022 08:52:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/24/2022 08:52:24 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
06/24/2022 08:52:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
06/24/2022 08:52:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 08:52:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/24/2022 08:52:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/24/2022 08:52:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/24/2022 08:52:31 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.46875 on epoch=549
06/24/2022 08:52:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/24/2022 08:52:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 08:52:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/24/2022 08:52:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
06/24/2022 08:52:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 08:52:38 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5 on epoch=574
06/24/2022 08:52:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 08:52:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=584
06/24/2022 08:52:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 08:52:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 08:52:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 08:52:44 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.5625 on epoch=599
06/24/2022 08:52:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 08:52:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 08:52:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/24/2022 08:52:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 08:52:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 08:52:51 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.4375 on epoch=624
06/24/2022 08:52:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/24/2022 08:52:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 08:52:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 08:52:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 08:52:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 08:52:58 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.53125 on epoch=649
06/24/2022 08:52:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 08:53:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=659
06/24/2022 08:53:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 08:53:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 08:53:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 08:53:04 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.46875 on epoch=674
06/24/2022 08:53:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 08:53:07 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 08:53:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 08:53:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 08:53:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 08:53:11 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5 on epoch=699
06/24/2022 08:53:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 08:53:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/24/2022 08:53:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/24/2022 08:53:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/24/2022 08:53:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 08:53:17 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.5 on epoch=724
06/24/2022 08:53:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 08:53:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 08:53:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 08:53:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 08:53:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 08:53:24 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.5 on epoch=749
06/24/2022 08:53:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 08:53:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/24/2022 08:53:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 08:53:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 08:53:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 08:53:31 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
06/24/2022 08:53:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 08:53:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 08:53:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 08:53:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 08:53:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 08:53:37 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.53125 on epoch=799
06/24/2022 08:53:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 08:53:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 08:53:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 08:53:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 08:53:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 08:53:44 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.53125 on epoch=824
06/24/2022 08:53:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/24/2022 08:53:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 08:53:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 08:53:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/24/2022 08:53:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 08:53:51 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.5625 on epoch=849
06/24/2022 08:53:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/24/2022 08:53:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 08:53:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 08:53:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 08:53:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 08:53:57 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5 on epoch=874
06/24/2022 08:53:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 08:54:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 08:54:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 08:54:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 08:54:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 08:54:04 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.59375 on epoch=899
06/24/2022 08:54:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 08:54:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 08:54:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 08:54:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 08:54:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/24/2022 08:54:11 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.53125 on epoch=924
06/24/2022 08:54:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 08:54:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 08:54:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 08:54:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 08:54:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 08:54:17 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.53125 on epoch=949
06/24/2022 08:54:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 08:54:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 08:54:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 08:54:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 08:54:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 08:54:24 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.53125 on epoch=974
06/24/2022 08:54:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 08:54:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 08:54:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 08:54:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 08:54:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 08:54:31 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5 on epoch=999
06/24/2022 08:54:31 - INFO - __main__ - save last model!
06/24/2022 08:54:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 08:54:31 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 08:54:31 - INFO - __main__ - Printing 3 examples
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 08:54:31 - INFO - __main__ - ['duplicate']
06/24/2022 08:54:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:54:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:54:31 - INFO - __main__ - Printing 3 examples
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:54:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:54:31 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:54:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:54:31 - INFO - __main__ - Printing 3 examples
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:54:31 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:54:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:54:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:54:31 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:54:37 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 08:54:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:54:37 - INFO - __main__ - Starting training!
06/24/2022 08:54:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:55:30 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 09:08:24 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.5_8_predictions.txt
06/24/2022 09:08:24 - INFO - __main__ - ACC on test data: 0.5918
06/24/2022 09:08:24 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.5, bsz=8, dev_performance=0.6875, test_performance=0.591788276032649
06/24/2022 09:08:24 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.4, bsz=8 ...
06/24/2022 09:08:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:08:25 - INFO - __main__ - Printing 3 examples
06/24/2022 09:08:25 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 09:08:25 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:08:25 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 09:08:25 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:08:25 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 09:08:25 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:08:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:08:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:08:25 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 09:08:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:08:25 - INFO - __main__ - Printing 3 examples
06/24/2022 09:08:25 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 09:08:25 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:08:25 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 09:08:25 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:08:25 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 09:08:25 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:08:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:08:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:08:25 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 09:08:30 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 09:08:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 09:08:31 - INFO - __main__ - Starting training!
06/24/2022 09:08:32 - INFO - __main__ - Step 10 Global step 10 Train loss 5.64 on epoch=4
06/24/2022 09:08:33 - INFO - __main__ - Step 20 Global step 20 Train loss 4.00 on epoch=9
06/24/2022 09:08:35 - INFO - __main__ - Step 30 Global step 30 Train loss 2.82 on epoch=14
06/24/2022 09:08:36 - INFO - __main__ - Step 40 Global step 40 Train loss 1.90 on epoch=19
06/24/2022 09:08:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.41 on epoch=24
06/24/2022 09:08:37 - INFO - __main__ - Global step 50 Train loss 3.16 ACC 0.5 on epoch=24
06/24/2022 09:08:38 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 09:08:39 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=29
06/24/2022 09:08:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
06/24/2022 09:08:41 - INFO - __main__ - Step 80 Global step 80 Train loss 0.66 on epoch=39
06/24/2022 09:08:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.50 on epoch=44
06/24/2022 09:08:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.42 on epoch=49
06/24/2022 09:08:44 - INFO - __main__ - Global step 100 Train loss 0.64 ACC 0.5 on epoch=49
06/24/2022 09:08:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.42 on epoch=54
06/24/2022 09:08:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=59
06/24/2022 09:08:48 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
06/24/2022 09:08:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
06/24/2022 09:08:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.34 on epoch=74
06/24/2022 09:08:51 - INFO - __main__ - Global step 150 Train loss 0.34 ACC 0.5 on epoch=74
06/24/2022 09:08:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=79
06/24/2022 09:08:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=84
06/24/2022 09:08:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.27 on epoch=89
06/24/2022 09:08:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=94
06/24/2022 09:08:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
06/24/2022 09:08:58 - INFO - __main__ - Global step 200 Train loss 0.29 ACC 0.5 on epoch=99
06/24/2022 09:08:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
06/24/2022 09:09:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
06/24/2022 09:09:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=114
06/24/2022 09:09:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=119
06/24/2022 09:09:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/24/2022 09:09:05 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.5 on epoch=124
06/24/2022 09:09:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=129
06/24/2022 09:09:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=134
06/24/2022 09:09:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=139
06/24/2022 09:09:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.18 on epoch=144
06/24/2022 09:09:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=149
06/24/2022 09:09:12 - INFO - __main__ - Global step 300 Train loss 0.22 ACC 0.5 on epoch=149
06/24/2022 09:09:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=154
06/24/2022 09:09:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=159
06/24/2022 09:09:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=164
06/24/2022 09:09:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=169
06/24/2022 09:09:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=174
06/24/2022 09:09:19 - INFO - __main__ - Global step 350 Train loss 0.18 ACC 0.625 on epoch=174
06/24/2022 09:09:19 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.625 on epoch=174, global_step=350
06/24/2022 09:09:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.13 on epoch=179
06/24/2022 09:09:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=184
06/24/2022 09:09:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.14 on epoch=189
06/24/2022 09:09:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=194
06/24/2022 09:09:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=199
06/24/2022 09:09:26 - INFO - __main__ - Global step 400 Train loss 0.15 ACC 0.59375 on epoch=199
06/24/2022 09:09:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=204
06/24/2022 09:09:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=209
06/24/2022 09:09:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=214
06/24/2022 09:09:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=219
06/24/2022 09:09:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=224
06/24/2022 09:09:33 - INFO - __main__ - Global step 450 Train loss 0.12 ACC 0.5625 on epoch=224
06/24/2022 09:09:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=229
06/24/2022 09:09:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=234
06/24/2022 09:09:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=239
06/24/2022 09:09:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=244
06/24/2022 09:09:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=249
06/24/2022 09:09:40 - INFO - __main__ - Global step 500 Train loss 0.11 ACC 0.5625 on epoch=249
06/24/2022 09:09:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=254
06/24/2022 09:09:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
06/24/2022 09:09:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=264
06/24/2022 09:09:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=269
06/24/2022 09:09:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
06/24/2022 09:09:47 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.6875 on epoch=274
06/24/2022 09:09:47 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=274, global_step=550
06/24/2022 09:09:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=279
06/24/2022 09:09:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
06/24/2022 09:09:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=289
06/24/2022 09:09:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/24/2022 09:09:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=299
06/24/2022 09:09:55 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.65625 on epoch=299
06/24/2022 09:09:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=304
06/24/2022 09:09:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
06/24/2022 09:09:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=314
06/24/2022 09:10:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=319
06/24/2022 09:10:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=324
06/24/2022 09:10:02 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.6875 on epoch=324
06/24/2022 09:10:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
06/24/2022 09:10:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/24/2022 09:10:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/24/2022 09:10:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
06/24/2022 09:10:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/24/2022 09:10:09 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.6875 on epoch=349
06/24/2022 09:10:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=354
06/24/2022 09:10:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=359
06/24/2022 09:10:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/24/2022 09:10:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=369
06/24/2022 09:10:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
06/24/2022 09:10:16 - INFO - __main__ - Global step 750 Train loss 0.04 ACC 0.5625 on epoch=374
06/24/2022 09:10:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
06/24/2022 09:10:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=384
06/24/2022 09:10:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/24/2022 09:10:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=394
06/24/2022 09:10:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/24/2022 09:10:23 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.5625 on epoch=399
06/24/2022 09:10:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/24/2022 09:10:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/24/2022 09:10:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/24/2022 09:10:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
06/24/2022 09:10:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
06/24/2022 09:10:30 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.59375 on epoch=424
06/24/2022 09:10:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
06/24/2022 09:10:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
06/24/2022 09:10:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/24/2022 09:10:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/24/2022 09:10:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/24/2022 09:10:37 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.59375 on epoch=449
06/24/2022 09:10:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/24/2022 09:10:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/24/2022 09:10:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
06/24/2022 09:10:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 09:10:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/24/2022 09:10:44 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.59375 on epoch=474
06/24/2022 09:10:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/24/2022 09:10:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
06/24/2022 09:10:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/24/2022 09:10:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/24/2022 09:10:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/24/2022 09:10:51 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
06/24/2022 09:10:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/24/2022 09:10:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/24/2022 09:10:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
06/24/2022 09:10:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/24/2022 09:10:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/24/2022 09:10:58 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5625 on epoch=524
06/24/2022 09:11:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/24/2022 09:11:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/24/2022 09:11:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/24/2022 09:11:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 09:11:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 09:11:05 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.59375 on epoch=549
06/24/2022 09:11:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/24/2022 09:11:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
06/24/2022 09:11:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 09:11:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/24/2022 09:11:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 09:11:13 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.65625 on epoch=574
06/24/2022 09:11:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 09:11:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 09:11:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/24/2022 09:11:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/24/2022 09:11:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 09:11:20 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.59375 on epoch=599
06/24/2022 09:11:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 09:11:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/24/2022 09:11:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 09:11:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 09:11:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 09:11:27 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.59375 on epoch=624
06/24/2022 09:11:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 09:11:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/24/2022 09:11:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
06/24/2022 09:11:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 09:11:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 09:11:34 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.59375 on epoch=649
06/24/2022 09:11:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/24/2022 09:11:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 09:11:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 09:11:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 09:11:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 09:11:41 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.65625 on epoch=674
06/24/2022 09:11:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 09:11:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 09:11:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 09:11:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 09:11:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=699
06/24/2022 09:11:48 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.625 on epoch=699
06/24/2022 09:11:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 09:11:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 09:11:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 09:11:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 09:11:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 09:11:55 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.5625 on epoch=724
06/24/2022 09:11:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 09:11:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 09:11:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/24/2022 09:12:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 09:12:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 09:12:02 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.625 on epoch=749
06/24/2022 09:12:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/24/2022 09:12:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 09:12:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 09:12:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 09:12:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 09:12:10 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5 on epoch=774
06/24/2022 09:12:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 09:12:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 09:12:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 09:12:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 09:12:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 09:12:17 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.59375 on epoch=799
06/24/2022 09:12:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 09:12:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 09:12:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 09:12:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 09:12:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 09:12:24 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.625 on epoch=824
06/24/2022 09:12:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 09:12:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 09:12:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 09:12:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 09:12:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 09:12:31 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.53125 on epoch=849
06/24/2022 09:12:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/24/2022 09:12:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 09:12:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 09:12:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 09:12:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 09:12:38 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
06/24/2022 09:12:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 09:12:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 09:12:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 09:12:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 09:12:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 09:12:45 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/24/2022 09:12:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 09:12:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 09:12:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 09:12:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 09:12:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/24/2022 09:12:52 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.59375 on epoch=924
06/24/2022 09:12:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 09:12:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 09:12:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 09:12:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 09:12:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 09:12:59 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/24/2022 09:13:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 09:13:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 09:13:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 09:13:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=969
06/24/2022 09:13:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 09:13:07 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.625 on epoch=974
06/24/2022 09:13:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=979
06/24/2022 09:13:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 09:13:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 09:13:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 09:13:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 09:13:14 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5625 on epoch=999
06/24/2022 09:13:14 - INFO - __main__ - save last model!
06/24/2022 09:13:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 09:13:14 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 09:13:14 - INFO - __main__ - Printing 3 examples
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 09:13:14 - INFO - __main__ - ['duplicate']
06/24/2022 09:13:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:13:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:13:14 - INFO - __main__ - Printing 3 examples
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:13:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:13:14 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 09:13:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:13:14 - INFO - __main__ - Printing 3 examples
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 09:13:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:13:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:13:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:13:14 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 09:13:20 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 09:13:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 09:13:20 - INFO - __main__ - Starting training!
06/24/2022 09:13:32 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:14:13 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 09:27:04 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.4_8_predictions.txt
06/24/2022 09:27:04 - INFO - __main__ - ACC on test data: 0.5624
06/24/2022 09:27:05 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.4, bsz=8, dev_performance=0.6875, test_performance=0.5624288894385358
06/24/2022 09:27:05 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.3, bsz=8 ...
06/24/2022 09:27:06 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:27:06 - INFO - __main__ - Printing 3 examples
06/24/2022 09:27:06 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 09:27:06 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:27:06 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 09:27:06 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:27:06 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 09:27:06 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:27:06 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:27:06 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:27:06 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 09:27:06 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:27:06 - INFO - __main__ - Printing 3 examples
06/24/2022 09:27:06 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 09:27:06 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:27:06 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 09:27:06 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:27:06 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 09:27:06 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:27:06 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:27:06 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:27:06 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 09:27:11 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 09:27:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 09:27:11 - INFO - __main__ - Starting training!
06/24/2022 09:27:13 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=4
06/24/2022 09:27:14 - INFO - __main__ - Step 20 Global step 20 Train loss 4.70 on epoch=9
06/24/2022 09:27:15 - INFO - __main__ - Step 30 Global step 30 Train loss 3.68 on epoch=14
06/24/2022 09:27:16 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=19
06/24/2022 09:27:18 - INFO - __main__ - Step 50 Global step 50 Train loss 2.18 on epoch=24
06/24/2022 09:27:18 - INFO - __main__ - Global step 50 Train loss 4.00 ACC 0.0 on epoch=24
06/24/2022 09:27:18 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 09:27:20 - INFO - __main__ - Step 60 Global step 60 Train loss 1.59 on epoch=29
06/24/2022 09:27:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.25 on epoch=34
06/24/2022 09:27:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=39
06/24/2022 09:27:24 - INFO - __main__ - Step 90 Global step 90 Train loss 0.76 on epoch=44
06/24/2022 09:27:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=49
06/24/2022 09:27:25 - INFO - __main__ - Global step 100 Train loss 1.04 ACC 0.5 on epoch=49
06/24/2022 09:27:25 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 09:27:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.50 on epoch=54
06/24/2022 09:27:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=59
06/24/2022 09:27:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=64
06/24/2022 09:27:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.40 on epoch=69
06/24/2022 09:27:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.40 on epoch=74
06/24/2022 09:27:32 - INFO - __main__ - Global step 150 Train loss 0.44 ACC 0.5 on epoch=74
06/24/2022 09:27:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.37 on epoch=79
06/24/2022 09:27:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/24/2022 09:27:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.32 on epoch=89
06/24/2022 09:27:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/24/2022 09:27:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.33 on epoch=99
06/24/2022 09:27:40 - INFO - __main__ - Global step 200 Train loss 0.34 ACC 0.5 on epoch=99
06/24/2022 09:27:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/24/2022 09:27:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=109
06/24/2022 09:27:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/24/2022 09:27:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=119
06/24/2022 09:27:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/24/2022 09:27:46 - INFO - __main__ - Global step 250 Train loss 0.31 ACC 0.5 on epoch=124
06/24/2022 09:27:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=129
06/24/2022 09:27:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/24/2022 09:27:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/24/2022 09:27:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/24/2022 09:27:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=149
06/24/2022 09:27:53 - INFO - __main__ - Global step 300 Train loss 0.27 ACC 0.5 on epoch=149
06/24/2022 09:27:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=154
06/24/2022 09:27:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=159
06/24/2022 09:27:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=164
06/24/2022 09:27:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=169
06/24/2022 09:28:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=174
06/24/2022 09:28:00 - INFO - __main__ - Global step 350 Train loss 0.23 ACC 0.46875 on epoch=174
06/24/2022 09:28:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 09:28:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=184
06/24/2022 09:28:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 09:28:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=194
06/24/2022 09:28:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=199
06/24/2022 09:28:07 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.46875 on epoch=199
06/24/2022 09:28:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/24/2022 09:28:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=209
06/24/2022 09:28:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=214
06/24/2022 09:28:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=219
06/24/2022 09:28:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=224
06/24/2022 09:28:14 - INFO - __main__ - Global step 450 Train loss 0.20 ACC 0.5 on epoch=224
06/24/2022 09:28:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
06/24/2022 09:28:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=234
06/24/2022 09:28:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=239
06/24/2022 09:28:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=244
06/24/2022 09:28:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=249
06/24/2022 09:28:21 - INFO - __main__ - Global step 500 Train loss 0.19 ACC 0.5 on epoch=249
06/24/2022 09:28:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=254
06/24/2022 09:28:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=259
06/24/2022 09:28:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=264
06/24/2022 09:28:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=269
06/24/2022 09:28:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=274
06/24/2022 09:28:29 - INFO - __main__ - Global step 550 Train loss 0.14 ACC 0.59375 on epoch=274
06/24/2022 09:28:29 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=274, global_step=550
06/24/2022 09:28:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/24/2022 09:28:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=284
06/24/2022 09:28:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=289
06/24/2022 09:28:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=294
06/24/2022 09:28:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=299
06/24/2022 09:28:36 - INFO - __main__ - Global step 600 Train loss 0.14 ACC 0.5625 on epoch=299
06/24/2022 09:28:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=304
06/24/2022 09:28:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=309
06/24/2022 09:28:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=314
06/24/2022 09:28:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=319
06/24/2022 09:28:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=324
06/24/2022 09:28:43 - INFO - __main__ - Global step 650 Train loss 0.11 ACC 0.53125 on epoch=324
06/24/2022 09:28:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=329
06/24/2022 09:28:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=334
06/24/2022 09:28:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=339
06/24/2022 09:28:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=344
06/24/2022 09:28:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=349
06/24/2022 09:28:50 - INFO - __main__ - Global step 700 Train loss 0.08 ACC 0.53125 on epoch=349
06/24/2022 09:28:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=354
06/24/2022 09:28:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=359
06/24/2022 09:28:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=364
06/24/2022 09:28:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
06/24/2022 09:28:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=374
06/24/2022 09:28:57 - INFO - __main__ - Global step 750 Train loss 0.06 ACC 0.5 on epoch=374
06/24/2022 09:28:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=379
06/24/2022 09:29:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=384
06/24/2022 09:29:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
06/24/2022 09:29:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/24/2022 09:29:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
06/24/2022 09:29:04 - INFO - __main__ - Global step 800 Train loss 0.05 ACC 0.46875 on epoch=399
06/24/2022 09:29:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=404
06/24/2022 09:29:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
06/24/2022 09:29:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/24/2022 09:29:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/24/2022 09:29:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=424
06/24/2022 09:29:11 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.40625 on epoch=424
06/24/2022 09:29:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
06/24/2022 09:29:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
06/24/2022 09:29:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/24/2022 09:29:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
06/24/2022 09:29:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/24/2022 09:29:18 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.5 on epoch=449
06/24/2022 09:29:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=454
06/24/2022 09:29:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/24/2022 09:29:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=464
06/24/2022 09:29:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=469
06/24/2022 09:29:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/24/2022 09:29:25 - INFO - __main__ - Global step 950 Train loss 0.04 ACC 0.5625 on epoch=474
06/24/2022 09:29:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/24/2022 09:29:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
06/24/2022 09:29:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/24/2022 09:29:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=494
06/24/2022 09:29:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 09:29:32 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.4375 on epoch=499
06/24/2022 09:29:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=504
06/24/2022 09:29:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/24/2022 09:29:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
06/24/2022 09:29:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/24/2022 09:29:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/24/2022 09:29:39 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5 on epoch=524
06/24/2022 09:29:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
06/24/2022 09:29:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
06/24/2022 09:29:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/24/2022 09:29:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 09:29:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/24/2022 09:29:46 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5 on epoch=549
06/24/2022 09:29:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=554
06/24/2022 09:29:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/24/2022 09:29:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
06/24/2022 09:29:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 09:29:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 09:29:53 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.53125 on epoch=574
06/24/2022 09:29:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 09:29:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 09:29:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 09:29:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 09:30:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/24/2022 09:30:00 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.46875 on epoch=599
06/24/2022 09:30:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 09:30:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 09:30:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 09:30:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/24/2022 09:30:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/24/2022 09:30:07 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5 on epoch=624
06/24/2022 09:30:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 09:30:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/24/2022 09:30:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
06/24/2022 09:30:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
06/24/2022 09:30:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
06/24/2022 09:30:14 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.46875 on epoch=649
06/24/2022 09:30:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 09:30:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 09:30:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/24/2022 09:30:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 09:30:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 09:30:21 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.46875 on epoch=674
06/24/2022 09:30:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 09:30:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 09:30:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/24/2022 09:30:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 09:30:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 09:30:28 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.4375 on epoch=699
06/24/2022 09:30:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 09:30:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 09:30:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 09:30:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/24/2022 09:30:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/24/2022 09:30:35 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.375 on epoch=724
06/24/2022 09:30:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/24/2022 09:30:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 09:30:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 09:30:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 09:30:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 09:30:42 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.34375 on epoch=749
06/24/2022 09:30:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 09:30:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 09:30:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/24/2022 09:30:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 09:30:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 09:30:49 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.46875 on epoch=774
06/24/2022 09:30:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 09:30:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 09:30:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 09:30:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 09:30:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 09:30:56 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.46875 on epoch=799
06/24/2022 09:30:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 09:30:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 09:31:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 09:31:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
06/24/2022 09:31:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 09:31:04 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.5 on epoch=824
06/24/2022 09:31:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 09:31:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 09:31:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 09:31:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 09:31:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 09:31:11 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.40625 on epoch=849
06/24/2022 09:31:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 09:31:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 09:31:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 09:31:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 09:31:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 09:31:18 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.4375 on epoch=874
06/24/2022 09:31:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 09:31:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 09:31:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 09:31:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 09:31:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 09:31:25 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.375 on epoch=899
06/24/2022 09:31:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 09:31:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 09:31:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 09:31:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 09:31:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 09:31:32 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5 on epoch=924
06/24/2022 09:31:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 09:31:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 09:31:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 09:31:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 09:31:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 09:31:39 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
06/24/2022 09:31:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 09:31:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 09:31:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/24/2022 09:31:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 09:31:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=974
06/24/2022 09:31:46 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5 on epoch=974
06/24/2022 09:31:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 09:31:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 09:31:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 09:31:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 09:31:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=999
06/24/2022 09:31:53 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.4375 on epoch=999
06/24/2022 09:31:53 - INFO - __main__ - save last model!
06/24/2022 09:31:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 09:31:53 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 09:31:53 - INFO - __main__ - Printing 3 examples
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 09:31:53 - INFO - __main__ - ['duplicate']
06/24/2022 09:31:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:31:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:31:53 - INFO - __main__ - Printing 3 examples
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:31:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:31:53 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 09:31:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:31:53 - INFO - __main__ - Printing 3 examples
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 09:31:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:31:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:31:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:31:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 09:31:59 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 09:31:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 09:31:59 - INFO - __main__ - Starting training!
06/24/2022 09:32:11 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:32:52 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 09:45:51 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.3_8_predictions.txt
06/24/2022 09:45:51 - INFO - __main__ - ACC on test data: 0.4599
06/24/2022 09:45:52 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.3, bsz=8, dev_performance=0.59375, test_performance=0.4598812762799901
06/24/2022 09:45:52 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.2, bsz=8 ...
06/24/2022 09:45:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:45:53 - INFO - __main__ - Printing 3 examples
06/24/2022 09:45:53 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 09:45:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:45:53 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 09:45:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:45:53 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 09:45:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:45:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:45:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:45:53 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 09:45:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:45:53 - INFO - __main__ - Printing 3 examples
06/24/2022 09:45:53 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 09:45:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:45:53 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 09:45:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:45:53 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 09:45:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:45:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:45:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:45:53 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 09:45:59 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 09:45:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 09:45:59 - INFO - __main__ - Starting training!
06/24/2022 09:46:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.46 on epoch=4
06/24/2022 09:46:02 - INFO - __main__ - Step 20 Global step 20 Train loss 5.29 on epoch=9
06/24/2022 09:46:03 - INFO - __main__ - Step 30 Global step 30 Train loss 4.46 on epoch=14
06/24/2022 09:46:04 - INFO - __main__ - Step 40 Global step 40 Train loss 3.78 on epoch=19
06/24/2022 09:46:06 - INFO - __main__ - Step 50 Global step 50 Train loss 3.17 on epoch=24
06/24/2022 09:46:06 - INFO - __main__ - Global step 50 Train loss 4.63 ACC 0.0 on epoch=24
06/24/2022 09:46:06 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 09:46:08 - INFO - __main__ - Step 60 Global step 60 Train loss 2.70 on epoch=29
06/24/2022 09:46:09 - INFO - __main__ - Step 70 Global step 70 Train loss 2.22 on epoch=34
06/24/2022 09:46:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.86 on epoch=39
06/24/2022 09:46:11 - INFO - __main__ - Step 90 Global step 90 Train loss 1.63 on epoch=44
06/24/2022 09:46:13 - INFO - __main__ - Step 100 Global step 100 Train loss 1.30 on epoch=49
06/24/2022 09:46:13 - INFO - __main__ - Global step 100 Train loss 1.94 ACC 0.5 on epoch=49
06/24/2022 09:46:13 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 09:46:14 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=54
06/24/2022 09:46:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=59
06/24/2022 09:46:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=64
06/24/2022 09:46:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=69
06/24/2022 09:46:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=74
06/24/2022 09:46:20 - INFO - __main__ - Global step 150 Train loss 0.79 ACC 0.5 on epoch=74
06/24/2022 09:46:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=79
06/24/2022 09:46:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.49 on epoch=84
06/24/2022 09:46:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=89
06/24/2022 09:46:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=94
06/24/2022 09:46:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=99
06/24/2022 09:46:27 - INFO - __main__ - Global step 200 Train loss 0.47 ACC 0.5 on epoch=99
06/24/2022 09:46:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=104
06/24/2022 09:46:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=109
06/24/2022 09:46:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=114
06/24/2022 09:46:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=119
06/24/2022 09:46:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=124
06/24/2022 09:46:34 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.5 on epoch=124
06/24/2022 09:46:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=129
06/24/2022 09:46:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=134
06/24/2022 09:46:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=139
06/24/2022 09:46:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 09:46:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=149
06/24/2022 09:46:41 - INFO - __main__ - Global step 300 Train loss 0.32 ACC 0.5 on epoch=149
06/24/2022 09:46:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/24/2022 09:46:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=159
06/24/2022 09:46:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/24/2022 09:46:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=169
06/24/2022 09:46:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=174
06/24/2022 09:46:47 - INFO - __main__ - Global step 350 Train loss 0.30 ACC 0.5 on epoch=174
06/24/2022 09:46:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=179
06/24/2022 09:46:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=184
06/24/2022 09:46:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=189
06/24/2022 09:46:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=194
06/24/2022 09:46:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=199
06/24/2022 09:46:54 - INFO - __main__ - Global step 400 Train loss 0.28 ACC 0.5 on epoch=199
06/24/2022 09:46:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/24/2022 09:46:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/24/2022 09:46:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/24/2022 09:46:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=219
06/24/2022 09:47:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=224
06/24/2022 09:47:01 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.5 on epoch=224
06/24/2022 09:47:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=229
06/24/2022 09:47:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=234
06/24/2022 09:47:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=239
06/24/2022 09:47:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=244
06/24/2022 09:47:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=249
06/24/2022 09:47:08 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/24/2022 09:47:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=254
06/24/2022 09:47:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=259
06/24/2022 09:47:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 09:47:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=269
06/24/2022 09:47:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/24/2022 09:47:15 - INFO - __main__ - Global step 550 Train loss 0.23 ACC 0.5 on epoch=274
06/24/2022 09:47:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/24/2022 09:47:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=284
06/24/2022 09:47:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=289
06/24/2022 09:47:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=294
06/24/2022 09:47:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=299
06/24/2022 09:47:22 - INFO - __main__ - Global step 600 Train loss 0.20 ACC 0.53125 on epoch=299
06/24/2022 09:47:22 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=299, global_step=600
06/24/2022 09:47:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=304
06/24/2022 09:47:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=309
06/24/2022 09:47:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=314
06/24/2022 09:47:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=319
06/24/2022 09:47:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=324
06/24/2022 09:47:29 - INFO - __main__ - Global step 650 Train loss 0.20 ACC 0.625 on epoch=324
06/24/2022 09:47:29 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=324, global_step=650
06/24/2022 09:47:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=329
06/24/2022 09:47:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=334
06/24/2022 09:47:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=339
06/24/2022 09:47:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=344
06/24/2022 09:47:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=349
06/24/2022 09:47:36 - INFO - __main__ - Global step 700 Train loss 0.17 ACC 0.625 on epoch=349
06/24/2022 09:47:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=354
06/24/2022 09:47:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=359
06/24/2022 09:47:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=364
06/24/2022 09:47:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=369
06/24/2022 09:47:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=374
06/24/2022 09:47:43 - INFO - __main__ - Global step 750 Train loss 0.15 ACC 0.625 on epoch=374
06/24/2022 09:47:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=379
06/24/2022 09:47:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=384
06/24/2022 09:47:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=389
06/24/2022 09:47:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=394
06/24/2022 09:47:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=399
06/24/2022 09:47:50 - INFO - __main__ - Global step 800 Train loss 0.12 ACC 0.625 on epoch=399
06/24/2022 09:47:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=404
06/24/2022 09:47:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=409
06/24/2022 09:47:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=414
06/24/2022 09:47:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=419
06/24/2022 09:47:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=424
06/24/2022 09:47:57 - INFO - __main__ - Global step 850 Train loss 0.10 ACC 0.5625 on epoch=424
06/24/2022 09:47:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=429
06/24/2022 09:47:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=434
06/24/2022 09:48:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=439
06/24/2022 09:48:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=444
06/24/2022 09:48:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=449
06/24/2022 09:48:04 - INFO - __main__ - Global step 900 Train loss 0.09 ACC 0.59375 on epoch=449
06/24/2022 09:48:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=454
06/24/2022 09:48:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=459
06/24/2022 09:48:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=464
06/24/2022 09:48:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=469
06/24/2022 09:48:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=474
06/24/2022 09:48:10 - INFO - __main__ - Global step 950 Train loss 0.08 ACC 0.53125 on epoch=474
06/24/2022 09:48:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=479
06/24/2022 09:48:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
06/24/2022 09:48:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=489
06/24/2022 09:48:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=494
06/24/2022 09:48:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=499
06/24/2022 09:48:17 - INFO - __main__ - Global step 1000 Train loss 0.06 ACC 0.59375 on epoch=499
06/24/2022 09:48:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=504
06/24/2022 09:48:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=509
06/24/2022 09:48:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
06/24/2022 09:48:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=519
06/24/2022 09:48:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=524
06/24/2022 09:48:24 - INFO - __main__ - Global step 1050 Train loss 0.06 ACC 0.46875 on epoch=524
06/24/2022 09:48:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/24/2022 09:48:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
06/24/2022 09:48:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/24/2022 09:48:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=544
06/24/2022 09:48:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=549
06/24/2022 09:48:31 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.5 on epoch=549
06/24/2022 09:48:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
06/24/2022 09:48:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/24/2022 09:48:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
06/24/2022 09:48:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=569
06/24/2022 09:48:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
06/24/2022 09:48:38 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.5 on epoch=574
06/24/2022 09:48:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
06/24/2022 09:48:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 09:48:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
06/24/2022 09:48:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
06/24/2022 09:48:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=599
06/24/2022 09:48:45 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.5 on epoch=599
06/24/2022 09:48:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 09:48:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/24/2022 09:48:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=614
06/24/2022 09:48:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=619
06/24/2022 09:48:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/24/2022 09:48:52 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.5625 on epoch=624
06/24/2022 09:48:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=629
06/24/2022 09:48:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
06/24/2022 09:48:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 09:48:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
06/24/2022 09:48:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=649
06/24/2022 09:48:59 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.5625 on epoch=649
06/24/2022 09:49:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=654
06/24/2022 09:49:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=659
06/24/2022 09:49:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/24/2022 09:49:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 09:49:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 09:49:06 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.53125 on epoch=674
06/24/2022 09:49:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 09:49:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/24/2022 09:49:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/24/2022 09:49:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/24/2022 09:49:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 09:49:13 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.53125 on epoch=699
06/24/2022 09:49:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
06/24/2022 09:49:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/24/2022 09:49:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 09:49:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=719
06/24/2022 09:49:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=724
06/24/2022 09:49:20 - INFO - __main__ - Global step 1450 Train loss 0.03 ACC 0.5 on epoch=724
06/24/2022 09:49:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/24/2022 09:49:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/24/2022 09:49:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
06/24/2022 09:49:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=744
06/24/2022 09:49:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/24/2022 09:49:27 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.46875 on epoch=749
06/24/2022 09:49:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=754
06/24/2022 09:49:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/24/2022 09:49:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/24/2022 09:49:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/24/2022 09:49:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 09:49:34 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.4375 on epoch=774
06/24/2022 09:49:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 09:49:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
06/24/2022 09:49:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
06/24/2022 09:49:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=794
06/24/2022 09:49:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
06/24/2022 09:49:41 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.5 on epoch=799
06/24/2022 09:49:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
06/24/2022 09:49:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/24/2022 09:49:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=814
06/24/2022 09:49:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 09:49:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 09:49:48 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.46875 on epoch=824
06/24/2022 09:49:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/24/2022 09:49:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 09:49:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 09:49:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/24/2022 09:49:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/24/2022 09:49:55 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.46875 on epoch=849
06/24/2022 09:49:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=854
06/24/2022 09:49:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 09:49:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 09:50:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
06/24/2022 09:50:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 09:50:02 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.4375 on epoch=874
06/24/2022 09:50:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 09:50:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 09:50:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 09:50:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 09:50:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 09:50:08 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.46875 on epoch=899
06/24/2022 09:50:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 09:50:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/24/2022 09:50:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 09:50:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 09:50:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 09:50:16 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.46875 on epoch=924
06/24/2022 09:50:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 09:50:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
06/24/2022 09:50:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 09:50:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 09:50:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=949
06/24/2022 09:50:25 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
06/24/2022 09:50:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 09:50:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
06/24/2022 09:50:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/24/2022 09:50:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 09:50:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 09:50:33 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.46875 on epoch=974
06/24/2022 09:50:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 09:50:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 09:50:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 09:50:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/24/2022 09:50:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 09:50:40 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.40625 on epoch=999
06/24/2022 09:50:40 - INFO - __main__ - save last model!
06/24/2022 09:50:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 09:50:40 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 09:50:40 - INFO - __main__ - Printing 3 examples
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 09:50:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 09:50:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:50:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:50:40 - INFO - __main__ - Printing 3 examples
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:50:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:50:40 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 09:50:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 09:50:40 - INFO - __main__ - Printing 3 examples
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 09:50:40 - INFO - __main__ - ['duplicate']
06/24/2022 09:50:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 09:50:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:50:40 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 09:50:46 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 09:50:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 09:50:46 - INFO - __main__ - Starting training!
06/24/2022 09:50:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 09:51:39 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 10:04:31 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_21_0.2_8_predictions.txt
06/24/2022 10:04:31 - INFO - __main__ - ACC on test data: 0.4470
06/24/2022 10:04:32 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.2, bsz=8, dev_performance=0.625, test_performance=0.44704427405392033
06/24/2022 10:04:32 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.5, bsz=8 ...
06/24/2022 10:04:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:04:33 - INFO - __main__ - Printing 3 examples
06/24/2022 10:04:33 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:04:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:04:33 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:04:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:04:33 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:04:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:04:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:04:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:04:33 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:04:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:04:33 - INFO - __main__ - Printing 3 examples
06/24/2022 10:04:33 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:04:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:04:33 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:04:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:04:33 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:04:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:04:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:04:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:04:33 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:04:39 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 10:04:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:04:39 - INFO - __main__ - Starting training!
06/24/2022 10:04:41 - INFO - __main__ - Step 10 Global step 10 Train loss 5.84 on epoch=4
06/24/2022 10:04:42 - INFO - __main__ - Step 20 Global step 20 Train loss 3.85 on epoch=9
06/24/2022 10:04:43 - INFO - __main__ - Step 30 Global step 30 Train loss 2.51 on epoch=14
06/24/2022 10:04:45 - INFO - __main__ - Step 40 Global step 40 Train loss 1.61 on epoch=19
06/24/2022 10:04:46 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=24
06/24/2022 10:04:47 - INFO - __main__ - Global step 50 Train loss 2.97 ACC 0.5 on epoch=24
06/24/2022 10:04:47 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 10:04:48 - INFO - __main__ - Step 60 Global step 60 Train loss 0.66 on epoch=29
06/24/2022 10:04:49 - INFO - __main__ - Step 70 Global step 70 Train loss 0.49 on epoch=34
06/24/2022 10:04:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.49 on epoch=39
06/24/2022 10:04:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.46 on epoch=44
06/24/2022 10:04:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.38 on epoch=49
06/24/2022 10:04:54 - INFO - __main__ - Global step 100 Train loss 0.49 ACC 0.5 on epoch=49
06/24/2022 10:04:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=54
06/24/2022 10:04:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
06/24/2022 10:04:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.39 on epoch=64
06/24/2022 10:04:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
06/24/2022 10:05:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.36 on epoch=74
06/24/2022 10:05:01 - INFO - __main__ - Global step 150 Train loss 0.36 ACC 0.5 on epoch=74
06/24/2022 10:05:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.34 on epoch=79
06/24/2022 10:05:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.32 on epoch=84
06/24/2022 10:05:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=89
06/24/2022 10:05:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/24/2022 10:05:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=99
06/24/2022 10:05:08 - INFO - __main__ - Global step 200 Train loss 0.32 ACC 0.5 on epoch=99
06/24/2022 10:05:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=104
06/24/2022 10:05:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=109
06/24/2022 10:05:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=114
06/24/2022 10:05:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 10:05:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=124
06/24/2022 10:05:15 - INFO - __main__ - Global step 250 Train loss 0.30 ACC 0.5 on epoch=124
06/24/2022 10:05:16 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/24/2022 10:05:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/24/2022 10:05:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=139
06/24/2022 10:05:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=144
06/24/2022 10:05:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/24/2022 10:05:22 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.53125 on epoch=149
06/24/2022 10:05:22 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=149, global_step=300
06/24/2022 10:05:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 10:05:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/24/2022 10:05:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=164
06/24/2022 10:05:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=169
06/24/2022 10:05:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=174
06/24/2022 10:05:29 - INFO - __main__ - Global step 350 Train loss 0.20 ACC 0.6875 on epoch=174
06/24/2022 10:05:29 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.6875 on epoch=174, global_step=350
06/24/2022 10:05:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=179
06/24/2022 10:05:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=184
06/24/2022 10:05:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=189
06/24/2022 10:05:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=194
06/24/2022 10:05:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=199
06/24/2022 10:05:37 - INFO - __main__ - Global step 400 Train loss 0.13 ACC 0.625 on epoch=199
06/24/2022 10:05:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.10 on epoch=204
06/24/2022 10:05:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=209
06/24/2022 10:05:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
06/24/2022 10:05:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=219
06/24/2022 10:05:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=224
06/24/2022 10:05:44 - INFO - __main__ - Global step 450 Train loss 0.09 ACC 0.65625 on epoch=224
06/24/2022 10:05:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.06 on epoch=229
06/24/2022 10:05:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=234
06/24/2022 10:05:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
06/24/2022 10:05:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
06/24/2022 10:05:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.03 on epoch=249
06/24/2022 10:05:51 - INFO - __main__ - Global step 500 Train loss 0.06 ACC 0.5625 on epoch=249
06/24/2022 10:05:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=254
06/24/2022 10:05:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=259
06/24/2022 10:05:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=264
06/24/2022 10:05:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=269
06/24/2022 10:05:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=274
06/24/2022 10:05:58 - INFO - __main__ - Global step 550 Train loss 0.04 ACC 0.5625 on epoch=274
06/24/2022 10:05:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=279
06/24/2022 10:06:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=284
06/24/2022 10:06:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
06/24/2022 10:06:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.03 on epoch=294
06/24/2022 10:06:04 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=299
06/24/2022 10:06:05 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.5625 on epoch=299
06/24/2022 10:06:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/24/2022 10:06:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.01 on epoch=309
06/24/2022 10:06:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.02 on epoch=314
06/24/2022 10:06:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=319
06/24/2022 10:06:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.01 on epoch=324
06/24/2022 10:06:12 - INFO - __main__ - Global step 650 Train loss 0.02 ACC 0.53125 on epoch=324
06/24/2022 10:06:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=329
06/24/2022 10:06:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/24/2022 10:06:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
06/24/2022 10:06:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=344
06/24/2022 10:06:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/24/2022 10:06:19 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.5625 on epoch=349
06/24/2022 10:06:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.00 on epoch=354
06/24/2022 10:06:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/24/2022 10:06:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=364
06/24/2022 10:06:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/24/2022 10:06:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=374
06/24/2022 10:06:27 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5 on epoch=374
06/24/2022 10:06:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/24/2022 10:06:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
06/24/2022 10:06:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=389
06/24/2022 10:06:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
06/24/2022 10:06:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/24/2022 10:06:34 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.53125 on epoch=399
06/24/2022 10:06:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=404
06/24/2022 10:06:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/24/2022 10:06:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=414
06/24/2022 10:06:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=419
06/24/2022 10:06:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/24/2022 10:06:41 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.53125 on epoch=424
06/24/2022 10:06:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
06/24/2022 10:06:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
06/24/2022 10:06:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
06/24/2022 10:06:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=444
06/24/2022 10:06:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/24/2022 10:06:48 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.46875 on epoch=449
06/24/2022 10:06:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=454
06/24/2022 10:06:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/24/2022 10:06:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=464
06/24/2022 10:06:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=469
06/24/2022 10:06:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=474
06/24/2022 10:06:55 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.5 on epoch=474
06/24/2022 10:06:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=479
06/24/2022 10:06:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=484
06/24/2022 10:06:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/24/2022 10:07:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/24/2022 10:07:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 10:07:02 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.625 on epoch=499
06/24/2022 10:07:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 10:07:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
06/24/2022 10:07:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
06/24/2022 10:07:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/24/2022 10:07:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=524
06/24/2022 10:07:09 - INFO - __main__ - Global step 1050 Train loss 0.00 ACC 0.59375 on epoch=524
06/24/2022 10:07:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
06/24/2022 10:07:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 10:07:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/24/2022 10:07:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/24/2022 10:07:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 10:07:17 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.65625 on epoch=549
06/24/2022 10:07:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/24/2022 10:07:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/24/2022 10:07:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 10:07:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 10:07:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=574
06/24/2022 10:07:24 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.59375 on epoch=574
06/24/2022 10:07:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 10:07:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 10:07:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
06/24/2022 10:07:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 10:07:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 10:07:31 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.625 on epoch=599
06/24/2022 10:07:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 10:07:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 10:07:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/24/2022 10:07:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 10:07:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/24/2022 10:07:38 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.625 on epoch=624
06/24/2022 10:07:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/24/2022 10:07:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 10:07:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 10:07:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 10:07:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 10:07:45 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
06/24/2022 10:07:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 10:07:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 10:07:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 10:07:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 10:07:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 10:07:52 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.625 on epoch=674
06/24/2022 10:07:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
06/24/2022 10:07:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 10:07:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 10:07:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 10:07:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 10:07:59 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.65625 on epoch=699
06/24/2022 10:08:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 10:08:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 10:08:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/24/2022 10:08:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 10:08:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/24/2022 10:08:06 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.59375 on epoch=724
06/24/2022 10:08:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 10:08:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 10:08:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 10:08:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 10:08:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 10:08:14 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.59375 on epoch=749
06/24/2022 10:08:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/24/2022 10:08:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/24/2022 10:08:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/24/2022 10:08:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 10:08:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 10:08:21 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.71875 on epoch=774
06/24/2022 10:08:21 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=774, global_step=1550
06/24/2022 10:08:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 10:08:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 10:08:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 10:08:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 10:08:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 10:08:28 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.625 on epoch=799
06/24/2022 10:08:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 10:08:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 10:08:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 10:08:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 10:08:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/24/2022 10:08:35 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.71875 on epoch=824
06/24/2022 10:08:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 10:08:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 10:08:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 10:08:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 10:08:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 10:08:42 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.71875 on epoch=849
06/24/2022 10:08:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 10:08:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 10:08:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 10:08:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 10:08:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 10:08:50 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.6875 on epoch=874
06/24/2022 10:08:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 10:08:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 10:08:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 10:08:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 10:08:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 10:08:57 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.65625 on epoch=899
06/24/2022 10:08:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 10:09:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 10:09:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 10:09:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 10:09:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 10:09:04 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.65625 on epoch=924
06/24/2022 10:09:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 10:09:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 10:09:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 10:09:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 10:09:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 10:09:11 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.6875 on epoch=949
06/24/2022 10:09:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 10:09:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 10:09:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 10:09:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 10:09:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 10:09:18 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.6875 on epoch=974
06/24/2022 10:09:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 10:09:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 10:09:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 10:09:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 10:09:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 10:09:26 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.625 on epoch=999
06/24/2022 10:09:26 - INFO - __main__ - save last model!
06/24/2022 10:09:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 10:09:26 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 10:09:26 - INFO - __main__ - Printing 3 examples
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 10:09:26 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 10:09:26 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:09:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:09:26 - INFO - __main__ - Printing 3 examples
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:09:26 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:09:26 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:09:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:09:26 - INFO - __main__ - Printing 3 examples
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:09:26 - INFO - __main__ - ['duplicate']
06/24/2022 10:09:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:09:26 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:09:26 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:09:32 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 10:09:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:09:32 - INFO - __main__ - Starting training!
06/24/2022 10:09:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:10:27 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 10:23:28 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.5_8_predictions.txt
06/24/2022 10:23:28 - INFO - __main__ - ACC on test data: 0.5482
06/24/2022 10:23:29 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.5, bsz=8, dev_performance=0.71875, test_performance=0.5481573089290132
06/24/2022 10:23:29 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.4, bsz=8 ...
06/24/2022 10:23:30 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:23:30 - INFO - __main__ - Printing 3 examples
06/24/2022 10:23:30 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:23:30 - INFO - __main__ - ['duplicate']
06/24/2022 10:23:30 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:23:30 - INFO - __main__ - ['duplicate']
06/24/2022 10:23:30 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:23:30 - INFO - __main__ - ['duplicate']
06/24/2022 10:23:30 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:23:30 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:23:30 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:23:30 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:23:30 - INFO - __main__ - Printing 3 examples
06/24/2022 10:23:30 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:23:30 - INFO - __main__ - ['duplicate']
06/24/2022 10:23:30 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:23:30 - INFO - __main__ - ['duplicate']
06/24/2022 10:23:30 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:23:30 - INFO - __main__ - ['duplicate']
06/24/2022 10:23:30 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:23:30 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:23:30 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:23:36 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 10:23:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:23:36 - INFO - __main__ - Starting training!
06/24/2022 10:23:37 - INFO - __main__ - Step 10 Global step 10 Train loss 5.99 on epoch=4
06/24/2022 10:23:39 - INFO - __main__ - Step 20 Global step 20 Train loss 4.28 on epoch=9
06/24/2022 10:23:40 - INFO - __main__ - Step 30 Global step 30 Train loss 2.92 on epoch=14
06/24/2022 10:23:41 - INFO - __main__ - Step 40 Global step 40 Train loss 2.09 on epoch=19
06/24/2022 10:23:43 - INFO - __main__ - Step 50 Global step 50 Train loss 1.40 on epoch=24
06/24/2022 10:23:43 - INFO - __main__ - Global step 50 Train loss 3.33 ACC 0.5 on epoch=24
06/24/2022 10:23:43 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 10:23:45 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=29
06/24/2022 10:23:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.72 on epoch=34
06/24/2022 10:23:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.59 on epoch=39
06/24/2022 10:23:49 - INFO - __main__ - Step 90 Global step 90 Train loss 0.47 on epoch=44
06/24/2022 10:23:50 - INFO - __main__ - Step 100 Global step 100 Train loss 0.44 on epoch=49
06/24/2022 10:23:50 - INFO - __main__ - Global step 100 Train loss 0.62 ACC 0.5 on epoch=49
06/24/2022 10:23:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=54
06/24/2022 10:23:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.49 on epoch=59
06/24/2022 10:23:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/24/2022 10:23:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.34 on epoch=69
06/24/2022 10:23:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.38 on epoch=74
06/24/2022 10:23:57 - INFO - __main__ - Global step 150 Train loss 0.38 ACC 0.5 on epoch=74
06/24/2022 10:23:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.39 on epoch=79
06/24/2022 10:24:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/24/2022 10:24:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=89
06/24/2022 10:24:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.30 on epoch=94
06/24/2022 10:24:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=99
06/24/2022 10:24:04 - INFO - __main__ - Global step 200 Train loss 0.35 ACC 0.5 on epoch=99
06/24/2022 10:24:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.30 on epoch=104
06/24/2022 10:24:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=109
06/24/2022 10:24:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.31 on epoch=114
06/24/2022 10:24:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=119
06/24/2022 10:24:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=124
06/24/2022 10:24:11 - INFO - __main__ - Global step 250 Train loss 0.33 ACC 0.5 on epoch=124
06/24/2022 10:24:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=129
06/24/2022 10:24:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=134
06/24/2022 10:24:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=139
06/24/2022 10:24:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=144
06/24/2022 10:24:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=149
06/24/2022 10:24:18 - INFO - __main__ - Global step 300 Train loss 0.30 ACC 0.5 on epoch=149
06/24/2022 10:24:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 10:24:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=159
06/24/2022 10:24:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=164
06/24/2022 10:24:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=169
06/24/2022 10:24:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=174
06/24/2022 10:24:25 - INFO - __main__ - Global step 350 Train loss 0.22 ACC 0.53125 on epoch=174
06/24/2022 10:24:25 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/24/2022 10:24:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=179
06/24/2022 10:24:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=184
06/24/2022 10:24:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=189
06/24/2022 10:24:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=194
06/24/2022 10:24:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=199
06/24/2022 10:24:32 - INFO - __main__ - Global step 400 Train loss 0.19 ACC 0.59375 on epoch=199
06/24/2022 10:24:32 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=199, global_step=400
06/24/2022 10:24:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=204
06/24/2022 10:24:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=209
06/24/2022 10:24:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=214
06/24/2022 10:24:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=219
06/24/2022 10:24:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=224
06/24/2022 10:24:39 - INFO - __main__ - Global step 450 Train loss 0.14 ACC 0.625 on epoch=224
06/24/2022 10:24:40 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=224, global_step=450
06/24/2022 10:24:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=229
06/24/2022 10:24:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
06/24/2022 10:24:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=239
06/24/2022 10:24:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
06/24/2022 10:24:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=249
06/24/2022 10:24:47 - INFO - __main__ - Global step 500 Train loss 0.09 ACC 0.5 on epoch=249
06/24/2022 10:24:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.09 on epoch=254
06/24/2022 10:24:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=259
06/24/2022 10:24:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.08 on epoch=264
06/24/2022 10:24:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=269
06/24/2022 10:24:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=274
06/24/2022 10:24:54 - INFO - __main__ - Global step 550 Train loss 0.09 ACC 0.59375 on epoch=274
06/24/2022 10:24:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
06/24/2022 10:24:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=284
06/24/2022 10:24:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=289
06/24/2022 10:24:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=294
06/24/2022 10:25:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=299
06/24/2022 10:25:01 - INFO - __main__ - Global step 600 Train loss 0.05 ACC 0.625 on epoch=299
06/24/2022 10:25:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/24/2022 10:25:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
06/24/2022 10:25:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
06/24/2022 10:25:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
06/24/2022 10:25:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/24/2022 10:25:08 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.625 on epoch=324
06/24/2022 10:25:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=329
06/24/2022 10:25:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=334
06/24/2022 10:25:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=339
06/24/2022 10:25:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
06/24/2022 10:25:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
06/24/2022 10:25:15 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.53125 on epoch=349
06/24/2022 10:25:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=354
06/24/2022 10:25:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
06/24/2022 10:25:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
06/24/2022 10:25:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=369
06/24/2022 10:25:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
06/24/2022 10:25:22 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5 on epoch=374
06/24/2022 10:25:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/24/2022 10:25:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=384
06/24/2022 10:25:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/24/2022 10:25:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/24/2022 10:25:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/24/2022 10:25:29 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.625 on epoch=399
06/24/2022 10:25:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
06/24/2022 10:25:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/24/2022 10:25:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
06/24/2022 10:25:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/24/2022 10:25:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=424
06/24/2022 10:25:36 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.5 on epoch=424
06/24/2022 10:25:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=429
06/24/2022 10:25:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/24/2022 10:25:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/24/2022 10:25:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=444
06/24/2022 10:25:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/24/2022 10:25:43 - INFO - __main__ - Global step 900 Train loss 0.02 ACC 0.6875 on epoch=449
06/24/2022 10:25:43 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=449, global_step=900
06/24/2022 10:25:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/24/2022 10:25:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=459
06/24/2022 10:25:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 10:25:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 10:25:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/24/2022 10:25:50 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.59375 on epoch=474
06/24/2022 10:25:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/24/2022 10:25:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/24/2022 10:25:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=489
06/24/2022 10:25:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=494
06/24/2022 10:25:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 10:25:57 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.625 on epoch=499
06/24/2022 10:25:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 10:26:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/24/2022 10:26:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 10:26:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/24/2022 10:26:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=524
06/24/2022 10:26:04 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.5625 on epoch=524
06/24/2022 10:26:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/24/2022 10:26:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/24/2022 10:26:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/24/2022 10:26:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=544
06/24/2022 10:26:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 10:26:11 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5625 on epoch=549
06/24/2022 10:26:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/24/2022 10:26:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 10:26:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 10:26:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 10:26:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/24/2022 10:26:18 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.6875 on epoch=574
06/24/2022 10:26:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 10:26:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 10:26:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 10:26:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/24/2022 10:26:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 10:26:26 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.59375 on epoch=599
06/24/2022 10:26:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 10:26:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 10:26:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/24/2022 10:26:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 10:26:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 10:26:33 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.6875 on epoch=624
06/24/2022 10:26:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 10:26:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 10:26:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 10:26:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 10:26:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 10:26:40 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.625 on epoch=649
06/24/2022 10:26:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 10:26:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 10:26:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=664
06/24/2022 10:26:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 10:26:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 10:26:47 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.625 on epoch=674
06/24/2022 10:26:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 10:26:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 10:26:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 10:26:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 10:26:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 10:26:54 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.6875 on epoch=699
06/24/2022 10:26:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 10:26:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 10:26:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 10:26:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=719
06/24/2022 10:27:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 10:27:01 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.65625 on epoch=724
06/24/2022 10:27:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 10:27:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 10:27:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 10:27:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 10:27:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 10:27:08 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.65625 on epoch=749
06/24/2022 10:27:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 10:27:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 10:27:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 10:27:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 10:27:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 10:27:15 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.65625 on epoch=774
06/24/2022 10:27:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 10:27:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 10:27:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 10:27:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 10:27:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 10:27:22 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.6875 on epoch=799
06/24/2022 10:27:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 10:27:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 10:27:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 10:27:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 10:27:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/24/2022 10:27:29 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.625 on epoch=824
06/24/2022 10:27:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 10:27:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 10:27:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 10:27:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 10:27:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 10:27:36 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.6875 on epoch=849
06/24/2022 10:27:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 10:27:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 10:27:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 10:27:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 10:27:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 10:27:42 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.6875 on epoch=874
06/24/2022 10:27:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 10:27:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 10:27:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 10:27:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 10:27:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 10:27:49 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.65625 on epoch=899
06/24/2022 10:27:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 10:27:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 10:27:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 10:27:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 10:27:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 10:27:56 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.6875 on epoch=924
06/24/2022 10:27:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 10:27:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 10:28:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 10:28:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 10:28:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 10:28:03 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.65625 on epoch=949
06/24/2022 10:28:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 10:28:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 10:28:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 10:28:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 10:28:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=974
06/24/2022 10:28:09 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.6875 on epoch=974
06/24/2022 10:28:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 10:28:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 10:28:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 10:28:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 10:28:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 10:28:16 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.6875 on epoch=999
06/24/2022 10:28:16 - INFO - __main__ - save last model!
06/24/2022 10:28:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 10:28:16 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 10:28:16 - INFO - __main__ - Printing 3 examples
06/24/2022 10:28:16 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 10:28:16 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:28:16 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 10:28:16 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:28:16 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 10:28:16 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:28:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:28:16 - INFO - __main__ - Printing 3 examples
06/24/2022 10:28:16 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:28:16 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:16 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:28:16 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:16 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:28:16 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:28:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:28:17 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:28:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:28:17 - INFO - __main__ - Printing 3 examples
06/24/2022 10:28:17 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:28:17 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:17 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:28:17 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:17 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:28:17 - INFO - __main__ - ['duplicate']
06/24/2022 10:28:17 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:28:17 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:28:17 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:28:23 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 10:28:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:28:23 - INFO - __main__ - Starting training!
06/24/2022 10:28:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:29:16 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 10:42:57 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.4_8_predictions.txt
06/24/2022 10:42:57 - INFO - __main__ - ACC on test data: 0.5876
06/24/2022 10:42:57 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.4, bsz=8, dev_performance=0.6875, test_performance=0.5875587435072965
06/24/2022 10:42:57 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.3, bsz=8 ...
06/24/2022 10:42:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:42:58 - INFO - __main__ - Printing 3 examples
06/24/2022 10:42:58 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:42:58 - INFO - __main__ - ['duplicate']
06/24/2022 10:42:58 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:42:58 - INFO - __main__ - ['duplicate']
06/24/2022 10:42:58 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:42:58 - INFO - __main__ - ['duplicate']
06/24/2022 10:42:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:42:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:42:58 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:42:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:42:58 - INFO - __main__ - Printing 3 examples
06/24/2022 10:42:58 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:42:58 - INFO - __main__ - ['duplicate']
06/24/2022 10:42:58 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:42:58 - INFO - __main__ - ['duplicate']
06/24/2022 10:42:58 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:42:58 - INFO - __main__ - ['duplicate']
06/24/2022 10:42:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:42:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:42:58 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:43:04 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 10:43:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:43:04 - INFO - __main__ - Starting training!
06/24/2022 10:43:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.35 on epoch=4
06/24/2022 10:43:07 - INFO - __main__ - Step 20 Global step 20 Train loss 4.90 on epoch=9
06/24/2022 10:43:09 - INFO - __main__ - Step 30 Global step 30 Train loss 3.72 on epoch=14
06/24/2022 10:43:10 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=19
06/24/2022 10:43:11 - INFO - __main__ - Step 50 Global step 50 Train loss 2.26 on epoch=24
06/24/2022 10:43:12 - INFO - __main__ - Global step 50 Train loss 4.02 ACC 0.0 on epoch=24
06/24/2022 10:43:12 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 10:43:13 - INFO - __main__ - Step 60 Global step 60 Train loss 1.67 on epoch=29
06/24/2022 10:43:14 - INFO - __main__ - Step 70 Global step 70 Train loss 1.27 on epoch=34
06/24/2022 10:43:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=39
06/24/2022 10:43:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=44
06/24/2022 10:43:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=49
06/24/2022 10:43:19 - INFO - __main__ - Global step 100 Train loss 1.06 ACC 0.5 on epoch=49
06/24/2022 10:43:19 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 10:43:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=54
06/24/2022 10:43:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=59
06/24/2022 10:43:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.45 on epoch=64
06/24/2022 10:43:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.41 on epoch=69
06/24/2022 10:43:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.41 on epoch=74
06/24/2022 10:43:26 - INFO - __main__ - Global step 150 Train loss 0.45 ACC 0.5 on epoch=74
06/24/2022 10:43:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.35 on epoch=79
06/24/2022 10:43:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=84
06/24/2022 10:43:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=89
06/24/2022 10:43:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.41 on epoch=94
06/24/2022 10:43:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=99
06/24/2022 10:43:33 - INFO - __main__ - Global step 200 Train loss 0.39 ACC 0.5 on epoch=99
06/24/2022 10:43:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=104
06/24/2022 10:43:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=109
06/24/2022 10:43:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=114
06/24/2022 10:43:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=119
06/24/2022 10:43:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/24/2022 10:43:40 - INFO - __main__ - Global step 250 Train loss 0.33 ACC 0.5 on epoch=124
06/24/2022 10:43:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/24/2022 10:43:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.30 on epoch=134
06/24/2022 10:43:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=139
06/24/2022 10:43:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=144
06/24/2022 10:43:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=149
06/24/2022 10:43:47 - INFO - __main__ - Global step 300 Train loss 0.31 ACC 0.5 on epoch=149
06/24/2022 10:43:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/24/2022 10:43:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=159
06/24/2022 10:43:51 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=164
06/24/2022 10:43:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=169
06/24/2022 10:43:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=174
06/24/2022 10:43:54 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.5 on epoch=174
06/24/2022 10:43:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 10:43:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=184
06/24/2022 10:43:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=189
06/24/2022 10:43:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=194
06/24/2022 10:44:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=199
06/24/2022 10:44:01 - INFO - __main__ - Global step 400 Train loss 0.29 ACC 0.53125 on epoch=199
06/24/2022 10:44:01 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=199, global_step=400
06/24/2022 10:44:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/24/2022 10:44:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/24/2022 10:44:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=214
06/24/2022 10:44:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=219
06/24/2022 10:44:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/24/2022 10:44:08 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.5 on epoch=224
06/24/2022 10:44:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 10:44:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=234
06/24/2022 10:44:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=239
06/24/2022 10:44:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=244
06/24/2022 10:44:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=249
06/24/2022 10:44:15 - INFO - __main__ - Global step 500 Train loss 0.22 ACC 0.625 on epoch=249
06/24/2022 10:44:15 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=249, global_step=500
06/24/2022 10:44:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/24/2022 10:44:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=259
06/24/2022 10:44:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=264
06/24/2022 10:44:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=269
06/24/2022 10:44:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=274
06/24/2022 10:44:22 - INFO - __main__ - Global step 550 Train loss 0.18 ACC 0.65625 on epoch=274
06/24/2022 10:44:22 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=274, global_step=550
06/24/2022 10:44:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=279
06/24/2022 10:44:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=284
06/24/2022 10:44:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=289
06/24/2022 10:44:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=294
06/24/2022 10:44:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=299
06/24/2022 10:44:29 - INFO - __main__ - Global step 600 Train loss 0.16 ACC 0.625 on epoch=299
06/24/2022 10:44:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=304
06/24/2022 10:44:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=309
06/24/2022 10:44:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=314
06/24/2022 10:44:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=319
06/24/2022 10:44:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=324
06/24/2022 10:44:36 - INFO - __main__ - Global step 650 Train loss 0.10 ACC 0.59375 on epoch=324
06/24/2022 10:44:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=329
06/24/2022 10:44:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=334
06/24/2022 10:44:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=339
06/24/2022 10:44:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=344
06/24/2022 10:44:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=349
06/24/2022 10:44:43 - INFO - __main__ - Global step 700 Train loss 0.09 ACC 0.625 on epoch=349
06/24/2022 10:44:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=354
06/24/2022 10:44:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/24/2022 10:44:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=364
06/24/2022 10:44:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
06/24/2022 10:44:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=374
06/24/2022 10:44:50 - INFO - __main__ - Global step 750 Train loss 0.08 ACC 0.625 on epoch=374
06/24/2022 10:44:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
06/24/2022 10:44:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
06/24/2022 10:44:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=389
06/24/2022 10:44:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=394
06/24/2022 10:44:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=399
06/24/2022 10:44:56 - INFO - __main__ - Global step 800 Train loss 0.06 ACC 0.6875 on epoch=399
06/24/2022 10:44:56 - INFO - __main__ - Saving model with best ACC: 0.65625 -> 0.6875 on epoch=399, global_step=800
06/24/2022 10:44:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=404
06/24/2022 10:44:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=409
06/24/2022 10:45:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/24/2022 10:45:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/24/2022 10:45:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
06/24/2022 10:45:03 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.6875 on epoch=424
06/24/2022 10:45:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=429
06/24/2022 10:45:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=434
06/24/2022 10:45:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=439
06/24/2022 10:45:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/24/2022 10:45:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/24/2022 10:45:10 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.71875 on epoch=449
06/24/2022 10:45:10 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=449, global_step=900
06/24/2022 10:45:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/24/2022 10:45:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
06/24/2022 10:45:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
06/24/2022 10:45:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=469
06/24/2022 10:45:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
06/24/2022 10:45:17 - INFO - __main__ - Global step 950 Train loss 0.03 ACC 0.71875 on epoch=474
06/24/2022 10:45:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/24/2022 10:45:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=484
06/24/2022 10:45:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/24/2022 10:45:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/24/2022 10:45:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/24/2022 10:45:24 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.59375 on epoch=499
06/24/2022 10:45:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
06/24/2022 10:45:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/24/2022 10:45:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 10:45:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/24/2022 10:45:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/24/2022 10:45:31 - INFO - __main__ - Global step 1050 Train loss 0.02 ACC 0.71875 on epoch=524
06/24/2022 10:45:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=529
06/24/2022 10:45:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
06/24/2022 10:45:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/24/2022 10:45:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
06/24/2022 10:45:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/24/2022 10:45:38 - INFO - __main__ - Global step 1100 Train loss 0.03 ACC 0.65625 on epoch=549
06/24/2022 10:45:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
06/24/2022 10:45:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/24/2022 10:45:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
06/24/2022 10:45:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/24/2022 10:45:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 10:45:45 - INFO - __main__ - Global step 1150 Train loss 0.02 ACC 0.65625 on epoch=574
06/24/2022 10:45:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 10:45:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 10:45:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 10:45:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 10:45:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/24/2022 10:45:52 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.65625 on epoch=599
06/24/2022 10:45:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 10:45:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 10:45:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 10:45:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 10:45:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
06/24/2022 10:45:58 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/24/2022 10:46:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 10:46:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/24/2022 10:46:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 10:46:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/24/2022 10:46:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 10:46:05 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.71875 on epoch=649
06/24/2022 10:46:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 10:46:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 10:46:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 10:46:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 10:46:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 10:46:12 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.6875 on epoch=674
06/24/2022 10:46:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 10:46:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 10:46:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 10:46:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 10:46:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 10:46:19 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.71875 on epoch=699
06/24/2022 10:46:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 10:46:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 10:46:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/24/2022 10:46:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/24/2022 10:46:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 10:46:26 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.65625 on epoch=724
06/24/2022 10:46:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 10:46:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=734
06/24/2022 10:46:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 10:46:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/24/2022 10:46:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 10:46:33 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.71875 on epoch=749
06/24/2022 10:46:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 10:46:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 10:46:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/24/2022 10:46:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 10:46:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 10:46:40 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.71875 on epoch=774
06/24/2022 10:46:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
06/24/2022 10:46:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 10:46:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 10:46:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 10:46:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 10:46:47 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.71875 on epoch=799
06/24/2022 10:46:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 10:46:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/24/2022 10:46:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 10:46:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 10:46:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/24/2022 10:46:54 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.65625 on epoch=824
06/24/2022 10:46:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/24/2022 10:46:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 10:46:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 10:46:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 10:47:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/24/2022 10:47:01 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.6875 on epoch=849
06/24/2022 10:47:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=854
06/24/2022 10:47:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 10:47:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 10:47:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 10:47:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 10:47:08 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.59375 on epoch=874
06/24/2022 10:47:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 10:47:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 10:47:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 10:47:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=894
06/24/2022 10:47:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 10:47:15 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.625 on epoch=899
06/24/2022 10:47:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 10:47:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 10:47:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 10:47:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 10:47:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 10:47:21 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.59375 on epoch=924
06/24/2022 10:47:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 10:47:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 10:47:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 10:47:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 10:47:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 10:47:28 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.65625 on epoch=949
06/24/2022 10:47:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=954
06/24/2022 10:47:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 10:47:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 10:47:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 10:47:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 10:47:35 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.6875 on epoch=974
06/24/2022 10:47:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 10:47:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 10:47:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/24/2022 10:47:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 10:47:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 10:47:42 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.6875 on epoch=999
06/24/2022 10:47:42 - INFO - __main__ - save last model!
06/24/2022 10:47:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 10:47:42 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 10:47:42 - INFO - __main__ - Printing 3 examples
06/24/2022 10:47:42 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 10:47:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:47:42 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 10:47:42 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:47:42 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 10:47:42 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:42 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:47:43 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:47:43 - INFO - __main__ - Printing 3 examples
06/24/2022 10:47:43 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:47:43 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:43 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:47:43 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:43 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:47:43 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:43 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:47:43 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:47:43 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:47:43 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:47:43 - INFO - __main__ - Printing 3 examples
06/24/2022 10:47:43 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:47:43 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:43 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:47:43 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:43 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:47:43 - INFO - __main__ - ['duplicate']
06/24/2022 10:47:43 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:47:43 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:47:43 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:47:48 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 10:47:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:47:49 - INFO - __main__ - Starting training!
06/24/2022 10:48:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:48:47 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:01:48 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.3_8_predictions.txt
06/24/2022 11:01:49 - INFO - __main__ - ACC on test data: 0.5545
06/24/2022 11:01:49 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.3, bsz=8, dev_performance=0.71875, test_performance=0.5544892406628741
06/24/2022 11:01:49 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.2, bsz=8 ...
06/24/2022 11:01:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:01:50 - INFO - __main__ - Printing 3 examples
06/24/2022 11:01:50 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 11:01:50 - INFO - __main__ - ['duplicate']
06/24/2022 11:01:50 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 11:01:50 - INFO - __main__ - ['duplicate']
06/24/2022 11:01:50 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 11:01:50 - INFO - __main__ - ['duplicate']
06/24/2022 11:01:50 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:01:50 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:01:50 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:01:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:01:50 - INFO - __main__ - Printing 3 examples
06/24/2022 11:01:50 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 11:01:50 - INFO - __main__ - ['duplicate']
06/24/2022 11:01:50 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 11:01:50 - INFO - __main__ - ['duplicate']
06/24/2022 11:01:50 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 11:01:50 - INFO - __main__ - ['duplicate']
06/24/2022 11:01:50 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:01:50 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:01:50 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:01:55 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:01:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:01:55 - INFO - __main__ - Starting training!
06/24/2022 11:01:57 - INFO - __main__ - Step 10 Global step 10 Train loss 6.45 on epoch=4
06/24/2022 11:01:58 - INFO - __main__ - Step 20 Global step 20 Train loss 5.22 on epoch=9
06/24/2022 11:01:59 - INFO - __main__ - Step 30 Global step 30 Train loss 4.43 on epoch=14
06/24/2022 11:02:00 - INFO - __main__ - Step 40 Global step 40 Train loss 3.90 on epoch=19
06/24/2022 11:02:02 - INFO - __main__ - Step 50 Global step 50 Train loss 3.16 on epoch=24
06/24/2022 11:02:02 - INFO - __main__ - Global step 50 Train loss 4.63 ACC 0.0 on epoch=24
06/24/2022 11:02:02 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 11:02:04 - INFO - __main__ - Step 60 Global step 60 Train loss 2.72 on epoch=29
06/24/2022 11:02:05 - INFO - __main__ - Step 70 Global step 70 Train loss 2.16 on epoch=34
06/24/2022 11:02:06 - INFO - __main__ - Step 80 Global step 80 Train loss 1.90 on epoch=39
06/24/2022 11:02:07 - INFO - __main__ - Step 90 Global step 90 Train loss 1.51 on epoch=44
06/24/2022 11:02:08 - INFO - __main__ - Step 100 Global step 100 Train loss 1.27 on epoch=49
06/24/2022 11:02:09 - INFO - __main__ - Global step 100 Train loss 1.91 ACC 0.5 on epoch=49
06/24/2022 11:02:09 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 11:02:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=54
06/24/2022 11:02:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=59
06/24/2022 11:02:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=64
06/24/2022 11:02:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=69
06/24/2022 11:02:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=74
06/24/2022 11:02:15 - INFO - __main__ - Global step 150 Train loss 0.78 ACC 0.5 on epoch=74
06/24/2022 11:02:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=79
06/24/2022 11:02:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=84
06/24/2022 11:02:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=89
06/24/2022 11:02:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=94
06/24/2022 11:02:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.54 on epoch=99
06/24/2022 11:02:22 - INFO - __main__ - Global step 200 Train loss 0.51 ACC 0.5 on epoch=99
06/24/2022 11:02:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.45 on epoch=104
06/24/2022 11:02:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=109
06/24/2022 11:02:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=114
06/24/2022 11:02:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=119
06/24/2022 11:02:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/24/2022 11:02:29 - INFO - __main__ - Global step 250 Train loss 0.39 ACC 0.5 on epoch=124
06/24/2022 11:02:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/24/2022 11:02:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=134
06/24/2022 11:02:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=139
06/24/2022 11:02:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=144
06/24/2022 11:02:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=149
06/24/2022 11:02:35 - INFO - __main__ - Global step 300 Train loss 0.36 ACC 0.5 on epoch=149
06/24/2022 11:02:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/24/2022 11:02:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=159
06/24/2022 11:02:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=164
06/24/2022 11:02:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=169
06/24/2022 11:02:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=174
06/24/2022 11:02:42 - INFO - __main__ - Global step 350 Train loss 0.32 ACC 0.5 on epoch=174
06/24/2022 11:02:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=179
06/24/2022 11:02:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=184
06/24/2022 11:02:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=189
06/24/2022 11:02:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=194
06/24/2022 11:02:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/24/2022 11:02:49 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/24/2022 11:02:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=204
06/24/2022 11:02:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=209
06/24/2022 11:02:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=214
06/24/2022 11:02:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=219
06/24/2022 11:02:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=224
06/24/2022 11:02:55 - INFO - __main__ - Global step 450 Train loss 0.29 ACC 0.5 on epoch=224
06/24/2022 11:02:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=229
06/24/2022 11:02:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=234
06/24/2022 11:02:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=239
06/24/2022 11:03:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=244
06/24/2022 11:03:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=249
06/24/2022 11:03:02 - INFO - __main__ - Global step 500 Train loss 0.28 ACC 0.5 on epoch=249
06/24/2022 11:03:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=254
06/24/2022 11:03:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=259
06/24/2022 11:03:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=264
06/24/2022 11:03:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=269
06/24/2022 11:03:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=274
06/24/2022 11:03:08 - INFO - __main__ - Global step 550 Train loss 0.30 ACC 0.5 on epoch=274
06/24/2022 11:03:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=279
06/24/2022 11:03:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=284
06/24/2022 11:03:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=289
06/24/2022 11:03:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=294
06/24/2022 11:03:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=299
06/24/2022 11:03:15 - INFO - __main__ - Global step 600 Train loss 0.28 ACC 0.53125 on epoch=299
06/24/2022 11:03:15 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=299, global_step=600
06/24/2022 11:03:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=304
06/24/2022 11:03:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/24/2022 11:03:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=314
06/24/2022 11:03:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=319
06/24/2022 11:03:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=324
06/24/2022 11:03:22 - INFO - __main__ - Global step 650 Train loss 0.25 ACC 0.53125 on epoch=324
06/24/2022 11:03:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=329
06/24/2022 11:03:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/24/2022 11:03:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=339
06/24/2022 11:03:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=344
06/24/2022 11:03:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=349
06/24/2022 11:03:28 - INFO - __main__ - Global step 700 Train loss 0.24 ACC 0.5625 on epoch=349
06/24/2022 11:03:28 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=349, global_step=700
06/24/2022 11:03:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=354
06/24/2022 11:03:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=359
06/24/2022 11:03:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=364
06/24/2022 11:03:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=369
06/24/2022 11:03:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=374
06/24/2022 11:03:35 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.53125 on epoch=374
06/24/2022 11:03:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=379
06/24/2022 11:03:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=384
06/24/2022 11:03:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/24/2022 11:03:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=394
06/24/2022 11:03:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=399
06/24/2022 11:03:41 - INFO - __main__ - Global step 800 Train loss 0.22 ACC 0.625 on epoch=399
06/24/2022 11:03:41 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=399, global_step=800
06/24/2022 11:03:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=404
06/24/2022 11:03:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=409
06/24/2022 11:03:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=414
06/24/2022 11:03:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=419
06/24/2022 11:03:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=424
06/24/2022 11:03:48 - INFO - __main__ - Global step 850 Train loss 0.20 ACC 0.625 on epoch=424
06/24/2022 11:03:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=429
06/24/2022 11:03:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=434
06/24/2022 11:03:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/24/2022 11:03:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=444
06/24/2022 11:03:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=449
06/24/2022 11:03:55 - INFO - __main__ - Global step 900 Train loss 0.16 ACC 0.6875 on epoch=449
06/24/2022 11:03:55 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.6875 on epoch=449, global_step=900
06/24/2022 11:03:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=454
06/24/2022 11:03:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=459
06/24/2022 11:03:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=464
06/24/2022 11:03:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=469
06/24/2022 11:04:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=474
06/24/2022 11:04:01 - INFO - __main__ - Global step 950 Train loss 0.12 ACC 0.6875 on epoch=474
06/24/2022 11:04:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=479
06/24/2022 11:04:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=484
06/24/2022 11:04:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=489
06/24/2022 11:04:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=494
06/24/2022 11:04:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=499
06/24/2022 11:04:08 - INFO - __main__ - Global step 1000 Train loss 0.10 ACC 0.625 on epoch=499
06/24/2022 11:04:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=504
06/24/2022 11:04:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=509
06/24/2022 11:04:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=514
06/24/2022 11:04:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=519
06/24/2022 11:04:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=524
06/24/2022 11:04:14 - INFO - __main__ - Global step 1050 Train loss 0.08 ACC 0.71875 on epoch=524
06/24/2022 11:04:14 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=524, global_step=1050
06/24/2022 11:04:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
06/24/2022 11:04:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=534
06/24/2022 11:04:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/24/2022 11:04:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
06/24/2022 11:04:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=549
06/24/2022 11:04:21 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.71875 on epoch=549
06/24/2022 11:04:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
06/24/2022 11:04:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=559
06/24/2022 11:04:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=564
06/24/2022 11:04:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/24/2022 11:04:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=574
06/24/2022 11:04:28 - INFO - __main__ - Global step 1150 Train loss 0.05 ACC 0.6875 on epoch=574
06/24/2022 11:04:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=579
06/24/2022 11:04:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=584
06/24/2022 11:04:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=589
06/24/2022 11:04:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
06/24/2022 11:04:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
06/24/2022 11:04:34 - INFO - __main__ - Global step 1200 Train loss 0.05 ACC 0.65625 on epoch=599
06/24/2022 11:04:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 11:04:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/24/2022 11:04:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=614
06/24/2022 11:04:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 11:04:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=624
06/24/2022 11:04:41 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.625 on epoch=624
06/24/2022 11:04:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=629
06/24/2022 11:04:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/24/2022 11:04:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 11:04:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
06/24/2022 11:04:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 11:04:48 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.65625 on epoch=649
06/24/2022 11:04:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=654
06/24/2022 11:04:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
06/24/2022 11:04:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/24/2022 11:04:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/24/2022 11:04:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 11:04:55 - INFO - __main__ - Global step 1350 Train loss 0.03 ACC 0.65625 on epoch=674
06/24/2022 11:04:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=679
06/24/2022 11:04:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=684
06/24/2022 11:04:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/24/2022 11:05:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/24/2022 11:05:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 11:05:02 - INFO - __main__ - Global step 1400 Train loss 0.03 ACC 0.71875 on epoch=699
06/24/2022 11:05:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=704
06/24/2022 11:05:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=709
06/24/2022 11:05:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=714
06/24/2022 11:05:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/24/2022 11:05:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/24/2022 11:05:09 - INFO - __main__ - Global step 1450 Train loss 0.03 ACC 0.59375 on epoch=724
06/24/2022 11:05:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 11:05:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 11:05:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=739
06/24/2022 11:05:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/24/2022 11:05:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=749
06/24/2022 11:05:16 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.59375 on epoch=749
06/24/2022 11:05:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/24/2022 11:05:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
06/24/2022 11:05:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 11:05:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/24/2022 11:05:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 11:05:23 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.65625 on epoch=774
06/24/2022 11:05:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
06/24/2022 11:05:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/24/2022 11:05:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 11:05:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
06/24/2022 11:05:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 11:05:30 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.6875 on epoch=799
06/24/2022 11:05:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
06/24/2022 11:05:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=809
06/24/2022 11:05:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=814
06/24/2022 11:05:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 11:05:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=824
06/24/2022 11:05:37 - INFO - __main__ - Global step 1650 Train loss 0.03 ACC 0.625 on epoch=824
06/24/2022 11:05:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=829
06/24/2022 11:05:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 11:05:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=839
06/24/2022 11:05:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/24/2022 11:05:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/24/2022 11:05:44 - INFO - __main__ - Global step 1700 Train loss 0.03 ACC 0.625 on epoch=849
06/24/2022 11:05:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=854
06/24/2022 11:05:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 11:05:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 11:05:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 11:05:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 11:05:51 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.53125 on epoch=874
06/24/2022 11:05:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/24/2022 11:05:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 11:05:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 11:05:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 11:05:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
06/24/2022 11:05:58 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.59375 on epoch=899
06/24/2022 11:06:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 11:06:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/24/2022 11:06:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 11:06:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=919
06/24/2022 11:06:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/24/2022 11:06:05 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.5625 on epoch=924
06/24/2022 11:06:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 11:06:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/24/2022 11:06:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 11:06:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 11:06:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
06/24/2022 11:06:12 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.625 on epoch=949
06/24/2022 11:06:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 11:06:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/24/2022 11:06:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 11:06:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 11:06:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 11:06:19 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
06/24/2022 11:06:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/24/2022 11:06:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
06/24/2022 11:06:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 11:06:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 11:06:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 11:06:26 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.5625 on epoch=999
06/24/2022 11:06:26 - INFO - __main__ - save last model!
06/24/2022 11:06:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 11:06:27 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 11:06:27 - INFO - __main__ - Printing 3 examples
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 11:06:27 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 11:06:27 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:06:27 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:06:27 - INFO - __main__ - Printing 3 examples
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:06:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:06:27 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:06:27 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:06:27 - INFO - __main__ - Printing 3 examples
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:06:27 - INFO - __main__ - ['duplicate']
06/24/2022 11:06:27 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:06:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:06:27 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:06:33 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:06:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:06:33 - INFO - __main__ - Starting training!
06/24/2022 11:06:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:07:26 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:20:31 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_42_0.2_8_predictions.txt
06/24/2022 11:20:31 - INFO - __main__ - ACC on test data: 0.5307
06/24/2022 11:20:31 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.2, bsz=8, dev_performance=0.71875, test_performance=0.5307197625525599
06/24/2022 11:20:31 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.5, bsz=8 ...
06/24/2022 11:20:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:20:32 - INFO - __main__ - Printing 3 examples
06/24/2022 11:20:32 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:20:32 - INFO - __main__ - ['duplicate']
06/24/2022 11:20:32 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:20:32 - INFO - __main__ - ['duplicate']
06/24/2022 11:20:32 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:20:32 - INFO - __main__ - ['duplicate']
06/24/2022 11:20:32 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:20:32 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:20:32 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:20:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:20:32 - INFO - __main__ - Printing 3 examples
06/24/2022 11:20:32 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:20:32 - INFO - __main__ - ['duplicate']
06/24/2022 11:20:32 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:20:32 - INFO - __main__ - ['duplicate']
06/24/2022 11:20:32 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:20:32 - INFO - __main__ - ['duplicate']
06/24/2022 11:20:32 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:20:32 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:20:32 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:20:37 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:20:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:20:38 - INFO - __main__ - Starting training!
06/24/2022 11:20:39 - INFO - __main__ - Step 10 Global step 10 Train loss 5.69 on epoch=4
06/24/2022 11:20:40 - INFO - __main__ - Step 20 Global step 20 Train loss 3.76 on epoch=9
06/24/2022 11:20:42 - INFO - __main__ - Step 30 Global step 30 Train loss 2.54 on epoch=14
06/24/2022 11:20:43 - INFO - __main__ - Step 40 Global step 40 Train loss 1.54 on epoch=19
06/24/2022 11:20:44 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=24
06/24/2022 11:20:45 - INFO - __main__ - Global step 50 Train loss 2.90 ACC 0.5 on epoch=24
06/24/2022 11:20:45 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 11:20:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.66 on epoch=29
06/24/2022 11:20:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.51 on epoch=34
06/24/2022 11:20:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.46 on epoch=39
06/24/2022 11:20:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.37 on epoch=44
06/24/2022 11:20:51 - INFO - __main__ - Step 100 Global step 100 Train loss 0.34 on epoch=49
06/24/2022 11:20:52 - INFO - __main__ - Global step 100 Train loss 0.47 ACC 0.5 on epoch=49
06/24/2022 11:20:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=54
06/24/2022 11:20:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.37 on epoch=59
06/24/2022 11:20:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
06/24/2022 11:20:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
06/24/2022 11:20:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.35 on epoch=74
06/24/2022 11:20:58 - INFO - __main__ - Global step 150 Train loss 0.35 ACC 0.5 on epoch=74
06/24/2022 11:21:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=79
06/24/2022 11:21:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.33 on epoch=84
06/24/2022 11:21:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=89
06/24/2022 11:21:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.29 on epoch=94
06/24/2022 11:21:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.31 on epoch=99
06/24/2022 11:21:05 - INFO - __main__ - Global step 200 Train loss 0.31 ACC 0.5 on epoch=99
06/24/2022 11:21:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
06/24/2022 11:21:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=109
06/24/2022 11:21:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=114
06/24/2022 11:21:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.21 on epoch=119
06/24/2022 11:21:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=124
06/24/2022 11:21:12 - INFO - __main__ - Global step 250 Train loss 0.23 ACC 0.5 on epoch=124
06/24/2022 11:21:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=129
06/24/2022 11:21:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.18 on epoch=134
06/24/2022 11:21:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=139
06/24/2022 11:21:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=144
06/24/2022 11:21:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.18 on epoch=149
06/24/2022 11:21:19 - INFO - __main__ - Global step 300 Train loss 0.20 ACC 0.59375 on epoch=149
06/24/2022 11:21:19 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.59375 on epoch=149, global_step=300
06/24/2022 11:21:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=154
06/24/2022 11:21:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.17 on epoch=159
06/24/2022 11:21:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.14 on epoch=164
06/24/2022 11:21:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.14 on epoch=169
06/24/2022 11:21:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.15 on epoch=174
06/24/2022 11:21:26 - INFO - __main__ - Global step 350 Train loss 0.16 ACC 0.5625 on epoch=174
06/24/2022 11:21:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.11 on epoch=179
06/24/2022 11:21:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.09 on epoch=184
06/24/2022 11:21:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=189
06/24/2022 11:21:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=194
06/24/2022 11:21:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=199
06/24/2022 11:21:33 - INFO - __main__ - Global step 400 Train loss 0.11 ACC 0.5625 on epoch=199
06/24/2022 11:21:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.07 on epoch=204
06/24/2022 11:21:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.07 on epoch=209
06/24/2022 11:21:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=214
06/24/2022 11:21:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=219
06/24/2022 11:21:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=224
06/24/2022 11:21:40 - INFO - __main__ - Global step 450 Train loss 0.07 ACC 0.5625 on epoch=224
06/24/2022 11:21:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.05 on epoch=229
06/24/2022 11:21:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.06 on epoch=234
06/24/2022 11:21:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=239
06/24/2022 11:21:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=244
06/24/2022 11:21:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=249
06/24/2022 11:21:47 - INFO - __main__ - Global step 500 Train loss 0.05 ACC 0.53125 on epoch=249
06/24/2022 11:21:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=254
06/24/2022 11:21:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=259
06/24/2022 11:21:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=264
06/24/2022 11:21:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=269
06/24/2022 11:21:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=274
06/24/2022 11:21:54 - INFO - __main__ - Global step 550 Train loss 0.03 ACC 0.5625 on epoch=274
06/24/2022 11:21:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=279
06/24/2022 11:21:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=284
06/24/2022 11:21:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=289
06/24/2022 11:21:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=294
06/24/2022 11:22:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=299
06/24/2022 11:22:00 - INFO - __main__ - Global step 600 Train loss 0.03 ACC 0.5625 on epoch=299
06/24/2022 11:22:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=304
06/24/2022 11:22:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=309
06/24/2022 11:22:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=314
06/24/2022 11:22:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=319
06/24/2022 11:22:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/24/2022 11:22:07 - INFO - __main__ - Global step 650 Train loss 0.03 ACC 0.5625 on epoch=324
06/24/2022 11:22:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
06/24/2022 11:22:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
06/24/2022 11:22:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/24/2022 11:22:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=344
06/24/2022 11:22:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=349
06/24/2022 11:22:14 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.5625 on epoch=349
06/24/2022 11:22:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/24/2022 11:22:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/24/2022 11:22:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=364
06/24/2022 11:22:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
06/24/2022 11:22:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=374
06/24/2022 11:22:21 - INFO - __main__ - Global step 750 Train loss 0.02 ACC 0.5625 on epoch=374
06/24/2022 11:22:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=379
06/24/2022 11:22:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=384
06/24/2022 11:22:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=389
06/24/2022 11:22:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=394
06/24/2022 11:22:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=399
06/24/2022 11:22:28 - INFO - __main__ - Global step 800 Train loss 0.01 ACC 0.59375 on epoch=399
06/24/2022 11:22:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/24/2022 11:22:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/24/2022 11:22:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
06/24/2022 11:22:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=419
06/24/2022 11:22:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=424
06/24/2022 11:22:35 - INFO - __main__ - Global step 850 Train loss 0.00 ACC 0.625 on epoch=424
06/24/2022 11:22:35 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=424, global_step=850
06/24/2022 11:22:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 11:22:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=434
06/24/2022 11:22:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=439
06/24/2022 11:22:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/24/2022 11:22:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=449
06/24/2022 11:22:42 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5625 on epoch=449
06/24/2022 11:22:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/24/2022 11:22:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/24/2022 11:22:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 11:22:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 11:22:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/24/2022 11:22:48 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.625 on epoch=474
06/24/2022 11:22:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/24/2022 11:22:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/24/2022 11:22:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
06/24/2022 11:22:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=494
06/24/2022 11:22:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=499
06/24/2022 11:22:55 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.59375 on epoch=499
06/24/2022 11:22:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
06/24/2022 11:22:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=509
06/24/2022 11:22:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=514
06/24/2022 11:23:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/24/2022 11:23:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/24/2022 11:23:02 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.59375 on epoch=524
06/24/2022 11:23:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/24/2022 11:23:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/24/2022 11:23:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/24/2022 11:23:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/24/2022 11:23:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 11:23:09 - INFO - __main__ - Global step 1100 Train loss 0.00 ACC 0.625 on epoch=549
06/24/2022 11:23:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/24/2022 11:23:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/24/2022 11:23:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 11:23:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 11:23:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
06/24/2022 11:23:16 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.625 on epoch=574
06/24/2022 11:23:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 11:23:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 11:23:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 11:23:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/24/2022 11:23:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 11:23:23 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.59375 on epoch=599
06/24/2022 11:23:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 11:23:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/24/2022 11:23:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/24/2022 11:23:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 11:23:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 11:23:30 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.625 on epoch=624
06/24/2022 11:23:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 11:23:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 11:23:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 11:23:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 11:23:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 11:23:37 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.625 on epoch=649
06/24/2022 11:23:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 11:23:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 11:23:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 11:23:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 11:23:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 11:23:44 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.65625 on epoch=674
06/24/2022 11:23:44 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=674, global_step=1350
06/24/2022 11:23:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 11:23:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 11:23:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 11:23:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 11:23:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 11:23:51 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.59375 on epoch=699
06/24/2022 11:23:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 11:23:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 11:23:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 11:23:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 11:23:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 11:23:58 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.5625 on epoch=724
06/24/2022 11:23:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 11:24:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 11:24:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 11:24:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 11:24:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=749
06/24/2022 11:24:05 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.59375 on epoch=749
06/24/2022 11:24:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 11:24:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 11:24:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 11:24:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 11:24:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 11:24:11 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.625 on epoch=774
06/24/2022 11:24:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 11:24:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 11:24:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 11:24:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 11:24:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 11:24:18 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.59375 on epoch=799
06/24/2022 11:24:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 11:24:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 11:24:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 11:24:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 11:24:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 11:24:25 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.625 on epoch=824
06/24/2022 11:24:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 11:24:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 11:24:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/24/2022 11:24:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 11:24:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 11:24:32 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.625 on epoch=849
06/24/2022 11:24:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 11:24:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 11:24:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 11:24:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 11:24:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 11:24:39 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.59375 on epoch=874
06/24/2022 11:24:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/24/2022 11:24:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 11:24:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 11:24:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 11:24:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 11:24:46 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.5625 on epoch=899
06/24/2022 11:24:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 11:24:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/24/2022 11:24:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 11:24:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 11:24:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 11:24:53 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.625 on epoch=924
06/24/2022 11:24:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 11:24:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 11:24:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 11:24:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 11:25:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 11:25:00 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/24/2022 11:25:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 11:25:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/24/2022 11:25:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 11:25:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 11:25:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 11:25:07 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
06/24/2022 11:25:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 11:25:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 11:25:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 11:25:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 11:25:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 11:25:14 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
06/24/2022 11:25:14 - INFO - __main__ - save last model!
06/24/2022 11:25:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 11:25:14 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 11:25:14 - INFO - __main__ - Printing 3 examples
06/24/2022 11:25:14 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 11:25:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:25:14 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 11:25:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:25:14 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 11:25:14 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:25:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:25:15 - INFO - __main__ - Printing 3 examples
06/24/2022 11:25:15 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:25:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:15 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:25:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:15 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:25:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:25:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:25:15 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:25:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:25:15 - INFO - __main__ - Printing 3 examples
06/24/2022 11:25:15 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:25:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:15 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:25:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:15 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:25:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:25:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:25:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:25:15 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:25:20 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:25:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:25:20 - INFO - __main__ - Starting training!
06/24/2022 11:25:32 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:26:13 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:39:15 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.5_8_predictions.txt
06/24/2022 11:39:15 - INFO - __main__ - ACC on test data: 0.5557
06/24/2022 11:39:15 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.5, bsz=8, dev_performance=0.65625, test_performance=0.5557012119713084
06/24/2022 11:39:15 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.4, bsz=8 ...
06/24/2022 11:39:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:39:16 - INFO - __main__ - Printing 3 examples
06/24/2022 11:39:16 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:39:16 - INFO - __main__ - ['duplicate']
06/24/2022 11:39:16 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:39:16 - INFO - __main__ - ['duplicate']
06/24/2022 11:39:16 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:39:16 - INFO - __main__ - ['duplicate']
06/24/2022 11:39:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:39:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:39:16 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:39:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:39:16 - INFO - __main__ - Printing 3 examples
06/24/2022 11:39:16 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:39:16 - INFO - __main__ - ['duplicate']
06/24/2022 11:39:16 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:39:16 - INFO - __main__ - ['duplicate']
06/24/2022 11:39:16 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:39:16 - INFO - __main__ - ['duplicate']
06/24/2022 11:39:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:39:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:39:16 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:39:22 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:39:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:39:23 - INFO - __main__ - Starting training!
06/24/2022 11:39:24 - INFO - __main__ - Step 10 Global step 10 Train loss 6.29 on epoch=4
06/24/2022 11:39:25 - INFO - __main__ - Step 20 Global step 20 Train loss 4.11 on epoch=9
06/24/2022 11:39:27 - INFO - __main__ - Step 30 Global step 30 Train loss 2.97 on epoch=14
06/24/2022 11:39:28 - INFO - __main__ - Step 40 Global step 40 Train loss 1.91 on epoch=19
06/24/2022 11:39:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.34 on epoch=24
06/24/2022 11:39:30 - INFO - __main__ - Global step 50 Train loss 3.32 ACC 0.5 on epoch=24
06/24/2022 11:39:30 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 11:39:31 - INFO - __main__ - Step 60 Global step 60 Train loss 1.07 on epoch=29
06/24/2022 11:39:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.75 on epoch=34
06/24/2022 11:39:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.58 on epoch=39
06/24/2022 11:39:35 - INFO - __main__ - Step 90 Global step 90 Train loss 0.56 on epoch=44
06/24/2022 11:39:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=49
06/24/2022 11:39:37 - INFO - __main__ - Global step 100 Train loss 0.69 ACC 0.5 on epoch=49
06/24/2022 11:39:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
06/24/2022 11:39:39 - INFO - __main__ - Step 120 Global step 120 Train loss 0.38 on epoch=59
06/24/2022 11:39:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=64
06/24/2022 11:39:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.33 on epoch=69
06/24/2022 11:39:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.46 on epoch=74
06/24/2022 11:39:44 - INFO - __main__ - Global step 150 Train loss 0.37 ACC 0.5 on epoch=74
06/24/2022 11:39:45 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=79
06/24/2022 11:39:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/24/2022 11:39:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.39 on epoch=89
06/24/2022 11:39:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=94
06/24/2022 11:39:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=99
06/24/2022 11:39:50 - INFO - __main__ - Global step 200 Train loss 0.33 ACC 0.5 on epoch=99
06/24/2022 11:39:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=104
06/24/2022 11:39:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=109
06/24/2022 11:39:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=114
06/24/2022 11:39:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=119
06/24/2022 11:39:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=124
06/24/2022 11:39:57 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/24/2022 11:39:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/24/2022 11:40:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/24/2022 11:40:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=139
06/24/2022 11:40:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 11:40:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=149
06/24/2022 11:40:04 - INFO - __main__ - Global step 300 Train loss 0.28 ACC 0.5 on epoch=149
06/24/2022 11:40:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/24/2022 11:40:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=159
06/24/2022 11:40:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/24/2022 11:40:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/24/2022 11:40:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/24/2022 11:40:11 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.53125 on epoch=174
06/24/2022 11:40:11 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/24/2022 11:40:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=179
06/24/2022 11:40:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=184
06/24/2022 11:40:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=189
06/24/2022 11:40:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=194
06/24/2022 11:40:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=199
06/24/2022 11:40:18 - INFO - __main__ - Global step 400 Train loss 0.20 ACC 0.625 on epoch=199
06/24/2022 11:40:18 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=199, global_step=400
06/24/2022 11:40:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=204
06/24/2022 11:40:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=209
06/24/2022 11:40:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=214
06/24/2022 11:40:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=219
06/24/2022 11:40:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=224
06/24/2022 11:40:25 - INFO - __main__ - Global step 450 Train loss 0.15 ACC 0.59375 on epoch=224
06/24/2022 11:40:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=229
06/24/2022 11:40:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=234
06/24/2022 11:40:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=239
06/24/2022 11:40:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=244
06/24/2022 11:40:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.08 on epoch=249
06/24/2022 11:40:32 - INFO - __main__ - Global step 500 Train loss 0.12 ACC 0.59375 on epoch=249
06/24/2022 11:40:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=254
06/24/2022 11:40:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=259
06/24/2022 11:40:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=264
06/24/2022 11:40:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
06/24/2022 11:40:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=274
06/24/2022 11:40:39 - INFO - __main__ - Global step 550 Train loss 0.08 ACC 0.59375 on epoch=274
06/24/2022 11:40:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=279
06/24/2022 11:40:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=284
06/24/2022 11:40:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=289
06/24/2022 11:40:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/24/2022 11:40:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
06/24/2022 11:40:46 - INFO - __main__ - Global step 600 Train loss 0.06 ACC 0.59375 on epoch=299
06/24/2022 11:40:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=304
06/24/2022 11:40:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=309
06/24/2022 11:40:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=314
06/24/2022 11:40:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=319
06/24/2022 11:40:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/24/2022 11:40:53 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.5625 on epoch=324
06/24/2022 11:40:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=329
06/24/2022 11:40:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=334
06/24/2022 11:40:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=339
06/24/2022 11:40:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=344
06/24/2022 11:40:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=349
06/24/2022 11:41:00 - INFO - __main__ - Global step 700 Train loss 0.03 ACC 0.5625 on epoch=349
06/24/2022 11:41:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=354
06/24/2022 11:41:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=359
06/24/2022 11:41:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/24/2022 11:41:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=369
06/24/2022 11:41:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=374
06/24/2022 11:41:07 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.53125 on epoch=374
06/24/2022 11:41:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/24/2022 11:41:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=384
06/24/2022 11:41:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
06/24/2022 11:41:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=394
06/24/2022 11:41:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=399
06/24/2022 11:41:14 - INFO - __main__ - Global step 800 Train loss 0.02 ACC 0.59375 on epoch=399
06/24/2022 11:41:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=404
06/24/2022 11:41:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=409
06/24/2022 11:41:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=414
06/24/2022 11:41:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=419
06/24/2022 11:41:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/24/2022 11:41:21 - INFO - __main__ - Global step 850 Train loss 0.01 ACC 0.53125 on epoch=424
06/24/2022 11:41:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 11:41:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/24/2022 11:41:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=439
06/24/2022 11:41:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=444
06/24/2022 11:41:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/24/2022 11:41:28 - INFO - __main__ - Global step 900 Train loss 0.01 ACC 0.5 on epoch=449
06/24/2022 11:41:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/24/2022 11:41:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/24/2022 11:41:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 11:41:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 11:41:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/24/2022 11:41:35 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.5625 on epoch=474
06/24/2022 11:41:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=479
06/24/2022 11:41:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=484
06/24/2022 11:41:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=489
06/24/2022 11:41:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
06/24/2022 11:41:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=499
06/24/2022 11:41:42 - INFO - __main__ - Global step 1000 Train loss 0.01 ACC 0.5625 on epoch=499
06/24/2022 11:41:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=504
06/24/2022 11:41:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=509
06/24/2022 11:41:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 11:41:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/24/2022 11:41:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/24/2022 11:41:49 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.53125 on epoch=524
06/24/2022 11:41:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=529
06/24/2022 11:41:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 11:41:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=539
06/24/2022 11:41:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=544
06/24/2022 11:41:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 11:41:56 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.5625 on epoch=549
06/24/2022 11:41:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/24/2022 11:41:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/24/2022 11:41:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/24/2022 11:42:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 11:42:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 11:42:03 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.53125 on epoch=574
06/24/2022 11:42:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 11:42:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 11:42:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=589
06/24/2022 11:42:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=594
06/24/2022 11:42:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/24/2022 11:42:10 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.59375 on epoch=599
06/24/2022 11:42:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 11:42:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 11:42:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 11:42:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 11:42:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 11:42:17 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.53125 on epoch=624
06/24/2022 11:42:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 11:42:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 11:42:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 11:42:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 11:42:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 11:42:23 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.59375 on epoch=649
06/24/2022 11:42:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 11:42:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 11:42:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 11:42:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 11:42:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 11:42:31 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.5625 on epoch=674
06/24/2022 11:42:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 11:42:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 11:42:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 11:42:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 11:42:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/24/2022 11:42:37 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5625 on epoch=699
06/24/2022 11:42:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 11:42:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 11:42:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 11:42:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 11:42:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/24/2022 11:42:44 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.53125 on epoch=724
06/24/2022 11:42:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 11:42:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 11:42:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 11:42:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 11:42:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 11:42:51 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.5625 on epoch=749
06/24/2022 11:42:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 11:42:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 11:42:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 11:42:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 11:42:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 11:42:58 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.59375 on epoch=774
06/24/2022 11:43:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=779
06/24/2022 11:43:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 11:43:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 11:43:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 11:43:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 11:43:05 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.59375 on epoch=799
06/24/2022 11:43:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
06/24/2022 11:43:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/24/2022 11:43:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 11:43:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 11:43:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 11:43:12 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.59375 on epoch=824
06/24/2022 11:43:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 11:43:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 11:43:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 11:43:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 11:43:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 11:43:19 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.5625 on epoch=849
06/24/2022 11:43:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 11:43:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 11:43:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 11:43:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 11:43:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 11:43:26 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.625 on epoch=874
06/24/2022 11:43:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 11:43:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 11:43:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 11:43:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 11:43:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 11:43:33 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/24/2022 11:43:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 11:43:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 11:43:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=914
06/24/2022 11:43:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 11:43:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 11:43:40 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.625 on epoch=924
06/24/2022 11:43:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 11:43:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 11:43:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 11:43:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 11:43:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 11:43:47 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/24/2022 11:43:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 11:43:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 11:43:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/24/2022 11:43:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 11:43:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 11:43:54 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.59375 on epoch=974
06/24/2022 11:43:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 11:43:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 11:43:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 11:43:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 11:44:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 11:44:01 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5625 on epoch=999
06/24/2022 11:44:01 - INFO - __main__ - save last model!
06/24/2022 11:44:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 11:44:01 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 11:44:01 - INFO - __main__ - Printing 3 examples
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 11:44:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 11:44:01 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:44:01 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:44:01 - INFO - __main__ - Printing 3 examples
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:44:01 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:44:01 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:44:01 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:44:01 - INFO - __main__ - Printing 3 examples
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:44:01 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:01 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:44:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:44:02 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:44:07 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:44:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:44:08 - INFO - __main__ - Starting training!
06/24/2022 11:44:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:45:00 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:58:11 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.4_8_predictions.txt
06/24/2022 11:58:11 - INFO - __main__ - ACC on test data: 0.5505
06/24/2022 11:58:12 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.4, bsz=8, dev_performance=0.625, test_performance=0.5504575810042048
06/24/2022 11:58:12 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.3, bsz=8 ...
06/24/2022 11:58:13 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:58:13 - INFO - __main__ - Printing 3 examples
06/24/2022 11:58:13 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:58:13 - INFO - __main__ - ['duplicate']
06/24/2022 11:58:13 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:58:13 - INFO - __main__ - ['duplicate']
06/24/2022 11:58:13 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:58:13 - INFO - __main__ - ['duplicate']
06/24/2022 11:58:13 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:58:13 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:58:13 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:58:13 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:58:13 - INFO - __main__ - Printing 3 examples
06/24/2022 11:58:13 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:58:13 - INFO - __main__ - ['duplicate']
06/24/2022 11:58:13 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:58:13 - INFO - __main__ - ['duplicate']
06/24/2022 11:58:13 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:58:13 - INFO - __main__ - ['duplicate']
06/24/2022 11:58:13 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:58:13 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:58:13 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:58:19 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 11:58:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:58:19 - INFO - __main__ - Starting training!
06/24/2022 11:58:21 - INFO - __main__ - Step 10 Global step 10 Train loss 5.80 on epoch=4
06/24/2022 11:58:22 - INFO - __main__ - Step 20 Global step 20 Train loss 4.75 on epoch=9
06/24/2022 11:58:23 - INFO - __main__ - Step 30 Global step 30 Train loss 3.61 on epoch=14
06/24/2022 11:58:24 - INFO - __main__ - Step 40 Global step 40 Train loss 2.76 on epoch=19
06/24/2022 11:58:26 - INFO - __main__ - Step 50 Global step 50 Train loss 2.18 on epoch=24
06/24/2022 11:58:26 - INFO - __main__ - Global step 50 Train loss 3.82 ACC 0.0625 on epoch=24
06/24/2022 11:58:26 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0625 on epoch=24, global_step=50
06/24/2022 11:58:27 - INFO - __main__ - Step 60 Global step 60 Train loss 1.52 on epoch=29
06/24/2022 11:58:29 - INFO - __main__ - Step 70 Global step 70 Train loss 1.22 on epoch=34
06/24/2022 11:58:30 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=39
06/24/2022 11:58:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=44
06/24/2022 11:58:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.58 on epoch=49
06/24/2022 11:58:33 - INFO - __main__ - Global step 100 Train loss 1.01 ACC 0.5 on epoch=49
06/24/2022 11:58:33 - INFO - __main__ - Saving model with best ACC: 0.0625 -> 0.5 on epoch=49, global_step=100
06/24/2022 11:58:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.51 on epoch=54
06/24/2022 11:58:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.44 on epoch=59
06/24/2022 11:58:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.47 on epoch=64
06/24/2022 11:58:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.46 on epoch=69
06/24/2022 11:58:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=74
06/24/2022 11:58:40 - INFO - __main__ - Global step 150 Train loss 0.47 ACC 0.5 on epoch=74
06/24/2022 11:58:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.36 on epoch=79
06/24/2022 11:58:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=84
06/24/2022 11:58:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=89
06/24/2022 11:58:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/24/2022 11:58:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=99
06/24/2022 11:58:47 - INFO - __main__ - Global step 200 Train loss 0.36 ACC 0.5 on epoch=99
06/24/2022 11:58:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=104
06/24/2022 11:58:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=109
06/24/2022 11:58:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=114
06/24/2022 11:58:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=119
06/24/2022 11:58:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=124
06/24/2022 11:58:53 - INFO - __main__ - Global step 250 Train loss 0.33 ACC 0.5 on epoch=124
06/24/2022 11:58:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/24/2022 11:58:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/24/2022 11:58:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.33 on epoch=139
06/24/2022 11:58:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=144
06/24/2022 11:58:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=149
06/24/2022 11:59:00 - INFO - __main__ - Global step 300 Train loss 0.32 ACC 0.5 on epoch=149
06/24/2022 11:59:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=154
06/24/2022 11:59:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=159
06/24/2022 11:59:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=164
06/24/2022 11:59:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/24/2022 11:59:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=174
06/24/2022 11:59:07 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.5 on epoch=174
06/24/2022 11:59:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=179
06/24/2022 11:59:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=184
06/24/2022 11:59:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=189
06/24/2022 11:59:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=194
06/24/2022 11:59:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=199
06/24/2022 11:59:14 - INFO - __main__ - Global step 400 Train loss 0.27 ACC 0.5 on epoch=199
06/24/2022 11:59:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=204
06/24/2022 11:59:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=209
06/24/2022 11:59:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=214
06/24/2022 11:59:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=219
06/24/2022 11:59:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=224
06/24/2022 11:59:20 - INFO - __main__ - Global step 450 Train loss 0.21 ACC 0.625 on epoch=224
06/24/2022 11:59:20 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.625 on epoch=224, global_step=450
06/24/2022 11:59:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 11:59:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=234
06/24/2022 11:59:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=239
06/24/2022 11:59:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=244
06/24/2022 11:59:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=249
06/24/2022 11:59:27 - INFO - __main__ - Global step 500 Train loss 0.18 ACC 0.65625 on epoch=249
06/24/2022 11:59:27 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=249, global_step=500
06/24/2022 11:59:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=254
06/24/2022 11:59:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=259
06/24/2022 11:59:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=264
06/24/2022 11:59:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=269
06/24/2022 11:59:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=274
06/24/2022 11:59:34 - INFO - __main__ - Global step 550 Train loss 0.15 ACC 0.5625 on epoch=274
06/24/2022 11:59:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=279
06/24/2022 11:59:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=284
06/24/2022 11:59:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=289
06/24/2022 11:59:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=294
06/24/2022 11:59:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=299
06/24/2022 11:59:41 - INFO - __main__ - Global step 600 Train loss 0.10 ACC 0.59375 on epoch=299
06/24/2022 11:59:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=304
06/24/2022 11:59:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=309
06/24/2022 11:59:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=314
06/24/2022 11:59:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=319
06/24/2022 11:59:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=324
06/24/2022 11:59:48 - INFO - __main__ - Global step 650 Train loss 0.09 ACC 0.59375 on epoch=324
06/24/2022 11:59:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=329
06/24/2022 11:59:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=334
06/24/2022 11:59:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=339
06/24/2022 11:59:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=344
06/24/2022 11:59:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=349
06/24/2022 11:59:55 - INFO - __main__ - Global step 700 Train loss 0.06 ACC 0.53125 on epoch=349
06/24/2022 11:59:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=354
06/24/2022 11:59:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/24/2022 11:59:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/24/2022 11:59:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=369
06/24/2022 12:00:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=374
06/24/2022 12:00:01 - INFO - __main__ - Global step 750 Train loss 0.07 ACC 0.5625 on epoch=374
06/24/2022 12:00:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=379
06/24/2022 12:00:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=384
06/24/2022 12:00:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
06/24/2022 12:00:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=394
06/24/2022 12:00:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=399
06/24/2022 12:00:08 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.53125 on epoch=399
06/24/2022 12:00:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=404
06/24/2022 12:00:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
06/24/2022 12:00:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=414
06/24/2022 12:00:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
06/24/2022 12:00:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=424
06/24/2022 12:00:15 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.65625 on epoch=424
06/24/2022 12:00:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 12:00:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
06/24/2022 12:00:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=439
06/24/2022 12:00:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/24/2022 12:00:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/24/2022 12:00:22 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.59375 on epoch=449
06/24/2022 12:00:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=454
06/24/2022 12:00:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=459
06/24/2022 12:00:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=464
06/24/2022 12:00:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/24/2022 12:00:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=474
06/24/2022 12:00:29 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.625 on epoch=474
06/24/2022 12:00:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=479
06/24/2022 12:00:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/24/2022 12:00:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
06/24/2022 12:00:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
06/24/2022 12:00:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=499
06/24/2022 12:00:36 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.625 on epoch=499
06/24/2022 12:00:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 12:00:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=509
06/24/2022 12:00:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 12:00:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/24/2022 12:00:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=524
06/24/2022 12:00:43 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.5625 on epoch=524
06/24/2022 12:00:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=529
06/24/2022 12:00:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=534
06/24/2022 12:00:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/24/2022 12:00:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 12:00:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
06/24/2022 12:00:49 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.5625 on epoch=549
06/24/2022 12:00:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/24/2022 12:00:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 12:00:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=564
06/24/2022 12:00:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
06/24/2022 12:00:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 12:00:56 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5 on epoch=574
06/24/2022 12:00:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 12:00:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 12:01:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/24/2022 12:01:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 12:01:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 12:01:03 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.625 on epoch=599
06/24/2022 12:01:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
06/24/2022 12:01:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/24/2022 12:01:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 12:01:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 12:01:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 12:01:10 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/24/2022 12:01:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
06/24/2022 12:01:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/24/2022 12:01:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 12:01:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/24/2022 12:01:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 12:01:17 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.53125 on epoch=649
06/24/2022 12:01:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=654
06/24/2022 12:01:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=659
06/24/2022 12:01:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 12:01:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 12:01:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 12:01:24 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.5 on epoch=674
06/24/2022 12:01:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 12:01:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/24/2022 12:01:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 12:01:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 12:01:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/24/2022 12:01:31 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/24/2022 12:01:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 12:01:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 12:01:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 12:01:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/24/2022 12:01:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/24/2022 12:01:38 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.53125 on epoch=724
06/24/2022 12:01:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 12:01:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 12:01:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 12:01:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=744
06/24/2022 12:01:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 12:01:44 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
06/24/2022 12:01:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/24/2022 12:01:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 12:01:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/24/2022 12:01:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/24/2022 12:01:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 12:01:51 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.5 on epoch=774
06/24/2022 12:01:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 12:01:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/24/2022 12:01:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 12:01:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 12:01:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 12:01:58 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.625 on epoch=799
06/24/2022 12:01:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=804
06/24/2022 12:02:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/24/2022 12:02:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
06/24/2022 12:02:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 12:02:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 12:02:05 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.53125 on epoch=824
06/24/2022 12:02:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=829
06/24/2022 12:02:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 12:02:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 12:02:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/24/2022 12:02:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/24/2022 12:02:12 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
06/24/2022 12:02:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 12:02:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 12:02:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 12:02:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 12:02:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 12:02:19 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.625 on epoch=874
06/24/2022 12:02:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 12:02:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 12:02:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 12:02:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 12:02:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 12:02:26 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.625 on epoch=899
06/24/2022 12:02:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 12:02:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 12:02:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 12:02:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 12:02:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 12:02:33 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.59375 on epoch=924
06/24/2022 12:02:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 12:02:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
06/24/2022 12:02:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 12:02:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 12:02:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 12:02:39 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.59375 on epoch=949
06/24/2022 12:02:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 12:02:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/24/2022 12:02:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/24/2022 12:02:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 12:02:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 12:02:46 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.59375 on epoch=974
06/24/2022 12:02:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 12:02:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 12:02:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 12:02:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/24/2022 12:02:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 12:02:53 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5625 on epoch=999
06/24/2022 12:02:53 - INFO - __main__ - save last model!
06/24/2022 12:02:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 12:02:53 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 12:02:53 - INFO - __main__ - Printing 3 examples
06/24/2022 12:02:53 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 12:02:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:02:53 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 12:02:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:02:53 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 12:02:53 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:02:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:02:54 - INFO - __main__ - Printing 3 examples
06/24/2022 12:02:54 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:02:54 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:02:54 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:02:54 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:02:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:02:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:02:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:02:54 - INFO - __main__ - Printing 3 examples
06/24/2022 12:02:54 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:02:54 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:02:54 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:02:54 - INFO - __main__ - ['duplicate']
06/24/2022 12:02:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:02:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:02:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:03:00 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 12:03:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:03:00 - INFO - __main__ - Starting training!
06/24/2022 12:03:12 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:03:52 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 12:17:03 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.3_8_predictions.txt
06/24/2022 12:17:03 - INFO - __main__ - ACC on test data: 0.5654
06/24/2022 12:17:04 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.3, bsz=8, dev_performance=0.65625, test_performance=0.5653722483304476
06/24/2022 12:17:04 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.2, bsz=8 ...
06/24/2022 12:17:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:17:05 - INFO - __main__ - Printing 3 examples
06/24/2022 12:17:05 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:17:05 - INFO - __main__ - ['duplicate']
06/24/2022 12:17:05 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:17:05 - INFO - __main__ - ['duplicate']
06/24/2022 12:17:05 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:17:05 - INFO - __main__ - ['duplicate']
06/24/2022 12:17:05 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:17:05 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:17:05 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:17:05 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:17:05 - INFO - __main__ - Printing 3 examples
06/24/2022 12:17:05 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:17:05 - INFO - __main__ - ['duplicate']
06/24/2022 12:17:05 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:17:05 - INFO - __main__ - ['duplicate']
06/24/2022 12:17:05 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:17:05 - INFO - __main__ - ['duplicate']
06/24/2022 12:17:05 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:17:05 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:17:05 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:17:11 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 12:17:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:17:11 - INFO - __main__ - Starting training!
06/24/2022 12:17:13 - INFO - __main__ - Step 10 Global step 10 Train loss 6.65 on epoch=4
06/24/2022 12:17:14 - INFO - __main__ - Step 20 Global step 20 Train loss 5.46 on epoch=9
06/24/2022 12:17:15 - INFO - __main__ - Step 30 Global step 30 Train loss 4.57 on epoch=14
06/24/2022 12:17:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.89 on epoch=19
06/24/2022 12:17:18 - INFO - __main__ - Step 50 Global step 50 Train loss 3.45 on epoch=24
06/24/2022 12:17:18 - INFO - __main__ - Global step 50 Train loss 4.80 ACC 0.0 on epoch=24
06/24/2022 12:17:18 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 12:17:20 - INFO - __main__ - Step 60 Global step 60 Train loss 2.61 on epoch=29
06/24/2022 12:17:21 - INFO - __main__ - Step 70 Global step 70 Train loss 2.28 on epoch=34
06/24/2022 12:17:22 - INFO - __main__ - Step 80 Global step 80 Train loss 1.96 on epoch=39
06/24/2022 12:17:24 - INFO - __main__ - Step 90 Global step 90 Train loss 1.51 on epoch=44
06/24/2022 12:17:25 - INFO - __main__ - Step 100 Global step 100 Train loss 1.33 on epoch=49
06/24/2022 12:17:25 - INFO - __main__ - Global step 100 Train loss 1.94 ACC 0.5 on epoch=49
06/24/2022 12:17:25 - INFO - __main__ - Saving model with best ACC: 0.0 -> 0.5 on epoch=49, global_step=100
06/24/2022 12:17:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.06 on epoch=54
06/24/2022 12:17:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=59
06/24/2022 12:17:29 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=64
06/24/2022 12:17:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=69
06/24/2022 12:17:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=74
06/24/2022 12:17:32 - INFO - __main__ - Global step 150 Train loss 0.83 ACC 0.5 on epoch=74
06/24/2022 12:17:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=79
06/24/2022 12:17:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.51 on epoch=84
06/24/2022 12:17:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.46 on epoch=89
06/24/2022 12:17:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.43 on epoch=94
06/24/2022 12:17:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=99
06/24/2022 12:17:39 - INFO - __main__ - Global step 200 Train loss 0.48 ACC 0.5 on epoch=99
06/24/2022 12:17:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.38 on epoch=104
06/24/2022 12:17:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=109
06/24/2022 12:17:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=114
06/24/2022 12:17:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=119
06/24/2022 12:17:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/24/2022 12:17:46 - INFO - __main__ - Global step 250 Train loss 0.40 ACC 0.5 on epoch=124
06/24/2022 12:17:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=129
06/24/2022 12:17:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=134
06/24/2022 12:17:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=139
06/24/2022 12:17:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=144
06/24/2022 12:17:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=149
06/24/2022 12:17:53 - INFO - __main__ - Global step 300 Train loss 0.34 ACC 0.5 on epoch=149
06/24/2022 12:17:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/24/2022 12:17:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=159
06/24/2022 12:17:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=164
06/24/2022 12:17:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=169
06/24/2022 12:18:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=174
06/24/2022 12:18:00 - INFO - __main__ - Global step 350 Train loss 0.33 ACC 0.5 on epoch=174
06/24/2022 12:18:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=179
06/24/2022 12:18:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=184
06/24/2022 12:18:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=189
06/24/2022 12:18:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=194
06/24/2022 12:18:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/24/2022 12:18:07 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/24/2022 12:18:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=204
06/24/2022 12:18:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/24/2022 12:18:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=214
06/24/2022 12:18:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=219
06/24/2022 12:18:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=224
06/24/2022 12:18:14 - INFO - __main__ - Global step 450 Train loss 0.28 ACC 0.5 on epoch=224
06/24/2022 12:18:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=229
06/24/2022 12:18:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=234
06/24/2022 12:18:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=239
06/24/2022 12:18:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=244
06/24/2022 12:18:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=249
06/24/2022 12:18:21 - INFO - __main__ - Global step 500 Train loss 0.29 ACC 0.5 on epoch=249
06/24/2022 12:18:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=254
06/24/2022 12:18:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=259
06/24/2022 12:18:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=264
06/24/2022 12:18:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=269
06/24/2022 12:18:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=274
06/24/2022 12:18:29 - INFO - __main__ - Global step 550 Train loss 0.28 ACC 0.5 on epoch=274
06/24/2022 12:18:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=279
06/24/2022 12:18:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=284
06/24/2022 12:18:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=289
06/24/2022 12:18:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=294
06/24/2022 12:18:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=299
06/24/2022 12:18:36 - INFO - __main__ - Global step 600 Train loss 0.25 ACC 0.5625 on epoch=299
06/24/2022 12:18:36 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=299, global_step=600
06/24/2022 12:18:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/24/2022 12:18:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=309
06/24/2022 12:18:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=314
06/24/2022 12:18:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=319
06/24/2022 12:18:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=324
06/24/2022 12:18:43 - INFO - __main__ - Global step 650 Train loss 0.21 ACC 0.625 on epoch=324
06/24/2022 12:18:43 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.625 on epoch=324, global_step=650
06/24/2022 12:18:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=329
06/24/2022 12:18:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=334
06/24/2022 12:18:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=339
06/24/2022 12:18:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=344
06/24/2022 12:18:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=349
06/24/2022 12:18:50 - INFO - __main__ - Global step 700 Train loss 0.18 ACC 0.5625 on epoch=349
06/24/2022 12:18:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=354
06/24/2022 12:18:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/24/2022 12:18:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=364
06/24/2022 12:18:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=369
06/24/2022 12:18:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=374
06/24/2022 12:18:57 - INFO - __main__ - Global step 750 Train loss 0.17 ACC 0.5625 on epoch=374
06/24/2022 12:18:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=379
06/24/2022 12:18:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=384
06/24/2022 12:19:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/24/2022 12:19:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=394
06/24/2022 12:19:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=399
06/24/2022 12:19:03 - INFO - __main__ - Global step 800 Train loss 0.15 ACC 0.5 on epoch=399
06/24/2022 12:19:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=404
06/24/2022 12:19:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=409
06/24/2022 12:19:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=414
06/24/2022 12:19:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=419
06/24/2022 12:19:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=424
06/24/2022 12:19:10 - INFO - __main__ - Global step 850 Train loss 0.12 ACC 0.5625 on epoch=424
06/24/2022 12:19:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=429
06/24/2022 12:19:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=434
06/24/2022 12:19:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=439
06/24/2022 12:19:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=444
06/24/2022 12:19:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=449
06/24/2022 12:19:17 - INFO - __main__ - Global step 900 Train loss 0.11 ACC 0.5625 on epoch=449
06/24/2022 12:19:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=454
06/24/2022 12:19:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=459
06/24/2022 12:19:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=464
06/24/2022 12:19:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=469
06/24/2022 12:19:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=474
06/24/2022 12:19:24 - INFO - __main__ - Global step 950 Train loss 0.08 ACC 0.625 on epoch=474
06/24/2022 12:19:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=479
06/24/2022 12:19:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=484
06/24/2022 12:19:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=489
06/24/2022 12:19:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=494
06/24/2022 12:19:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=499
06/24/2022 12:19:31 - INFO - __main__ - Global step 1000 Train loss 0.07 ACC 0.65625 on epoch=499
06/24/2022 12:19:31 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=499, global_step=1000
06/24/2022 12:19:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=504
06/24/2022 12:19:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=509
06/24/2022 12:19:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=514
06/24/2022 12:19:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=519
06/24/2022 12:19:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=524
06/24/2022 12:19:38 - INFO - __main__ - Global step 1050 Train loss 0.06 ACC 0.59375 on epoch=524
06/24/2022 12:19:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/24/2022 12:19:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=534
06/24/2022 12:19:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/24/2022 12:19:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
06/24/2022 12:19:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=549
06/24/2022 12:19:45 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.59375 on epoch=549
06/24/2022 12:19:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=554
06/24/2022 12:19:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=559
06/24/2022 12:19:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=564
06/24/2022 12:19:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/24/2022 12:19:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=574
06/24/2022 12:19:52 - INFO - __main__ - Global step 1150 Train loss 0.04 ACC 0.5625 on epoch=574
06/24/2022 12:19:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
06/24/2022 12:19:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=584
06/24/2022 12:19:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=589
06/24/2022 12:19:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=594
06/24/2022 12:19:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
06/24/2022 12:19:59 - INFO - __main__ - Global step 1200 Train loss 0.06 ACC 0.5625 on epoch=599
06/24/2022 12:20:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 12:20:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/24/2022 12:20:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/24/2022 12:20:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=619
06/24/2022 12:20:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/24/2022 12:20:06 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.5625 on epoch=624
06/24/2022 12:20:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
06/24/2022 12:20:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
06/24/2022 12:20:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=639
06/24/2022 12:20:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
06/24/2022 12:20:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 12:20:13 - INFO - __main__ - Global step 1300 Train loss 0.04 ACC 0.59375 on epoch=649
06/24/2022 12:20:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/24/2022 12:20:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
06/24/2022 12:20:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 12:20:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=669
06/24/2022 12:20:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=674
06/24/2022 12:20:19 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.53125 on epoch=674
06/24/2022 12:20:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 12:20:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/24/2022 12:20:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 12:20:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=694
06/24/2022 12:20:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/24/2022 12:20:26 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.59375 on epoch=699
06/24/2022 12:20:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=704
06/24/2022 12:20:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=709
06/24/2022 12:20:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 12:20:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/24/2022 12:20:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/24/2022 12:20:33 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.5625 on epoch=724
06/24/2022 12:20:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 12:20:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/24/2022 12:20:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=739
06/24/2022 12:20:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 12:20:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
06/24/2022 12:20:40 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.59375 on epoch=749
06/24/2022 12:20:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=754
06/24/2022 12:20:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/24/2022 12:20:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/24/2022 12:20:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 12:20:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=774
06/24/2022 12:20:47 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.59375 on epoch=774
06/24/2022 12:20:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 12:20:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
06/24/2022 12:20:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 12:20:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 12:20:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 12:20:54 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.59375 on epoch=799
06/24/2022 12:20:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 12:20:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/24/2022 12:20:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=814
06/24/2022 12:20:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 12:21:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/24/2022 12:21:01 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.625 on epoch=824
06/24/2022 12:21:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 12:21:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 12:21:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 12:21:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/24/2022 12:21:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/24/2022 12:21:08 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.625 on epoch=849
06/24/2022 12:21:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 12:21:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
06/24/2022 12:21:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=864
06/24/2022 12:21:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
06/24/2022 12:21:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 12:21:15 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.625 on epoch=874
06/24/2022 12:21:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 12:21:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
06/24/2022 12:21:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 12:21:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=894
06/24/2022 12:21:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
06/24/2022 12:21:22 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.625 on epoch=899
06/24/2022 12:21:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 12:21:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 12:21:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=914
06/24/2022 12:21:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 12:21:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 12:21:29 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.625 on epoch=924
06/24/2022 12:21:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 12:21:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/24/2022 12:21:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 12:21:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 12:21:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 12:21:35 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.625 on epoch=949
06/24/2022 12:21:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 12:21:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 12:21:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/24/2022 12:21:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 12:21:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 12:21:42 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.625 on epoch=974
06/24/2022 12:21:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/24/2022 12:21:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 12:21:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 12:21:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/24/2022 12:21:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 12:21:49 - INFO - __main__ - Global step 2000 Train loss 0.01 ACC 0.625 on epoch=999
06/24/2022 12:21:49 - INFO - __main__ - save last model!
06/24/2022 12:21:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 12:21:49 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 12:21:49 - INFO - __main__ - Printing 3 examples
06/24/2022 12:21:49 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 12:21:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:21:49 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 12:21:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:21:49 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 12:21:49 - INFO - __main__ - ['duplicate']
06/24/2022 12:21:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:22:07 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:22:48 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 12:35:54 - INFO - __main__ - Saved prediction in models/T5-base-multitask-nopara2para-5e-1-4-20/singletask-glue-qqp/glue-qqp_16_87_0.2_8_predictions.txt
06/24/2022 12:35:54 - INFO - __main__ - ACC on test data: 0.5176
06/24/2022 12:35:54 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.2, bsz=8, dev_performance=0.65625, test_performance=0.5175612169181301
