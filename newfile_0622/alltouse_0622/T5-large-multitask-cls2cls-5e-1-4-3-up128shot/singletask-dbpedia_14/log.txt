05/21/2022 21:36:02 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/21/2022 21:36:02 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14
05/21/2022 21:36:02 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/21/2022 21:36:02 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14
05/21/2022 21:36:02 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:36:02 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:36:02 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:36:02 - INFO - __main__ - Using 2 gpus
05/21/2022 21:36:02 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:36:02 - INFO - __main__ - Using 2 gpus
05/21/2022 21:36:02 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 21:36:02 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 21:36:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/21/2022 21:36:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 21:36:08 - INFO - __main__ - Printing 3 examples
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Input ...
05/21/2022 21:36:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 21:36:08 - INFO - __main__ - Printing 3 examples
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Input ...
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Output ...
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Output ...
05/21/2022 21:36:08 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 21:36:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 21:36:08 - INFO - __main__ - Printing 3 examples
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Input ...
05/21/2022 21:36:08 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 21:36:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 21:36:08 - INFO - __main__ - Printing 3 examples
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 21:36:08 - INFO - __main__ - ['Animal']
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Input ...
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Output ...
05/21/2022 21:36:08 - INFO - __main__ - Tokenizing Output ...
05/21/2022 21:36:08 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 21:36:08 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 21:36:26 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 21:36:26 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 01:25:46 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/01/2022 01:25:46 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14
06/01/2022 01:25:46 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/01/2022 01:25:46 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14
06/01/2022 01:25:47 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/01/2022 01:25:47 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/01/2022 01:25:47 - INFO - __main__ - args.device: cuda:0
06/01/2022 01:25:47 - INFO - __main__ - Using 2 gpus
06/01/2022 01:25:47 - INFO - __main__ - args.device: cuda:1
06/01/2022 01:25:47 - INFO - __main__ - Using 2 gpus
06/01/2022 01:25:47 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/01/2022 01:25:47 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/01/2022 01:25:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/01/2022 01:25:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 01:25:52 - INFO - __main__ - Printing 3 examples
06/01/2022 01:25:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 01:25:52 - INFO - __main__ - ['Animal']
06/01/2022 01:25:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 01:25:52 - INFO - __main__ - ['Animal']
06/01/2022 01:25:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 01:25:52 - INFO - __main__ - ['Animal']
06/01/2022 01:25:52 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:25:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 01:25:52 - INFO - __main__ - Printing 3 examples
06/01/2022 01:25:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 01:25:52 - INFO - __main__ - ['Animal']
06/01/2022 01:25:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 01:25:52 - INFO - __main__ - ['Animal']
06/01/2022 01:25:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 01:25:52 - INFO - __main__ - ['Animal']
06/01/2022 01:25:52 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:25:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:25:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:25:53 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 01:25:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 01:25:53 - INFO - __main__ - Printing 3 examples
06/01/2022 01:25:53 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 01:25:53 - INFO - __main__ - ['Animal']
06/01/2022 01:25:53 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 01:25:53 - INFO - __main__ - ['Animal']
06/01/2022 01:25:53 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 01:25:53 - INFO - __main__ - ['Animal']
06/01/2022 01:25:53 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:25:53 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 01:25:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 01:25:53 - INFO - __main__ - Printing 3 examples
06/01/2022 01:25:53 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 01:25:53 - INFO - __main__ - ['Animal']
06/01/2022 01:25:53 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 01:25:53 - INFO - __main__ - ['Animal']
06/01/2022 01:25:53 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 01:25:53 - INFO - __main__ - ['Animal']
06/01/2022 01:25:53 - INFO - __main__ - Tokenizing Input ...
06/01/2022 01:25:53 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:25:53 - INFO - __main__ - Tokenizing Output ...
06/01/2022 01:25:53 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 01:25:53 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 01:26:11 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 01:26:11 - INFO - __main__ - load prompt embedding from ckpt
06/14/2022 19:32:08 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/14/2022 19:32:08 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14
06/14/2022 19:32:08 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/14/2022 19:32:08 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-up128shot/singletask-dbpedia_14
06/14/2022 19:32:10 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/14/2022 19:32:10 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/14/2022 19:32:10 - INFO - __main__ - args.device: cuda:1
06/14/2022 19:32:10 - INFO - __main__ - args.device: cuda:0
06/14/2022 19:32:10 - INFO - __main__ - Using 2 gpus
06/14/2022 19:32:10 - INFO - __main__ - Using 2 gpus
06/14/2022 19:32:10 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/14/2022 19:32:10 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/14/2022 19:32:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/14/2022 19:32:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/14/2022 19:32:15 - INFO - __main__ - Printing 3 examples
06/14/2022 19:32:15 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/14/2022 19:32:15 - INFO - __main__ - ['Animal']
06/14/2022 19:32:15 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/14/2022 19:32:15 - INFO - __main__ - ['Animal']
06/14/2022 19:32:15 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/14/2022 19:32:15 - INFO - __main__ - ['Animal']
06/14/2022 19:32:15 - INFO - __main__ - Tokenizing Input ...
06/14/2022 19:32:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/14/2022 19:32:15 - INFO - __main__ - Printing 3 examples
06/14/2022 19:32:15 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/14/2022 19:32:15 - INFO - __main__ - ['Animal']
06/14/2022 19:32:15 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/14/2022 19:32:15 - INFO - __main__ - ['Animal']
06/14/2022 19:32:15 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/14/2022 19:32:15 - INFO - __main__ - ['Animal']
06/14/2022 19:32:15 - INFO - __main__ - Tokenizing Input ...
06/14/2022 19:32:15 - INFO - __main__ - Tokenizing Output ...
06/14/2022 19:32:15 - INFO - __main__ - Tokenizing Output ...
06/14/2022 19:32:16 - INFO - __main__ - Loaded 224 examples from train data
06/14/2022 19:32:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/14/2022 19:32:16 - INFO - __main__ - Printing 3 examples
06/14/2022 19:32:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/14/2022 19:32:16 - INFO - __main__ - ['Animal']
06/14/2022 19:32:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/14/2022 19:32:16 - INFO - __main__ - ['Animal']
06/14/2022 19:32:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/14/2022 19:32:16 - INFO - __main__ - ['Animal']
06/14/2022 19:32:16 - INFO - __main__ - Tokenizing Input ...
06/14/2022 19:32:16 - INFO - __main__ - Loaded 224 examples from train data
06/14/2022 19:32:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/14/2022 19:32:16 - INFO - __main__ - Printing 3 examples
06/14/2022 19:32:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/14/2022 19:32:16 - INFO - __main__ - ['Animal']
06/14/2022 19:32:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/14/2022 19:32:16 - INFO - __main__ - ['Animal']
06/14/2022 19:32:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/14/2022 19:32:16 - INFO - __main__ - ['Animal']
06/14/2022 19:32:16 - INFO - __main__ - Tokenizing Input ...
06/14/2022 19:32:16 - INFO - __main__ - Tokenizing Output ...
06/14/2022 19:32:16 - INFO - __main__ - Tokenizing Output ...
06/14/2022 19:32:16 - INFO - __main__ - Loaded 224 examples from dev data
06/14/2022 19:32:16 - INFO - __main__ - Loaded 224 examples from dev data
06/14/2022 19:32:34 - INFO - __main__ - load prompt embedding from ckpt
06/14/2022 19:32:35 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 20:37:51 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-3-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-3-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/22/2022 20:37:51 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-3-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-3-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/22/2022 20:37:51 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14
06/22/2022 20:37:51 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14
06/22/2022 20:37:52 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/22/2022 20:37:52 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/22/2022 20:37:52 - INFO - __main__ - args.device: cuda:0
06/22/2022 20:37:52 - INFO - __main__ - args.device: cuda:1
06/22/2022 20:37:52 - INFO - __main__ - Using 2 gpus
06/22/2022 20:37:52 - INFO - __main__ - Using 2 gpus
06/22/2022 20:37:52 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/22/2022 20:37:52 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/22/2022 20:37:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/22/2022 20:37:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 20:37:57 - INFO - __main__ - Printing 3 examples
06/22/2022 20:37:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 20:37:57 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 20:37:57 - INFO - __main__ - ['Animal']
06/22/2022 20:37:57 - INFO - __main__ - Printing 3 examples
06/22/2022 20:37:57 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 20:37:57 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 20:37:57 - INFO - __main__ - ['Animal']
06/22/2022 20:37:57 - INFO - __main__ - ['Animal']
06/22/2022 20:37:57 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 20:37:57 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 20:37:57 - INFO - __main__ - ['Animal']
06/22/2022 20:37:57 - INFO - __main__ - ['Animal']
06/22/2022 20:37:57 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:37:57 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 20:37:57 - INFO - __main__ - ['Animal']
06/22/2022 20:37:57 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:37:58 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:37:58 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:37:58 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 20:37:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 20:37:58 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 20:37:58 - INFO - __main__ - Printing 3 examples
06/22/2022 20:37:58 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 20:37:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 20:37:58 - INFO - __main__ - ['Animal']
06/22/2022 20:37:58 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 20:37:58 - INFO - __main__ - Printing 3 examples
06/22/2022 20:37:58 - INFO - __main__ - ['Animal']
06/22/2022 20:37:58 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 20:37:58 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 20:37:58 - INFO - __main__ - ['Animal']
06/22/2022 20:37:58 - INFO - __main__ - ['Animal']
06/22/2022 20:37:58 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:37:58 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 20:37:58 - INFO - __main__ - ['Animal']
06/22/2022 20:37:58 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 20:37:58 - INFO - __main__ - ['Animal']
06/22/2022 20:37:58 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:37:58 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:37:58 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:37:58 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 20:37:58 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 20:38:16 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 20:38:16 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 20:38:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 20:38:17 - INFO - __main__ - Starting training!
06/22/2022 20:38:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 20:38:21 - INFO - __main__ - Starting training!
06/22/2022 20:38:25 - INFO - __main__ - Step 10 Global step 10 Train loss 6.41 on epoch=0
06/22/2022 20:38:28 - INFO - __main__ - Step 20 Global step 20 Train loss 4.79 on epoch=1
06/22/2022 20:38:31 - INFO - __main__ - Step 30 Global step 30 Train loss 4.09 on epoch=2
06/22/2022 20:38:33 - INFO - __main__ - Step 40 Global step 40 Train loss 3.50 on epoch=2
06/22/2022 20:38:36 - INFO - __main__ - Step 50 Global step 50 Train loss 3.12 on epoch=3
06/22/2022 20:38:41 - INFO - __main__ - Global step 50 Train loss 4.38 Classification-F1 0.055747054082218375 on epoch=3
06/22/2022 20:38:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.055747054082218375 on epoch=3, global_step=50
06/22/2022 20:38:44 - INFO - __main__ - Step 60 Global step 60 Train loss 3.14 on epoch=4
06/22/2022 20:38:47 - INFO - __main__ - Step 70 Global step 70 Train loss 2.36 on epoch=4
06/22/2022 20:38:49 - INFO - __main__ - Step 80 Global step 80 Train loss 2.62 on epoch=5
06/22/2022 20:38:52 - INFO - __main__ - Step 90 Global step 90 Train loss 2.28 on epoch=6
06/22/2022 20:38:55 - INFO - __main__ - Step 100 Global step 100 Train loss 2.05 on epoch=7
06/22/2022 20:39:00 - INFO - __main__ - Global step 100 Train loss 2.49 Classification-F1 0.09451882744739531 on epoch=7
06/22/2022 20:39:00 - INFO - __main__ - Saving model with best Classification-F1: 0.055747054082218375 -> 0.09451882744739531 on epoch=7, global_step=100
06/22/2022 20:39:03 - INFO - __main__ - Step 110 Global step 110 Train loss 1.85 on epoch=7
06/22/2022 20:39:05 - INFO - __main__ - Step 120 Global step 120 Train loss 1.61 on epoch=8
06/22/2022 20:39:08 - INFO - __main__ - Step 130 Global step 130 Train loss 1.82 on epoch=9
06/22/2022 20:39:10 - INFO - __main__ - Step 140 Global step 140 Train loss 1.30 on epoch=9
06/22/2022 20:39:13 - INFO - __main__ - Step 150 Global step 150 Train loss 1.43 on epoch=10
06/22/2022 20:39:19 - INFO - __main__ - Global step 150 Train loss 1.60 Classification-F1 0.16470674364177934 on epoch=10
06/22/2022 20:39:19 - INFO - __main__ - Saving model with best Classification-F1: 0.09451882744739531 -> 0.16470674364177934 on epoch=10, global_step=150
06/22/2022 20:39:21 - INFO - __main__ - Step 160 Global step 160 Train loss 1.14 on epoch=11
06/22/2022 20:39:24 - INFO - __main__ - Step 170 Global step 170 Train loss 1.18 on epoch=12
06/22/2022 20:39:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=12
06/22/2022 20:39:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=13
06/22/2022 20:39:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=14
06/22/2022 20:39:38 - INFO - __main__ - Global step 200 Train loss 1.00 Classification-F1 0.3486989227916647 on epoch=14
06/22/2022 20:39:38 - INFO - __main__ - Saving model with best Classification-F1: 0.16470674364177934 -> 0.3486989227916647 on epoch=14, global_step=200
06/22/2022 20:39:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=14
06/22/2022 20:39:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=15
06/22/2022 20:39:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=16
06/22/2022 20:39:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=17
06/22/2022 20:39:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=17
06/22/2022 20:39:58 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.4466319622233601 on epoch=17
06/22/2022 20:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3486989227916647 -> 0.4466319622233601 on epoch=17, global_step=250
06/22/2022 20:40:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=18
06/22/2022 20:40:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=19
06/22/2022 20:40:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=19
06/22/2022 20:40:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=20
06/22/2022 20:40:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=21
06/22/2022 20:40:18 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.670172155384603 on epoch=21
06/22/2022 20:40:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4466319622233601 -> 0.670172155384603 on epoch=21, global_step=300
06/22/2022 20:40:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
06/22/2022 20:40:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/22/2022 20:40:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/22/2022 20:40:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
06/22/2022 20:40:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=24
06/22/2022 20:40:38 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.5719662571773578 on epoch=24
06/22/2022 20:40:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/22/2022 20:40:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
06/22/2022 20:40:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=27
06/22/2022 20:40:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/22/2022 20:40:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=28
06/22/2022 20:40:59 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.6473301288411646 on epoch=28
06/22/2022 20:41:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
06/22/2022 20:41:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
06/22/2022 20:41:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/22/2022 20:41:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=31
06/22/2022 20:41:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=32
06/22/2022 20:41:19 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7449807241927485 on epoch=32
06/22/2022 20:41:19 - INFO - __main__ - Saving model with best Classification-F1: 0.670172155384603 -> 0.7449807241927485 on epoch=32, global_step=450
06/22/2022 20:41:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
06/22/2022 20:41:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
06/22/2022 20:41:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
06/22/2022 20:41:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/22/2022 20:41:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
06/22/2022 20:41:39 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6885885694959915 on epoch=35
06/22/2022 20:41:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
06/22/2022 20:41:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
06/22/2022 20:41:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
06/22/2022 20:41:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/22/2022 20:41:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
06/22/2022 20:42:00 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.7359820355053961 on epoch=39
06/22/2022 20:42:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
06/22/2022 20:42:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=40
06/22/2022 20:42:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/22/2022 20:42:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/22/2022 20:42:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/22/2022 20:42:20 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.7034766679018735 on epoch=42
06/22/2022 20:42:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
06/22/2022 20:42:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
06/22/2022 20:42:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/22/2022 20:42:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/22/2022 20:42:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/22/2022 20:42:40 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.6967690690374118 on epoch=46
06/22/2022 20:42:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/22/2022 20:42:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/22/2022 20:42:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/22/2022 20:42:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/22/2022 20:42:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/22/2022 20:43:01 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.7443054132123782 on epoch=49
06/22/2022 20:43:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/22/2022 20:43:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/22/2022 20:43:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/22/2022 20:43:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/22/2022 20:43:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
06/22/2022 20:43:21 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.801537262021133 on epoch=53
06/22/2022 20:43:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7449807241927485 -> 0.801537262021133 on epoch=53, global_step=750
06/22/2022 20:43:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
06/22/2022 20:43:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
06/22/2022 20:43:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/22/2022 20:43:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=56
06/22/2022 20:43:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=57
06/22/2022 20:43:42 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7331969032828504 on epoch=57
06/22/2022 20:43:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/22/2022 20:43:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/22/2022 20:43:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/22/2022 20:43:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/22/2022 20:43:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/22/2022 20:44:02 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7292537765479192 on epoch=60
06/22/2022 20:44:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
06/22/2022 20:44:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/22/2022 20:44:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/22/2022 20:44:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/22/2022 20:44:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/22/2022 20:44:22 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7439123849214261 on epoch=64
06/22/2022 20:44:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=64
06/22/2022 20:44:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
06/22/2022 20:44:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/22/2022 20:44:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/22/2022 20:44:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
06/22/2022 20:44:42 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7687596854926386 on epoch=67
06/22/2022 20:44:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/22/2022 20:44:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/22/2022 20:44:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/22/2022 20:44:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/22/2022 20:44:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/22/2022 20:45:02 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7595756651231592 on epoch=71
06/22/2022 20:45:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/22/2022 20:45:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/22/2022 20:45:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
06/22/2022 20:45:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/22/2022 20:45:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/22/2022 20:45:22 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7131551520901616 on epoch=74
06/22/2022 20:45:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/22/2022 20:45:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
06/22/2022 20:45:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/22/2022 20:45:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/22/2022 20:45:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/22/2022 20:45:42 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8006246046805819 on epoch=78
06/22/2022 20:45:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/22/2022 20:45:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/22/2022 20:45:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/22/2022 20:45:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/22/2022 20:45:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/22/2022 20:46:02 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8104760571966997 on epoch=82
06/22/2022 20:46:02 - INFO - __main__ - Saving model with best Classification-F1: 0.801537262021133 -> 0.8104760571966997 on epoch=82, global_step=1150
06/22/2022 20:46:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/22/2022 20:46:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/22/2022 20:46:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/22/2022 20:46:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/22/2022 20:46:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/22/2022 20:46:22 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7909621947795852 on epoch=85
06/22/2022 20:46:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/22/2022 20:46:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/22/2022 20:46:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/22/2022 20:46:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/22/2022 20:46:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/22/2022 20:46:42 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8457467943189005 on epoch=89
06/22/2022 20:46:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8104760571966997 -> 0.8457467943189005 on epoch=89, global_step=1250
06/22/2022 20:46:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/22/2022 20:46:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/22/2022 20:46:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/22/2022 20:46:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/22/2022 20:46:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/22/2022 20:47:02 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7238471073596522 on epoch=92
06/22/2022 20:47:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/22/2022 20:47:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/22/2022 20:47:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/22/2022 20:47:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/22/2022 20:47:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/22/2022 20:47:21 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6923807870115171 on epoch=96
06/22/2022 20:47:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/22/2022 20:47:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/22/2022 20:47:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/22/2022 20:47:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/22/2022 20:47:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/22/2022 20:47:41 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7364503064627386 on epoch=99
06/22/2022 20:47:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/22/2022 20:47:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/22/2022 20:47:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/22/2022 20:47:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/22/2022 20:47:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/22/2022 20:48:00 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7495238630277563 on epoch=103
06/22/2022 20:48:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/22/2022 20:48:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/22/2022 20:48:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/22/2022 20:48:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/22/2022 20:48:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/22/2022 20:48:20 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7941912609844298 on epoch=107
06/22/2022 20:48:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/22/2022 20:48:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/22/2022 20:48:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/22/2022 20:48:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/22/2022 20:48:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/22/2022 20:48:39 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7319093670558989 on epoch=110
06/22/2022 20:48:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/22/2022 20:48:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/22/2022 20:48:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/22/2022 20:48:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/22/2022 20:48:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/22/2022 20:48:58 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7547913527396903 on epoch=114
06/22/2022 20:49:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/22/2022 20:49:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/22/2022 20:49:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/22/2022 20:49:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/22/2022 20:49:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/22/2022 20:49:18 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.792934220006207 on epoch=117
06/22/2022 20:49:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/22/2022 20:49:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/22/2022 20:49:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/22/2022 20:49:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/22/2022 20:49:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/22/2022 20:49:37 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7977792585226451 on epoch=121
06/22/2022 20:49:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/22/2022 20:49:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/22/2022 20:49:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/22/2022 20:49:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/22/2022 20:49:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/22/2022 20:49:56 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7547913527396903 on epoch=124
06/22/2022 20:49:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/22/2022 20:50:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/22/2022 20:50:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/22/2022 20:50:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/22/2022 20:50:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/22/2022 20:50:15 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7534581886047204 on epoch=128
06/22/2022 20:50:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/22/2022 20:50:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/22/2022 20:50:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/22/2022 20:50:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/22/2022 20:50:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/22/2022 20:50:35 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8630131964809384 on epoch=132
06/22/2022 20:50:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8457467943189005 -> 0.8630131964809384 on epoch=132, global_step=1850
06/22/2022 20:50:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/22/2022 20:50:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/22/2022 20:50:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/22/2022 20:50:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/22/2022 20:50:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/22/2022 20:50:54 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=135
06/22/2022 20:50:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8630131964809384 -> 0.9910627007401202 on epoch=135, global_step=1900
06/22/2022 20:50:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/22/2022 20:50:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/22/2022 20:51:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/22/2022 20:51:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/22/2022 20:51:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/22/2022 20:51:14 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=139
06/22/2022 20:51:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/22/2022 20:51:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/22/2022 20:51:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/22/2022 20:51:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/22/2022 20:51:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/22/2022 20:51:33 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=142
06/22/2022 20:51:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/22/2022 20:51:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/22/2022 20:51:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/22/2022 20:51:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/22/2022 20:51:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/22/2022 20:51:53 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9187894121480459 on epoch=146
06/22/2022 20:51:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/22/2022 20:51:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/22/2022 20:52:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/22/2022 20:52:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/22/2022 20:52:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/22/2022 20:52:13 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=149
06/22/2022 20:52:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/22/2022 20:52:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/22/2022 20:52:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/22/2022 20:52:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/22/2022 20:52:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/22/2022 20:52:32 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=153
06/22/2022 20:52:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/22/2022 20:52:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/22/2022 20:52:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/22/2022 20:52:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/22/2022 20:52:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/22/2022 20:52:51 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=157
06/22/2022 20:52:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/22/2022 20:52:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/22/2022 20:52:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/22/2022 20:53:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/22/2022 20:53:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/22/2022 20:53:11 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=160
06/22/2022 20:53:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/22/2022 20:53:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/22/2022 20:53:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/22/2022 20:53:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/22/2022 20:53:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/22/2022 20:53:30 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=164
06/22/2022 20:53:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/22/2022 20:53:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/22/2022 20:53:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/22/2022 20:53:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/22/2022 20:53:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/22/2022 20:53:49 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=167
06/22/2022 20:53:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/22/2022 20:53:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/22/2022 20:53:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/22/2022 20:53:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/22/2022 20:54:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/22/2022 20:54:08 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=171
06/22/2022 20:54:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/22/2022 20:54:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/22/2022 20:54:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/22/2022 20:54:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/22/2022 20:54:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/22/2022 20:54:27 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=174
06/22/2022 20:54:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/22/2022 20:54:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/22/2022 20:54:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/22/2022 20:54:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/22/2022 20:54:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/22/2022 20:54:46 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.9910627007401202 on epoch=178
06/22/2022 20:54:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/22/2022 20:54:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/22/2022 20:54:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/22/2022 20:54:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/22/2022 20:54:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/22/2022 20:55:06 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=182
06/22/2022 20:55:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/22/2022 20:55:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/22/2022 20:55:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/22/2022 20:55:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/22/2022 20:55:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/22/2022 20:55:25 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=185
06/22/2022 20:55:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/22/2022 20:55:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/22/2022 20:55:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/22/2022 20:55:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/22/2022 20:55:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/22/2022 20:55:44 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=189
06/22/2022 20:55:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/22/2022 20:55:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/22/2022 20:55:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/22/2022 20:55:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/22/2022 20:55:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/22/2022 20:56:03 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=192
06/22/2022 20:56:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/22/2022 20:56:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/22/2022 20:56:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/22/2022 20:56:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/22/2022 20:56:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/22/2022 20:56:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=196
06/22/2022 20:56:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/22/2022 20:56:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/22/2022 20:56:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/22/2022 20:56:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/22/2022 20:56:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/22/2022 20:56:41 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=199
06/22/2022 20:56:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/22/2022 20:56:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/22/2022 20:56:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/22/2022 20:56:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/22/2022 20:56:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/22/2022 20:57:01 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=203
06/22/2022 20:57:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/22/2022 20:57:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/22/2022 20:57:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/22/2022 20:57:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/22/2022 20:57:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/22/2022 20:57:20 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=207
06/22/2022 20:57:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/22/2022 20:57:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/22/2022 20:57:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/22/2022 20:57:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/22/2022 20:57:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/22/2022 20:57:39 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=210
06/22/2022 20:57:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/22/2022 20:57:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/22/2022 20:57:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/22/2022 20:57:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/22/2022 20:57:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/22/2022 20:57:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 20:57:53 - INFO - __main__ - Printing 3 examples
06/22/2022 20:57:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 20:57:53 - INFO - __main__ - ['Animal']
06/22/2022 20:57:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 20:57:53 - INFO - __main__ - ['Animal']
06/22/2022 20:57:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 20:57:53 - INFO - __main__ - ['Animal']
06/22/2022 20:57:53 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:57:53 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:57:53 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 20:57:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 20:57:53 - INFO - __main__ - Printing 3 examples
06/22/2022 20:57:53 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 20:57:53 - INFO - __main__ - ['Animal']
06/22/2022 20:57:53 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 20:57:53 - INFO - __main__ - ['Animal']
06/22/2022 20:57:53 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 20:57:53 - INFO - __main__ - ['Animal']
06/22/2022 20:57:53 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:57:54 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:57:54 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 20:57:58 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=214
06/22/2022 20:57:58 - INFO - __main__ - save last model!
06/22/2022 20:57:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 20:57:58 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 20:57:58 - INFO - __main__ - Printing 3 examples
06/22/2022 20:57:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 20:57:58 - INFO - __main__ - ['Animal']
06/22/2022 20:57:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 20:57:58 - INFO - __main__ - ['Animal']
06/22/2022 20:57:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 20:57:58 - INFO - __main__ - ['Village']
06/22/2022 20:57:58 - INFO - __main__ - Tokenizing Input ...
06/22/2022 20:58:00 - INFO - __main__ - Tokenizing Output ...
06/22/2022 20:58:04 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 20:58:09 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 20:58:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 20:58:10 - INFO - __main__ - Starting training!
06/22/2022 21:00:14 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/22/2022 21:00:14 - INFO - __main__ - Classification-F1 on test data: 0.6193
06/22/2022 21:00:14 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6193324386578175
06/22/2022 21:00:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/22/2022 21:00:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:00:16 - INFO - __main__ - Printing 3 examples
06/22/2022 21:00:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 21:00:16 - INFO - __main__ - ['Animal']
06/22/2022 21:00:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 21:00:16 - INFO - __main__ - ['Animal']
06/22/2022 21:00:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 21:00:16 - INFO - __main__ - ['Animal']
06/22/2022 21:00:16 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:00:16 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:00:16 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 21:00:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:00:16 - INFO - __main__ - Printing 3 examples
06/22/2022 21:00:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 21:00:16 - INFO - __main__ - ['Animal']
06/22/2022 21:00:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 21:00:16 - INFO - __main__ - ['Animal']
06/22/2022 21:00:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 21:00:16 - INFO - __main__ - ['Animal']
06/22/2022 21:00:16 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:00:16 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:00:17 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 21:00:32 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 21:00:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 21:00:33 - INFO - __main__ - Starting training!
06/22/2022 21:00:37 - INFO - __main__ - Step 10 Global step 10 Train loss 6.75 on epoch=0
06/22/2022 21:00:39 - INFO - __main__ - Step 20 Global step 20 Train loss 4.82 on epoch=1
06/22/2022 21:00:42 - INFO - __main__ - Step 30 Global step 30 Train loss 4.13 on epoch=2
06/22/2022 21:00:44 - INFO - __main__ - Step 40 Global step 40 Train loss 3.67 on epoch=2
06/22/2022 21:00:47 - INFO - __main__ - Step 50 Global step 50 Train loss 3.50 on epoch=3
06/22/2022 21:00:52 - INFO - __main__ - Global step 50 Train loss 4.57 Classification-F1 0.048410067638512445 on epoch=3
06/22/2022 21:00:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.048410067638512445 on epoch=3, global_step=50
06/22/2022 21:00:55 - INFO - __main__ - Step 60 Global step 60 Train loss 3.36 on epoch=4
06/22/2022 21:00:57 - INFO - __main__ - Step 70 Global step 70 Train loss 2.61 on epoch=4
06/22/2022 21:01:00 - INFO - __main__ - Step 80 Global step 80 Train loss 2.72 on epoch=5
06/22/2022 21:01:03 - INFO - __main__ - Step 90 Global step 90 Train loss 2.53 on epoch=6
06/22/2022 21:01:05 - INFO - __main__ - Step 100 Global step 100 Train loss 2.34 on epoch=7
06/22/2022 21:01:10 - INFO - __main__ - Global step 100 Train loss 2.71 Classification-F1 0.07822048604731117 on epoch=7
06/22/2022 21:01:10 - INFO - __main__ - Saving model with best Classification-F1: 0.048410067638512445 -> 0.07822048604731117 on epoch=7, global_step=100
06/22/2022 21:01:13 - INFO - __main__ - Step 110 Global step 110 Train loss 2.17 on epoch=7
06/22/2022 21:01:16 - INFO - __main__ - Step 120 Global step 120 Train loss 2.01 on epoch=8
06/22/2022 21:01:18 - INFO - __main__ - Step 130 Global step 130 Train loss 2.10 on epoch=9
06/22/2022 21:01:21 - INFO - __main__ - Step 140 Global step 140 Train loss 1.60 on epoch=9
06/22/2022 21:01:23 - INFO - __main__ - Step 150 Global step 150 Train loss 1.85 on epoch=10
06/22/2022 21:01:29 - INFO - __main__ - Global step 150 Train loss 1.95 Classification-F1 0.12276567518503002 on epoch=10
06/22/2022 21:01:29 - INFO - __main__ - Saving model with best Classification-F1: 0.07822048604731117 -> 0.12276567518503002 on epoch=10, global_step=150
06/22/2022 21:01:31 - INFO - __main__ - Step 160 Global step 160 Train loss 1.57 on epoch=11
06/22/2022 21:01:34 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=12
06/22/2022 21:01:36 - INFO - __main__ - Step 180 Global step 180 Train loss 1.24 on epoch=12
06/22/2022 21:01:39 - INFO - __main__ - Step 190 Global step 190 Train loss 1.33 on epoch=13
06/22/2022 21:01:42 - INFO - __main__ - Step 200 Global step 200 Train loss 1.24 on epoch=14
06/22/2022 21:01:47 - INFO - __main__ - Global step 200 Train loss 1.37 Classification-F1 0.2280641554460446 on epoch=14
06/22/2022 21:01:47 - INFO - __main__ - Saving model with best Classification-F1: 0.12276567518503002 -> 0.2280641554460446 on epoch=14, global_step=200
06/22/2022 21:01:50 - INFO - __main__ - Step 210 Global step 210 Train loss 1.05 on epoch=14
06/22/2022 21:01:52 - INFO - __main__ - Step 220 Global step 220 Train loss 1.06 on epoch=15
06/22/2022 21:01:55 - INFO - __main__ - Step 230 Global step 230 Train loss 1.09 on epoch=16
06/22/2022 21:01:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=17
06/22/2022 21:02:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=17
06/22/2022 21:02:07 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.318035515526555 on epoch=17
06/22/2022 21:02:07 - INFO - __main__ - Saving model with best Classification-F1: 0.2280641554460446 -> 0.318035515526555 on epoch=17, global_step=250
06/22/2022 21:02:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=18
06/22/2022 21:02:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.87 on epoch=19
06/22/2022 21:02:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.64 on epoch=19
06/22/2022 21:02:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=20
06/22/2022 21:02:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.55 on epoch=21
06/22/2022 21:02:26 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.4937809347624175 on epoch=21
06/22/2022 21:02:26 - INFO - __main__ - Saving model with best Classification-F1: 0.318035515526555 -> 0.4937809347624175 on epoch=21, global_step=300
06/22/2022 21:02:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=22
06/22/2022 21:02:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.52 on epoch=22
06/22/2022 21:02:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.57 on epoch=23
06/22/2022 21:02:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=24
06/22/2022 21:02:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/22/2022 21:02:46 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.47027648317970905 on epoch=24
06/22/2022 21:02:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=25
06/22/2022 21:02:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=26
06/22/2022 21:02:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=27
06/22/2022 21:02:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=27
06/22/2022 21:02:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
06/22/2022 21:03:06 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.6248441646345972 on epoch=28
06/22/2022 21:03:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4937809347624175 -> 0.6248441646345972 on epoch=28, global_step=400
06/22/2022 21:03:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=29
06/22/2022 21:03:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=29
06/22/2022 21:03:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
06/22/2022 21:03:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=31
06/22/2022 21:03:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=32
06/22/2022 21:03:26 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.585168255963187 on epoch=32
06/22/2022 21:03:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
06/22/2022 21:03:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=33
06/22/2022 21:03:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
06/22/2022 21:03:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/22/2022 21:03:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=35
06/22/2022 21:03:46 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.7150671834139577 on epoch=35
06/22/2022 21:03:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6248441646345972 -> 0.7150671834139577 on epoch=35, global_step=500
06/22/2022 21:03:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
06/22/2022 21:03:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
06/22/2022 21:03:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
06/22/2022 21:03:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=38
06/22/2022 21:03:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
06/22/2022 21:04:06 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7972759158359284 on epoch=39
06/22/2022 21:04:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7150671834139577 -> 0.7972759158359284 on epoch=39, global_step=550
06/22/2022 21:04:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
06/22/2022 21:04:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=40
06/22/2022 21:04:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
06/22/2022 21:04:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=42
06/22/2022 21:04:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=42
06/22/2022 21:04:27 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.7617300946997342 on epoch=42
06/22/2022 21:04:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=43
06/22/2022 21:04:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=44
06/22/2022 21:04:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
06/22/2022 21:04:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=45
06/22/2022 21:04:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
06/22/2022 21:04:47 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.7203491699459441 on epoch=46
06/22/2022 21:04:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/22/2022 21:04:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
06/22/2022 21:04:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/22/2022 21:04:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/22/2022 21:05:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
06/22/2022 21:05:08 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7505965387132371 on epoch=49
06/22/2022 21:05:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
06/22/2022 21:05:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
06/22/2022 21:05:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
06/22/2022 21:05:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/22/2022 21:05:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
06/22/2022 21:05:28 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.7984175317030016 on epoch=53
06/22/2022 21:05:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7972759158359284 -> 0.7984175317030016 on epoch=53, global_step=750
06/22/2022 21:05:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/22/2022 21:05:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/22/2022 21:05:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/22/2022 21:05:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=56
06/22/2022 21:05:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/22/2022 21:05:48 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.748799751054467 on epoch=57
06/22/2022 21:05:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
06/22/2022 21:05:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
06/22/2022 21:05:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
06/22/2022 21:05:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
06/22/2022 21:06:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/22/2022 21:06:09 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7043236393493255 on epoch=60
06/22/2022 21:06:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/22/2022 21:06:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=62
06/22/2022 21:06:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=62
06/22/2022 21:06:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
06/22/2022 21:06:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
06/22/2022 21:06:29 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7554811314889067 on epoch=64
06/22/2022 21:06:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/22/2022 21:06:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=65
06/22/2022 21:06:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/22/2022 21:06:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/22/2022 21:06:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
06/22/2022 21:06:50 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7471942537380177 on epoch=67
06/22/2022 21:06:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
06/22/2022 21:06:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/22/2022 21:06:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/22/2022 21:07:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/22/2022 21:07:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/22/2022 21:07:10 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7071997648847744 on epoch=71
06/22/2022 21:07:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/22/2022 21:07:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/22/2022 21:07:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/22/2022 21:07:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
06/22/2022 21:07:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/22/2022 21:07:30 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7394221764952316 on epoch=74
06/22/2022 21:07:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/22/2022 21:07:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/22/2022 21:07:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/22/2022 21:07:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/22/2022 21:07:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/22/2022 21:07:51 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.730518198864973 on epoch=78
06/22/2022 21:07:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/22/2022 21:07:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/22/2022 21:07:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/22/2022 21:08:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/22/2022 21:08:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/22/2022 21:08:11 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7709020042985887 on epoch=82
06/22/2022 21:08:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/22/2022 21:08:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/22/2022 21:08:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/22/2022 21:08:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
06/22/2022 21:08:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/22/2022 21:08:32 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8254022858861568 on epoch=85
06/22/2022 21:08:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7984175317030016 -> 0.8254022858861568 on epoch=85, global_step=1200
06/22/2022 21:08:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/22/2022 21:08:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/22/2022 21:08:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/22/2022 21:08:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/22/2022 21:08:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/22/2022 21:08:51 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8275866211587274 on epoch=89
06/22/2022 21:08:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8254022858861568 -> 0.8275866211587274 on epoch=89, global_step=1250
06/22/2022 21:08:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=89
06/22/2022 21:08:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
06/22/2022 21:08:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/22/2022 21:09:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/22/2022 21:09:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/22/2022 21:09:11 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8238452843291553 on epoch=92
06/22/2022 21:09:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/22/2022 21:09:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/22/2022 21:09:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/22/2022 21:09:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/22/2022 21:09:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/22/2022 21:09:31 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7060052235124641 on epoch=96
06/22/2022 21:09:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/22/2022 21:09:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/22/2022 21:09:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/22/2022 21:09:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/22/2022 21:09:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/22/2022 21:09:51 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6032432259148813 on epoch=99
06/22/2022 21:09:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/22/2022 21:09:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/22/2022 21:09:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/22/2022 21:10:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/22/2022 21:10:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/22/2022 21:10:12 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7573139588766333 on epoch=103
06/22/2022 21:10:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/22/2022 21:10:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/22/2022 21:10:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/22/2022 21:10:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/22/2022 21:10:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/22/2022 21:10:32 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7910214700942866 on epoch=107
06/22/2022 21:10:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/22/2022 21:10:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/22/2022 21:10:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/22/2022 21:10:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/22/2022 21:10:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/22/2022 21:10:53 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7496077893185791 on epoch=110
06/22/2022 21:10:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/22/2022 21:10:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/22/2022 21:11:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/22/2022 21:11:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/22/2022 21:11:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/22/2022 21:11:13 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8298847015537058 on epoch=114
06/22/2022 21:11:13 - INFO - __main__ - Saving model with best Classification-F1: 0.8275866211587274 -> 0.8298847015537058 on epoch=114, global_step=1600
06/22/2022 21:11:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/22/2022 21:11:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/22/2022 21:11:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
06/22/2022 21:11:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/22/2022 21:11:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/22/2022 21:11:32 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8264764410162893 on epoch=117
06/22/2022 21:11:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/22/2022 21:11:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/22/2022 21:11:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
06/22/2022 21:11:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/22/2022 21:11:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/22/2022 21:11:52 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.833736990397332 on epoch=121
06/22/2022 21:11:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8298847015537058 -> 0.833736990397332 on epoch=121, global_step=1700
06/22/2022 21:11:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/22/2022 21:11:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/22/2022 21:12:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/22/2022 21:12:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/22/2022 21:12:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/22/2022 21:12:12 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.83069403714565 on epoch=124
06/22/2022 21:12:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/22/2022 21:12:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/22/2022 21:12:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/22/2022 21:12:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/22/2022 21:12:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/22/2022 21:12:32 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9071306381790253 on epoch=128
06/22/2022 21:12:32 - INFO - __main__ - Saving model with best Classification-F1: 0.833736990397332 -> 0.9071306381790253 on epoch=128, global_step=1800
06/22/2022 21:12:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/22/2022 21:12:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/22/2022 21:12:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/22/2022 21:12:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/22/2022 21:12:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/22/2022 21:12:51 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8504081544641318 on epoch=132
06/22/2022 21:12:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/22/2022 21:12:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/22/2022 21:12:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/22/2022 21:13:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/22/2022 21:13:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/22/2022 21:13:11 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8389950883635656 on epoch=135
06/22/2022 21:13:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/22/2022 21:13:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
06/22/2022 21:13:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/22/2022 21:13:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/22/2022 21:13:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/22/2022 21:13:30 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8551700592260365 on epoch=139
06/22/2022 21:13:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/22/2022 21:13:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/22/2022 21:13:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/22/2022 21:13:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/22/2022 21:13:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/22/2022 21:13:50 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.905562622561412 on epoch=142
06/22/2022 21:13:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/22/2022 21:13:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/22/2022 21:13:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/22/2022 21:14:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/22/2022 21:14:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/22/2022 21:14:09 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9098481246410318 on epoch=146
06/22/2022 21:14:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9071306381790253 -> 0.9098481246410318 on epoch=146, global_step=2050
06/22/2022 21:14:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/22/2022 21:14:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/22/2022 21:14:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/22/2022 21:14:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/22/2022 21:14:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/22/2022 21:14:29 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7979195017857257 on epoch=149
06/22/2022 21:14:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/22/2022 21:14:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/22/2022 21:14:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/22/2022 21:14:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/22/2022 21:14:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/22/2022 21:14:48 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9180953022999743 on epoch=153
06/22/2022 21:14:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9098481246410318 -> 0.9180953022999743 on epoch=153, global_step=2150
06/22/2022 21:14:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/22/2022 21:14:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/22/2022 21:14:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/22/2022 21:14:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.19 on epoch=156
06/22/2022 21:15:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/22/2022 21:15:07 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.9180953022999743 on epoch=157
06/22/2022 21:15:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/22/2022 21:15:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/22/2022 21:15:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/22/2022 21:15:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/22/2022 21:15:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/22/2022 21:15:26 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8505463814924797 on epoch=160
06/22/2022 21:15:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/22/2022 21:15:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/22/2022 21:15:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/22/2022 21:15:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/22/2022 21:15:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/22/2022 21:15:46 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8544526314924796 on epoch=164
06/22/2022 21:15:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/22/2022 21:15:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/22/2022 21:15:54 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/22/2022 21:15:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/22/2022 21:15:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/22/2022 21:16:06 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8569156856796718 on epoch=167
06/22/2022 21:16:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/22/2022 21:16:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/22/2022 21:16:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/22/2022 21:16:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/22/2022 21:16:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/22/2022 21:16:25 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8065088806396911 on epoch=171
06/22/2022 21:16:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/22/2022 21:16:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/22/2022 21:16:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/22/2022 21:16:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/22/2022 21:16:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/22/2022 21:16:45 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9145941387307611 on epoch=174
06/22/2022 21:16:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/22/2022 21:16:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/22/2022 21:16:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/22/2022 21:16:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/22/2022 21:16:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/22/2022 21:17:05 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8592145362543845 on epoch=178
06/22/2022 21:17:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/22/2022 21:17:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/22/2022 21:17:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/22/2022 21:17:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/22/2022 21:17:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/22/2022 21:17:25 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9145941387307611 on epoch=182
06/22/2022 21:17:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/22/2022 21:17:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/22/2022 21:17:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/22/2022 21:17:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/22/2022 21:17:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/22/2022 21:17:45 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9102800299005234 on epoch=185
06/22/2022 21:17:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/22/2022 21:17:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/22/2022 21:17:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/22/2022 21:17:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/22/2022 21:17:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/22/2022 21:18:04 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9164955053380103 on epoch=189
06/22/2022 21:18:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/22/2022 21:18:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/22/2022 21:18:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/22/2022 21:18:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/22/2022 21:18:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/22/2022 21:18:23 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=192
06/22/2022 21:18:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/22/2022 21:18:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/22/2022 21:18:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/22/2022 21:18:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/22/2022 21:18:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/22/2022 21:18:43 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9080147298411057 on epoch=196
06/22/2022 21:18:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/22/2022 21:18:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/22/2022 21:18:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/22/2022 21:18:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/22/2022 21:18:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/22/2022 21:19:02 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8504081544641318 on epoch=199
06/22/2022 21:19:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/22/2022 21:19:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/22/2022 21:19:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/22/2022 21:19:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/22/2022 21:19:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/22/2022 21:19:21 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9121813965077723 on epoch=203
06/22/2022 21:19:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/22/2022 21:19:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/22/2022 21:19:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/22/2022 21:19:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/22/2022 21:19:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/22/2022 21:19:41 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9097292892280786 on epoch=207
06/22/2022 21:19:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/22/2022 21:19:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/22/2022 21:19:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/22/2022 21:19:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/22/2022 21:19:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/22/2022 21:20:00 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9205474095796676 on epoch=210
06/22/2022 21:20:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9180953022999743 -> 0.9205474095796676 on epoch=210, global_step=2950
06/22/2022 21:20:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/22/2022 21:20:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/22/2022 21:20:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/22/2022 21:20:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/22/2022 21:20:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/22/2022 21:20:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:20:14 - INFO - __main__ - Printing 3 examples
06/22/2022 21:20:14 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 21:20:14 - INFO - __main__ - ['Animal']
06/22/2022 21:20:14 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 21:20:14 - INFO - __main__ - ['Animal']
06/22/2022 21:20:14 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 21:20:14 - INFO - __main__ - ['Animal']
06/22/2022 21:20:14 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:20:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:20:15 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 21:20:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:20:15 - INFO - __main__ - Printing 3 examples
06/22/2022 21:20:15 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 21:20:15 - INFO - __main__ - ['Animal']
06/22/2022 21:20:15 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 21:20:15 - INFO - __main__ - ['Animal']
06/22/2022 21:20:15 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 21:20:15 - INFO - __main__ - ['Animal']
06/22/2022 21:20:15 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:20:15 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:20:15 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 21:20:19 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9144753033178081 on epoch=214
06/22/2022 21:20:19 - INFO - __main__ - save last model!
06/22/2022 21:20:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 21:20:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 21:20:19 - INFO - __main__ - Printing 3 examples
06/22/2022 21:20:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 21:20:19 - INFO - __main__ - ['Animal']
06/22/2022 21:20:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 21:20:19 - INFO - __main__ - ['Animal']
06/22/2022 21:20:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 21:20:19 - INFO - __main__ - ['Village']
06/22/2022 21:20:19 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:20:21 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:20:25 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 21:20:30 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 21:20:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 21:20:31 - INFO - __main__ - Starting training!
06/22/2022 21:22:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/22/2022 21:22:34 - INFO - __main__ - Classification-F1 on test data: 0.5023
06/22/2022 21:22:35 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9205474095796676, test_performance=0.5022728998691975
06/22/2022 21:22:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/22/2022 21:22:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:22:36 - INFO - __main__ - Printing 3 examples
06/22/2022 21:22:36 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 21:22:36 - INFO - __main__ - ['Animal']
06/22/2022 21:22:36 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 21:22:36 - INFO - __main__ - ['Animal']
06/22/2022 21:22:36 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 21:22:36 - INFO - __main__ - ['Animal']
06/22/2022 21:22:36 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:22:36 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:22:36 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 21:22:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:22:36 - INFO - __main__ - Printing 3 examples
06/22/2022 21:22:36 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 21:22:36 - INFO - __main__ - ['Animal']
06/22/2022 21:22:36 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 21:22:36 - INFO - __main__ - ['Animal']
06/22/2022 21:22:36 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 21:22:36 - INFO - __main__ - ['Animal']
06/22/2022 21:22:36 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:22:36 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:22:36 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 21:22:52 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 21:22:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 21:22:52 - INFO - __main__ - Starting training!
06/22/2022 21:22:56 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=0
06/22/2022 21:22:59 - INFO - __main__ - Step 20 Global step 20 Train loss 5.33 on epoch=1
06/22/2022 21:23:01 - INFO - __main__ - Step 30 Global step 30 Train loss 4.35 on epoch=2
06/22/2022 21:23:04 - INFO - __main__ - Step 40 Global step 40 Train loss 4.10 on epoch=2
06/22/2022 21:23:06 - INFO - __main__ - Step 50 Global step 50 Train loss 3.82 on epoch=3
06/22/2022 21:23:12 - INFO - __main__ - Global step 50 Train loss 4.86 Classification-F1 0.046624106398052444 on epoch=3
06/22/2022 21:23:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.046624106398052444 on epoch=3, global_step=50
06/22/2022 21:23:14 - INFO - __main__ - Step 60 Global step 60 Train loss 3.77 on epoch=4
06/22/2022 21:23:17 - INFO - __main__ - Step 70 Global step 70 Train loss 3.08 on epoch=4
06/22/2022 21:23:19 - INFO - __main__ - Step 80 Global step 80 Train loss 3.35 on epoch=5
06/22/2022 21:23:22 - INFO - __main__ - Step 90 Global step 90 Train loss 2.89 on epoch=6
06/22/2022 21:23:24 - INFO - __main__ - Step 100 Global step 100 Train loss 2.68 on epoch=7
06/22/2022 21:23:29 - INFO - __main__ - Global step 100 Train loss 3.15 Classification-F1 0.05597688557840361 on epoch=7
06/22/2022 21:23:30 - INFO - __main__ - Saving model with best Classification-F1: 0.046624106398052444 -> 0.05597688557840361 on epoch=7, global_step=100
06/22/2022 21:23:32 - INFO - __main__ - Step 110 Global step 110 Train loss 2.64 on epoch=7
06/22/2022 21:23:35 - INFO - __main__ - Step 120 Global step 120 Train loss 2.44 on epoch=8
06/22/2022 21:23:37 - INFO - __main__ - Step 130 Global step 130 Train loss 2.62 on epoch=9
06/22/2022 21:23:40 - INFO - __main__ - Step 140 Global step 140 Train loss 2.02 on epoch=9
06/22/2022 21:23:42 - INFO - __main__ - Step 150 Global step 150 Train loss 2.16 on epoch=10
06/22/2022 21:23:48 - INFO - __main__ - Global step 150 Train loss 2.37 Classification-F1 0.0946324369597192 on epoch=10
06/22/2022 21:23:48 - INFO - __main__ - Saving model with best Classification-F1: 0.05597688557840361 -> 0.0946324369597192 on epoch=10, global_step=150
06/22/2022 21:23:50 - INFO - __main__ - Step 160 Global step 160 Train loss 1.93 on epoch=11
06/22/2022 21:23:53 - INFO - __main__ - Step 170 Global step 170 Train loss 1.86 on epoch=12
06/22/2022 21:23:56 - INFO - __main__ - Step 180 Global step 180 Train loss 1.79 on epoch=12
06/22/2022 21:23:58 - INFO - __main__ - Step 190 Global step 190 Train loss 1.66 on epoch=13
06/22/2022 21:24:01 - INFO - __main__ - Step 200 Global step 200 Train loss 1.80 on epoch=14
06/22/2022 21:24:06 - INFO - __main__ - Global step 200 Train loss 1.81 Classification-F1 0.12008373939647393 on epoch=14
06/22/2022 21:24:06 - INFO - __main__ - Saving model with best Classification-F1: 0.0946324369597192 -> 0.12008373939647393 on epoch=14, global_step=200
06/22/2022 21:24:09 - INFO - __main__ - Step 210 Global step 210 Train loss 1.42 on epoch=14
06/22/2022 21:24:11 - INFO - __main__ - Step 220 Global step 220 Train loss 1.60 on epoch=15
06/22/2022 21:24:14 - INFO - __main__ - Step 230 Global step 230 Train loss 1.39 on epoch=16
06/22/2022 21:24:16 - INFO - __main__ - Step 240 Global step 240 Train loss 1.22 on epoch=17
06/22/2022 21:24:19 - INFO - __main__ - Step 250 Global step 250 Train loss 1.19 on epoch=17
06/22/2022 21:24:24 - INFO - __main__ - Global step 250 Train loss 1.36 Classification-F1 0.16965414370630727 on epoch=17
06/22/2022 21:24:25 - INFO - __main__ - Saving model with best Classification-F1: 0.12008373939647393 -> 0.16965414370630727 on epoch=17, global_step=250
06/22/2022 21:24:27 - INFO - __main__ - Step 260 Global step 260 Train loss 1.07 on epoch=18
06/22/2022 21:24:30 - INFO - __main__ - Step 270 Global step 270 Train loss 1.25 on epoch=19
06/22/2022 21:24:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.88 on epoch=19
06/22/2022 21:24:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.99 on epoch=20
06/22/2022 21:24:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.89 on epoch=21
06/22/2022 21:24:43 - INFO - __main__ - Global step 300 Train loss 1.01 Classification-F1 0.2452506802968669 on epoch=21
06/22/2022 21:24:43 - INFO - __main__ - Saving model with best Classification-F1: 0.16965414370630727 -> 0.2452506802968669 on epoch=21, global_step=300
06/22/2022 21:24:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.93 on epoch=22
06/22/2022 21:24:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=22
06/22/2022 21:24:51 - INFO - __main__ - Step 330 Global step 330 Train loss 0.79 on epoch=23
06/22/2022 21:24:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.83 on epoch=24
06/22/2022 21:24:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=24
06/22/2022 21:25:02 - INFO - __main__ - Global step 350 Train loss 0.80 Classification-F1 0.37438338018309864 on epoch=24
06/22/2022 21:25:03 - INFO - __main__ - Saving model with best Classification-F1: 0.2452506802968669 -> 0.37438338018309864 on epoch=24, global_step=350
06/22/2022 21:25:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.73 on epoch=25
06/22/2022 21:25:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.62 on epoch=26
06/22/2022 21:25:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.70 on epoch=27
06/22/2022 21:25:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.60 on epoch=27
06/22/2022 21:25:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=28
06/22/2022 21:25:22 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.4903067895060632 on epoch=28
06/22/2022 21:25:22 - INFO - __main__ - Saving model with best Classification-F1: 0.37438338018309864 -> 0.4903067895060632 on epoch=28, global_step=400
06/22/2022 21:25:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
06/22/2022 21:25:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=29
06/22/2022 21:25:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.48 on epoch=30
06/22/2022 21:25:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=31
06/22/2022 21:25:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=32
06/22/2022 21:25:43 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.5812446042225163 on epoch=32
06/22/2022 21:25:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4903067895060632 -> 0.5812446042225163 on epoch=32, global_step=450
06/22/2022 21:25:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=32
06/22/2022 21:25:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=33
06/22/2022 21:25:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=34
06/22/2022 21:25:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=34
06/22/2022 21:25:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=35
06/22/2022 21:26:03 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.6669672239202019 on epoch=35
06/22/2022 21:26:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5812446042225163 -> 0.6669672239202019 on epoch=35, global_step=500
06/22/2022 21:26:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=36
06/22/2022 21:26:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
06/22/2022 21:26:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/22/2022 21:26:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=38
06/22/2022 21:26:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=39
06/22/2022 21:26:24 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.6135350558241072 on epoch=39
06/22/2022 21:26:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
06/22/2022 21:26:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
06/22/2022 21:26:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=41
06/22/2022 21:26:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=42
06/22/2022 21:26:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
06/22/2022 21:26:44 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6080380688572182 on epoch=42
06/22/2022 21:26:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=43
06/22/2022 21:26:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=44
06/22/2022 21:26:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
06/22/2022 21:26:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=45
06/22/2022 21:26:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
06/22/2022 21:27:04 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.6037205213773089 on epoch=46
06/22/2022 21:27:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=47
06/22/2022 21:27:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/22/2022 21:27:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=48
06/22/2022 21:27:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=49
06/22/2022 21:27:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=49
06/22/2022 21:27:25 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.6356028767215826 on epoch=49
06/22/2022 21:27:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=50
06/22/2022 21:27:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=51
06/22/2022 21:27:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/22/2022 21:27:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=52
06/22/2022 21:27:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=53
06/22/2022 21:27:46 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6847315672443007 on epoch=53
06/22/2022 21:27:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6669672239202019 -> 0.6847315672443007 on epoch=53, global_step=750
06/22/2022 21:27:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=54
06/22/2022 21:27:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
06/22/2022 21:27:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/22/2022 21:27:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
06/22/2022 21:27:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=57
06/22/2022 21:28:06 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.6325587947789086 on epoch=57
06/22/2022 21:28:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/22/2022 21:28:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
06/22/2022 21:28:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=59
06/22/2022 21:28:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/22/2022 21:28:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
06/22/2022 21:28:27 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.6251643450635387 on epoch=60
06/22/2022 21:28:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=61
06/22/2022 21:28:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
06/22/2022 21:28:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
06/22/2022 21:28:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=63
06/22/2022 21:28:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
06/22/2022 21:28:48 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.7768872309432082 on epoch=64
06/22/2022 21:28:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6847315672443007 -> 0.7768872309432082 on epoch=64, global_step=900
06/22/2022 21:28:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
06/22/2022 21:28:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=65
06/22/2022 21:28:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/22/2022 21:28:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=67
06/22/2022 21:29:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/22/2022 21:29:09 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.6995785256103093 on epoch=67
06/22/2022 21:29:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
06/22/2022 21:29:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=69
06/22/2022 21:29:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=69
06/22/2022 21:29:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/22/2022 21:29:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/22/2022 21:29:30 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7518046609006714 on epoch=71
06/22/2022 21:29:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=72
06/22/2022 21:29:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/22/2022 21:29:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
06/22/2022 21:29:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
06/22/2022 21:29:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/22/2022 21:29:50 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.8040884224245854 on epoch=74
06/22/2022 21:29:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7768872309432082 -> 0.8040884224245854 on epoch=74, global_step=1050
06/22/2022 21:29:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
06/22/2022 21:29:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
06/22/2022 21:29:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
06/22/2022 21:30:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/22/2022 21:30:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/22/2022 21:30:11 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7600117776770395 on epoch=78
06/22/2022 21:30:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=79
06/22/2022 21:30:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
06/22/2022 21:30:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
06/22/2022 21:30:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/22/2022 21:30:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
06/22/2022 21:30:31 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7647214447010742 on epoch=82
06/22/2022 21:30:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
06/22/2022 21:30:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
06/22/2022 21:30:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=84
06/22/2022 21:30:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
06/22/2022 21:30:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/22/2022 21:30:51 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.7162113137601254 on epoch=85
06/22/2022 21:30:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/22/2022 21:30:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/22/2022 21:30:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/22/2022 21:31:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/22/2022 21:31:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/22/2022 21:31:11 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7729367587987412 on epoch=89
06/22/2022 21:31:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=89
06/22/2022 21:31:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/22/2022 21:31:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/22/2022 21:31:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=92
06/22/2022 21:31:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/22/2022 21:31:31 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.7535871920949674 on epoch=92
06/22/2022 21:31:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/22/2022 21:31:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/22/2022 21:31:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/22/2022 21:31:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/22/2022 21:31:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=96
06/22/2022 21:31:52 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7638852950759971 on epoch=96
06/22/2022 21:31:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/22/2022 21:31:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=97
06/22/2022 21:31:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/22/2022 21:32:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/22/2022 21:32:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/22/2022 21:32:12 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7683670877930839 on epoch=99
06/22/2022 21:32:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/22/2022 21:32:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/22/2022 21:32:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/22/2022 21:32:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/22/2022 21:32:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/22/2022 21:32:32 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.74970735888249 on epoch=103
06/22/2022 21:32:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/22/2022 21:32:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/22/2022 21:32:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=105
06/22/2022 21:32:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/22/2022 21:32:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
06/22/2022 21:32:52 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7921013468926182 on epoch=107
06/22/2022 21:32:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/22/2022 21:32:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
06/22/2022 21:33:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/22/2022 21:33:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/22/2022 21:33:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/22/2022 21:33:12 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.768854974569898 on epoch=110
06/22/2022 21:33:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
06/22/2022 21:33:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/22/2022 21:33:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/22/2022 21:33:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/22/2022 21:33:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/22/2022 21:33:32 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7227642224479669 on epoch=114
06/22/2022 21:33:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/22/2022 21:33:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/22/2022 21:33:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/22/2022 21:33:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/22/2022 21:33:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/22/2022 21:33:52 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7647496604299819 on epoch=117
06/22/2022 21:33:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/22/2022 21:33:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/22/2022 21:34:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/22/2022 21:34:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/22/2022 21:34:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/22/2022 21:34:12 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.8194589566031691 on epoch=121
06/22/2022 21:34:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8040884224245854 -> 0.8194589566031691 on epoch=121, global_step=1700
06/22/2022 21:34:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=122
06/22/2022 21:34:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/22/2022 21:34:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
06/22/2022 21:34:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=124
06/22/2022 21:34:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=124
06/22/2022 21:34:32 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.8146970518412644 on epoch=124
06/22/2022 21:34:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/22/2022 21:34:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/22/2022 21:34:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
06/22/2022 21:34:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/22/2022 21:34:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/22/2022 21:34:52 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.738721816520678 on epoch=128
06/22/2022 21:34:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/22/2022 21:34:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/22/2022 21:34:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/22/2022 21:35:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/22/2022 21:35:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/22/2022 21:35:11 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.772397584184614 on epoch=132
06/22/2022 21:35:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/22/2022 21:35:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/22/2022 21:35:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/22/2022 21:35:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/22/2022 21:35:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/22/2022 21:35:31 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7959967273283491 on epoch=135
06/22/2022 21:35:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/22/2022 21:35:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/22/2022 21:35:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/22/2022 21:35:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/22/2022 21:35:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/22/2022 21:35:51 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7060615846132605 on epoch=139
06/22/2022 21:35:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/22/2022 21:35:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/22/2022 21:35:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/22/2022 21:36:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/22/2022 21:36:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/22/2022 21:36:11 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8468144210169153 on epoch=142
06/22/2022 21:36:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8194589566031691 -> 0.8468144210169153 on epoch=142, global_step=2000
06/22/2022 21:36:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/22/2022 21:36:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
06/22/2022 21:36:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/22/2022 21:36:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/22/2022 21:36:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/22/2022 21:36:31 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8513713989994826 on epoch=146
06/22/2022 21:36:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8468144210169153 -> 0.8513713989994826 on epoch=146, global_step=2050
06/22/2022 21:36:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/22/2022 21:36:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/22/2022 21:36:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/22/2022 21:36:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/22/2022 21:36:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/22/2022 21:36:50 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9144753033178081 on epoch=149
06/22/2022 21:36:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8513713989994826 -> 0.9144753033178081 on epoch=149, global_step=2100
06/22/2022 21:36:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/22/2022 21:36:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/22/2022 21:36:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/22/2022 21:37:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/22/2022 21:37:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/22/2022 21:37:10 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=153
06/22/2022 21:37:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9144753033178081 -> 0.9910627007401202 on epoch=153, global_step=2150
06/22/2022 21:37:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/22/2022 21:37:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/22/2022 21:37:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/22/2022 21:37:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/22/2022 21:37:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/22/2022 21:37:30 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=157
06/22/2022 21:37:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/22/2022 21:37:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/22/2022 21:37:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/22/2022 21:37:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/22/2022 21:37:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/22/2022 21:37:50 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=160
06/22/2022 21:37:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/22/2022 21:37:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/22/2022 21:37:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/22/2022 21:38:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/22/2022 21:38:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/22/2022 21:38:10 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9185312805474095 on epoch=164
06/22/2022 21:38:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/22/2022 21:38:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/22/2022 21:38:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/22/2022 21:38:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/22/2022 21:38:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/22/2022 21:38:30 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9186746497230369 on epoch=167
06/22/2022 21:38:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/22/2022 21:38:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/22/2022 21:38:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/22/2022 21:38:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/22/2022 21:38:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/22/2022 21:38:50 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=171
06/22/2022 21:38:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/22/2022 21:38:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/22/2022 21:38:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/22/2022 21:39:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/22/2022 21:39:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/22/2022 21:39:09 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=174
06/22/2022 21:39:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/22/2022 21:39:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/22/2022 21:39:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/22/2022 21:39:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/22/2022 21:39:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/22/2022 21:39:29 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=178
06/22/2022 21:39:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/22/2022 21:39:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/22/2022 21:39:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/22/2022 21:39:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/22/2022 21:39:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/22/2022 21:39:49 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9865984150258343 on epoch=182
06/22/2022 21:39:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/22/2022 21:39:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/22/2022 21:39:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/22/2022 21:40:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/22/2022 21:40:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/22/2022 21:40:09 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=185
06/22/2022 21:40:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/22/2022 21:40:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/22/2022 21:40:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/22/2022 21:40:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/22/2022 21:40:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/22/2022 21:40:29 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=189
06/22/2022 21:40:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/22/2022 21:40:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/22/2022 21:40:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/22/2022 21:40:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/22/2022 21:40:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/22/2022 21:40:48 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9820991153059465 on epoch=192
06/22/2022 21:40:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/22/2022 21:40:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/22/2022 21:40:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/22/2022 21:40:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/22/2022 21:41:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/22/2022 21:41:08 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9776348295916607 on epoch=196
06/22/2022 21:41:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/22/2022 21:41:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/22/2022 21:41:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/22/2022 21:41:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/22/2022 21:41:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/22/2022 21:41:28 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=199
06/22/2022 21:41:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/22/2022 21:41:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/22/2022 21:41:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/22/2022 21:41:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/22/2022 21:41:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/22/2022 21:41:47 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=203
06/22/2022 21:41:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/22/2022 21:41:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/22/2022 21:41:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/22/2022 21:41:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/22/2022 21:42:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/22/2022 21:42:07 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8504081544641318 on epoch=207
06/22/2022 21:42:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/22/2022 21:42:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/22/2022 21:42:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/22/2022 21:42:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/22/2022 21:42:20 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/22/2022 21:42:27 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8553082862543845 on epoch=210
06/22/2022 21:42:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/22/2022 21:42:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/22/2022 21:42:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/22/2022 21:42:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/22/2022 21:42:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/22/2022 21:42:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:42:41 - INFO - __main__ - Printing 3 examples
06/22/2022 21:42:41 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 21:42:41 - INFO - __main__ - ['Animal']
06/22/2022 21:42:41 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 21:42:41 - INFO - __main__ - ['Animal']
06/22/2022 21:42:41 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 21:42:41 - INFO - __main__ - ['Animal']
06/22/2022 21:42:41 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:42:41 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:42:41 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 21:42:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:42:41 - INFO - __main__ - Printing 3 examples
06/22/2022 21:42:41 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 21:42:41 - INFO - __main__ - ['Animal']
06/22/2022 21:42:41 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 21:42:41 - INFO - __main__ - ['Animal']
06/22/2022 21:42:41 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 21:42:41 - INFO - __main__ - ['Animal']
06/22/2022 21:42:41 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:42:42 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:42:42 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 21:42:46 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8551822781898684 on epoch=214
06/22/2022 21:42:46 - INFO - __main__ - save last model!
06/22/2022 21:42:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 21:42:46 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 21:42:46 - INFO - __main__ - Printing 3 examples
06/22/2022 21:42:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 21:42:46 - INFO - __main__ - ['Animal']
06/22/2022 21:42:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 21:42:46 - INFO - __main__ - ['Animal']
06/22/2022 21:42:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 21:42:46 - INFO - __main__ - ['Village']
06/22/2022 21:42:46 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:42:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:42:52 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 21:42:57 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 21:42:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 21:42:58 - INFO - __main__ - Starting training!
06/22/2022 21:45:02 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/22/2022 21:45:02 - INFO - __main__ - Classification-F1 on test data: 0.4841
06/22/2022 21:45:03 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9910627007401202, test_performance=0.4841175231209324
06/22/2022 21:45:03 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/22/2022 21:45:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:45:04 - INFO - __main__ - Printing 3 examples
06/22/2022 21:45:04 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/22/2022 21:45:04 - INFO - __main__ - ['Animal']
06/22/2022 21:45:04 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/22/2022 21:45:04 - INFO - __main__ - ['Animal']
06/22/2022 21:45:04 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/22/2022 21:45:04 - INFO - __main__ - ['Animal']
06/22/2022 21:45:04 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:45:04 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:45:04 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 21:45:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 21:45:04 - INFO - __main__ - Printing 3 examples
06/22/2022 21:45:04 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/22/2022 21:45:04 - INFO - __main__ - ['Animal']
06/22/2022 21:45:04 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/22/2022 21:45:04 - INFO - __main__ - ['Animal']
06/22/2022 21:45:04 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/22/2022 21:45:04 - INFO - __main__ - ['Animal']
06/22/2022 21:45:04 - INFO - __main__ - Tokenizing Input ...
06/22/2022 21:45:04 - INFO - __main__ - Tokenizing Output ...
06/22/2022 21:45:04 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 21:45:20 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 21:45:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 21:45:20 - INFO - __main__ - Starting training!
06/22/2022 21:45:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.74 on epoch=0
06/22/2022 21:45:27 - INFO - __main__ - Step 20 Global step 20 Train loss 6.05 on epoch=1
06/22/2022 21:45:29 - INFO - __main__ - Step 30 Global step 30 Train loss 5.11 on epoch=2
06/22/2022 21:45:32 - INFO - __main__ - Step 40 Global step 40 Train loss 4.53 on epoch=2
06/22/2022 21:45:34 - INFO - __main__ - Step 50 Global step 50 Train loss 4.50 on epoch=3
06/22/2022 21:45:42 - INFO - __main__ - Global step 50 Train loss 5.59 Classification-F1 0.03285668350338797 on epoch=3
06/22/2022 21:45:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03285668350338797 on epoch=3, global_step=50
06/22/2022 21:45:45 - INFO - __main__ - Step 60 Global step 60 Train loss 4.30 on epoch=4
06/22/2022 21:45:48 - INFO - __main__ - Step 70 Global step 70 Train loss 3.53 on epoch=4
06/22/2022 21:45:50 - INFO - __main__ - Step 80 Global step 80 Train loss 3.77 on epoch=5
06/22/2022 21:45:53 - INFO - __main__ - Step 90 Global step 90 Train loss 3.56 on epoch=6
06/22/2022 21:45:55 - INFO - __main__ - Step 100 Global step 100 Train loss 3.33 on epoch=7
06/22/2022 21:46:01 - INFO - __main__ - Global step 100 Train loss 3.70 Classification-F1 0.059627927837658586 on epoch=7
06/22/2022 21:46:01 - INFO - __main__ - Saving model with best Classification-F1: 0.03285668350338797 -> 0.059627927837658586 on epoch=7, global_step=100
06/22/2022 21:46:03 - INFO - __main__ - Step 110 Global step 110 Train loss 3.22 on epoch=7
06/22/2022 21:46:06 - INFO - __main__ - Step 120 Global step 120 Train loss 3.02 on epoch=8
06/22/2022 21:46:08 - INFO - __main__ - Step 130 Global step 130 Train loss 3.11 on epoch=9
06/22/2022 21:46:11 - INFO - __main__ - Step 140 Global step 140 Train loss 2.63 on epoch=9
06/22/2022 21:46:14 - INFO - __main__ - Step 150 Global step 150 Train loss 2.82 on epoch=10
06/22/2022 21:46:19 - INFO - __main__ - Global step 150 Train loss 2.96 Classification-F1 0.05750087476468182 on epoch=10
06/22/2022 21:46:21 - INFO - __main__ - Step 160 Global step 160 Train loss 2.68 on epoch=11
06/22/2022 21:46:24 - INFO - __main__ - Step 170 Global step 170 Train loss 2.37 on epoch=12
06/22/2022 21:46:26 - INFO - __main__ - Step 180 Global step 180 Train loss 2.32 on epoch=12
06/22/2022 21:46:29 - INFO - __main__ - Step 190 Global step 190 Train loss 2.33 on epoch=13
06/22/2022 21:46:31 - INFO - __main__ - Step 200 Global step 200 Train loss 2.49 on epoch=14
06/22/2022 21:46:36 - INFO - __main__ - Global step 200 Train loss 2.44 Classification-F1 0.08551477560127518 on epoch=14
06/22/2022 21:46:36 - INFO - __main__ - Saving model with best Classification-F1: 0.059627927837658586 -> 0.08551477560127518 on epoch=14, global_step=200
06/22/2022 21:46:39 - INFO - __main__ - Step 210 Global step 210 Train loss 2.02 on epoch=14
06/22/2022 21:46:42 - INFO - __main__ - Step 220 Global step 220 Train loss 2.08 on epoch=15
06/22/2022 21:46:44 - INFO - __main__ - Step 230 Global step 230 Train loss 1.99 on epoch=16
06/22/2022 21:46:47 - INFO - __main__ - Step 240 Global step 240 Train loss 1.93 on epoch=17
06/22/2022 21:46:49 - INFO - __main__ - Step 250 Global step 250 Train loss 1.90 on epoch=17
06/22/2022 21:46:55 - INFO - __main__ - Global step 250 Train loss 1.98 Classification-F1 0.09999875619570017 on epoch=17
06/22/2022 21:46:55 - INFO - __main__ - Saving model with best Classification-F1: 0.08551477560127518 -> 0.09999875619570017 on epoch=17, global_step=250
06/22/2022 21:46:57 - INFO - __main__ - Step 260 Global step 260 Train loss 1.81 on epoch=18
06/22/2022 21:47:00 - INFO - __main__ - Step 270 Global step 270 Train loss 1.92 on epoch=19
06/22/2022 21:47:02 - INFO - __main__ - Step 280 Global step 280 Train loss 1.49 on epoch=19
06/22/2022 21:47:05 - INFO - __main__ - Step 290 Global step 290 Train loss 1.62 on epoch=20
06/22/2022 21:47:07 - INFO - __main__ - Step 300 Global step 300 Train loss 1.49 on epoch=21
06/22/2022 21:47:13 - INFO - __main__ - Global step 300 Train loss 1.66 Classification-F1 0.13203403108426578 on epoch=21
06/22/2022 21:47:13 - INFO - __main__ - Saving model with best Classification-F1: 0.09999875619570017 -> 0.13203403108426578 on epoch=21, global_step=300
06/22/2022 21:47:16 - INFO - __main__ - Step 310 Global step 310 Train loss 1.46 on epoch=22
06/22/2022 21:47:18 - INFO - __main__ - Step 320 Global step 320 Train loss 1.37 on epoch=22
06/22/2022 21:47:21 - INFO - __main__ - Step 330 Global step 330 Train loss 1.41 on epoch=23
06/22/2022 21:47:23 - INFO - __main__ - Step 340 Global step 340 Train loss 1.50 on epoch=24
06/22/2022 21:47:26 - INFO - __main__ - Step 350 Global step 350 Train loss 1.12 on epoch=24
06/22/2022 21:47:31 - INFO - __main__ - Global step 350 Train loss 1.37 Classification-F1 0.17223682651343675 on epoch=24
06/22/2022 21:47:32 - INFO - __main__ - Saving model with best Classification-F1: 0.13203403108426578 -> 0.17223682651343675 on epoch=24, global_step=350
06/22/2022 21:47:34 - INFO - __main__ - Step 360 Global step 360 Train loss 1.26 on epoch=25
06/22/2022 21:47:37 - INFO - __main__ - Step 370 Global step 370 Train loss 1.20 on epoch=26
06/22/2022 21:47:39 - INFO - __main__ - Step 380 Global step 380 Train loss 1.25 on epoch=27
06/22/2022 21:47:42 - INFO - __main__ - Step 390 Global step 390 Train loss 1.06 on epoch=27
06/22/2022 21:47:44 - INFO - __main__ - Step 400 Global step 400 Train loss 1.12 on epoch=28
06/22/2022 21:47:50 - INFO - __main__ - Global step 400 Train loss 1.18 Classification-F1 0.2681742632108165 on epoch=28
06/22/2022 21:47:50 - INFO - __main__ - Saving model with best Classification-F1: 0.17223682651343675 -> 0.2681742632108165 on epoch=28, global_step=400
06/22/2022 21:47:53 - INFO - __main__ - Step 410 Global step 410 Train loss 1.23 on epoch=29
06/22/2022 21:47:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.91 on epoch=29
06/22/2022 21:47:58 - INFO - __main__ - Step 430 Global step 430 Train loss 1.02 on epoch=30
06/22/2022 21:48:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.97 on epoch=31
06/22/2022 21:48:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.84 on epoch=32
06/22/2022 21:48:09 - INFO - __main__ - Global step 450 Train loss 0.99 Classification-F1 0.3091039151725454 on epoch=32
06/22/2022 21:48:09 - INFO - __main__ - Saving model with best Classification-F1: 0.2681742632108165 -> 0.3091039151725454 on epoch=32, global_step=450
06/22/2022 21:48:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.81 on epoch=32
06/22/2022 21:48:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.94 on epoch=33
06/22/2022 21:48:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.92 on epoch=34
06/22/2022 21:48:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=34
06/22/2022 21:48:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.78 on epoch=35
06/22/2022 21:48:28 - INFO - __main__ - Global step 500 Train loss 0.83 Classification-F1 0.40719930223299977 on epoch=35
06/22/2022 21:48:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3091039151725454 -> 0.40719930223299977 on epoch=35, global_step=500
06/22/2022 21:48:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.82 on epoch=36
06/22/2022 21:48:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.70 on epoch=37
06/22/2022 21:48:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=37
06/22/2022 21:48:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.72 on epoch=38
06/22/2022 21:48:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.73 on epoch=39
06/22/2022 21:48:48 - INFO - __main__ - Global step 550 Train loss 0.72 Classification-F1 0.4310953706995995 on epoch=39
06/22/2022 21:48:48 - INFO - __main__ - Saving model with best Classification-F1: 0.40719930223299977 -> 0.4310953706995995 on epoch=39, global_step=550
06/22/2022 21:48:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.51 on epoch=39
06/22/2022 21:48:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.57 on epoch=40
06/22/2022 21:48:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.56 on epoch=41
06/22/2022 21:48:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.57 on epoch=42
06/22/2022 21:49:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.57 on epoch=42
06/22/2022 21:49:08 - INFO - __main__ - Global step 600 Train loss 0.55 Classification-F1 0.46775180479296163 on epoch=42
06/22/2022 21:49:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4310953706995995 -> 0.46775180479296163 on epoch=42, global_step=600
06/22/2022 21:49:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.48 on epoch=43
06/22/2022 21:49:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.51 on epoch=44
06/22/2022 21:49:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.51 on epoch=44
06/22/2022 21:49:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.57 on epoch=45
06/22/2022 21:49:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=46
06/22/2022 21:49:28 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.4950998671482543 on epoch=46
06/22/2022 21:49:28 - INFO - __main__ - Saving model with best Classification-F1: 0.46775180479296163 -> 0.4950998671482543 on epoch=46, global_step=650
06/22/2022 21:49:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
06/22/2022 21:49:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.52 on epoch=47
06/22/2022 21:49:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.44 on epoch=48
06/22/2022 21:49:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=49
06/22/2022 21:49:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=49
06/22/2022 21:49:48 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.5202420243133982 on epoch=49
06/22/2022 21:49:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4950998671482543 -> 0.5202420243133982 on epoch=49, global_step=700
06/22/2022 21:49:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.51 on epoch=50
06/22/2022 21:49:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=51
06/22/2022 21:49:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.43 on epoch=52
06/22/2022 21:49:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=52
06/22/2022 21:50:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/22/2022 21:50:08 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.640537308263327 on epoch=53
06/22/2022 21:50:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5202420243133982 -> 0.640537308263327 on epoch=53, global_step=750
06/22/2022 21:50:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.44 on epoch=54
06/22/2022 21:50:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=54
06/22/2022 21:50:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.49 on epoch=55
06/22/2022 21:50:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=56
06/22/2022 21:50:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.46 on epoch=57
06/22/2022 21:50:28 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.6684750115154775 on epoch=57
06/22/2022 21:50:28 - INFO - __main__ - Saving model with best Classification-F1: 0.640537308263327 -> 0.6684750115154775 on epoch=57, global_step=800
06/22/2022 21:50:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
06/22/2022 21:50:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.45 on epoch=58
06/22/2022 21:50:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=59
06/22/2022 21:50:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.30 on epoch=59
06/22/2022 21:50:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=60
06/22/2022 21:50:49 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.711759899490548 on epoch=60
06/22/2022 21:50:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6684750115154775 -> 0.711759899490548 on epoch=60, global_step=850
06/22/2022 21:50:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.41 on epoch=61
06/22/2022 21:50:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.43 on epoch=62
06/22/2022 21:50:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=62
06/22/2022 21:50:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.39 on epoch=63
06/22/2022 21:51:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=64
06/22/2022 21:51:09 - INFO - __main__ - Global step 900 Train loss 0.37 Classification-F1 0.673673236585244 on epoch=64
06/22/2022 21:51:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.39 on epoch=64
06/22/2022 21:51:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=65
06/22/2022 21:51:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.34 on epoch=66
06/22/2022 21:51:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=67
06/22/2022 21:51:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=67
06/22/2022 21:51:29 - INFO - __main__ - Global step 950 Train loss 0.33 Classification-F1 0.6760437567525853 on epoch=67
06/22/2022 21:51:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.40 on epoch=68
06/22/2022 21:51:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
06/22/2022 21:51:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=69
06/22/2022 21:51:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=70
06/22/2022 21:51:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=71
06/22/2022 21:51:50 - INFO - __main__ - Global step 1000 Train loss 0.29 Classification-F1 0.630777295653956 on epoch=71
06/22/2022 21:51:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.36 on epoch=72
06/22/2022 21:51:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=72
06/22/2022 21:51:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.33 on epoch=73
06/22/2022 21:52:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=74
06/22/2022 21:52:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=74
06/22/2022 21:52:10 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.6642483864349098 on epoch=74
06/22/2022 21:52:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.33 on epoch=75
06/22/2022 21:52:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=76
06/22/2022 21:52:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.33 on epoch=77
06/22/2022 21:52:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=77
06/22/2022 21:52:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=78
06/22/2022 21:52:30 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.674182829447404 on epoch=78
06/22/2022 21:52:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=79
06/22/2022 21:52:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=79
06/22/2022 21:52:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.22 on epoch=80
06/22/2022 21:52:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/22/2022 21:52:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=82
06/22/2022 21:52:51 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.7162113137601254 on epoch=82
06/22/2022 21:52:51 - INFO - __main__ - Saving model with best Classification-F1: 0.711759899490548 -> 0.7162113137601254 on epoch=82, global_step=1150
06/22/2022 21:52:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=82
06/22/2022 21:52:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.28 on epoch=83
06/22/2022 21:52:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=84
06/22/2022 21:53:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=84
06/22/2022 21:53:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/22/2022 21:53:11 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.7590911480633196 on epoch=85
06/22/2022 21:53:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7162113137601254 -> 0.7590911480633196 on epoch=85, global_step=1200
06/22/2022 21:53:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=86
06/22/2022 21:53:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.21 on epoch=87
06/22/2022 21:53:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=87
06/22/2022 21:53:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/22/2022 21:53:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=89
06/22/2022 21:53:32 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.7566289076725509 on epoch=89
06/22/2022 21:53:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/22/2022 21:53:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=90
06/22/2022 21:53:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.21 on epoch=91
06/22/2022 21:53:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.26 on epoch=92
06/22/2022 21:53:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=92
06/22/2022 21:53:53 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.711384580151772 on epoch=92
06/22/2022 21:53:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
06/22/2022 21:53:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=94
06/22/2022 21:54:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=94
06/22/2022 21:54:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=95
06/22/2022 21:54:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/22/2022 21:54:13 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.7929890037026541 on epoch=96
06/22/2022 21:54:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7590911480633196 -> 0.7929890037026541 on epoch=96, global_step=1350
06/22/2022 21:54:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
06/22/2022 21:54:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.25 on epoch=97
06/22/2022 21:54:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=98
06/22/2022 21:54:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
06/22/2022 21:54:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=99
06/22/2022 21:54:34 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.744445058513314 on epoch=99
06/22/2022 21:54:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.23 on epoch=100
06/22/2022 21:54:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=101
06/22/2022 21:54:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=102
06/22/2022 21:54:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/22/2022 21:54:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=103
06/22/2022 21:54:55 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.7402738385131042 on epoch=103
06/22/2022 21:54:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=104
06/22/2022 21:55:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.19 on epoch=104
06/22/2022 21:55:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
06/22/2022 21:55:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.20 on epoch=106
06/22/2022 21:55:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=107
06/22/2022 21:55:15 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.7845286428141126 on epoch=107
06/22/2022 21:55:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/22/2022 21:55:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.22 on epoch=108
06/22/2022 21:55:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=109
06/22/2022 21:55:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.17 on epoch=109
06/22/2022 21:55:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/22/2022 21:55:36 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.7354874647806336 on epoch=110
06/22/2022 21:55:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=111
06/22/2022 21:55:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.17 on epoch=112
06/22/2022 21:55:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=112
06/22/2022 21:55:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.18 on epoch=113
06/22/2022 21:55:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=114
06/22/2022 21:55:56 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7041193909833124 on epoch=114
06/22/2022 21:55:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.20 on epoch=114
06/22/2022 21:56:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.20 on epoch=115
06/22/2022 21:56:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
06/22/2022 21:56:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=117
06/22/2022 21:56:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=117
06/22/2022 21:56:17 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.7504774274726278 on epoch=117
06/22/2022 21:56:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=118
06/22/2022 21:56:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.15 on epoch=119
06/22/2022 21:56:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=119
06/22/2022 21:56:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
06/22/2022 21:56:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
06/22/2022 21:56:37 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.7591056878583096 on epoch=121
06/22/2022 21:56:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
06/22/2022 21:56:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=122
06/22/2022 21:56:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
06/22/2022 21:56:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=124
06/22/2022 21:56:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.19 on epoch=124
06/22/2022 21:56:58 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.7702535243144951 on epoch=124
06/22/2022 21:57:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.17 on epoch=125
06/22/2022 21:57:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
06/22/2022 21:57:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.23 on epoch=127
06/22/2022 21:57:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=127
06/22/2022 21:57:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.18 on epoch=128
06/22/2022 21:57:18 - INFO - __main__ - Global step 1800 Train loss 0.17 Classification-F1 0.7407315596459094 on epoch=128
06/22/2022 21:57:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=129
06/22/2022 21:57:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/22/2022 21:57:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/22/2022 21:57:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/22/2022 21:57:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=132
06/22/2022 21:57:38 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.7476519748708228 on epoch=132
06/22/2022 21:57:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/22/2022 21:57:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/22/2022 21:57:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
06/22/2022 21:57:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/22/2022 21:57:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=135
06/22/2022 21:57:58 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.7561578677551443 on epoch=135
06/22/2022 21:58:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=136
06/22/2022 21:58:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.20 on epoch=137
06/22/2022 21:58:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
06/22/2022 21:58:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=138
06/22/2022 21:58:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.18 on epoch=139
06/22/2022 21:58:19 - INFO - __main__ - Global step 1950 Train loss 0.15 Classification-F1 0.7781950385812424 on epoch=139
06/22/2022 21:58:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/22/2022 21:58:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
06/22/2022 21:58:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/22/2022 21:58:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/22/2022 21:58:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=142
06/22/2022 21:58:39 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.7781950385812424 on epoch=142
06/22/2022 21:58:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=143
06/22/2022 21:58:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=144
06/22/2022 21:58:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/22/2022 21:58:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/22/2022 21:58:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/22/2022 21:58:59 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.7704373619107995 on epoch=146
06/22/2022 21:59:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=147
06/22/2022 21:59:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/22/2022 21:59:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/22/2022 21:59:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=149
06/22/2022 21:59:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=149
06/22/2022 21:59:19 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.7721314366698896 on epoch=149
06/22/2022 21:59:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=150
06/22/2022 21:59:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/22/2022 21:59:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=152
06/22/2022 21:59:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/22/2022 21:59:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.14 on epoch=153
06/22/2022 21:59:39 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.770637505764194 on epoch=153
06/22/2022 21:59:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.16 on epoch=154
06/22/2022 21:59:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/22/2022 21:59:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/22/2022 21:59:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/22/2022 21:59:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.19 on epoch=157
06/22/2022 21:59:59 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.7821645408206408 on epoch=157
06/22/2022 22:00:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/22/2022 22:00:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.11 on epoch=158
06/22/2022 22:00:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=159
06/22/2022 22:00:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=159
06/22/2022 22:00:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/22/2022 22:00:19 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.7323136488221877 on epoch=160
06/22/2022 22:00:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/22/2022 22:00:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=162
06/22/2022 22:00:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
06/22/2022 22:00:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/22/2022 22:00:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=164
06/22/2022 22:00:39 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.7702530382516988 on epoch=164
06/22/2022 22:00:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=164
06/22/2022 22:00:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/22/2022 22:00:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/22/2022 22:00:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/22/2022 22:00:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
06/22/2022 22:00:58 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7387109552194941 on epoch=167
06/22/2022 22:01:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.13 on epoch=168
06/22/2022 22:01:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
06/22/2022 22:01:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=169
06/22/2022 22:01:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/22/2022 22:01:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/22/2022 22:01:18 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.787667137116076 on epoch=171
06/22/2022 22:01:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
06/22/2022 22:01:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=172
06/22/2022 22:01:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/22/2022 22:01:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/22/2022 22:01:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/22/2022 22:01:38 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7488119653205042 on epoch=174
06/22/2022 22:01:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/22/2022 22:01:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/22/2022 22:01:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=177
06/22/2022 22:01:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/22/2022 22:01:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/22/2022 22:01:58 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8488237173958237 on epoch=178
06/22/2022 22:01:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7929890037026541 -> 0.8488237173958237 on epoch=178, global_step=2500
06/22/2022 22:02:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/22/2022 22:02:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=179
06/22/2022 22:02:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=180
06/22/2022 22:02:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.14 on epoch=181
06/22/2022 22:02:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/22/2022 22:02:18 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.795892128112242 on epoch=182
06/22/2022 22:02:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/22/2022 22:02:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=183
06/22/2022 22:02:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.10 on epoch=184
06/22/2022 22:02:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/22/2022 22:02:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/22/2022 22:02:38 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7988929104901871 on epoch=185
06/22/2022 22:02:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/22/2022 22:02:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=187
06/22/2022 22:02:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/22/2022 22:02:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/22/2022 22:02:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/22/2022 22:02:58 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7526222209689952 on epoch=189
06/22/2022 22:03:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=189
06/22/2022 22:03:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/22/2022 22:03:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=191
06/22/2022 22:03:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/22/2022 22:03:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/22/2022 22:03:18 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7138024944676298 on epoch=192
06/22/2022 22:03:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/22/2022 22:03:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/22/2022 22:03:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/22/2022 22:03:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=195
06/22/2022 22:03:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/22/2022 22:03:37 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.7088122410563238 on epoch=196
06/22/2022 22:03:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
06/22/2022 22:03:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/22/2022 22:03:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/22/2022 22:03:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/22/2022 22:03:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/22/2022 22:03:57 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.801354468147637 on epoch=199
06/22/2022 22:03:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/22/2022 22:04:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=201
06/22/2022 22:04:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/22/2022 22:04:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/22/2022 22:04:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/22/2022 22:04:16 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7976527563088563 on epoch=203
06/22/2022 22:04:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=204
06/22/2022 22:04:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/22/2022 22:04:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/22/2022 22:04:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/22/2022 22:04:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=207
06/22/2022 22:04:36 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7988929104901871 on epoch=207
06/22/2022 22:04:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/22/2022 22:04:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/22/2022 22:04:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/22/2022 22:04:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/22/2022 22:04:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/22/2022 22:04:55 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.8062890238510209 on epoch=210
06/22/2022 22:04:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/22/2022 22:05:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/22/2022 22:05:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/22/2022 22:05:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/22/2022 22:05:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/22/2022 22:05:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:05:09 - INFO - __main__ - Printing 3 examples
06/22/2022 22:05:09 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 22:05:09 - INFO - __main__ - ['Animal']
06/22/2022 22:05:09 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 22:05:09 - INFO - __main__ - ['Animal']
06/22/2022 22:05:09 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 22:05:09 - INFO - __main__ - ['Animal']
06/22/2022 22:05:09 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:05:10 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:05:10 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 22:05:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:05:10 - INFO - __main__ - Printing 3 examples
06/22/2022 22:05:10 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 22:05:10 - INFO - __main__ - ['Animal']
06/22/2022 22:05:10 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 22:05:10 - INFO - __main__ - ['Animal']
06/22/2022 22:05:10 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 22:05:10 - INFO - __main__ - ['Animal']
06/22/2022 22:05:10 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:05:10 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:05:10 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 22:05:15 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=214
06/22/2022 22:05:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8488237173958237 -> 0.9228413163897036 on epoch=214, global_step=3000
06/22/2022 22:05:15 - INFO - __main__ - save last model!
06/22/2022 22:05:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 22:05:15 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 22:05:15 - INFO - __main__ - Printing 3 examples
06/22/2022 22:05:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 22:05:15 - INFO - __main__ - ['Animal']
06/22/2022 22:05:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 22:05:15 - INFO - __main__ - ['Animal']
06/22/2022 22:05:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 22:05:15 - INFO - __main__ - ['Village']
06/22/2022 22:05:15 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:05:17 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:05:20 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 22:05:26 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 22:05:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 22:05:26 - INFO - __main__ - Starting training!
06/22/2022 22:07:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/22/2022 22:07:34 - INFO - __main__ - Classification-F1 on test data: 0.3880
06/22/2022 22:07:35 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9228413163897036, test_performance=0.38803063585559605
06/22/2022 22:07:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/22/2022 22:07:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:07:36 - INFO - __main__ - Printing 3 examples
06/22/2022 22:07:36 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 22:07:36 - INFO - __main__ - ['Animal']
06/22/2022 22:07:36 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 22:07:36 - INFO - __main__ - ['Animal']
06/22/2022 22:07:36 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 22:07:36 - INFO - __main__ - ['Animal']
06/22/2022 22:07:36 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:07:36 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:07:36 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 22:07:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:07:36 - INFO - __main__ - Printing 3 examples
06/22/2022 22:07:36 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 22:07:36 - INFO - __main__ - ['Animal']
06/22/2022 22:07:36 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 22:07:36 - INFO - __main__ - ['Animal']
06/22/2022 22:07:36 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 22:07:36 - INFO - __main__ - ['Animal']
06/22/2022 22:07:36 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:07:36 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:07:36 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 22:07:52 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 22:07:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 22:07:53 - INFO - __main__ - Starting training!
06/22/2022 22:07:56 - INFO - __main__ - Step 10 Global step 10 Train loss 6.06 on epoch=0
06/22/2022 22:07:59 - INFO - __main__ - Step 20 Global step 20 Train loss 4.69 on epoch=1
06/22/2022 22:08:01 - INFO - __main__ - Step 30 Global step 30 Train loss 3.92 on epoch=2
06/22/2022 22:08:04 - INFO - __main__ - Step 40 Global step 40 Train loss 3.39 on epoch=2
06/22/2022 22:08:06 - INFO - __main__ - Step 50 Global step 50 Train loss 3.08 on epoch=3
06/22/2022 22:08:11 - INFO - __main__ - Global step 50 Train loss 4.23 Classification-F1 0.06319889953169525 on epoch=3
06/22/2022 22:08:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06319889953169525 on epoch=3, global_step=50
06/22/2022 22:08:14 - INFO - __main__ - Step 60 Global step 60 Train loss 2.83 on epoch=4
06/22/2022 22:08:17 - INFO - __main__ - Step 70 Global step 70 Train loss 2.56 on epoch=4
06/22/2022 22:08:19 - INFO - __main__ - Step 80 Global step 80 Train loss 2.29 on epoch=5
06/22/2022 22:08:22 - INFO - __main__ - Step 90 Global step 90 Train loss 2.15 on epoch=6
06/22/2022 22:08:24 - INFO - __main__ - Step 100 Global step 100 Train loss 2.00 on epoch=7
06/22/2022 22:08:30 - INFO - __main__ - Global step 100 Train loss 2.37 Classification-F1 0.08583729171212019 on epoch=7
06/22/2022 22:08:30 - INFO - __main__ - Saving model with best Classification-F1: 0.06319889953169525 -> 0.08583729171212019 on epoch=7, global_step=100
06/22/2022 22:08:32 - INFO - __main__ - Step 110 Global step 110 Train loss 1.82 on epoch=7
06/22/2022 22:08:35 - INFO - __main__ - Step 120 Global step 120 Train loss 1.75 on epoch=8
06/22/2022 22:08:38 - INFO - __main__ - Step 130 Global step 130 Train loss 1.48 on epoch=9
06/22/2022 22:08:40 - INFO - __main__ - Step 140 Global step 140 Train loss 1.36 on epoch=9
06/22/2022 22:08:43 - INFO - __main__ - Step 150 Global step 150 Train loss 1.28 on epoch=10
06/22/2022 22:08:48 - INFO - __main__ - Global step 150 Train loss 1.54 Classification-F1 0.1228132415487465 on epoch=10
06/22/2022 22:08:49 - INFO - __main__ - Saving model with best Classification-F1: 0.08583729171212019 -> 0.1228132415487465 on epoch=10, global_step=150
06/22/2022 22:08:51 - INFO - __main__ - Step 160 Global step 160 Train loss 1.12 on epoch=11
06/22/2022 22:08:54 - INFO - __main__ - Step 170 Global step 170 Train loss 1.08 on epoch=12
06/22/2022 22:08:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=12
06/22/2022 22:08:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=13
06/22/2022 22:09:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=14
06/22/2022 22:09:08 - INFO - __main__ - Global step 200 Train loss 0.94 Classification-F1 0.3161812103101035 on epoch=14
06/22/2022 22:09:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1228132415487465 -> 0.3161812103101035 on epoch=14, global_step=200
06/22/2022 22:09:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.66 on epoch=14
06/22/2022 22:09:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.70 on epoch=15
06/22/2022 22:09:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=16
06/22/2022 22:09:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=17
06/22/2022 22:09:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.62 on epoch=17
06/22/2022 22:09:28 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.34400802478944853 on epoch=17
06/22/2022 22:09:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3161812103101035 -> 0.34400802478944853 on epoch=17, global_step=250
06/22/2022 22:09:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=18
06/22/2022 22:09:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=19
06/22/2022 22:09:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=19
06/22/2022 22:09:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.46 on epoch=20
06/22/2022 22:09:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
06/22/2022 22:09:48 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.5183094741986932 on epoch=21
06/22/2022 22:09:48 - INFO - __main__ - Saving model with best Classification-F1: 0.34400802478944853 -> 0.5183094741986932 on epoch=21, global_step=300
06/22/2022 22:09:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=22
06/22/2022 22:09:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/22/2022 22:09:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
06/22/2022 22:09:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=24
06/22/2022 22:10:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=24
06/22/2022 22:10:08 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.5201207616352304 on epoch=24
06/22/2022 22:10:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5183094741986932 -> 0.5201207616352304 on epoch=24, global_step=350
06/22/2022 22:10:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/22/2022 22:10:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=26
06/22/2022 22:10:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=27
06/22/2022 22:10:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/22/2022 22:10:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
06/22/2022 22:10:28 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6389184088365777 on epoch=28
06/22/2022 22:10:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5201207616352304 -> 0.6389184088365777 on epoch=28, global_step=400
06/22/2022 22:10:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
06/22/2022 22:10:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=29
06/22/2022 22:10:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
06/22/2022 22:10:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/22/2022 22:10:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/22/2022 22:10:49 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.6098611513934094 on epoch=32
06/22/2022 22:10:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
06/22/2022 22:10:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=33
06/22/2022 22:10:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
06/22/2022 22:10:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/22/2022 22:11:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
06/22/2022 22:11:10 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.613300051203277 on epoch=35
06/22/2022 22:11:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/22/2022 22:11:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=37
06/22/2022 22:11:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
06/22/2022 22:11:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/22/2022 22:11:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
06/22/2022 22:11:30 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.608025004002733 on epoch=39
06/22/2022 22:11:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/22/2022 22:11:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=40
06/22/2022 22:11:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/22/2022 22:11:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/22/2022 22:11:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/22/2022 22:11:51 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.744809247977629 on epoch=42
06/22/2022 22:11:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6389184088365777 -> 0.744809247977629 on epoch=42, global_step=600
06/22/2022 22:11:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
06/22/2022 22:11:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
06/22/2022 22:11:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=44
06/22/2022 22:12:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/22/2022 22:12:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=46
06/22/2022 22:12:11 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6929544096882806 on epoch=46
06/22/2022 22:12:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
06/22/2022 22:12:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/22/2022 22:12:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/22/2022 22:12:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/22/2022 22:12:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
06/22/2022 22:12:32 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6893593189964159 on epoch=49
06/22/2022 22:12:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
06/22/2022 22:12:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
06/22/2022 22:12:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/22/2022 22:12:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/22/2022 22:12:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/22/2022 22:12:52 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.8026756985174324 on epoch=53
06/22/2022 22:12:52 - INFO - __main__ - Saving model with best Classification-F1: 0.744809247977629 -> 0.8026756985174324 on epoch=53, global_step=750
06/22/2022 22:12:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
06/22/2022 22:12:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/22/2022 22:12:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/22/2022 22:13:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
06/22/2022 22:13:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
06/22/2022 22:13:12 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.7800622448392848 on epoch=57
06/22/2022 22:13:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/22/2022 22:13:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/22/2022 22:13:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/22/2022 22:13:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/22/2022 22:13:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/22/2022 22:13:32 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8085236517338067 on epoch=60
06/22/2022 22:13:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8026756985174324 -> 0.8085236517338067 on epoch=60, global_step=850
06/22/2022 22:13:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/22/2022 22:13:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/22/2022 22:13:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/22/2022 22:13:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/22/2022 22:13:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
06/22/2022 22:13:51 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7943572196107183 on epoch=64
06/22/2022 22:13:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/22/2022 22:13:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/22/2022 22:13:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/22/2022 22:14:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/22/2022 22:14:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/22/2022 22:14:11 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8317476801937784 on epoch=67
06/22/2022 22:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8085236517338067 -> 0.8317476801937784 on epoch=67, global_step=950
06/22/2022 22:14:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/22/2022 22:14:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/22/2022 22:14:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/22/2022 22:14:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
06/22/2022 22:14:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/22/2022 22:14:32 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.8731227016710886 on epoch=71
06/22/2022 22:14:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8317476801937784 -> 0.8731227016710886 on epoch=71, global_step=1000
06/22/2022 22:14:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/22/2022 22:14:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
06/22/2022 22:14:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/22/2022 22:14:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/22/2022 22:14:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/22/2022 22:14:51 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8953476415003929 on epoch=74
06/22/2022 22:14:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8731227016710886 -> 0.8953476415003929 on epoch=74, global_step=1050
06/22/2022 22:14:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/22/2022 22:14:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/22/2022 22:14:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/22/2022 22:15:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/22/2022 22:15:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/22/2022 22:15:11 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8971966094895165 on epoch=78
06/22/2022 22:15:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8953476415003929 -> 0.8971966094895165 on epoch=78, global_step=1100
06/22/2022 22:15:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/22/2022 22:15:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/22/2022 22:15:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/22/2022 22:15:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/22/2022 22:15:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/22/2022 22:15:31 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9058470856573322 on epoch=82
06/22/2022 22:15:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8971966094895165 -> 0.9058470856573322 on epoch=82, global_step=1150
06/22/2022 22:15:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/22/2022 22:15:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
06/22/2022 22:15:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/22/2022 22:15:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/22/2022 22:15:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/22/2022 22:15:51 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9035531788472964 on epoch=85
06/22/2022 22:15:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/22/2022 22:15:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/22/2022 22:15:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/22/2022 22:16:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/22/2022 22:16:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/22/2022 22:16:11 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8370895633319058 on epoch=89
06/22/2022 22:16:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/22/2022 22:16:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/22/2022 22:16:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/22/2022 22:16:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/22/2022 22:16:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/22/2022 22:16:31 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8980239026206768 on epoch=92
06/22/2022 22:16:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/22/2022 22:16:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/22/2022 22:16:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/22/2022 22:16:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/22/2022 22:16:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/22/2022 22:16:51 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9061092902459126 on epoch=96
06/22/2022 22:16:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9058470856573322 -> 0.9061092902459126 on epoch=96, global_step=1350
06/22/2022 22:16:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/22/2022 22:16:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/22/2022 22:16:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/22/2022 22:17:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/22/2022 22:17:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/22/2022 22:17:10 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9818181818181818 on epoch=99
06/22/2022 22:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9061092902459126 -> 0.9818181818181818 on epoch=99, global_step=1400
06/22/2022 22:17:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/22/2022 22:17:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/22/2022 22:17:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/22/2022 22:17:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/22/2022 22:17:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/22/2022 22:17:30 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9684042751998158 on epoch=103
06/22/2022 22:17:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/22/2022 22:17:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/22/2022 22:17:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/22/2022 22:17:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/22/2022 22:17:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/22/2022 22:17:49 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9775118698505797 on epoch=107
06/22/2022 22:17:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/22/2022 22:17:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/22/2022 22:17:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/22/2022 22:18:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/22/2022 22:18:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/22/2022 22:18:09 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9774812197606314 on epoch=110
06/22/2022 22:18:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/22/2022 22:18:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/22/2022 22:18:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/22/2022 22:18:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/22/2022 22:18:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/22/2022 22:18:28 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.9017951814156746 on epoch=114
06/22/2022 22:18:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/22/2022 22:18:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/22/2022 22:18:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/22/2022 22:18:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/22/2022 22:18:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/22/2022 22:18:48 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8977547773752707 on epoch=117
06/22/2022 22:18:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/22/2022 22:18:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/22/2022 22:18:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/22/2022 22:18:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/22/2022 22:19:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/22/2022 22:19:07 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.910046432062561 on epoch=121
06/22/2022 22:19:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/22/2022 22:19:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/22/2022 22:19:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/22/2022 22:19:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/22/2022 22:19:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/22/2022 22:19:27 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9018644658793844 on epoch=124
06/22/2022 22:19:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/22/2022 22:19:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/22/2022 22:19:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/22/2022 22:19:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
06/22/2022 22:19:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/22/2022 22:19:46 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9726894597964577 on epoch=128
06/22/2022 22:19:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/22/2022 22:19:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/22/2022 22:19:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/22/2022 22:19:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/22/2022 22:19:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/22/2022 22:20:06 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9683065702770135 on epoch=132
06/22/2022 22:20:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/22/2022 22:20:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/22/2022 22:20:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/22/2022 22:20:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/22/2022 22:20:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/22/2022 22:20:25 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9685132704108036 on epoch=135
06/22/2022 22:20:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/22/2022 22:20:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/22/2022 22:20:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/22/2022 22:20:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/22/2022 22:20:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/22/2022 22:20:45 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9642288807018409 on epoch=139
06/22/2022 22:20:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/22/2022 22:20:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/22/2022 22:20:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/22/2022 22:20:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/22/2022 22:20:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/22/2022 22:21:04 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9730082062150373 on epoch=142
06/22/2022 22:21:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/22/2022 22:21:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/22/2022 22:21:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/22/2022 22:21:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/22/2022 22:21:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/22/2022 22:21:23 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9730169340463457 on epoch=146
06/22/2022 22:21:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/22/2022 22:21:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/22/2022 22:21:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/22/2022 22:21:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/22/2022 22:21:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/22/2022 22:21:42 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9101652674755142 on epoch=149
06/22/2022 22:21:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/22/2022 22:21:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/22/2022 22:21:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/22/2022 22:21:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/22/2022 22:21:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/22/2022 22:22:02 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9730125701306915 on epoch=153
06/22/2022 22:22:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/22/2022 22:22:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/22/2022 22:22:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/22/2022 22:22:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/22/2022 22:22:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/22/2022 22:22:21 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9773678606339897 on epoch=157
06/22/2022 22:22:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/22/2022 22:22:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/22/2022 22:22:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/22/2022 22:22:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/22/2022 22:22:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/22/2022 22:22:40 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9059986008088475 on epoch=160
06/22/2022 22:22:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/22/2022 22:22:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/22/2022 22:22:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/22/2022 22:22:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/22/2022 22:22:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/22/2022 22:23:00 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8976456212983728 on epoch=164
06/22/2022 22:23:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/22/2022 22:23:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/22/2022 22:23:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/22/2022 22:23:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/22/2022 22:23:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/22/2022 22:23:19 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9101652674755142 on epoch=167
06/22/2022 22:23:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/22/2022 22:23:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/22/2022 22:23:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/22/2022 22:23:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/22/2022 22:23:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/22/2022 22:23:38 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9730308985764394 on epoch=171
06/22/2022 22:23:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/22/2022 22:23:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/22/2022 22:23:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/22/2022 22:23:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/22/2022 22:23:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/22/2022 22:23:57 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9685176343264578 on epoch=174
06/22/2022 22:24:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/22/2022 22:24:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/22/2022 22:24:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/22/2022 22:24:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/22/2022 22:24:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/22/2022 22:24:17 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9730169340463457 on epoch=178
06/22/2022 22:24:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/22/2022 22:24:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/22/2022 22:24:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/22/2022 22:24:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/22/2022 22:24:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/22/2022 22:24:36 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9730125701306915 on epoch=182
06/22/2022 22:24:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/22/2022 22:24:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/22/2022 22:24:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/22/2022 22:24:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/22/2022 22:24:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/22/2022 22:24:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9059945278209035 on epoch=185
06/22/2022 22:24:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/22/2022 22:25:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/22/2022 22:25:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/22/2022 22:25:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/22/2022 22:25:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/22/2022 22:25:15 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9058797653958943 on epoch=189
06/22/2022 22:25:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/22/2022 22:25:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/22/2022 22:25:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/22/2022 22:25:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/22/2022 22:25:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/22/2022 22:25:34 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9685176343264578 on epoch=192
06/22/2022 22:25:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/22/2022 22:25:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/22/2022 22:25:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/22/2022 22:25:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/22/2022 22:25:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/22/2022 22:25:54 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9597339448976072 on epoch=196
06/22/2022 22:25:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/22/2022 22:25:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/22/2022 22:26:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/22/2022 22:26:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/22/2022 22:26:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/22/2022 22:26:13 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9638562490928214 on epoch=199
06/22/2022 22:26:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/22/2022 22:26:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/22/2022 22:26:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/22/2022 22:26:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/22/2022 22:26:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/22/2022 22:26:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9730125701306915 on epoch=203
06/22/2022 22:26:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/22/2022 22:26:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/22/2022 22:26:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/22/2022 22:26:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/22/2022 22:26:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/22/2022 22:26:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8434314534098097 on epoch=207
06/22/2022 22:26:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/22/2022 22:26:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/22/2022 22:26:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/22/2022 22:27:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/22/2022 22:27:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/22/2022 22:27:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9641842660817991 on epoch=210
06/22/2022 22:27:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/22/2022 22:27:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/22/2022 22:27:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/22/2022 22:27:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/22/2022 22:27:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/22/2022 22:27:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:27:25 - INFO - __main__ - Printing 3 examples
06/22/2022 22:27:25 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 22:27:25 - INFO - __main__ - ['Animal']
06/22/2022 22:27:25 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 22:27:25 - INFO - __main__ - ['Animal']
06/22/2022 22:27:25 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 22:27:25 - INFO - __main__ - ['Animal']
06/22/2022 22:27:25 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:27:25 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:27:26 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 22:27:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:27:26 - INFO - __main__ - Printing 3 examples
06/22/2022 22:27:26 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 22:27:26 - INFO - __main__ - ['Animal']
06/22/2022 22:27:26 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 22:27:26 - INFO - __main__ - ['Animal']
06/22/2022 22:27:26 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 22:27:26 - INFO - __main__ - ['Animal']
06/22/2022 22:27:26 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:27:26 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:27:26 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 22:27:30 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9642288807018409 on epoch=214
06/22/2022 22:27:30 - INFO - __main__ - save last model!
06/22/2022 22:27:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 22:27:31 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 22:27:31 - INFO - __main__ - Printing 3 examples
06/22/2022 22:27:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 22:27:31 - INFO - __main__ - ['Animal']
06/22/2022 22:27:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 22:27:31 - INFO - __main__ - ['Animal']
06/22/2022 22:27:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 22:27:31 - INFO - __main__ - ['Village']
06/22/2022 22:27:31 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:27:32 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:27:36 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 22:27:41 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 22:27:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 22:27:42 - INFO - __main__ - Starting training!
06/22/2022 22:29:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/22/2022 22:29:46 - INFO - __main__ - Classification-F1 on test data: 0.5964
06/22/2022 22:29:47 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9818181818181818, test_performance=0.5963824766502104
06/22/2022 22:29:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/22/2022 22:29:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:29:48 - INFO - __main__ - Printing 3 examples
06/22/2022 22:29:48 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 22:29:48 - INFO - __main__ - ['Animal']
06/22/2022 22:29:48 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 22:29:48 - INFO - __main__ - ['Animal']
06/22/2022 22:29:48 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 22:29:48 - INFO - __main__ - ['Animal']
06/22/2022 22:29:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:29:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:29:48 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 22:29:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:29:48 - INFO - __main__ - Printing 3 examples
06/22/2022 22:29:48 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 22:29:48 - INFO - __main__ - ['Animal']
06/22/2022 22:29:48 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 22:29:48 - INFO - __main__ - ['Animal']
06/22/2022 22:29:48 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 22:29:48 - INFO - __main__ - ['Animal']
06/22/2022 22:29:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:29:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:29:48 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 22:30:04 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 22:30:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 22:30:04 - INFO - __main__ - Starting training!
06/22/2022 22:30:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.26 on epoch=0
06/22/2022 22:30:11 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=1
06/22/2022 22:30:13 - INFO - __main__ - Step 30 Global step 30 Train loss 4.33 on epoch=2
06/22/2022 22:30:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.57 on epoch=2
06/22/2022 22:30:18 - INFO - __main__ - Step 50 Global step 50 Train loss 3.28 on epoch=3
06/22/2022 22:30:24 - INFO - __main__ - Global step 50 Train loss 4.48 Classification-F1 0.05757357684666998 on epoch=3
06/22/2022 22:30:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05757357684666998 on epoch=3, global_step=50
06/22/2022 22:30:26 - INFO - __main__ - Step 60 Global step 60 Train loss 3.20 on epoch=4
06/22/2022 22:30:29 - INFO - __main__ - Step 70 Global step 70 Train loss 2.83 on epoch=4
06/22/2022 22:30:31 - INFO - __main__ - Step 80 Global step 80 Train loss 2.57 on epoch=5
06/22/2022 22:30:34 - INFO - __main__ - Step 90 Global step 90 Train loss 2.41 on epoch=6
06/22/2022 22:30:36 - INFO - __main__ - Step 100 Global step 100 Train loss 2.37 on epoch=7
06/22/2022 22:30:41 - INFO - __main__ - Global step 100 Train loss 2.68 Classification-F1 0.07790123456790123 on epoch=7
06/22/2022 22:30:41 - INFO - __main__ - Saving model with best Classification-F1: 0.05757357684666998 -> 0.07790123456790123 on epoch=7, global_step=100
06/22/2022 22:30:44 - INFO - __main__ - Step 110 Global step 110 Train loss 2.13 on epoch=7
06/22/2022 22:30:46 - INFO - __main__ - Step 120 Global step 120 Train loss 2.04 on epoch=8
06/22/2022 22:30:49 - INFO - __main__ - Step 130 Global step 130 Train loss 1.91 on epoch=9
06/22/2022 22:30:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.64 on epoch=9
06/22/2022 22:30:54 - INFO - __main__ - Step 150 Global step 150 Train loss 1.65 on epoch=10
06/22/2022 22:31:00 - INFO - __main__ - Global step 150 Train loss 1.87 Classification-F1 0.0991531658840277 on epoch=10
06/22/2022 22:31:00 - INFO - __main__ - Saving model with best Classification-F1: 0.07790123456790123 -> 0.0991531658840277 on epoch=10, global_step=150
06/22/2022 22:31:02 - INFO - __main__ - Step 160 Global step 160 Train loss 1.47 on epoch=11
06/22/2022 22:31:05 - INFO - __main__ - Step 170 Global step 170 Train loss 1.47 on epoch=12
06/22/2022 22:31:07 - INFO - __main__ - Step 180 Global step 180 Train loss 1.30 on epoch=12
06/22/2022 22:31:10 - INFO - __main__ - Step 190 Global step 190 Train loss 1.14 on epoch=13
06/22/2022 22:31:12 - INFO - __main__ - Step 200 Global step 200 Train loss 1.20 on epoch=14
06/22/2022 22:31:18 - INFO - __main__ - Global step 200 Train loss 1.32 Classification-F1 0.18075192754653244 on epoch=14
06/22/2022 22:31:18 - INFO - __main__ - Saving model with best Classification-F1: 0.0991531658840277 -> 0.18075192754653244 on epoch=14, global_step=200
06/22/2022 22:31:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=14
06/22/2022 22:31:23 - INFO - __main__ - Step 220 Global step 220 Train loss 1.02 on epoch=15
06/22/2022 22:31:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.81 on epoch=16
06/22/2022 22:31:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=17
06/22/2022 22:31:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=17
06/22/2022 22:31:38 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.2660227132279413 on epoch=17
06/22/2022 22:31:38 - INFO - __main__ - Saving model with best Classification-F1: 0.18075192754653244 -> 0.2660227132279413 on epoch=17, global_step=250
06/22/2022 22:31:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=18
06/22/2022 22:31:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=19
06/22/2022 22:31:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.70 on epoch=19
06/22/2022 22:31:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=20
06/22/2022 22:31:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=21
06/22/2022 22:31:57 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.33501937661822556 on epoch=21
06/22/2022 22:31:57 - INFO - __main__ - Saving model with best Classification-F1: 0.2660227132279413 -> 0.33501937661822556 on epoch=21, global_step=300
06/22/2022 22:32:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=22
06/22/2022 22:32:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=22
06/22/2022 22:32:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=23
06/22/2022 22:32:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=24
06/22/2022 22:32:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=24
06/22/2022 22:32:17 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.5033508551495668 on epoch=24
06/22/2022 22:32:17 - INFO - __main__ - Saving model with best Classification-F1: 0.33501937661822556 -> 0.5033508551495668 on epoch=24, global_step=350
06/22/2022 22:32:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=25
06/22/2022 22:32:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/22/2022 22:32:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=27
06/22/2022 22:32:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=27
06/22/2022 22:32:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=28
06/22/2022 22:32:38 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.5346107084514343 on epoch=28
06/22/2022 22:32:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5033508551495668 -> 0.5346107084514343 on epoch=28, global_step=400
06/22/2022 22:32:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=29
06/22/2022 22:32:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/22/2022 22:32:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
06/22/2022 22:32:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=31
06/22/2022 22:32:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=32
06/22/2022 22:32:58 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.5093011781653547 on epoch=32
06/22/2022 22:33:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=32
06/22/2022 22:33:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=33
06/22/2022 22:33:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=34
06/22/2022 22:33:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/22/2022 22:33:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=35
06/22/2022 22:33:18 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.5472487705471782 on epoch=35
06/22/2022 22:33:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5346107084514343 -> 0.5472487705471782 on epoch=35, global_step=500
06/22/2022 22:33:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
06/22/2022 22:33:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
06/22/2022 22:33:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/22/2022 22:33:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/22/2022 22:33:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=39
06/22/2022 22:33:39 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.620785559940908 on epoch=39
06/22/2022 22:33:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5472487705471782 -> 0.620785559940908 on epoch=39, global_step=550
06/22/2022 22:33:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=39
06/22/2022 22:33:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/22/2022 22:33:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
06/22/2022 22:33:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=42
06/22/2022 22:33:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
06/22/2022 22:33:59 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.5329000123928517 on epoch=42
06/22/2022 22:34:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=43
06/22/2022 22:34:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=44
06/22/2022 22:34:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
06/22/2022 22:34:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
06/22/2022 22:34:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/22/2022 22:34:19 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.5990682555198684 on epoch=46
06/22/2022 22:34:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/22/2022 22:34:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=47
06/22/2022 22:34:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
06/22/2022 22:34:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
06/22/2022 22:34:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/22/2022 22:34:40 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.5792329448133472 on epoch=49
06/22/2022 22:34:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/22/2022 22:34:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/22/2022 22:34:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/22/2022 22:34:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
06/22/2022 22:34:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/22/2022 22:35:00 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.5792878039540333 on epoch=53
06/22/2022 22:35:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/22/2022 22:35:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
06/22/2022 22:35:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=55
06/22/2022 22:35:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=56
06/22/2022 22:35:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/22/2022 22:35:20 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.7018793419684761 on epoch=57
06/22/2022 22:35:21 - INFO - __main__ - Saving model with best Classification-F1: 0.620785559940908 -> 0.7018793419684761 on epoch=57, global_step=800
06/22/2022 22:35:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/22/2022 22:35:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
06/22/2022 22:35:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/22/2022 22:35:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=59
06/22/2022 22:35:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/22/2022 22:35:41 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6656633307050845 on epoch=60
06/22/2022 22:35:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/22/2022 22:35:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/22/2022 22:35:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/22/2022 22:35:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/22/2022 22:35:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/22/2022 22:36:00 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7782063848877772 on epoch=64
06/22/2022 22:36:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7018793419684761 -> 0.7782063848877772 on epoch=64, global_step=900
06/22/2022 22:36:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
06/22/2022 22:36:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=65
06/22/2022 22:36:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/22/2022 22:36:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
06/22/2022 22:36:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/22/2022 22:36:20 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.7895403123981753 on epoch=67
06/22/2022 22:36:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7782063848877772 -> 0.7895403123981753 on epoch=67, global_step=950
06/22/2022 22:36:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/22/2022 22:36:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/22/2022 22:36:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/22/2022 22:36:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=70
06/22/2022 22:36:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/22/2022 22:36:40 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7461055539259671 on epoch=71
06/22/2022 22:36:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=72
06/22/2022 22:36:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/22/2022 22:36:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/22/2022 22:36:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/22/2022 22:36:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/22/2022 22:37:01 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7836280794698134 on epoch=74
06/22/2022 22:37:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/22/2022 22:37:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/22/2022 22:37:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
06/22/2022 22:37:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/22/2022 22:37:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/22/2022 22:37:21 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7384026599341458 on epoch=78
06/22/2022 22:37:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
06/22/2022 22:37:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/22/2022 22:37:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/22/2022 22:37:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/22/2022 22:37:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/22/2022 22:37:41 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7462385634939669 on epoch=82
06/22/2022 22:37:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/22/2022 22:37:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/22/2022 22:37:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/22/2022 22:37:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=84
06/22/2022 22:37:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/22/2022 22:38:01 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.8105742327317561 on epoch=85
06/22/2022 22:38:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7895403123981753 -> 0.8105742327317561 on epoch=85, global_step=1200
06/22/2022 22:38:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/22/2022 22:38:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=87
06/22/2022 22:38:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/22/2022 22:38:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/22/2022 22:38:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
06/22/2022 22:38:21 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7714962475078608 on epoch=89
06/22/2022 22:38:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/22/2022 22:38:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
06/22/2022 22:38:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/22/2022 22:38:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/22/2022 22:38:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/22/2022 22:38:41 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.7395463056516187 on epoch=92
06/22/2022 22:38:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/22/2022 22:38:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/22/2022 22:38:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/22/2022 22:38:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/22/2022 22:38:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/22/2022 22:39:01 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7059651511476638 on epoch=96
06/22/2022 22:39:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
06/22/2022 22:39:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/22/2022 22:39:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/22/2022 22:39:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/22/2022 22:39:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/22/2022 22:39:21 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7449341292847966 on epoch=99
06/22/2022 22:39:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/22/2022 22:39:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/22/2022 22:39:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/22/2022 22:39:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/22/2022 22:39:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/22/2022 22:39:41 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.9054151803978409 on epoch=103
06/22/2022 22:39:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8105742327317561 -> 0.9054151803978409 on epoch=103, global_step=1450
06/22/2022 22:39:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/22/2022 22:39:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/22/2022 22:39:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/22/2022 22:39:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/22/2022 22:39:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/22/2022 22:40:01 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.9100423590746171 on epoch=107
06/22/2022 22:40:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9054151803978409 -> 0.9100423590746171 on epoch=107, global_step=1500
06/22/2022 22:40:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/22/2022 22:40:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/22/2022 22:40:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/22/2022 22:40:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/22/2022 22:40:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/22/2022 22:40:20 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9016934525520862 on epoch=110
06/22/2022 22:40:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/22/2022 22:40:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/22/2022 22:40:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/22/2022 22:40:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/22/2022 22:40:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/22/2022 22:40:40 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9059945278209035 on epoch=114
06/22/2022 22:40:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/22/2022 22:40:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/22/2022 22:40:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/22/2022 22:40:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/22/2022 22:40:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/22/2022 22:40:59 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8431870741331724 on epoch=117
06/22/2022 22:41:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/22/2022 22:41:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/22/2022 22:41:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/22/2022 22:41:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/22/2022 22:41:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/22/2022 22:41:20 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9818181818181818 on epoch=121
06/22/2022 22:41:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9100423590746171 -> 0.9818181818181818 on epoch=121, global_step=1700
06/22/2022 22:41:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/22/2022 22:41:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/22/2022 22:41:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/22/2022 22:41:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/22/2022 22:41:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/22/2022 22:41:39 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9060075613823242 on epoch=124
06/22/2022 22:41:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/22/2022 22:41:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
06/22/2022 22:41:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/22/2022 22:41:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/22/2022 22:41:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/22/2022 22:41:59 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8487191418495298 on epoch=128
06/22/2022 22:42:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/22/2022 22:42:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/22/2022 22:42:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/22/2022 22:42:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/22/2022 22:42:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/22/2022 22:42:19 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8436105850168351 on epoch=132
06/22/2022 22:42:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/22/2022 22:42:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/22/2022 22:42:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/22/2022 22:42:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/22/2022 22:42:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/22/2022 22:42:39 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8322253857758484 on epoch=135
06/22/2022 22:42:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/22/2022 22:42:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/22/2022 22:42:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/22/2022 22:42:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/22/2022 22:42:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/22/2022 22:42:58 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8334852168506699 on epoch=139
06/22/2022 22:43:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/22/2022 22:43:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/22/2022 22:43:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/22/2022 22:43:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/22/2022 22:43:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/22/2022 22:43:18 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8332024953082153 on epoch=142
06/22/2022 22:43:21 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/22/2022 22:43:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/22/2022 22:43:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/22/2022 22:43:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/22/2022 22:43:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/22/2022 22:43:38 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9018449677036015 on epoch=146
06/22/2022 22:43:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/22/2022 22:43:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/22/2022 22:43:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/22/2022 22:43:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/22/2022 22:43:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/22/2022 22:43:57 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9019541237804993 on epoch=149
06/22/2022 22:44:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/22/2022 22:44:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/22/2022 22:44:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/22/2022 22:44:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/22/2022 22:44:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/22/2022 22:44:17 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9056929581756187 on epoch=153
06/22/2022 22:44:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/22/2022 22:44:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/22/2022 22:44:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/22/2022 22:44:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/22/2022 22:44:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/22/2022 22:44:36 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7811470078994356 on epoch=157
06/22/2022 22:44:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/22/2022 22:44:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/22/2022 22:44:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/22/2022 22:44:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/22/2022 22:44:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/22/2022 22:44:56 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8408691719412782 on epoch=160
06/22/2022 22:44:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/22/2022 22:45:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/22/2022 22:45:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/22/2022 22:45:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/22/2022 22:45:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/22/2022 22:45:15 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9056929581756187 on epoch=164
06/22/2022 22:45:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/22/2022 22:45:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/22/2022 22:45:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/22/2022 22:45:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/22/2022 22:45:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/22/2022 22:45:35 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7377561412494473 on epoch=167
06/22/2022 22:45:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/22/2022 22:45:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
06/22/2022 22:45:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/22/2022 22:45:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/22/2022 22:45:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/22/2022 22:45:54 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7046244573197035 on epoch=171
06/22/2022 22:45:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/22/2022 22:45:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/22/2022 22:46:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/22/2022 22:46:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/22/2022 22:46:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/22/2022 22:46:14 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7480982163329833 on epoch=174
06/22/2022 22:46:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/22/2022 22:46:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/22/2022 22:46:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/22/2022 22:46:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/22/2022 22:46:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/22/2022 22:46:33 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7866276571196205 on epoch=178
06/22/2022 22:46:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/22/2022 22:46:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/22/2022 22:46:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/22/2022 22:46:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/22/2022 22:46:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/22/2022 22:46:53 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8407890343226481 on epoch=182
06/22/2022 22:46:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/22/2022 22:46:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/22/2022 22:47:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/22/2022 22:47:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/22/2022 22:47:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/22/2022 22:47:12 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7939864329570212 on epoch=185
06/22/2022 22:47:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/22/2022 22:47:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/22/2022 22:47:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/22/2022 22:47:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/22/2022 22:47:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/22/2022 22:47:32 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8292498999656257 on epoch=189
06/22/2022 22:47:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/22/2022 22:47:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=190
06/22/2022 22:47:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/22/2022 22:47:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/22/2022 22:47:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/22/2022 22:47:51 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.831797474192568 on epoch=192
06/22/2022 22:47:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/22/2022 22:47:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/22/2022 22:47:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/22/2022 22:48:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/22/2022 22:48:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/22/2022 22:48:10 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.829567200831187 on epoch=196
06/22/2022 22:48:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/22/2022 22:48:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/22/2022 22:48:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/22/2022 22:48:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/22/2022 22:48:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/22/2022 22:48:30 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7807691301940584 on epoch=199
06/22/2022 22:48:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/22/2022 22:48:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/22/2022 22:48:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/22/2022 22:48:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/22/2022 22:48:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/22/2022 22:48:49 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7228403215806277 on epoch=203
06/22/2022 22:48:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/22/2022 22:48:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/22/2022 22:48:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/22/2022 22:48:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/22/2022 22:49:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/22/2022 22:49:08 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7668271742024393 on epoch=207
06/22/2022 22:49:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/22/2022 22:49:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/22/2022 22:49:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/22/2022 22:49:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/22/2022 22:49:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/22/2022 22:49:27 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6536715142514993 on epoch=210
06/22/2022 22:49:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/22/2022 22:49:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/22/2022 22:49:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/22/2022 22:49:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/22/2022 22:49:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/22/2022 22:49:42 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:49:42 - INFO - __main__ - Printing 3 examples
06/22/2022 22:49:42 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 22:49:42 - INFO - __main__ - ['Animal']
06/22/2022 22:49:42 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 22:49:42 - INFO - __main__ - ['Animal']
06/22/2022 22:49:42 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 22:49:42 - INFO - __main__ - ['Animal']
06/22/2022 22:49:42 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:49:42 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:49:42 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 22:49:42 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:49:42 - INFO - __main__ - Printing 3 examples
06/22/2022 22:49:42 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 22:49:42 - INFO - __main__ - ['Animal']
06/22/2022 22:49:42 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 22:49:42 - INFO - __main__ - ['Animal']
06/22/2022 22:49:42 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 22:49:42 - INFO - __main__ - ['Animal']
06/22/2022 22:49:42 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:49:42 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:49:43 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 22:49:47 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6747188920239386 on epoch=214
06/22/2022 22:49:47 - INFO - __main__ - save last model!
06/22/2022 22:49:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 22:49:47 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 22:49:47 - INFO - __main__ - Printing 3 examples
06/22/2022 22:49:47 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 22:49:47 - INFO - __main__ - ['Animal']
06/22/2022 22:49:47 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 22:49:47 - INFO - __main__ - ['Animal']
06/22/2022 22:49:47 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 22:49:47 - INFO - __main__ - ['Village']
06/22/2022 22:49:47 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:49:49 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:49:52 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 22:49:58 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 22:49:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 22:49:58 - INFO - __main__ - Starting training!
06/22/2022 22:52:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/22/2022 22:52:01 - INFO - __main__ - Classification-F1 on test data: 0.4245
06/22/2022 22:52:01 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9818181818181818, test_performance=0.4245047155527624
06/22/2022 22:52:01 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/22/2022 22:52:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:52:02 - INFO - __main__ - Printing 3 examples
06/22/2022 22:52:02 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 22:52:02 - INFO - __main__ - ['Animal']
06/22/2022 22:52:02 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 22:52:02 - INFO - __main__ - ['Animal']
06/22/2022 22:52:02 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 22:52:02 - INFO - __main__ - ['Animal']
06/22/2022 22:52:02 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:52:02 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:52:02 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 22:52:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 22:52:02 - INFO - __main__ - Printing 3 examples
06/22/2022 22:52:02 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 22:52:02 - INFO - __main__ - ['Animal']
06/22/2022 22:52:02 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 22:52:02 - INFO - __main__ - ['Animal']
06/22/2022 22:52:02 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 22:52:02 - INFO - __main__ - ['Animal']
06/22/2022 22:52:02 - INFO - __main__ - Tokenizing Input ...
06/22/2022 22:52:02 - INFO - __main__ - Tokenizing Output ...
06/22/2022 22:52:03 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 22:52:18 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 22:52:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 22:52:19 - INFO - __main__ - Starting training!
06/22/2022 22:52:22 - INFO - __main__ - Step 10 Global step 10 Train loss 6.80 on epoch=0
06/22/2022 22:52:25 - INFO - __main__ - Step 20 Global step 20 Train loss 5.26 on epoch=1
06/22/2022 22:52:27 - INFO - __main__ - Step 30 Global step 30 Train loss 4.44 on epoch=2
06/22/2022 22:52:30 - INFO - __main__ - Step 40 Global step 40 Train loss 4.05 on epoch=2
06/22/2022 22:52:32 - INFO - __main__ - Step 50 Global step 50 Train loss 3.80 on epoch=3
06/22/2022 22:52:38 - INFO - __main__ - Global step 50 Train loss 4.87 Classification-F1 0.041288879369838896 on epoch=3
06/22/2022 22:52:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.041288879369838896 on epoch=3, global_step=50
06/22/2022 22:52:41 - INFO - __main__ - Step 60 Global step 60 Train loss 3.44 on epoch=4
06/22/2022 22:52:43 - INFO - __main__ - Step 70 Global step 70 Train loss 3.19 on epoch=4
06/22/2022 22:52:46 - INFO - __main__ - Step 80 Global step 80 Train loss 3.01 on epoch=5
06/22/2022 22:52:48 - INFO - __main__ - Step 90 Global step 90 Train loss 2.79 on epoch=6
06/22/2022 22:52:51 - INFO - __main__ - Step 100 Global step 100 Train loss 2.81 on epoch=7
06/22/2022 22:52:56 - INFO - __main__ - Global step 100 Train loss 3.05 Classification-F1 0.0698356110120816 on epoch=7
06/22/2022 22:52:56 - INFO - __main__ - Saving model with best Classification-F1: 0.041288879369838896 -> 0.0698356110120816 on epoch=7, global_step=100
06/22/2022 22:52:58 - INFO - __main__ - Step 110 Global step 110 Train loss 2.52 on epoch=7
06/22/2022 22:53:01 - INFO - __main__ - Step 120 Global step 120 Train loss 2.49 on epoch=8
06/22/2022 22:53:03 - INFO - __main__ - Step 130 Global step 130 Train loss 2.33 on epoch=9
06/22/2022 22:53:06 - INFO - __main__ - Step 140 Global step 140 Train loss 2.22 on epoch=9
06/22/2022 22:53:09 - INFO - __main__ - Step 150 Global step 150 Train loss 2.19 on epoch=10
06/22/2022 22:53:14 - INFO - __main__ - Global step 150 Train loss 2.35 Classification-F1 0.08675466443887496 on epoch=10
06/22/2022 22:53:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0698356110120816 -> 0.08675466443887496 on epoch=10, global_step=150
06/22/2022 22:53:17 - INFO - __main__ - Step 160 Global step 160 Train loss 1.83 on epoch=11
06/22/2022 22:53:19 - INFO - __main__ - Step 170 Global step 170 Train loss 1.92 on epoch=12
06/22/2022 22:53:22 - INFO - __main__ - Step 180 Global step 180 Train loss 1.72 on epoch=12
06/22/2022 22:53:24 - INFO - __main__ - Step 190 Global step 190 Train loss 1.68 on epoch=13
06/22/2022 22:53:27 - INFO - __main__ - Step 200 Global step 200 Train loss 1.68 on epoch=14
06/22/2022 22:53:33 - INFO - __main__ - Global step 200 Train loss 1.77 Classification-F1 0.09769242629706683 on epoch=14
06/22/2022 22:53:33 - INFO - __main__ - Saving model with best Classification-F1: 0.08675466443887496 -> 0.09769242629706683 on epoch=14, global_step=200
06/22/2022 22:53:35 - INFO - __main__ - Step 210 Global step 210 Train loss 1.39 on epoch=14
06/22/2022 22:53:38 - INFO - __main__ - Step 220 Global step 220 Train loss 1.45 on epoch=15
06/22/2022 22:53:40 - INFO - __main__ - Step 230 Global step 230 Train loss 1.32 on epoch=16
06/22/2022 22:53:43 - INFO - __main__ - Step 240 Global step 240 Train loss 1.32 on epoch=17
06/22/2022 22:53:45 - INFO - __main__ - Step 250 Global step 250 Train loss 1.29 on epoch=17
06/22/2022 22:53:51 - INFO - __main__ - Global step 250 Train loss 1.35 Classification-F1 0.15522814773018448 on epoch=17
06/22/2022 22:53:51 - INFO - __main__ - Saving model with best Classification-F1: 0.09769242629706683 -> 0.15522814773018448 on epoch=17, global_step=250
06/22/2022 22:53:54 - INFO - __main__ - Step 260 Global step 260 Train loss 1.11 on epoch=18
06/22/2022 22:53:56 - INFO - __main__ - Step 270 Global step 270 Train loss 1.07 on epoch=19
06/22/2022 22:53:59 - INFO - __main__ - Step 280 Global step 280 Train loss 1.00 on epoch=19
06/22/2022 22:54:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.96 on epoch=20
06/22/2022 22:54:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=21
06/22/2022 22:54:10 - INFO - __main__ - Global step 300 Train loss 0.98 Classification-F1 0.21809865053788907 on epoch=21
06/22/2022 22:54:10 - INFO - __main__ - Saving model with best Classification-F1: 0.15522814773018448 -> 0.21809865053788907 on epoch=21, global_step=300
06/22/2022 22:54:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.96 on epoch=22
06/22/2022 22:54:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=22
06/22/2022 22:54:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.89 on epoch=23
06/22/2022 22:54:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=24
06/22/2022 22:54:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=24
06/22/2022 22:54:30 - INFO - __main__ - Global step 350 Train loss 0.79 Classification-F1 0.3243592641403312 on epoch=24
06/22/2022 22:54:30 - INFO - __main__ - Saving model with best Classification-F1: 0.21809865053788907 -> 0.3243592641403312 on epoch=24, global_step=350
06/22/2022 22:54:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=25
06/22/2022 22:54:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.62 on epoch=26
06/22/2022 22:54:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.75 on epoch=27
06/22/2022 22:54:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
06/22/2022 22:54:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=28
06/22/2022 22:54:50 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.4019000596159858 on epoch=28
06/22/2022 22:54:50 - INFO - __main__ - Saving model with best Classification-F1: 0.3243592641403312 -> 0.4019000596159858 on epoch=28, global_step=400
06/22/2022 22:54:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
06/22/2022 22:54:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=29
06/22/2022 22:54:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=30
06/22/2022 22:55:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=31
06/22/2022 22:55:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=32
06/22/2022 22:55:10 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.4672821677571107 on epoch=32
06/22/2022 22:55:10 - INFO - __main__ - Saving model with best Classification-F1: 0.4019000596159858 -> 0.4672821677571107 on epoch=32, global_step=450
06/22/2022 22:55:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/22/2022 22:55:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
06/22/2022 22:55:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
06/22/2022 22:55:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=34
06/22/2022 22:55:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=35
06/22/2022 22:55:30 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.47438565363503327 on epoch=35
06/22/2022 22:55:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4672821677571107 -> 0.47438565363503327 on epoch=35, global_step=500
06/22/2022 22:55:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=36
06/22/2022 22:55:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
06/22/2022 22:55:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=37
06/22/2022 22:55:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
06/22/2022 22:55:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=39
06/22/2022 22:55:50 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.590140724378261 on epoch=39
06/22/2022 22:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.47438565363503327 -> 0.590140724378261 on epoch=39, global_step=550
06/22/2022 22:55:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
06/22/2022 22:55:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
06/22/2022 22:55:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=41
06/22/2022 22:56:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=42
06/22/2022 22:56:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
06/22/2022 22:56:10 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.5477822240094331 on epoch=42
06/22/2022 22:56:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.42 on epoch=43
06/22/2022 22:56:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=44
06/22/2022 22:56:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=44
06/22/2022 22:56:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=45
06/22/2022 22:56:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=46
06/22/2022 22:56:30 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.6709695228370949 on epoch=46
06/22/2022 22:56:30 - INFO - __main__ - Saving model with best Classification-F1: 0.590140724378261 -> 0.6709695228370949 on epoch=46, global_step=650
06/22/2022 22:56:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=47
06/22/2022 22:56:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/22/2022 22:56:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=48
06/22/2022 22:56:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/22/2022 22:56:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=49
06/22/2022 22:56:50 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6451831434694337 on epoch=49
06/22/2022 22:56:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/22/2022 22:56:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/22/2022 22:56:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=52
06/22/2022 22:57:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/22/2022 22:57:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=53
06/22/2022 22:57:11 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6622050705952741 on epoch=53
06/22/2022 22:57:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/22/2022 22:57:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=54
06/22/2022 22:57:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
06/22/2022 22:57:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=56
06/22/2022 22:57:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/22/2022 22:57:31 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.595753864300045 on epoch=57
06/22/2022 22:57:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/22/2022 22:57:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
06/22/2022 22:57:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
06/22/2022 22:57:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/22/2022 22:57:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=60
06/22/2022 22:57:51 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.6498213291101016 on epoch=60
06/22/2022 22:57:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
06/22/2022 22:57:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=62
06/22/2022 22:57:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
06/22/2022 22:58:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=63
06/22/2022 22:58:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
06/22/2022 22:58:11 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7216051772927303 on epoch=64
06/22/2022 22:58:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6709695228370949 -> 0.7216051772927303 on epoch=64, global_step=900
06/22/2022 22:58:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=64
06/22/2022 22:58:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/22/2022 22:58:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=66
06/22/2022 22:58:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/22/2022 22:58:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/22/2022 22:58:31 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6843354823193533 on epoch=67
06/22/2022 22:58:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/22/2022 22:58:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
06/22/2022 22:58:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=69
06/22/2022 22:58:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
06/22/2022 22:58:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/22/2022 22:58:51 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7252827132808157 on epoch=71
06/22/2022 22:58:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7216051772927303 -> 0.7252827132808157 on epoch=71, global_step=1000
06/22/2022 22:58:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
06/22/2022 22:58:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=72
06/22/2022 22:58:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
06/22/2022 22:59:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/22/2022 22:59:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
06/22/2022 22:59:11 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.682630426534601 on epoch=74
06/22/2022 22:59:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/22/2022 22:59:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/22/2022 22:59:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/22/2022 22:59:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
06/22/2022 22:59:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/22/2022 22:59:31 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6902989478430214 on epoch=78
06/22/2022 22:59:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/22/2022 22:59:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
06/22/2022 22:59:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/22/2022 22:59:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
06/22/2022 22:59:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/22/2022 22:59:51 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.7011925631434548 on epoch=82
06/22/2022 22:59:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/22/2022 22:59:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
06/22/2022 22:59:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
06/22/2022 23:00:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=84
06/22/2022 23:00:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/22/2022 23:00:12 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6369020083132986 on epoch=85
06/22/2022 23:00:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/22/2022 23:00:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/22/2022 23:00:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/22/2022 23:00:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/22/2022 23:00:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/22/2022 23:00:32 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6634012021745469 on epoch=89
06/22/2022 23:00:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/22/2022 23:00:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/22/2022 23:00:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/22/2022 23:00:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
06/22/2022 23:00:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/22/2022 23:00:52 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7198938307809275 on epoch=92
06/22/2022 23:00:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/22/2022 23:00:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/22/2022 23:01:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/22/2022 23:01:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/22/2022 23:01:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=96
06/22/2022 23:01:13 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.7003355713330246 on epoch=96
06/22/2022 23:01:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=97
06/22/2022 23:01:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=97
06/22/2022 23:01:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
06/22/2022 23:01:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/22/2022 23:01:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/22/2022 23:01:33 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.7006383973561643 on epoch=99
06/22/2022 23:01:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/22/2022 23:01:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/22/2022 23:01:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
06/22/2022 23:01:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/22/2022 23:01:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/22/2022 23:01:53 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7865230579035133 on epoch=103
06/22/2022 23:01:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7252827132808157 -> 0.7865230579035133 on epoch=103, global_step=1450
06/22/2022 23:01:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/22/2022 23:01:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/22/2022 23:02:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/22/2022 23:02:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/22/2022 23:02:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=107
06/22/2022 23:02:13 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7009273550445027 on epoch=107
06/22/2022 23:02:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/22/2022 23:02:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
06/22/2022 23:02:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=109
06/22/2022 23:02:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/22/2022 23:02:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/22/2022 23:02:33 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7969120472539304 on epoch=110
06/22/2022 23:02:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7865230579035133 -> 0.7969120472539304 on epoch=110, global_step=1550
06/22/2022 23:02:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/22/2022 23:02:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/22/2022 23:02:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/22/2022 23:02:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/22/2022 23:02:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/22/2022 23:02:53 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9015876507005539 on epoch=114
06/22/2022 23:02:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7969120472539304 -> 0.9015876507005539 on epoch=114, global_step=1600
06/22/2022 23:02:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
06/22/2022 23:02:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=115
06/22/2022 23:03:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/22/2022 23:03:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=117
06/22/2022 23:03:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/22/2022 23:03:13 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.9016934525520862 on epoch=117
06/22/2022 23:03:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9015876507005539 -> 0.9016934525520862 on epoch=117, global_step=1650
06/22/2022 23:03:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
06/22/2022 23:03:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/22/2022 23:03:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/22/2022 23:03:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/22/2022 23:03:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/22/2022 23:03:33 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9015876507005539 on epoch=121
06/22/2022 23:03:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/22/2022 23:03:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/22/2022 23:03:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/22/2022 23:03:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/22/2022 23:03:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/22/2022 23:03:53 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9682909160731741 on epoch=124
06/22/2022 23:03:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9016934525520862 -> 0.9682909160731741 on epoch=124, global_step=1750
06/22/2022 23:03:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/22/2022 23:03:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/22/2022 23:04:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/22/2022 23:04:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/22/2022 23:04:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/22/2022 23:04:13 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9682909160731741 on epoch=128
06/22/2022 23:04:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/22/2022 23:04:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
06/22/2022 23:04:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/22/2022 23:04:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/22/2022 23:04:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/22/2022 23:04:34 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.9682909160731741 on epoch=132
06/22/2022 23:04:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/22/2022 23:04:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/22/2022 23:04:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/22/2022 23:04:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=134
06/22/2022 23:04:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/22/2022 23:04:53 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.972903574919704 on epoch=135
06/22/2022 23:04:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9682909160731741 -> 0.972903574919704 on epoch=135, global_step=1900
06/22/2022 23:04:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/22/2022 23:04:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/22/2022 23:05:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/22/2022 23:05:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/22/2022 23:05:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/22/2022 23:05:13 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.9684042751998158 on epoch=139
06/22/2022 23:05:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/22/2022 23:05:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/22/2022 23:05:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/22/2022 23:05:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/22/2022 23:05:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/22/2022 23:05:33 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.972903574919704 on epoch=142
06/22/2022 23:05:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/22/2022 23:05:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/22/2022 23:05:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/22/2022 23:05:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=145
06/22/2022 23:05:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/22/2022 23:05:53 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8511684384164223 on epoch=146
06/22/2022 23:05:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/22/2022 23:05:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/22/2022 23:06:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/22/2022 23:06:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/22/2022 23:06:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/22/2022 23:06:12 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.972903574919704 on epoch=149
06/22/2022 23:06:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/22/2022 23:06:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/22/2022 23:06:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/22/2022 23:06:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/22/2022 23:06:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/22/2022 23:06:32 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9058927989573149 on epoch=153
06/22/2022 23:06:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/22/2022 23:06:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/22/2022 23:06:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/22/2022 23:06:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/22/2022 23:06:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/22/2022 23:06:52 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.972903574919704 on epoch=157
06/22/2022 23:06:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/22/2022 23:06:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/22/2022 23:07:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/22/2022 23:07:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/22/2022 23:07:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/22/2022 23:07:12 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.972903574919704 on epoch=160
06/22/2022 23:07:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/22/2022 23:07:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
06/22/2022 23:07:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/22/2022 23:07:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/22/2022 23:07:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/22/2022 23:07:32 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9100594656239819 on epoch=164
06/22/2022 23:07:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/22/2022 23:07:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/22/2022 23:07:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/22/2022 23:07:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/22/2022 23:07:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
06/22/2022 23:07:52 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9016934525520862 on epoch=167
06/22/2022 23:07:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/22/2022 23:07:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/22/2022 23:08:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/22/2022 23:08:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/22/2022 23:08:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/22/2022 23:08:12 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7464017369918171 on epoch=171
06/22/2022 23:08:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/22/2022 23:08:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/22/2022 23:08:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/22/2022 23:08:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/22/2022 23:08:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/22/2022 23:08:32 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9057583903551645 on epoch=174
06/22/2022 23:08:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/22/2022 23:08:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/22/2022 23:08:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/22/2022 23:08:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/22/2022 23:08:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/22/2022 23:08:52 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9684042751998158 on epoch=178
06/22/2022 23:08:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/22/2022 23:08:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
06/22/2022 23:09:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/22/2022 23:09:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/22/2022 23:09:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/22/2022 23:09:12 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9773678606339897 on epoch=182
06/22/2022 23:09:12 - INFO - __main__ - Saving model with best Classification-F1: 0.972903574919704 -> 0.9773678606339897 on epoch=182, global_step=2550
06/22/2022 23:09:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/22/2022 23:09:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/22/2022 23:09:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/22/2022 23:09:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/22/2022 23:09:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/22/2022 23:09:32 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9686852086875807 on epoch=185
06/22/2022 23:09:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/22/2022 23:09:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/22/2022 23:09:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/22/2022 23:09:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/22/2022 23:09:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/22/2022 23:09:53 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8976415483104287 on epoch=189
06/22/2022 23:09:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/22/2022 23:09:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/22/2022 23:10:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/22/2022 23:10:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/22/2022 23:10:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/22/2022 23:10:13 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9100423590746171 on epoch=192
06/22/2022 23:10:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/22/2022 23:10:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/22/2022 23:10:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/22/2022 23:10:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/22/2022 23:10:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/22/2022 23:10:33 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8426555215617716 on epoch=196
06/22/2022 23:10:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/22/2022 23:10:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/22/2022 23:10:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/22/2022 23:10:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/22/2022 23:10:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/22/2022 23:10:52 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8467152317811035 on epoch=199
06/22/2022 23:10:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/22/2022 23:10:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/22/2022 23:11:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/22/2022 23:11:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/22/2022 23:11:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/22/2022 23:11:12 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9013285565009703 on epoch=203
06/22/2022 23:11:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/22/2022 23:11:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/22/2022 23:11:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/22/2022 23:11:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/22/2022 23:11:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/22/2022 23:11:32 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9052963449848878 on epoch=207
06/22/2022 23:11:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/22/2022 23:11:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/22/2022 23:11:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/22/2022 23:11:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/22/2022 23:11:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/22/2022 23:11:52 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8970908076379842 on epoch=210
06/22/2022 23:11:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/22/2022 23:11:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/22/2022 23:11:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/22/2022 23:12:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/22/2022 23:12:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/22/2022 23:12:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:12:06 - INFO - __main__ - Printing 3 examples
06/22/2022 23:12:06 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 23:12:06 - INFO - __main__ - ['Animal']
06/22/2022 23:12:06 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 23:12:06 - INFO - __main__ - ['Animal']
06/22/2022 23:12:06 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 23:12:06 - INFO - __main__ - ['Animal']
06/22/2022 23:12:06 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:12:06 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:12:06 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 23:12:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:12:06 - INFO - __main__ - Printing 3 examples
06/22/2022 23:12:06 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 23:12:06 - INFO - __main__ - ['Animal']
06/22/2022 23:12:06 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 23:12:06 - INFO - __main__ - ['Animal']
06/22/2022 23:12:06 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 23:12:06 - INFO - __main__ - ['Animal']
06/22/2022 23:12:06 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:12:07 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:12:07 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 23:12:11 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9035948191593354 on epoch=214
06/22/2022 23:12:11 - INFO - __main__ - save last model!
06/22/2022 23:12:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 23:12:12 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 23:12:12 - INFO - __main__ - Printing 3 examples
06/22/2022 23:12:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 23:12:12 - INFO - __main__ - ['Animal']
06/22/2022 23:12:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 23:12:12 - INFO - __main__ - ['Animal']
06/22/2022 23:12:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 23:12:12 - INFO - __main__ - ['Village']
06/22/2022 23:12:12 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:12:13 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:12:17 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 23:12:22 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 23:12:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 23:12:23 - INFO - __main__ - Starting training!
06/22/2022 23:14:31 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/22/2022 23:14:31 - INFO - __main__ - Classification-F1 on test data: 0.5643
06/22/2022 23:14:31 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9773678606339897, test_performance=0.5643124935090912
06/22/2022 23:14:31 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/22/2022 23:14:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:14:32 - INFO - __main__ - Printing 3 examples
06/22/2022 23:14:32 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/22/2022 23:14:32 - INFO - __main__ - ['Animal']
06/22/2022 23:14:32 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/22/2022 23:14:32 - INFO - __main__ - ['Animal']
06/22/2022 23:14:32 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/22/2022 23:14:32 - INFO - __main__ - ['Animal']
06/22/2022 23:14:32 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:14:32 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:14:32 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 23:14:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:14:32 - INFO - __main__ - Printing 3 examples
06/22/2022 23:14:32 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/22/2022 23:14:32 - INFO - __main__ - ['Animal']
06/22/2022 23:14:32 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/22/2022 23:14:32 - INFO - __main__ - ['Animal']
06/22/2022 23:14:32 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/22/2022 23:14:32 - INFO - __main__ - ['Animal']
06/22/2022 23:14:32 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:14:33 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:14:33 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 23:14:48 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 23:14:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 23:14:49 - INFO - __main__ - Starting training!
06/22/2022 23:14:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.27 on epoch=0
06/22/2022 23:14:55 - INFO - __main__ - Step 20 Global step 20 Train loss 5.35 on epoch=1
06/22/2022 23:14:58 - INFO - __main__ - Step 30 Global step 30 Train loss 5.05 on epoch=2
06/22/2022 23:15:00 - INFO - __main__ - Step 40 Global step 40 Train loss 4.53 on epoch=2
06/22/2022 23:15:03 - INFO - __main__ - Step 50 Global step 50 Train loss 4.32 on epoch=3
06/22/2022 23:15:08 - INFO - __main__ - Global step 50 Train loss 5.10 Classification-F1 0.039595937340298246 on epoch=3
06/22/2022 23:15:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.039595937340298246 on epoch=3, global_step=50
06/22/2022 23:15:11 - INFO - __main__ - Step 60 Global step 60 Train loss 4.07 on epoch=4
06/22/2022 23:15:13 - INFO - __main__ - Step 70 Global step 70 Train loss 3.75 on epoch=4
06/22/2022 23:15:16 - INFO - __main__ - Step 80 Global step 80 Train loss 3.44 on epoch=5
06/22/2022 23:15:19 - INFO - __main__ - Step 90 Global step 90 Train loss 3.46 on epoch=6
06/22/2022 23:15:21 - INFO - __main__ - Step 100 Global step 100 Train loss 3.32 on epoch=7
06/22/2022 23:15:26 - INFO - __main__ - Global step 100 Train loss 3.61 Classification-F1 0.05549101600018741 on epoch=7
06/22/2022 23:15:26 - INFO - __main__ - Saving model with best Classification-F1: 0.039595937340298246 -> 0.05549101600018741 on epoch=7, global_step=100
06/22/2022 23:15:29 - INFO - __main__ - Step 110 Global step 110 Train loss 3.03 on epoch=7
06/22/2022 23:15:32 - INFO - __main__ - Step 120 Global step 120 Train loss 3.01 on epoch=8
06/22/2022 23:15:34 - INFO - __main__ - Step 130 Global step 130 Train loss 2.82 on epoch=9
06/22/2022 23:15:37 - INFO - __main__ - Step 140 Global step 140 Train loss 2.73 on epoch=9
06/22/2022 23:15:39 - INFO - __main__ - Step 150 Global step 150 Train loss 2.56 on epoch=10
06/22/2022 23:15:45 - INFO - __main__ - Global step 150 Train loss 2.83 Classification-F1 0.06737520128824477 on epoch=10
06/22/2022 23:15:45 - INFO - __main__ - Saving model with best Classification-F1: 0.05549101600018741 -> 0.06737520128824477 on epoch=10, global_step=150
06/22/2022 23:15:47 - INFO - __main__ - Step 160 Global step 160 Train loss 2.48 on epoch=11
06/22/2022 23:15:50 - INFO - __main__ - Step 170 Global step 170 Train loss 2.43 on epoch=12
06/22/2022 23:15:52 - INFO - __main__ - Step 180 Global step 180 Train loss 2.20 on epoch=12
06/22/2022 23:15:55 - INFO - __main__ - Step 190 Global step 190 Train loss 2.24 on epoch=13
06/22/2022 23:15:57 - INFO - __main__ - Step 200 Global step 200 Train loss 2.20 on epoch=14
06/22/2022 23:16:03 - INFO - __main__ - Global step 200 Train loss 2.31 Classification-F1 0.0835728903334537 on epoch=14
06/22/2022 23:16:03 - INFO - __main__ - Saving model with best Classification-F1: 0.06737520128824477 -> 0.0835728903334537 on epoch=14, global_step=200
06/22/2022 23:16:05 - INFO - __main__ - Step 210 Global step 210 Train loss 2.11 on epoch=14
06/22/2022 23:16:08 - INFO - __main__ - Step 220 Global step 220 Train loss 2.06 on epoch=15
06/22/2022 23:16:10 - INFO - __main__ - Step 230 Global step 230 Train loss 1.81 on epoch=16
06/22/2022 23:16:13 - INFO - __main__ - Step 240 Global step 240 Train loss 2.03 on epoch=17
06/22/2022 23:16:15 - INFO - __main__ - Step 250 Global step 250 Train loss 1.85 on epoch=17
06/22/2022 23:16:21 - INFO - __main__ - Global step 250 Train loss 1.97 Classification-F1 0.09214885727918787 on epoch=17
06/22/2022 23:16:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0835728903334537 -> 0.09214885727918787 on epoch=17, global_step=250
06/22/2022 23:16:24 - INFO - __main__ - Step 260 Global step 260 Train loss 1.75 on epoch=18
06/22/2022 23:16:26 - INFO - __main__ - Step 270 Global step 270 Train loss 1.73 on epoch=19
06/22/2022 23:16:29 - INFO - __main__ - Step 280 Global step 280 Train loss 1.59 on epoch=19
06/22/2022 23:16:31 - INFO - __main__ - Step 290 Global step 290 Train loss 1.64 on epoch=20
06/22/2022 23:16:34 - INFO - __main__ - Step 300 Global step 300 Train loss 1.47 on epoch=21
06/22/2022 23:16:40 - INFO - __main__ - Global step 300 Train loss 1.64 Classification-F1 0.10935784324988201 on epoch=21
06/22/2022 23:16:40 - INFO - __main__ - Saving model with best Classification-F1: 0.09214885727918787 -> 0.10935784324988201 on epoch=21, global_step=300
06/22/2022 23:16:42 - INFO - __main__ - Step 310 Global step 310 Train loss 1.44 on epoch=22
06/22/2022 23:16:45 - INFO - __main__ - Step 320 Global step 320 Train loss 1.39 on epoch=22
06/22/2022 23:16:47 - INFO - __main__ - Step 330 Global step 330 Train loss 1.41 on epoch=23
06/22/2022 23:16:50 - INFO - __main__ - Step 340 Global step 340 Train loss 1.41 on epoch=24
06/22/2022 23:16:53 - INFO - __main__ - Step 350 Global step 350 Train loss 1.11 on epoch=24
06/22/2022 23:16:58 - INFO - __main__ - Global step 350 Train loss 1.35 Classification-F1 0.1271614694808085 on epoch=24
06/22/2022 23:16:58 - INFO - __main__ - Saving model with best Classification-F1: 0.10935784324988201 -> 0.1271614694808085 on epoch=24, global_step=350
06/22/2022 23:17:01 - INFO - __main__ - Step 360 Global step 360 Train loss 1.25 on epoch=25
06/22/2022 23:17:03 - INFO - __main__ - Step 370 Global step 370 Train loss 1.10 on epoch=26
06/22/2022 23:17:06 - INFO - __main__ - Step 380 Global step 380 Train loss 1.08 on epoch=27
06/22/2022 23:17:09 - INFO - __main__ - Step 390 Global step 390 Train loss 1.11 on epoch=27
06/22/2022 23:17:11 - INFO - __main__ - Step 400 Global step 400 Train loss 1.03 on epoch=28
06/22/2022 23:17:17 - INFO - __main__ - Global step 400 Train loss 1.11 Classification-F1 0.18617790983823318 on epoch=28
06/22/2022 23:17:17 - INFO - __main__ - Saving model with best Classification-F1: 0.1271614694808085 -> 0.18617790983823318 on epoch=28, global_step=400
06/22/2022 23:17:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.98 on epoch=29
06/22/2022 23:17:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.89 on epoch=29
06/22/2022 23:17:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.88 on epoch=30
06/22/2022 23:17:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.76 on epoch=31
06/22/2022 23:17:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.95 on epoch=32
06/22/2022 23:17:36 - INFO - __main__ - Global step 450 Train loss 0.89 Classification-F1 0.28061937093409256 on epoch=32
06/22/2022 23:17:36 - INFO - __main__ - Saving model with best Classification-F1: 0.18617790983823318 -> 0.28061937093409256 on epoch=32, global_step=450
06/22/2022 23:17:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.85 on epoch=32
06/22/2022 23:17:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.68 on epoch=33
06/22/2022 23:17:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.73 on epoch=34
06/22/2022 23:17:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.77 on epoch=34
06/22/2022 23:17:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.66 on epoch=35
06/22/2022 23:17:56 - INFO - __main__ - Global step 500 Train loss 0.74 Classification-F1 0.3105602411424239 on epoch=35
06/22/2022 23:17:56 - INFO - __main__ - Saving model with best Classification-F1: 0.28061937093409256 -> 0.3105602411424239 on epoch=35, global_step=500
06/22/2022 23:17:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.66 on epoch=36
06/22/2022 23:18:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.62 on epoch=37
06/22/2022 23:18:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.72 on epoch=37
06/22/2022 23:18:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.65 on epoch=38
06/22/2022 23:18:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.66 on epoch=39
06/22/2022 23:18:16 - INFO - __main__ - Global step 550 Train loss 0.66 Classification-F1 0.339998768913185 on epoch=39
06/22/2022 23:18:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3105602411424239 -> 0.339998768913185 on epoch=39, global_step=550
06/22/2022 23:18:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=39
06/22/2022 23:18:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.54 on epoch=40
06/22/2022 23:18:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.53 on epoch=41
06/22/2022 23:18:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.51 on epoch=42
06/22/2022 23:18:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.52 on epoch=42
06/22/2022 23:18:35 - INFO - __main__ - Global step 600 Train loss 0.53 Classification-F1 0.35617390674251714 on epoch=42
06/22/2022 23:18:35 - INFO - __main__ - Saving model with best Classification-F1: 0.339998768913185 -> 0.35617390674251714 on epoch=42, global_step=600
06/22/2022 23:18:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.55 on epoch=43
06/22/2022 23:18:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.61 on epoch=44
06/22/2022 23:18:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.50 on epoch=44
06/22/2022 23:18:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.56 on epoch=45
06/22/2022 23:18:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=46
06/22/2022 23:18:55 - INFO - __main__ - Global step 650 Train loss 0.55 Classification-F1 0.44225474908674506 on epoch=46
06/22/2022 23:18:55 - INFO - __main__ - Saving model with best Classification-F1: 0.35617390674251714 -> 0.44225474908674506 on epoch=46, global_step=650
06/22/2022 23:18:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=47
06/22/2022 23:19:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.45 on epoch=47
06/22/2022 23:19:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=48
06/22/2022 23:19:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=49
06/22/2022 23:19:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=49
06/22/2022 23:19:15 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.4185544872154994 on epoch=49
06/22/2022 23:19:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.47 on epoch=50
06/22/2022 23:19:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=51
06/22/2022 23:19:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.43 on epoch=52
06/22/2022 23:19:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=52
06/22/2022 23:19:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/22/2022 23:19:36 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.5401921422030571 on epoch=53
06/22/2022 23:19:36 - INFO - __main__ - Saving model with best Classification-F1: 0.44225474908674506 -> 0.5401921422030571 on epoch=53, global_step=750
06/22/2022 23:19:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=54
06/22/2022 23:19:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.46 on epoch=54
06/22/2022 23:19:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=55
06/22/2022 23:19:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=56
06/22/2022 23:19:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.40 on epoch=57
06/22/2022 23:19:56 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.5357508140073007 on epoch=57
06/22/2022 23:19:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
06/22/2022 23:20:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=58
06/22/2022 23:20:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.35 on epoch=59
06/22/2022 23:20:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.36 on epoch=59
06/22/2022 23:20:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.43 on epoch=60
06/22/2022 23:20:16 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.5788025574132614 on epoch=60
06/22/2022 23:20:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5401921422030571 -> 0.5788025574132614 on epoch=60, global_step=850
06/22/2022 23:20:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.28 on epoch=61
06/22/2022 23:20:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.41 on epoch=62
06/22/2022 23:20:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=62
06/22/2022 23:20:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=63
06/22/2022 23:20:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=64
06/22/2022 23:20:36 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.5635334017140835 on epoch=64
06/22/2022 23:20:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=64
06/22/2022 23:20:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=65
06/22/2022 23:20:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=66
06/22/2022 23:20:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=67
06/22/2022 23:20:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=67
06/22/2022 23:20:57 - INFO - __main__ - Global step 950 Train loss 0.32 Classification-F1 0.547129782649887 on epoch=67
06/22/2022 23:20:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=68
06/22/2022 23:21:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=69
06/22/2022 23:21:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.26 on epoch=69
06/22/2022 23:21:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=70
06/22/2022 23:21:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=71
06/22/2022 23:21:17 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.6441539576015382 on epoch=71
06/22/2022 23:21:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5788025574132614 -> 0.6441539576015382 on epoch=71, global_step=1000
06/22/2022 23:21:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.31 on epoch=72
06/22/2022 23:21:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=72
06/22/2022 23:21:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/22/2022 23:21:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.37 on epoch=74
06/22/2022 23:21:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=74
06/22/2022 23:21:37 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.5938798507346894 on epoch=74
06/22/2022 23:21:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=75
06/22/2022 23:21:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=76
06/22/2022 23:21:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.29 on epoch=77
06/22/2022 23:21:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
06/22/2022 23:21:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=78
06/22/2022 23:21:57 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.633203504545822 on epoch=78
06/22/2022 23:22:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=79
06/22/2022 23:22:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=79
06/22/2022 23:22:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.28 on epoch=80
06/22/2022 23:22:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/22/2022 23:22:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=82
06/22/2022 23:22:17 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.5703214460840094 on epoch=82
06/22/2022 23:22:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/22/2022 23:22:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=83
06/22/2022 23:22:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.29 on epoch=84
06/22/2022 23:22:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=84
06/22/2022 23:22:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=85
06/22/2022 23:22:37 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.6015744730606482 on epoch=85
06/22/2022 23:22:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/22/2022 23:22:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=87
06/22/2022 23:22:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
06/22/2022 23:22:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=88
06/22/2022 23:22:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.30 on epoch=89
06/22/2022 23:22:57 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.6045535728139415 on epoch=89
06/22/2022 23:23:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=89
06/22/2022 23:23:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=90
06/22/2022 23:23:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
06/22/2022 23:23:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=92
06/22/2022 23:23:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=92
06/22/2022 23:23:17 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5661674587035189 on epoch=92
06/22/2022 23:23:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=93
06/22/2022 23:23:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=94
06/22/2022 23:23:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=94
06/22/2022 23:23:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=95
06/22/2022 23:23:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=96
06/22/2022 23:23:37 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.5661674587035189 on epoch=96
06/22/2022 23:23:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.27 on epoch=97
06/22/2022 23:23:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/22/2022 23:23:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/22/2022 23:23:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
06/22/2022 23:23:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=99
06/22/2022 23:23:58 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.6246958915531022 on epoch=99
06/22/2022 23:24:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=100
06/22/2022 23:24:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.22 on epoch=101
06/22/2022 23:24:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.24 on epoch=102
06/22/2022 23:24:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=102
06/22/2022 23:24:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=103
06/22/2022 23:24:18 - INFO - __main__ - Global step 1450 Train loss 0.20 Classification-F1 0.6278208915531023 on epoch=103
06/22/2022 23:24:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/22/2022 23:24:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=104
06/22/2022 23:24:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
06/22/2022 23:24:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/22/2022 23:24:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
06/22/2022 23:24:38 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.6278208915531023 on epoch=107
06/22/2022 23:24:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=107
06/22/2022 23:24:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.17 on epoch=108
06/22/2022 23:24:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.24 on epoch=109
06/22/2022 23:24:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=109
06/22/2022 23:24:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=110
06/22/2022 23:24:58 - INFO - __main__ - Global step 1550 Train loss 0.18 Classification-F1 0.659272415556746 on epoch=110
06/22/2022 23:24:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6441539576015382 -> 0.659272415556746 on epoch=110, global_step=1550
06/22/2022 23:25:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=111
06/22/2022 23:25:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.22 on epoch=112
06/22/2022 23:25:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/22/2022 23:25:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=113
06/22/2022 23:25:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=114
06/22/2022 23:25:18 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.5988324613302549 on epoch=114
06/22/2022 23:25:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/22/2022 23:25:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=115
06/22/2022 23:25:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=116
06/22/2022 23:25:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=117
06/22/2022 23:25:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=117
06/22/2022 23:25:38 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.7294270983075537 on epoch=117
06/22/2022 23:25:38 - INFO - __main__ - Saving model with best Classification-F1: 0.659272415556746 -> 0.7294270983075537 on epoch=117, global_step=1650
06/22/2022 23:25:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/22/2022 23:25:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=119
06/22/2022 23:25:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=119
06/22/2022 23:25:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=120
06/22/2022 23:25:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
06/22/2022 23:25:58 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.725279119467924 on epoch=121
06/22/2022 23:26:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
06/22/2022 23:26:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=122
06/22/2022 23:26:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=123
06/22/2022 23:26:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/22/2022 23:26:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/22/2022 23:26:18 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.755482077844257 on epoch=124
06/22/2022 23:26:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7294270983075537 -> 0.755482077844257 on epoch=124, global_step=1750
06/22/2022 23:26:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/22/2022 23:26:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=126
06/22/2022 23:26:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.17 on epoch=127
06/22/2022 23:26:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=127
06/22/2022 23:26:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=128
06/22/2022 23:26:38 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.7371000237252051 on epoch=128
06/22/2022 23:26:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=129
06/22/2022 23:26:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/22/2022 23:26:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
06/22/2022 23:26:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
06/22/2022 23:26:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=132
06/22/2022 23:26:58 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.7024467506009946 on epoch=132
06/22/2022 23:27:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=132
06/22/2022 23:27:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=133
06/22/2022 23:27:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.16 on epoch=134
06/22/2022 23:27:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=134
06/22/2022 23:27:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/22/2022 23:27:18 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.784786424017992 on epoch=135
06/22/2022 23:27:18 - INFO - __main__ - Saving model with best Classification-F1: 0.755482077844257 -> 0.784786424017992 on epoch=135, global_step=1900
06/22/2022 23:27:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
06/22/2022 23:27:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=137
06/22/2022 23:27:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/22/2022 23:27:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/22/2022 23:27:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/22/2022 23:27:37 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7957824555485877 on epoch=139
06/22/2022 23:27:37 - INFO - __main__ - Saving model with best Classification-F1: 0.784786424017992 -> 0.7957824555485877 on epoch=139, global_step=1950
06/22/2022 23:27:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
06/22/2022 23:27:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
06/22/2022 23:27:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=141
06/22/2022 23:27:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
06/22/2022 23:27:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
06/22/2022 23:27:57 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.7713621107066854 on epoch=142
06/22/2022 23:28:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
06/22/2022 23:28:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/22/2022 23:28:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/22/2022 23:28:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/22/2022 23:28:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
06/22/2022 23:28:17 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.7910959425180439 on epoch=146
06/22/2022 23:28:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=147
06/22/2022 23:28:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/22/2022 23:28:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
06/22/2022 23:28:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/22/2022 23:28:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=149
06/22/2022 23:28:37 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.8205240981392006 on epoch=149
06/22/2022 23:28:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7957824555485877 -> 0.8205240981392006 on epoch=149, global_step=2100
06/22/2022 23:28:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/22/2022 23:28:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
06/22/2022 23:28:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/22/2022 23:28:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/22/2022 23:28:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/22/2022 23:28:57 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.758642959785078 on epoch=153
06/22/2022 23:29:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=154
06/22/2022 23:29:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
06/22/2022 23:29:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/22/2022 23:29:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/22/2022 23:29:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=157
06/22/2022 23:29:17 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.7671991095176983 on epoch=157
06/22/2022 23:29:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=157
06/22/2022 23:29:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=158
06/22/2022 23:29:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=159
06/22/2022 23:29:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/22/2022 23:29:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
06/22/2022 23:29:37 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.7231129135699028 on epoch=160
06/22/2022 23:29:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/22/2022 23:29:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/22/2022 23:29:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=162
06/22/2022 23:29:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/22/2022 23:29:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/22/2022 23:29:57 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7823871620807663 on epoch=164
06/22/2022 23:30:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/22/2022 23:30:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.11 on epoch=165
06/22/2022 23:30:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/22/2022 23:30:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/22/2022 23:30:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=167
06/22/2022 23:30:17 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.7785751431847536 on epoch=167
06/22/2022 23:30:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/22/2022 23:30:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/22/2022 23:30:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=169
06/22/2022 23:30:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=170
06/22/2022 23:30:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/22/2022 23:30:37 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7430347336248138 on epoch=171
06/22/2022 23:30:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/22/2022 23:30:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/22/2022 23:30:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/22/2022 23:30:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/22/2022 23:30:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/22/2022 23:30:57 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.7867462529450475 on epoch=174
06/22/2022 23:30:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=175
06/22/2022 23:31:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/22/2022 23:31:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=177
06/22/2022 23:31:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/22/2022 23:31:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/22/2022 23:31:16 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.7894333226262494 on epoch=178
06/22/2022 23:31:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
06/22/2022 23:31:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
06/22/2022 23:31:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=180
06/22/2022 23:31:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/22/2022 23:31:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/22/2022 23:31:36 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7933332438160468 on epoch=182
06/22/2022 23:31:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.09 on epoch=182
06/22/2022 23:31:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=183
06/22/2022 23:31:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/22/2022 23:31:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/22/2022 23:31:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=185
06/22/2022 23:31:56 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.743133763135608 on epoch=185
06/22/2022 23:31:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/22/2022 23:32:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/22/2022 23:32:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/22/2022 23:32:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/22/2022 23:32:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/22/2022 23:32:15 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7492591747151552 on epoch=189
06/22/2022 23:32:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
06/22/2022 23:32:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=190
06/22/2022 23:32:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/22/2022 23:32:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/22/2022 23:32:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/22/2022 23:32:35 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7955004616992563 on epoch=192
06/22/2022 23:32:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/22/2022 23:32:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/22/2022 23:32:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
06/22/2022 23:32:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/22/2022 23:32:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/22/2022 23:32:55 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.7457739748352684 on epoch=196
06/22/2022 23:32:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
06/22/2022 23:33:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/22/2022 23:33:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
06/22/2022 23:33:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/22/2022 23:33:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
06/22/2022 23:33:14 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7992666930494814 on epoch=199
06/22/2022 23:33:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/22/2022 23:33:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/22/2022 23:33:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
06/22/2022 23:33:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/22/2022 23:33:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=203
06/22/2022 23:33:34 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.7471688227262231 on epoch=203
06/22/2022 23:33:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.11 on epoch=204
06/22/2022 23:33:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/22/2022 23:33:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/22/2022 23:33:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/22/2022 23:33:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/22/2022 23:33:54 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7934380985921818 on epoch=207
06/22/2022 23:33:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/22/2022 23:33:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/22/2022 23:34:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/22/2022 23:34:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/22/2022 23:34:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.15 on epoch=210
06/22/2022 23:34:13 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.7970133082171738 on epoch=210
06/22/2022 23:34:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/22/2022 23:34:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=212
06/22/2022 23:34:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/22/2022 23:34:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/22/2022 23:34:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/22/2022 23:34:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:34:28 - INFO - __main__ - Printing 3 examples
06/22/2022 23:34:28 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/22/2022 23:34:28 - INFO - __main__ - ['Plant']
06/22/2022 23:34:28 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/22/2022 23:34:28 - INFO - __main__ - ['Plant']
06/22/2022 23:34:28 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/22/2022 23:34:28 - INFO - __main__ - ['Plant']
06/22/2022 23:34:28 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:34:28 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:34:28 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 23:34:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:34:28 - INFO - __main__ - Printing 3 examples
06/22/2022 23:34:28 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/22/2022 23:34:28 - INFO - __main__ - ['Plant']
06/22/2022 23:34:28 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/22/2022 23:34:28 - INFO - __main__ - ['Plant']
06/22/2022 23:34:28 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/22/2022 23:34:28 - INFO - __main__ - ['Plant']
06/22/2022 23:34:28 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:34:28 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:34:28 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 23:34:33 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7499717109246943 on epoch=214
06/22/2022 23:34:33 - INFO - __main__ - save last model!
06/22/2022 23:34:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 23:34:33 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 23:34:33 - INFO - __main__ - Printing 3 examples
06/22/2022 23:34:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 23:34:33 - INFO - __main__ - ['Animal']
06/22/2022 23:34:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 23:34:33 - INFO - __main__ - ['Animal']
06/22/2022 23:34:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 23:34:33 - INFO - __main__ - ['Village']
06/22/2022 23:34:33 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:34:35 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:34:38 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 23:34:44 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 23:34:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 23:34:44 - INFO - __main__ - Starting training!
06/22/2022 23:36:47 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/22/2022 23:36:47 - INFO - __main__ - Classification-F1 on test data: 0.4087
06/22/2022 23:36:47 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.8205240981392006, test_performance=0.40873915316088105
06/22/2022 23:36:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/22/2022 23:36:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:36:48 - INFO - __main__ - Printing 3 examples
06/22/2022 23:36:48 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/22/2022 23:36:48 - INFO - __main__ - ['Plant']
06/22/2022 23:36:48 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/22/2022 23:36:48 - INFO - __main__ - ['Plant']
06/22/2022 23:36:48 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/22/2022 23:36:48 - INFO - __main__ - ['Plant']
06/22/2022 23:36:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:36:48 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:36:48 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 23:36:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:36:48 - INFO - __main__ - Printing 3 examples
06/22/2022 23:36:48 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/22/2022 23:36:48 - INFO - __main__ - ['Plant']
06/22/2022 23:36:48 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/22/2022 23:36:48 - INFO - __main__ - ['Plant']
06/22/2022 23:36:48 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/22/2022 23:36:48 - INFO - __main__ - ['Plant']
06/22/2022 23:36:48 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:36:49 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:36:49 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 23:37:04 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 23:37:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 23:37:05 - INFO - __main__ - Starting training!
06/22/2022 23:37:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.01 on epoch=0
06/22/2022 23:37:11 - INFO - __main__ - Step 20 Global step 20 Train loss 4.43 on epoch=1
06/22/2022 23:37:13 - INFO - __main__ - Step 30 Global step 30 Train loss 3.96 on epoch=2
06/22/2022 23:37:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.29 on epoch=2
06/22/2022 23:37:18 - INFO - __main__ - Step 50 Global step 50 Train loss 3.10 on epoch=3
06/22/2022 23:37:24 - INFO - __main__ - Global step 50 Train loss 4.16 Classification-F1 0.06665040945252788 on epoch=3
06/22/2022 23:37:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06665040945252788 on epoch=3, global_step=50
06/22/2022 23:37:26 - INFO - __main__ - Step 60 Global step 60 Train loss 2.66 on epoch=4
06/22/2022 23:37:29 - INFO - __main__ - Step 70 Global step 70 Train loss 2.55 on epoch=4
06/22/2022 23:37:31 - INFO - __main__ - Step 80 Global step 80 Train loss 2.12 on epoch=5
06/22/2022 23:37:34 - INFO - __main__ - Step 90 Global step 90 Train loss 1.97 on epoch=6
06/22/2022 23:37:37 - INFO - __main__ - Step 100 Global step 100 Train loss 1.89 on epoch=7
06/22/2022 23:37:42 - INFO - __main__ - Global step 100 Train loss 2.24 Classification-F1 0.10104312267321672 on epoch=7
06/22/2022 23:37:42 - INFO - __main__ - Saving model with best Classification-F1: 0.06665040945252788 -> 0.10104312267321672 on epoch=7, global_step=100
06/22/2022 23:37:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.58 on epoch=7
06/22/2022 23:37:47 - INFO - __main__ - Step 120 Global step 120 Train loss 1.66 on epoch=8
06/22/2022 23:37:50 - INFO - __main__ - Step 130 Global step 130 Train loss 1.35 on epoch=9
06/22/2022 23:37:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.38 on epoch=9
06/22/2022 23:37:55 - INFO - __main__ - Step 150 Global step 150 Train loss 1.16 on epoch=10
06/22/2022 23:38:01 - INFO - __main__ - Global step 150 Train loss 1.43 Classification-F1 0.1329491857555556 on epoch=10
06/22/2022 23:38:01 - INFO - __main__ - Saving model with best Classification-F1: 0.10104312267321672 -> 0.1329491857555556 on epoch=10, global_step=150
06/22/2022 23:38:03 - INFO - __main__ - Step 160 Global step 160 Train loss 1.19 on epoch=11
06/22/2022 23:38:06 - INFO - __main__ - Step 170 Global step 170 Train loss 1.01 on epoch=12
06/22/2022 23:38:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=12
06/22/2022 23:38:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=13
06/22/2022 23:38:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=14
06/22/2022 23:38:20 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.2910469021401732 on epoch=14
06/22/2022 23:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.1329491857555556 -> 0.2910469021401732 on epoch=14, global_step=200
06/22/2022 23:38:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=14
06/22/2022 23:38:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=15
06/22/2022 23:38:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=16
06/22/2022 23:38:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=17
06/22/2022 23:38:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=17
06/22/2022 23:38:40 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.440140195990778 on epoch=17
06/22/2022 23:38:41 - INFO - __main__ - Saving model with best Classification-F1: 0.2910469021401732 -> 0.440140195990778 on epoch=17, global_step=250
06/22/2022 23:38:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=18
06/22/2022 23:38:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=19
06/22/2022 23:38:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=19
06/22/2022 23:38:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=20
06/22/2022 23:38:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=21
06/22/2022 23:39:01 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.4272248308324125 on epoch=21
06/22/2022 23:39:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=22
06/22/2022 23:39:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/22/2022 23:39:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
06/22/2022 23:39:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=24
06/22/2022 23:39:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=24
06/22/2022 23:39:21 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.5367703143648574 on epoch=24
06/22/2022 23:39:21 - INFO - __main__ - Saving model with best Classification-F1: 0.440140195990778 -> 0.5367703143648574 on epoch=24, global_step=350
06/22/2022 23:39:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=25
06/22/2022 23:39:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
06/22/2022 23:39:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
06/22/2022 23:39:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
06/22/2022 23:39:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
06/22/2022 23:39:42 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6110676929534075 on epoch=28
06/22/2022 23:39:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5367703143648574 -> 0.6110676929534075 on epoch=28, global_step=400
06/22/2022 23:39:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/22/2022 23:39:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=29
06/22/2022 23:39:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/22/2022 23:39:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
06/22/2022 23:39:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=32
06/22/2022 23:40:02 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6045477990883998 on epoch=32
06/22/2022 23:40:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
06/22/2022 23:40:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=33
06/22/2022 23:40:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=34
06/22/2022 23:40:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
06/22/2022 23:40:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
06/22/2022 23:40:22 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.5509495347671108 on epoch=35
06/22/2022 23:40:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
06/22/2022 23:40:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=37
06/22/2022 23:40:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/22/2022 23:40:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/22/2022 23:40:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
06/22/2022 23:40:43 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.5764377441069799 on epoch=39
06/22/2022 23:40:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/22/2022 23:40:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/22/2022 23:40:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
06/22/2022 23:40:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=42
06/22/2022 23:40:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=42
06/22/2022 23:41:03 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.6046321803319366 on epoch=42
06/22/2022 23:41:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=43
06/22/2022 23:41:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/22/2022 23:41:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/22/2022 23:41:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/22/2022 23:41:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/22/2022 23:41:23 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5348010151063867 on epoch=46
06/22/2022 23:41:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/22/2022 23:41:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
06/22/2022 23:41:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/22/2022 23:41:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/22/2022 23:41:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/22/2022 23:41:44 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.620623164353652 on epoch=49
06/22/2022 23:41:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6110676929534075 -> 0.620623164353652 on epoch=49, global_step=700
06/22/2022 23:41:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/22/2022 23:41:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=51
06/22/2022 23:41:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/22/2022 23:41:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/22/2022 23:41:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=53
06/22/2022 23:42:04 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6930411384098627 on epoch=53
06/22/2022 23:42:05 - INFO - __main__ - Saving model with best Classification-F1: 0.620623164353652 -> 0.6930411384098627 on epoch=53, global_step=750
06/22/2022 23:42:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/22/2022 23:42:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/22/2022 23:42:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/22/2022 23:42:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/22/2022 23:42:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
06/22/2022 23:42:25 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7023694798587812 on epoch=57
06/22/2022 23:42:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6930411384098627 -> 0.7023694798587812 on epoch=57, global_step=800
06/22/2022 23:42:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/22/2022 23:42:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/22/2022 23:42:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/22/2022 23:42:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/22/2022 23:42:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/22/2022 23:42:46 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7057301640844186 on epoch=60
06/22/2022 23:42:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7023694798587812 -> 0.7057301640844186 on epoch=60, global_step=850
06/22/2022 23:42:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/22/2022 23:42:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/22/2022 23:42:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
06/22/2022 23:42:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
06/22/2022 23:42:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/22/2022 23:43:07 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7039725698036935 on epoch=64
06/22/2022 23:43:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/22/2022 23:43:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/22/2022 23:43:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
06/22/2022 23:43:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
06/22/2022 23:43:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/22/2022 23:43:27 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7743189327002176 on epoch=67
06/22/2022 23:43:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7057301640844186 -> 0.7743189327002176 on epoch=67, global_step=950
06/22/2022 23:43:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/22/2022 23:43:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/22/2022 23:43:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/22/2022 23:43:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/22/2022 23:43:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/22/2022 23:43:48 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7843742368731688 on epoch=71
06/22/2022 23:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7743189327002176 -> 0.7843742368731688 on epoch=71, global_step=1000
06/22/2022 23:43:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/22/2022 23:43:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/22/2022 23:43:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/22/2022 23:43:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
06/22/2022 23:44:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/22/2022 23:44:10 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7885495822249848 on epoch=74
06/22/2022 23:44:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7843742368731688 -> 0.7885495822249848 on epoch=74, global_step=1050
06/22/2022 23:44:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/22/2022 23:44:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/22/2022 23:44:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/22/2022 23:44:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/22/2022 23:44:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/22/2022 23:44:30 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8043799904429363 on epoch=78
06/22/2022 23:44:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7885495822249848 -> 0.8043799904429363 on epoch=78, global_step=1100
06/22/2022 23:44:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/22/2022 23:44:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/22/2022 23:44:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/22/2022 23:44:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/22/2022 23:44:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/22/2022 23:44:51 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8471786090308304 on epoch=82
06/22/2022 23:44:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8043799904429363 -> 0.8471786090308304 on epoch=82, global_step=1150
06/22/2022 23:44:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/22/2022 23:44:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/22/2022 23:44:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/22/2022 23:45:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/22/2022 23:45:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
06/22/2022 23:45:12 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.9058077206006279 on epoch=85
06/22/2022 23:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8471786090308304 -> 0.9058077206006279 on epoch=85, global_step=1200
06/22/2022 23:45:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/22/2022 23:45:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/22/2022 23:45:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/22/2022 23:45:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/22/2022 23:45:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/22/2022 23:45:33 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.836020581253029 on epoch=89
06/22/2022 23:45:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/22/2022 23:45:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/22/2022 23:45:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/22/2022 23:45:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/22/2022 23:45:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/22/2022 23:45:53 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7719645200158193 on epoch=92
06/22/2022 23:45:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/22/2022 23:45:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/22/2022 23:46:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/22/2022 23:46:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/22/2022 23:46:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/22/2022 23:46:14 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7187485048112909 on epoch=96
06/22/2022 23:46:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/22/2022 23:46:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/22/2022 23:46:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/22/2022 23:46:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/22/2022 23:46:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/22/2022 23:46:34 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6862397392159675 on epoch=99
06/22/2022 23:46:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/22/2022 23:46:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/22/2022 23:46:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/22/2022 23:46:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/22/2022 23:46:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/22/2022 23:46:55 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6615503021302873 on epoch=103
06/22/2022 23:46:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/22/2022 23:47:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/22/2022 23:47:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/22/2022 23:47:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/22/2022 23:47:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/22/2022 23:47:15 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6015267039900472 on epoch=107
06/22/2022 23:47:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/22/2022 23:47:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/22/2022 23:47:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/22/2022 23:47:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/22/2022 23:47:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/22/2022 23:47:35 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6433473377553401 on epoch=110
06/22/2022 23:47:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/22/2022 23:47:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/22/2022 23:47:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/22/2022 23:47:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/22/2022 23:47:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/22/2022 23:47:56 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7866867828917166 on epoch=114
06/22/2022 23:47:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/22/2022 23:48:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/22/2022 23:48:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/22/2022 23:48:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/22/2022 23:48:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/22/2022 23:48:16 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6625329193260882 on epoch=117
06/22/2022 23:48:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/22/2022 23:48:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
06/22/2022 23:48:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/22/2022 23:48:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/22/2022 23:48:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/22/2022 23:48:35 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6643870064601132 on epoch=121
06/22/2022 23:48:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/22/2022 23:48:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/22/2022 23:48:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/22/2022 23:48:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/22/2022 23:48:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/22/2022 23:48:56 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6530970863418682 on epoch=124
06/22/2022 23:48:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/22/2022 23:49:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
06/22/2022 23:49:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/22/2022 23:49:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/22/2022 23:49:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/22/2022 23:49:15 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6852804266179922 on epoch=128
06/22/2022 23:49:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/22/2022 23:49:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/22/2022 23:49:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/22/2022 23:49:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/22/2022 23:49:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/22/2022 23:49:35 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6277469021788107 on epoch=132
06/22/2022 23:49:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/22/2022 23:49:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/22/2022 23:49:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/22/2022 23:49:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/22/2022 23:49:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/22/2022 23:49:55 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.5847896632449441 on epoch=135
06/22/2022 23:49:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/22/2022 23:50:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/22/2022 23:50:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/22/2022 23:50:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/22/2022 23:50:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/22/2022 23:50:15 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.707541321822756 on epoch=139
06/22/2022 23:50:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/22/2022 23:50:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/22/2022 23:50:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/22/2022 23:50:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/22/2022 23:50:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/22/2022 23:50:35 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7091156388469881 on epoch=142
06/22/2022 23:50:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/22/2022 23:50:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/22/2022 23:50:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/22/2022 23:50:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/22/2022 23:50:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/22/2022 23:50:55 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8474409998603547 on epoch=146
06/22/2022 23:50:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/22/2022 23:51:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/22/2022 23:51:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/22/2022 23:51:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
06/22/2022 23:51:08 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/22/2022 23:51:15 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7107331194555304 on epoch=149
06/22/2022 23:51:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/22/2022 23:51:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/22/2022 23:51:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/22/2022 23:51:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/22/2022 23:51:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/22/2022 23:51:35 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.675554003606701 on epoch=153
06/22/2022 23:51:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/22/2022 23:51:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/22/2022 23:51:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/22/2022 23:51:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/22/2022 23:51:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/22/2022 23:51:55 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6941103837738213 on epoch=157
06/22/2022 23:51:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/22/2022 23:52:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/22/2022 23:52:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/22/2022 23:52:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/22/2022 23:52:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/22/2022 23:52:15 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7790262796510703 on epoch=160
06/22/2022 23:52:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/22/2022 23:52:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/22/2022 23:52:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/22/2022 23:52:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/22/2022 23:52:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/22/2022 23:52:35 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7417526842930068 on epoch=164
06/22/2022 23:52:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/22/2022 23:52:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/22/2022 23:52:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/22/2022 23:52:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/22/2022 23:52:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/22/2022 23:52:55 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7915890403082054 on epoch=167
06/22/2022 23:52:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/22/2022 23:53:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/22/2022 23:53:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/22/2022 23:53:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/22/2022 23:53:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/22/2022 23:53:14 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.855196878054741 on epoch=171
06/22/2022 23:53:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/22/2022 23:53:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/22/2022 23:53:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/22/2022 23:53:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/22/2022 23:53:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/22/2022 23:53:34 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8028750503133805 on epoch=174
06/22/2022 23:53:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/22/2022 23:53:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/22/2022 23:53:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/22/2022 23:53:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/22/2022 23:53:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/22/2022 23:53:54 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9018498552891342 on epoch=178
06/22/2022 23:53:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/22/2022 23:53:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/22/2022 23:54:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/22/2022 23:54:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/22/2022 23:54:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/22/2022 23:54:14 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8452238226668967 on epoch=182
06/22/2022 23:54:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/22/2022 23:54:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/22/2022 23:54:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/22/2022 23:54:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/22/2022 23:54:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/22/2022 23:54:33 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.795626963913045 on epoch=185
06/22/2022 23:54:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/22/2022 23:54:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/22/2022 23:54:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/22/2022 23:54:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/22/2022 23:54:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/22/2022 23:54:53 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9686808447719264 on epoch=189
06/22/2022 23:54:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9058077206006279 -> 0.9686808447719264 on epoch=189, global_step=2650
06/22/2022 23:54:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/22/2022 23:54:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/22/2022 23:55:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/22/2022 23:55:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/22/2022 23:55:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/22/2022 23:55:13 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9022117488246522 on epoch=192
06/22/2022 23:55:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/22/2022 23:55:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/22/2022 23:55:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/22/2022 23:55:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/22/2022 23:55:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/22/2022 23:55:33 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9734099138189001 on epoch=196
06/22/2022 23:55:33 - INFO - __main__ - Saving model with best Classification-F1: 0.9686808447719264 -> 0.9734099138189001 on epoch=196, global_step=2750
06/22/2022 23:55:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/22/2022 23:55:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/22/2022 23:55:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/22/2022 23:55:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/22/2022 23:55:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/22/2022 23:55:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9731355298717729 on epoch=199
06/22/2022 23:55:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/22/2022 23:55:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/22/2022 23:56:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/22/2022 23:56:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/22/2022 23:56:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/22/2022 23:56:13 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9683481338232534 on epoch=203
06/22/2022 23:56:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/22/2022 23:56:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/22/2022 23:56:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/22/2022 23:56:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/22/2022 23:56:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/22/2022 23:56:32 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8475670079248708 on epoch=207
06/22/2022 23:56:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/22/2022 23:56:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/22/2022 23:56:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/22/2022 23:56:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/22/2022 23:56:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/22/2022 23:56:52 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=210
06/22/2022 23:56:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/22/2022 23:56:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/22/2022 23:57:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/22/2022 23:57:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/22/2022 23:57:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/22/2022 23:57:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:57:06 - INFO - __main__ - Printing 3 examples
06/22/2022 23:57:06 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/22/2022 23:57:06 - INFO - __main__ - ['Plant']
06/22/2022 23:57:06 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/22/2022 23:57:06 - INFO - __main__ - ['Plant']
06/22/2022 23:57:06 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/22/2022 23:57:06 - INFO - __main__ - ['Plant']
06/22/2022 23:57:06 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:57:06 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:57:07 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 23:57:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:57:07 - INFO - __main__ - Printing 3 examples
06/22/2022 23:57:07 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/22/2022 23:57:07 - INFO - __main__ - ['Plant']
06/22/2022 23:57:07 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/22/2022 23:57:07 - INFO - __main__ - ['Plant']
06/22/2022 23:57:07 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/22/2022 23:57:07 - INFO - __main__ - ['Plant']
06/22/2022 23:57:07 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:57:07 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:57:07 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 23:57:12 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=214
06/22/2022 23:57:12 - INFO - __main__ - save last model!
06/22/2022 23:57:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/22/2022 23:57:12 - INFO - __main__ - Start tokenizing ... 3500 instances
06/22/2022 23:57:12 - INFO - __main__ - Printing 3 examples
06/22/2022 23:57:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/22/2022 23:57:12 - INFO - __main__ - ['Animal']
06/22/2022 23:57:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/22/2022 23:57:12 - INFO - __main__ - ['Animal']
06/22/2022 23:57:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/22/2022 23:57:12 - INFO - __main__ - ['Village']
06/22/2022 23:57:12 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:57:14 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:57:18 - INFO - __main__ - Loaded 3500 examples from test data
06/22/2022 23:57:22 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 23:57:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 23:57:23 - INFO - __main__ - Starting training!
06/22/2022 23:59:30 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/22/2022 23:59:30 - INFO - __main__ - Classification-F1 on test data: 0.4522
06/22/2022 23:59:31 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9734099138189001, test_performance=0.45215774030300204
06/22/2022 23:59:31 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/22/2022 23:59:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:59:33 - INFO - __main__ - Printing 3 examples
06/22/2022 23:59:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/22/2022 23:59:33 - INFO - __main__ - ['Plant']
06/22/2022 23:59:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/22/2022 23:59:33 - INFO - __main__ - ['Plant']
06/22/2022 23:59:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/22/2022 23:59:33 - INFO - __main__ - ['Plant']
06/22/2022 23:59:33 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:59:33 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:59:33 - INFO - __main__ - Loaded 224 examples from train data
06/22/2022 23:59:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/22/2022 23:59:33 - INFO - __main__ - Printing 3 examples
06/22/2022 23:59:33 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/22/2022 23:59:33 - INFO - __main__ - ['Plant']
06/22/2022 23:59:33 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/22/2022 23:59:33 - INFO - __main__ - ['Plant']
06/22/2022 23:59:33 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/22/2022 23:59:33 - INFO - __main__ - ['Plant']
06/22/2022 23:59:33 - INFO - __main__ - Tokenizing Input ...
06/22/2022 23:59:33 - INFO - __main__ - Tokenizing Output ...
06/22/2022 23:59:33 - INFO - __main__ - Loaded 224 examples from dev data
06/22/2022 23:59:49 - INFO - __main__ - load prompt embedding from ckpt
06/22/2022 23:59:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/22/2022 23:59:49 - INFO - __main__ - Starting training!
06/22/2022 23:59:53 - INFO - __main__ - Step 10 Global step 10 Train loss 6.38 on epoch=0
06/22/2022 23:59:55 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=1
06/22/2022 23:59:58 - INFO - __main__ - Step 30 Global step 30 Train loss 4.14 on epoch=2
06/23/2022 00:00:00 - INFO - __main__ - Step 40 Global step 40 Train loss 3.52 on epoch=2
06/23/2022 00:00:03 - INFO - __main__ - Step 50 Global step 50 Train loss 3.43 on epoch=3
06/23/2022 00:00:08 - INFO - __main__ - Global step 50 Train loss 4.40 Classification-F1 0.05710222277926614 on epoch=3
06/23/2022 00:00:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05710222277926614 on epoch=3, global_step=50
06/23/2022 00:00:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.85 on epoch=4
06/23/2022 00:00:13 - INFO - __main__ - Step 70 Global step 70 Train loss 2.72 on epoch=4
06/23/2022 00:00:16 - INFO - __main__ - Step 80 Global step 80 Train loss 2.34 on epoch=5
06/23/2022 00:00:19 - INFO - __main__ - Step 90 Global step 90 Train loss 2.30 on epoch=6
06/23/2022 00:00:21 - INFO - __main__ - Step 100 Global step 100 Train loss 2.25 on epoch=7
06/23/2022 00:00:27 - INFO - __main__ - Global step 100 Train loss 2.49 Classification-F1 0.08481479534111114 on epoch=7
06/23/2022 00:00:27 - INFO - __main__ - Saving model with best Classification-F1: 0.05710222277926614 -> 0.08481479534111114 on epoch=7, global_step=100
06/23/2022 00:00:29 - INFO - __main__ - Step 110 Global step 110 Train loss 1.94 on epoch=7
06/23/2022 00:00:32 - INFO - __main__ - Step 120 Global step 120 Train loss 1.94 on epoch=8
06/23/2022 00:00:35 - INFO - __main__ - Step 130 Global step 130 Train loss 1.75 on epoch=9
06/23/2022 00:00:37 - INFO - __main__ - Step 140 Global step 140 Train loss 1.58 on epoch=9
06/23/2022 00:00:40 - INFO - __main__ - Step 150 Global step 150 Train loss 1.42 on epoch=10
06/23/2022 00:00:45 - INFO - __main__ - Global step 150 Train loss 1.72 Classification-F1 0.10950000010580122 on epoch=10
06/23/2022 00:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.08481479534111114 -> 0.10950000010580122 on epoch=10, global_step=150
06/23/2022 00:00:48 - INFO - __main__ - Step 160 Global step 160 Train loss 1.44 on epoch=11
06/23/2022 00:00:50 - INFO - __main__ - Step 170 Global step 170 Train loss 1.19 on epoch=12
06/23/2022 00:00:53 - INFO - __main__ - Step 180 Global step 180 Train loss 1.21 on epoch=12
06/23/2022 00:00:56 - INFO - __main__ - Step 190 Global step 190 Train loss 1.13 on epoch=13
06/23/2022 00:00:58 - INFO - __main__ - Step 200 Global step 200 Train loss 1.07 on epoch=14
06/23/2022 00:01:04 - INFO - __main__ - Global step 200 Train loss 1.21 Classification-F1 0.18197574030907365 on epoch=14
06/23/2022 00:01:04 - INFO - __main__ - Saving model with best Classification-F1: 0.10950000010580122 -> 0.18197574030907365 on epoch=14, global_step=200
06/23/2022 00:01:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=14
06/23/2022 00:01:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=15
06/23/2022 00:01:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=16
06/23/2022 00:01:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=17
06/23/2022 00:01:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=17
06/23/2022 00:01:24 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.3097228517761136 on epoch=17
06/23/2022 00:01:24 - INFO - __main__ - Saving model with best Classification-F1: 0.18197574030907365 -> 0.3097228517761136 on epoch=17, global_step=250
06/23/2022 00:01:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=18
06/23/2022 00:01:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=19
06/23/2022 00:01:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=19
06/23/2022 00:01:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=20
06/23/2022 00:01:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=21
06/23/2022 00:01:44 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.3929424840126273 on epoch=21
06/23/2022 00:01:44 - INFO - __main__ - Saving model with best Classification-F1: 0.3097228517761136 -> 0.3929424840126273 on epoch=21, global_step=300
06/23/2022 00:01:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=22
06/23/2022 00:01:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=22
06/23/2022 00:01:51 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/23/2022 00:01:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=24
06/23/2022 00:01:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/23/2022 00:02:04 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.46753896264020234 on epoch=24
06/23/2022 00:02:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3929424840126273 -> 0.46753896264020234 on epoch=24, global_step=350
06/23/2022 00:02:06 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=25
06/23/2022 00:02:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=26
06/23/2022 00:02:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/23/2022 00:02:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
06/23/2022 00:02:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=28
06/23/2022 00:02:24 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.47865383501425174 on epoch=28
06/23/2022 00:02:24 - INFO - __main__ - Saving model with best Classification-F1: 0.46753896264020234 -> 0.47865383501425174 on epoch=28, global_step=400
06/23/2022 00:02:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
06/23/2022 00:02:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=29
06/23/2022 00:02:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
06/23/2022 00:02:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
06/23/2022 00:02:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
06/23/2022 00:02:45 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.5097955226086484 on epoch=32
06/23/2022 00:02:45 - INFO - __main__ - Saving model with best Classification-F1: 0.47865383501425174 -> 0.5097955226086484 on epoch=32, global_step=450
06/23/2022 00:02:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=32
06/23/2022 00:02:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
06/23/2022 00:02:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=34
06/23/2022 00:02:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/23/2022 00:02:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=35
06/23/2022 00:03:05 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.4872337228267622 on epoch=35
06/23/2022 00:03:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
06/23/2022 00:03:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/23/2022 00:03:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=37
06/23/2022 00:03:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/23/2022 00:03:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/23/2022 00:03:25 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.49582342217857134 on epoch=39
06/23/2022 00:03:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=39
06/23/2022 00:03:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/23/2022 00:03:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
06/23/2022 00:03:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/23/2022 00:03:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
06/23/2022 00:03:46 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.5005473890654715 on epoch=42
06/23/2022 00:03:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/23/2022 00:03:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
06/23/2022 00:03:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/23/2022 00:03:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/23/2022 00:03:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/23/2022 00:04:06 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6020635796784268 on epoch=46
06/23/2022 00:04:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5097955226086484 -> 0.6020635796784268 on epoch=46, global_step=650
06/23/2022 00:04:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
06/23/2022 00:04:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/23/2022 00:04:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
06/23/2022 00:04:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/23/2022 00:04:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
06/23/2022 00:04:26 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6440560099571104 on epoch=49
06/23/2022 00:04:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6020635796784268 -> 0.6440560099571104 on epoch=49, global_step=700
06/23/2022 00:04:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/23/2022 00:04:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/23/2022 00:04:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/23/2022 00:04:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/23/2022 00:04:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
06/23/2022 00:04:47 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6278460056959043 on epoch=53
06/23/2022 00:04:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/23/2022 00:04:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/23/2022 00:04:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/23/2022 00:04:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/23/2022 00:05:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
06/23/2022 00:05:08 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6472587517105506 on epoch=57
06/23/2022 00:05:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6440560099571104 -> 0.6472587517105506 on epoch=57, global_step=800
06/23/2022 00:05:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/23/2022 00:05:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/23/2022 00:05:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/23/2022 00:05:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/23/2022 00:05:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/23/2022 00:05:28 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6845936016890811 on epoch=60
06/23/2022 00:05:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6472587517105506 -> 0.6845936016890811 on epoch=60, global_step=850
06/23/2022 00:05:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/23/2022 00:05:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=62
06/23/2022 00:05:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
06/23/2022 00:05:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/23/2022 00:05:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
06/23/2022 00:05:49 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.6911295494014996 on epoch=64
06/23/2022 00:05:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6845936016890811 -> 0.6911295494014996 on epoch=64, global_step=900
06/23/2022 00:05:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/23/2022 00:05:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/23/2022 00:05:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/23/2022 00:05:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/23/2022 00:06:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/23/2022 00:06:09 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.6875344587096346 on epoch=67
06/23/2022 00:06:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/23/2022 00:06:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/23/2022 00:06:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/23/2022 00:06:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=70
06/23/2022 00:06:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
06/23/2022 00:06:29 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6420993499492486 on epoch=71
06/23/2022 00:06:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/23/2022 00:06:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/23/2022 00:06:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/23/2022 00:06:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=74
06/23/2022 00:06:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/23/2022 00:06:50 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6809756349093142 on epoch=74
06/23/2022 00:06:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/23/2022 00:06:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
06/23/2022 00:06:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/23/2022 00:07:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/23/2022 00:07:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/23/2022 00:07:10 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6649343662364666 on epoch=78
06/23/2022 00:07:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/23/2022 00:07:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/23/2022 00:07:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/23/2022 00:07:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/23/2022 00:07:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/23/2022 00:07:30 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6959361130276871 on epoch=82
06/23/2022 00:07:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6911295494014996 -> 0.6959361130276871 on epoch=82, global_step=1150
06/23/2022 00:07:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
06/23/2022 00:07:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/23/2022 00:07:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/23/2022 00:07:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/23/2022 00:07:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/23/2022 00:07:50 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6530415228079299 on epoch=85
06/23/2022 00:07:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/23/2022 00:07:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/23/2022 00:07:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/23/2022 00:08:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/23/2022 00:08:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/23/2022 00:08:10 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7257392380666607 on epoch=89
06/23/2022 00:08:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6959361130276871 -> 0.7257392380666607 on epoch=89, global_step=1250
06/23/2022 00:08:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/23/2022 00:08:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/23/2022 00:08:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/23/2022 00:08:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/23/2022 00:08:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/23/2022 00:08:31 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7186015681838929 on epoch=92
06/23/2022 00:08:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/23/2022 00:08:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
06/23/2022 00:08:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/23/2022 00:08:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/23/2022 00:08:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/23/2022 00:08:51 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7780524540807977 on epoch=96
06/23/2022 00:08:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7257392380666607 -> 0.7780524540807977 on epoch=96, global_step=1350
06/23/2022 00:08:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/23/2022 00:08:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/23/2022 00:08:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/23/2022 00:09:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/23/2022 00:09:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/23/2022 00:09:11 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7931569137145499 on epoch=99
06/23/2022 00:09:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7780524540807977 -> 0.7931569137145499 on epoch=99, global_step=1400
06/23/2022 00:09:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/23/2022 00:09:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
06/23/2022 00:09:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/23/2022 00:09:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
06/23/2022 00:09:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/23/2022 00:09:31 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.840266166634517 on epoch=103
06/23/2022 00:09:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7931569137145499 -> 0.840266166634517 on epoch=103, global_step=1450
06/23/2022 00:09:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/23/2022 00:09:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/23/2022 00:09:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/23/2022 00:09:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
06/23/2022 00:09:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/23/2022 00:09:51 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8402661666345171 on epoch=107
06/23/2022 00:09:51 - INFO - __main__ - Saving model with best Classification-F1: 0.840266166634517 -> 0.8402661666345171 on epoch=107, global_step=1500
06/23/2022 00:09:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/23/2022 00:09:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/23/2022 00:09:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/23/2022 00:10:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/23/2022 00:10:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/23/2022 00:10:11 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7692446528854534 on epoch=110
06/23/2022 00:10:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/23/2022 00:10:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/23/2022 00:10:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
06/23/2022 00:10:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/23/2022 00:10:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/23/2022 00:10:30 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7331006367324071 on epoch=114
06/23/2022 00:10:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/23/2022 00:10:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/23/2022 00:10:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/23/2022 00:10:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/23/2022 00:10:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/23/2022 00:10:50 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7131726590929627 on epoch=117
06/23/2022 00:10:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/23/2022 00:10:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/23/2022 00:10:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/23/2022 00:11:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/23/2022 00:11:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/23/2022 00:11:10 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7864732300158053 on epoch=121
06/23/2022 00:11:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/23/2022 00:11:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/23/2022 00:11:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/23/2022 00:11:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/23/2022 00:11:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/23/2022 00:11:30 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.765354041382385 on epoch=124
06/23/2022 00:11:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/23/2022 00:11:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/23/2022 00:11:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/23/2022 00:11:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/23/2022 00:11:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/23/2022 00:11:50 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7363212486486712 on epoch=128
06/23/2022 00:11:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/23/2022 00:11:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/23/2022 00:11:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/23/2022 00:12:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/23/2022 00:12:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/23/2022 00:12:10 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8347716611400117 on epoch=132
06/23/2022 00:12:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/23/2022 00:12:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/23/2022 00:12:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/23/2022 00:12:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/23/2022 00:12:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/23/2022 00:12:29 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8146741116306975 on epoch=135
06/23/2022 00:12:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/23/2022 00:12:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/23/2022 00:12:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/23/2022 00:12:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/23/2022 00:12:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/23/2022 00:12:48 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6881139367307348 on epoch=139
06/23/2022 00:12:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/23/2022 00:12:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/23/2022 00:12:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/23/2022 00:12:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/23/2022 00:13:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/23/2022 00:13:08 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8358381327947186 on epoch=142
06/23/2022 00:13:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/23/2022 00:13:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/23/2022 00:13:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/23/2022 00:13:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/23/2022 00:13:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/23/2022 00:13:27 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7813119396932244 on epoch=146
06/23/2022 00:13:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/23/2022 00:13:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/23/2022 00:13:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/23/2022 00:13:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/23/2022 00:13:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/23/2022 00:13:47 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7642797398163699 on epoch=149
06/23/2022 00:13:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/23/2022 00:13:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/23/2022 00:13:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/23/2022 00:13:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/23/2022 00:13:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/23/2022 00:14:06 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8383983505425631 on epoch=153
06/23/2022 00:14:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/23/2022 00:14:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
06/23/2022 00:14:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
06/23/2022 00:14:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/23/2022 00:14:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/23/2022 00:14:25 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8329038450480576 on epoch=157
06/23/2022 00:14:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/23/2022 00:14:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=158
06/23/2022 00:14:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/23/2022 00:14:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/23/2022 00:14:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/23/2022 00:14:45 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7834755637635423 on epoch=160
06/23/2022 00:14:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/23/2022 00:14:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/23/2022 00:14:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/23/2022 00:14:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/23/2022 00:14:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/23/2022 00:15:04 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7761986422997696 on epoch=164
06/23/2022 00:15:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/23/2022 00:15:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/23/2022 00:15:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/23/2022 00:15:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/23/2022 00:15:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/23/2022 00:15:23 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7827715181770245 on epoch=167
06/23/2022 00:15:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/23/2022 00:15:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/23/2022 00:15:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/23/2022 00:15:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/23/2022 00:15:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/23/2022 00:15:43 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8247110574435053 on epoch=171
06/23/2022 00:15:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/23/2022 00:15:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/23/2022 00:15:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/23/2022 00:15:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/23/2022 00:15:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/23/2022 00:16:02 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8357528478970604 on epoch=174
06/23/2022 00:16:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/23/2022 00:16:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
06/23/2022 00:16:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/23/2022 00:16:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/23/2022 00:16:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/23/2022 00:16:22 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7908387450677807 on epoch=178
06/23/2022 00:16:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/23/2022 00:16:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/23/2022 00:16:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/23/2022 00:16:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/23/2022 00:16:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/23/2022 00:16:42 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9055585495734683 on epoch=182
06/23/2022 00:16:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8402661666345171 -> 0.9055585495734683 on epoch=182, global_step=2550
06/23/2022 00:16:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/23/2022 00:16:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/23/2022 00:16:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/23/2022 00:16:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/23/2022 00:16:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/23/2022 00:17:01 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.781999778746128 on epoch=185
06/23/2022 00:17:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/23/2022 00:17:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/23/2022 00:17:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/23/2022 00:17:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/23/2022 00:17:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/23/2022 00:17:20 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8251274455896729 on epoch=189
06/23/2022 00:17:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/23/2022 00:17:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/23/2022 00:17:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/23/2022 00:17:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/23/2022 00:17:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/23/2022 00:17:40 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8410035805434288 on epoch=192
06/23/2022 00:17:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/23/2022 00:17:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/23/2022 00:17:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/23/2022 00:17:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/23/2022 00:17:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/23/2022 00:17:59 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8959141488679757 on epoch=196
06/23/2022 00:18:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/23/2022 00:18:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/23/2022 00:18:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/23/2022 00:18:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/23/2022 00:18:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/23/2022 00:18:19 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8489611402251265 on epoch=199
06/23/2022 00:18:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/23/2022 00:18:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/23/2022 00:18:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/23/2022 00:18:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/23/2022 00:18:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/23/2022 00:18:39 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9080106568531616 on epoch=203
06/23/2022 00:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.9055585495734683 -> 0.9080106568531616 on epoch=203, global_step=2850
06/23/2022 00:18:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/23/2022 00:18:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/23/2022 00:18:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/23/2022 00:18:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/23/2022 00:18:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/23/2022 00:18:59 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8471055430970043 on epoch=207
06/23/2022 00:19:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/23/2022 00:19:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/23/2022 00:19:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/23/2022 00:19:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/23/2022 00:19:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/23/2022 00:19:18 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7848313848760329 on epoch=210
06/23/2022 00:19:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/23/2022 00:19:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/23/2022 00:19:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/23/2022 00:19:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/23/2022 00:19:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/23/2022 00:19:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:19:33 - INFO - __main__ - Printing 3 examples
06/23/2022 00:19:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/23/2022 00:19:33 - INFO - __main__ - ['Plant']
06/23/2022 00:19:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/23/2022 00:19:33 - INFO - __main__ - ['Plant']
06/23/2022 00:19:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/23/2022 00:19:33 - INFO - __main__ - ['Plant']
06/23/2022 00:19:33 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:19:33 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:19:33 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 00:19:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:19:33 - INFO - __main__ - Printing 3 examples
06/23/2022 00:19:33 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/23/2022 00:19:33 - INFO - __main__ - ['Plant']
06/23/2022 00:19:33 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/23/2022 00:19:33 - INFO - __main__ - ['Plant']
06/23/2022 00:19:33 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/23/2022 00:19:33 - INFO - __main__ - ['Plant']
06/23/2022 00:19:33 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:19:33 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:19:33 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 00:19:38 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8474651489994824 on epoch=214
06/23/2022 00:19:38 - INFO - __main__ - save last model!
06/23/2022 00:19:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 00:19:38 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 00:19:38 - INFO - __main__ - Printing 3 examples
06/23/2022 00:19:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 00:19:38 - INFO - __main__ - ['Animal']
06/23/2022 00:19:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 00:19:38 - INFO - __main__ - ['Animal']
06/23/2022 00:19:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 00:19:38 - INFO - __main__ - ['Village']
06/23/2022 00:19:38 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:19:40 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:19:43 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 00:19:49 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 00:19:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 00:19:49 - INFO - __main__ - Starting training!
06/23/2022 00:21:51 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/23/2022 00:21:51 - INFO - __main__ - Classification-F1 on test data: 0.4067
06/23/2022 00:21:52 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9080106568531616, test_performance=0.40668148491790707
06/23/2022 00:21:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/23/2022 00:21:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:21:52 - INFO - __main__ - Printing 3 examples
06/23/2022 00:21:52 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/23/2022 00:21:52 - INFO - __main__ - ['Plant']
06/23/2022 00:21:53 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/23/2022 00:21:53 - INFO - __main__ - ['Plant']
06/23/2022 00:21:53 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/23/2022 00:21:53 - INFO - __main__ - ['Plant']
06/23/2022 00:21:53 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:21:53 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:21:53 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 00:21:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:21:53 - INFO - __main__ - Printing 3 examples
06/23/2022 00:21:53 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/23/2022 00:21:53 - INFO - __main__ - ['Plant']
06/23/2022 00:21:53 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/23/2022 00:21:53 - INFO - __main__ - ['Plant']
06/23/2022 00:21:53 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/23/2022 00:21:53 - INFO - __main__ - ['Plant']
06/23/2022 00:21:53 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:21:53 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:21:53 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 00:22:09 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 00:22:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 00:22:09 - INFO - __main__ - Starting training!
06/23/2022 00:22:13 - INFO - __main__ - Step 10 Global step 10 Train loss 6.36 on epoch=0
06/23/2022 00:22:15 - INFO - __main__ - Step 20 Global step 20 Train loss 5.07 on epoch=1
06/23/2022 00:22:18 - INFO - __main__ - Step 30 Global step 30 Train loss 4.44 on epoch=2
06/23/2022 00:22:21 - INFO - __main__ - Step 40 Global step 40 Train loss 4.06 on epoch=2
06/23/2022 00:22:23 - INFO - __main__ - Step 50 Global step 50 Train loss 4.04 on epoch=3
06/23/2022 00:22:29 - INFO - __main__ - Global step 50 Train loss 4.79 Classification-F1 0.04488577990329788 on epoch=3
06/23/2022 00:22:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04488577990329788 on epoch=3, global_step=50
06/23/2022 00:22:31 - INFO - __main__ - Step 60 Global step 60 Train loss 3.33 on epoch=4
06/23/2022 00:22:34 - INFO - __main__ - Step 70 Global step 70 Train loss 3.26 on epoch=4
06/23/2022 00:22:37 - INFO - __main__ - Step 80 Global step 80 Train loss 2.77 on epoch=5
06/23/2022 00:22:39 - INFO - __main__ - Step 90 Global step 90 Train loss 2.80 on epoch=6
06/23/2022 00:22:42 - INFO - __main__ - Step 100 Global step 100 Train loss 2.64 on epoch=7
06/23/2022 00:22:47 - INFO - __main__ - Global step 100 Train loss 2.96 Classification-F1 0.06361636779094085 on epoch=7
06/23/2022 00:22:47 - INFO - __main__ - Saving model with best Classification-F1: 0.04488577990329788 -> 0.06361636779094085 on epoch=7, global_step=100
06/23/2022 00:22:50 - INFO - __main__ - Step 110 Global step 110 Train loss 2.31 on epoch=7
06/23/2022 00:22:52 - INFO - __main__ - Step 120 Global step 120 Train loss 2.46 on epoch=8
06/23/2022 00:22:55 - INFO - __main__ - Step 130 Global step 130 Train loss 2.12 on epoch=9
06/23/2022 00:22:57 - INFO - __main__ - Step 140 Global step 140 Train loss 2.28 on epoch=9
06/23/2022 00:23:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.86 on epoch=10
06/23/2022 00:23:05 - INFO - __main__ - Global step 150 Train loss 2.21 Classification-F1 0.08841327505070196 on epoch=10
06/23/2022 00:23:05 - INFO - __main__ - Saving model with best Classification-F1: 0.06361636779094085 -> 0.08841327505070196 on epoch=10, global_step=150
06/23/2022 00:23:08 - INFO - __main__ - Step 160 Global step 160 Train loss 1.90 on epoch=11
06/23/2022 00:23:10 - INFO - __main__ - Step 170 Global step 170 Train loss 1.87 on epoch=12
06/23/2022 00:23:13 - INFO - __main__ - Step 180 Global step 180 Train loss 1.52 on epoch=12
06/23/2022 00:23:16 - INFO - __main__ - Step 190 Global step 190 Train loss 1.70 on epoch=13
06/23/2022 00:23:18 - INFO - __main__ - Step 200 Global step 200 Train loss 1.45 on epoch=14
06/23/2022 00:23:24 - INFO - __main__ - Global step 200 Train loss 1.69 Classification-F1 0.10653691877273636 on epoch=14
06/23/2022 00:23:24 - INFO - __main__ - Saving model with best Classification-F1: 0.08841327505070196 -> 0.10653691877273636 on epoch=14, global_step=200
06/23/2022 00:23:27 - INFO - __main__ - Step 210 Global step 210 Train loss 1.49 on epoch=14
06/23/2022 00:23:29 - INFO - __main__ - Step 220 Global step 220 Train loss 1.24 on epoch=15
06/23/2022 00:23:32 - INFO - __main__ - Step 230 Global step 230 Train loss 1.27 on epoch=16
06/23/2022 00:23:34 - INFO - __main__ - Step 240 Global step 240 Train loss 1.10 on epoch=17
06/23/2022 00:23:37 - INFO - __main__ - Step 250 Global step 250 Train loss 1.13 on epoch=17
06/23/2022 00:23:43 - INFO - __main__ - Global step 250 Train loss 1.25 Classification-F1 0.1600807254528528 on epoch=17
06/23/2022 00:23:43 - INFO - __main__ - Saving model with best Classification-F1: 0.10653691877273636 -> 0.1600807254528528 on epoch=17, global_step=250
06/23/2022 00:23:45 - INFO - __main__ - Step 260 Global step 260 Train loss 1.09 on epoch=18
06/23/2022 00:23:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.92 on epoch=19
06/23/2022 00:23:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.95 on epoch=19
06/23/2022 00:23:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.88 on epoch=20
06/23/2022 00:23:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.92 on epoch=21
06/23/2022 00:24:02 - INFO - __main__ - Global step 300 Train loss 0.95 Classification-F1 0.2812342520907593 on epoch=21
06/23/2022 00:24:02 - INFO - __main__ - Saving model with best Classification-F1: 0.1600807254528528 -> 0.2812342520907593 on epoch=21, global_step=300
06/23/2022 00:24:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=22
06/23/2022 00:24:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=22
06/23/2022 00:24:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=23
06/23/2022 00:24:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=24
06/23/2022 00:24:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=24
06/23/2022 00:24:22 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.3649583696798571 on epoch=24
06/23/2022 00:24:22 - INFO - __main__ - Saving model with best Classification-F1: 0.2812342520907593 -> 0.3649583696798571 on epoch=24, global_step=350
06/23/2022 00:24:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=25
06/23/2022 00:24:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.59 on epoch=26
06/23/2022 00:24:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.62 on epoch=27
06/23/2022 00:24:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
06/23/2022 00:24:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=28
06/23/2022 00:24:42 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.4003878277320991 on epoch=28
06/23/2022 00:24:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3649583696798571 -> 0.4003878277320991 on epoch=28, global_step=400
06/23/2022 00:24:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.62 on epoch=29
06/23/2022 00:24:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=29
06/23/2022 00:24:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=30
06/23/2022 00:24:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=31
06/23/2022 00:24:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.48 on epoch=32
06/23/2022 00:25:02 - INFO - __main__ - Global step 450 Train loss 0.50 Classification-F1 0.5057122447340517 on epoch=32
06/23/2022 00:25:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4003878277320991 -> 0.5057122447340517 on epoch=32, global_step=450
06/23/2022 00:25:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=32
06/23/2022 00:25:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
06/23/2022 00:25:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=34
06/23/2022 00:25:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=34
06/23/2022 00:25:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=35
06/23/2022 00:25:22 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.5314386783583163 on epoch=35
06/23/2022 00:25:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5057122447340517 -> 0.5314386783583163 on epoch=35, global_step=500
06/23/2022 00:25:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=36
06/23/2022 00:25:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
06/23/2022 00:25:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/23/2022 00:25:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=38
06/23/2022 00:25:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=39
06/23/2022 00:25:43 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.6134491757483542 on epoch=39
06/23/2022 00:25:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5314386783583163 -> 0.6134491757483542 on epoch=39, global_step=550
06/23/2022 00:25:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=39
06/23/2022 00:25:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=40
06/23/2022 00:25:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=41
06/23/2022 00:25:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=42
06/23/2022 00:25:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=42
06/23/2022 00:26:03 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.6200516178530142 on epoch=42
06/23/2022 00:26:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6134491757483542 -> 0.6200516178530142 on epoch=42, global_step=600
06/23/2022 00:26:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/23/2022 00:26:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=44
06/23/2022 00:26:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
06/23/2022 00:26:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=45
06/23/2022 00:26:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
06/23/2022 00:26:24 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.6247231866852989 on epoch=46
06/23/2022 00:26:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6200516178530142 -> 0.6247231866852989 on epoch=46, global_step=650
06/23/2022 00:26:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=47
06/23/2022 00:26:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=47
06/23/2022 00:26:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=48
06/23/2022 00:26:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=49
06/23/2022 00:26:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=49
06/23/2022 00:26:45 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.6291511889780799 on epoch=49
06/23/2022 00:26:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6247231866852989 -> 0.6291511889780799 on epoch=49, global_step=700
06/23/2022 00:26:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=50
06/23/2022 00:26:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/23/2022 00:26:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/23/2022 00:26:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/23/2022 00:26:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/23/2022 00:27:05 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.6622644094506104 on epoch=53
06/23/2022 00:27:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6291511889780799 -> 0.6622644094506104 on epoch=53, global_step=750
06/23/2022 00:27:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=54
06/23/2022 00:27:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
06/23/2022 00:27:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/23/2022 00:27:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
06/23/2022 00:27:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=57
06/23/2022 00:27:26 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.6365854025491927 on epoch=57
06/23/2022 00:27:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=57
06/23/2022 00:27:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/23/2022 00:27:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
06/23/2022 00:27:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
06/23/2022 00:27:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/23/2022 00:27:46 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.5783357096769753 on epoch=60
06/23/2022 00:27:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/23/2022 00:27:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/23/2022 00:27:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/23/2022 00:27:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=63
06/23/2022 00:27:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/23/2022 00:28:06 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6418114771069291 on epoch=64
06/23/2022 00:28:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/23/2022 00:28:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/23/2022 00:28:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/23/2022 00:28:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=67
06/23/2022 00:28:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
06/23/2022 00:28:26 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.5733626382092932 on epoch=67
06/23/2022 00:28:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/23/2022 00:28:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=69
06/23/2022 00:28:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/23/2022 00:28:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/23/2022 00:28:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
06/23/2022 00:28:47 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.5825214934458632 on epoch=71
06/23/2022 00:28:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/23/2022 00:28:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/23/2022 00:28:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=73
06/23/2022 00:28:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
06/23/2022 00:29:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=74
06/23/2022 00:29:07 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.6466575630030856 on epoch=74
06/23/2022 00:29:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
06/23/2022 00:29:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/23/2022 00:29:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/23/2022 00:29:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/23/2022 00:29:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/23/2022 00:29:28 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6117763845350053 on epoch=78
06/23/2022 00:29:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/23/2022 00:29:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=79
06/23/2022 00:29:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=80
06/23/2022 00:29:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/23/2022 00:29:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/23/2022 00:29:49 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.6143246848529313 on epoch=82
06/23/2022 00:29:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/23/2022 00:29:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
06/23/2022 00:29:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/23/2022 00:29:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/23/2022 00:30:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=85
06/23/2022 00:30:09 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.645911015783974 on epoch=85
06/23/2022 00:30:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=86
06/23/2022 00:30:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/23/2022 00:30:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/23/2022 00:30:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=88
06/23/2022 00:30:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=89
06/23/2022 00:30:30 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.766014173998045 on epoch=89
06/23/2022 00:30:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6622644094506104 -> 0.766014173998045 on epoch=89, global_step=1250
06/23/2022 00:30:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/23/2022 00:30:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/23/2022 00:30:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
06/23/2022 00:30:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/23/2022 00:30:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=92
06/23/2022 00:30:50 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6198831088494893 on epoch=92
06/23/2022 00:30:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/23/2022 00:30:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/23/2022 00:30:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/23/2022 00:31:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=95
06/23/2022 00:31:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/23/2022 00:31:11 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.8311356448737854 on epoch=96
06/23/2022 00:31:11 - INFO - __main__ - Saving model with best Classification-F1: 0.766014173998045 -> 0.8311356448737854 on epoch=96, global_step=1350
06/23/2022 00:31:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/23/2022 00:31:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/23/2022 00:31:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
06/23/2022 00:31:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
06/23/2022 00:31:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/23/2022 00:31:32 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7214465859270848 on epoch=99
06/23/2022 00:31:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/23/2022 00:31:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/23/2022 00:31:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
06/23/2022 00:31:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/23/2022 00:31:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/23/2022 00:31:52 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.6470590183301589 on epoch=103
06/23/2022 00:31:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=104
06/23/2022 00:31:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=104
06/23/2022 00:31:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/23/2022 00:32:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
06/23/2022 00:32:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/23/2022 00:32:12 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7117517075705914 on epoch=107
06/23/2022 00:32:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/23/2022 00:32:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.16 on epoch=108
06/23/2022 00:32:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
06/23/2022 00:32:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/23/2022 00:32:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
06/23/2022 00:32:32 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7544185588423414 on epoch=110
06/23/2022 00:32:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/23/2022 00:32:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/23/2022 00:32:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/23/2022 00:32:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/23/2022 00:32:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/23/2022 00:32:52 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7020773516596763 on epoch=114
06/23/2022 00:32:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
06/23/2022 00:32:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/23/2022 00:33:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=116
06/23/2022 00:33:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/23/2022 00:33:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=117
06/23/2022 00:33:12 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7251053177794686 on epoch=117
06/23/2022 00:33:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/23/2022 00:33:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/23/2022 00:33:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/23/2022 00:33:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/23/2022 00:33:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/23/2022 00:33:32 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8125635429353097 on epoch=121
06/23/2022 00:33:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=122
06/23/2022 00:33:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/23/2022 00:33:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/23/2022 00:33:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/23/2022 00:33:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
06/23/2022 00:33:52 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6625999972240895 on epoch=124
06/23/2022 00:33:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/23/2022 00:33:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/23/2022 00:34:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/23/2022 00:34:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/23/2022 00:34:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=128
06/23/2022 00:34:13 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6952327302584165 on epoch=128
06/23/2022 00:34:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/23/2022 00:34:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
06/23/2022 00:34:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/23/2022 00:34:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/23/2022 00:34:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/23/2022 00:34:33 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.717266900182558 on epoch=132
06/23/2022 00:34:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/23/2022 00:34:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/23/2022 00:34:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/23/2022 00:34:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/23/2022 00:34:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/23/2022 00:34:53 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7622889072827682 on epoch=135
06/23/2022 00:34:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/23/2022 00:34:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/23/2022 00:35:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/23/2022 00:35:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/23/2022 00:35:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/23/2022 00:35:13 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7314784501784337 on epoch=139
06/23/2022 00:35:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/23/2022 00:35:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/23/2022 00:35:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/23/2022 00:35:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/23/2022 00:35:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/23/2022 00:35:33 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7743879984811499 on epoch=142
06/23/2022 00:35:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/23/2022 00:35:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/23/2022 00:35:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/23/2022 00:35:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/23/2022 00:35:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/23/2022 00:35:53 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7034766938704751 on epoch=146
06/23/2022 00:35:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/23/2022 00:35:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
06/23/2022 00:36:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/23/2022 00:36:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/23/2022 00:36:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/23/2022 00:36:13 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6956794229153094 on epoch=149
06/23/2022 00:36:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
06/23/2022 00:36:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/23/2022 00:36:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/23/2022 00:36:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/23/2022 00:36:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/23/2022 00:36:33 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8360327180725663 on epoch=153
06/23/2022 00:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8311356448737854 -> 0.8360327180725663 on epoch=153, global_step=2150
06/23/2022 00:36:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/23/2022 00:36:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/23/2022 00:36:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/23/2022 00:36:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.18 on epoch=156
06/23/2022 00:36:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/23/2022 00:36:53 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7952632700484024 on epoch=157
06/23/2022 00:36:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/23/2022 00:36:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/23/2022 00:37:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/23/2022 00:37:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/23/2022 00:37:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/23/2022 00:37:13 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.744937584026768 on epoch=160
06/23/2022 00:37:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=161
06/23/2022 00:37:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/23/2022 00:37:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
06/23/2022 00:37:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=163
06/23/2022 00:37:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
06/23/2022 00:37:33 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.8471177620608361 on epoch=164
06/23/2022 00:37:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8360327180725663 -> 0.8471177620608361 on epoch=164, global_step=2300
06/23/2022 00:37:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/23/2022 00:37:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/23/2022 00:37:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/23/2022 00:37:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
06/23/2022 00:37:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/23/2022 00:37:53 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7871014129301885 on epoch=167
06/23/2022 00:37:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/23/2022 00:37:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/23/2022 00:38:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/23/2022 00:38:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/23/2022 00:38:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/23/2022 00:38:12 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8529325513196482 on epoch=171
06/23/2022 00:38:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8471177620608361 -> 0.8529325513196482 on epoch=171, global_step=2400
06/23/2022 00:38:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/23/2022 00:38:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/23/2022 00:38:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/23/2022 00:38:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=174
06/23/2022 00:38:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/23/2022 00:38:32 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8530547409579667 on epoch=174
06/23/2022 00:38:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8529325513196482 -> 0.8530547409579667 on epoch=174, global_step=2450
06/23/2022 00:38:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.14 on epoch=175
06/23/2022 00:38:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/23/2022 00:38:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/23/2022 00:38:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
06/23/2022 00:38:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/23/2022 00:38:52 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8394645378516347 on epoch=178
06/23/2022 00:38:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/23/2022 00:38:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/23/2022 00:39:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/23/2022 00:39:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/23/2022 00:39:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/23/2022 00:39:12 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8254578517624058 on epoch=182
06/23/2022 00:39:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/23/2022 00:39:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
06/23/2022 00:39:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
06/23/2022 00:39:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/23/2022 00:39:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=185
06/23/2022 00:39:32 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7258283000218485 on epoch=185
06/23/2022 00:39:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/23/2022 00:39:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/23/2022 00:39:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/23/2022 00:39:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/23/2022 00:39:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
06/23/2022 00:39:52 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7043131433812437 on epoch=189
06/23/2022 00:39:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/23/2022 00:39:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/23/2022 00:40:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/23/2022 00:40:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/23/2022 00:40:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/23/2022 00:40:11 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6873818118936965 on epoch=192
06/23/2022 00:40:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/23/2022 00:40:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/23/2022 00:40:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/23/2022 00:40:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/23/2022 00:40:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/23/2022 00:40:31 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8406316253179905 on epoch=196
06/23/2022 00:40:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/23/2022 00:40:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/23/2022 00:40:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/23/2022 00:40:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/23/2022 00:40:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/23/2022 00:40:50 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7865126551070853 on epoch=199
06/23/2022 00:40:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/23/2022 00:40:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/23/2022 00:40:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/23/2022 00:41:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/23/2022 00:41:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/23/2022 00:41:10 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8376628121164534 on epoch=203
06/23/2022 00:41:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/23/2022 00:41:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/23/2022 00:41:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/23/2022 00:41:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/23/2022 00:41:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/23/2022 00:41:30 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8516114849532188 on epoch=207
06/23/2022 00:41:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/23/2022 00:41:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/23/2022 00:41:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/23/2022 00:41:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/23/2022 00:41:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/23/2022 00:41:49 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8448066925222917 on epoch=210
06/23/2022 00:41:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/23/2022 00:41:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/23/2022 00:41:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/23/2022 00:41:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/23/2022 00:42:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/23/2022 00:42:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:42:03 - INFO - __main__ - Printing 3 examples
06/23/2022 00:42:03 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/23/2022 00:42:03 - INFO - __main__ - ['Plant']
06/23/2022 00:42:03 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/23/2022 00:42:03 - INFO - __main__ - ['Plant']
06/23/2022 00:42:03 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/23/2022 00:42:03 - INFO - __main__ - ['Plant']
06/23/2022 00:42:03 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:42:03 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:42:04 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 00:42:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:42:04 - INFO - __main__ - Printing 3 examples
06/23/2022 00:42:04 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/23/2022 00:42:04 - INFO - __main__ - ['Plant']
06/23/2022 00:42:04 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/23/2022 00:42:04 - INFO - __main__ - ['Plant']
06/23/2022 00:42:04 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/23/2022 00:42:04 - INFO - __main__ - ['Plant']
06/23/2022 00:42:04 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:42:04 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:42:04 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 00:42:09 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8397610730509213 on epoch=214
06/23/2022 00:42:09 - INFO - __main__ - save last model!
06/23/2022 00:42:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 00:42:09 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 00:42:09 - INFO - __main__ - Printing 3 examples
06/23/2022 00:42:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 00:42:09 - INFO - __main__ - ['Animal']
06/23/2022 00:42:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 00:42:09 - INFO - __main__ - ['Animal']
06/23/2022 00:42:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 00:42:09 - INFO - __main__ - ['Village']
06/23/2022 00:42:09 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:42:11 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:42:14 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 00:42:19 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 00:42:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 00:42:20 - INFO - __main__ - Starting training!
06/23/2022 00:44:24 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/23/2022 00:44:24 - INFO - __main__ - Classification-F1 on test data: 0.4428
06/23/2022 00:44:25 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.8530547409579667, test_performance=0.4427773489284019
06/23/2022 00:44:25 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/23/2022 00:44:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:44:26 - INFO - __main__ - Printing 3 examples
06/23/2022 00:44:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/23/2022 00:44:26 - INFO - __main__ - ['Plant']
06/23/2022 00:44:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/23/2022 00:44:26 - INFO - __main__ - ['Plant']
06/23/2022 00:44:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/23/2022 00:44:26 - INFO - __main__ - ['Plant']
06/23/2022 00:44:26 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:44:26 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:44:26 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 00:44:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 00:44:26 - INFO - __main__ - Printing 3 examples
06/23/2022 00:44:26 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/23/2022 00:44:26 - INFO - __main__ - ['Plant']
06/23/2022 00:44:26 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/23/2022 00:44:26 - INFO - __main__ - ['Plant']
06/23/2022 00:44:26 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/23/2022 00:44:26 - INFO - __main__ - ['Plant']
06/23/2022 00:44:26 - INFO - __main__ - Tokenizing Input ...
06/23/2022 00:44:26 - INFO - __main__ - Tokenizing Output ...
06/23/2022 00:44:26 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 00:44:42 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 00:44:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 00:44:42 - INFO - __main__ - Starting training!
06/23/2022 00:44:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.98 on epoch=0
06/23/2022 00:44:48 - INFO - __main__ - Step 20 Global step 20 Train loss 5.52 on epoch=1
06/23/2022 00:44:51 - INFO - __main__ - Step 30 Global step 30 Train loss 5.04 on epoch=2
06/23/2022 00:44:54 - INFO - __main__ - Step 40 Global step 40 Train loss 4.46 on epoch=2
06/23/2022 00:44:56 - INFO - __main__ - Step 50 Global step 50 Train loss 4.37 on epoch=3
06/23/2022 00:45:02 - INFO - __main__ - Global step 50 Train loss 5.27 Classification-F1 0.04358357025216195 on epoch=3
06/23/2022 00:45:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04358357025216195 on epoch=3, global_step=50
06/23/2022 00:45:05 - INFO - __main__ - Step 60 Global step 60 Train loss 3.86 on epoch=4
06/23/2022 00:45:07 - INFO - __main__ - Step 70 Global step 70 Train loss 3.99 on epoch=4
06/23/2022 00:45:10 - INFO - __main__ - Step 80 Global step 80 Train loss 3.27 on epoch=5
06/23/2022 00:45:12 - INFO - __main__ - Step 90 Global step 90 Train loss 3.31 on epoch=6
06/23/2022 00:45:15 - INFO - __main__ - Step 100 Global step 100 Train loss 3.11 on epoch=7
06/23/2022 00:45:20 - INFO - __main__ - Global step 100 Train loss 3.51 Classification-F1 0.060809410475666265 on epoch=7
06/23/2022 00:45:20 - INFO - __main__ - Saving model with best Classification-F1: 0.04358357025216195 -> 0.060809410475666265 on epoch=7, global_step=100
06/23/2022 00:45:23 - INFO - __main__ - Step 110 Global step 110 Train loss 2.85 on epoch=7
06/23/2022 00:45:25 - INFO - __main__ - Step 120 Global step 120 Train loss 2.93 on epoch=8
06/23/2022 00:45:28 - INFO - __main__ - Step 130 Global step 130 Train loss 2.62 on epoch=9
06/23/2022 00:45:31 - INFO - __main__ - Step 140 Global step 140 Train loss 2.69 on epoch=9
06/23/2022 00:45:33 - INFO - __main__ - Step 150 Global step 150 Train loss 2.43 on epoch=10
06/23/2022 00:45:38 - INFO - __main__ - Global step 150 Train loss 2.70 Classification-F1 0.07653439490746644 on epoch=10
06/23/2022 00:45:38 - INFO - __main__ - Saving model with best Classification-F1: 0.060809410475666265 -> 0.07653439490746644 on epoch=10, global_step=150
06/23/2022 00:45:41 - INFO - __main__ - Step 160 Global step 160 Train loss 2.41 on epoch=11
06/23/2022 00:45:44 - INFO - __main__ - Step 170 Global step 170 Train loss 2.32 on epoch=12
06/23/2022 00:45:46 - INFO - __main__ - Step 180 Global step 180 Train loss 2.16 on epoch=12
06/23/2022 00:45:49 - INFO - __main__ - Step 190 Global step 190 Train loss 2.24 on epoch=13
06/23/2022 00:45:51 - INFO - __main__ - Step 200 Global step 200 Train loss 2.06 on epoch=14
06/23/2022 00:45:57 - INFO - __main__ - Global step 200 Train loss 2.24 Classification-F1 0.08936747150650894 on epoch=14
06/23/2022 00:45:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07653439490746644 -> 0.08936747150650894 on epoch=14, global_step=200
06/23/2022 00:45:59 - INFO - __main__ - Step 210 Global step 210 Train loss 2.11 on epoch=14
06/23/2022 00:46:02 - INFO - __main__ - Step 220 Global step 220 Train loss 1.84 on epoch=15
06/23/2022 00:46:05 - INFO - __main__ - Step 230 Global step 230 Train loss 1.87 on epoch=16
06/23/2022 00:46:07 - INFO - __main__ - Step 240 Global step 240 Train loss 1.89 on epoch=17
06/23/2022 00:46:10 - INFO - __main__ - Step 250 Global step 250 Train loss 1.71 on epoch=17
06/23/2022 00:46:15 - INFO - __main__ - Global step 250 Train loss 1.88 Classification-F1 0.09861217214158391 on epoch=17
06/23/2022 00:46:15 - INFO - __main__ - Saving model with best Classification-F1: 0.08936747150650894 -> 0.09861217214158391 on epoch=17, global_step=250
06/23/2022 00:46:18 - INFO - __main__ - Step 260 Global step 260 Train loss 1.74 on epoch=18
06/23/2022 00:46:20 - INFO - __main__ - Step 270 Global step 270 Train loss 1.62 on epoch=19
06/23/2022 00:46:23 - INFO - __main__ - Step 280 Global step 280 Train loss 1.43 on epoch=19
06/23/2022 00:46:25 - INFO - __main__ - Step 290 Global step 290 Train loss 1.60 on epoch=20
06/23/2022 00:46:28 - INFO - __main__ - Step 300 Global step 300 Train loss 1.45 on epoch=21
06/23/2022 00:46:34 - INFO - __main__ - Global step 300 Train loss 1.57 Classification-F1 0.10732787876034434 on epoch=21
06/23/2022 00:46:34 - INFO - __main__ - Saving model with best Classification-F1: 0.09861217214158391 -> 0.10732787876034434 on epoch=21, global_step=300
06/23/2022 00:46:36 - INFO - __main__ - Step 310 Global step 310 Train loss 1.49 on epoch=22
06/23/2022 00:46:39 - INFO - __main__ - Step 320 Global step 320 Train loss 1.40 on epoch=22
06/23/2022 00:46:41 - INFO - __main__ - Step 330 Global step 330 Train loss 1.34 on epoch=23
06/23/2022 00:46:44 - INFO - __main__ - Step 340 Global step 340 Train loss 1.16 on epoch=24
06/23/2022 00:46:47 - INFO - __main__ - Step 350 Global step 350 Train loss 1.15 on epoch=24
06/23/2022 00:46:53 - INFO - __main__ - Global step 350 Train loss 1.31 Classification-F1 0.13842098426349067 on epoch=24
06/23/2022 00:46:53 - INFO - __main__ - Saving model with best Classification-F1: 0.10732787876034434 -> 0.13842098426349067 on epoch=24, global_step=350
06/23/2022 00:46:55 - INFO - __main__ - Step 360 Global step 360 Train loss 1.13 on epoch=25
06/23/2022 00:46:58 - INFO - __main__ - Step 370 Global step 370 Train loss 1.24 on epoch=26
06/23/2022 00:47:00 - INFO - __main__ - Step 380 Global step 380 Train loss 1.13 on epoch=27
06/23/2022 00:47:03 - INFO - __main__ - Step 390 Global step 390 Train loss 1.02 on epoch=27
06/23/2022 00:47:06 - INFO - __main__ - Step 400 Global step 400 Train loss 1.07 on epoch=28
06/23/2022 00:47:12 - INFO - __main__ - Global step 400 Train loss 1.12 Classification-F1 0.20285769207609605 on epoch=28
06/23/2022 00:47:12 - INFO - __main__ - Saving model with best Classification-F1: 0.13842098426349067 -> 0.20285769207609605 on epoch=28, global_step=400
06/23/2022 00:47:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.88 on epoch=29
06/23/2022 00:47:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.97 on epoch=29
06/23/2022 00:47:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.91 on epoch=30
06/23/2022 00:47:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.91 on epoch=31
06/23/2022 00:47:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.86 on epoch=32
06/23/2022 00:47:31 - INFO - __main__ - Global step 450 Train loss 0.91 Classification-F1 0.3018572113440255 on epoch=32
06/23/2022 00:47:31 - INFO - __main__ - Saving model with best Classification-F1: 0.20285769207609605 -> 0.3018572113440255 on epoch=32, global_step=450
06/23/2022 00:47:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.77 on epoch=32
06/23/2022 00:47:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.77 on epoch=33
06/23/2022 00:47:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.84 on epoch=34
06/23/2022 00:47:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.72 on epoch=34
06/23/2022 00:47:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.69 on epoch=35
06/23/2022 00:47:51 - INFO - __main__ - Global step 500 Train loss 0.76 Classification-F1 0.38206339903566217 on epoch=35
06/23/2022 00:47:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3018572113440255 -> 0.38206339903566217 on epoch=35, global_step=500
06/23/2022 00:47:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.63 on epoch=36
06/23/2022 00:47:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.65 on epoch=37
06/23/2022 00:47:59 - INFO - __main__ - Step 530 Global step 530 Train loss 0.56 on epoch=37
06/23/2022 00:48:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.64 on epoch=38
06/23/2022 00:48:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.60 on epoch=39
06/23/2022 00:48:11 - INFO - __main__ - Global step 550 Train loss 0.62 Classification-F1 0.3985940842480315 on epoch=39
06/23/2022 00:48:11 - INFO - __main__ - Saving model with best Classification-F1: 0.38206339903566217 -> 0.3985940842480315 on epoch=39, global_step=550
06/23/2022 00:48:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.62 on epoch=39
06/23/2022 00:48:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.60 on epoch=40
06/23/2022 00:48:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.48 on epoch=41
06/23/2022 00:48:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.58 on epoch=42
06/23/2022 00:48:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=42
06/23/2022 00:48:31 - INFO - __main__ - Global step 600 Train loss 0.55 Classification-F1 0.43762824042191467 on epoch=42
06/23/2022 00:48:31 - INFO - __main__ - Saving model with best Classification-F1: 0.3985940842480315 -> 0.43762824042191467 on epoch=42, global_step=600
06/23/2022 00:48:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.52 on epoch=43
06/23/2022 00:48:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.49 on epoch=44
06/23/2022 00:48:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.48 on epoch=44
06/23/2022 00:48:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=45
06/23/2022 00:48:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=46
06/23/2022 00:48:52 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.4759356040854714 on epoch=46
06/23/2022 00:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.43762824042191467 -> 0.4759356040854714 on epoch=46, global_step=650
06/23/2022 00:48:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
06/23/2022 00:48:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=47
06/23/2022 00:48:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.51 on epoch=48
06/23/2022 00:49:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.38 on epoch=49
06/23/2022 00:49:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=49
06/23/2022 00:49:12 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.5442052665919062 on epoch=49
06/23/2022 00:49:12 - INFO - __main__ - Saving model with best Classification-F1: 0.4759356040854714 -> 0.5442052665919062 on epoch=49, global_step=700
06/23/2022 00:49:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.44 on epoch=50
06/23/2022 00:49:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=51
06/23/2022 00:49:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=52
06/23/2022 00:49:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=52
06/23/2022 00:49:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.33 on epoch=53
06/23/2022 00:49:32 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.6135789035668366 on epoch=53
06/23/2022 00:49:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5442052665919062 -> 0.6135789035668366 on epoch=53, global_step=750
06/23/2022 00:49:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.42 on epoch=54
06/23/2022 00:49:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=54
06/23/2022 00:49:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.36 on epoch=55
06/23/2022 00:49:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=56
06/23/2022 00:49:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=57
06/23/2022 00:49:53 - INFO - __main__ - Global step 800 Train loss 0.37 Classification-F1 0.5904942482593507 on epoch=57
06/23/2022 00:49:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=57
06/23/2022 00:49:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.37 on epoch=58
06/23/2022 00:50:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=59
06/23/2022 00:50:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=59
06/23/2022 00:50:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=60
06/23/2022 00:50:13 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.5637041406728686 on epoch=60
06/23/2022 00:50:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=61
06/23/2022 00:50:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
06/23/2022 00:50:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=62
06/23/2022 00:50:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=63
06/23/2022 00:50:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.32 on epoch=64
06/23/2022 00:50:33 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.6140949412427525 on epoch=64
06/23/2022 00:50:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6135789035668366 -> 0.6140949412427525 on epoch=64, global_step=900
06/23/2022 00:50:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=64
06/23/2022 00:50:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.34 on epoch=65
06/23/2022 00:50:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.31 on epoch=66
06/23/2022 00:50:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.32 on epoch=67
06/23/2022 00:50:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=67
06/23/2022 00:50:54 - INFO - __main__ - Global step 950 Train loss 0.31 Classification-F1 0.5842954893556169 on epoch=67
06/23/2022 00:50:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.33 on epoch=68
06/23/2022 00:50:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=69
06/23/2022 00:51:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=69
06/23/2022 00:51:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/23/2022 00:51:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=71
06/23/2022 00:51:14 - INFO - __main__ - Global step 1000 Train loss 0.26 Classification-F1 0.6069957614884899 on epoch=71
06/23/2022 00:51:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=72
06/23/2022 00:51:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=72
06/23/2022 00:51:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=73
06/23/2022 00:51:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.25 on epoch=74
06/23/2022 00:51:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=74
06/23/2022 00:51:34 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.5863152955477761 on epoch=74
06/23/2022 00:51:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=75
06/23/2022 00:51:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/23/2022 00:51:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=77
06/23/2022 00:51:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=77
06/23/2022 00:51:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/23/2022 00:51:55 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.5342548230083424 on epoch=78
06/23/2022 00:51:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
06/23/2022 00:52:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=79
06/23/2022 00:52:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=80
06/23/2022 00:52:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.28 on epoch=81
06/23/2022 00:52:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=82
06/23/2022 00:52:15 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.5866165364283841 on epoch=82
06/23/2022 00:52:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/23/2022 00:52:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/23/2022 00:52:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=84
06/23/2022 00:52:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=84
06/23/2022 00:52:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=85
06/23/2022 00:52:36 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.5819061099585379 on epoch=85
06/23/2022 00:52:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.26 on epoch=86
06/23/2022 00:52:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=87
06/23/2022 00:52:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=87
06/23/2022 00:52:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/23/2022 00:52:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=89
06/23/2022 00:52:56 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.6408873451451462 on epoch=89
06/23/2022 00:52:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6140949412427525 -> 0.6408873451451462 on epoch=89, global_step=1250
06/23/2022 00:52:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.26 on epoch=89
06/23/2022 00:53:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.20 on epoch=90
06/23/2022 00:53:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=91
06/23/2022 00:53:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=92
06/23/2022 00:53:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=92
06/23/2022 00:53:17 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.6757841685960346 on epoch=92
06/23/2022 00:53:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6408873451451462 -> 0.6757841685960346 on epoch=92, global_step=1300
06/23/2022 00:53:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=93
06/23/2022 00:53:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=94
06/23/2022 00:53:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
06/23/2022 00:53:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=95
06/23/2022 00:53:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/23/2022 00:53:37 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6117763845350053 on epoch=96
06/23/2022 00:53:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
06/23/2022 00:53:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/23/2022 00:53:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=98
06/23/2022 00:53:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=99
06/23/2022 00:53:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=99
06/23/2022 00:53:58 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.6773230400911951 on epoch=99
06/23/2022 00:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6757841685960346 -> 0.6773230400911951 on epoch=99, global_step=1400
06/23/2022 00:54:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=100
06/23/2022 00:54:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=101
06/23/2022 00:54:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
06/23/2022 00:54:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.30 on epoch=102
06/23/2022 00:54:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=103
06/23/2022 00:54:18 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.6803134796238245 on epoch=103
06/23/2022 00:54:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6773230400911951 -> 0.6803134796238245 on epoch=103, global_step=1450
06/23/2022 00:54:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
06/23/2022 00:54:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=104
06/23/2022 00:54:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/23/2022 00:54:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=106
06/23/2022 00:54:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/23/2022 00:54:39 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.6782700568907465 on epoch=107
06/23/2022 00:54:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/23/2022 00:54:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=108
06/23/2022 00:54:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
06/23/2022 00:54:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
06/23/2022 00:54:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=110
06/23/2022 00:54:59 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.5827383678721768 on epoch=110
06/23/2022 00:55:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=111
06/23/2022 00:55:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
06/23/2022 00:55:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=112
06/23/2022 00:55:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.16 on epoch=113
06/23/2022 00:55:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=114
06/23/2022 00:55:20 - INFO - __main__ - Global step 1600 Train loss 0.15 Classification-F1 0.6512244927118953 on epoch=114
06/23/2022 00:55:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/23/2022 00:55:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=115
06/23/2022 00:55:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=116
06/23/2022 00:55:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/23/2022 00:55:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=117
06/23/2022 00:55:41 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.7705513073175978 on epoch=117
06/23/2022 00:55:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6803134796238245 -> 0.7705513073175978 on epoch=117, global_step=1650
06/23/2022 00:55:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/23/2022 00:55:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
06/23/2022 00:55:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/23/2022 00:55:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/23/2022 00:55:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=121
06/23/2022 00:56:02 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.5991936955229502 on epoch=121
06/23/2022 00:56:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/23/2022 00:56:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.20 on epoch=122
06/23/2022 00:56:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.21 on epoch=123
06/23/2022 00:56:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=124
06/23/2022 00:56:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=124
06/23/2022 00:56:23 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.7369964778981334 on epoch=124
06/23/2022 00:56:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
06/23/2022 00:56:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
06/23/2022 00:56:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/23/2022 00:56:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
06/23/2022 00:56:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=128
06/23/2022 00:56:43 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.5441520645330505 on epoch=128
06/23/2022 00:56:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=129
06/23/2022 00:56:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
06/23/2022 00:56:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
06/23/2022 00:56:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.14 on epoch=131
06/23/2022 00:56:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/23/2022 00:57:04 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.5921163707707232 on epoch=132
06/23/2022 00:57:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.16 on epoch=132
06/23/2022 00:57:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/23/2022 00:57:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/23/2022 00:57:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=134
06/23/2022 00:57:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=135
06/23/2022 00:57:24 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.5652089230265814 on epoch=135
06/23/2022 00:57:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.17 on epoch=136
06/23/2022 00:57:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/23/2022 00:57:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
06/23/2022 00:57:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
06/23/2022 00:57:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=139
06/23/2022 00:57:44 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.6987743891669163 on epoch=139
06/23/2022 00:57:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/23/2022 00:57:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=140
06/23/2022 00:57:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=141
06/23/2022 00:57:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=142
06/23/2022 00:57:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=142
06/23/2022 00:58:04 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.6566161899666275 on epoch=142
06/23/2022 00:58:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=143
06/23/2022 00:58:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/23/2022 00:58:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=144
06/23/2022 00:58:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/23/2022 00:58:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=146
06/23/2022 00:58:25 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.734756419089261 on epoch=146
06/23/2022 00:58:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/23/2022 00:58:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/23/2022 00:58:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=148
06/23/2022 00:58:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.16 on epoch=149
06/23/2022 00:58:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=149
06/23/2022 00:58:46 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.7862045419846571 on epoch=149
06/23/2022 00:58:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7705513073175978 -> 0.7862045419846571 on epoch=149, global_step=2100
06/23/2022 00:58:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=150
06/23/2022 00:58:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.15 on epoch=151
06/23/2022 00:58:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/23/2022 00:58:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=152
06/23/2022 00:58:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
06/23/2022 00:59:06 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.7148028977185557 on epoch=153
06/23/2022 00:59:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
06/23/2022 00:59:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/23/2022 00:59:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/23/2022 00:59:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.15 on epoch=156
06/23/2022 00:59:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
06/23/2022 00:59:27 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.7391143886967133 on epoch=157
06/23/2022 00:59:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=157
06/23/2022 00:59:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=158
06/23/2022 00:59:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
06/23/2022 00:59:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/23/2022 00:59:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=160
06/23/2022 00:59:47 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.7190357019513599 on epoch=160
06/23/2022 00:59:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=161
06/23/2022 00:59:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/23/2022 00:59:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/23/2022 00:59:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=163
06/23/2022 01:00:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=164
06/23/2022 01:00:08 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.676678774067015 on epoch=164
06/23/2022 01:00:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=164
06/23/2022 01:00:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=165
06/23/2022 01:00:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=166
06/23/2022 01:00:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
06/23/2022 01:00:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/23/2022 01:00:28 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.676678774067015 on epoch=167
06/23/2022 01:00:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/23/2022 01:00:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.15 on epoch=169
06/23/2022 01:00:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=169
06/23/2022 01:00:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/23/2022 01:00:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/23/2022 01:00:49 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.6743444559432233 on epoch=171
06/23/2022 01:00:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/23/2022 01:00:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/23/2022 01:00:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/23/2022 01:00:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/23/2022 01:01:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/23/2022 01:01:09 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.6977470920882417 on epoch=174
06/23/2022 01:01:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=175
06/23/2022 01:01:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.15 on epoch=176
06/23/2022 01:01:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/23/2022 01:01:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/23/2022 01:01:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/23/2022 01:01:29 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7019694125953918 on epoch=178
06/23/2022 01:01:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/23/2022 01:01:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/23/2022 01:01:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/23/2022 01:01:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.11 on epoch=181
06/23/2022 01:01:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
06/23/2022 01:01:49 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7019694125953918 on epoch=182
06/23/2022 01:01:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=182
06/23/2022 01:01:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/23/2022 01:01:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
06/23/2022 01:02:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/23/2022 01:02:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=185
06/23/2022 01:02:10 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.6961112890255979 on epoch=185
06/23/2022 01:02:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/23/2022 01:02:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/23/2022 01:02:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=187
06/23/2022 01:02:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/23/2022 01:02:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=189
06/23/2022 01:02:30 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.7462352030070701 on epoch=189
06/23/2022 01:02:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/23/2022 01:02:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/23/2022 01:02:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=191
06/23/2022 01:02:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/23/2022 01:02:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/23/2022 01:02:51 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.6583219223577792 on epoch=192
06/23/2022 01:02:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
06/23/2022 01:02:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/23/2022 01:02:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/23/2022 01:03:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/23/2022 01:03:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
06/23/2022 01:03:11 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6851209320936607 on epoch=196
06/23/2022 01:03:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/23/2022 01:03:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=197
06/23/2022 01:03:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.14 on epoch=198
06/23/2022 01:03:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/23/2022 01:03:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/23/2022 01:03:32 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.7409677132951358 on epoch=199
06/23/2022 01:03:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/23/2022 01:03:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=201
06/23/2022 01:03:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
06/23/2022 01:03:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
06/23/2022 01:03:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/23/2022 01:03:52 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.7036760559119424 on epoch=203
06/23/2022 01:03:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/23/2022 01:03:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/23/2022 01:04:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/23/2022 01:04:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=206
06/23/2022 01:04:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/23/2022 01:04:13 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7034766938704751 on epoch=207
06/23/2022 01:04:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=207
06/23/2022 01:04:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/23/2022 01:04:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/23/2022 01:04:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/23/2022 01:04:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.11 on epoch=210
06/23/2022 01:04:33 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7052709522436809 on epoch=210
06/23/2022 01:04:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
06/23/2022 01:04:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=212
06/23/2022 01:04:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
06/23/2022 01:04:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
06/23/2022 01:04:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.12 on epoch=214
06/23/2022 01:04:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:04:47 - INFO - __main__ - Printing 3 examples
06/23/2022 01:04:47 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 01:04:47 - INFO - __main__ - ['Company']
06/23/2022 01:04:47 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 01:04:47 - INFO - __main__ - ['Company']
06/23/2022 01:04:47 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 01:04:47 - INFO - __main__ - ['Company']
06/23/2022 01:04:47 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:04:48 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:04:48 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 01:04:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:04:48 - INFO - __main__ - Printing 3 examples
06/23/2022 01:04:48 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 01:04:48 - INFO - __main__ - ['Company']
06/23/2022 01:04:48 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 01:04:48 - INFO - __main__ - ['Company']
06/23/2022 01:04:48 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 01:04:48 - INFO - __main__ - ['Company']
06/23/2022 01:04:48 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:04:48 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:04:48 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 01:04:53 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.6971301651555253 on epoch=214
06/23/2022 01:04:53 - INFO - __main__ - save last model!
06/23/2022 01:04:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 01:04:54 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 01:04:54 - INFO - __main__ - Printing 3 examples
06/23/2022 01:04:54 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 01:04:54 - INFO - __main__ - ['Animal']
06/23/2022 01:04:54 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 01:04:54 - INFO - __main__ - ['Animal']
06/23/2022 01:04:54 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 01:04:54 - INFO - __main__ - ['Village']
06/23/2022 01:04:54 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:04:56 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:04:59 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 01:05:04 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 01:05:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 01:05:04 - INFO - __main__ - Starting training!
06/23/2022 01:07:13 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/23/2022 01:07:13 - INFO - __main__ - Classification-F1 on test data: 0.4011
06/23/2022 01:07:14 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.7862045419846571, test_performance=0.4011011559815408
06/23/2022 01:07:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/23/2022 01:07:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:07:15 - INFO - __main__ - Printing 3 examples
06/23/2022 01:07:15 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 01:07:15 - INFO - __main__ - ['Company']
06/23/2022 01:07:15 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 01:07:15 - INFO - __main__ - ['Company']
06/23/2022 01:07:15 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 01:07:15 - INFO - __main__ - ['Company']
06/23/2022 01:07:15 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:07:15 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:07:15 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 01:07:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:07:15 - INFO - __main__ - Printing 3 examples
06/23/2022 01:07:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 01:07:15 - INFO - __main__ - ['Company']
06/23/2022 01:07:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 01:07:15 - INFO - __main__ - ['Company']
06/23/2022 01:07:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 01:07:15 - INFO - __main__ - ['Company']
06/23/2022 01:07:15 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:07:15 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:07:16 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 01:07:31 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 01:07:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 01:07:32 - INFO - __main__ - Starting training!
06/23/2022 01:07:35 - INFO - __main__ - Step 10 Global step 10 Train loss 6.01 on epoch=0
06/23/2022 01:07:37 - INFO - __main__ - Step 20 Global step 20 Train loss 4.71 on epoch=1
06/23/2022 01:07:40 - INFO - __main__ - Step 30 Global step 30 Train loss 4.07 on epoch=2
06/23/2022 01:07:43 - INFO - __main__ - Step 40 Global step 40 Train loss 3.58 on epoch=2
06/23/2022 01:07:45 - INFO - __main__ - Step 50 Global step 50 Train loss 3.25 on epoch=3
06/23/2022 01:07:51 - INFO - __main__ - Global step 50 Train loss 4.32 Classification-F1 0.05069217723655844 on epoch=3
06/23/2022 01:07:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05069217723655844 on epoch=3, global_step=50
06/23/2022 01:07:53 - INFO - __main__ - Step 60 Global step 60 Train loss 3.03 on epoch=4
06/23/2022 01:07:56 - INFO - __main__ - Step 70 Global step 70 Train loss 2.74 on epoch=4
06/23/2022 01:07:58 - INFO - __main__ - Step 80 Global step 80 Train loss 2.36 on epoch=5
06/23/2022 01:08:01 - INFO - __main__ - Step 90 Global step 90 Train loss 2.21 on epoch=6
06/23/2022 01:08:03 - INFO - __main__ - Step 100 Global step 100 Train loss 2.06 on epoch=7
06/23/2022 01:08:09 - INFO - __main__ - Global step 100 Train loss 2.48 Classification-F1 0.09043505456224528 on epoch=7
06/23/2022 01:08:09 - INFO - __main__ - Saving model with best Classification-F1: 0.05069217723655844 -> 0.09043505456224528 on epoch=7, global_step=100
06/23/2022 01:08:12 - INFO - __main__ - Step 110 Global step 110 Train loss 1.97 on epoch=7
06/23/2022 01:08:14 - INFO - __main__ - Step 120 Global step 120 Train loss 1.60 on epoch=8
06/23/2022 01:08:17 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=9
06/23/2022 01:08:20 - INFO - __main__ - Step 140 Global step 140 Train loss 1.39 on epoch=9
06/23/2022 01:08:22 - INFO - __main__ - Step 150 Global step 150 Train loss 1.38 on epoch=10
06/23/2022 01:08:28 - INFO - __main__ - Global step 150 Train loss 1.58 Classification-F1 0.1398284825674412 on epoch=10
06/23/2022 01:08:28 - INFO - __main__ - Saving model with best Classification-F1: 0.09043505456224528 -> 0.1398284825674412 on epoch=10, global_step=150
06/23/2022 01:08:31 - INFO - __main__ - Step 160 Global step 160 Train loss 1.07 on epoch=11
06/23/2022 01:08:33 - INFO - __main__ - Step 170 Global step 170 Train loss 1.10 on epoch=12
06/23/2022 01:08:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=12
06/23/2022 01:08:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.96 on epoch=13
06/23/2022 01:08:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=14
06/23/2022 01:08:48 - INFO - __main__ - Global step 200 Train loss 1.00 Classification-F1 0.28304571783208177 on epoch=14
06/23/2022 01:08:48 - INFO - __main__ - Saving model with best Classification-F1: 0.1398284825674412 -> 0.28304571783208177 on epoch=14, global_step=200
06/23/2022 01:08:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=14
06/23/2022 01:08:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=15
06/23/2022 01:08:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=16
06/23/2022 01:08:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=17
06/23/2022 01:09:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=17
06/23/2022 01:09:08 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.32139562354012735 on epoch=17
06/23/2022 01:09:08 - INFO - __main__ - Saving model with best Classification-F1: 0.28304571783208177 -> 0.32139562354012735 on epoch=17, global_step=250
06/23/2022 01:09:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=18
06/23/2022 01:09:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=19
06/23/2022 01:09:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=19
06/23/2022 01:09:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=20
06/23/2022 01:09:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=21
06/23/2022 01:09:28 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.43473295243873666 on epoch=21
06/23/2022 01:09:28 - INFO - __main__ - Saving model with best Classification-F1: 0.32139562354012735 -> 0.43473295243873666 on epoch=21, global_step=300
06/23/2022 01:09:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=22
06/23/2022 01:09:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=22
06/23/2022 01:09:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=23
06/23/2022 01:09:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=24
06/23/2022 01:09:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
06/23/2022 01:09:48 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.5041588542878865 on epoch=24
06/23/2022 01:09:48 - INFO - __main__ - Saving model with best Classification-F1: 0.43473295243873666 -> 0.5041588542878865 on epoch=24, global_step=350
06/23/2022 01:09:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=25
06/23/2022 01:09:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/23/2022 01:09:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/23/2022 01:09:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=27
06/23/2022 01:10:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=28
06/23/2022 01:10:09 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5717003569387861 on epoch=28
06/23/2022 01:10:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5041588542878865 -> 0.5717003569387861 on epoch=28, global_step=400
06/23/2022 01:10:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=29
06/23/2022 01:10:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=29
06/23/2022 01:10:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=30
06/23/2022 01:10:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
06/23/2022 01:10:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=32
06/23/2022 01:10:29 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.5808700307783886 on epoch=32
06/23/2022 01:10:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5717003569387861 -> 0.5808700307783886 on epoch=32, global_step=450
06/23/2022 01:10:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=32
06/23/2022 01:10:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
06/23/2022 01:10:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=34
06/23/2022 01:10:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
06/23/2022 01:10:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=35
06/23/2022 01:10:50 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.525806026456351 on epoch=35
06/23/2022 01:10:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
06/23/2022 01:10:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
06/23/2022 01:10:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/23/2022 01:11:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=38
06/23/2022 01:11:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
06/23/2022 01:11:11 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7133351882246765 on epoch=39
06/23/2022 01:11:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5808700307783886 -> 0.7133351882246765 on epoch=39, global_step=550
06/23/2022 01:11:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=39
06/23/2022 01:11:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/23/2022 01:11:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/23/2022 01:11:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/23/2022 01:11:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/23/2022 01:11:31 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6206926406926406 on epoch=42
06/23/2022 01:11:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
06/23/2022 01:11:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=44
06/23/2022 01:11:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
06/23/2022 01:11:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=45
06/23/2022 01:11:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
06/23/2022 01:11:52 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.5973590951532127 on epoch=46
06/23/2022 01:11:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
06/23/2022 01:11:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/23/2022 01:11:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/23/2022 01:12:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
06/23/2022 01:12:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/23/2022 01:12:12 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6286459184123255 on epoch=49
06/23/2022 01:12:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/23/2022 01:12:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=51
06/23/2022 01:12:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=52
06/23/2022 01:12:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
06/23/2022 01:12:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/23/2022 01:12:32 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6265591879384983 on epoch=53
06/23/2022 01:12:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=54
06/23/2022 01:12:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/23/2022 01:12:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/23/2022 01:12:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/23/2022 01:12:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/23/2022 01:12:52 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.6256732521688416 on epoch=57
06/23/2022 01:12:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/23/2022 01:12:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
06/23/2022 01:13:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/23/2022 01:13:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/23/2022 01:13:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/23/2022 01:13:12 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6933550059986842 on epoch=60
06/23/2022 01:13:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
06/23/2022 01:13:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/23/2022 01:13:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/23/2022 01:13:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/23/2022 01:13:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/23/2022 01:13:32 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6984954649025839 on epoch=64
06/23/2022 01:13:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/23/2022 01:13:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/23/2022 01:13:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
06/23/2022 01:13:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=67
06/23/2022 01:13:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/23/2022 01:13:53 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7025836681777791 on epoch=67
06/23/2022 01:13:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/23/2022 01:13:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
06/23/2022 01:14:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/23/2022 01:14:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/23/2022 01:14:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/23/2022 01:14:13 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6937347601418791 on epoch=71
06/23/2022 01:14:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/23/2022 01:14:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/23/2022 01:14:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=73
06/23/2022 01:14:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=74
06/23/2022 01:14:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/23/2022 01:14:33 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6965292212696735 on epoch=74
06/23/2022 01:14:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/23/2022 01:14:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/23/2022 01:14:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/23/2022 01:14:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/23/2022 01:14:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
06/23/2022 01:14:53 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7382259375362824 on epoch=78
06/23/2022 01:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7133351882246765 -> 0.7382259375362824 on epoch=78, global_step=1100
06/23/2022 01:14:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/23/2022 01:14:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/23/2022 01:15:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/23/2022 01:15:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/23/2022 01:15:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/23/2022 01:15:14 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.704106470583843 on epoch=82
06/23/2022 01:15:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/23/2022 01:15:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/23/2022 01:15:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/23/2022 01:15:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/23/2022 01:15:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/23/2022 01:15:34 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7908165983216693 on epoch=85
06/23/2022 01:15:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7382259375362824 -> 0.7908165983216693 on epoch=85, global_step=1200
06/23/2022 01:15:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/23/2022 01:15:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/23/2022 01:15:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/23/2022 01:15:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/23/2022 01:15:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/23/2022 01:15:53 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.676076635843043 on epoch=89
06/23/2022 01:15:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/23/2022 01:15:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/23/2022 01:16:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/23/2022 01:16:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/23/2022 01:16:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/23/2022 01:16:13 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.806543614513254 on epoch=92
06/23/2022 01:16:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7908165983216693 -> 0.806543614513254 on epoch=92, global_step=1300
06/23/2022 01:16:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/23/2022 01:16:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/23/2022 01:16:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/23/2022 01:16:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/23/2022 01:16:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/23/2022 01:16:33 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.763419137612686 on epoch=96
06/23/2022 01:16:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/23/2022 01:16:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/23/2022 01:16:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/23/2022 01:16:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/23/2022 01:16:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/23/2022 01:16:54 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7598150816657491 on epoch=99
06/23/2022 01:16:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/23/2022 01:16:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/23/2022 01:17:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/23/2022 01:17:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/23/2022 01:17:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/23/2022 01:17:14 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8102351791156345 on epoch=103
06/23/2022 01:17:14 - INFO - __main__ - Saving model with best Classification-F1: 0.806543614513254 -> 0.8102351791156345 on epoch=103, global_step=1450
06/23/2022 01:17:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/23/2022 01:17:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/23/2022 01:17:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/23/2022 01:17:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/23/2022 01:17:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/23/2022 01:17:34 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8588204065122864 on epoch=107
06/23/2022 01:17:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8102351791156345 -> 0.8588204065122864 on epoch=107, global_step=1500
06/23/2022 01:17:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/23/2022 01:17:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/23/2022 01:17:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/23/2022 01:17:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/23/2022 01:17:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/23/2022 01:17:53 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9226979472140762 on epoch=110
06/23/2022 01:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8588204065122864 -> 0.9226979472140762 on epoch=110, global_step=1550
06/23/2022 01:17:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/23/2022 01:17:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/23/2022 01:18:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/23/2022 01:18:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/23/2022 01:18:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/23/2022 01:18:14 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7651026392961877 on epoch=114
06/23/2022 01:18:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/23/2022 01:18:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/23/2022 01:18:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/23/2022 01:18:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
06/23/2022 01:18:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/23/2022 01:18:33 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8589318147119299 on epoch=117
06/23/2022 01:18:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/23/2022 01:18:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/23/2022 01:18:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/23/2022 01:18:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/23/2022 01:18:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/23/2022 01:18:53 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8589318147119299 on epoch=121
06/23/2022 01:18:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/23/2022 01:18:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/23/2022 01:19:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/23/2022 01:19:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/23/2022 01:19:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/23/2022 01:19:13 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8630131964809384 on epoch=124
06/23/2022 01:19:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/23/2022 01:19:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/23/2022 01:19:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/23/2022 01:19:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/23/2022 01:19:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/23/2022 01:19:33 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8669232649071359 on epoch=128
06/23/2022 01:19:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/23/2022 01:19:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/23/2022 01:19:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/23/2022 01:19:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/23/2022 01:19:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/23/2022 01:19:53 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7631678295749487 on epoch=132
06/23/2022 01:19:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/23/2022 01:19:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/23/2022 01:20:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/23/2022 01:20:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/23/2022 01:20:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/23/2022 01:20:13 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7994454347395523 on epoch=135
06/23/2022 01:20:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/23/2022 01:20:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/23/2022 01:20:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/23/2022 01:20:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/23/2022 01:20:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/23/2022 01:20:33 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.810223678914381 on epoch=139
06/23/2022 01:20:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/23/2022 01:20:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/23/2022 01:20:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/23/2022 01:20:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/23/2022 01:20:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/23/2022 01:20:53 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8708333333333333 on epoch=142
06/23/2022 01:20:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/23/2022 01:20:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/23/2022 01:21:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=144
06/23/2022 01:21:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/23/2022 01:21:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/23/2022 01:21:13 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7702385366456556 on epoch=146
06/23/2022 01:21:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/23/2022 01:21:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/23/2022 01:21:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/23/2022 01:21:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/23/2022 01:21:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/23/2022 01:21:33 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.723878662172673 on epoch=149
06/23/2022 01:21:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/23/2022 01:21:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/23/2022 01:21:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/23/2022 01:21:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/23/2022 01:21:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/23/2022 01:21:52 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8137641546658102 on epoch=153
06/23/2022 01:21:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/23/2022 01:21:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/23/2022 01:22:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/23/2022 01:22:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/23/2022 01:22:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/23/2022 01:22:12 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8174442190669371 on epoch=157
06/23/2022 01:22:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/23/2022 01:22:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/23/2022 01:22:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/23/2022 01:22:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/23/2022 01:22:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/23/2022 01:22:32 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8708333333333333 on epoch=160
06/23/2022 01:22:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/23/2022 01:22:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/23/2022 01:22:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/23/2022 01:22:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/23/2022 01:22:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/23/2022 01:22:52 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7703703703703704 on epoch=164
06/23/2022 01:22:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/23/2022 01:22:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/23/2022 01:23:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/23/2022 01:23:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/23/2022 01:23:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/23/2022 01:23:12 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8177103099304238 on epoch=167
06/23/2022 01:23:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/23/2022 01:23:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/23/2022 01:23:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/23/2022 01:23:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/23/2022 01:23:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/23/2022 01:23:31 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7669056152927121 on epoch=171
06/23/2022 01:23:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/23/2022 01:23:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/23/2022 01:23:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/23/2022 01:23:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/23/2022 01:23:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/23/2022 01:23:51 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7635386119257087 on epoch=174
06/23/2022 01:23:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/23/2022 01:23:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/23/2022 01:23:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/23/2022 01:24:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/23/2022 01:24:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/23/2022 01:24:11 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7631678295749487 on epoch=178
06/23/2022 01:24:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/23/2022 01:24:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/23/2022 01:24:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/23/2022 01:24:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/23/2022 01:24:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/23/2022 01:24:31 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7670142283045509 on epoch=182
06/23/2022 01:24:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/23/2022 01:24:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/23/2022 01:24:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/23/2022 01:24:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/23/2022 01:24:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/23/2022 01:24:51 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8588204065122864 on epoch=185
06/23/2022 01:24:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/23/2022 01:24:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/23/2022 01:24:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/23/2022 01:25:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/23/2022 01:25:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/23/2022 01:25:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9226979472140762 on epoch=189
06/23/2022 01:25:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/23/2022 01:25:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/23/2022 01:25:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/23/2022 01:25:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/23/2022 01:25:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/23/2022 01:25:29 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7685782556750299 on epoch=192
06/23/2022 01:25:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/23/2022 01:25:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/23/2022 01:25:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/23/2022 01:25:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/23/2022 01:25:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/23/2022 01:25:49 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8140302455292968 on epoch=196
06/23/2022 01:25:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/23/2022 01:25:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/23/2022 01:25:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/23/2022 01:25:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/23/2022 01:26:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/23/2022 01:26:08 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8630131964809384 on epoch=199
06/23/2022 01:26:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/23/2022 01:26:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/23/2022 01:26:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/23/2022 01:26:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/23/2022 01:26:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/23/2022 01:26:28 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9183838383838382 on epoch=203
06/23/2022 01:26:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/23/2022 01:26:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/23/2022 01:26:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/23/2022 01:26:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/23/2022 01:26:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/23/2022 01:26:48 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9268686868686868 on epoch=207
06/23/2022 01:26:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9226979472140762 -> 0.9268686868686868 on epoch=207, global_step=2900
06/23/2022 01:26:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/23/2022 01:26:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/23/2022 01:26:55 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/23/2022 01:26:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/23/2022 01:27:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/23/2022 01:27:07 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=210
06/23/2022 01:27:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/23/2022 01:27:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/23/2022 01:27:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/23/2022 01:27:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/23/2022 01:27:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/23/2022 01:27:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:27:22 - INFO - __main__ - Printing 3 examples
06/23/2022 01:27:22 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 01:27:22 - INFO - __main__ - ['Company']
06/23/2022 01:27:22 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 01:27:22 - INFO - __main__ - ['Company']
06/23/2022 01:27:22 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 01:27:22 - INFO - __main__ - ['Company']
06/23/2022 01:27:22 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:27:22 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:27:22 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 01:27:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:27:22 - INFO - __main__ - Printing 3 examples
06/23/2022 01:27:22 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 01:27:22 - INFO - __main__ - ['Company']
06/23/2022 01:27:22 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 01:27:22 - INFO - __main__ - ['Company']
06/23/2022 01:27:22 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 01:27:22 - INFO - __main__ - ['Company']
06/23/2022 01:27:22 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:27:22 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:27:22 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 01:27:27 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9268686868686868 on epoch=214
06/23/2022 01:27:27 - INFO - __main__ - save last model!
06/23/2022 01:27:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 01:27:27 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 01:27:27 - INFO - __main__ - Printing 3 examples
06/23/2022 01:27:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 01:27:27 - INFO - __main__ - ['Animal']
06/23/2022 01:27:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 01:27:27 - INFO - __main__ - ['Animal']
06/23/2022 01:27:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 01:27:27 - INFO - __main__ - ['Village']
06/23/2022 01:27:27 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:27:29 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:27:32 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 01:27:38 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 01:27:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 01:27:38 - INFO - __main__ - Starting training!
06/23/2022 01:29:45 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/23/2022 01:29:45 - INFO - __main__ - Classification-F1 on test data: 0.5472
06/23/2022 01:29:46 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9268686868686868, test_performance=0.5471759696630637
06/23/2022 01:29:46 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/23/2022 01:29:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:29:47 - INFO - __main__ - Printing 3 examples
06/23/2022 01:29:47 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 01:29:47 - INFO - __main__ - ['Company']
06/23/2022 01:29:47 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 01:29:47 - INFO - __main__ - ['Company']
06/23/2022 01:29:47 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 01:29:47 - INFO - __main__ - ['Company']
06/23/2022 01:29:47 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:29:47 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:29:47 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 01:29:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:29:47 - INFO - __main__ - Printing 3 examples
06/23/2022 01:29:47 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 01:29:47 - INFO - __main__ - ['Company']
06/23/2022 01:29:47 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 01:29:47 - INFO - __main__ - ['Company']
06/23/2022 01:29:47 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 01:29:47 - INFO - __main__ - ['Company']
06/23/2022 01:29:47 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:29:47 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:29:47 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 01:30:03 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 01:30:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 01:30:03 - INFO - __main__ - Starting training!
06/23/2022 01:30:07 - INFO - __main__ - Step 10 Global step 10 Train loss 6.60 on epoch=0
06/23/2022 01:30:09 - INFO - __main__ - Step 20 Global step 20 Train loss 5.15 on epoch=1
06/23/2022 01:30:12 - INFO - __main__ - Step 30 Global step 30 Train loss 4.42 on epoch=2
06/23/2022 01:30:14 - INFO - __main__ - Step 40 Global step 40 Train loss 3.90 on epoch=2
06/23/2022 01:30:17 - INFO - __main__ - Step 50 Global step 50 Train loss 3.62 on epoch=3
06/23/2022 01:30:23 - INFO - __main__ - Global step 50 Train loss 4.74 Classification-F1 0.048387096774193554 on epoch=3
06/23/2022 01:30:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.048387096774193554 on epoch=3, global_step=50
06/23/2022 01:30:25 - INFO - __main__ - Step 60 Global step 60 Train loss 3.30 on epoch=4
06/23/2022 01:30:28 - INFO - __main__ - Step 70 Global step 70 Train loss 2.93 on epoch=4
06/23/2022 01:30:30 - INFO - __main__ - Step 80 Global step 80 Train loss 2.82 on epoch=5
06/23/2022 01:30:33 - INFO - __main__ - Step 90 Global step 90 Train loss 2.70 on epoch=6
06/23/2022 01:30:35 - INFO - __main__ - Step 100 Global step 100 Train loss 2.43 on epoch=7
06/23/2022 01:30:41 - INFO - __main__ - Global step 100 Train loss 2.84 Classification-F1 0.07484356588054637 on epoch=7
06/23/2022 01:30:42 - INFO - __main__ - Saving model with best Classification-F1: 0.048387096774193554 -> 0.07484356588054637 on epoch=7, global_step=100
06/23/2022 01:30:44 - INFO - __main__ - Step 110 Global step 110 Train loss 2.26 on epoch=7
06/23/2022 01:30:47 - INFO - __main__ - Step 120 Global step 120 Train loss 2.02 on epoch=8
06/23/2022 01:30:49 - INFO - __main__ - Step 130 Global step 130 Train loss 2.09 on epoch=9
06/23/2022 01:30:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.72 on epoch=9
06/23/2022 01:30:54 - INFO - __main__ - Step 150 Global step 150 Train loss 1.69 on epoch=10
06/23/2022 01:31:00 - INFO - __main__ - Global step 150 Train loss 1.96 Classification-F1 0.10038907092737114 on epoch=10
06/23/2022 01:31:00 - INFO - __main__ - Saving model with best Classification-F1: 0.07484356588054637 -> 0.10038907092737114 on epoch=10, global_step=150
06/23/2022 01:31:03 - INFO - __main__ - Step 160 Global step 160 Train loss 1.53 on epoch=11
06/23/2022 01:31:05 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=12
06/23/2022 01:31:08 - INFO - __main__ - Step 180 Global step 180 Train loss 1.45 on epoch=12
06/23/2022 01:31:11 - INFO - __main__ - Step 190 Global step 190 Train loss 1.23 on epoch=13
06/23/2022 01:31:13 - INFO - __main__ - Step 200 Global step 200 Train loss 1.29 on epoch=14
06/23/2022 01:31:19 - INFO - __main__ - Global step 200 Train loss 1.39 Classification-F1 0.17775266127806413 on epoch=14
06/23/2022 01:31:20 - INFO - __main__ - Saving model with best Classification-F1: 0.10038907092737114 -> 0.17775266127806413 on epoch=14, global_step=200
06/23/2022 01:31:22 - INFO - __main__ - Step 210 Global step 210 Train loss 1.07 on epoch=14
06/23/2022 01:31:25 - INFO - __main__ - Step 220 Global step 220 Train loss 1.04 on epoch=15
06/23/2022 01:31:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.97 on epoch=16
06/23/2022 01:31:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.90 on epoch=17
06/23/2022 01:31:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.77 on epoch=17
06/23/2022 01:31:40 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.27823342577072213 on epoch=17
06/23/2022 01:31:40 - INFO - __main__ - Saving model with best Classification-F1: 0.17775266127806413 -> 0.27823342577072213 on epoch=17, global_step=250
06/23/2022 01:31:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=18
06/23/2022 01:31:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=19
06/23/2022 01:31:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.65 on epoch=19
06/23/2022 01:31:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=20
06/23/2022 01:31:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.54 on epoch=21
06/23/2022 01:32:00 - INFO - __main__ - Global step 300 Train loss 0.65 Classification-F1 0.32878120677217215 on epoch=21
06/23/2022 01:32:00 - INFO - __main__ - Saving model with best Classification-F1: 0.27823342577072213 -> 0.32878120677217215 on epoch=21, global_step=300
06/23/2022 01:32:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=22
06/23/2022 01:32:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=22
06/23/2022 01:32:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/23/2022 01:32:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.48 on epoch=24
06/23/2022 01:32:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=24
06/23/2022 01:32:20 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.38730867757543663 on epoch=24
06/23/2022 01:32:20 - INFO - __main__ - Saving model with best Classification-F1: 0.32878120677217215 -> 0.38730867757543663 on epoch=24, global_step=350
06/23/2022 01:32:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.52 on epoch=25
06/23/2022 01:32:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=26
06/23/2022 01:32:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=27
06/23/2022 01:32:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
06/23/2022 01:32:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=28
06/23/2022 01:32:40 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.44066403438512797 on epoch=28
06/23/2022 01:32:40 - INFO - __main__ - Saving model with best Classification-F1: 0.38730867757543663 -> 0.44066403438512797 on epoch=28, global_step=400
06/23/2022 01:32:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=29
06/23/2022 01:32:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=29
06/23/2022 01:32:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=30
06/23/2022 01:32:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=31
06/23/2022 01:32:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
06/23/2022 01:33:01 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.48323855496531015 on epoch=32
06/23/2022 01:33:01 - INFO - __main__ - Saving model with best Classification-F1: 0.44066403438512797 -> 0.48323855496531015 on epoch=32, global_step=450
06/23/2022 01:33:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=32
06/23/2022 01:33:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=33
06/23/2022 01:33:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
06/23/2022 01:33:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=34
06/23/2022 01:33:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
06/23/2022 01:33:21 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.47894643988721686 on epoch=35
06/23/2022 01:33:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
06/23/2022 01:33:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=37
06/23/2022 01:33:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/23/2022 01:33:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=38
06/23/2022 01:33:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=39
06/23/2022 01:33:41 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.5874701946894461 on epoch=39
06/23/2022 01:33:41 - INFO - __main__ - Saving model with best Classification-F1: 0.48323855496531015 -> 0.5874701946894461 on epoch=39, global_step=550
06/23/2022 01:33:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=39
06/23/2022 01:33:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=40
06/23/2022 01:33:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=41
06/23/2022 01:33:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=42
06/23/2022 01:33:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
06/23/2022 01:34:02 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.597730412262432 on epoch=42
06/23/2022 01:34:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5874701946894461 -> 0.597730412262432 on epoch=42, global_step=600
06/23/2022 01:34:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/23/2022 01:34:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
06/23/2022 01:34:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=44
06/23/2022 01:34:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=45
06/23/2022 01:34:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
06/23/2022 01:34:22 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.5871603960389479 on epoch=46
06/23/2022 01:34:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/23/2022 01:34:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
06/23/2022 01:34:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/23/2022 01:34:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/23/2022 01:34:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
06/23/2022 01:34:43 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.6132252953557671 on epoch=49
06/23/2022 01:34:43 - INFO - __main__ - Saving model with best Classification-F1: 0.597730412262432 -> 0.6132252953557671 on epoch=49, global_step=700
06/23/2022 01:34:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
06/23/2022 01:34:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=51
06/23/2022 01:34:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=52
06/23/2022 01:34:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=52
06/23/2022 01:34:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
06/23/2022 01:35:03 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6830093047436238 on epoch=53
06/23/2022 01:35:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6132252953557671 -> 0.6830093047436238 on epoch=53, global_step=750
06/23/2022 01:35:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=54
06/23/2022 01:35:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/23/2022 01:35:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
06/23/2022 01:35:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
06/23/2022 01:35:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
06/23/2022 01:35:24 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6607154064397579 on epoch=57
06/23/2022 01:35:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/23/2022 01:35:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/23/2022 01:35:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/23/2022 01:35:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/23/2022 01:35:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/23/2022 01:35:44 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7288283621669924 on epoch=60
06/23/2022 01:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6830093047436238 -> 0.7288283621669924 on epoch=60, global_step=850
06/23/2022 01:35:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
06/23/2022 01:35:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
06/23/2022 01:35:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/23/2022 01:35:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=63
06/23/2022 01:35:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
06/23/2022 01:36:04 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6583486688749847 on epoch=64
06/23/2022 01:36:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=64
06/23/2022 01:36:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
06/23/2022 01:36:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/23/2022 01:36:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/23/2022 01:36:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
06/23/2022 01:36:25 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.7462528717145991 on epoch=67
06/23/2022 01:36:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7288283621669924 -> 0.7462528717145991 on epoch=67, global_step=950
06/23/2022 01:36:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/23/2022 01:36:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=69
06/23/2022 01:36:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/23/2022 01:36:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/23/2022 01:36:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=71
06/23/2022 01:36:45 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6962962962962964 on epoch=71
06/23/2022 01:36:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=72
06/23/2022 01:36:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/23/2022 01:36:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
06/23/2022 01:36:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=74
06/23/2022 01:36:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
06/23/2022 01:37:05 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.6993897120333901 on epoch=74
06/23/2022 01:37:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/23/2022 01:37:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/23/2022 01:37:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/23/2022 01:37:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/23/2022 01:37:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/23/2022 01:37:25 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.703943432402384 on epoch=78
06/23/2022 01:37:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/23/2022 01:37:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/23/2022 01:37:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/23/2022 01:37:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/23/2022 01:37:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
06/23/2022 01:37:46 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7099891840363709 on epoch=82
06/23/2022 01:37:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/23/2022 01:37:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/23/2022 01:37:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/23/2022 01:37:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
06/23/2022 01:37:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/23/2022 01:38:06 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.713877043187388 on epoch=85
06/23/2022 01:38:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/23/2022 01:38:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/23/2022 01:38:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=87
06/23/2022 01:38:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=88
06/23/2022 01:38:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/23/2022 01:38:26 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7008054672125863 on epoch=89
06/23/2022 01:38:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
06/23/2022 01:38:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/23/2022 01:38:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/23/2022 01:38:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/23/2022 01:38:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/23/2022 01:38:46 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7113159777230967 on epoch=92
06/23/2022 01:38:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
06/23/2022 01:38:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
06/23/2022 01:38:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/23/2022 01:38:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=95
06/23/2022 01:38:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/23/2022 01:39:06 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.7219694883766073 on epoch=96
06/23/2022 01:39:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/23/2022 01:39:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/23/2022 01:39:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/23/2022 01:39:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/23/2022 01:39:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
06/23/2022 01:39:26 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6958081192464426 on epoch=99
06/23/2022 01:39:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/23/2022 01:39:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/23/2022 01:39:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/23/2022 01:39:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
06/23/2022 01:39:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/23/2022 01:39:46 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6776251479137727 on epoch=103
06/23/2022 01:39:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
06/23/2022 01:39:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/23/2022 01:39:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/23/2022 01:39:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/23/2022 01:39:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/23/2022 01:40:06 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7617984120643164 on epoch=107
06/23/2022 01:40:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7462528717145991 -> 0.7617984120643164 on epoch=107, global_step=1500
06/23/2022 01:40:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/23/2022 01:40:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/23/2022 01:40:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/23/2022 01:40:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/23/2022 01:40:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/23/2022 01:40:26 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7871611205577049 on epoch=110
06/23/2022 01:40:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7617984120643164 -> 0.7871611205577049 on epoch=110, global_step=1550
06/23/2022 01:40:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=111
06/23/2022 01:40:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/23/2022 01:40:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/23/2022 01:40:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/23/2022 01:40:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
06/23/2022 01:40:46 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7020450260096651 on epoch=114
06/23/2022 01:40:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/23/2022 01:40:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/23/2022 01:40:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/23/2022 01:40:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/23/2022 01:40:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/23/2022 01:41:06 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7439535103606294 on epoch=117
06/23/2022 01:41:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/23/2022 01:41:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/23/2022 01:41:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/23/2022 01:41:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/23/2022 01:41:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/23/2022 01:41:26 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7397831051375926 on epoch=121
06/23/2022 01:41:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/23/2022 01:41:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/23/2022 01:41:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/23/2022 01:41:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/23/2022 01:41:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/23/2022 01:41:46 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7484127519166451 on epoch=124
06/23/2022 01:41:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/23/2022 01:41:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/23/2022 01:41:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/23/2022 01:41:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/23/2022 01:41:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/23/2022 01:42:06 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7987807453973242 on epoch=128
06/23/2022 01:42:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7871611205577049 -> 0.7987807453973242 on epoch=128, global_step=1800
06/23/2022 01:42:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/23/2022 01:42:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/23/2022 01:42:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/23/2022 01:42:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/23/2022 01:42:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/23/2022 01:42:26 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7108094157729631 on epoch=132
06/23/2022 01:42:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/23/2022 01:42:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/23/2022 01:42:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/23/2022 01:42:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/23/2022 01:42:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/23/2022 01:42:46 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.810223678914381 on epoch=135
06/23/2022 01:42:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7987807453973242 -> 0.810223678914381 on epoch=135, global_step=1900
06/23/2022 01:42:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/23/2022 01:42:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/23/2022 01:42:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/23/2022 01:42:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/23/2022 01:42:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/23/2022 01:43:06 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7521957391805062 on epoch=139
06/23/2022 01:43:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/23/2022 01:43:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/23/2022 01:43:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/23/2022 01:43:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/23/2022 01:43:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/23/2022 01:43:26 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7968969532397852 on epoch=142
06/23/2022 01:43:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/23/2022 01:43:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/23/2022 01:43:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/23/2022 01:43:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/23/2022 01:43:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/23/2022 01:43:46 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.808199643493761 on epoch=146
06/23/2022 01:43:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/23/2022 01:43:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/23/2022 01:43:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/23/2022 01:43:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/23/2022 01:43:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/23/2022 01:44:06 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7557107170010396 on epoch=149
06/23/2022 01:44:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/23/2022 01:44:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/23/2022 01:44:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/23/2022 01:44:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/23/2022 01:44:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/23/2022 01:44:26 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8140302455292968 on epoch=153
06/23/2022 01:44:26 - INFO - __main__ - Saving model with best Classification-F1: 0.810223678914381 -> 0.8140302455292968 on epoch=153, global_step=2150
06/23/2022 01:44:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/23/2022 01:44:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/23/2022 01:44:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/23/2022 01:44:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/23/2022 01:44:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
06/23/2022 01:44:46 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7991949859122535 on epoch=157
06/23/2022 01:44:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/23/2022 01:44:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/23/2022 01:44:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/23/2022 01:44:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/23/2022 01:44:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/23/2022 01:45:06 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6954692037759481 on epoch=160
06/23/2022 01:45:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/23/2022 01:45:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/23/2022 01:45:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/23/2022 01:45:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/23/2022 01:45:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/23/2022 01:45:25 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.745188198692092 on epoch=164
06/23/2022 01:45:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/23/2022 01:45:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/23/2022 01:45:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/23/2022 01:45:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/23/2022 01:45:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/23/2022 01:45:45 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7911900164983656 on epoch=167
06/23/2022 01:45:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/23/2022 01:45:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/23/2022 01:45:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/23/2022 01:45:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/23/2022 01:45:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/23/2022 01:46:05 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7463104159878353 on epoch=171
06/23/2022 01:46:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/23/2022 01:46:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/23/2022 01:46:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/23/2022 01:46:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/23/2022 01:46:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/23/2022 01:46:25 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7976779975594017 on epoch=174
06/23/2022 01:46:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/23/2022 01:46:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/23/2022 01:46:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/23/2022 01:46:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/23/2022 01:46:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/23/2022 01:46:44 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8066737105399345 on epoch=178
06/23/2022 01:46:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/23/2022 01:46:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/23/2022 01:46:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/23/2022 01:46:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/23/2022 01:46:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/23/2022 01:47:04 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8553082862543845 on epoch=182
06/23/2022 01:47:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8140302455292968 -> 0.8553082862543845 on epoch=182, global_step=2550
06/23/2022 01:47:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/23/2022 01:47:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/23/2022 01:47:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/23/2022 01:47:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/23/2022 01:47:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/23/2022 01:47:24 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8140338393421885 on epoch=185
06/23/2022 01:47:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/23/2022 01:47:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/23/2022 01:47:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/23/2022 01:47:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/23/2022 01:47:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/23/2022 01:47:43 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8521906856584276 on epoch=189
06/23/2022 01:47:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/23/2022 01:47:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/23/2022 01:47:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/23/2022 01:47:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/23/2022 01:47:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/23/2022 01:48:03 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8001678824022278 on epoch=192
06/23/2022 01:48:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/23/2022 01:48:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/23/2022 01:48:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/23/2022 01:48:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/23/2022 01:48:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/23/2022 01:48:22 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8075280112044818 on epoch=196
06/23/2022 01:48:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/23/2022 01:48:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/23/2022 01:48:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/23/2022 01:48:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/23/2022 01:48:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/23/2022 01:48:42 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=199
06/23/2022 01:48:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8553082862543845 -> 0.8591069464809384 on epoch=199, global_step=2800
06/23/2022 01:48:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/23/2022 01:48:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/23/2022 01:48:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/23/2022 01:48:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/23/2022 01:48:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/23/2022 01:49:02 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8591191654447703 on epoch=203
06/23/2022 01:49:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8591069464809384 -> 0.8591191654447703 on epoch=203, global_step=2850
06/23/2022 01:49:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/23/2022 01:49:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/23/2022 01:49:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/23/2022 01:49:12 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/23/2022 01:49:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/23/2022 01:49:21 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8630170149071359 on epoch=207
06/23/2022 01:49:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8591191654447703 -> 0.8630170149071359 on epoch=207, global_step=2900
06/23/2022 01:49:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/23/2022 01:49:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/23/2022 01:49:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/23/2022 01:49:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/23/2022 01:49:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/23/2022 01:49:41 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=210
06/23/2022 01:49:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/23/2022 01:49:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/23/2022 01:49:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/23/2022 01:49:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/23/2022 01:49:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/23/2022 01:49:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:49:55 - INFO - __main__ - Printing 3 examples
06/23/2022 01:49:55 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 01:49:55 - INFO - __main__ - ['Company']
06/23/2022 01:49:55 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 01:49:55 - INFO - __main__ - ['Company']
06/23/2022 01:49:55 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 01:49:55 - INFO - __main__ - ['Company']
06/23/2022 01:49:55 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:49:55 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:49:56 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 01:49:56 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:49:56 - INFO - __main__ - Printing 3 examples
06/23/2022 01:49:56 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 01:49:56 - INFO - __main__ - ['Company']
06/23/2022 01:49:56 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 01:49:56 - INFO - __main__ - ['Company']
06/23/2022 01:49:56 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 01:49:56 - INFO - __main__ - ['Company']
06/23/2022 01:49:56 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:49:56 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:49:56 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 01:50:01 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8043799904429363 on epoch=214
06/23/2022 01:50:01 - INFO - __main__ - save last model!
06/23/2022 01:50:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 01:50:01 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 01:50:01 - INFO - __main__ - Printing 3 examples
06/23/2022 01:50:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 01:50:01 - INFO - __main__ - ['Animal']
06/23/2022 01:50:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 01:50:01 - INFO - __main__ - ['Animal']
06/23/2022 01:50:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 01:50:01 - INFO - __main__ - ['Village']
06/23/2022 01:50:01 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:50:03 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:50:06 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 01:50:11 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 01:50:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 01:50:12 - INFO - __main__ - Starting training!
06/23/2022 01:52:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/23/2022 01:52:16 - INFO - __main__ - Classification-F1 on test data: 0.4542
06/23/2022 01:52:17 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.8630170149071359, test_performance=0.45416775269474924
06/23/2022 01:52:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/23/2022 01:52:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:52:18 - INFO - __main__ - Printing 3 examples
06/23/2022 01:52:18 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 01:52:18 - INFO - __main__ - ['Company']
06/23/2022 01:52:18 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 01:52:18 - INFO - __main__ - ['Company']
06/23/2022 01:52:18 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 01:52:18 - INFO - __main__ - ['Company']
06/23/2022 01:52:18 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:52:18 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:52:18 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 01:52:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 01:52:18 - INFO - __main__ - Printing 3 examples
06/23/2022 01:52:18 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 01:52:18 - INFO - __main__ - ['Company']
06/23/2022 01:52:18 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 01:52:18 - INFO - __main__ - ['Company']
06/23/2022 01:52:18 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 01:52:18 - INFO - __main__ - ['Company']
06/23/2022 01:52:18 - INFO - __main__ - Tokenizing Input ...
06/23/2022 01:52:18 - INFO - __main__ - Tokenizing Output ...
06/23/2022 01:52:18 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 01:52:34 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 01:52:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 01:52:35 - INFO - __main__ - Starting training!
06/23/2022 01:52:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.82 on epoch=0
06/23/2022 01:52:41 - INFO - __main__ - Step 20 Global step 20 Train loss 5.26 on epoch=1
06/23/2022 01:52:43 - INFO - __main__ - Step 30 Global step 30 Train loss 5.06 on epoch=2
06/23/2022 01:52:46 - INFO - __main__ - Step 40 Global step 40 Train loss 4.24 on epoch=2
06/23/2022 01:52:48 - INFO - __main__ - Step 50 Global step 50 Train loss 3.85 on epoch=3
06/23/2022 01:52:53 - INFO - __main__ - Global step 50 Train loss 5.05 Classification-F1 0.04430794430794431 on epoch=3
06/23/2022 01:52:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04430794430794431 on epoch=3, global_step=50
06/23/2022 01:52:56 - INFO - __main__ - Step 60 Global step 60 Train loss 3.68 on epoch=4
06/23/2022 01:52:59 - INFO - __main__ - Step 70 Global step 70 Train loss 3.47 on epoch=4
06/23/2022 01:53:01 - INFO - __main__ - Step 80 Global step 80 Train loss 3.23 on epoch=5
06/23/2022 01:53:04 - INFO - __main__ - Step 90 Global step 90 Train loss 2.83 on epoch=6
06/23/2022 01:53:06 - INFO - __main__ - Step 100 Global step 100 Train loss 2.82 on epoch=7
06/23/2022 01:53:12 - INFO - __main__ - Global step 100 Train loss 3.21 Classification-F1 0.05630666167153918 on epoch=7
06/23/2022 01:53:12 - INFO - __main__ - Saving model with best Classification-F1: 0.04430794430794431 -> 0.05630666167153918 on epoch=7, global_step=100
06/23/2022 01:53:14 - INFO - __main__ - Step 110 Global step 110 Train loss 2.65 on epoch=7
06/23/2022 01:53:17 - INFO - __main__ - Step 120 Global step 120 Train loss 2.40 on epoch=8
06/23/2022 01:53:19 - INFO - __main__ - Step 130 Global step 130 Train loss 2.40 on epoch=9
06/23/2022 01:53:22 - INFO - __main__ - Step 140 Global step 140 Train loss 2.23 on epoch=9
06/23/2022 01:53:24 - INFO - __main__ - Step 150 Global step 150 Train loss 2.09 on epoch=10
06/23/2022 01:53:30 - INFO - __main__ - Global step 150 Train loss 2.35 Classification-F1 0.09591900659013414 on epoch=10
06/23/2022 01:53:30 - INFO - __main__ - Saving model with best Classification-F1: 0.05630666167153918 -> 0.09591900659013414 on epoch=10, global_step=150
06/23/2022 01:53:33 - INFO - __main__ - Step 160 Global step 160 Train loss 2.06 on epoch=11
06/23/2022 01:53:36 - INFO - __main__ - Step 170 Global step 170 Train loss 1.96 on epoch=12
06/23/2022 01:53:38 - INFO - __main__ - Step 180 Global step 180 Train loss 1.72 on epoch=12
06/23/2022 01:53:41 - INFO - __main__ - Step 190 Global step 190 Train loss 1.73 on epoch=13
06/23/2022 01:53:43 - INFO - __main__ - Step 200 Global step 200 Train loss 1.51 on epoch=14
06/23/2022 01:53:49 - INFO - __main__ - Global step 200 Train loss 1.80 Classification-F1 0.10552335827508873 on epoch=14
06/23/2022 01:53:49 - INFO - __main__ - Saving model with best Classification-F1: 0.09591900659013414 -> 0.10552335827508873 on epoch=14, global_step=200
06/23/2022 01:53:52 - INFO - __main__ - Step 210 Global step 210 Train loss 1.39 on epoch=14
06/23/2022 01:53:54 - INFO - __main__ - Step 220 Global step 220 Train loss 1.43 on epoch=15
06/23/2022 01:53:57 - INFO - __main__ - Step 230 Global step 230 Train loss 1.26 on epoch=16
06/23/2022 01:54:00 - INFO - __main__ - Step 240 Global step 240 Train loss 1.17 on epoch=17
06/23/2022 01:54:02 - INFO - __main__ - Step 250 Global step 250 Train loss 1.22 on epoch=17
06/23/2022 01:54:08 - INFO - __main__ - Global step 250 Train loss 1.29 Classification-F1 0.1333882137245196 on epoch=17
06/23/2022 01:54:08 - INFO - __main__ - Saving model with best Classification-F1: 0.10552335827508873 -> 0.1333882137245196 on epoch=17, global_step=250
06/23/2022 01:54:11 - INFO - __main__ - Step 260 Global step 260 Train loss 1.14 on epoch=18
06/23/2022 01:54:13 - INFO - __main__ - Step 270 Global step 270 Train loss 1.16 on epoch=19
06/23/2022 01:54:16 - INFO - __main__ - Step 280 Global step 280 Train loss 1.01 on epoch=19
06/23/2022 01:54:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.97 on epoch=20
06/23/2022 01:54:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.94 on epoch=21
06/23/2022 01:54:28 - INFO - __main__ - Global step 300 Train loss 1.04 Classification-F1 0.2302214226057385 on epoch=21
06/23/2022 01:54:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1333882137245196 -> 0.2302214226057385 on epoch=21, global_step=300
06/23/2022 01:54:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.95 on epoch=22
06/23/2022 01:54:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.88 on epoch=22
06/23/2022 01:54:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.68 on epoch=23
06/23/2022 01:54:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.83 on epoch=24
06/23/2022 01:54:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=24
06/23/2022 01:54:48 - INFO - __main__ - Global step 350 Train loss 0.82 Classification-F1 0.3097109843280016 on epoch=24
06/23/2022 01:54:48 - INFO - __main__ - Saving model with best Classification-F1: 0.2302214226057385 -> 0.3097109843280016 on epoch=24, global_step=350
06/23/2022 01:54:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=25
06/23/2022 01:54:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.79 on epoch=26
06/23/2022 01:54:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=27
06/23/2022 01:54:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=27
06/23/2022 01:55:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.59 on epoch=28
06/23/2022 01:55:08 - INFO - __main__ - Global step 400 Train loss 0.65 Classification-F1 0.38888109897401957 on epoch=28
06/23/2022 01:55:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3097109843280016 -> 0.38888109897401957 on epoch=28, global_step=400
06/23/2022 01:55:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.54 on epoch=29
06/23/2022 01:55:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=29
06/23/2022 01:55:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=30
06/23/2022 01:55:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=31
06/23/2022 01:55:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.54 on epoch=32
06/23/2022 01:55:28 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.4617042115109442 on epoch=32
06/23/2022 01:55:28 - INFO - __main__ - Saving model with best Classification-F1: 0.38888109897401957 -> 0.4617042115109442 on epoch=32, global_step=450
06/23/2022 01:55:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/23/2022 01:55:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=33
06/23/2022 01:55:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=34
06/23/2022 01:55:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=34
06/23/2022 01:55:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=35
06/23/2022 01:55:49 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.4822102466196394 on epoch=35
06/23/2022 01:55:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4617042115109442 -> 0.4822102466196394 on epoch=35, global_step=500
06/23/2022 01:55:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=36
06/23/2022 01:55:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=37
06/23/2022 01:55:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.45 on epoch=37
06/23/2022 01:55:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
06/23/2022 01:56:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=39
06/23/2022 01:56:09 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.4677805162589758 on epoch=39
06/23/2022 01:56:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
06/23/2022 01:56:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
06/23/2022 01:56:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=41
06/23/2022 01:56:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=42
06/23/2022 01:56:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=42
06/23/2022 01:56:30 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.575901558526192 on epoch=42
06/23/2022 01:56:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4822102466196394 -> 0.575901558526192 on epoch=42, global_step=600
06/23/2022 01:56:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=43
06/23/2022 01:56:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=44
06/23/2022 01:56:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=44
06/23/2022 01:56:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
06/23/2022 01:56:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
06/23/2022 01:56:50 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.546746789484424 on epoch=46
06/23/2022 01:56:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=47
06/23/2022 01:56:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
06/23/2022 01:56:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=48
06/23/2022 01:57:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/23/2022 01:57:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=49
06/23/2022 01:57:11 - INFO - __main__ - Global step 700 Train loss 0.32 Classification-F1 0.521788795077062 on epoch=49
06/23/2022 01:57:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=50
06/23/2022 01:57:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=51
06/23/2022 01:57:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=52
06/23/2022 01:57:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=52
06/23/2022 01:57:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/23/2022 01:57:31 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.5990106907508015 on epoch=53
06/23/2022 01:57:31 - INFO - __main__ - Saving model with best Classification-F1: 0.575901558526192 -> 0.5990106907508015 on epoch=53, global_step=750
06/23/2022 01:57:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
06/23/2022 01:57:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=54
06/23/2022 01:57:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=55
06/23/2022 01:57:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
06/23/2022 01:57:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=57
06/23/2022 01:57:51 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.5919654484114415 on epoch=57
06/23/2022 01:57:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=57
06/23/2022 01:57:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/23/2022 01:57:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=59
06/23/2022 01:58:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=59
06/23/2022 01:58:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
06/23/2022 01:58:12 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.5712315412850173 on epoch=60
06/23/2022 01:58:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/23/2022 01:58:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=62
06/23/2022 01:58:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/23/2022 01:58:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=63
06/23/2022 01:58:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=64
06/23/2022 01:58:32 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.601126063141567 on epoch=64
06/23/2022 01:58:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5990106907508015 -> 0.601126063141567 on epoch=64, global_step=900
06/23/2022 01:58:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
06/23/2022 01:58:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
06/23/2022 01:58:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=66
06/23/2022 01:58:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=67
06/23/2022 01:58:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=67
06/23/2022 01:58:53 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.6517901336413132 on epoch=67
06/23/2022 01:58:53 - INFO - __main__ - Saving model with best Classification-F1: 0.601126063141567 -> 0.6517901336413132 on epoch=67, global_step=950
06/23/2022 01:58:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
06/23/2022 01:58:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
06/23/2022 01:59:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=69
06/23/2022 01:59:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/23/2022 01:59:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/23/2022 01:59:13 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.6223901968748423 on epoch=71
06/23/2022 01:59:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=72
06/23/2022 01:59:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/23/2022 01:59:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=73
06/23/2022 01:59:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=74
06/23/2022 01:59:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/23/2022 01:59:33 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.6536454773296879 on epoch=74
06/23/2022 01:59:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6517901336413132 -> 0.6536454773296879 on epoch=74, global_step=1050
06/23/2022 01:59:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
06/23/2022 01:59:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
06/23/2022 01:59:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=77
06/23/2022 01:59:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
06/23/2022 01:59:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/23/2022 01:59:54 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.6933550059986842 on epoch=78
06/23/2022 01:59:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6536454773296879 -> 0.6933550059986842 on epoch=78, global_step=1100
06/23/2022 01:59:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.24 on epoch=79
06/23/2022 01:59:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=79
06/23/2022 02:00:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=80
06/23/2022 02:00:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=81
06/23/2022 02:00:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=82
06/23/2022 02:00:14 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.6583266703048917 on epoch=82
06/23/2022 02:00:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=82
06/23/2022 02:00:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=83
06/23/2022 02:00:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
06/23/2022 02:00:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=84
06/23/2022 02:00:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/23/2022 02:00:34 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.6909250213981569 on epoch=85
06/23/2022 02:00:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=86
06/23/2022 02:00:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/23/2022 02:00:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/23/2022 02:00:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/23/2022 02:00:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/23/2022 02:00:54 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7346456450918925 on epoch=89
06/23/2022 02:00:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6933550059986842 -> 0.7346456450918925 on epoch=89, global_step=1250
06/23/2022 02:00:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=89
06/23/2022 02:00:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/23/2022 02:01:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/23/2022 02:01:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=92
06/23/2022 02:01:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=92
06/23/2022 02:01:14 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.6961768754872204 on epoch=92
06/23/2022 02:01:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=93
06/23/2022 02:01:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/23/2022 02:01:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
06/23/2022 02:01:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
06/23/2022 02:01:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=96
06/23/2022 02:01:34 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.7371284563982333 on epoch=96
06/23/2022 02:01:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7346456450918925 -> 0.7371284563982333 on epoch=96, global_step=1350
06/23/2022 02:01:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/23/2022 02:01:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/23/2022 02:01:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/23/2022 02:01:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=99
06/23/2022 02:01:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/23/2022 02:01:54 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.6938319981423429 on epoch=99
06/23/2022 02:01:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
06/23/2022 02:01:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/23/2022 02:02:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/23/2022 02:02:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/23/2022 02:02:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=103
06/23/2022 02:02:14 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6323048354798114 on epoch=103
06/23/2022 02:02:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=104
06/23/2022 02:02:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
06/23/2022 02:02:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=105
06/23/2022 02:02:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/23/2022 02:02:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
06/23/2022 02:02:34 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7346456450918925 on epoch=107
06/23/2022 02:02:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/23/2022 02:02:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
06/23/2022 02:02:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
06/23/2022 02:02:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/23/2022 02:02:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/23/2022 02:02:54 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.7321917865021313 on epoch=110
06/23/2022 02:02:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/23/2022 02:02:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
06/23/2022 02:03:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/23/2022 02:03:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/23/2022 02:03:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/23/2022 02:03:15 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7308823884536029 on epoch=114
06/23/2022 02:03:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=114
06/23/2022 02:03:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
06/23/2022 02:03:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=116
06/23/2022 02:03:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/23/2022 02:03:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/23/2022 02:03:35 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7632996632996633 on epoch=117
06/23/2022 02:03:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7371284563982333 -> 0.7632996632996633 on epoch=117, global_step=1650
06/23/2022 02:03:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
06/23/2022 02:03:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/23/2022 02:03:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
06/23/2022 02:03:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/23/2022 02:03:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/23/2022 02:03:55 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8589725378787878 on epoch=121
06/23/2022 02:03:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7632996632996633 -> 0.8589725378787878 on epoch=121, global_step=1700
06/23/2022 02:03:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/23/2022 02:04:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/23/2022 02:04:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/23/2022 02:04:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/23/2022 02:04:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/23/2022 02:04:15 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7986542431835356 on epoch=124
06/23/2022 02:04:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
06/23/2022 02:04:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/23/2022 02:04:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/23/2022 02:04:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/23/2022 02:04:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=128
06/23/2022 02:04:36 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7884371865396533 on epoch=128
06/23/2022 02:04:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=129
06/23/2022 02:04:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/23/2022 02:04:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/23/2022 02:04:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/23/2022 02:04:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
06/23/2022 02:04:56 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.804264988430401 on epoch=132
06/23/2022 02:04:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/23/2022 02:05:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
06/23/2022 02:05:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/23/2022 02:05:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/23/2022 02:05:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=135
06/23/2022 02:05:17 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.8100876840775749 on epoch=135
06/23/2022 02:05:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=136
06/23/2022 02:05:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/23/2022 02:05:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/23/2022 02:05:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/23/2022 02:05:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/23/2022 02:05:37 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.802380541659479 on epoch=139
06/23/2022 02:05:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
06/23/2022 02:05:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/23/2022 02:05:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/23/2022 02:05:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
06/23/2022 02:05:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/23/2022 02:05:57 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7982099845477455 on epoch=142
06/23/2022 02:06:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/23/2022 02:06:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
06/23/2022 02:06:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/23/2022 02:06:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/23/2022 02:06:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/23/2022 02:06:18 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8102351791156345 on epoch=146
06/23/2022 02:06:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
06/23/2022 02:06:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/23/2022 02:06:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/23/2022 02:06:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/23/2022 02:06:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/23/2022 02:06:38 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7530551823655272 on epoch=149
06/23/2022 02:06:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/23/2022 02:06:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/23/2022 02:06:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/23/2022 02:06:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/23/2022 02:06:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/23/2022 02:06:58 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.759066859066859 on epoch=153
06/23/2022 02:07:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/23/2022 02:07:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/23/2022 02:07:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/23/2022 02:07:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/23/2022 02:07:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/23/2022 02:07:18 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.759834908222005 on epoch=157
06/23/2022 02:07:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/23/2022 02:07:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/23/2022 02:07:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/23/2022 02:07:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/23/2022 02:07:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/23/2022 02:07:38 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7633105246008471 on epoch=160
06/23/2022 02:07:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/23/2022 02:07:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/23/2022 02:07:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/23/2022 02:07:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/23/2022 02:07:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/23/2022 02:07:58 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.859103128054741 on epoch=164
06/23/2022 02:07:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8589725378787878 -> 0.859103128054741 on epoch=164, global_step=2300
06/23/2022 02:08:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=164
06/23/2022 02:08:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=165
06/23/2022 02:08:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/23/2022 02:08:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/23/2022 02:08:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/23/2022 02:08:18 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.9226979472140762 on epoch=167
06/23/2022 02:08:18 - INFO - __main__ - Saving model with best Classification-F1: 0.859103128054741 -> 0.9226979472140762 on epoch=167, global_step=2350
06/23/2022 02:08:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/23/2022 02:08:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/23/2022 02:08:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/23/2022 02:08:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/23/2022 02:08:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/23/2022 02:08:38 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.763419137612686 on epoch=171
06/23/2022 02:08:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/23/2022 02:08:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/23/2022 02:08:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/23/2022 02:08:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/23/2022 02:08:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/23/2022 02:08:58 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9183838383838382 on epoch=174
06/23/2022 02:09:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/23/2022 02:09:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=176
06/23/2022 02:09:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/23/2022 02:09:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/23/2022 02:09:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=178
06/23/2022 02:09:19 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8589687194525903 on epoch=178
06/23/2022 02:09:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/23/2022 02:09:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/23/2022 02:09:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/23/2022 02:09:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/23/2022 02:09:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=182
06/23/2022 02:09:38 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.9183838383838382 on epoch=182
06/23/2022 02:09:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/23/2022 02:09:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/23/2022 02:09:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=184
06/23/2022 02:09:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/23/2022 02:09:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/23/2022 02:09:58 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7174284685320339 on epoch=185
06/23/2022 02:10:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/23/2022 02:10:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/23/2022 02:10:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/23/2022 02:10:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/23/2022 02:10:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/23/2022 02:10:18 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8103537749410615 on epoch=189
06/23/2022 02:10:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/23/2022 02:10:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/23/2022 02:10:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/23/2022 02:10:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/23/2022 02:10:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/23/2022 02:10:38 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8008510148927606 on epoch=192
06/23/2022 02:10:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/23/2022 02:10:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/23/2022 02:10:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/23/2022 02:10:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/23/2022 02:10:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/23/2022 02:10:58 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8083376459088034 on epoch=196
06/23/2022 02:11:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/23/2022 02:11:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/23/2022 02:11:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/23/2022 02:11:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/23/2022 02:11:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/23/2022 02:11:18 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7670142283045508 on epoch=199
06/23/2022 02:11:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/23/2022 02:11:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/23/2022 02:11:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/23/2022 02:11:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=202
06/23/2022 02:11:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/23/2022 02:11:38 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7248340793332305 on epoch=203
06/23/2022 02:11:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=204
06/23/2022 02:11:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/23/2022 02:11:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/23/2022 02:11:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/23/2022 02:11:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/23/2022 02:11:59 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8141567477430854 on epoch=207
06/23/2022 02:12:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/23/2022 02:12:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/23/2022 02:12:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/23/2022 02:12:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/23/2022 02:12:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/23/2022 02:12:19 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7670142283045508 on epoch=210
06/23/2022 02:12:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/23/2022 02:12:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/23/2022 02:12:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/23/2022 02:12:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/23/2022 02:12:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/23/2022 02:12:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:12:33 - INFO - __main__ - Printing 3 examples
06/23/2022 02:12:33 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 02:12:33 - INFO - __main__ - ['Company']
06/23/2022 02:12:33 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 02:12:33 - INFO - __main__ - ['Company']
06/23/2022 02:12:33 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 02:12:33 - INFO - __main__ - ['Company']
06/23/2022 02:12:33 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:12:33 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:12:33 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 02:12:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:12:33 - INFO - __main__ - Printing 3 examples
06/23/2022 02:12:33 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 02:12:33 - INFO - __main__ - ['Company']
06/23/2022 02:12:33 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 02:12:33 - INFO - __main__ - ['Company']
06/23/2022 02:12:33 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 02:12:33 - INFO - __main__ - ['Company']
06/23/2022 02:12:33 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:12:34 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:12:34 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 02:12:39 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8670576735092864 on epoch=214
06/23/2022 02:12:39 - INFO - __main__ - save last model!
06/23/2022 02:12:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 02:12:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 02:12:39 - INFO - __main__ - Printing 3 examples
06/23/2022 02:12:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 02:12:39 - INFO - __main__ - ['Animal']
06/23/2022 02:12:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 02:12:39 - INFO - __main__ - ['Animal']
06/23/2022 02:12:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 02:12:39 - INFO - __main__ - ['Village']
06/23/2022 02:12:39 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:12:41 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:12:44 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 02:12:49 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 02:12:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 02:12:49 - INFO - __main__ - Starting training!
06/23/2022 02:14:58 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/23/2022 02:14:58 - INFO - __main__ - Classification-F1 on test data: 0.4549
06/23/2022 02:14:59 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9226979472140762, test_performance=0.45492206569399385
06/23/2022 02:14:59 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/23/2022 02:15:00 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:15:00 - INFO - __main__ - Printing 3 examples
06/23/2022 02:15:00 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/23/2022 02:15:00 - INFO - __main__ - ['Company']
06/23/2022 02:15:00 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/23/2022 02:15:00 - INFO - __main__ - ['Company']
06/23/2022 02:15:00 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/23/2022 02:15:00 - INFO - __main__ - ['Company']
06/23/2022 02:15:00 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:15:00 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:15:00 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 02:15:00 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:15:00 - INFO - __main__ - Printing 3 examples
06/23/2022 02:15:00 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/23/2022 02:15:00 - INFO - __main__ - ['Company']
06/23/2022 02:15:00 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/23/2022 02:15:00 - INFO - __main__ - ['Company']
06/23/2022 02:15:00 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/23/2022 02:15:00 - INFO - __main__ - ['Company']
06/23/2022 02:15:00 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:15:00 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:15:01 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 02:15:16 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 02:15:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 02:15:17 - INFO - __main__ - Starting training!
06/23/2022 02:15:20 - INFO - __main__ - Step 10 Global step 10 Train loss 7.36 on epoch=0
06/23/2022 02:15:23 - INFO - __main__ - Step 20 Global step 20 Train loss 6.36 on epoch=1
06/23/2022 02:15:25 - INFO - __main__ - Step 30 Global step 30 Train loss 5.35 on epoch=2
06/23/2022 02:15:28 - INFO - __main__ - Step 40 Global step 40 Train loss 4.75 on epoch=2
06/23/2022 02:15:30 - INFO - __main__ - Step 50 Global step 50 Train loss 4.49 on epoch=3
06/23/2022 02:15:36 - INFO - __main__ - Global step 50 Train loss 5.66 Classification-F1 0.03864833107079454 on epoch=3
06/23/2022 02:15:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03864833107079454 on epoch=3, global_step=50
06/23/2022 02:15:39 - INFO - __main__ - Step 60 Global step 60 Train loss 4.28 on epoch=4
06/23/2022 02:15:41 - INFO - __main__ - Step 70 Global step 70 Train loss 4.03 on epoch=4
06/23/2022 02:15:44 - INFO - __main__ - Step 80 Global step 80 Train loss 3.89 on epoch=5
06/23/2022 02:15:46 - INFO - __main__ - Step 90 Global step 90 Train loss 3.59 on epoch=6
06/23/2022 02:15:49 - INFO - __main__ - Step 100 Global step 100 Train loss 3.50 on epoch=7
06/23/2022 02:15:54 - INFO - __main__ - Global step 100 Train loss 3.86 Classification-F1 0.047967765361819764 on epoch=7
06/23/2022 02:15:55 - INFO - __main__ - Saving model with best Classification-F1: 0.03864833107079454 -> 0.047967765361819764 on epoch=7, global_step=100
06/23/2022 02:15:57 - INFO - __main__ - Step 110 Global step 110 Train loss 3.25 on epoch=7
06/23/2022 02:16:00 - INFO - __main__ - Step 120 Global step 120 Train loss 3.17 on epoch=8
06/23/2022 02:16:02 - INFO - __main__ - Step 130 Global step 130 Train loss 3.03 on epoch=9
06/23/2022 02:16:05 - INFO - __main__ - Step 140 Global step 140 Train loss 2.89 on epoch=9
06/23/2022 02:16:07 - INFO - __main__ - Step 150 Global step 150 Train loss 2.79 on epoch=10
06/23/2022 02:16:13 - INFO - __main__ - Global step 150 Train loss 3.03 Classification-F1 0.06347660783930671 on epoch=10
06/23/2022 02:16:13 - INFO - __main__ - Saving model with best Classification-F1: 0.047967765361819764 -> 0.06347660783930671 on epoch=10, global_step=150
06/23/2022 02:16:15 - INFO - __main__ - Step 160 Global step 160 Train loss 2.60 on epoch=11
06/23/2022 02:16:18 - INFO - __main__ - Step 170 Global step 170 Train loss 2.65 on epoch=12
06/23/2022 02:16:20 - INFO - __main__ - Step 180 Global step 180 Train loss 2.52 on epoch=12
06/23/2022 02:16:23 - INFO - __main__ - Step 190 Global step 190 Train loss 2.28 on epoch=13
06/23/2022 02:16:26 - INFO - __main__ - Step 200 Global step 200 Train loss 2.26 on epoch=14
06/23/2022 02:16:32 - INFO - __main__ - Global step 200 Train loss 2.46 Classification-F1 0.07331944631147976 on epoch=14
06/23/2022 02:16:32 - INFO - __main__ - Saving model with best Classification-F1: 0.06347660783930671 -> 0.07331944631147976 on epoch=14, global_step=200
06/23/2022 02:16:34 - INFO - __main__ - Step 210 Global step 210 Train loss 2.32 on epoch=14
06/23/2022 02:16:37 - INFO - __main__ - Step 220 Global step 220 Train loss 2.15 on epoch=15
06/23/2022 02:16:39 - INFO - __main__ - Step 230 Global step 230 Train loss 2.05 on epoch=16
06/23/2022 02:16:42 - INFO - __main__ - Step 240 Global step 240 Train loss 1.95 on epoch=17
06/23/2022 02:16:44 - INFO - __main__ - Step 250 Global step 250 Train loss 2.02 on epoch=17
06/23/2022 02:16:51 - INFO - __main__ - Global step 250 Train loss 2.10 Classification-F1 0.09125556718119883 on epoch=17
06/23/2022 02:16:51 - INFO - __main__ - Saving model with best Classification-F1: 0.07331944631147976 -> 0.09125556718119883 on epoch=17, global_step=250
06/23/2022 02:16:53 - INFO - __main__ - Step 260 Global step 260 Train loss 1.77 on epoch=18
06/23/2022 02:16:56 - INFO - __main__ - Step 270 Global step 270 Train loss 1.71 on epoch=19
06/23/2022 02:16:58 - INFO - __main__ - Step 280 Global step 280 Train loss 1.63 on epoch=19
06/23/2022 02:17:01 - INFO - __main__ - Step 290 Global step 290 Train loss 1.71 on epoch=20
06/23/2022 02:17:03 - INFO - __main__ - Step 300 Global step 300 Train loss 1.54 on epoch=21
06/23/2022 02:17:09 - INFO - __main__ - Global step 300 Train loss 1.67 Classification-F1 0.1094940278503562 on epoch=21
06/23/2022 02:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.09125556718119883 -> 0.1094940278503562 on epoch=21, global_step=300
06/23/2022 02:17:12 - INFO - __main__ - Step 310 Global step 310 Train loss 1.51 on epoch=22
06/23/2022 02:17:15 - INFO - __main__ - Step 320 Global step 320 Train loss 1.46 on epoch=22
06/23/2022 02:17:17 - INFO - __main__ - Step 330 Global step 330 Train loss 1.47 on epoch=23
06/23/2022 02:17:20 - INFO - __main__ - Step 340 Global step 340 Train loss 1.47 on epoch=24
06/23/2022 02:17:22 - INFO - __main__ - Step 350 Global step 350 Train loss 1.30 on epoch=24
06/23/2022 02:17:28 - INFO - __main__ - Global step 350 Train loss 1.44 Classification-F1 0.12384760317498661 on epoch=24
06/23/2022 02:17:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1094940278503562 -> 0.12384760317498661 on epoch=24, global_step=350
06/23/2022 02:17:31 - INFO - __main__ - Step 360 Global step 360 Train loss 1.21 on epoch=25
06/23/2022 02:17:34 - INFO - __main__ - Step 370 Global step 370 Train loss 1.24 on epoch=26
06/23/2022 02:17:36 - INFO - __main__ - Step 380 Global step 380 Train loss 1.10 on epoch=27
06/23/2022 02:17:39 - INFO - __main__ - Step 390 Global step 390 Train loss 1.17 on epoch=27
06/23/2022 02:17:41 - INFO - __main__ - Step 400 Global step 400 Train loss 1.18 on epoch=28
06/23/2022 02:17:47 - INFO - __main__ - Global step 400 Train loss 1.18 Classification-F1 0.1933224292289921 on epoch=28
06/23/2022 02:17:47 - INFO - __main__ - Saving model with best Classification-F1: 0.12384760317498661 -> 0.1933224292289921 on epoch=28, global_step=400
06/23/2022 02:17:50 - INFO - __main__ - Step 410 Global step 410 Train loss 1.13 on epoch=29
06/23/2022 02:17:53 - INFO - __main__ - Step 420 Global step 420 Train loss 1.06 on epoch=29
06/23/2022 02:17:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.97 on epoch=30
06/23/2022 02:17:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.99 on epoch=31
06/23/2022 02:18:00 - INFO - __main__ - Step 450 Global step 450 Train loss 1.06 on epoch=32
06/23/2022 02:18:07 - INFO - __main__ - Global step 450 Train loss 1.04 Classification-F1 0.23404604451158703 on epoch=32
06/23/2022 02:18:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1933224292289921 -> 0.23404604451158703 on epoch=32, global_step=450
06/23/2022 02:18:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.92 on epoch=32
06/23/2022 02:18:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.89 on epoch=33
06/23/2022 02:18:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.81 on epoch=34
06/23/2022 02:18:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.77 on epoch=34
06/23/2022 02:18:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.77 on epoch=35
06/23/2022 02:18:27 - INFO - __main__ - Global step 500 Train loss 0.83 Classification-F1 0.2974564921593789 on epoch=35
06/23/2022 02:18:27 - INFO - __main__ - Saving model with best Classification-F1: 0.23404604451158703 -> 0.2974564921593789 on epoch=35, global_step=500
06/23/2022 02:18:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.76 on epoch=36
06/23/2022 02:18:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.71 on epoch=37
06/23/2022 02:18:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.61 on epoch=37
06/23/2022 02:18:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.73 on epoch=38
06/23/2022 02:18:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.70 on epoch=39
06/23/2022 02:18:47 - INFO - __main__ - Global step 550 Train loss 0.70 Classification-F1 0.35390368668572914 on epoch=39
06/23/2022 02:18:47 - INFO - __main__ - Saving model with best Classification-F1: 0.2974564921593789 -> 0.35390368668572914 on epoch=39, global_step=550
06/23/2022 02:18:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.58 on epoch=39
06/23/2022 02:18:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.66 on epoch=40
06/23/2022 02:18:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=41
06/23/2022 02:18:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.66 on epoch=42
06/23/2022 02:19:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.53 on epoch=42
06/23/2022 02:19:07 - INFO - __main__ - Global step 600 Train loss 0.60 Classification-F1 0.38146054176384103 on epoch=42
06/23/2022 02:19:07 - INFO - __main__ - Saving model with best Classification-F1: 0.35390368668572914 -> 0.38146054176384103 on epoch=42, global_step=600
06/23/2022 02:19:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.57 on epoch=43
06/23/2022 02:19:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.57 on epoch=44
06/23/2022 02:19:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=44
06/23/2022 02:19:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.46 on epoch=45
06/23/2022 02:19:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.48 on epoch=46
06/23/2022 02:19:27 - INFO - __main__ - Global step 650 Train loss 0.52 Classification-F1 0.3849938417150719 on epoch=46
06/23/2022 02:19:27 - INFO - __main__ - Saving model with best Classification-F1: 0.38146054176384103 -> 0.3849938417150719 on epoch=46, global_step=650
06/23/2022 02:19:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=47
06/23/2022 02:19:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.57 on epoch=47
06/23/2022 02:19:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.47 on epoch=48
06/23/2022 02:19:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.57 on epoch=49
06/23/2022 02:19:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=49
06/23/2022 02:19:47 - INFO - __main__ - Global step 700 Train loss 0.52 Classification-F1 0.4002482162875734 on epoch=49
06/23/2022 02:19:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3849938417150719 -> 0.4002482162875734 on epoch=49, global_step=700
06/23/2022 02:19:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.48 on epoch=50
06/23/2022 02:19:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=51
06/23/2022 02:19:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.51 on epoch=52
06/23/2022 02:19:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.50 on epoch=52
06/23/2022 02:20:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/23/2022 02:20:07 - INFO - __main__ - Global step 750 Train loss 0.47 Classification-F1 0.4519766948113801 on epoch=53
06/23/2022 02:20:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4002482162875734 -> 0.4519766948113801 on epoch=53, global_step=750
06/23/2022 02:20:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.51 on epoch=54
06/23/2022 02:20:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=54
06/23/2022 02:20:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.43 on epoch=55
06/23/2022 02:20:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=56
06/23/2022 02:20:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.43 on epoch=57
06/23/2022 02:20:27 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.4587951986149145 on epoch=57
06/23/2022 02:20:27 - INFO - __main__ - Saving model with best Classification-F1: 0.4519766948113801 -> 0.4587951986149145 on epoch=57, global_step=800
06/23/2022 02:20:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.50 on epoch=57
06/23/2022 02:20:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.39 on epoch=58
06/23/2022 02:20:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=59
06/23/2022 02:20:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.45 on epoch=59
06/23/2022 02:20:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.40 on epoch=60
06/23/2022 02:20:47 - INFO - __main__ - Global step 850 Train loss 0.42 Classification-F1 0.4760835648881189 on epoch=60
06/23/2022 02:20:47 - INFO - __main__ - Saving model with best Classification-F1: 0.4587951986149145 -> 0.4760835648881189 on epoch=60, global_step=850
06/23/2022 02:20:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.45 on epoch=61
06/23/2022 02:20:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.37 on epoch=62
06/23/2022 02:20:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=62
06/23/2022 02:20:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.40 on epoch=63
06/23/2022 02:21:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.36 on epoch=64
06/23/2022 02:21:08 - INFO - __main__ - Global step 900 Train loss 0.39 Classification-F1 0.5265833569755138 on epoch=64
06/23/2022 02:21:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4760835648881189 -> 0.5265833569755138 on epoch=64, global_step=900
06/23/2022 02:21:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.49 on epoch=64
06/23/2022 02:21:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.38 on epoch=65
06/23/2022 02:21:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.33 on epoch=66
06/23/2022 02:21:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=67
06/23/2022 02:21:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.36 on epoch=67
06/23/2022 02:21:28 - INFO - __main__ - Global step 950 Train loss 0.37 Classification-F1 0.5136151468298844 on epoch=67
06/23/2022 02:21:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=68
06/23/2022 02:21:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=69
06/23/2022 02:21:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.42 on epoch=69
06/23/2022 02:21:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.40 on epoch=70
06/23/2022 02:21:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=71
06/23/2022 02:21:48 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.5990106907508015 on epoch=71
06/23/2022 02:21:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5265833569755138 -> 0.5990106907508015 on epoch=71, global_step=1000
06/23/2022 02:21:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=72
06/23/2022 02:21:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=72
06/23/2022 02:21:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/23/2022 02:21:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.32 on epoch=74
06/23/2022 02:22:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=74
06/23/2022 02:22:09 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.6318463027844368 on epoch=74
06/23/2022 02:22:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5990106907508015 -> 0.6318463027844368 on epoch=74, global_step=1050
06/23/2022 02:22:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.37 on epoch=75
06/23/2022 02:22:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.33 on epoch=76
06/23/2022 02:22:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.36 on epoch=77
06/23/2022 02:22:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.36 on epoch=77
06/23/2022 02:22:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.34 on epoch=78
06/23/2022 02:22:29 - INFO - __main__ - Global step 1100 Train loss 0.35 Classification-F1 0.5485542590401925 on epoch=78
06/23/2022 02:22:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=79
06/23/2022 02:22:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.27 on epoch=79
06/23/2022 02:22:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=80
06/23/2022 02:22:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=81
06/23/2022 02:22:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.31 on epoch=82
06/23/2022 02:22:49 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.6309316686380952 on epoch=82
06/23/2022 02:22:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.30 on epoch=82
06/23/2022 02:22:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/23/2022 02:22:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.29 on epoch=84
06/23/2022 02:23:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.29 on epoch=84
06/23/2022 02:23:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=85
06/23/2022 02:23:10 - INFO - __main__ - Global step 1200 Train loss 0.28 Classification-F1 0.6241782355575459 on epoch=85
06/23/2022 02:23:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=86
06/23/2022 02:23:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=87
06/23/2022 02:23:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.27 on epoch=87
06/23/2022 02:23:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.26 on epoch=88
06/23/2022 02:23:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=89
06/23/2022 02:23:30 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.5580492733810811 on epoch=89
06/23/2022 02:23:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.28 on epoch=89
06/23/2022 02:23:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=90
06/23/2022 02:23:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=91
06/23/2022 02:23:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.27 on epoch=92
06/23/2022 02:23:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=92
06/23/2022 02:23:51 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.5235365418894831 on epoch=92
06/23/2022 02:23:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
06/23/2022 02:23:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=94
06/23/2022 02:23:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=94
06/23/2022 02:24:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=95
06/23/2022 02:24:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.21 on epoch=96
06/23/2022 02:24:11 - INFO - __main__ - Global step 1350 Train loss 0.22 Classification-F1 0.6303311512692852 on epoch=96
06/23/2022 02:24:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=97
06/23/2022 02:24:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.29 on epoch=97
06/23/2022 02:24:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=98
06/23/2022 02:24:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.23 on epoch=99
06/23/2022 02:24:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=99
06/23/2022 02:24:31 - INFO - __main__ - Global step 1400 Train loss 0.22 Classification-F1 0.5690581362211456 on epoch=99
06/23/2022 02:24:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=100
06/23/2022 02:24:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=101
06/23/2022 02:24:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=102
06/23/2022 02:24:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.23 on epoch=102
06/23/2022 02:24:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=103
06/23/2022 02:24:52 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.5735742442164502 on epoch=103
06/23/2022 02:24:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=104
06/23/2022 02:24:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.21 on epoch=104
06/23/2022 02:24:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.20 on epoch=105
06/23/2022 02:25:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/23/2022 02:25:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=107
06/23/2022 02:25:12 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.6062109027626269 on epoch=107
06/23/2022 02:25:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/23/2022 02:25:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.19 on epoch=108
06/23/2022 02:25:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
06/23/2022 02:25:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.21 on epoch=109
06/23/2022 02:25:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=110
06/23/2022 02:25:32 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.5438350754692584 on epoch=110
06/23/2022 02:25:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=111
06/23/2022 02:25:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=112
06/23/2022 02:25:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/23/2022 02:25:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=113
06/23/2022 02:25:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
06/23/2022 02:25:52 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.5489501649833248 on epoch=114
06/23/2022 02:25:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/23/2022 02:25:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=115
06/23/2022 02:26:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.20 on epoch=116
06/23/2022 02:26:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=117
06/23/2022 02:26:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.20 on epoch=117
06/23/2022 02:26:13 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.6346452752928784 on epoch=117
06/23/2022 02:26:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6318463027844368 -> 0.6346452752928784 on epoch=117, global_step=1650
06/23/2022 02:26:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/23/2022 02:26:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.20 on epoch=119
06/23/2022 02:26:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/23/2022 02:26:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=120
06/23/2022 02:26:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=121
06/23/2022 02:26:33 - INFO - __main__ - Global step 1700 Train loss 0.16 Classification-F1 0.5994443020218512 on epoch=121
06/23/2022 02:26:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=122
06/23/2022 02:26:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/23/2022 02:26:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=123
06/23/2022 02:26:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/23/2022 02:26:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.17 on epoch=124
06/23/2022 02:26:54 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.5735742442164503 on epoch=124
06/23/2022 02:26:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=125
06/23/2022 02:26:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.20 on epoch=126
06/23/2022 02:27:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/23/2022 02:27:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.19 on epoch=127
06/23/2022 02:27:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=128
06/23/2022 02:27:14 - INFO - __main__ - Global step 1800 Train loss 0.16 Classification-F1 0.6621997049866556 on epoch=128
06/23/2022 02:27:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6346452752928784 -> 0.6621997049866556 on epoch=128, global_step=1800
06/23/2022 02:27:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.16 on epoch=129
06/23/2022 02:27:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.20 on epoch=129
06/23/2022 02:27:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
06/23/2022 02:27:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
06/23/2022 02:27:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=132
06/23/2022 02:27:35 - INFO - __main__ - Global step 1850 Train loss 0.17 Classification-F1 0.6303311512692852 on epoch=132
06/23/2022 02:27:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=132
06/23/2022 02:27:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.15 on epoch=133
06/23/2022 02:27:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
06/23/2022 02:27:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=134
06/23/2022 02:27:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/23/2022 02:27:55 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.6980207106643889 on epoch=135
06/23/2022 02:27:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6621997049866556 -> 0.6980207106643889 on epoch=135, global_step=1900
06/23/2022 02:27:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=136
06/23/2022 02:28:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=137
06/23/2022 02:28:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/23/2022 02:28:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=138
06/23/2022 02:28:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=139
06/23/2022 02:28:15 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.6761564859186409 on epoch=139
06/23/2022 02:28:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/23/2022 02:28:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.16 on epoch=140
06/23/2022 02:28:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=141
06/23/2022 02:28:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
06/23/2022 02:28:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=142
06/23/2022 02:28:35 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.6419212609559608 on epoch=142
06/23/2022 02:28:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.21 on epoch=143
06/23/2022 02:28:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/23/2022 02:28:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=144
06/23/2022 02:28:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.14 on epoch=145
06/23/2022 02:28:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.15 on epoch=146
06/23/2022 02:28:56 - INFO - __main__ - Global step 2050 Train loss 0.15 Classification-F1 0.6355599094392197 on epoch=146
06/23/2022 02:28:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=147
06/23/2022 02:29:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=147
06/23/2022 02:29:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
06/23/2022 02:29:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=149
06/23/2022 02:29:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=149
06/23/2022 02:29:16 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.6731039982401144 on epoch=149
06/23/2022 02:29:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=150
06/23/2022 02:29:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=151
06/23/2022 02:29:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=152
06/23/2022 02:29:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
06/23/2022 02:29:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/23/2022 02:29:37 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6795433921795082 on epoch=153
06/23/2022 02:29:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=154
06/23/2022 02:29:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.14 on epoch=154
06/23/2022 02:29:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.16 on epoch=155
06/23/2022 02:29:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
06/23/2022 02:29:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/23/2022 02:29:57 - INFO - __main__ - Global step 2200 Train loss 0.13 Classification-F1 0.726195883767098 on epoch=157
06/23/2022 02:29:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6980207106643889 -> 0.726195883767098 on epoch=157, global_step=2200
06/23/2022 02:30:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.12 on epoch=157
06/23/2022 02:30:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/23/2022 02:30:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
06/23/2022 02:30:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
06/23/2022 02:30:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.17 on epoch=160
06/23/2022 02:30:17 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.7308690351793801 on epoch=160
06/23/2022 02:30:17 - INFO - __main__ - Saving model with best Classification-F1: 0.726195883767098 -> 0.7308690351793801 on epoch=160, global_step=2250
06/23/2022 02:30:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
06/23/2022 02:30:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/23/2022 02:30:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/23/2022 02:30:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/23/2022 02:30:30 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.15 on epoch=164
06/23/2022 02:30:37 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.7738613313664023 on epoch=164
06/23/2022 02:30:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7308690351793801 -> 0.7738613313664023 on epoch=164, global_step=2300
06/23/2022 02:30:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=164
06/23/2022 02:30:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=165
06/23/2022 02:30:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/23/2022 02:30:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/23/2022 02:30:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=167
06/23/2022 02:30:58 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.7649607195246141 on epoch=167
06/23/2022 02:31:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=168
06/23/2022 02:31:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
06/23/2022 02:31:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=169
06/23/2022 02:31:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
06/23/2022 02:31:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.22 on epoch=171
06/23/2022 02:31:19 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.7816721480007485 on epoch=171
06/23/2022 02:31:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7738613313664023 -> 0.7816721480007485 on epoch=171, global_step=2400
06/23/2022 02:31:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=172
06/23/2022 02:31:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/23/2022 02:31:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=173
06/23/2022 02:31:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=174
06/23/2022 02:31:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/23/2022 02:31:39 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.7237141530244978 on epoch=174
06/23/2022 02:31:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=175
06/23/2022 02:31:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=176
06/23/2022 02:31:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=177
06/23/2022 02:31:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/23/2022 02:31:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=178
06/23/2022 02:31:59 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7378543630850116 on epoch=178
06/23/2022 02:32:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/23/2022 02:32:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
06/23/2022 02:32:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=180
06/23/2022 02:32:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/23/2022 02:32:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=182
06/23/2022 02:32:19 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.725655020323009 on epoch=182
06/23/2022 02:32:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=182
06/23/2022 02:32:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/23/2022 02:32:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=184
06/23/2022 02:32:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
06/23/2022 02:32:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/23/2022 02:32:40 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7351310515381706 on epoch=185
06/23/2022 02:32:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/23/2022 02:32:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=187
06/23/2022 02:32:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/23/2022 02:32:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=188
06/23/2022 02:32:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
06/23/2022 02:33:00 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.7412381883349624 on epoch=189
06/23/2022 02:33:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.12 on epoch=189
06/23/2022 02:33:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/23/2022 02:33:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=191
06/23/2022 02:33:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=192
06/23/2022 02:33:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/23/2022 02:33:21 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.8390896549741345 on epoch=192
06/23/2022 02:33:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7816721480007485 -> 0.8390896549741345 on epoch=192, global_step=2700
06/23/2022 02:33:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=193
06/23/2022 02:33:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/23/2022 02:33:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
06/23/2022 02:33:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=195
06/23/2022 02:33:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=196
06/23/2022 02:33:40 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.7427102032705482 on epoch=196
06/23/2022 02:33:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/23/2022 02:33:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/23/2022 02:33:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=198
06/23/2022 02:33:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/23/2022 02:33:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
06/23/2022 02:34:01 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.8023559550223164 on epoch=199
06/23/2022 02:34:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/23/2022 02:34:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
06/23/2022 02:34:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=202
06/23/2022 02:34:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
06/23/2022 02:34:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=203
06/23/2022 02:34:21 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.7519057838301442 on epoch=203
06/23/2022 02:34:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/23/2022 02:34:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=204
06/23/2022 02:34:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/23/2022 02:34:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=206
06/23/2022 02:34:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/23/2022 02:34:41 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7577806241877432 on epoch=207
06/23/2022 02:34:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/23/2022 02:34:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=208
06/23/2022 02:34:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=209
06/23/2022 02:34:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
06/23/2022 02:34:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=210
06/23/2022 02:35:00 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.7462920875420875 on epoch=210
06/23/2022 02:35:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/23/2022 02:35:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/23/2022 02:35:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=212
06/23/2022 02:35:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/23/2022 02:35:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/23/2022 02:35:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:35:14 - INFO - __main__ - Printing 3 examples
06/23/2022 02:35:14 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 02:35:14 - INFO - __main__ - ['Film']
06/23/2022 02:35:14 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 02:35:14 - INFO - __main__ - ['Film']
06/23/2022 02:35:14 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 02:35:14 - INFO - __main__ - ['Film']
06/23/2022 02:35:14 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:35:15 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:35:15 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 02:35:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:35:15 - INFO - __main__ - Printing 3 examples
06/23/2022 02:35:15 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 02:35:15 - INFO - __main__ - ['Film']
06/23/2022 02:35:15 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 02:35:15 - INFO - __main__ - ['Film']
06/23/2022 02:35:15 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 02:35:15 - INFO - __main__ - ['Film']
06/23/2022 02:35:15 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:35:15 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:35:15 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 02:35:20 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.6998223521543206 on epoch=214
06/23/2022 02:35:20 - INFO - __main__ - save last model!
06/23/2022 02:35:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 02:35:20 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 02:35:20 - INFO - __main__ - Printing 3 examples
06/23/2022 02:35:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 02:35:20 - INFO - __main__ - ['Animal']
06/23/2022 02:35:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 02:35:20 - INFO - __main__ - ['Animal']
06/23/2022 02:35:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 02:35:20 - INFO - __main__ - ['Village']
06/23/2022 02:35:20 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:35:22 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:35:26 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 02:35:30 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 02:35:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 02:35:31 - INFO - __main__ - Starting training!
06/23/2022 02:37:36 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/23/2022 02:37:36 - INFO - __main__ - Classification-F1 on test data: 0.4342
06/23/2022 02:37:36 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.8390896549741345, test_performance=0.43416443233005203
06/23/2022 02:37:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/23/2022 02:37:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:37:37 - INFO - __main__ - Printing 3 examples
06/23/2022 02:37:37 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 02:37:37 - INFO - __main__ - ['Film']
06/23/2022 02:37:37 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 02:37:37 - INFO - __main__ - ['Film']
06/23/2022 02:37:37 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 02:37:37 - INFO - __main__ - ['Film']
06/23/2022 02:37:37 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:37:37 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:37:37 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 02:37:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:37:37 - INFO - __main__ - Printing 3 examples
06/23/2022 02:37:37 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 02:37:37 - INFO - __main__ - ['Film']
06/23/2022 02:37:37 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 02:37:37 - INFO - __main__ - ['Film']
06/23/2022 02:37:37 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 02:37:37 - INFO - __main__ - ['Film']
06/23/2022 02:37:37 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:37:37 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:37:38 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 02:37:53 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 02:37:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 02:37:54 - INFO - __main__ - Starting training!
06/23/2022 02:37:57 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=0
06/23/2022 02:38:00 - INFO - __main__ - Step 20 Global step 20 Train loss 4.75 on epoch=1
06/23/2022 02:38:03 - INFO - __main__ - Step 30 Global step 30 Train loss 4.19 on epoch=2
06/23/2022 02:38:05 - INFO - __main__ - Step 40 Global step 40 Train loss 3.45 on epoch=2
06/23/2022 02:38:08 - INFO - __main__ - Step 50 Global step 50 Train loss 3.42 on epoch=3
06/23/2022 02:38:13 - INFO - __main__ - Global step 50 Train loss 4.55 Classification-F1 0.056532235353866846 on epoch=3
06/23/2022 02:38:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.056532235353866846 on epoch=3, global_step=50
06/23/2022 02:38:16 - INFO - __main__ - Step 60 Global step 60 Train loss 3.07 on epoch=4
06/23/2022 02:38:19 - INFO - __main__ - Step 70 Global step 70 Train loss 2.52 on epoch=4
06/23/2022 02:38:21 - INFO - __main__ - Step 80 Global step 80 Train loss 2.77 on epoch=5
06/23/2022 02:38:24 - INFO - __main__ - Step 90 Global step 90 Train loss 2.23 on epoch=6
06/23/2022 02:38:26 - INFO - __main__ - Step 100 Global step 100 Train loss 2.11 on epoch=7
06/23/2022 02:38:32 - INFO - __main__ - Global step 100 Train loss 2.54 Classification-F1 0.1100615149384969 on epoch=7
06/23/2022 02:38:32 - INFO - __main__ - Saving model with best Classification-F1: 0.056532235353866846 -> 0.1100615149384969 on epoch=7, global_step=100
06/23/2022 02:38:35 - INFO - __main__ - Step 110 Global step 110 Train loss 1.87 on epoch=7
06/23/2022 02:38:37 - INFO - __main__ - Step 120 Global step 120 Train loss 1.98 on epoch=8
06/23/2022 02:38:40 - INFO - __main__ - Step 130 Global step 130 Train loss 1.67 on epoch=9
06/23/2022 02:38:42 - INFO - __main__ - Step 140 Global step 140 Train loss 1.36 on epoch=9
06/23/2022 02:38:45 - INFO - __main__ - Step 150 Global step 150 Train loss 1.52 on epoch=10
06/23/2022 02:38:51 - INFO - __main__ - Global step 150 Train loss 1.68 Classification-F1 0.1433356416896716 on epoch=10
06/23/2022 02:38:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1100615149384969 -> 0.1433356416896716 on epoch=10, global_step=150
06/23/2022 02:38:54 - INFO - __main__ - Step 160 Global step 160 Train loss 1.26 on epoch=11
06/23/2022 02:38:56 - INFO - __main__ - Step 170 Global step 170 Train loss 1.15 on epoch=12
06/23/2022 02:38:59 - INFO - __main__ - Step 180 Global step 180 Train loss 1.00 on epoch=12
06/23/2022 02:39:01 - INFO - __main__ - Step 190 Global step 190 Train loss 1.10 on epoch=13
06/23/2022 02:39:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=14
06/23/2022 02:39:10 - INFO - __main__ - Global step 200 Train loss 1.09 Classification-F1 0.2999043039096233 on epoch=14
06/23/2022 02:39:10 - INFO - __main__ - Saving model with best Classification-F1: 0.1433356416896716 -> 0.2999043039096233 on epoch=14, global_step=200
06/23/2022 02:39:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.81 on epoch=14
06/23/2022 02:39:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=15
06/23/2022 02:39:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.71 on epoch=16
06/23/2022 02:39:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=17
06/23/2022 02:39:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=17
06/23/2022 02:39:30 - INFO - __main__ - Global step 250 Train loss 0.69 Classification-F1 0.5050892487631224 on epoch=17
06/23/2022 02:39:30 - INFO - __main__ - Saving model with best Classification-F1: 0.2999043039096233 -> 0.5050892487631224 on epoch=17, global_step=250
06/23/2022 02:39:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=18
06/23/2022 02:39:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=19
06/23/2022 02:39:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=19
06/23/2022 02:39:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=20
06/23/2022 02:39:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=21
06/23/2022 02:39:49 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.5578351845279076 on epoch=21
06/23/2022 02:39:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5050892487631224 -> 0.5578351845279076 on epoch=21, global_step=300
06/23/2022 02:39:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=22
06/23/2022 02:39:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/23/2022 02:39:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=23
06/23/2022 02:40:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
06/23/2022 02:40:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/23/2022 02:40:10 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6991600577738599 on epoch=24
06/23/2022 02:40:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5578351845279076 -> 0.6991600577738599 on epoch=24, global_step=350
06/23/2022 02:40:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
06/23/2022 02:40:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/23/2022 02:40:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
06/23/2022 02:40:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=27
06/23/2022 02:40:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=28
06/23/2022 02:40:30 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.6312089109753182 on epoch=28
06/23/2022 02:40:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
06/23/2022 02:40:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
06/23/2022 02:40:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
06/23/2022 02:40:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=31
06/23/2022 02:40:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
06/23/2022 02:40:50 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.6237678920541825 on epoch=32
06/23/2022 02:40:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
06/23/2022 02:40:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/23/2022 02:40:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
06/23/2022 02:41:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/23/2022 02:41:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=35
06/23/2022 02:41:11 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.7038436228189551 on epoch=35
06/23/2022 02:41:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6991600577738599 -> 0.7038436228189551 on epoch=35, global_step=500
06/23/2022 02:41:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
06/23/2022 02:41:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
06/23/2022 02:41:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
06/23/2022 02:41:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/23/2022 02:41:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
06/23/2022 02:41:31 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.7338653426434963 on epoch=39
06/23/2022 02:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7038436228189551 -> 0.7338653426434963 on epoch=39, global_step=550
06/23/2022 02:41:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/23/2022 02:41:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/23/2022 02:41:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/23/2022 02:41:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/23/2022 02:41:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=42
06/23/2022 02:41:51 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6895855637791122 on epoch=42
06/23/2022 02:41:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
06/23/2022 02:41:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
06/23/2022 02:41:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=44
06/23/2022 02:42:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/23/2022 02:42:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/23/2022 02:42:11 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6586022586222327 on epoch=46
06/23/2022 02:42:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
06/23/2022 02:42:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/23/2022 02:42:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/23/2022 02:42:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/23/2022 02:42:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
06/23/2022 02:42:31 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6885690582327508 on epoch=49
06/23/2022 02:42:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
06/23/2022 02:42:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=51
06/23/2022 02:42:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=52
06/23/2022 02:42:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/23/2022 02:42:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/23/2022 02:42:51 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.8167340130487167 on epoch=53
06/23/2022 02:42:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7338653426434963 -> 0.8167340130487167 on epoch=53, global_step=750
06/23/2022 02:42:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/23/2022 02:42:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/23/2022 02:42:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/23/2022 02:43:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=56
06/23/2022 02:43:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=57
06/23/2022 02:43:11 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.6690557009268266 on epoch=57
06/23/2022 02:43:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/23/2022 02:43:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
06/23/2022 02:43:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=59
06/23/2022 02:43:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
06/23/2022 02:43:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/23/2022 02:43:32 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7590320462187037 on epoch=60
06/23/2022 02:43:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/23/2022 02:43:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
06/23/2022 02:43:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/23/2022 02:43:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
06/23/2022 02:43:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/23/2022 02:43:52 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6501307996574152 on epoch=64
06/23/2022 02:43:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/23/2022 02:43:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/23/2022 02:44:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/23/2022 02:44:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/23/2022 02:44:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
06/23/2022 02:44:13 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7516662970173407 on epoch=67
06/23/2022 02:44:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/23/2022 02:44:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/23/2022 02:44:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/23/2022 02:44:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/23/2022 02:44:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/23/2022 02:44:33 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6485178964316086 on epoch=71
06/23/2022 02:44:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/23/2022 02:44:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/23/2022 02:44:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/23/2022 02:44:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/23/2022 02:44:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/23/2022 02:44:53 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6299306428338687 on epoch=74
06/23/2022 02:44:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/23/2022 02:44:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
06/23/2022 02:45:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/23/2022 02:45:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
06/23/2022 02:45:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/23/2022 02:45:13 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.6741311376795249 on epoch=78
06/23/2022 02:45:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/23/2022 02:45:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/23/2022 02:45:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/23/2022 02:45:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/23/2022 02:45:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=82
06/23/2022 02:45:33 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6684340175953079 on epoch=82
06/23/2022 02:45:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/23/2022 02:45:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/23/2022 02:45:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=84
06/23/2022 02:45:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/23/2022 02:45:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/23/2022 02:45:53 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8009660169052959 on epoch=85
06/23/2022 02:45:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/23/2022 02:45:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/23/2022 02:46:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/23/2022 02:46:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/23/2022 02:46:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/23/2022 02:46:13 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7149560117302054 on epoch=89
06/23/2022 02:46:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/23/2022 02:46:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/23/2022 02:46:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/23/2022 02:46:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/23/2022 02:46:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/23/2022 02:46:33 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8066701167270428 on epoch=92
06/23/2022 02:46:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/23/2022 02:46:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=94
06/23/2022 02:46:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
06/23/2022 02:46:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/23/2022 02:46:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/23/2022 02:46:53 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7599469153904638 on epoch=96
06/23/2022 02:46:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/23/2022 02:46:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/23/2022 02:47:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/23/2022 02:47:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/23/2022 02:47:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/23/2022 02:47:12 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=99
06/23/2022 02:47:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8167340130487167 -> 0.8591069464809384 on epoch=99, global_step=1400
06/23/2022 02:47:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/23/2022 02:47:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/23/2022 02:47:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/23/2022 02:47:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/23/2022 02:47:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/23/2022 02:47:32 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7581514065385034 on epoch=103
06/23/2022 02:47:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/23/2022 02:47:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/23/2022 02:47:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/23/2022 02:47:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/23/2022 02:47:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/23/2022 02:47:52 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7213033088333128 on epoch=107
06/23/2022 02:47:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/23/2022 02:47:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/23/2022 02:48:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
06/23/2022 02:48:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/23/2022 02:48:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/23/2022 02:48:12 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9101857282502444 on epoch=110
06/23/2022 02:48:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8591069464809384 -> 0.9101857282502444 on epoch=110, global_step=1550
06/23/2022 02:48:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/23/2022 02:48:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/23/2022 02:48:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/23/2022 02:48:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/23/2022 02:48:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/23/2022 02:48:32 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=114
06/23/2022 02:48:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/23/2022 02:48:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/23/2022 02:48:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/23/2022 02:48:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/23/2022 02:48:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/23/2022 02:48:53 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8569525904203323 on epoch=117
06/23/2022 02:48:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/23/2022 02:48:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/23/2022 02:49:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/23/2022 02:49:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/23/2022 02:49:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/23/2022 02:49:13 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7503964374932117 on epoch=121
06/23/2022 02:49:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/23/2022 02:49:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/23/2022 02:49:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/23/2022 02:49:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/23/2022 02:49:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/23/2022 02:49:33 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8530425219941349 on epoch=124
06/23/2022 02:49:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/23/2022 02:49:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/23/2022 02:49:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/23/2022 02:49:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/23/2022 02:49:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/23/2022 02:49:54 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7932104581060938 on epoch=128
06/23/2022 02:49:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/23/2022 02:49:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/23/2022 02:50:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/23/2022 02:50:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/23/2022 02:50:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/23/2022 02:50:14 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7957653703384253 on epoch=132
06/23/2022 02:50:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/23/2022 02:50:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/23/2022 02:50:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/23/2022 02:50:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/23/2022 02:50:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/23/2022 02:50:34 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8007245126789719 on epoch=135
06/23/2022 02:50:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/23/2022 02:50:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/23/2022 02:50:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/23/2022 02:50:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/23/2022 02:50:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/23/2022 02:50:55 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7970444482778449 on epoch=139
06/23/2022 02:50:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/23/2022 02:51:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/23/2022 02:51:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/23/2022 02:51:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/23/2022 02:51:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/23/2022 02:51:15 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7522765661809044 on epoch=142
06/23/2022 02:51:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/23/2022 02:51:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/23/2022 02:51:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/23/2022 02:51:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/23/2022 02:51:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/23/2022 02:51:36 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.799183485711 on epoch=146
06/23/2022 02:51:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/23/2022 02:51:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/23/2022 02:51:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/23/2022 02:51:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/23/2022 02:51:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/23/2022 02:51:56 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7464081676984902 on epoch=149
06/23/2022 02:51:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/23/2022 02:52:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/23/2022 02:52:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/23/2022 02:52:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/23/2022 02:52:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/23/2022 02:52:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8006999260418093 on epoch=153
06/23/2022 02:52:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/23/2022 02:52:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/23/2022 02:52:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/23/2022 02:52:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/23/2022 02:52:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/23/2022 02:52:37 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9101857282502444 on epoch=157
06/23/2022 02:52:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/23/2022 02:52:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/23/2022 02:52:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/23/2022 02:52:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/23/2022 02:52:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/23/2022 02:52:57 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9060190615835777 on epoch=160
06/23/2022 02:53:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/23/2022 02:53:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/23/2022 02:53:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/23/2022 02:53:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/23/2022 02:53:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/23/2022 02:53:18 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9101898012381883 on epoch=164
06/23/2022 02:53:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9101857282502444 -> 0.9101898012381883 on epoch=164, global_step=2300
06/23/2022 02:53:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/23/2022 02:53:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/23/2022 02:53:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/23/2022 02:53:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/23/2022 02:53:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/23/2022 02:53:38 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8511608015640274 on epoch=167
06/23/2022 02:53:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/23/2022 02:53:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/23/2022 02:53:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/23/2022 02:53:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/23/2022 02:53:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/23/2022 02:53:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8448022407699827 on epoch=171
06/23/2022 02:54:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/23/2022 02:54:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/23/2022 02:54:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/23/2022 02:54:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/23/2022 02:54:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/23/2022 02:54:19 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7500589613492838 on epoch=174
06/23/2022 02:54:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/23/2022 02:54:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/23/2022 02:54:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/23/2022 02:54:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/23/2022 02:54:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/23/2022 02:54:39 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7915345740772686 on epoch=178
06/23/2022 02:54:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/23/2022 02:54:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/23/2022 02:54:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/23/2022 02:54:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/23/2022 02:54:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/23/2022 02:55:00 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7516756574104245 on epoch=182
06/23/2022 02:55:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/23/2022 02:55:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/23/2022 02:55:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/23/2022 02:55:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/23/2022 02:55:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/23/2022 02:55:20 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8020618217961671 on epoch=185
06/23/2022 02:55:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/23/2022 02:55:25 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/23/2022 02:55:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/23/2022 02:55:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/23/2022 02:55:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/23/2022 02:55:40 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8591069464809384 on epoch=189
06/23/2022 02:55:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/23/2022 02:55:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/23/2022 02:55:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/23/2022 02:55:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/23/2022 02:55:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/23/2022 02:56:01 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8065551147145075 on epoch=192
06/23/2022 02:56:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/23/2022 02:56:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/23/2022 02:56:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/23/2022 02:56:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/23/2022 02:56:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/23/2022 02:56:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7969971696726915 on epoch=196
06/23/2022 02:56:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/23/2022 02:56:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/23/2022 02:56:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/23/2022 02:56:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/23/2022 02:56:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/23/2022 02:56:42 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.859103128054741 on epoch=199
06/23/2022 02:56:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/23/2022 02:56:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/23/2022 02:56:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/23/2022 02:56:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/23/2022 02:56:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/23/2022 02:57:03 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8551930596285435 on epoch=203
06/23/2022 02:57:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/23/2022 02:57:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/23/2022 02:57:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/23/2022 02:57:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/23/2022 02:57:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/23/2022 02:57:23 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7968905225072208 on epoch=207
06/23/2022 02:57:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/23/2022 02:57:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/23/2022 02:57:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/23/2022 02:57:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/23/2022 02:57:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/23/2022 02:57:44 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7932104581060938 on epoch=210
06/23/2022 02:57:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/23/2022 02:57:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/23/2022 02:57:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/23/2022 02:57:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/23/2022 02:57:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/23/2022 02:57:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:57:58 - INFO - __main__ - Printing 3 examples
06/23/2022 02:57:58 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 02:57:58 - INFO - __main__ - ['Film']
06/23/2022 02:57:58 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 02:57:58 - INFO - __main__ - ['Film']
06/23/2022 02:57:58 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 02:57:58 - INFO - __main__ - ['Film']
06/23/2022 02:57:58 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:57:58 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:57:58 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 02:57:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 02:57:58 - INFO - __main__ - Printing 3 examples
06/23/2022 02:57:58 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 02:57:58 - INFO - __main__ - ['Film']
06/23/2022 02:57:58 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 02:57:58 - INFO - __main__ - ['Film']
06/23/2022 02:57:58 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 02:57:58 - INFO - __main__ - ['Film']
06/23/2022 02:57:58 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:57:58 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:57:59 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 02:58:04 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7464081676984904 on epoch=214
06/23/2022 02:58:04 - INFO - __main__ - save last model!
06/23/2022 02:58:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 02:58:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 02:58:04 - INFO - __main__ - Printing 3 examples
06/23/2022 02:58:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 02:58:04 - INFO - __main__ - ['Animal']
06/23/2022 02:58:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 02:58:04 - INFO - __main__ - ['Animal']
06/23/2022 02:58:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 02:58:04 - INFO - __main__ - ['Village']
06/23/2022 02:58:04 - INFO - __main__ - Tokenizing Input ...
06/23/2022 02:58:06 - INFO - __main__ - Tokenizing Output ...
06/23/2022 02:58:09 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 02:58:14 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 02:58:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 02:58:15 - INFO - __main__ - Starting training!
06/23/2022 03:00:32 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/23/2022 03:00:32 - INFO - __main__ - Classification-F1 on test data: 0.4566
06/23/2022 03:00:33 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9101898012381883, test_performance=0.4565835269392464
06/23/2022 03:00:33 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/23/2022 03:00:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:00:34 - INFO - __main__ - Printing 3 examples
06/23/2022 03:00:34 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 03:00:34 - INFO - __main__ - ['Film']
06/23/2022 03:00:34 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 03:00:34 - INFO - __main__ - ['Film']
06/23/2022 03:00:34 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 03:00:34 - INFO - __main__ - ['Film']
06/23/2022 03:00:34 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:00:34 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:00:34 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 03:00:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:00:34 - INFO - __main__ - Printing 3 examples
06/23/2022 03:00:34 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 03:00:34 - INFO - __main__ - ['Film']
06/23/2022 03:00:34 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 03:00:34 - INFO - __main__ - ['Film']
06/23/2022 03:00:34 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 03:00:34 - INFO - __main__ - ['Film']
06/23/2022 03:00:34 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:00:34 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:00:34 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 03:00:50 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 03:00:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 03:00:50 - INFO - __main__ - Starting training!
06/23/2022 03:00:54 - INFO - __main__ - Step 10 Global step 10 Train loss 6.98 on epoch=0
06/23/2022 03:00:57 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/23/2022 03:00:59 - INFO - __main__ - Step 30 Global step 30 Train loss 4.28 on epoch=2
06/23/2022 03:01:02 - INFO - __main__ - Step 40 Global step 40 Train loss 3.69 on epoch=2
06/23/2022 03:01:04 - INFO - __main__ - Step 50 Global step 50 Train loss 3.56 on epoch=3
06/23/2022 03:01:09 - INFO - __main__ - Global step 50 Train loss 4.67 Classification-F1 0.05455591626699621 on epoch=3
06/23/2022 03:01:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05455591626699621 on epoch=3, global_step=50
06/23/2022 03:01:12 - INFO - __main__ - Step 60 Global step 60 Train loss 3.30 on epoch=4
06/23/2022 03:01:15 - INFO - __main__ - Step 70 Global step 70 Train loss 2.75 on epoch=4
06/23/2022 03:01:18 - INFO - __main__ - Step 80 Global step 80 Train loss 2.88 on epoch=5
06/23/2022 03:01:20 - INFO - __main__ - Step 90 Global step 90 Train loss 2.47 on epoch=6
06/23/2022 03:01:23 - INFO - __main__ - Step 100 Global step 100 Train loss 2.35 on epoch=7
06/23/2022 03:01:28 - INFO - __main__ - Global step 100 Train loss 2.75 Classification-F1 0.09062398175301402 on epoch=7
06/23/2022 03:01:28 - INFO - __main__ - Saving model with best Classification-F1: 0.05455591626699621 -> 0.09062398175301402 on epoch=7, global_step=100
06/23/2022 03:01:31 - INFO - __main__ - Step 110 Global step 110 Train loss 2.03 on epoch=7
06/23/2022 03:01:34 - INFO - __main__ - Step 120 Global step 120 Train loss 2.21 on epoch=8
06/23/2022 03:01:36 - INFO - __main__ - Step 130 Global step 130 Train loss 1.95 on epoch=9
06/23/2022 03:01:39 - INFO - __main__ - Step 140 Global step 140 Train loss 1.63 on epoch=9
06/23/2022 03:01:42 - INFO - __main__ - Step 150 Global step 150 Train loss 1.84 on epoch=10
06/23/2022 03:01:47 - INFO - __main__ - Global step 150 Train loss 1.93 Classification-F1 0.1322176504769323 on epoch=10
06/23/2022 03:01:48 - INFO - __main__ - Saving model with best Classification-F1: 0.09062398175301402 -> 0.1322176504769323 on epoch=10, global_step=150
06/23/2022 03:01:50 - INFO - __main__ - Step 160 Global step 160 Train loss 1.58 on epoch=11
06/23/2022 03:01:53 - INFO - __main__ - Step 170 Global step 170 Train loss 1.53 on epoch=12
06/23/2022 03:01:55 - INFO - __main__ - Step 180 Global step 180 Train loss 1.32 on epoch=12
06/23/2022 03:01:58 - INFO - __main__ - Step 190 Global step 190 Train loss 1.33 on epoch=13
06/23/2022 03:02:00 - INFO - __main__ - Step 200 Global step 200 Train loss 1.30 on epoch=14
06/23/2022 03:02:06 - INFO - __main__ - Global step 200 Train loss 1.41 Classification-F1 0.1804386941850848 on epoch=14
06/23/2022 03:02:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1322176504769323 -> 0.1804386941850848 on epoch=14, global_step=200
06/23/2022 03:02:09 - INFO - __main__ - Step 210 Global step 210 Train loss 1.00 on epoch=14
06/23/2022 03:02:12 - INFO - __main__ - Step 220 Global step 220 Train loss 1.17 on epoch=15
06/23/2022 03:02:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.96 on epoch=16
06/23/2022 03:02:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.92 on epoch=17
06/23/2022 03:02:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.84 on epoch=17
06/23/2022 03:02:26 - INFO - __main__ - Global step 250 Train loss 0.98 Classification-F1 0.3012524731562308 on epoch=17
06/23/2022 03:02:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1804386941850848 -> 0.3012524731562308 on epoch=17, global_step=250
06/23/2022 03:02:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.88 on epoch=18
06/23/2022 03:02:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=19
06/23/2022 03:02:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.72 on epoch=19
06/23/2022 03:02:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=20
06/23/2022 03:02:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=21
06/23/2022 03:02:46 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.41108463460982153 on epoch=21
06/23/2022 03:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.3012524731562308 -> 0.41108463460982153 on epoch=21, global_step=300
06/23/2022 03:02:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=22
06/23/2022 03:02:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
06/23/2022 03:02:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.68 on epoch=23
06/23/2022 03:02:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
06/23/2022 03:02:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=24
06/23/2022 03:03:06 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.46461001974317423 on epoch=24
06/23/2022 03:03:06 - INFO - __main__ - Saving model with best Classification-F1: 0.41108463460982153 -> 0.46461001974317423 on epoch=24, global_step=350
06/23/2022 03:03:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=25
06/23/2022 03:03:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/23/2022 03:03:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=27
06/23/2022 03:03:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=27
06/23/2022 03:03:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=28
06/23/2022 03:03:26 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.703277946930467 on epoch=28
06/23/2022 03:03:26 - INFO - __main__ - Saving model with best Classification-F1: 0.46461001974317423 -> 0.703277946930467 on epoch=28, global_step=400
06/23/2022 03:03:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=29
06/23/2022 03:03:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=29
06/23/2022 03:03:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=30
06/23/2022 03:03:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=31
06/23/2022 03:03:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
06/23/2022 03:03:47 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.806635612139992 on epoch=32
06/23/2022 03:03:47 - INFO - __main__ - Saving model with best Classification-F1: 0.703277946930467 -> 0.806635612139992 on epoch=32, global_step=450
06/23/2022 03:03:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=32
06/23/2022 03:03:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=33
06/23/2022 03:03:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=34
06/23/2022 03:03:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
06/23/2022 03:04:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
06/23/2022 03:04:08 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.7163749912024139 on epoch=35
06/23/2022 03:04:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
06/23/2022 03:04:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=37
06/23/2022 03:04:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/23/2022 03:04:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=38
06/23/2022 03:04:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=39
06/23/2022 03:04:28 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.8023899627478257 on epoch=39
06/23/2022 03:04:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=39
06/23/2022 03:04:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/23/2022 03:04:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=41
06/23/2022 03:04:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
06/23/2022 03:04:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
06/23/2022 03:04:49 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.8668478624123785 on epoch=42
06/23/2022 03:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.806635612139992 -> 0.8668478624123785 on epoch=42, global_step=600
06/23/2022 03:04:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=43
06/23/2022 03:04:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
06/23/2022 03:04:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=44
06/23/2022 03:04:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
06/23/2022 03:05:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=46
06/23/2022 03:05:09 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.8658567239212402 on epoch=46
06/23/2022 03:05:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/23/2022 03:05:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=47
06/23/2022 03:05:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=48
06/23/2022 03:05:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=49
06/23/2022 03:05:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=49
06/23/2022 03:05:30 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.8753990210332557 on epoch=49
06/23/2022 03:05:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8668478624123785 -> 0.8753990210332557 on epoch=49, global_step=700
06/23/2022 03:05:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/23/2022 03:05:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=51
06/23/2022 03:05:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=52
06/23/2022 03:05:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
06/23/2022 03:05:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/23/2022 03:05:50 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.8733334848863732 on epoch=53
06/23/2022 03:05:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
06/23/2022 03:05:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=54
06/23/2022 03:05:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/23/2022 03:06:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
06/23/2022 03:06:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=57
06/23/2022 03:06:10 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.839645027121308 on epoch=57
06/23/2022 03:06:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=57
06/23/2022 03:06:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
06/23/2022 03:06:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/23/2022 03:06:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=59
06/23/2022 03:06:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/23/2022 03:06:31 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.8422147609805395 on epoch=60
06/23/2022 03:06:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/23/2022 03:06:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/23/2022 03:06:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
06/23/2022 03:06:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
06/23/2022 03:06:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
06/23/2022 03:06:51 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6969974168661709 on epoch=64
06/23/2022 03:06:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
06/23/2022 03:06:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/23/2022 03:06:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/23/2022 03:07:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
06/23/2022 03:07:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/23/2022 03:07:11 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.8401520582165745 on epoch=67
06/23/2022 03:07:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
06/23/2022 03:07:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/23/2022 03:07:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
06/23/2022 03:07:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/23/2022 03:07:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
06/23/2022 03:07:31 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7813402047035825 on epoch=71
06/23/2022 03:07:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/23/2022 03:07:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/23/2022 03:07:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/23/2022 03:07:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/23/2022 03:07:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=74
06/23/2022 03:07:51 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7424417868489169 on epoch=74
06/23/2022 03:07:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=75
06/23/2022 03:07:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/23/2022 03:07:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/23/2022 03:08:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/23/2022 03:08:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/23/2022 03:08:12 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.7875602093869976 on epoch=78
06/23/2022 03:08:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
06/23/2022 03:08:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/23/2022 03:08:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
06/23/2022 03:08:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/23/2022 03:08:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/23/2022 03:08:32 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7243546762068336 on epoch=82
06/23/2022 03:08:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/23/2022 03:08:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=83
06/23/2022 03:08:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/23/2022 03:08:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=84
06/23/2022 03:08:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
06/23/2022 03:08:52 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7069693349263242 on epoch=85
06/23/2022 03:08:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
06/23/2022 03:08:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/23/2022 03:09:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/23/2022 03:09:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/23/2022 03:09:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/23/2022 03:09:13 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7874472803274057 on epoch=89
06/23/2022 03:09:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
06/23/2022 03:09:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/23/2022 03:09:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
06/23/2022 03:09:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/23/2022 03:09:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/23/2022 03:09:33 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7012296136235016 on epoch=92
06/23/2022 03:09:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/23/2022 03:09:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/23/2022 03:09:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/23/2022 03:09:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/23/2022 03:09:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/23/2022 03:09:53 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7146022059434624 on epoch=96
06/23/2022 03:09:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/23/2022 03:09:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/23/2022 03:10:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/23/2022 03:10:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/23/2022 03:10:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/23/2022 03:10:13 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7456675940546909 on epoch=99
06/23/2022 03:10:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/23/2022 03:10:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/23/2022 03:10:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/23/2022 03:10:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/23/2022 03:10:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/23/2022 03:10:33 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7562165968172643 on epoch=103
06/23/2022 03:10:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/23/2022 03:10:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/23/2022 03:10:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/23/2022 03:10:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/23/2022 03:10:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/23/2022 03:10:52 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7599435212338439 on epoch=107
06/23/2022 03:10:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/23/2022 03:10:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/23/2022 03:11:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/23/2022 03:11:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/23/2022 03:11:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/23/2022 03:11:12 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9185272075594656 on epoch=110
06/23/2022 03:11:13 - INFO - __main__ - Saving model with best Classification-F1: 0.8753990210332557 -> 0.9185272075594656 on epoch=110, global_step=1550
06/23/2022 03:11:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/23/2022 03:11:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/23/2022 03:11:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/23/2022 03:11:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/23/2022 03:11:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/23/2022 03:11:32 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7248340793332305 on epoch=114
06/23/2022 03:11:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/23/2022 03:11:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/23/2022 03:11:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/23/2022 03:11:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/23/2022 03:11:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/23/2022 03:11:52 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8103501811281698 on epoch=117
06/23/2022 03:11:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/23/2022 03:11:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
06/23/2022 03:12:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/23/2022 03:12:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/23/2022 03:12:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/23/2022 03:12:12 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8140302455292968 on epoch=121
06/23/2022 03:12:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/23/2022 03:12:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/23/2022 03:12:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/23/2022 03:12:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/23/2022 03:12:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/23/2022 03:12:31 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7598240469208212 on epoch=124
06/23/2022 03:12:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/23/2022 03:12:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/23/2022 03:12:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/23/2022 03:12:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/23/2022 03:12:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/23/2022 03:12:51 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8045195790926342 on epoch=128
06/23/2022 03:12:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/23/2022 03:12:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/23/2022 03:12:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/23/2022 03:13:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/23/2022 03:13:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/23/2022 03:13:10 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7598240469208212 on epoch=132
06/23/2022 03:13:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/23/2022 03:13:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/23/2022 03:13:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/23/2022 03:13:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/23/2022 03:13:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/23/2022 03:13:30 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=135
06/23/2022 03:13:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/23/2022 03:13:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/23/2022 03:13:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/23/2022 03:13:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/23/2022 03:13:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/23/2022 03:13:49 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=139
06/23/2022 03:13:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/23/2022 03:13:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/23/2022 03:13:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/23/2022 03:14:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/23/2022 03:14:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/23/2022 03:14:09 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.802863550112127 on epoch=142
06/23/2022 03:14:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/23/2022 03:14:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/23/2022 03:14:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/23/2022 03:14:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/23/2022 03:14:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/23/2022 03:14:29 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.802863550112127 on epoch=146
06/23/2022 03:14:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/23/2022 03:14:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/23/2022 03:14:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/23/2022 03:14:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/23/2022 03:14:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/23/2022 03:14:49 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8551930596285435 on epoch=149
06/23/2022 03:14:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/23/2022 03:14:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/23/2022 03:14:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/23/2022 03:14:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/23/2022 03:15:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/23/2022 03:15:09 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.802863550112127 on epoch=153
06/23/2022 03:15:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/23/2022 03:15:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/23/2022 03:15:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/23/2022 03:15:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/23/2022 03:15:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/23/2022 03:15:28 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8508658610577409 on epoch=157
06/23/2022 03:15:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/23/2022 03:15:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/23/2022 03:15:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/23/2022 03:15:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/23/2022 03:15:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/23/2022 03:15:48 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=160
06/23/2022 03:15:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/23/2022 03:15:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/23/2022 03:15:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/23/2022 03:15:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/23/2022 03:16:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/23/2022 03:16:08 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8025974592486403 on epoch=164
06/23/2022 03:16:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/23/2022 03:16:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/23/2022 03:16:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/23/2022 03:16:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/23/2022 03:16:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/23/2022 03:16:27 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9100423590746171 on epoch=167
06/23/2022 03:16:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/23/2022 03:16:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/23/2022 03:16:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/23/2022 03:16:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/23/2022 03:16:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/23/2022 03:16:47 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9100423590746171 on epoch=171
06/23/2022 03:16:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/23/2022 03:16:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/23/2022 03:16:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/23/2022 03:16:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/23/2022 03:17:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/23/2022 03:17:07 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9773495321882419 on epoch=174
06/23/2022 03:17:07 - INFO - __main__ - Saving model with best Classification-F1: 0.9185272075594656 -> 0.9773495321882419 on epoch=174, global_step=2450
06/23/2022 03:17:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/23/2022 03:17:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/23/2022 03:17:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/23/2022 03:17:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/23/2022 03:17:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/23/2022 03:17:26 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=178
06/23/2022 03:17:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9773495321882419 -> 0.9776304656760065 on epoch=178, global_step=2500
06/23/2022 03:17:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/23/2022 03:17:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/23/2022 03:17:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/23/2022 03:17:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/23/2022 03:17:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/23/2022 03:17:46 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9773495321882419 on epoch=182
06/23/2022 03:17:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/23/2022 03:17:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/23/2022 03:17:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/23/2022 03:17:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/23/2022 03:17:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/23/2022 03:18:06 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9685395565850976 on epoch=185
06/23/2022 03:18:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/23/2022 03:18:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/23/2022 03:18:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/23/2022 03:18:16 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/23/2022 03:18:19 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/23/2022 03:18:25 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9142130987292278 on epoch=189
06/23/2022 03:18:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/23/2022 03:18:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/23/2022 03:18:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/23/2022 03:18:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/23/2022 03:18:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/23/2022 03:18:45 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9142130987292278 on epoch=192
06/23/2022 03:18:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/23/2022 03:18:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/23/2022 03:18:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/23/2022 03:18:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/23/2022 03:18:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/23/2022 03:19:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9058797653958945 on epoch=196
06/23/2022 03:19:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/23/2022 03:19:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/23/2022 03:19:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
06/23/2022 03:19:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/23/2022 03:19:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/23/2022 03:19:24 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8469557926315435 on epoch=199
06/23/2022 03:19:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/23/2022 03:19:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/23/2022 03:19:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/23/2022 03:19:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/23/2022 03:19:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/23/2022 03:19:44 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9015181455330641 on epoch=203
06/23/2022 03:19:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/23/2022 03:19:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/23/2022 03:19:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/23/2022 03:19:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/23/2022 03:19:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/23/2022 03:20:03 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8469557926315435 on epoch=207
06/23/2022 03:20:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/23/2022 03:20:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/23/2022 03:20:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/23/2022 03:20:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/23/2022 03:20:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/23/2022 03:20:23 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9058716194200066 on epoch=210
06/23/2022 03:20:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/23/2022 03:20:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/23/2022 03:20:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/23/2022 03:20:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/23/2022 03:20:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/23/2022 03:20:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:20:38 - INFO - __main__ - Printing 3 examples
06/23/2022 03:20:38 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 03:20:38 - INFO - __main__ - ['Film']
06/23/2022 03:20:38 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 03:20:38 - INFO - __main__ - ['Film']
06/23/2022 03:20:38 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 03:20:38 - INFO - __main__ - ['Film']
06/23/2022 03:20:38 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:20:38 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:20:38 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 03:20:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:20:38 - INFO - __main__ - Printing 3 examples
06/23/2022 03:20:38 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 03:20:38 - INFO - __main__ - ['Film']
06/23/2022 03:20:38 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 03:20:38 - INFO - __main__ - ['Film']
06/23/2022 03:20:38 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 03:20:38 - INFO - __main__ - ['Film']
06/23/2022 03:20:38 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:20:38 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:20:38 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 03:20:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7948166950064485 on epoch=214
06/23/2022 03:20:43 - INFO - __main__ - save last model!
06/23/2022 03:20:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 03:20:43 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 03:20:43 - INFO - __main__ - Printing 3 examples
06/23/2022 03:20:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 03:20:43 - INFO - __main__ - ['Animal']
06/23/2022 03:20:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 03:20:43 - INFO - __main__ - ['Animal']
06/23/2022 03:20:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 03:20:43 - INFO - __main__ - ['Village']
06/23/2022 03:20:43 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:20:45 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:20:48 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 03:20:54 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 03:20:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 03:20:54 - INFO - __main__ - Starting training!
06/23/2022 03:23:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/23/2022 03:23:08 - INFO - __main__ - Classification-F1 on test data: 0.5685
06/23/2022 03:23:08 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9776304656760065, test_performance=0.5684765030959318
06/23/2022 03:23:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/23/2022 03:23:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:23:09 - INFO - __main__ - Printing 3 examples
06/23/2022 03:23:09 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 03:23:09 - INFO - __main__ - ['Film']
06/23/2022 03:23:09 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 03:23:09 - INFO - __main__ - ['Film']
06/23/2022 03:23:09 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 03:23:09 - INFO - __main__ - ['Film']
06/23/2022 03:23:09 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:23:09 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:23:09 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 03:23:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:23:09 - INFO - __main__ - Printing 3 examples
06/23/2022 03:23:09 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 03:23:09 - INFO - __main__ - ['Film']
06/23/2022 03:23:09 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 03:23:09 - INFO - __main__ - ['Film']
06/23/2022 03:23:09 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 03:23:09 - INFO - __main__ - ['Film']
06/23/2022 03:23:09 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:23:10 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:23:10 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 03:23:25 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 03:23:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 03:23:26 - INFO - __main__ - Starting training!
06/23/2022 03:23:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.27 on epoch=0
06/23/2022 03:23:32 - INFO - __main__ - Step 20 Global step 20 Train loss 5.73 on epoch=1
06/23/2022 03:23:35 - INFO - __main__ - Step 30 Global step 30 Train loss 4.98 on epoch=2
06/23/2022 03:23:37 - INFO - __main__ - Step 40 Global step 40 Train loss 4.14 on epoch=2
06/23/2022 03:23:40 - INFO - __main__ - Step 50 Global step 50 Train loss 4.16 on epoch=3
06/23/2022 03:23:45 - INFO - __main__ - Global step 50 Train loss 5.26 Classification-F1 0.06493845275943588 on epoch=3
06/23/2022 03:23:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06493845275943588 on epoch=3, global_step=50
06/23/2022 03:23:48 - INFO - __main__ - Step 60 Global step 60 Train loss 3.78 on epoch=4
06/23/2022 03:23:51 - INFO - __main__ - Step 70 Global step 70 Train loss 3.13 on epoch=4
06/23/2022 03:23:53 - INFO - __main__ - Step 80 Global step 80 Train loss 3.37 on epoch=5
06/23/2022 03:23:56 - INFO - __main__ - Step 90 Global step 90 Train loss 2.89 on epoch=6
06/23/2022 03:23:58 - INFO - __main__ - Step 100 Global step 100 Train loss 2.64 on epoch=7
06/23/2022 03:24:03 - INFO - __main__ - Global step 100 Train loss 3.16 Classification-F1 0.0724668045167789 on epoch=7
06/23/2022 03:24:03 - INFO - __main__ - Saving model with best Classification-F1: 0.06493845275943588 -> 0.0724668045167789 on epoch=7, global_step=100
06/23/2022 03:24:06 - INFO - __main__ - Step 110 Global step 110 Train loss 2.53 on epoch=7
06/23/2022 03:24:08 - INFO - __main__ - Step 120 Global step 120 Train loss 2.63 on epoch=8
06/23/2022 03:24:11 - INFO - __main__ - Step 130 Global step 130 Train loss 2.50 on epoch=9
06/23/2022 03:24:13 - INFO - __main__ - Step 140 Global step 140 Train loss 2.02 on epoch=9
06/23/2022 03:24:16 - INFO - __main__ - Step 150 Global step 150 Train loss 2.42 on epoch=10
06/23/2022 03:24:22 - INFO - __main__ - Global step 150 Train loss 2.42 Classification-F1 0.11936476009056654 on epoch=10
06/23/2022 03:24:22 - INFO - __main__ - Saving model with best Classification-F1: 0.0724668045167789 -> 0.11936476009056654 on epoch=10, global_step=150
06/23/2022 03:24:24 - INFO - __main__ - Step 160 Global step 160 Train loss 2.08 on epoch=11
06/23/2022 03:24:27 - INFO - __main__ - Step 170 Global step 170 Train loss 2.03 on epoch=12
06/23/2022 03:24:29 - INFO - __main__ - Step 180 Global step 180 Train loss 1.64 on epoch=12
06/23/2022 03:24:32 - INFO - __main__ - Step 190 Global step 190 Train loss 1.85 on epoch=13
06/23/2022 03:24:35 - INFO - __main__ - Step 200 Global step 200 Train loss 1.77 on epoch=14
06/23/2022 03:24:40 - INFO - __main__ - Global step 200 Train loss 1.87 Classification-F1 0.12407047066961853 on epoch=14
06/23/2022 03:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.11936476009056654 -> 0.12407047066961853 on epoch=14, global_step=200
06/23/2022 03:24:43 - INFO - __main__ - Step 210 Global step 210 Train loss 1.50 on epoch=14
06/23/2022 03:24:45 - INFO - __main__ - Step 220 Global step 220 Train loss 1.63 on epoch=15
06/23/2022 03:24:48 - INFO - __main__ - Step 230 Global step 230 Train loss 1.42 on epoch=16
06/23/2022 03:24:51 - INFO - __main__ - Step 240 Global step 240 Train loss 1.38 on epoch=17
06/23/2022 03:24:53 - INFO - __main__ - Step 250 Global step 250 Train loss 1.27 on epoch=17
06/23/2022 03:24:59 - INFO - __main__ - Global step 250 Train loss 1.44 Classification-F1 0.15785830465043432 on epoch=17
06/23/2022 03:24:59 - INFO - __main__ - Saving model with best Classification-F1: 0.12407047066961853 -> 0.15785830465043432 on epoch=17, global_step=250
06/23/2022 03:25:02 - INFO - __main__ - Step 260 Global step 260 Train loss 1.20 on epoch=18
06/23/2022 03:25:04 - INFO - __main__ - Step 270 Global step 270 Train loss 1.13 on epoch=19
06/23/2022 03:25:07 - INFO - __main__ - Step 280 Global step 280 Train loss 1.01 on epoch=19
06/23/2022 03:25:09 - INFO - __main__ - Step 290 Global step 290 Train loss 1.19 on epoch=20
06/23/2022 03:25:12 - INFO - __main__ - Step 300 Global step 300 Train loss 1.00 on epoch=21
06/23/2022 03:25:18 - INFO - __main__ - Global step 300 Train loss 1.11 Classification-F1 0.25438952149218075 on epoch=21
06/23/2022 03:25:18 - INFO - __main__ - Saving model with best Classification-F1: 0.15785830465043432 -> 0.25438952149218075 on epoch=21, global_step=300
06/23/2022 03:25:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.96 on epoch=22
06/23/2022 03:25:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.83 on epoch=22
06/23/2022 03:25:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.92 on epoch=23
06/23/2022 03:25:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.83 on epoch=24
06/23/2022 03:25:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=24
06/23/2022 03:25:39 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.3107318433161554 on epoch=24
06/23/2022 03:25:39 - INFO - __main__ - Saving model with best Classification-F1: 0.25438952149218075 -> 0.3107318433161554 on epoch=24, global_step=350
06/23/2022 03:25:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.78 on epoch=25
06/23/2022 03:25:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=26
06/23/2022 03:25:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.65 on epoch=27
06/23/2022 03:25:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.67 on epoch=27
06/23/2022 03:25:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.73 on epoch=28
06/23/2022 03:25:59 - INFO - __main__ - Global step 400 Train loss 0.69 Classification-F1 0.453976620055239 on epoch=28
06/23/2022 03:25:59 - INFO - __main__ - Saving model with best Classification-F1: 0.3107318433161554 -> 0.453976620055239 on epoch=28, global_step=400
06/23/2022 03:26:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=29
06/23/2022 03:26:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=29
06/23/2022 03:26:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=30
06/23/2022 03:26:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=31
06/23/2022 03:26:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=32
06/23/2022 03:26:19 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.47225864572134874 on epoch=32
06/23/2022 03:26:19 - INFO - __main__ - Saving model with best Classification-F1: 0.453976620055239 -> 0.47225864572134874 on epoch=32, global_step=450
06/23/2022 03:26:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=32
06/23/2022 03:26:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=33
06/23/2022 03:26:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.53 on epoch=34
06/23/2022 03:26:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=34
06/23/2022 03:26:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=35
06/23/2022 03:26:39 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.5407290331451235 on epoch=35
06/23/2022 03:26:39 - INFO - __main__ - Saving model with best Classification-F1: 0.47225864572134874 -> 0.5407290331451235 on epoch=35, global_step=500
06/23/2022 03:26:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=36
06/23/2022 03:26:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=37
06/23/2022 03:26:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=37
06/23/2022 03:26:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.45 on epoch=38
06/23/2022 03:26:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
06/23/2022 03:27:00 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.5730489543269294 on epoch=39
06/23/2022 03:27:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5407290331451235 -> 0.5730489543269294 on epoch=39, global_step=550
06/23/2022 03:27:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=39
06/23/2022 03:27:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
06/23/2022 03:27:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=41
06/23/2022 03:27:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.45 on epoch=42
06/23/2022 03:27:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=42
06/23/2022 03:27:20 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.6747513475592278 on epoch=42
06/23/2022 03:27:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5730489543269294 -> 0.6747513475592278 on epoch=42, global_step=600
06/23/2022 03:27:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
06/23/2022 03:27:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=44
06/23/2022 03:27:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.43 on epoch=44
06/23/2022 03:27:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=45
06/23/2022 03:27:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=46
06/23/2022 03:27:40 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.7180632994741694 on epoch=46
06/23/2022 03:27:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6747513475592278 -> 0.7180632994741694 on epoch=46, global_step=650
06/23/2022 03:27:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=47
06/23/2022 03:27:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/23/2022 03:27:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=48
06/23/2022 03:27:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=49
06/23/2022 03:27:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=49
06/23/2022 03:28:01 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.6634058552165015 on epoch=49
06/23/2022 03:28:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/23/2022 03:28:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=51
06/23/2022 03:28:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=52
06/23/2022 03:28:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.29 on epoch=52
06/23/2022 03:28:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=53
06/23/2022 03:28:21 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.8086021505376344 on epoch=53
06/23/2022 03:28:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7180632994741694 -> 0.8086021505376344 on epoch=53, global_step=750
06/23/2022 03:28:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
06/23/2022 03:28:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=54
06/23/2022 03:28:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/23/2022 03:28:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
06/23/2022 03:28:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
06/23/2022 03:28:41 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.8077652935961264 on epoch=57
06/23/2022 03:28:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/23/2022 03:28:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/23/2022 03:28:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=59
06/23/2022 03:28:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=59
06/23/2022 03:28:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=60
06/23/2022 03:29:01 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.8297816878462041 on epoch=60
06/23/2022 03:29:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8086021505376344 -> 0.8297816878462041 on epoch=60, global_step=850
06/23/2022 03:29:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=61
06/23/2022 03:29:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=62
06/23/2022 03:29:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=62
06/23/2022 03:29:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=63
06/23/2022 03:29:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/23/2022 03:29:22 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.7900671803423227 on epoch=64
06/23/2022 03:29:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
06/23/2022 03:29:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
06/23/2022 03:29:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/23/2022 03:29:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/23/2022 03:29:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/23/2022 03:29:42 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.8475623311587623 on epoch=67
06/23/2022 03:29:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8297816878462041 -> 0.8475623311587623 on epoch=67, global_step=950
06/23/2022 03:29:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=68
06/23/2022 03:29:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
06/23/2022 03:29:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=69
06/23/2022 03:29:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
06/23/2022 03:29:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/23/2022 03:30:02 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.7786724485763608 on epoch=71
06/23/2022 03:30:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/23/2022 03:30:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=72
06/23/2022 03:30:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
06/23/2022 03:30:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=74
06/23/2022 03:30:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
06/23/2022 03:30:22 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.7718597262952102 on epoch=74
06/23/2022 03:30:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
06/23/2022 03:30:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
06/23/2022 03:30:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
06/23/2022 03:30:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
06/23/2022 03:30:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=78
06/23/2022 03:30:42 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.7337388404297075 on epoch=78
06/23/2022 03:30:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=79
06/23/2022 03:30:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=79
06/23/2022 03:30:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=80
06/23/2022 03:30:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
06/23/2022 03:30:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=82
06/23/2022 03:31:02 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.6896960193331161 on epoch=82
06/23/2022 03:31:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/23/2022 03:31:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/23/2022 03:31:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/23/2022 03:31:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=84
06/23/2022 03:31:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=85
06/23/2022 03:31:22 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.6964366577269803 on epoch=85
06/23/2022 03:31:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/23/2022 03:31:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/23/2022 03:31:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/23/2022 03:31:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=88
06/23/2022 03:31:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.26 on epoch=89
06/23/2022 03:31:42 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.7329137097108502 on epoch=89
06/23/2022 03:31:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/23/2022 03:31:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/23/2022 03:31:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
06/23/2022 03:31:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
06/23/2022 03:31:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/23/2022 03:32:02 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.7707179031218153 on epoch=92
06/23/2022 03:32:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=93
06/23/2022 03:32:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=94
06/23/2022 03:32:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/23/2022 03:32:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/23/2022 03:32:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
06/23/2022 03:32:22 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.7301494204720012 on epoch=96
06/23/2022 03:32:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
06/23/2022 03:32:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
06/23/2022 03:32:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/23/2022 03:32:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=99
06/23/2022 03:32:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/23/2022 03:32:42 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.7374035199462144 on epoch=99
06/23/2022 03:32:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/23/2022 03:32:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/23/2022 03:32:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/23/2022 03:32:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=102
06/23/2022 03:32:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=103
06/23/2022 03:33:02 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6621164149177732 on epoch=103
06/23/2022 03:33:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/23/2022 03:33:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
06/23/2022 03:33:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/23/2022 03:33:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/23/2022 03:33:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
06/23/2022 03:33:22 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.6935049418920387 on epoch=107
06/23/2022 03:33:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
06/23/2022 03:33:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
06/23/2022 03:33:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
06/23/2022 03:33:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/23/2022 03:33:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/23/2022 03:33:42 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7429195725210905 on epoch=110
06/23/2022 03:33:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/23/2022 03:33:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/23/2022 03:33:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/23/2022 03:33:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
06/23/2022 03:33:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
06/23/2022 03:34:02 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7016462629365855 on epoch=114
06/23/2022 03:34:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
06/23/2022 03:34:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
06/23/2022 03:34:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
06/23/2022 03:34:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=117
06/23/2022 03:34:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=117
06/23/2022 03:34:22 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6557751878160927 on epoch=117
06/23/2022 03:34:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=118
06/23/2022 03:34:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/23/2022 03:34:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/23/2022 03:34:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
06/23/2022 03:34:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
06/23/2022 03:34:42 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.6614901793170044 on epoch=121
06/23/2022 03:34:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
06/23/2022 03:34:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/23/2022 03:34:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=123
06/23/2022 03:34:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/23/2022 03:34:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/23/2022 03:35:02 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7154858728546268 on epoch=124
06/23/2022 03:35:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/23/2022 03:35:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/23/2022 03:35:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=127
06/23/2022 03:35:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/23/2022 03:35:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=128
06/23/2022 03:35:22 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.6689188902911065 on epoch=128
06/23/2022 03:35:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/23/2022 03:35:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/23/2022 03:35:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
06/23/2022 03:35:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/23/2022 03:35:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
06/23/2022 03:35:42 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.6728654769002317 on epoch=132
06/23/2022 03:35:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/23/2022 03:35:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.14 on epoch=133
06/23/2022 03:35:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
06/23/2022 03:35:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/23/2022 03:35:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/23/2022 03:36:02 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6795368041747748 on epoch=135
06/23/2022 03:36:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/23/2022 03:36:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/23/2022 03:36:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/23/2022 03:36:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/23/2022 03:36:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/23/2022 03:36:22 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6860460030349701 on epoch=139
06/23/2022 03:36:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/23/2022 03:36:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/23/2022 03:36:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/23/2022 03:36:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/23/2022 03:36:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/23/2022 03:36:42 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7367111980015206 on epoch=142
06/23/2022 03:36:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/23/2022 03:36:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/23/2022 03:36:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/23/2022 03:36:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
06/23/2022 03:36:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/23/2022 03:37:02 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7908573400034501 on epoch=146
06/23/2022 03:37:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/23/2022 03:37:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/23/2022 03:37:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/23/2022 03:37:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/23/2022 03:37:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/23/2022 03:37:22 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7239520273476132 on epoch=149
06/23/2022 03:37:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/23/2022 03:37:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/23/2022 03:37:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
06/23/2022 03:37:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/23/2022 03:37:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/23/2022 03:37:42 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7274276437264553 on epoch=153
06/23/2022 03:37:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/23/2022 03:37:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/23/2022 03:37:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/23/2022 03:37:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=156
06/23/2022 03:37:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/23/2022 03:38:02 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7939945949054108 on epoch=157
06/23/2022 03:38:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/23/2022 03:38:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/23/2022 03:38:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/23/2022 03:38:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/23/2022 03:38:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/23/2022 03:38:21 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6661681329423266 on epoch=160
06/23/2022 03:38:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/23/2022 03:38:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/23/2022 03:38:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/23/2022 03:38:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/23/2022 03:38:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/23/2022 03:38:41 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7533594004561747 on epoch=164
06/23/2022 03:38:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/23/2022 03:38:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/23/2022 03:38:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/23/2022 03:38:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/23/2022 03:38:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/23/2022 03:39:01 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7976746593065379 on epoch=167
06/23/2022 03:39:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/23/2022 03:39:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/23/2022 03:39:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=169
06/23/2022 03:39:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/23/2022 03:39:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/23/2022 03:39:21 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8005705869083478 on epoch=171
06/23/2022 03:39:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/23/2022 03:39:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/23/2022 03:39:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/23/2022 03:39:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/23/2022 03:39:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/23/2022 03:39:41 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8608626588465298 on epoch=174
06/23/2022 03:39:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8475623311587623 -> 0.8608626588465298 on epoch=174, global_step=2450
06/23/2022 03:39:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/23/2022 03:39:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/23/2022 03:39:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/23/2022 03:39:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/23/2022 03:39:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/23/2022 03:40:01 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7471758255769476 on epoch=178
06/23/2022 03:40:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/23/2022 03:40:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
06/23/2022 03:40:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/23/2022 03:40:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/23/2022 03:40:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/23/2022 03:40:21 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.8057418861972941 on epoch=182
06/23/2022 03:40:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/23/2022 03:40:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/23/2022 03:40:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/23/2022 03:40:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=184
06/23/2022 03:40:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/23/2022 03:40:41 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8057418861972941 on epoch=185
06/23/2022 03:40:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/23/2022 03:40:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/23/2022 03:40:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/23/2022 03:40:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/23/2022 03:40:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/23/2022 03:41:00 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7609784480752223 on epoch=189
06/23/2022 03:41:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/23/2022 03:41:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/23/2022 03:41:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/23/2022 03:41:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/23/2022 03:41:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/23/2022 03:41:20 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.810223678914381 on epoch=192
06/23/2022 03:41:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/23/2022 03:41:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/23/2022 03:41:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/23/2022 03:41:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
06/23/2022 03:41:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/23/2022 03:41:39 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8080600548440633 on epoch=196
06/23/2022 03:41:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/23/2022 03:41:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/23/2022 03:41:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/23/2022 03:41:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/23/2022 03:41:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/23/2022 03:41:59 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7526188268123752 on epoch=199
06/23/2022 03:42:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/23/2022 03:42:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/23/2022 03:42:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/23/2022 03:42:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/23/2022 03:42:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/23/2022 03:42:19 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=203
06/23/2022 03:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8608626588465298 -> 0.9226979472140762 on epoch=203, global_step=2850
06/23/2022 03:42:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/23/2022 03:42:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=204
06/23/2022 03:42:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/23/2022 03:42:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/23/2022 03:42:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/23/2022 03:42:38 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8608626588465298 on epoch=207
06/23/2022 03:42:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/23/2022 03:42:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/23/2022 03:42:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/23/2022 03:42:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/23/2022 03:42:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/23/2022 03:42:58 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8608626588465298 on epoch=210
06/23/2022 03:43:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/23/2022 03:43:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/23/2022 03:43:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/23/2022 03:43:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/23/2022 03:43:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/23/2022 03:43:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:43:12 - INFO - __main__ - Printing 3 examples
06/23/2022 03:43:12 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 03:43:12 - INFO - __main__ - ['Film']
06/23/2022 03:43:12 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 03:43:12 - INFO - __main__ - ['Film']
06/23/2022 03:43:12 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 03:43:12 - INFO - __main__ - ['Film']
06/23/2022 03:43:12 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:43:12 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:43:13 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 03:43:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:43:13 - INFO - __main__ - Printing 3 examples
06/23/2022 03:43:13 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 03:43:13 - INFO - __main__ - ['Film']
06/23/2022 03:43:13 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 03:43:13 - INFO - __main__ - ['Film']
06/23/2022 03:43:13 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 03:43:13 - INFO - __main__ - ['Film']
06/23/2022 03:43:13 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:43:13 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:43:13 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 03:43:18 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9226979472140762 on epoch=214
06/23/2022 03:43:18 - INFO - __main__ - save last model!
06/23/2022 03:43:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 03:43:18 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 03:43:18 - INFO - __main__ - Printing 3 examples
06/23/2022 03:43:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 03:43:18 - INFO - __main__ - ['Animal']
06/23/2022 03:43:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 03:43:18 - INFO - __main__ - ['Animal']
06/23/2022 03:43:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 03:43:18 - INFO - __main__ - ['Village']
06/23/2022 03:43:18 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:43:20 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:43:23 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 03:43:28 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 03:43:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 03:43:29 - INFO - __main__ - Starting training!
06/23/2022 03:45:37 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/23/2022 03:45:37 - INFO - __main__ - Classification-F1 on test data: 0.5466
06/23/2022 03:45:37 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9226979472140762, test_performance=0.5466386744168896
06/23/2022 03:45:37 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/23/2022 03:45:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:45:38 - INFO - __main__ - Printing 3 examples
06/23/2022 03:45:38 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/23/2022 03:45:38 - INFO - __main__ - ['Film']
06/23/2022 03:45:38 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/23/2022 03:45:38 - INFO - __main__ - ['Film']
06/23/2022 03:45:38 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/23/2022 03:45:38 - INFO - __main__ - ['Film']
06/23/2022 03:45:38 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:45:39 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:45:39 - INFO - __main__ - Loaded 224 examples from train data
06/23/2022 03:45:39 - INFO - __main__ - Start tokenizing ... 224 instances
06/23/2022 03:45:39 - INFO - __main__ - Printing 3 examples
06/23/2022 03:45:39 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/23/2022 03:45:39 - INFO - __main__ - ['Film']
06/23/2022 03:45:39 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/23/2022 03:45:39 - INFO - __main__ - ['Film']
06/23/2022 03:45:39 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/23/2022 03:45:39 - INFO - __main__ - ['Film']
06/23/2022 03:45:39 - INFO - __main__ - Tokenizing Input ...
06/23/2022 03:45:39 - INFO - __main__ - Tokenizing Output ...
06/23/2022 03:45:39 - INFO - __main__ - Loaded 224 examples from dev data
06/23/2022 03:45:55 - INFO - __main__ - load prompt embedding from ckpt
06/23/2022 03:45:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/23/2022 03:45:55 - INFO - __main__ - Starting training!
06/23/2022 03:45:59 - INFO - __main__ - Step 10 Global step 10 Train loss 7.42 on epoch=0
06/23/2022 03:46:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.01 on epoch=1
06/23/2022 03:46:04 - INFO - __main__ - Step 30 Global step 30 Train loss 5.09 on epoch=2
06/23/2022 03:46:07 - INFO - __main__ - Step 40 Global step 40 Train loss 4.44 on epoch=2
06/23/2022 03:46:09 - INFO - __main__ - Step 50 Global step 50 Train loss 4.87 on epoch=3
06/23/2022 03:46:16 - INFO - __main__ - Global step 50 Train loss 5.57 Classification-F1 0.041227863046044866 on epoch=3
06/23/2022 03:46:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.041227863046044866 on epoch=3, global_step=50
06/23/2022 03:46:19 - INFO - __main__ - Step 60 Global step 60 Train loss 4.42 on epoch=4
06/23/2022 03:46:21 - INFO - __main__ - Step 70 Global step 70 Train loss 3.65 on epoch=4
06/23/2022 03:46:24 - INFO - __main__ - Step 80 Global step 80 Train loss 3.99 on epoch=5
06/23/2022 03:46:26 - INFO - __main__ - Step 90 Global step 90 Train loss 3.50 on epoch=6
06/23/2022 03:46:29 - INFO - __main__ - Step 100 Global step 100 Train loss 3.40 on epoch=7
06/23/2022 03:46:34 - INFO - __main__ - Global step 100 Train loss 3.79 Classification-F1 0.05414154472978002 on epoch=7
06/23/2022 03:46:34 - INFO - __main__ - Saving model with best Classification-F1: 0.041227863046044866 -> 0.05414154472978002 on epoch=7, global_step=100
06/23/2022 03:46:36 - INFO - __main__ - Step 110 Global step 110 Train loss 3.01 on epoch=7
06/23/2022 03:46:39 - INFO - __main__ - Step 120 Global step 120 Train loss 3.14 on epoch=8
06/23/2022 03:46:41 - INFO - __main__ - Step 130 Global step 130 Train loss 3.02 on epoch=9
06/23/2022 03:46:44 - INFO - __main__ - Step 140 Global step 140 Train loss 2.80 on epoch=9
06/23/2022 03:46:47 - INFO - __main__ - Step 150 Global step 150 Train loss 3.01 on epoch=10
06/23/2022 03:46:52 - INFO - __main__ - Global step 150 Train loss 3.00 Classification-F1 0.0780171509361063 on epoch=10
06/23/2022 03:46:52 - INFO - __main__ - Saving model with best Classification-F1: 0.05414154472978002 -> 0.0780171509361063 on epoch=10, global_step=150
06/23/2022 03:46:54 - INFO - __main__ - Step 160 Global step 160 Train loss 2.62 on epoch=11
06/23/2022 03:46:57 - INFO - __main__ - Step 170 Global step 170 Train loss 2.60 on epoch=12
06/23/2022 03:46:59 - INFO - __main__ - Step 180 Global step 180 Train loss 2.23 on epoch=12
06/23/2022 03:47:02 - INFO - __main__ - Step 190 Global step 190 Train loss 2.45 on epoch=13
06/23/2022 03:47:05 - INFO - __main__ - Step 200 Global step 200 Train loss 2.29 on epoch=14
06/23/2022 03:47:10 - INFO - __main__ - Global step 200 Train loss 2.44 Classification-F1 0.08842318635665411 on epoch=14
06/23/2022 03:47:10 - INFO - __main__ - Saving model with best Classification-F1: 0.0780171509361063 -> 0.08842318635665411 on epoch=14, global_step=200
06/23/2022 03:47:13 - INFO - __main__ - Step 210 Global step 210 Train loss 1.99 on epoch=14
06/23/2022 03:47:16 - INFO - __main__ - Step 220 Global step 220 Train loss 2.41 on epoch=15
06/23/2022 03:47:18 - INFO - __main__ - Step 230 Global step 230 Train loss 2.01 on epoch=16
06/23/2022 03:47:21 - INFO - __main__ - Step 240 Global step 240 Train loss 2.00 on epoch=17
06/23/2022 03:47:23 - INFO - __main__ - Step 250 Global step 250 Train loss 1.70 on epoch=17
06/23/2022 03:47:29 - INFO - __main__ - Global step 250 Train loss 2.02 Classification-F1 0.11750191142849652 on epoch=17
06/23/2022 03:47:29 - INFO - __main__ - Saving model with best Classification-F1: 0.08842318635665411 -> 0.11750191142849652 on epoch=17, global_step=250
06/23/2022 03:47:32 - INFO - __main__ - Step 260 Global step 260 Train loss 1.92 on epoch=18
06/23/2022 03:47:34 - INFO - __main__ - Step 270 Global step 270 Train loss 1.84 on epoch=19
06/23/2022 03:47:37 - INFO - __main__ - Step 280 Global step 280 Train loss 1.63 on epoch=19
06/23/2022 03:47:39 - INFO - __main__ - Step 290 Global step 290 Train loss 1.82 on epoch=20
06/23/2022 03:47:42 - INFO - __main__ - Step 300 Global step 300 Train loss 1.63 on epoch=21
06/23/2022 03:47:48 - INFO - __main__ - Global step 300 Train loss 1.77 Classification-F1 0.12026445699276624 on epoch=21
06/23/2022 03:47:48 - INFO - __main__ - Saving model with best Classification-F1: 0.11750191142849652 -> 0.12026445699276624 on epoch=21, global_step=300
06/23/2022 03:47:50 - INFO - __main__ - Step 310 Global step 310 Train loss 1.58 on epoch=22
06/23/2022 03:47:53 - INFO - __main__ - Step 320 Global step 320 Train loss 1.40 on epoch=22
06/23/2022 03:47:56 - INFO - __main__ - Step 330 Global step 330 Train loss 1.47 on epoch=23
06/23/2022 03:47:58 - INFO - __main__ - Step 340 Global step 340 Train loss 1.47 on epoch=24
06/23/2022 03:48:01 - INFO - __main__ - Step 350 Global step 350 Train loss 1.25 on epoch=24
06/23/2022 03:48:07 - INFO - __main__ - Global step 350 Train loss 1.43 Classification-F1 0.1379983828004972 on epoch=24
06/23/2022 03:48:07 - INFO - __main__ - Saving model with best Classification-F1: 0.12026445699276624 -> 0.1379983828004972 on epoch=24, global_step=350
06/23/2022 03:48:09 - INFO - __main__ - Step 360 Global step 360 Train loss 1.39 on epoch=25
06/23/2022 03:48:12 - INFO - __main__ - Step 370 Global step 370 Train loss 1.29 on epoch=26
06/23/2022 03:48:14 - INFO - __main__ - Step 380 Global step 380 Train loss 1.26 on epoch=27
06/23/2022 03:48:17 - INFO - __main__ - Step 390 Global step 390 Train loss 1.03 on epoch=27
06/23/2022 03:48:19 - INFO - __main__ - Step 400 Global step 400 Train loss 1.21 on epoch=28
06/23/2022 03:48:26 - INFO - __main__ - Global step 400 Train loss 1.23 Classification-F1 0.17469815602243446 on epoch=28
06/23/2022 03:48:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1379983828004972 -> 0.17469815602243446 on epoch=28, global_step=400
06/23/2022 03:48:28 - INFO - __main__ - Step 410 Global step 410 Train loss 1.20 on epoch=29
06/23/2022 03:48:31 - INFO - __main__ - Step 420 Global step 420 Train loss 1.08 on epoch=29
06/23/2022 03:48:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.96 on epoch=30
06/23/2022 03:48:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.92 on epoch=31
06/23/2022 03:48:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.93 on epoch=32
06/23/2022 03:48:45 - INFO - __main__ - Global step 450 Train loss 1.02 Classification-F1 0.29634033647916597 on epoch=32
06/23/2022 03:48:45 - INFO - __main__ - Saving model with best Classification-F1: 0.17469815602243446 -> 0.29634033647916597 on epoch=32, global_step=450
06/23/2022 03:48:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.82 on epoch=32
06/23/2022 03:48:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.89 on epoch=33
06/23/2022 03:48:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.86 on epoch=34
06/23/2022 03:48:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.79 on epoch=34
06/23/2022 03:48:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.85 on epoch=35
06/23/2022 03:49:05 - INFO - __main__ - Global step 500 Train loss 0.84 Classification-F1 0.345675351336582 on epoch=35
06/23/2022 03:49:05 - INFO - __main__ - Saving model with best Classification-F1: 0.29634033647916597 -> 0.345675351336582 on epoch=35, global_step=500
06/23/2022 03:49:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.78 on epoch=36
06/23/2022 03:49:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.73 on epoch=37
06/23/2022 03:49:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.64 on epoch=37
06/23/2022 03:49:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.63 on epoch=38
06/23/2022 03:49:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.74 on epoch=39
06/23/2022 03:49:24 - INFO - __main__ - Global step 550 Train loss 0.70 Classification-F1 0.4308254571518317 on epoch=39
06/23/2022 03:49:24 - INFO - __main__ - Saving model with best Classification-F1: 0.345675351336582 -> 0.4308254571518317 on epoch=39, global_step=550
06/23/2022 03:49:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.64 on epoch=39
06/23/2022 03:49:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.63 on epoch=40
06/23/2022 03:49:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.63 on epoch=41
06/23/2022 03:49:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.67 on epoch=42
06/23/2022 03:49:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=42
06/23/2022 03:49:45 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.41477527512269746 on epoch=42
06/23/2022 03:49:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.61 on epoch=43
06/23/2022 03:49:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=44
06/23/2022 03:49:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.58 on epoch=44
06/23/2022 03:49:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=45
06/23/2022 03:49:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.58 on epoch=46
06/23/2022 03:50:05 - INFO - __main__ - Global step 650 Train loss 0.56 Classification-F1 0.5415062905048207 on epoch=46
06/23/2022 03:50:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4308254571518317 -> 0.5415062905048207 on epoch=46, global_step=650
06/23/2022 03:50:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.48 on epoch=47
06/23/2022 03:50:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.54 on epoch=47
06/23/2022 03:50:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.45 on epoch=48
06/23/2022 03:50:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.47 on epoch=49
06/23/2022 03:50:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.51 on epoch=49
06/23/2022 03:50:25 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.6310849521236642 on epoch=49
06/23/2022 03:50:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5415062905048207 -> 0.6310849521236642 on epoch=49, global_step=700
06/23/2022 03:50:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.52 on epoch=50
06/23/2022 03:50:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=51
06/23/2022 03:50:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.46 on epoch=52
06/23/2022 03:50:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.45 on epoch=52
06/23/2022 03:50:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=53
06/23/2022 03:50:46 - INFO - __main__ - Global step 750 Train loss 0.46 Classification-F1 0.5705463512117371 on epoch=53
06/23/2022 03:50:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.40 on epoch=54
06/23/2022 03:50:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.44 on epoch=54
06/23/2022 03:50:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.38 on epoch=55
06/23/2022 03:50:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=56
06/23/2022 03:50:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.46 on epoch=57
06/23/2022 03:51:06 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.7623376033887094 on epoch=57
06/23/2022 03:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6310849521236642 -> 0.7623376033887094 on epoch=57, global_step=800
06/23/2022 03:51:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=57
06/23/2022 03:51:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.40 on epoch=58
06/23/2022 03:51:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=59
06/23/2022 03:51:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.36 on epoch=59
06/23/2022 03:51:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.42 on epoch=60
06/23/2022 03:51:27 - INFO - __main__ - Global step 850 Train loss 0.38 Classification-F1 0.7169319852787596 on epoch=60
06/23/2022 03:51:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.38 on epoch=61
06/23/2022 03:51:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
06/23/2022 03:51:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.38 on epoch=62
06/23/2022 03:51:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=63
06/23/2022 03:51:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.33 on epoch=64
06/23/2022 03:51:47 - INFO - __main__ - Global step 900 Train loss 0.35 Classification-F1 0.8100866875060424 on epoch=64
06/23/2022 03:51:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7623376033887094 -> 0.8100866875060424 on epoch=64, global_step=900
06/23/2022 03:51:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.49 on epoch=64
06/23/2022 03:51:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.42 on epoch=65
06/23/2022 03:51:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.33 on epoch=66
06/23/2022 03:51:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=67
06/23/2022 03:52:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=67
06/23/2022 03:52:08 - INFO - __main__ - Global step 950 Train loss 0.36 Classification-F1 0.7587353450954301 on epoch=67
06/23/2022 03:52:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.35 on epoch=68
06/23/2022 03:52:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.39 on epoch=69
06/23/2022 03:52:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=69
06/23/2022 03:52:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.37 on epoch=70
06/23/2022 03:52:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=71
06/23/2022 03:52:28 - INFO - __main__ - Global step 1000 Train loss 0.36 Classification-F1 0.8510997624628975 on epoch=71
06/23/2022 03:52:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8100866875060424 -> 0.8510997624628975 on epoch=71, global_step=1000
06/23/2022 03:52:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=72
06/23/2022 03:52:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.32 on epoch=72
06/23/2022 03:52:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.37 on epoch=73
06/23/2022 03:52:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
06/23/2022 03:52:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=74
06/23/2022 03:52:48 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.8681844947167529 on epoch=74
06/23/2022 03:52:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8510997624628975 -> 0.8681844947167529 on epoch=74, global_step=1050
06/23/2022 03:52:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.27 on epoch=75
06/23/2022 03:52:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/23/2022 03:52:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=77
06/23/2022 03:52:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
06/23/2022 03:53:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/23/2022 03:53:09 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.8724945305590469 on epoch=78
06/23/2022 03:53:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8681844947167529 -> 0.8724945305590469 on epoch=78, global_step=1100
06/23/2022 03:53:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=79
06/23/2022 03:53:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.26 on epoch=79
06/23/2022 03:53:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.27 on epoch=80
06/23/2022 03:53:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/23/2022 03:53:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=82
06/23/2022 03:53:29 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.8825811759398098 on epoch=82
06/23/2022 03:53:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8724945305590469 -> 0.8825811759398098 on epoch=82, global_step=1150
06/23/2022 03:53:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/23/2022 03:53:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.31 on epoch=83
06/23/2022 03:53:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=84
06/23/2022 03:53:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.31 on epoch=84
06/23/2022 03:53:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.22 on epoch=85
06/23/2022 03:53:50 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.8666956782485665 on epoch=85
06/23/2022 03:53:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/23/2022 03:53:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=87
06/23/2022 03:53:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=87
06/23/2022 03:54:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.25 on epoch=88
06/23/2022 03:54:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=89
06/23/2022 03:54:10 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.7966751274787456 on epoch=89
06/23/2022 03:54:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.25 on epoch=89
06/23/2022 03:54:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=90
06/23/2022 03:54:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.24 on epoch=91
06/23/2022 03:54:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=92
06/23/2022 03:54:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=92
06/23/2022 03:54:30 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.8475623311587623 on epoch=92
06/23/2022 03:54:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.26 on epoch=93
06/23/2022 03:54:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.22 on epoch=94
06/23/2022 03:54:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=94
06/23/2022 03:54:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=95
06/23/2022 03:54:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.25 on epoch=96
06/23/2022 03:54:51 - INFO - __main__ - Global step 1350 Train loss 0.23 Classification-F1 0.7916085048415431 on epoch=96
06/23/2022 03:54:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=97
06/23/2022 03:54:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/23/2022 03:54:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=98
06/23/2022 03:55:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
06/23/2022 03:55:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.22 on epoch=99
06/23/2022 03:55:11 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.7925773748552789 on epoch=99
06/23/2022 03:55:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=100
06/23/2022 03:55:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.28 on epoch=101
06/23/2022 03:55:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.23 on epoch=102
06/23/2022 03:55:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=102
06/23/2022 03:55:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.24 on epoch=103
06/23/2022 03:55:31 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.788532897826931 on epoch=103
06/23/2022 03:55:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/23/2022 03:55:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.24 on epoch=104
06/23/2022 03:55:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
06/23/2022 03:55:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.20 on epoch=106
06/23/2022 03:55:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
06/23/2022 03:55:51 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.7925735564290814 on epoch=107
06/23/2022 03:55:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=107
06/23/2022 03:55:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=108
06/23/2022 03:55:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.21 on epoch=109
06/23/2022 03:56:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=109
06/23/2022 03:56:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.22 on epoch=110
06/23/2022 03:56:12 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.7390731079891599 on epoch=110
06/23/2022 03:56:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.20 on epoch=111
06/23/2022 03:56:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=112
06/23/2022 03:56:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=112
06/23/2022 03:56:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
06/23/2022 03:56:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=114
06/23/2022 03:56:32 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.741184137389071 on epoch=114
06/23/2022 03:56:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=114
06/23/2022 03:56:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.18 on epoch=115
06/23/2022 03:56:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=116
06/23/2022 03:56:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.22 on epoch=117
06/23/2022 03:56:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.16 on epoch=117
06/23/2022 03:56:52 - INFO - __main__ - Global step 1650 Train loss 0.18 Classification-F1 0.7320509742549276 on epoch=117
06/23/2022 03:56:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
06/23/2022 03:56:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
06/23/2022 03:57:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/23/2022 03:57:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
06/23/2022 03:57:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=121
06/23/2022 03:57:12 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.7292904488573649 on epoch=121
06/23/2022 03:57:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.19 on epoch=122
06/23/2022 03:57:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=122
06/23/2022 03:57:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.23 on epoch=123
06/23/2022 03:57:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/23/2022 03:57:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/23/2022 03:57:32 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.7777147885456213 on epoch=124
06/23/2022 03:57:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/23/2022 03:57:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.22 on epoch=126
06/23/2022 03:57:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/23/2022 03:57:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
06/23/2022 03:57:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.19 on epoch=128
06/23/2022 03:57:52 - INFO - __main__ - Global step 1800 Train loss 0.16 Classification-F1 0.7338653426434963 on epoch=128
06/23/2022 03:57:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=129
06/23/2022 03:57:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
06/23/2022 03:58:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/23/2022 03:58:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
06/23/2022 03:58:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=132
06/23/2022 03:58:13 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.6942130457472708 on epoch=132
06/23/2022 03:58:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/23/2022 03:58:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/23/2022 03:58:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.15 on epoch=134
06/23/2022 03:58:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=134
06/23/2022 03:58:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/23/2022 03:58:33 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.6676718401276477 on epoch=135
06/23/2022 03:58:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
06/23/2022 03:58:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
06/23/2022 03:58:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/23/2022 03:58:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=138
06/23/2022 03:58:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/23/2022 03:58:53 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.6287612544847443 on epoch=139
06/23/2022 03:58:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.16 on epoch=139
06/23/2022 03:58:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=140
06/23/2022 03:59:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.14 on epoch=141
06/23/2022 03:59:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/23/2022 03:59:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=142
06/23/2022 03:59:14 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.6716010545831779 on epoch=142
06/23/2022 03:59:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
06/23/2022 03:59:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/23/2022 03:59:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=144
06/23/2022 03:59:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/23/2022 03:59:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/23/2022 03:59:34 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.6362929101259273 on epoch=146
06/23/2022 03:59:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/23/2022 03:59:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
06/23/2022 03:59:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=148
06/23/2022 03:59:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=149
06/23/2022 03:59:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.14 on epoch=149
06/23/2022 03:59:54 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.6948641561544788 on epoch=149
06/23/2022 03:59:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
06/23/2022 03:59:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=151
06/23/2022 04:00:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/23/2022 04:00:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=152
06/23/2022 04:00:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=153
06/23/2022 04:00:14 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.6699882648948863 on epoch=153
06/23/2022 04:00:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.17 on epoch=154
06/23/2022 04:00:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.13 on epoch=154
06/23/2022 04:00:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/23/2022 04:00:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=156
06/23/2022 04:00:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=157
06/23/2022 04:00:35 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.6725043590518474 on epoch=157
06/23/2022 04:00:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=157
06/23/2022 04:00:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/23/2022 04:00:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.13 on epoch=159
06/23/2022 04:00:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=159
06/23/2022 04:00:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/23/2022 04:00:55 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.7156754436324329 on epoch=160
06/23/2022 04:00:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
06/23/2022 04:01:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/23/2022 04:01:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
06/23/2022 04:01:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/23/2022 04:01:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.13 on epoch=164
06/23/2022 04:01:16 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.6730728995584684 on epoch=164
06/23/2022 04:01:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=164
06/23/2022 04:01:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/23/2022 04:01:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/23/2022 04:01:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/23/2022 04:01:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/23/2022 04:01:36 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.6811214108527601 on epoch=167
06/23/2022 04:01:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
06/23/2022 04:01:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/23/2022 04:01:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=169
06/23/2022 04:01:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/23/2022 04:01:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=171
06/23/2022 04:01:56 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.7194626895249419 on epoch=171
06/23/2022 04:01:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/23/2022 04:02:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/23/2022 04:02:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/23/2022 04:02:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=174
06/23/2022 04:02:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/23/2022 04:02:16 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.6827533138339618 on epoch=174
06/23/2022 04:02:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/23/2022 04:02:21 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
06/23/2022 04:02:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/23/2022 04:02:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/23/2022 04:02:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=178
06/23/2022 04:02:37 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.8329126518642648 on epoch=178
06/23/2022 04:02:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=179
06/23/2022 04:02:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=179
06/23/2022 04:02:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=180
06/23/2022 04:02:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/23/2022 04:02:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/23/2022 04:02:57 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.7886368540861229 on epoch=182
06/23/2022 04:03:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/23/2022 04:03:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
06/23/2022 04:03:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.15 on epoch=184
06/23/2022 04:03:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/23/2022 04:03:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=185
06/23/2022 04:03:17 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.7968905225072208 on epoch=185
06/23/2022 04:03:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/23/2022 04:03:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/23/2022 04:03:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/23/2022 04:03:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=188
06/23/2022 04:03:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=189
06/23/2022 04:03:37 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.806543614513254 on epoch=189
06/23/2022 04:03:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=189
06/23/2022 04:03:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/23/2022 04:03:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=191
06/23/2022 04:03:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=192
06/23/2022 04:03:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/23/2022 04:03:57 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.8569525904203323 on epoch=192
06/23/2022 04:04:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/23/2022 04:04:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/23/2022 04:04:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=194
06/23/2022 04:04:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/23/2022 04:04:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/23/2022 04:04:17 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.7596922131961065 on epoch=196
06/23/2022 04:04:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=197
06/23/2022 04:04:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/23/2022 04:04:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=198
06/23/2022 04:04:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/23/2022 04:04:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.11 on epoch=199
06/23/2022 04:04:37 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.7631678295749487 on epoch=199
06/23/2022 04:04:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/23/2022 04:04:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=201
06/23/2022 04:04:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=202
06/23/2022 04:04:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/23/2022 04:04:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/23/2022 04:04:57 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.810223678914381 on epoch=203
06/23/2022 04:04:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/23/2022 04:05:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/23/2022 04:05:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/23/2022 04:05:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
06/23/2022 04:05:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/23/2022 04:05:17 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.8043799904429363 on epoch=207
06/23/2022 04:05:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/23/2022 04:05:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/23/2022 04:05:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/23/2022 04:05:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.13 on epoch=209
06/23/2022 04:05:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/23/2022 04:05:36 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.806543614513254 on epoch=210
06/23/2022 04:05:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.13 on epoch=211
06/23/2022 04:05:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=212
06/23/2022 04:05:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/23/2022 04:05:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=213
06/23/2022 04:05:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/23/2022 04:05:56 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.7598240469208211 on epoch=214
06/23/2022 04:05:56 - INFO - __main__ - save last model!
06/23/2022 04:05:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/23/2022 04:05:56 - INFO - __main__ - Start tokenizing ... 3500 instances
06/23/2022 04:05:57 - INFO - __main__ - Printing 3 examples
06/23/2022 04:05:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/23/2022 04:05:57 - INFO - __main__ - ['Animal']
06/23/2022 04:05:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/23/2022 04:05:57 - INFO - __main__ - ['Animal']
06/23/2022 04:05:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/23/2022 04:05:57 - INFO - __main__ - ['Village']
06/23/2022 04:05:57 - INFO - __main__ - Tokenizing Input ...
06/23/2022 04:05:58 - INFO - __main__ - Tokenizing Output ...
06/23/2022 04:06:02 - INFO - __main__ - Loaded 3500 examples from test data
06/23/2022 04:08:13 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/23/2022 04:08:13 - INFO - __main__ - Classification-F1 on test data: 0.4526
06/23/2022 04:08:14 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.8825811759398098, test_performance=0.45261208543589504
06/24/2022 21:27:14 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-3-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-3-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/24/2022 21:27:14 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14
06/24/2022 21:27:14 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-3-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-3-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
06/24/2022 21:27:14 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14
06/24/2022 21:27:16 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/24/2022 21:27:16 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/24/2022 21:27:16 - INFO - __main__ - args.device: cuda:0
06/24/2022 21:27:16 - INFO - __main__ - args.device: cuda:1
06/24/2022 21:27:16 - INFO - __main__ - Using 2 gpus
06/24/2022 21:27:16 - INFO - __main__ - Using 2 gpus
06/24/2022 21:27:16 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/24/2022 21:27:16 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/24/2022 21:27:20 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/24/2022 21:27:21 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:27:21 - INFO - __main__ - Printing 3 examples
06/24/2022 21:27:21 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 21:27:21 - INFO - __main__ - ['Animal']
06/24/2022 21:27:21 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 21:27:21 - INFO - __main__ - ['Animal']
06/24/2022 21:27:21 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 21:27:21 - INFO - __main__ - ['Animal']
06/24/2022 21:27:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:27:21 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:27:21 - INFO - __main__ - Printing 3 examples
06/24/2022 21:27:21 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 21:27:21 - INFO - __main__ - ['Animal']
06/24/2022 21:27:21 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 21:27:21 - INFO - __main__ - ['Animal']
06/24/2022 21:27:21 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 21:27:21 - INFO - __main__ - ['Animal']
06/24/2022 21:27:21 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:27:21 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:27:21 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:27:22 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 21:27:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:27:22 - INFO - __main__ - Printing 3 examples
06/24/2022 21:27:22 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 21:27:22 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 21:27:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:27:22 - INFO - __main__ - ['Animal']
06/24/2022 21:27:22 - INFO - __main__ - Printing 3 examples
06/24/2022 21:27:22 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 21:27:22 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 21:27:22 - INFO - __main__ - ['Animal']
06/24/2022 21:27:22 - INFO - __main__ - ['Animal']
06/24/2022 21:27:22 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 21:27:22 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 21:27:22 - INFO - __main__ - ['Animal']
06/24/2022 21:27:22 - INFO - __main__ - ['Animal']
06/24/2022 21:27:22 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 21:27:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:27:22 - INFO - __main__ - ['Animal']
06/24/2022 21:27:22 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:27:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:27:22 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:27:22 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 21:27:22 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 21:27:40 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:27:40 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:27:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 21:27:41 - INFO - __main__ - Starting training!
06/24/2022 21:27:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 21:27:45 - INFO - __main__ - Starting training!
06/24/2022 21:27:50 - INFO - __main__ - Step 10 Global step 10 Train loss 6.41 on epoch=0
06/24/2022 21:27:52 - INFO - __main__ - Step 20 Global step 20 Train loss 4.79 on epoch=1
06/24/2022 21:27:55 - INFO - __main__ - Step 30 Global step 30 Train loss 4.09 on epoch=2
06/24/2022 21:27:57 - INFO - __main__ - Step 40 Global step 40 Train loss 3.50 on epoch=2
06/24/2022 21:28:00 - INFO - __main__ - Step 50 Global step 50 Train loss 3.12 on epoch=3
06/24/2022 21:28:05 - INFO - __main__ - Global step 50 Train loss 4.38 Classification-F1 0.055747054082218375 on epoch=3
06/24/2022 21:28:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.055747054082218375 on epoch=3, global_step=50
06/24/2022 21:28:08 - INFO - __main__ - Step 60 Global step 60 Train loss 3.14 on epoch=4
06/24/2022 21:28:10 - INFO - __main__ - Step 70 Global step 70 Train loss 2.36 on epoch=4
06/24/2022 21:28:13 - INFO - __main__ - Step 80 Global step 80 Train loss 2.62 on epoch=5
06/24/2022 21:28:15 - INFO - __main__ - Step 90 Global step 90 Train loss 2.28 on epoch=6
06/24/2022 21:28:18 - INFO - __main__ - Step 100 Global step 100 Train loss 2.05 on epoch=7
06/24/2022 21:28:23 - INFO - __main__ - Global step 100 Train loss 2.49 Classification-F1 0.09451882744739531 on epoch=7
06/24/2022 21:28:23 - INFO - __main__ - Saving model with best Classification-F1: 0.055747054082218375 -> 0.09451882744739531 on epoch=7, global_step=100
06/24/2022 21:28:26 - INFO - __main__ - Step 110 Global step 110 Train loss 1.85 on epoch=7
06/24/2022 21:28:28 - INFO - __main__ - Step 120 Global step 120 Train loss 1.61 on epoch=8
06/24/2022 21:28:31 - INFO - __main__ - Step 130 Global step 130 Train loss 1.82 on epoch=9
06/24/2022 21:28:33 - INFO - __main__ - Step 140 Global step 140 Train loss 1.30 on epoch=9
06/24/2022 21:28:36 - INFO - __main__ - Step 150 Global step 150 Train loss 1.43 on epoch=10
06/24/2022 21:28:42 - INFO - __main__ - Global step 150 Train loss 1.60 Classification-F1 0.16470674364177934 on epoch=10
06/24/2022 21:28:42 - INFO - __main__ - Saving model with best Classification-F1: 0.09451882744739531 -> 0.16470674364177934 on epoch=10, global_step=150
06/24/2022 21:28:44 - INFO - __main__ - Step 160 Global step 160 Train loss 1.14 on epoch=11
06/24/2022 21:28:47 - INFO - __main__ - Step 170 Global step 170 Train loss 1.18 on epoch=12
06/24/2022 21:28:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=12
06/24/2022 21:28:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=13
06/24/2022 21:28:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=14
06/24/2022 21:29:00 - INFO - __main__ - Global step 200 Train loss 1.00 Classification-F1 0.3486989227916647 on epoch=14
06/24/2022 21:29:00 - INFO - __main__ - Saving model with best Classification-F1: 0.16470674364177934 -> 0.3486989227916647 on epoch=14, global_step=200
06/24/2022 21:29:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=14
06/24/2022 21:29:05 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=15
06/24/2022 21:29:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=16
06/24/2022 21:29:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=17
06/24/2022 21:29:13 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=17
06/24/2022 21:29:20 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.4466319622233601 on epoch=17
06/24/2022 21:29:20 - INFO - __main__ - Saving model with best Classification-F1: 0.3486989227916647 -> 0.4466319622233601 on epoch=17, global_step=250
06/24/2022 21:29:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=18
06/24/2022 21:29:25 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=19
06/24/2022 21:29:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=19
06/24/2022 21:29:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=20
06/24/2022 21:29:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=21
06/24/2022 21:29:40 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.670172155384603 on epoch=21
06/24/2022 21:29:40 - INFO - __main__ - Saving model with best Classification-F1: 0.4466319622233601 -> 0.670172155384603 on epoch=21, global_step=300
06/24/2022 21:29:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
06/24/2022 21:29:45 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/24/2022 21:29:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/24/2022 21:29:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
06/24/2022 21:29:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=24
06/24/2022 21:29:59 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.5719662571773578 on epoch=24
06/24/2022 21:30:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/24/2022 21:30:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
06/24/2022 21:30:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=27
06/24/2022 21:30:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/24/2022 21:30:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=28
06/24/2022 21:30:19 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.6473301288411646 on epoch=28
06/24/2022 21:30:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
06/24/2022 21:30:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
06/24/2022 21:30:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/24/2022 21:30:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=31
06/24/2022 21:30:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=32
06/24/2022 21:30:39 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7449807241927485 on epoch=32
06/24/2022 21:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.670172155384603 -> 0.7449807241927485 on epoch=32, global_step=450
06/24/2022 21:30:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
06/24/2022 21:30:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
06/24/2022 21:30:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
06/24/2022 21:30:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/24/2022 21:30:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
06/24/2022 21:30:59 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6885885694959915 on epoch=35
06/24/2022 21:31:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
06/24/2022 21:31:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
06/24/2022 21:31:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
06/24/2022 21:31:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/24/2022 21:31:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
06/24/2022 21:31:19 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.7359820355053961 on epoch=39
06/24/2022 21:31:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
06/24/2022 21:31:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=40
06/24/2022 21:31:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/24/2022 21:31:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/24/2022 21:31:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/24/2022 21:31:39 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.7034766679018735 on epoch=42
06/24/2022 21:31:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
06/24/2022 21:31:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
06/24/2022 21:31:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/24/2022 21:31:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/24/2022 21:31:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/24/2022 21:31:59 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.6967690690374118 on epoch=46
06/24/2022 21:32:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/24/2022 21:32:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/24/2022 21:32:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/24/2022 21:32:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/24/2022 21:32:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/24/2022 21:32:19 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.7443054132123782 on epoch=49
06/24/2022 21:32:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/24/2022 21:32:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/24/2022 21:32:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/24/2022 21:32:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/24/2022 21:32:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
06/24/2022 21:32:39 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.801537262021133 on epoch=53
06/24/2022 21:32:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7449807241927485 -> 0.801537262021133 on epoch=53, global_step=750
06/24/2022 21:32:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
06/24/2022 21:32:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
06/24/2022 21:32:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/24/2022 21:32:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=56
06/24/2022 21:32:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=57
06/24/2022 21:32:59 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7331969032828504 on epoch=57
06/24/2022 21:33:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/24/2022 21:33:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/24/2022 21:33:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/24/2022 21:33:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/24/2022 21:33:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/24/2022 21:33:19 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7292537765479192 on epoch=60
06/24/2022 21:33:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
06/24/2022 21:33:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/24/2022 21:33:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/24/2022 21:33:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/24/2022 21:33:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/24/2022 21:33:38 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7439123849214261 on epoch=64
06/24/2022 21:33:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=64
06/24/2022 21:33:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
06/24/2022 21:33:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/24/2022 21:33:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/24/2022 21:33:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
06/24/2022 21:33:58 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7687596854926386 on epoch=67
06/24/2022 21:34:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/24/2022 21:34:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/24/2022 21:34:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/24/2022 21:34:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/24/2022 21:34:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/24/2022 21:34:18 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7595756651231592 on epoch=71
06/24/2022 21:34:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/24/2022 21:34:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/24/2022 21:34:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
06/24/2022 21:34:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/24/2022 21:34:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/24/2022 21:34:37 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7131551520901616 on epoch=74
06/24/2022 21:34:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/24/2022 21:34:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
06/24/2022 21:34:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/24/2022 21:34:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/24/2022 21:34:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/24/2022 21:34:57 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8006246046805819 on epoch=78
06/24/2022 21:35:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/24/2022 21:35:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/24/2022 21:35:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/24/2022 21:35:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/24/2022 21:35:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/24/2022 21:35:17 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8104760571966997 on epoch=82
06/24/2022 21:35:17 - INFO - __main__ - Saving model with best Classification-F1: 0.801537262021133 -> 0.8104760571966997 on epoch=82, global_step=1150
06/24/2022 21:35:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/24/2022 21:35:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/24/2022 21:35:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/24/2022 21:35:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/24/2022 21:35:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/24/2022 21:35:36 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7909621947795852 on epoch=85
06/24/2022 21:35:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/24/2022 21:35:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/24/2022 21:35:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/24/2022 21:35:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/24/2022 21:35:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/24/2022 21:35:56 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8457467943189005 on epoch=89
06/24/2022 21:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8104760571966997 -> 0.8457467943189005 on epoch=89, global_step=1250
06/24/2022 21:35:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/24/2022 21:36:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/24/2022 21:36:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/24/2022 21:36:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/24/2022 21:36:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/24/2022 21:36:15 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7238471073596522 on epoch=92
06/24/2022 21:36:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/24/2022 21:36:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/24/2022 21:36:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/24/2022 21:36:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/24/2022 21:36:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/24/2022 21:36:35 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6923807870115171 on epoch=96
06/24/2022 21:36:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/24/2022 21:36:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/24/2022 21:36:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/24/2022 21:36:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/24/2022 21:36:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/24/2022 21:36:54 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7364503064627386 on epoch=99
06/24/2022 21:36:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/24/2022 21:36:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/24/2022 21:37:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/24/2022 21:37:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/24/2022 21:37:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/24/2022 21:37:13 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7495238630277563 on epoch=103
06/24/2022 21:37:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/24/2022 21:37:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/24/2022 21:37:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/24/2022 21:37:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/24/2022 21:37:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/24/2022 21:37:32 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7941912609844298 on epoch=107
06/24/2022 21:37:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/24/2022 21:37:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/24/2022 21:37:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/24/2022 21:37:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/24/2022 21:37:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/24/2022 21:37:51 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7319093670558989 on epoch=110
06/24/2022 21:37:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/24/2022 21:37:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/24/2022 21:37:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/24/2022 21:38:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/24/2022 21:38:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/24/2022 21:38:10 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7547913527396903 on epoch=114
06/24/2022 21:38:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/24/2022 21:38:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/24/2022 21:38:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/24/2022 21:38:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/24/2022 21:38:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/24/2022 21:38:29 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.792934220006207 on epoch=117
06/24/2022 21:38:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/24/2022 21:38:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/24/2022 21:38:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/24/2022 21:38:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/24/2022 21:38:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/24/2022 21:38:48 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7977792585226451 on epoch=121
06/24/2022 21:38:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/24/2022 21:38:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/24/2022 21:38:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/24/2022 21:38:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/24/2022 21:39:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/24/2022 21:39:06 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7547913527396903 on epoch=124
06/24/2022 21:39:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/24/2022 21:39:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/24/2022 21:39:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/24/2022 21:39:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/24/2022 21:39:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/24/2022 21:39:25 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7534581886047204 on epoch=128
06/24/2022 21:39:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/24/2022 21:39:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/24/2022 21:39:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/24/2022 21:39:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/24/2022 21:39:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/24/2022 21:39:44 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8630131964809384 on epoch=132
06/24/2022 21:39:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8457467943189005 -> 0.8630131964809384 on epoch=132, global_step=1850
06/24/2022 21:39:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/24/2022 21:39:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/24/2022 21:39:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/24/2022 21:39:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/24/2022 21:39:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/24/2022 21:40:03 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=135
06/24/2022 21:40:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8630131964809384 -> 0.9910627007401202 on epoch=135, global_step=1900
06/24/2022 21:40:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/24/2022 21:40:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/24/2022 21:40:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/24/2022 21:40:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/24/2022 21:40:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/24/2022 21:40:22 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=139
06/24/2022 21:40:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/24/2022 21:40:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/24/2022 21:40:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/24/2022 21:40:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/24/2022 21:40:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/24/2022 21:40:41 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=142
06/24/2022 21:40:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/24/2022 21:40:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/24/2022 21:40:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/24/2022 21:40:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/24/2022 21:40:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/24/2022 21:41:00 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9187894121480459 on epoch=146
06/24/2022 21:41:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/24/2022 21:41:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/24/2022 21:41:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/24/2022 21:41:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/24/2022 21:41:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/24/2022 21:41:20 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=149
06/24/2022 21:41:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/24/2022 21:41:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/24/2022 21:41:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/24/2022 21:41:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/24/2022 21:41:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/24/2022 21:41:39 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=153
06/24/2022 21:41:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/24/2022 21:41:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/24/2022 21:41:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/24/2022 21:41:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/24/2022 21:41:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/24/2022 21:41:58 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=157
06/24/2022 21:42:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/24/2022 21:42:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/24/2022 21:42:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/24/2022 21:42:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/24/2022 21:42:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/24/2022 21:42:17 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=160
06/24/2022 21:42:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/24/2022 21:42:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/24/2022 21:42:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/24/2022 21:42:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/24/2022 21:42:30 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/24/2022 21:42:36 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=164
06/24/2022 21:42:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/24/2022 21:42:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/24/2022 21:42:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/24/2022 21:42:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/24/2022 21:42:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/24/2022 21:42:56 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=167
06/24/2022 21:42:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/24/2022 21:43:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/24/2022 21:43:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/24/2022 21:43:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/24/2022 21:43:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/24/2022 21:43:15 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=171
06/24/2022 21:43:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/24/2022 21:43:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/24/2022 21:43:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/24/2022 21:43:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/24/2022 21:43:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/24/2022 21:43:34 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=174
06/24/2022 21:43:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/24/2022 21:43:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/24/2022 21:43:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/24/2022 21:43:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/24/2022 21:43:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/24/2022 21:43:53 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.9910627007401202 on epoch=178
06/24/2022 21:43:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/24/2022 21:43:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/24/2022 21:44:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/24/2022 21:44:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/24/2022 21:44:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/24/2022 21:44:12 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=182
06/24/2022 21:44:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/24/2022 21:44:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/24/2022 21:44:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/24/2022 21:44:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/24/2022 21:44:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/24/2022 21:44:31 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=185
06/24/2022 21:44:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/24/2022 21:44:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/24/2022 21:44:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/24/2022 21:44:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/24/2022 21:44:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/24/2022 21:44:50 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=189
06/24/2022 21:44:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/24/2022 21:44:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/24/2022 21:44:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/24/2022 21:45:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/24/2022 21:45:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/24/2022 21:45:09 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=192
06/24/2022 21:45:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/24/2022 21:45:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/24/2022 21:45:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/24/2022 21:45:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/24/2022 21:45:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/24/2022 21:45:28 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=196
06/24/2022 21:45:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/24/2022 21:45:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/24/2022 21:45:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/24/2022 21:45:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/24/2022 21:45:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/24/2022 21:45:47 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=199
06/24/2022 21:45:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/24/2022 21:45:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/24/2022 21:45:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/24/2022 21:45:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/24/2022 21:46:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/24/2022 21:46:06 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=203
06/24/2022 21:46:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/24/2022 21:46:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/24/2022 21:46:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/24/2022 21:46:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/24/2022 21:46:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/24/2022 21:46:25 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=207
06/24/2022 21:46:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/24/2022 21:46:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/24/2022 21:46:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/24/2022 21:46:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/24/2022 21:46:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/24/2022 21:46:44 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=210
06/24/2022 21:46:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/24/2022 21:46:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/24/2022 21:46:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/24/2022 21:46:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/24/2022 21:46:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/24/2022 21:46:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:46:59 - INFO - __main__ - Printing 3 examples
06/24/2022 21:46:59 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 21:46:59 - INFO - __main__ - ['Animal']
06/24/2022 21:46:59 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 21:46:59 - INFO - __main__ - ['Animal']
06/24/2022 21:46:59 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 21:46:59 - INFO - __main__ - ['Animal']
06/24/2022 21:46:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:46:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:46:59 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 21:46:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:46:59 - INFO - __main__ - Printing 3 examples
06/24/2022 21:46:59 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 21:46:59 - INFO - __main__ - ['Animal']
06/24/2022 21:46:59 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 21:46:59 - INFO - __main__ - ['Animal']
06/24/2022 21:46:59 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 21:46:59 - INFO - __main__ - ['Animal']
06/24/2022 21:46:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:46:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:46:59 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 21:47:03 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=214
06/24/2022 21:47:03 - INFO - __main__ - save last model!
06/24/2022 21:47:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 21:47:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/24/2022 21:47:04 - INFO - __main__ - Printing 3 examples
06/24/2022 21:47:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/24/2022 21:47:04 - INFO - __main__ - ['Animal']
06/24/2022 21:47:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/24/2022 21:47:04 - INFO - __main__ - ['Animal']
06/24/2022 21:47:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/24/2022 21:47:04 - INFO - __main__ - ['Village']
06/24/2022 21:47:04 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:47:05 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:47:09 - INFO - __main__ - Loaded 3500 examples from test data
06/24/2022 21:47:15 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:47:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 21:47:15 - INFO - __main__ - Starting training!
06/24/2022 21:49:17 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/24/2022 21:49:17 - INFO - __main__ - Classification-F1 on test data: 0.6193
06/24/2022 21:49:17 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6193324386578175
06/24/2022 21:49:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/24/2022 21:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:49:18 - INFO - __main__ - Printing 3 examples
06/24/2022 21:49:18 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 21:49:18 - INFO - __main__ - ['Animal']
06/24/2022 21:49:18 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 21:49:18 - INFO - __main__ - ['Animal']
06/24/2022 21:49:18 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 21:49:18 - INFO - __main__ - ['Animal']
06/24/2022 21:49:18 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:49:18 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:49:19 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 21:49:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 21:49:19 - INFO - __main__ - Printing 3 examples
06/24/2022 21:49:19 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 21:49:19 - INFO - __main__ - ['Animal']
06/24/2022 21:49:19 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 21:49:19 - INFO - __main__ - ['Animal']
06/24/2022 21:49:19 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 21:49:19 - INFO - __main__ - ['Animal']
06/24/2022 21:49:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 21:49:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 21:49:19 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 21:49:34 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 21:49:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 21:49:35 - INFO - __main__ - Starting training!
06/24/2022 21:49:39 - INFO - __main__ - Step 10 Global step 10 Train loss 6.75 on epoch=0
06/24/2022 21:49:42 - INFO - __main__ - Step 20 Global step 20 Train loss 4.82 on epoch=1
06/24/2022 21:49:44 - INFO - __main__ - Step 30 Global step 30 Train loss 4.13 on epoch=2
06/24/2022 21:49:47 - INFO - __main__ - Step 40 Global step 40 Train loss 3.67 on epoch=2
06/24/2022 21:49:49 - INFO - __main__ - Step 50 Global step 50 Train loss 3.50 on epoch=3
06/24/2022 21:49:55 - INFO - __main__ - Global step 50 Train loss 4.57 Classification-F1 0.048410067638512445 on epoch=3
06/24/2022 21:49:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.048410067638512445 on epoch=3, global_step=50
06/24/2022 21:49:57 - INFO - __main__ - Step 60 Global step 60 Train loss 3.36 on epoch=4
06/24/2022 21:50:00 - INFO - __main__ - Step 70 Global step 70 Train loss 2.61 on epoch=4
06/24/2022 21:50:03 - INFO - __main__ - Step 80 Global step 80 Train loss 2.72 on epoch=5
06/24/2022 21:50:05 - INFO - __main__ - Step 90 Global step 90 Train loss 2.53 on epoch=6
06/24/2022 21:50:08 - INFO - __main__ - Step 100 Global step 100 Train loss 2.34 on epoch=7
06/24/2022 21:50:13 - INFO - __main__ - Global step 100 Train loss 2.71 Classification-F1 0.07822048604731117 on epoch=7
06/24/2022 21:50:13 - INFO - __main__ - Saving model with best Classification-F1: 0.048410067638512445 -> 0.07822048604731117 on epoch=7, global_step=100
06/24/2022 21:50:15 - INFO - __main__ - Step 110 Global step 110 Train loss 2.17 on epoch=7
06/24/2022 21:50:18 - INFO - __main__ - Step 120 Global step 120 Train loss 2.01 on epoch=8
06/24/2022 21:50:21 - INFO - __main__ - Step 130 Global step 130 Train loss 2.10 on epoch=9
06/24/2022 21:50:23 - INFO - __main__ - Step 140 Global step 140 Train loss 1.60 on epoch=9
06/24/2022 21:50:26 - INFO - __main__ - Step 150 Global step 150 Train loss 1.85 on epoch=10
06/24/2022 21:50:31 - INFO - __main__ - Global step 150 Train loss 1.95 Classification-F1 0.12276567518503002 on epoch=10
06/24/2022 21:50:31 - INFO - __main__ - Saving model with best Classification-F1: 0.07822048604731117 -> 0.12276567518503002 on epoch=10, global_step=150
06/24/2022 21:50:34 - INFO - __main__ - Step 160 Global step 160 Train loss 1.57 on epoch=11
06/24/2022 21:50:37 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=12
06/24/2022 21:50:39 - INFO - __main__ - Step 180 Global step 180 Train loss 1.24 on epoch=12
06/24/2022 21:50:42 - INFO - __main__ - Step 190 Global step 190 Train loss 1.33 on epoch=13
06/24/2022 21:50:44 - INFO - __main__ - Step 200 Global step 200 Train loss 1.24 on epoch=14
06/24/2022 21:50:50 - INFO - __main__ - Global step 200 Train loss 1.37 Classification-F1 0.2280641554460446 on epoch=14
06/24/2022 21:50:50 - INFO - __main__ - Saving model with best Classification-F1: 0.12276567518503002 -> 0.2280641554460446 on epoch=14, global_step=200
06/24/2022 21:50:53 - INFO - __main__ - Step 210 Global step 210 Train loss 1.05 on epoch=14
06/24/2022 21:50:55 - INFO - __main__ - Step 220 Global step 220 Train loss 1.06 on epoch=15
06/24/2022 21:50:58 - INFO - __main__ - Step 230 Global step 230 Train loss 1.09 on epoch=16
06/24/2022 21:51:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=17
06/24/2022 21:51:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=17
06/24/2022 21:51:09 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.318035515526555 on epoch=17
06/24/2022 21:51:09 - INFO - __main__ - Saving model with best Classification-F1: 0.2280641554460446 -> 0.318035515526555 on epoch=17, global_step=250
06/24/2022 21:51:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=18
06/24/2022 21:51:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.87 on epoch=19
06/24/2022 21:51:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.64 on epoch=19
06/24/2022 21:51:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=20
06/24/2022 21:51:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.55 on epoch=21
06/24/2022 21:51:29 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.4937809347624175 on epoch=21
06/24/2022 21:51:29 - INFO - __main__ - Saving model with best Classification-F1: 0.318035515526555 -> 0.4937809347624175 on epoch=21, global_step=300
06/24/2022 21:51:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=22
06/24/2022 21:51:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.52 on epoch=22
06/24/2022 21:51:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.57 on epoch=23
06/24/2022 21:51:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=24
06/24/2022 21:51:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/24/2022 21:51:49 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.47027648317970905 on epoch=24
06/24/2022 21:51:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=25
06/24/2022 21:51:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=26
06/24/2022 21:51:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=27
06/24/2022 21:51:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=27
06/24/2022 21:52:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
06/24/2022 21:52:09 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.6248441646345972 on epoch=28
06/24/2022 21:52:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4937809347624175 -> 0.6248441646345972 on epoch=28, global_step=400
06/24/2022 21:52:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=29
06/24/2022 21:52:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=29
06/24/2022 21:52:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
06/24/2022 21:52:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=31
06/24/2022 21:52:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=32
06/24/2022 21:52:29 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.585168255963187 on epoch=32
06/24/2022 21:52:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
06/24/2022 21:52:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=33
06/24/2022 21:52:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
06/24/2022 21:52:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/24/2022 21:52:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=35
06/24/2022 21:52:49 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.7150671834139577 on epoch=35
06/24/2022 21:52:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6248441646345972 -> 0.7150671834139577 on epoch=35, global_step=500
06/24/2022 21:52:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
06/24/2022 21:52:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
06/24/2022 21:52:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
06/24/2022 21:52:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=38
06/24/2022 21:53:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
06/24/2022 21:53:09 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.7972759158359284 on epoch=39
06/24/2022 21:53:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7150671834139577 -> 0.7972759158359284 on epoch=39, global_step=550
06/24/2022 21:53:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
06/24/2022 21:53:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=40
06/24/2022 21:53:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
06/24/2022 21:53:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=42
06/24/2022 21:53:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=42
06/24/2022 21:53:30 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.7617300946997342 on epoch=42
06/24/2022 21:53:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=43
06/24/2022 21:53:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=44
06/24/2022 21:53:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
06/24/2022 21:53:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=45
06/24/2022 21:53:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
06/24/2022 21:53:50 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.7203491699459441 on epoch=46
06/24/2022 21:53:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/24/2022 21:53:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
06/24/2022 21:53:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/24/2022 21:54:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/24/2022 21:54:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
06/24/2022 21:54:10 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7505965387132371 on epoch=49
06/24/2022 21:54:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
06/24/2022 21:54:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
06/24/2022 21:54:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
06/24/2022 21:54:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/24/2022 21:54:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
06/24/2022 21:54:31 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.7984175317030016 on epoch=53
06/24/2022 21:54:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7972759158359284 -> 0.7984175317030016 on epoch=53, global_step=750
06/24/2022 21:54:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/24/2022 21:54:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/24/2022 21:54:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/24/2022 21:54:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=56
06/24/2022 21:54:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/24/2022 21:54:51 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.748799751054467 on epoch=57
06/24/2022 21:54:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
06/24/2022 21:54:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
06/24/2022 21:54:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
06/24/2022 21:55:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
06/24/2022 21:55:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/24/2022 21:55:11 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7043236393493255 on epoch=60
06/24/2022 21:55:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/24/2022 21:55:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=62
06/24/2022 21:55:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=62
06/24/2022 21:55:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
06/24/2022 21:55:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
06/24/2022 21:55:32 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7554811314889067 on epoch=64
06/24/2022 21:55:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/24/2022 21:55:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=65
06/24/2022 21:55:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/24/2022 21:55:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/24/2022 21:55:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
06/24/2022 21:55:52 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7471942537380177 on epoch=67
06/24/2022 21:55:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
06/24/2022 21:55:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/24/2022 21:56:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/24/2022 21:56:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/24/2022 21:56:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/24/2022 21:56:13 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7071997648847744 on epoch=71
06/24/2022 21:56:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/24/2022 21:56:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/24/2022 21:56:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/24/2022 21:56:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
06/24/2022 21:56:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/24/2022 21:56:33 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7394221764952316 on epoch=74
06/24/2022 21:56:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/24/2022 21:56:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/24/2022 21:56:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/24/2022 21:56:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/24/2022 21:56:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/24/2022 21:56:53 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.730518198864973 on epoch=78
06/24/2022 21:56:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/24/2022 21:56:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/24/2022 21:57:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/24/2022 21:57:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/24/2022 21:57:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/24/2022 21:57:14 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7709020042985887 on epoch=82
06/24/2022 21:57:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/24/2022 21:57:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/24/2022 21:57:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/24/2022 21:57:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
06/24/2022 21:57:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/24/2022 21:57:34 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8254022858861568 on epoch=85
06/24/2022 21:57:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7984175317030016 -> 0.8254022858861568 on epoch=85, global_step=1200
06/24/2022 21:57:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/24/2022 21:57:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/24/2022 21:57:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/24/2022 21:57:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/24/2022 21:57:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/24/2022 21:57:54 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8275866211587274 on epoch=89
06/24/2022 21:57:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8254022858861568 -> 0.8275866211587274 on epoch=89, global_step=1250
06/24/2022 21:57:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=89
06/24/2022 21:57:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
06/24/2022 21:58:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/24/2022 21:58:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/24/2022 21:58:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/24/2022 21:58:14 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8238452843291553 on epoch=92
06/24/2022 21:58:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/24/2022 21:58:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/24/2022 21:58:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/24/2022 21:58:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/24/2022 21:58:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/24/2022 21:58:34 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7060052235124641 on epoch=96
06/24/2022 21:58:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/24/2022 21:58:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/24/2022 21:58:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/24/2022 21:58:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/24/2022 21:58:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/24/2022 21:58:55 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6032432259148813 on epoch=99
06/24/2022 21:58:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/24/2022 21:59:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/24/2022 21:59:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/24/2022 21:59:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/24/2022 21:59:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/24/2022 21:59:15 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7573139588766333 on epoch=103
06/24/2022 21:59:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/24/2022 21:59:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/24/2022 21:59:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/24/2022 21:59:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/24/2022 21:59:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/24/2022 21:59:35 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7910214700942866 on epoch=107
06/24/2022 21:59:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/24/2022 21:59:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/24/2022 21:59:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/24/2022 21:59:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/24/2022 21:59:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/24/2022 21:59:56 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7496077893185791 on epoch=110
06/24/2022 21:59:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/24/2022 22:00:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/24/2022 22:00:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/24/2022 22:00:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/24/2022 22:00:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/24/2022 22:00:15 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8298847015537058 on epoch=114
06/24/2022 22:00:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8275866211587274 -> 0.8298847015537058 on epoch=114, global_step=1600
06/24/2022 22:00:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/24/2022 22:00:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/24/2022 22:00:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
06/24/2022 22:00:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/24/2022 22:00:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/24/2022 22:00:35 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8264764410162893 on epoch=117
06/24/2022 22:00:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/24/2022 22:00:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/24/2022 22:00:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
06/24/2022 22:00:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/24/2022 22:00:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/24/2022 22:00:55 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.833736990397332 on epoch=121
06/24/2022 22:00:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8298847015537058 -> 0.833736990397332 on epoch=121, global_step=1700
06/24/2022 22:00:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/24/2022 22:01:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/24/2022 22:01:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/24/2022 22:01:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/24/2022 22:01:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/24/2022 22:01:15 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.83069403714565 on epoch=124
06/24/2022 22:01:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/24/2022 22:01:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/24/2022 22:01:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/24/2022 22:01:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/24/2022 22:01:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/24/2022 22:01:34 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9071306381790253 on epoch=128
06/24/2022 22:01:35 - INFO - __main__ - Saving model with best Classification-F1: 0.833736990397332 -> 0.9071306381790253 on epoch=128, global_step=1800
06/24/2022 22:01:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/24/2022 22:01:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/24/2022 22:01:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/24/2022 22:01:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/24/2022 22:01:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/24/2022 22:01:54 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8504081544641318 on epoch=132
06/24/2022 22:01:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/24/2022 22:02:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/24/2022 22:02:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/24/2022 22:02:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/24/2022 22:02:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/24/2022 22:02:14 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8389950883635656 on epoch=135
06/24/2022 22:02:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/24/2022 22:02:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
06/24/2022 22:02:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/24/2022 22:02:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/24/2022 22:02:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/24/2022 22:02:34 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8551700592260365 on epoch=139
06/24/2022 22:02:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/24/2022 22:02:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/24/2022 22:02:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/24/2022 22:02:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/24/2022 22:02:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/24/2022 22:02:53 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.905562622561412 on epoch=142
06/24/2022 22:02:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/24/2022 22:02:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/24/2022 22:03:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/24/2022 22:03:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/24/2022 22:03:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/24/2022 22:03:13 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9098481246410318 on epoch=146
06/24/2022 22:03:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9071306381790253 -> 0.9098481246410318 on epoch=146, global_step=2050
06/24/2022 22:03:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/24/2022 22:03:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/24/2022 22:03:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/24/2022 22:03:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/24/2022 22:03:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/24/2022 22:03:33 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7979195017857257 on epoch=149
06/24/2022 22:03:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/24/2022 22:03:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/24/2022 22:03:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/24/2022 22:03:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/24/2022 22:03:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/24/2022 22:03:52 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9180953022999743 on epoch=153
06/24/2022 22:03:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9098481246410318 -> 0.9180953022999743 on epoch=153, global_step=2150
06/24/2022 22:03:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/24/2022 22:03:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/24/2022 22:04:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/24/2022 22:04:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.19 on epoch=156
06/24/2022 22:04:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/24/2022 22:04:12 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.9180953022999743 on epoch=157
06/24/2022 22:04:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/24/2022 22:04:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/24/2022 22:04:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/24/2022 22:04:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/24/2022 22:04:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/24/2022 22:04:32 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8505463814924797 on epoch=160
06/24/2022 22:04:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/24/2022 22:04:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/24/2022 22:04:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/24/2022 22:04:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/24/2022 22:04:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/24/2022 22:04:51 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8544526314924796 on epoch=164
06/24/2022 22:04:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/24/2022 22:04:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/24/2022 22:04:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/24/2022 22:05:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/24/2022 22:05:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/24/2022 22:05:11 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8569156856796718 on epoch=167
06/24/2022 22:05:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/24/2022 22:05:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/24/2022 22:05:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/24/2022 22:05:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/24/2022 22:05:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/24/2022 22:05:31 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8065088806396911 on epoch=171
06/24/2022 22:05:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/24/2022 22:05:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/24/2022 22:05:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/24/2022 22:05:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/24/2022 22:05:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/24/2022 22:05:52 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9145941387307611 on epoch=174
06/24/2022 22:05:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/24/2022 22:05:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/24/2022 22:05:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/24/2022 22:06:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/24/2022 22:06:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/24/2022 22:06:12 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8592145362543845 on epoch=178
06/24/2022 22:06:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/24/2022 22:06:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/24/2022 22:06:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/24/2022 22:06:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/24/2022 22:06:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/24/2022 22:06:32 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9145941387307611 on epoch=182
06/24/2022 22:06:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/24/2022 22:06:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/24/2022 22:06:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/24/2022 22:06:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/24/2022 22:06:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/24/2022 22:06:52 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9102800299005234 on epoch=185
06/24/2022 22:06:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/24/2022 22:06:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/24/2022 22:07:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/24/2022 22:07:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/24/2022 22:07:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/24/2022 22:07:12 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9164955053380103 on epoch=189
06/24/2022 22:07:14 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/24/2022 22:07:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/24/2022 22:07:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/24/2022 22:07:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/24/2022 22:07:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/24/2022 22:07:31 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=192
06/24/2022 22:07:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/24/2022 22:07:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/24/2022 22:07:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/24/2022 22:07:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/24/2022 22:07:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/24/2022 22:07:51 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9080147298411057 on epoch=196
06/24/2022 22:07:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/24/2022 22:07:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/24/2022 22:07:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/24/2022 22:08:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/24/2022 22:08:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/24/2022 22:08:10 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8504081544641318 on epoch=199
06/24/2022 22:08:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/24/2022 22:08:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/24/2022 22:08:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/24/2022 22:08:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/24/2022 22:08:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/24/2022 22:08:30 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9121813965077723 on epoch=203
06/24/2022 22:08:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/24/2022 22:08:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/24/2022 22:08:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/24/2022 22:08:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/24/2022 22:08:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/24/2022 22:08:49 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9097292892280786 on epoch=207
06/24/2022 22:08:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/24/2022 22:08:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/24/2022 22:08:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/24/2022 22:09:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/24/2022 22:09:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/24/2022 22:09:09 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9205474095796676 on epoch=210
06/24/2022 22:09:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9180953022999743 -> 0.9205474095796676 on epoch=210, global_step=2950
06/24/2022 22:09:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/24/2022 22:09:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/24/2022 22:09:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/24/2022 22:09:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/24/2022 22:09:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/24/2022 22:09:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:09:23 - INFO - __main__ - Printing 3 examples
06/24/2022 22:09:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 22:09:23 - INFO - __main__ - ['Animal']
06/24/2022 22:09:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 22:09:23 - INFO - __main__ - ['Animal']
06/24/2022 22:09:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 22:09:23 - INFO - __main__ - ['Animal']
06/24/2022 22:09:23 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:09:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:09:24 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 22:09:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:09:24 - INFO - __main__ - Printing 3 examples
06/24/2022 22:09:24 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 22:09:24 - INFO - __main__ - ['Animal']
06/24/2022 22:09:24 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 22:09:24 - INFO - __main__ - ['Animal']
06/24/2022 22:09:24 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 22:09:24 - INFO - __main__ - ['Animal']
06/24/2022 22:09:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:09:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:09:24 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 22:09:28 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9144753033178081 on epoch=214
06/24/2022 22:09:28 - INFO - __main__ - save last model!
06/24/2022 22:09:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:09:28 - INFO - __main__ - Start tokenizing ... 3500 instances
06/24/2022 22:09:28 - INFO - __main__ - Printing 3 examples
06/24/2022 22:09:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/24/2022 22:09:28 - INFO - __main__ - ['Animal']
06/24/2022 22:09:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/24/2022 22:09:28 - INFO - __main__ - ['Animal']
06/24/2022 22:09:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/24/2022 22:09:28 - INFO - __main__ - ['Village']
06/24/2022 22:09:28 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:09:30 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:09:34 - INFO - __main__ - Loaded 3500 examples from test data
06/24/2022 22:09:40 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:09:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 22:09:40 - INFO - __main__ - Starting training!
06/24/2022 22:11:45 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/24/2022 22:11:45 - INFO - __main__ - Classification-F1 on test data: 0.5023
06/24/2022 22:11:45 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9205474095796676, test_performance=0.5022728998691975
06/24/2022 22:11:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/24/2022 22:11:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:11:46 - INFO - __main__ - Printing 3 examples
06/24/2022 22:11:46 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 22:11:46 - INFO - __main__ - ['Animal']
06/24/2022 22:11:46 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 22:11:46 - INFO - __main__ - ['Animal']
06/24/2022 22:11:46 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 22:11:46 - INFO - __main__ - ['Animal']
06/24/2022 22:11:46 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:11:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:11:46 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 22:11:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:11:46 - INFO - __main__ - Printing 3 examples
06/24/2022 22:11:46 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 22:11:46 - INFO - __main__ - ['Animal']
06/24/2022 22:11:46 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 22:11:46 - INFO - __main__ - ['Animal']
06/24/2022 22:11:46 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 22:11:46 - INFO - __main__ - ['Animal']
06/24/2022 22:11:46 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:11:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:11:47 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 22:12:02 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:12:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 22:12:03 - INFO - __main__ - Starting training!
06/24/2022 22:12:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=0
06/24/2022 22:12:09 - INFO - __main__ - Step 20 Global step 20 Train loss 5.33 on epoch=1
06/24/2022 22:12:11 - INFO - __main__ - Step 30 Global step 30 Train loss 4.35 on epoch=2
06/24/2022 22:12:14 - INFO - __main__ - Step 40 Global step 40 Train loss 4.10 on epoch=2
06/24/2022 22:12:17 - INFO - __main__ - Step 50 Global step 50 Train loss 3.82 on epoch=3
06/24/2022 22:12:22 - INFO - __main__ - Global step 50 Train loss 4.86 Classification-F1 0.046624106398052444 on epoch=3
06/24/2022 22:12:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.046624106398052444 on epoch=3, global_step=50
06/24/2022 22:12:25 - INFO - __main__ - Step 60 Global step 60 Train loss 3.77 on epoch=4
06/24/2022 22:12:27 - INFO - __main__ - Step 70 Global step 70 Train loss 3.08 on epoch=4
06/24/2022 22:12:30 - INFO - __main__ - Step 80 Global step 80 Train loss 3.35 on epoch=5
06/24/2022 22:12:33 - INFO - __main__ - Step 90 Global step 90 Train loss 2.89 on epoch=6
06/24/2022 22:12:35 - INFO - __main__ - Step 100 Global step 100 Train loss 2.68 on epoch=7
06/24/2022 22:12:40 - INFO - __main__ - Global step 100 Train loss 3.15 Classification-F1 0.05597688557840361 on epoch=7
06/24/2022 22:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.046624106398052444 -> 0.05597688557840361 on epoch=7, global_step=100
06/24/2022 22:12:43 - INFO - __main__ - Step 110 Global step 110 Train loss 2.64 on epoch=7
06/24/2022 22:12:45 - INFO - __main__ - Step 120 Global step 120 Train loss 2.44 on epoch=8
06/24/2022 22:12:48 - INFO - __main__ - Step 130 Global step 130 Train loss 2.62 on epoch=9
06/24/2022 22:12:51 - INFO - __main__ - Step 140 Global step 140 Train loss 2.02 on epoch=9
06/24/2022 22:12:53 - INFO - __main__ - Step 150 Global step 150 Train loss 2.16 on epoch=10
06/24/2022 22:12:59 - INFO - __main__ - Global step 150 Train loss 2.37 Classification-F1 0.0946324369597192 on epoch=10
06/24/2022 22:12:59 - INFO - __main__ - Saving model with best Classification-F1: 0.05597688557840361 -> 0.0946324369597192 on epoch=10, global_step=150
06/24/2022 22:13:01 - INFO - __main__ - Step 160 Global step 160 Train loss 1.93 on epoch=11
06/24/2022 22:13:04 - INFO - __main__ - Step 170 Global step 170 Train loss 1.86 on epoch=12
06/24/2022 22:13:06 - INFO - __main__ - Step 180 Global step 180 Train loss 1.79 on epoch=12
06/24/2022 22:13:09 - INFO - __main__ - Step 190 Global step 190 Train loss 1.66 on epoch=13
06/24/2022 22:13:12 - INFO - __main__ - Step 200 Global step 200 Train loss 1.80 on epoch=14
06/24/2022 22:13:17 - INFO - __main__ - Global step 200 Train loss 1.81 Classification-F1 0.12008373939647393 on epoch=14
06/24/2022 22:13:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0946324369597192 -> 0.12008373939647393 on epoch=14, global_step=200
06/24/2022 22:13:20 - INFO - __main__ - Step 210 Global step 210 Train loss 1.42 on epoch=14
06/24/2022 22:13:22 - INFO - __main__ - Step 220 Global step 220 Train loss 1.60 on epoch=15
06/24/2022 22:13:25 - INFO - __main__ - Step 230 Global step 230 Train loss 1.39 on epoch=16
06/24/2022 22:13:28 - INFO - __main__ - Step 240 Global step 240 Train loss 1.22 on epoch=17
06/24/2022 22:13:30 - INFO - __main__ - Step 250 Global step 250 Train loss 1.19 on epoch=17
06/24/2022 22:13:36 - INFO - __main__ - Global step 250 Train loss 1.36 Classification-F1 0.16965414370630727 on epoch=17
06/24/2022 22:13:36 - INFO - __main__ - Saving model with best Classification-F1: 0.12008373939647393 -> 0.16965414370630727 on epoch=17, global_step=250
06/24/2022 22:13:38 - INFO - __main__ - Step 260 Global step 260 Train loss 1.07 on epoch=18
06/24/2022 22:13:41 - INFO - __main__ - Step 270 Global step 270 Train loss 1.25 on epoch=19
06/24/2022 22:13:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.88 on epoch=19
06/24/2022 22:13:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.99 on epoch=20
06/24/2022 22:13:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.89 on epoch=21
06/24/2022 22:13:54 - INFO - __main__ - Global step 300 Train loss 1.01 Classification-F1 0.2452506802968669 on epoch=21
06/24/2022 22:13:54 - INFO - __main__ - Saving model with best Classification-F1: 0.16965414370630727 -> 0.2452506802968669 on epoch=21, global_step=300
06/24/2022 22:13:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.93 on epoch=22
06/24/2022 22:13:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=22
06/24/2022 22:14:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.79 on epoch=23
06/24/2022 22:14:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.83 on epoch=24
06/24/2022 22:14:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=24
06/24/2022 22:14:14 - INFO - __main__ - Global step 350 Train loss 0.80 Classification-F1 0.37438338018309864 on epoch=24
06/24/2022 22:14:14 - INFO - __main__ - Saving model with best Classification-F1: 0.2452506802968669 -> 0.37438338018309864 on epoch=24, global_step=350
06/24/2022 22:14:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.73 on epoch=25
06/24/2022 22:14:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.62 on epoch=26
06/24/2022 22:14:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.70 on epoch=27
06/24/2022 22:14:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.60 on epoch=27
06/24/2022 22:14:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=28
06/24/2022 22:14:34 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.4903067895060632 on epoch=28
06/24/2022 22:14:34 - INFO - __main__ - Saving model with best Classification-F1: 0.37438338018309864 -> 0.4903067895060632 on epoch=28, global_step=400
06/24/2022 22:14:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
06/24/2022 22:14:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=29
06/24/2022 22:14:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.48 on epoch=30
06/24/2022 22:14:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=31
06/24/2022 22:14:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=32
06/24/2022 22:14:54 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.5812446042225163 on epoch=32
06/24/2022 22:14:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4903067895060632 -> 0.5812446042225163 on epoch=32, global_step=450
06/24/2022 22:14:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=32
06/24/2022 22:14:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=33
06/24/2022 22:15:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=34
06/24/2022 22:15:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=34
06/24/2022 22:15:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=35
06/24/2022 22:15:15 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.6669672239202019 on epoch=35
06/24/2022 22:15:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5812446042225163 -> 0.6669672239202019 on epoch=35, global_step=500
06/24/2022 22:15:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=36
06/24/2022 22:15:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
06/24/2022 22:15:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/24/2022 22:15:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=38
06/24/2022 22:15:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=39
06/24/2022 22:15:35 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.6135350558241072 on epoch=39
06/24/2022 22:15:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
06/24/2022 22:15:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
06/24/2022 22:15:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=41
06/24/2022 22:15:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=42
06/24/2022 22:15:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
06/24/2022 22:15:56 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6080380688572182 on epoch=42
06/24/2022 22:15:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=43
06/24/2022 22:16:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=44
06/24/2022 22:16:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
06/24/2022 22:16:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=45
06/24/2022 22:16:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
06/24/2022 22:16:16 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.6037205213773089 on epoch=46
06/24/2022 22:16:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=47
06/24/2022 22:16:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/24/2022 22:16:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=48
06/24/2022 22:16:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=49
06/24/2022 22:16:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=49
06/24/2022 22:16:37 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.6356028767215826 on epoch=49
06/24/2022 22:16:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=50
06/24/2022 22:16:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=51
06/24/2022 22:16:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/24/2022 22:16:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=52
06/24/2022 22:16:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=53
06/24/2022 22:16:58 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6847315672443007 on epoch=53
06/24/2022 22:16:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6669672239202019 -> 0.6847315672443007 on epoch=53, global_step=750
06/24/2022 22:17:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=54
06/24/2022 22:17:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
06/24/2022 22:17:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/24/2022 22:17:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
06/24/2022 22:17:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=57
06/24/2022 22:17:19 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.6325587947789086 on epoch=57
06/24/2022 22:17:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/24/2022 22:17:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
06/24/2022 22:17:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=59
06/24/2022 22:17:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/24/2022 22:17:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
06/24/2022 22:17:39 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.6251643450635387 on epoch=60
06/24/2022 22:17:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=61
06/24/2022 22:17:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
06/24/2022 22:17:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
06/24/2022 22:17:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=63
06/24/2022 22:17:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
06/24/2022 22:18:00 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.7768872309432082 on epoch=64
06/24/2022 22:18:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6847315672443007 -> 0.7768872309432082 on epoch=64, global_step=900
06/24/2022 22:18:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
06/24/2022 22:18:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=65
06/24/2022 22:18:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/24/2022 22:18:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=67
06/24/2022 22:18:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/24/2022 22:18:22 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.6995785256103093 on epoch=67
06/24/2022 22:18:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
06/24/2022 22:18:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=69
06/24/2022 22:18:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=69
06/24/2022 22:18:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/24/2022 22:18:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/24/2022 22:18:42 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7518046609006714 on epoch=71
06/24/2022 22:18:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=72
06/24/2022 22:18:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/24/2022 22:18:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
06/24/2022 22:18:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
06/24/2022 22:18:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/24/2022 22:19:03 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.8040884224245854 on epoch=74
06/24/2022 22:19:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7768872309432082 -> 0.8040884224245854 on epoch=74, global_step=1050
06/24/2022 22:19:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
06/24/2022 22:19:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
06/24/2022 22:19:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
06/24/2022 22:19:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/24/2022 22:19:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/24/2022 22:19:24 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7600117776770395 on epoch=78
06/24/2022 22:19:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=79
06/24/2022 22:19:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
06/24/2022 22:19:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
06/24/2022 22:19:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/24/2022 22:19:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
06/24/2022 22:19:44 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7647214447010742 on epoch=82
06/24/2022 22:19:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
06/24/2022 22:19:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
06/24/2022 22:19:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=84
06/24/2022 22:19:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
06/24/2022 22:19:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/24/2022 22:20:04 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.7162113137601254 on epoch=85
06/24/2022 22:20:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/24/2022 22:20:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/24/2022 22:20:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/24/2022 22:20:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/24/2022 22:20:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/24/2022 22:20:24 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7729367587987412 on epoch=89
06/24/2022 22:20:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=89
06/24/2022 22:20:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/24/2022 22:20:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/24/2022 22:20:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=92
06/24/2022 22:20:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/24/2022 22:20:45 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.7535871920949674 on epoch=92
06/24/2022 22:20:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/24/2022 22:20:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/24/2022 22:20:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/24/2022 22:20:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/24/2022 22:20:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=96
06/24/2022 22:21:05 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7638852950759971 on epoch=96
06/24/2022 22:21:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/24/2022 22:21:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=97
06/24/2022 22:21:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/24/2022 22:21:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/24/2022 22:21:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/24/2022 22:21:25 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7683670877930839 on epoch=99
06/24/2022 22:21:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/24/2022 22:21:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/24/2022 22:21:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/24/2022 22:21:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/24/2022 22:21:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/24/2022 22:21:45 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.74970735888249 on epoch=103
06/24/2022 22:21:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/24/2022 22:21:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/24/2022 22:21:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=105
06/24/2022 22:21:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/24/2022 22:21:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
06/24/2022 22:22:05 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7921013468926182 on epoch=107
06/24/2022 22:22:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/24/2022 22:22:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
06/24/2022 22:22:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/24/2022 22:22:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/24/2022 22:22:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/24/2022 22:22:25 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.768854974569898 on epoch=110
06/24/2022 22:22:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
06/24/2022 22:22:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/24/2022 22:22:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/24/2022 22:22:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/24/2022 22:22:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/24/2022 22:22:45 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7227642224479669 on epoch=114
06/24/2022 22:22:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/24/2022 22:22:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/24/2022 22:22:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/24/2022 22:22:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/24/2022 22:22:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/24/2022 22:23:06 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7647496604299819 on epoch=117
06/24/2022 22:23:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/24/2022 22:23:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/24/2022 22:23:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/24/2022 22:23:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/24/2022 22:23:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/24/2022 22:23:26 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.8194589566031691 on epoch=121
06/24/2022 22:23:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8040884224245854 -> 0.8194589566031691 on epoch=121, global_step=1700
06/24/2022 22:23:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=122
06/24/2022 22:23:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/24/2022 22:23:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
06/24/2022 22:23:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=124
06/24/2022 22:23:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=124
06/24/2022 22:23:46 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.8146970518412644 on epoch=124
06/24/2022 22:23:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/24/2022 22:23:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/24/2022 22:23:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
06/24/2022 22:23:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/24/2022 22:23:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/24/2022 22:24:05 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.738721816520678 on epoch=128
06/24/2022 22:24:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/24/2022 22:24:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/24/2022 22:24:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/24/2022 22:24:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/24/2022 22:24:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/24/2022 22:24:25 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.772397584184614 on epoch=132
06/24/2022 22:24:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/24/2022 22:24:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/24/2022 22:24:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/24/2022 22:24:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/24/2022 22:24:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/24/2022 22:24:45 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7959967273283491 on epoch=135
06/24/2022 22:24:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/24/2022 22:24:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/24/2022 22:24:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/24/2022 22:24:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/24/2022 22:24:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/24/2022 22:25:05 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7060615846132605 on epoch=139
06/24/2022 22:25:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/24/2022 22:25:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/24/2022 22:25:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/24/2022 22:25:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/24/2022 22:25:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/24/2022 22:25:25 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8468144210169153 on epoch=142
06/24/2022 22:25:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8194589566031691 -> 0.8468144210169153 on epoch=142, global_step=2000
06/24/2022 22:25:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/24/2022 22:25:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
06/24/2022 22:25:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/24/2022 22:25:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/24/2022 22:25:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/24/2022 22:25:45 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8513713989994826 on epoch=146
06/24/2022 22:25:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8468144210169153 -> 0.8513713989994826 on epoch=146, global_step=2050
06/24/2022 22:25:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/24/2022 22:25:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/24/2022 22:25:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/24/2022 22:25:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/24/2022 22:25:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/24/2022 22:26:05 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9144753033178081 on epoch=149
06/24/2022 22:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8513713989994826 -> 0.9144753033178081 on epoch=149, global_step=2100
06/24/2022 22:26:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/24/2022 22:26:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/24/2022 22:26:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/24/2022 22:26:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/24/2022 22:26:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/24/2022 22:26:25 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=153
06/24/2022 22:26:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9144753033178081 -> 0.9910627007401202 on epoch=153, global_step=2150
06/24/2022 22:26:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/24/2022 22:26:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/24/2022 22:26:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/24/2022 22:26:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/24/2022 22:26:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/24/2022 22:26:45 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=157
06/24/2022 22:26:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/24/2022 22:26:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/24/2022 22:26:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/24/2022 22:26:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/24/2022 22:26:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/24/2022 22:27:05 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=160
06/24/2022 22:27:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/24/2022 22:27:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/24/2022 22:27:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/24/2022 22:27:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/24/2022 22:27:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/24/2022 22:27:25 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9185312805474095 on epoch=164
06/24/2022 22:27:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/24/2022 22:27:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/24/2022 22:27:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/24/2022 22:27:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/24/2022 22:27:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/24/2022 22:27:45 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9186746497230369 on epoch=167
06/24/2022 22:27:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/24/2022 22:27:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/24/2022 22:27:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/24/2022 22:27:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/24/2022 22:27:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/24/2022 22:28:05 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=171
06/24/2022 22:28:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/24/2022 22:28:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/24/2022 22:28:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/24/2022 22:28:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/24/2022 22:28:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/24/2022 22:28:25 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=174
06/24/2022 22:28:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/24/2022 22:28:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/24/2022 22:28:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/24/2022 22:28:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/24/2022 22:28:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/24/2022 22:28:45 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=178
06/24/2022 22:28:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/24/2022 22:28:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/24/2022 22:28:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/24/2022 22:28:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/24/2022 22:28:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/24/2022 22:29:05 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9865984150258343 on epoch=182
06/24/2022 22:29:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/24/2022 22:29:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/24/2022 22:29:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/24/2022 22:29:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/24/2022 22:29:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/24/2022 22:29:25 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=185
06/24/2022 22:29:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/24/2022 22:29:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/24/2022 22:29:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/24/2022 22:29:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/24/2022 22:29:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/24/2022 22:29:45 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=189
06/24/2022 22:29:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/24/2022 22:29:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/24/2022 22:29:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/24/2022 22:29:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/24/2022 22:29:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/24/2022 22:30:05 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9820991153059465 on epoch=192
06/24/2022 22:30:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/24/2022 22:30:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/24/2022 22:30:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/24/2022 22:30:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/24/2022 22:30:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/24/2022 22:30:25 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9776348295916607 on epoch=196
06/24/2022 22:30:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/24/2022 22:30:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/24/2022 22:30:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/24/2022 22:30:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/24/2022 22:30:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/24/2022 22:30:45 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=199
06/24/2022 22:30:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/24/2022 22:30:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/24/2022 22:30:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/24/2022 22:30:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/24/2022 22:30:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/24/2022 22:31:05 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=203
06/24/2022 22:31:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/24/2022 22:31:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/24/2022 22:31:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/24/2022 22:31:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/24/2022 22:31:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/24/2022 22:31:24 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8504081544641318 on epoch=207
06/24/2022 22:31:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/24/2022 22:31:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/24/2022 22:31:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/24/2022 22:31:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/24/2022 22:31:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/24/2022 22:31:44 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8553082862543845 on epoch=210
06/24/2022 22:31:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/24/2022 22:31:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/24/2022 22:31:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/24/2022 22:31:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/24/2022 22:31:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/24/2022 22:31:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:31:59 - INFO - __main__ - Printing 3 examples
06/24/2022 22:31:59 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 22:31:59 - INFO - __main__ - ['Animal']
06/24/2022 22:31:59 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 22:31:59 - INFO - __main__ - ['Animal']
06/24/2022 22:31:59 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 22:31:59 - INFO - __main__ - ['Animal']
06/24/2022 22:31:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:31:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:31:59 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 22:31:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:31:59 - INFO - __main__ - Printing 3 examples
06/24/2022 22:31:59 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 22:31:59 - INFO - __main__ - ['Animal']
06/24/2022 22:31:59 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 22:31:59 - INFO - __main__ - ['Animal']
06/24/2022 22:31:59 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 22:31:59 - INFO - __main__ - ['Animal']
06/24/2022 22:31:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:31:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:31:59 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 22:32:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8551822781898684 on epoch=214
06/24/2022 22:32:04 - INFO - __main__ - save last model!
06/24/2022 22:32:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:32:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/24/2022 22:32:04 - INFO - __main__ - Printing 3 examples
06/24/2022 22:32:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/24/2022 22:32:04 - INFO - __main__ - ['Animal']
06/24/2022 22:32:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/24/2022 22:32:04 - INFO - __main__ - ['Animal']
06/24/2022 22:32:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/24/2022 22:32:04 - INFO - __main__ - ['Village']
06/24/2022 22:32:04 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:32:06 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:32:09 - INFO - __main__ - Loaded 3500 examples from test data
06/24/2022 22:32:15 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:32:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 22:32:15 - INFO - __main__ - Starting training!
06/24/2022 22:34:17 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/24/2022 22:34:17 - INFO - __main__ - Classification-F1 on test data: 0.4841
06/24/2022 22:34:17 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9910627007401202, test_performance=0.4841175231209324
06/24/2022 22:34:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/24/2022 22:34:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:34:18 - INFO - __main__ - Printing 3 examples
06/24/2022 22:34:18 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/24/2022 22:34:18 - INFO - __main__ - ['Animal']
06/24/2022 22:34:18 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/24/2022 22:34:18 - INFO - __main__ - ['Animal']
06/24/2022 22:34:18 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/24/2022 22:34:18 - INFO - __main__ - ['Animal']
06/24/2022 22:34:18 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:34:18 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:34:19 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 22:34:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:34:19 - INFO - __main__ - Printing 3 examples
06/24/2022 22:34:19 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/24/2022 22:34:19 - INFO - __main__ - ['Animal']
06/24/2022 22:34:19 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/24/2022 22:34:19 - INFO - __main__ - ['Animal']
06/24/2022 22:34:19 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/24/2022 22:34:19 - INFO - __main__ - ['Animal']
06/24/2022 22:34:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:34:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:34:19 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 22:34:34 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:34:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 22:34:35 - INFO - __main__ - Starting training!
06/24/2022 22:34:39 - INFO - __main__ - Step 10 Global step 10 Train loss 7.74 on epoch=0
06/24/2022 22:34:42 - INFO - __main__ - Step 20 Global step 20 Train loss 6.05 on epoch=1
06/24/2022 22:34:44 - INFO - __main__ - Step 30 Global step 30 Train loss 5.11 on epoch=2
06/24/2022 22:34:47 - INFO - __main__ - Step 40 Global step 40 Train loss 4.53 on epoch=2
06/24/2022 22:34:49 - INFO - __main__ - Step 50 Global step 50 Train loss 4.50 on epoch=3
06/24/2022 22:34:57 - INFO - __main__ - Global step 50 Train loss 5.59 Classification-F1 0.03285668350338797 on epoch=3
06/24/2022 22:34:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03285668350338797 on epoch=3, global_step=50
06/24/2022 22:35:00 - INFO - __main__ - Step 60 Global step 60 Train loss 4.30 on epoch=4
06/24/2022 22:35:03 - INFO - __main__ - Step 70 Global step 70 Train loss 3.53 on epoch=4
06/24/2022 22:35:05 - INFO - __main__ - Step 80 Global step 80 Train loss 3.77 on epoch=5
06/24/2022 22:35:08 - INFO - __main__ - Step 90 Global step 90 Train loss 3.56 on epoch=6
06/24/2022 22:35:10 - INFO - __main__ - Step 100 Global step 100 Train loss 3.33 on epoch=7
06/24/2022 22:35:16 - INFO - __main__ - Global step 100 Train loss 3.70 Classification-F1 0.059627927837658586 on epoch=7
06/24/2022 22:35:16 - INFO - __main__ - Saving model with best Classification-F1: 0.03285668350338797 -> 0.059627927837658586 on epoch=7, global_step=100
06/24/2022 22:35:18 - INFO - __main__ - Step 110 Global step 110 Train loss 3.22 on epoch=7
06/24/2022 22:35:21 - INFO - __main__ - Step 120 Global step 120 Train loss 3.02 on epoch=8
06/24/2022 22:35:23 - INFO - __main__ - Step 130 Global step 130 Train loss 3.11 on epoch=9
06/24/2022 22:35:26 - INFO - __main__ - Step 140 Global step 140 Train loss 2.63 on epoch=9
06/24/2022 22:35:28 - INFO - __main__ - Step 150 Global step 150 Train loss 2.82 on epoch=10
06/24/2022 22:35:34 - INFO - __main__ - Global step 150 Train loss 2.96 Classification-F1 0.05750087476468182 on epoch=10
06/24/2022 22:35:36 - INFO - __main__ - Step 160 Global step 160 Train loss 2.68 on epoch=11
06/24/2022 22:35:39 - INFO - __main__ - Step 170 Global step 170 Train loss 2.37 on epoch=12
06/24/2022 22:35:41 - INFO - __main__ - Step 180 Global step 180 Train loss 2.32 on epoch=12
06/24/2022 22:35:44 - INFO - __main__ - Step 190 Global step 190 Train loss 2.33 on epoch=13
06/24/2022 22:35:46 - INFO - __main__ - Step 200 Global step 200 Train loss 2.49 on epoch=14
06/24/2022 22:35:51 - INFO - __main__ - Global step 200 Train loss 2.44 Classification-F1 0.08551477560127518 on epoch=14
06/24/2022 22:35:51 - INFO - __main__ - Saving model with best Classification-F1: 0.059627927837658586 -> 0.08551477560127518 on epoch=14, global_step=200
06/24/2022 22:35:54 - INFO - __main__ - Step 210 Global step 210 Train loss 2.02 on epoch=14
06/24/2022 22:35:57 - INFO - __main__ - Step 220 Global step 220 Train loss 2.08 on epoch=15
06/24/2022 22:35:59 - INFO - __main__ - Step 230 Global step 230 Train loss 1.99 on epoch=16
06/24/2022 22:36:02 - INFO - __main__ - Step 240 Global step 240 Train loss 1.93 on epoch=17
06/24/2022 22:36:04 - INFO - __main__ - Step 250 Global step 250 Train loss 1.90 on epoch=17
06/24/2022 22:36:10 - INFO - __main__ - Global step 250 Train loss 1.98 Classification-F1 0.09999875619570017 on epoch=17
06/24/2022 22:36:10 - INFO - __main__ - Saving model with best Classification-F1: 0.08551477560127518 -> 0.09999875619570017 on epoch=17, global_step=250
06/24/2022 22:36:12 - INFO - __main__ - Step 260 Global step 260 Train loss 1.81 on epoch=18
06/24/2022 22:36:15 - INFO - __main__ - Step 270 Global step 270 Train loss 1.92 on epoch=19
06/24/2022 22:36:18 - INFO - __main__ - Step 280 Global step 280 Train loss 1.49 on epoch=19
06/24/2022 22:36:20 - INFO - __main__ - Step 290 Global step 290 Train loss 1.62 on epoch=20
06/24/2022 22:36:23 - INFO - __main__ - Step 300 Global step 300 Train loss 1.49 on epoch=21
06/24/2022 22:36:28 - INFO - __main__ - Global step 300 Train loss 1.66 Classification-F1 0.13203403108426578 on epoch=21
06/24/2022 22:36:28 - INFO - __main__ - Saving model with best Classification-F1: 0.09999875619570017 -> 0.13203403108426578 on epoch=21, global_step=300
06/24/2022 22:36:31 - INFO - __main__ - Step 310 Global step 310 Train loss 1.46 on epoch=22
06/24/2022 22:36:33 - INFO - __main__ - Step 320 Global step 320 Train loss 1.37 on epoch=22
06/24/2022 22:36:36 - INFO - __main__ - Step 330 Global step 330 Train loss 1.41 on epoch=23
06/24/2022 22:36:39 - INFO - __main__ - Step 340 Global step 340 Train loss 1.50 on epoch=24
06/24/2022 22:36:41 - INFO - __main__ - Step 350 Global step 350 Train loss 1.12 on epoch=24
06/24/2022 22:36:47 - INFO - __main__ - Global step 350 Train loss 1.37 Classification-F1 0.17223682651343675 on epoch=24
06/24/2022 22:36:47 - INFO - __main__ - Saving model with best Classification-F1: 0.13203403108426578 -> 0.17223682651343675 on epoch=24, global_step=350
06/24/2022 22:36:49 - INFO - __main__ - Step 360 Global step 360 Train loss 1.26 on epoch=25
06/24/2022 22:36:52 - INFO - __main__ - Step 370 Global step 370 Train loss 1.20 on epoch=26
06/24/2022 22:36:54 - INFO - __main__ - Step 380 Global step 380 Train loss 1.25 on epoch=27
06/24/2022 22:36:57 - INFO - __main__ - Step 390 Global step 390 Train loss 1.06 on epoch=27
06/24/2022 22:37:00 - INFO - __main__ - Step 400 Global step 400 Train loss 1.12 on epoch=28
06/24/2022 22:37:05 - INFO - __main__ - Global step 400 Train loss 1.18 Classification-F1 0.2681742632108165 on epoch=28
06/24/2022 22:37:05 - INFO - __main__ - Saving model with best Classification-F1: 0.17223682651343675 -> 0.2681742632108165 on epoch=28, global_step=400
06/24/2022 22:37:08 - INFO - __main__ - Step 410 Global step 410 Train loss 1.23 on epoch=29
06/24/2022 22:37:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.91 on epoch=29
06/24/2022 22:37:13 - INFO - __main__ - Step 430 Global step 430 Train loss 1.02 on epoch=30
06/24/2022 22:37:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.97 on epoch=31
06/24/2022 22:37:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.84 on epoch=32
06/24/2022 22:37:24 - INFO - __main__ - Global step 450 Train loss 0.99 Classification-F1 0.3091039151725454 on epoch=32
06/24/2022 22:37:24 - INFO - __main__ - Saving model with best Classification-F1: 0.2681742632108165 -> 0.3091039151725454 on epoch=32, global_step=450
06/24/2022 22:37:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.81 on epoch=32
06/24/2022 22:37:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.94 on epoch=33
06/24/2022 22:37:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.92 on epoch=34
06/24/2022 22:37:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=34
06/24/2022 22:37:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.78 on epoch=35
06/24/2022 22:37:44 - INFO - __main__ - Global step 500 Train loss 0.83 Classification-F1 0.40719930223299977 on epoch=35
06/24/2022 22:37:44 - INFO - __main__ - Saving model with best Classification-F1: 0.3091039151725454 -> 0.40719930223299977 on epoch=35, global_step=500
06/24/2022 22:37:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.82 on epoch=36
06/24/2022 22:37:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.70 on epoch=37
06/24/2022 22:37:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=37
06/24/2022 22:37:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.72 on epoch=38
06/24/2022 22:37:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.73 on epoch=39
06/24/2022 22:38:03 - INFO - __main__ - Global step 550 Train loss 0.72 Classification-F1 0.4310953706995995 on epoch=39
06/24/2022 22:38:04 - INFO - __main__ - Saving model with best Classification-F1: 0.40719930223299977 -> 0.4310953706995995 on epoch=39, global_step=550
06/24/2022 22:38:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.51 on epoch=39
06/24/2022 22:38:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.57 on epoch=40
06/24/2022 22:38:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.56 on epoch=41
06/24/2022 22:38:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.57 on epoch=42
06/24/2022 22:38:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.57 on epoch=42
06/24/2022 22:38:23 - INFO - __main__ - Global step 600 Train loss 0.55 Classification-F1 0.46775180479296163 on epoch=42
06/24/2022 22:38:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4310953706995995 -> 0.46775180479296163 on epoch=42, global_step=600
06/24/2022 22:38:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.48 on epoch=43
06/24/2022 22:38:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.51 on epoch=44
06/24/2022 22:38:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.51 on epoch=44
06/24/2022 22:38:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.57 on epoch=45
06/24/2022 22:38:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=46
06/24/2022 22:38:43 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.4950998671482543 on epoch=46
06/24/2022 22:38:43 - INFO - __main__ - Saving model with best Classification-F1: 0.46775180479296163 -> 0.4950998671482543 on epoch=46, global_step=650
06/24/2022 22:38:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
06/24/2022 22:38:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.52 on epoch=47
06/24/2022 22:38:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.44 on epoch=48
06/24/2022 22:38:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=49
06/24/2022 22:38:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=49
06/24/2022 22:39:03 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.5202420243133982 on epoch=49
06/24/2022 22:39:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4950998671482543 -> 0.5202420243133982 on epoch=49, global_step=700
06/24/2022 22:39:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.51 on epoch=50
06/24/2022 22:39:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=51
06/24/2022 22:39:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.43 on epoch=52
06/24/2022 22:39:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=52
06/24/2022 22:39:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/24/2022 22:39:23 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.640537308263327 on epoch=53
06/24/2022 22:39:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5202420243133982 -> 0.640537308263327 on epoch=53, global_step=750
06/24/2022 22:39:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.44 on epoch=54
06/24/2022 22:39:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=54
06/24/2022 22:39:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.49 on epoch=55
06/24/2022 22:39:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=56
06/24/2022 22:39:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.46 on epoch=57
06/24/2022 22:39:43 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.6684750115154775 on epoch=57
06/24/2022 22:39:44 - INFO - __main__ - Saving model with best Classification-F1: 0.640537308263327 -> 0.6684750115154775 on epoch=57, global_step=800
06/24/2022 22:39:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
06/24/2022 22:39:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.45 on epoch=58
06/24/2022 22:39:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=59
06/24/2022 22:39:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.30 on epoch=59
06/24/2022 22:39:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=60
06/24/2022 22:40:04 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.711759899490548 on epoch=60
06/24/2022 22:40:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6684750115154775 -> 0.711759899490548 on epoch=60, global_step=850
06/24/2022 22:40:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.41 on epoch=61
06/24/2022 22:40:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.43 on epoch=62
06/24/2022 22:40:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=62
06/24/2022 22:40:14 - INFO - __main__ - Step 890 Global step 890 Train loss 0.39 on epoch=63
06/24/2022 22:40:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=64
06/24/2022 22:40:24 - INFO - __main__ - Global step 900 Train loss 0.37 Classification-F1 0.673673236585244 on epoch=64
06/24/2022 22:40:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.39 on epoch=64
06/24/2022 22:40:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=65
06/24/2022 22:40:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.34 on epoch=66
06/24/2022 22:40:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=67
06/24/2022 22:40:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=67
06/24/2022 22:40:44 - INFO - __main__ - Global step 950 Train loss 0.33 Classification-F1 0.6760437567525853 on epoch=67
06/24/2022 22:40:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.40 on epoch=68
06/24/2022 22:40:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
06/24/2022 22:40:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=69
06/24/2022 22:40:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=70
06/24/2022 22:40:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=71
06/24/2022 22:41:05 - INFO - __main__ - Global step 1000 Train loss 0.29 Classification-F1 0.630777295653956 on epoch=71
06/24/2022 22:41:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.36 on epoch=72
06/24/2022 22:41:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=72
06/24/2022 22:41:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.33 on epoch=73
06/24/2022 22:41:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=74
06/24/2022 22:41:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=74
06/24/2022 22:41:25 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.6642483864349098 on epoch=74
06/24/2022 22:41:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.33 on epoch=75
06/24/2022 22:41:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=76
06/24/2022 22:41:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.33 on epoch=77
06/24/2022 22:41:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=77
06/24/2022 22:41:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=78
06/24/2022 22:41:46 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.674182829447404 on epoch=78
06/24/2022 22:41:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=79
06/24/2022 22:41:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=79
06/24/2022 22:41:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.22 on epoch=80
06/24/2022 22:41:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/24/2022 22:41:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=82
06/24/2022 22:42:06 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.7162113137601254 on epoch=82
06/24/2022 22:42:07 - INFO - __main__ - Saving model with best Classification-F1: 0.711759899490548 -> 0.7162113137601254 on epoch=82, global_step=1150
06/24/2022 22:42:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=82
06/24/2022 22:42:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.28 on epoch=83
06/24/2022 22:42:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=84
06/24/2022 22:42:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=84
06/24/2022 22:42:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/24/2022 22:42:27 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.7590911480633196 on epoch=85
06/24/2022 22:42:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7162113137601254 -> 0.7590911480633196 on epoch=85, global_step=1200
06/24/2022 22:42:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=86
06/24/2022 22:42:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.21 on epoch=87
06/24/2022 22:42:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=87
06/24/2022 22:42:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/24/2022 22:42:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=89
06/24/2022 22:42:48 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.7566289076725509 on epoch=89
06/24/2022 22:42:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/24/2022 22:42:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=90
06/24/2022 22:42:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.21 on epoch=91
06/24/2022 22:42:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.26 on epoch=92
06/24/2022 22:43:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=92
06/24/2022 22:43:09 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.711384580151772 on epoch=92
06/24/2022 22:43:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
06/24/2022 22:43:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=94
06/24/2022 22:43:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=94
06/24/2022 22:43:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=95
06/24/2022 22:43:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/24/2022 22:43:29 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.7929890037026541 on epoch=96
06/24/2022 22:43:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7590911480633196 -> 0.7929890037026541 on epoch=96, global_step=1350
06/24/2022 22:43:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
06/24/2022 22:43:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.25 on epoch=97
06/24/2022 22:43:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=98
06/24/2022 22:43:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
06/24/2022 22:43:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=99
06/24/2022 22:43:50 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.744445058513314 on epoch=99
06/24/2022 22:43:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.23 on epoch=100
06/24/2022 22:43:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=101
06/24/2022 22:43:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=102
06/24/2022 22:44:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/24/2022 22:44:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=103
06/24/2022 22:44:11 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.7402738385131042 on epoch=103
06/24/2022 22:44:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=104
06/24/2022 22:44:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.19 on epoch=104
06/24/2022 22:44:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
06/24/2022 22:44:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.20 on epoch=106
06/24/2022 22:44:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=107
06/24/2022 22:44:31 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.7845286428141126 on epoch=107
06/24/2022 22:44:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/24/2022 22:44:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.22 on epoch=108
06/24/2022 22:44:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=109
06/24/2022 22:44:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.17 on epoch=109
06/24/2022 22:44:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/24/2022 22:44:52 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.7354874647806336 on epoch=110
06/24/2022 22:44:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=111
06/24/2022 22:44:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.17 on epoch=112
06/24/2022 22:45:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=112
06/24/2022 22:45:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.18 on epoch=113
06/24/2022 22:45:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=114
06/24/2022 22:45:12 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7041193909833124 on epoch=114
06/24/2022 22:45:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.20 on epoch=114
06/24/2022 22:45:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.20 on epoch=115
06/24/2022 22:45:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
06/24/2022 22:45:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=117
06/24/2022 22:45:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=117
06/24/2022 22:45:33 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.7504774274726278 on epoch=117
06/24/2022 22:45:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=118
06/24/2022 22:45:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.15 on epoch=119
06/24/2022 22:45:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=119
06/24/2022 22:45:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
06/24/2022 22:45:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
06/24/2022 22:45:53 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.7591056878583096 on epoch=121
06/24/2022 22:45:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
06/24/2022 22:45:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=122
06/24/2022 22:46:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
06/24/2022 22:46:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=124
06/24/2022 22:46:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.19 on epoch=124
06/24/2022 22:46:14 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.7702535243144951 on epoch=124
06/24/2022 22:46:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.17 on epoch=125
06/24/2022 22:46:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
06/24/2022 22:46:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.23 on epoch=127
06/24/2022 22:46:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=127
06/24/2022 22:46:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.18 on epoch=128
06/24/2022 22:46:34 - INFO - __main__ - Global step 1800 Train loss 0.17 Classification-F1 0.7407315596459094 on epoch=128
06/24/2022 22:46:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=129
06/24/2022 22:46:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/24/2022 22:46:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/24/2022 22:46:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/24/2022 22:46:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=132
06/24/2022 22:46:54 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.7476519748708228 on epoch=132
06/24/2022 22:46:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/24/2022 22:46:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/24/2022 22:47:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
06/24/2022 22:47:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/24/2022 22:47:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=135
06/24/2022 22:47:14 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.7561578677551443 on epoch=135
06/24/2022 22:47:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=136
06/24/2022 22:47:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.20 on epoch=137
06/24/2022 22:47:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
06/24/2022 22:47:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=138
06/24/2022 22:47:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.18 on epoch=139
06/24/2022 22:47:35 - INFO - __main__ - Global step 1950 Train loss 0.15 Classification-F1 0.7781950385812424 on epoch=139
06/24/2022 22:47:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/24/2022 22:47:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
06/24/2022 22:47:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/24/2022 22:47:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/24/2022 22:47:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=142
06/24/2022 22:47:55 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.7781950385812424 on epoch=142
06/24/2022 22:47:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=143
06/24/2022 22:48:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=144
06/24/2022 22:48:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/24/2022 22:48:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/24/2022 22:48:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/24/2022 22:48:15 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.7704373619107995 on epoch=146
06/24/2022 22:48:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=147
06/24/2022 22:48:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/24/2022 22:48:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/24/2022 22:48:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=149
06/24/2022 22:48:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=149
06/24/2022 22:48:35 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.7721314366698896 on epoch=149
06/24/2022 22:48:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=150
06/24/2022 22:48:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/24/2022 22:48:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=152
06/24/2022 22:48:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/24/2022 22:48:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.14 on epoch=153
06/24/2022 22:48:55 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.770637505764194 on epoch=153
06/24/2022 22:48:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.16 on epoch=154
06/24/2022 22:49:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/24/2022 22:49:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/24/2022 22:49:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/24/2022 22:49:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.19 on epoch=157
06/24/2022 22:49:15 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.7821645408206408 on epoch=157
06/24/2022 22:49:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/24/2022 22:49:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.11 on epoch=158
06/24/2022 22:49:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=159
06/24/2022 22:49:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=159
06/24/2022 22:49:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/24/2022 22:49:35 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.7323136488221877 on epoch=160
06/24/2022 22:49:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/24/2022 22:49:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=162
06/24/2022 22:49:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
06/24/2022 22:49:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/24/2022 22:49:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=164
06/24/2022 22:49:55 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.7702530382516988 on epoch=164
06/24/2022 22:49:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=164
06/24/2022 22:50:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/24/2022 22:50:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/24/2022 22:50:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/24/2022 22:50:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
06/24/2022 22:50:15 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7387109552194941 on epoch=167
06/24/2022 22:50:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.13 on epoch=168
06/24/2022 22:50:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
06/24/2022 22:50:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=169
06/24/2022 22:50:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/24/2022 22:50:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/24/2022 22:50:35 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.787667137116076 on epoch=171
06/24/2022 22:50:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
06/24/2022 22:50:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=172
06/24/2022 22:50:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/24/2022 22:50:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/24/2022 22:50:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/24/2022 22:50:55 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7488119653205042 on epoch=174
06/24/2022 22:50:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/24/2022 22:51:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/24/2022 22:51:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=177
06/24/2022 22:51:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/24/2022 22:51:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/24/2022 22:51:15 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8488237173958237 on epoch=178
06/24/2022 22:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7929890037026541 -> 0.8488237173958237 on epoch=178, global_step=2500
06/24/2022 22:51:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/24/2022 22:51:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=179
06/24/2022 22:51:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=180
06/24/2022 22:51:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.14 on epoch=181
06/24/2022 22:51:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/24/2022 22:51:34 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.795892128112242 on epoch=182
06/24/2022 22:51:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/24/2022 22:51:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=183
06/24/2022 22:51:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.10 on epoch=184
06/24/2022 22:51:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/24/2022 22:51:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/24/2022 22:51:55 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7988929104901871 on epoch=185
06/24/2022 22:51:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/24/2022 22:52:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=187
06/24/2022 22:52:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/24/2022 22:52:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/24/2022 22:52:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/24/2022 22:52:14 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7526222209689952 on epoch=189
06/24/2022 22:52:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=189
06/24/2022 22:52:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/24/2022 22:52:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=191
06/24/2022 22:52:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/24/2022 22:52:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/24/2022 22:52:34 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7138024944676298 on epoch=192
06/24/2022 22:52:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/24/2022 22:52:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/24/2022 22:52:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/24/2022 22:52:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=195
06/24/2022 22:52:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/24/2022 22:52:54 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.7088122410563238 on epoch=196
06/24/2022 22:52:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
06/24/2022 22:52:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/24/2022 22:53:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/24/2022 22:53:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/24/2022 22:53:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/24/2022 22:53:13 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.801354468147637 on epoch=199
06/24/2022 22:53:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/24/2022 22:53:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=201
06/24/2022 22:53:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/24/2022 22:53:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/24/2022 22:53:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/24/2022 22:53:33 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7976527563088563 on epoch=203
06/24/2022 22:53:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=204
06/24/2022 22:53:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/24/2022 22:53:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/24/2022 22:53:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/24/2022 22:53:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=207
06/24/2022 22:53:52 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7988929104901871 on epoch=207
06/24/2022 22:53:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/24/2022 22:53:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/24/2022 22:54:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/24/2022 22:54:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/24/2022 22:54:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/24/2022 22:54:12 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.8062890238510209 on epoch=210
06/24/2022 22:54:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/24/2022 22:54:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/24/2022 22:54:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/24/2022 22:54:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/24/2022 22:54:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/24/2022 22:54:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:54:26 - INFO - __main__ - Printing 3 examples
06/24/2022 22:54:26 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/24/2022 22:54:26 - INFO - __main__ - ['Animal']
06/24/2022 22:54:26 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/24/2022 22:54:26 - INFO - __main__ - ['Animal']
06/24/2022 22:54:26 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/24/2022 22:54:26 - INFO - __main__ - ['Animal']
06/24/2022 22:54:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:54:26 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:54:27 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 22:54:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:54:27 - INFO - __main__ - Printing 3 examples
06/24/2022 22:54:27 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/24/2022 22:54:27 - INFO - __main__ - ['Animal']
06/24/2022 22:54:27 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/24/2022 22:54:27 - INFO - __main__ - ['Animal']
06/24/2022 22:54:27 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/24/2022 22:54:27 - INFO - __main__ - ['Animal']
06/24/2022 22:54:27 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:54:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:54:27 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 22:54:31 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=214
06/24/2022 22:54:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8488237173958237 -> 0.9228413163897036 on epoch=214, global_step=3000
06/24/2022 22:54:31 - INFO - __main__ - save last model!
06/24/2022 22:54:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 22:54:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/24/2022 22:54:32 - INFO - __main__ - Printing 3 examples
06/24/2022 22:54:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/24/2022 22:54:32 - INFO - __main__ - ['Animal']
06/24/2022 22:54:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/24/2022 22:54:32 - INFO - __main__ - ['Animal']
06/24/2022 22:54:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/24/2022 22:54:32 - INFO - __main__ - ['Village']
06/24/2022 22:54:32 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:54:34 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:54:37 - INFO - __main__ - Loaded 3500 examples from test data
06/24/2022 22:54:46 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:54:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 22:54:47 - INFO - __main__ - Starting training!
06/24/2022 22:56:48 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/24/2022 22:56:48 - INFO - __main__ - Classification-F1 on test data: 0.3880
06/24/2022 22:56:49 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9228413163897036, test_performance=0.38803063585559605
06/24/2022 22:56:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/24/2022 22:56:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:56:50 - INFO - __main__ - Printing 3 examples
06/24/2022 22:56:50 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/24/2022 22:56:50 - INFO - __main__ - ['Animal']
06/24/2022 22:56:50 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/24/2022 22:56:50 - INFO - __main__ - ['Animal']
06/24/2022 22:56:50 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/24/2022 22:56:50 - INFO - __main__ - ['Animal']
06/24/2022 22:56:50 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:56:50 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:56:50 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 22:56:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 22:56:50 - INFO - __main__ - Printing 3 examples
06/24/2022 22:56:50 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/24/2022 22:56:50 - INFO - __main__ - ['Animal']
06/24/2022 22:56:50 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/24/2022 22:56:50 - INFO - __main__ - ['Animal']
06/24/2022 22:56:50 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/24/2022 22:56:50 - INFO - __main__ - ['Animal']
06/24/2022 22:56:50 - INFO - __main__ - Tokenizing Input ...
06/24/2022 22:56:50 - INFO - __main__ - Tokenizing Output ...
06/24/2022 22:56:51 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 22:57:06 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 22:57:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 22:57:07 - INFO - __main__ - Starting training!
06/24/2022 22:57:10 - INFO - __main__ - Step 10 Global step 10 Train loss 6.06 on epoch=0
06/24/2022 22:57:13 - INFO - __main__ - Step 20 Global step 20 Train loss 4.69 on epoch=1
06/24/2022 22:57:16 - INFO - __main__ - Step 30 Global step 30 Train loss 3.92 on epoch=2
06/24/2022 22:57:18 - INFO - __main__ - Step 40 Global step 40 Train loss 3.39 on epoch=2
06/24/2022 22:57:21 - INFO - __main__ - Step 50 Global step 50 Train loss 3.08 on epoch=3
06/24/2022 22:57:26 - INFO - __main__ - Global step 50 Train loss 4.23 Classification-F1 0.06319889953169525 on epoch=3
06/24/2022 22:57:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06319889953169525 on epoch=3, global_step=50
06/24/2022 22:57:28 - INFO - __main__ - Step 60 Global step 60 Train loss 2.83 on epoch=4
06/24/2022 22:57:31 - INFO - __main__ - Step 70 Global step 70 Train loss 2.56 on epoch=4
06/24/2022 22:57:34 - INFO - __main__ - Step 80 Global step 80 Train loss 2.29 on epoch=5
06/24/2022 22:57:36 - INFO - __main__ - Step 90 Global step 90 Train loss 2.15 on epoch=6
06/24/2022 22:57:39 - INFO - __main__ - Step 100 Global step 100 Train loss 2.00 on epoch=7
06/24/2022 22:57:44 - INFO - __main__ - Global step 100 Train loss 2.37 Classification-F1 0.08583729171212019 on epoch=7
06/24/2022 22:57:44 - INFO - __main__ - Saving model with best Classification-F1: 0.06319889953169525 -> 0.08583729171212019 on epoch=7, global_step=100
06/24/2022 22:57:47 - INFO - __main__ - Step 110 Global step 110 Train loss 1.82 on epoch=7
06/24/2022 22:57:49 - INFO - __main__ - Step 120 Global step 120 Train loss 1.75 on epoch=8
06/24/2022 22:57:52 - INFO - __main__ - Step 130 Global step 130 Train loss 1.48 on epoch=9
06/24/2022 22:57:55 - INFO - __main__ - Step 140 Global step 140 Train loss 1.36 on epoch=9
06/24/2022 22:57:57 - INFO - __main__ - Step 150 Global step 150 Train loss 1.28 on epoch=10
06/24/2022 22:58:03 - INFO - __main__ - Global step 150 Train loss 1.54 Classification-F1 0.1228132415487465 on epoch=10
06/24/2022 22:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.08583729171212019 -> 0.1228132415487465 on epoch=10, global_step=150
06/24/2022 22:58:05 - INFO - __main__ - Step 160 Global step 160 Train loss 1.12 on epoch=11
06/24/2022 22:58:08 - INFO - __main__ - Step 170 Global step 170 Train loss 1.08 on epoch=12
06/24/2022 22:58:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=12
06/24/2022 22:58:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=13
06/24/2022 22:58:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=14
06/24/2022 22:58:22 - INFO - __main__ - Global step 200 Train loss 0.94 Classification-F1 0.3161812103101035 on epoch=14
06/24/2022 22:58:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1228132415487465 -> 0.3161812103101035 on epoch=14, global_step=200
06/24/2022 22:58:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.66 on epoch=14
06/24/2022 22:58:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.70 on epoch=15
06/24/2022 22:58:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=16
06/24/2022 22:58:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=17
06/24/2022 22:58:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.62 on epoch=17
06/24/2022 22:58:42 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.34400802478944853 on epoch=17
06/24/2022 22:58:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3161812103101035 -> 0.34400802478944853 on epoch=17, global_step=250
06/24/2022 22:58:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=18
06/24/2022 22:58:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=19
06/24/2022 22:58:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=19
06/24/2022 22:58:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.46 on epoch=20
06/24/2022 22:58:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
06/24/2022 22:59:02 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.5183094741986932 on epoch=21
06/24/2022 22:59:02 - INFO - __main__ - Saving model with best Classification-F1: 0.34400802478944853 -> 0.5183094741986932 on epoch=21, global_step=300
06/24/2022 22:59:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=22
06/24/2022 22:59:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/24/2022 22:59:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
06/24/2022 22:59:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=24
06/24/2022 22:59:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=24
06/24/2022 22:59:22 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.5201207616352304 on epoch=24
06/24/2022 22:59:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5183094741986932 -> 0.5201207616352304 on epoch=24, global_step=350
06/24/2022 22:59:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/24/2022 22:59:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=26
06/24/2022 22:59:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=27
06/24/2022 22:59:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/24/2022 22:59:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
06/24/2022 22:59:43 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6389184088365777 on epoch=28
06/24/2022 22:59:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5201207616352304 -> 0.6389184088365777 on epoch=28, global_step=400
06/24/2022 22:59:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
06/24/2022 22:59:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=29
06/24/2022 22:59:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
06/24/2022 22:59:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/24/2022 22:59:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/24/2022 23:00:03 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.6098611513934094 on epoch=32
06/24/2022 23:00:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
06/24/2022 23:00:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=33
06/24/2022 23:00:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
06/24/2022 23:00:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/24/2022 23:00:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
06/24/2022 23:00:24 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.613300051203277 on epoch=35
06/24/2022 23:00:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/24/2022 23:00:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=37
06/24/2022 23:00:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
06/24/2022 23:00:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/24/2022 23:00:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
06/24/2022 23:00:44 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.608025004002733 on epoch=39
06/24/2022 23:00:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/24/2022 23:00:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=40
06/24/2022 23:00:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/24/2022 23:00:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/24/2022 23:00:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/24/2022 23:01:05 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.744809247977629 on epoch=42
06/24/2022 23:01:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6389184088365777 -> 0.744809247977629 on epoch=42, global_step=600
06/24/2022 23:01:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
06/24/2022 23:01:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
06/24/2022 23:01:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=44
06/24/2022 23:01:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/24/2022 23:01:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=46
06/24/2022 23:01:25 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6929544096882806 on epoch=46
06/24/2022 23:01:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
06/24/2022 23:01:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/24/2022 23:01:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/24/2022 23:01:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/24/2022 23:01:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
06/24/2022 23:01:46 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6893593189964159 on epoch=49
06/24/2022 23:01:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
06/24/2022 23:01:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
06/24/2022 23:01:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/24/2022 23:01:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/24/2022 23:01:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/24/2022 23:02:06 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.8026756985174324 on epoch=53
06/24/2022 23:02:06 - INFO - __main__ - Saving model with best Classification-F1: 0.744809247977629 -> 0.8026756985174324 on epoch=53, global_step=750
06/24/2022 23:02:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
06/24/2022 23:02:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/24/2022 23:02:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/24/2022 23:02:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
06/24/2022 23:02:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
06/24/2022 23:02:26 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.7800622448392848 on epoch=57
06/24/2022 23:02:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/24/2022 23:02:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/24/2022 23:02:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/24/2022 23:02:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/24/2022 23:02:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/24/2022 23:02:46 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8085236517338067 on epoch=60
06/24/2022 23:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8026756985174324 -> 0.8085236517338067 on epoch=60, global_step=850
06/24/2022 23:02:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/24/2022 23:02:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/24/2022 23:02:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/24/2022 23:02:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/24/2022 23:02:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
06/24/2022 23:03:06 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7943572196107183 on epoch=64
06/24/2022 23:03:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/24/2022 23:03:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/24/2022 23:03:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/24/2022 23:03:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/24/2022 23:03:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/24/2022 23:03:26 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8317476801937784 on epoch=67
06/24/2022 23:03:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8085236517338067 -> 0.8317476801937784 on epoch=67, global_step=950
06/24/2022 23:03:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/24/2022 23:03:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/24/2022 23:03:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/24/2022 23:03:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
06/24/2022 23:03:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/24/2022 23:03:46 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.8731227016710886 on epoch=71
06/24/2022 23:03:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8317476801937784 -> 0.8731227016710886 on epoch=71, global_step=1000
06/24/2022 23:03:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/24/2022 23:03:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
06/24/2022 23:03:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/24/2022 23:03:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/24/2022 23:03:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/24/2022 23:04:06 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8953476415003929 on epoch=74
06/24/2022 23:04:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8731227016710886 -> 0.8953476415003929 on epoch=74, global_step=1050
06/24/2022 23:04:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/24/2022 23:04:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/24/2022 23:04:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/24/2022 23:04:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/24/2022 23:04:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/24/2022 23:04:26 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8971966094895165 on epoch=78
06/24/2022 23:04:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8953476415003929 -> 0.8971966094895165 on epoch=78, global_step=1100
06/24/2022 23:04:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/24/2022 23:04:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/24/2022 23:04:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/24/2022 23:04:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/24/2022 23:04:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/24/2022 23:04:46 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9058470856573322 on epoch=82
06/24/2022 23:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8971966094895165 -> 0.9058470856573322 on epoch=82, global_step=1150
06/24/2022 23:04:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/24/2022 23:04:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
06/24/2022 23:04:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/24/2022 23:04:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/24/2022 23:04:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/24/2022 23:05:06 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9035531788472964 on epoch=85
06/24/2022 23:05:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/24/2022 23:05:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/24/2022 23:05:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/24/2022 23:05:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/24/2022 23:05:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/24/2022 23:05:26 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8370895633319058 on epoch=89
06/24/2022 23:05:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/24/2022 23:05:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/24/2022 23:05:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/24/2022 23:05:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/24/2022 23:05:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/24/2022 23:05:46 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8980239026206768 on epoch=92
06/24/2022 23:05:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/24/2022 23:05:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/24/2022 23:05:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/24/2022 23:05:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/24/2022 23:05:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/24/2022 23:06:05 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9061092902459126 on epoch=96
06/24/2022 23:06:05 - INFO - __main__ - Saving model with best Classification-F1: 0.9058470856573322 -> 0.9061092902459126 on epoch=96, global_step=1350
06/24/2022 23:06:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/24/2022 23:06:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/24/2022 23:06:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/24/2022 23:06:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/24/2022 23:06:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/24/2022 23:06:25 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9818181818181818 on epoch=99
06/24/2022 23:06:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9061092902459126 -> 0.9818181818181818 on epoch=99, global_step=1400
06/24/2022 23:06:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/24/2022 23:06:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/24/2022 23:06:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/24/2022 23:06:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/24/2022 23:06:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/24/2022 23:06:44 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9684042751998158 on epoch=103
06/24/2022 23:06:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/24/2022 23:06:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/24/2022 23:06:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/24/2022 23:06:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/24/2022 23:06:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/24/2022 23:07:04 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9775118698505797 on epoch=107
06/24/2022 23:07:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/24/2022 23:07:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/24/2022 23:07:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/24/2022 23:07:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/24/2022 23:07:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/24/2022 23:07:23 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9774812197606314 on epoch=110
06/24/2022 23:07:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/24/2022 23:07:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/24/2022 23:07:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/24/2022 23:07:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/24/2022 23:07:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/24/2022 23:07:43 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.9017951814156746 on epoch=114
06/24/2022 23:07:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/24/2022 23:07:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/24/2022 23:07:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/24/2022 23:07:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/24/2022 23:07:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/24/2022 23:08:02 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8977547773752707 on epoch=117
06/24/2022 23:08:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/24/2022 23:08:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/24/2022 23:08:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/24/2022 23:08:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/24/2022 23:08:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/24/2022 23:08:22 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.910046432062561 on epoch=121
06/24/2022 23:08:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/24/2022 23:08:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/24/2022 23:08:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/24/2022 23:08:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/24/2022 23:08:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/24/2022 23:08:41 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9018644658793844 on epoch=124
06/24/2022 23:08:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/24/2022 23:08:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/24/2022 23:08:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/24/2022 23:08:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
06/24/2022 23:08:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/24/2022 23:09:01 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9726894597964577 on epoch=128
06/24/2022 23:09:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/24/2022 23:09:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/24/2022 23:09:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/24/2022 23:09:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/24/2022 23:09:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/24/2022 23:09:20 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9683065702770135 on epoch=132
06/24/2022 23:09:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/24/2022 23:09:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/24/2022 23:09:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/24/2022 23:09:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/24/2022 23:09:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/24/2022 23:09:39 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9685132704108036 on epoch=135
06/24/2022 23:09:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/24/2022 23:09:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/24/2022 23:09:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/24/2022 23:09:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/24/2022 23:09:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/24/2022 23:09:59 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9642288807018409 on epoch=139
06/24/2022 23:10:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/24/2022 23:10:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/24/2022 23:10:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/24/2022 23:10:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/24/2022 23:10:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/24/2022 23:10:18 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9730082062150373 on epoch=142
06/24/2022 23:10:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/24/2022 23:10:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/24/2022 23:10:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/24/2022 23:10:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/24/2022 23:10:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/24/2022 23:10:37 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9730169340463457 on epoch=146
06/24/2022 23:10:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/24/2022 23:10:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/24/2022 23:10:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/24/2022 23:10:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/24/2022 23:10:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/24/2022 23:10:56 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9101652674755142 on epoch=149
06/24/2022 23:10:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/24/2022 23:11:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/24/2022 23:11:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/24/2022 23:11:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/24/2022 23:11:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/24/2022 23:11:15 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9730125701306915 on epoch=153
06/24/2022 23:11:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/24/2022 23:11:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/24/2022 23:11:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/24/2022 23:11:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/24/2022 23:11:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/24/2022 23:11:35 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9773678606339897 on epoch=157
06/24/2022 23:11:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/24/2022 23:11:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/24/2022 23:11:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/24/2022 23:11:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/24/2022 23:11:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/24/2022 23:11:54 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9059986008088475 on epoch=160
06/24/2022 23:11:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/24/2022 23:11:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/24/2022 23:12:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/24/2022 23:12:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/24/2022 23:12:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/24/2022 23:12:13 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8976456212983728 on epoch=164
06/24/2022 23:12:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/24/2022 23:12:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/24/2022 23:12:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/24/2022 23:12:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/24/2022 23:12:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/24/2022 23:12:32 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9101652674755142 on epoch=167
06/24/2022 23:12:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/24/2022 23:12:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/24/2022 23:12:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/24/2022 23:12:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/24/2022 23:12:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/24/2022 23:12:51 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9730308985764394 on epoch=171
06/24/2022 23:12:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/24/2022 23:12:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/24/2022 23:12:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/24/2022 23:13:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/24/2022 23:13:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/24/2022 23:13:10 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9685176343264578 on epoch=174
06/24/2022 23:13:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/24/2022 23:13:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/24/2022 23:13:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/24/2022 23:13:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/24/2022 23:13:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/24/2022 23:13:30 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9730169340463457 on epoch=178
06/24/2022 23:13:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/24/2022 23:13:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/24/2022 23:13:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/24/2022 23:13:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/24/2022 23:13:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/24/2022 23:13:49 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9730125701306915 on epoch=182
06/24/2022 23:13:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/24/2022 23:13:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/24/2022 23:13:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/24/2022 23:13:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/24/2022 23:14:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/24/2022 23:14:08 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9059945278209035 on epoch=185
06/24/2022 23:14:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/24/2022 23:14:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/24/2022 23:14:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/24/2022 23:14:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/24/2022 23:14:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/24/2022 23:14:27 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9058797653958943 on epoch=189
06/24/2022 23:14:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/24/2022 23:14:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/24/2022 23:14:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/24/2022 23:14:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/24/2022 23:14:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/24/2022 23:14:47 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9685176343264578 on epoch=192
06/24/2022 23:14:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/24/2022 23:14:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/24/2022 23:14:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/24/2022 23:14:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/24/2022 23:14:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/24/2022 23:15:06 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9597339448976072 on epoch=196
06/24/2022 23:15:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/24/2022 23:15:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/24/2022 23:15:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/24/2022 23:15:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/24/2022 23:15:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/24/2022 23:15:25 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9638562490928214 on epoch=199
06/24/2022 23:15:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/24/2022 23:15:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/24/2022 23:15:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/24/2022 23:15:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/24/2022 23:15:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/24/2022 23:15:45 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9730125701306915 on epoch=203
06/24/2022 23:15:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/24/2022 23:15:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/24/2022 23:15:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/24/2022 23:15:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/24/2022 23:15:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/24/2022 23:16:04 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8434314534098097 on epoch=207
06/24/2022 23:16:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/24/2022 23:16:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/24/2022 23:16:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/24/2022 23:16:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/24/2022 23:16:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/24/2022 23:16:23 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9641842660817991 on epoch=210
06/24/2022 23:16:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/24/2022 23:16:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/24/2022 23:16:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/24/2022 23:16:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/24/2022 23:16:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/24/2022 23:16:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:16:38 - INFO - __main__ - Printing 3 examples
06/24/2022 23:16:38 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/24/2022 23:16:38 - INFO - __main__ - ['Animal']
06/24/2022 23:16:38 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/24/2022 23:16:38 - INFO - __main__ - ['Animal']
06/24/2022 23:16:38 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/24/2022 23:16:38 - INFO - __main__ - ['Animal']
06/24/2022 23:16:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:16:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:16:38 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 23:16:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:16:38 - INFO - __main__ - Printing 3 examples
06/24/2022 23:16:38 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/24/2022 23:16:38 - INFO - __main__ - ['Animal']
06/24/2022 23:16:38 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/24/2022 23:16:38 - INFO - __main__ - ['Animal']
06/24/2022 23:16:38 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/24/2022 23:16:38 - INFO - __main__ - ['Animal']
06/24/2022 23:16:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:16:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:16:38 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 23:16:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9642288807018409 on epoch=214
06/24/2022 23:16:43 - INFO - __main__ - save last model!
06/24/2022 23:16:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 23:16:43 - INFO - __main__ - Start tokenizing ... 3500 instances
06/24/2022 23:16:43 - INFO - __main__ - Printing 3 examples
06/24/2022 23:16:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/24/2022 23:16:43 - INFO - __main__ - ['Animal']
06/24/2022 23:16:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/24/2022 23:16:43 - INFO - __main__ - ['Animal']
06/24/2022 23:16:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/24/2022 23:16:43 - INFO - __main__ - ['Village']
06/24/2022 23:16:43 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:16:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:16:48 - INFO - __main__ - Loaded 3500 examples from test data
06/24/2022 23:16:57 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:16:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 23:16:58 - INFO - __main__ - Starting training!
06/24/2022 23:18:56 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/24/2022 23:18:56 - INFO - __main__ - Classification-F1 on test data: 0.5964
06/24/2022 23:18:57 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9818181818181818, test_performance=0.5963824766502104
06/24/2022 23:18:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/24/2022 23:18:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:18:58 - INFO - __main__ - Printing 3 examples
06/24/2022 23:18:58 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/24/2022 23:18:58 - INFO - __main__ - ['Animal']
06/24/2022 23:18:58 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/24/2022 23:18:58 - INFO - __main__ - ['Animal']
06/24/2022 23:18:58 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/24/2022 23:18:58 - INFO - __main__ - ['Animal']
06/24/2022 23:18:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:18:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:18:58 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 23:18:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:18:58 - INFO - __main__ - Printing 3 examples
06/24/2022 23:18:58 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/24/2022 23:18:58 - INFO - __main__ - ['Animal']
06/24/2022 23:18:58 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/24/2022 23:18:58 - INFO - __main__ - ['Animal']
06/24/2022 23:18:58 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/24/2022 23:18:58 - INFO - __main__ - ['Animal']
06/24/2022 23:18:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:18:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:18:58 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 23:19:14 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:19:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 23:19:15 - INFO - __main__ - Starting training!
06/24/2022 23:19:18 - INFO - __main__ - Step 10 Global step 10 Train loss 6.26 on epoch=0
06/24/2022 23:19:20 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=1
06/24/2022 23:19:23 - INFO - __main__ - Step 30 Global step 30 Train loss 4.33 on epoch=2
06/24/2022 23:19:25 - INFO - __main__ - Step 40 Global step 40 Train loss 3.57 on epoch=2
06/24/2022 23:19:28 - INFO - __main__ - Step 50 Global step 50 Train loss 3.28 on epoch=3
06/24/2022 23:19:33 - INFO - __main__ - Global step 50 Train loss 4.48 Classification-F1 0.05757357684666998 on epoch=3
06/24/2022 23:19:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05757357684666998 on epoch=3, global_step=50
06/24/2022 23:19:36 - INFO - __main__ - Step 60 Global step 60 Train loss 3.20 on epoch=4
06/24/2022 23:19:38 - INFO - __main__ - Step 70 Global step 70 Train loss 2.83 on epoch=4
06/24/2022 23:19:41 - INFO - __main__ - Step 80 Global step 80 Train loss 2.57 on epoch=5
06/24/2022 23:19:43 - INFO - __main__ - Step 90 Global step 90 Train loss 2.41 on epoch=6
06/24/2022 23:19:46 - INFO - __main__ - Step 100 Global step 100 Train loss 2.37 on epoch=7
06/24/2022 23:19:51 - INFO - __main__ - Global step 100 Train loss 2.68 Classification-F1 0.07790123456790123 on epoch=7
06/24/2022 23:19:51 - INFO - __main__ - Saving model with best Classification-F1: 0.05757357684666998 -> 0.07790123456790123 on epoch=7, global_step=100
06/24/2022 23:19:53 - INFO - __main__ - Step 110 Global step 110 Train loss 2.13 on epoch=7
06/24/2022 23:19:56 - INFO - __main__ - Step 120 Global step 120 Train loss 2.04 on epoch=8
06/24/2022 23:19:58 - INFO - __main__ - Step 130 Global step 130 Train loss 1.91 on epoch=9
06/24/2022 23:20:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.64 on epoch=9
06/24/2022 23:20:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.65 on epoch=10
06/24/2022 23:20:09 - INFO - __main__ - Global step 150 Train loss 1.87 Classification-F1 0.0991531658840277 on epoch=10
06/24/2022 23:20:09 - INFO - __main__ - Saving model with best Classification-F1: 0.07790123456790123 -> 0.0991531658840277 on epoch=10, global_step=150
06/24/2022 23:20:11 - INFO - __main__ - Step 160 Global step 160 Train loss 1.47 on epoch=11
06/24/2022 23:20:14 - INFO - __main__ - Step 170 Global step 170 Train loss 1.47 on epoch=12
06/24/2022 23:20:16 - INFO - __main__ - Step 180 Global step 180 Train loss 1.30 on epoch=12
06/24/2022 23:20:18 - INFO - __main__ - Step 190 Global step 190 Train loss 1.14 on epoch=13
06/24/2022 23:20:21 - INFO - __main__ - Step 200 Global step 200 Train loss 1.20 on epoch=14
06/24/2022 23:20:27 - INFO - __main__ - Global step 200 Train loss 1.32 Classification-F1 0.18075192754653244 on epoch=14
06/24/2022 23:20:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0991531658840277 -> 0.18075192754653244 on epoch=14, global_step=200
06/24/2022 23:20:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=14
06/24/2022 23:20:32 - INFO - __main__ - Step 220 Global step 220 Train loss 1.02 on epoch=15
06/24/2022 23:20:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.81 on epoch=16
06/24/2022 23:20:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=17
06/24/2022 23:20:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=17
06/24/2022 23:20:46 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.2660227132279413 on epoch=17
06/24/2022 23:20:46 - INFO - __main__ - Saving model with best Classification-F1: 0.18075192754653244 -> 0.2660227132279413 on epoch=17, global_step=250
06/24/2022 23:20:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=18
06/24/2022 23:20:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=19
06/24/2022 23:20:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.70 on epoch=19
06/24/2022 23:20:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=20
06/24/2022 23:20:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=21
06/24/2022 23:21:05 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.33501937661822556 on epoch=21
06/24/2022 23:21:05 - INFO - __main__ - Saving model with best Classification-F1: 0.2660227132279413 -> 0.33501937661822556 on epoch=21, global_step=300
06/24/2022 23:21:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=22
06/24/2022 23:21:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=22
06/24/2022 23:21:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=23
06/24/2022 23:21:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=24
06/24/2022 23:21:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=24
06/24/2022 23:21:24 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.5033508551495668 on epoch=24
06/24/2022 23:21:24 - INFO - __main__ - Saving model with best Classification-F1: 0.33501937661822556 -> 0.5033508551495668 on epoch=24, global_step=350
06/24/2022 23:21:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=25
06/24/2022 23:21:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/24/2022 23:21:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=27
06/24/2022 23:21:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=27
06/24/2022 23:21:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=28
06/24/2022 23:21:44 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.5346107084514343 on epoch=28
06/24/2022 23:21:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5033508551495668 -> 0.5346107084514343 on epoch=28, global_step=400
06/24/2022 23:21:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=29
06/24/2022 23:21:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/24/2022 23:21:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
06/24/2022 23:21:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=31
06/24/2022 23:21:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=32
06/24/2022 23:22:05 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.5093011781653547 on epoch=32
06/24/2022 23:22:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=32
06/24/2022 23:22:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=33
06/24/2022 23:22:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=34
06/24/2022 23:22:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/24/2022 23:22:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=35
06/24/2022 23:22:24 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.5472487705471782 on epoch=35
06/24/2022 23:22:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5346107084514343 -> 0.5472487705471782 on epoch=35, global_step=500
06/24/2022 23:22:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
06/24/2022 23:22:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
06/24/2022 23:22:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/24/2022 23:22:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/24/2022 23:22:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=39
06/24/2022 23:22:44 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.620785559940908 on epoch=39
06/24/2022 23:22:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5472487705471782 -> 0.620785559940908 on epoch=39, global_step=550
06/24/2022 23:22:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=39
06/24/2022 23:22:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/24/2022 23:22:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
06/24/2022 23:22:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=42
06/24/2022 23:22:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
06/24/2022 23:23:04 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.5329000123928517 on epoch=42
06/24/2022 23:23:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=43
06/24/2022 23:23:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=44
06/24/2022 23:23:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
06/24/2022 23:23:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
06/24/2022 23:23:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/24/2022 23:23:23 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.5990682555198684 on epoch=46
06/24/2022 23:23:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/24/2022 23:23:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=47
06/24/2022 23:23:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
06/24/2022 23:23:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
06/24/2022 23:23:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/24/2022 23:23:44 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.5792329448133472 on epoch=49
06/24/2022 23:23:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/24/2022 23:23:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/24/2022 23:23:51 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/24/2022 23:23:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
06/24/2022 23:23:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/24/2022 23:24:03 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.5792878039540333 on epoch=53
06/24/2022 23:24:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/24/2022 23:24:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
06/24/2022 23:24:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=55
06/24/2022 23:24:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=56
06/24/2022 23:24:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/24/2022 23:24:24 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.7018793419684761 on epoch=57
06/24/2022 23:24:24 - INFO - __main__ - Saving model with best Classification-F1: 0.620785559940908 -> 0.7018793419684761 on epoch=57, global_step=800
06/24/2022 23:24:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/24/2022 23:24:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
06/24/2022 23:24:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/24/2022 23:24:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=59
06/24/2022 23:24:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/24/2022 23:24:43 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6656633307050845 on epoch=60
06/24/2022 23:24:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/24/2022 23:24:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/24/2022 23:24:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/24/2022 23:24:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/24/2022 23:24:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/24/2022 23:25:02 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7782063848877772 on epoch=64
06/24/2022 23:25:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7018793419684761 -> 0.7782063848877772 on epoch=64, global_step=900
06/24/2022 23:25:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
06/24/2022 23:25:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=65
06/24/2022 23:25:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/24/2022 23:25:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
06/24/2022 23:25:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/24/2022 23:25:22 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.7895403123981753 on epoch=67
06/24/2022 23:25:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7782063848877772 -> 0.7895403123981753 on epoch=67, global_step=950
06/24/2022 23:25:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/24/2022 23:25:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/24/2022 23:25:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/24/2022 23:25:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=70
06/24/2022 23:25:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/24/2022 23:25:42 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7461055539259671 on epoch=71
06/24/2022 23:25:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=72
06/24/2022 23:25:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/24/2022 23:25:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/24/2022 23:25:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/24/2022 23:25:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/24/2022 23:26:02 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7836280794698134 on epoch=74
06/24/2022 23:26:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/24/2022 23:26:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/24/2022 23:26:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
06/24/2022 23:26:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/24/2022 23:26:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/24/2022 23:26:21 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7384026599341458 on epoch=78
06/24/2022 23:26:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
06/24/2022 23:26:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/24/2022 23:26:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/24/2022 23:26:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/24/2022 23:26:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/24/2022 23:26:40 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7462385634939669 on epoch=82
06/24/2022 23:26:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/24/2022 23:26:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/24/2022 23:26:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/24/2022 23:26:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=84
06/24/2022 23:26:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/24/2022 23:27:00 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.8105742327317561 on epoch=85
06/24/2022 23:27:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7895403123981753 -> 0.8105742327317561 on epoch=85, global_step=1200
06/24/2022 23:27:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/24/2022 23:27:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=87
06/24/2022 23:27:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/24/2022 23:27:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/24/2022 23:27:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
06/24/2022 23:27:20 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7714962475078608 on epoch=89
06/24/2022 23:27:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/24/2022 23:27:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
06/24/2022 23:27:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/24/2022 23:27:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/24/2022 23:27:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/24/2022 23:27:39 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.7395463056516187 on epoch=92
06/24/2022 23:27:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/24/2022 23:27:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/24/2022 23:27:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/24/2022 23:27:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/24/2022 23:27:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/24/2022 23:27:59 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7059651511476638 on epoch=96
06/24/2022 23:28:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
06/24/2022 23:28:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/24/2022 23:28:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/24/2022 23:28:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/24/2022 23:28:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/24/2022 23:28:18 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7449341292847966 on epoch=99
06/24/2022 23:28:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/24/2022 23:28:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/24/2022 23:28:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/24/2022 23:28:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/24/2022 23:28:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/24/2022 23:28:38 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.9054151803978409 on epoch=103
06/24/2022 23:28:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8105742327317561 -> 0.9054151803978409 on epoch=103, global_step=1450
06/24/2022 23:28:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/24/2022 23:28:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/24/2022 23:28:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/24/2022 23:28:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/24/2022 23:28:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/24/2022 23:28:57 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.9100423590746171 on epoch=107
06/24/2022 23:28:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9054151803978409 -> 0.9100423590746171 on epoch=107, global_step=1500
06/24/2022 23:29:00 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/24/2022 23:29:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/24/2022 23:29:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/24/2022 23:29:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/24/2022 23:29:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/24/2022 23:29:17 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9016934525520862 on epoch=110
06/24/2022 23:29:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/24/2022 23:29:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/24/2022 23:29:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/24/2022 23:29:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/24/2022 23:29:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/24/2022 23:29:36 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9059945278209035 on epoch=114
06/24/2022 23:29:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/24/2022 23:29:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/24/2022 23:29:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/24/2022 23:29:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/24/2022 23:29:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/24/2022 23:29:55 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8431870741331724 on epoch=117
06/24/2022 23:29:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/24/2022 23:30:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/24/2022 23:30:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/24/2022 23:30:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/24/2022 23:30:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/24/2022 23:30:15 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9818181818181818 on epoch=121
06/24/2022 23:30:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9100423590746171 -> 0.9818181818181818 on epoch=121, global_step=1700
06/24/2022 23:30:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/24/2022 23:30:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/24/2022 23:30:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/24/2022 23:30:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/24/2022 23:30:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/24/2022 23:30:34 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9060075613823242 on epoch=124
06/24/2022 23:30:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/24/2022 23:30:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
06/24/2022 23:30:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/24/2022 23:30:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/24/2022 23:30:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/24/2022 23:30:54 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8487191418495298 on epoch=128
06/24/2022 23:30:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/24/2022 23:30:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/24/2022 23:31:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/24/2022 23:31:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/24/2022 23:31:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/24/2022 23:31:13 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8436105850168351 on epoch=132
06/24/2022 23:31:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/24/2022 23:31:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/24/2022 23:31:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/24/2022 23:31:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/24/2022 23:31:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/24/2022 23:31:32 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8322253857758484 on epoch=135
06/24/2022 23:31:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/24/2022 23:31:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/24/2022 23:31:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/24/2022 23:31:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/24/2022 23:31:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/24/2022 23:31:51 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8334852168506699 on epoch=139
06/24/2022 23:31:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/24/2022 23:31:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/24/2022 23:31:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/24/2022 23:32:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/24/2022 23:32:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/24/2022 23:32:11 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8332024953082153 on epoch=142
06/24/2022 23:32:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/24/2022 23:32:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/24/2022 23:32:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/24/2022 23:32:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/24/2022 23:32:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/24/2022 23:32:30 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9018449677036015 on epoch=146
06/24/2022 23:32:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/24/2022 23:32:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/24/2022 23:32:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/24/2022 23:32:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/24/2022 23:32:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/24/2022 23:32:49 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9019541237804993 on epoch=149
06/24/2022 23:32:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/24/2022 23:32:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/24/2022 23:32:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/24/2022 23:33:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/24/2022 23:33:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/24/2022 23:33:11 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9056929581756187 on epoch=153
06/24/2022 23:33:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/24/2022 23:33:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/24/2022 23:33:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/24/2022 23:33:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/24/2022 23:33:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/24/2022 23:33:30 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7811470078994356 on epoch=157
06/24/2022 23:33:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/24/2022 23:33:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/24/2022 23:33:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/24/2022 23:33:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/24/2022 23:33:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/24/2022 23:33:48 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8408691719412782 on epoch=160
06/24/2022 23:33:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/24/2022 23:33:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/24/2022 23:33:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/24/2022 23:33:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/24/2022 23:34:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/24/2022 23:34:08 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9056929581756187 on epoch=164
06/24/2022 23:34:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/24/2022 23:34:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/24/2022 23:34:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/24/2022 23:34:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/24/2022 23:34:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/24/2022 23:34:27 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7377561412494473 on epoch=167
06/24/2022 23:34:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/24/2022 23:34:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
06/24/2022 23:34:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/24/2022 23:34:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/24/2022 23:34:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/24/2022 23:34:46 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7046244573197035 on epoch=171
06/24/2022 23:34:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/24/2022 23:34:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/24/2022 23:34:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/24/2022 23:34:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/24/2022 23:34:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/24/2022 23:35:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7480982163329833 on epoch=174
06/24/2022 23:35:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/24/2022 23:35:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/24/2022 23:35:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/24/2022 23:35:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/24/2022 23:35:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/24/2022 23:35:24 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7866276571196205 on epoch=178
06/24/2022 23:35:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/24/2022 23:35:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/24/2022 23:35:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/24/2022 23:35:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/24/2022 23:35:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/24/2022 23:35:43 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8407890343226481 on epoch=182
06/24/2022 23:35:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/24/2022 23:35:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/24/2022 23:35:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/24/2022 23:35:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/24/2022 23:35:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/24/2022 23:36:02 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7939864329570212 on epoch=185
06/24/2022 23:36:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/24/2022 23:36:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/24/2022 23:36:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/24/2022 23:36:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/24/2022 23:36:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/24/2022 23:36:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8292498999656257 on epoch=189
06/24/2022 23:36:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/24/2022 23:36:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=190
06/24/2022 23:36:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/24/2022 23:36:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/24/2022 23:36:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/24/2022 23:36:41 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.831797474192568 on epoch=192
06/24/2022 23:36:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/24/2022 23:36:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/24/2022 23:36:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/24/2022 23:36:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/24/2022 23:36:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/24/2022 23:36:59 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.829567200831187 on epoch=196
06/24/2022 23:37:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/24/2022 23:37:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/24/2022 23:37:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/24/2022 23:37:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/24/2022 23:37:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/24/2022 23:37:18 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7807691301940584 on epoch=199
06/24/2022 23:37:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/24/2022 23:37:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/24/2022 23:37:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/24/2022 23:37:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/24/2022 23:37:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/24/2022 23:37:37 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7228403215806277 on epoch=203
06/24/2022 23:37:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/24/2022 23:37:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/24/2022 23:37:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/24/2022 23:37:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/24/2022 23:37:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/24/2022 23:37:56 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7668271742024393 on epoch=207
06/24/2022 23:37:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/24/2022 23:38:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/24/2022 23:38:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/24/2022 23:38:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/24/2022 23:38:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/24/2022 23:38:16 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6536715142514993 on epoch=210
06/24/2022 23:38:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/24/2022 23:38:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/24/2022 23:38:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/24/2022 23:38:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/24/2022 23:38:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/24/2022 23:38:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:38:31 - INFO - __main__ - Printing 3 examples
06/24/2022 23:38:31 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/24/2022 23:38:31 - INFO - __main__ - ['Animal']
06/24/2022 23:38:31 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/24/2022 23:38:31 - INFO - __main__ - ['Animal']
06/24/2022 23:38:31 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/24/2022 23:38:31 - INFO - __main__ - ['Animal']
06/24/2022 23:38:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:38:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:38:31 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 23:38:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:38:31 - INFO - __main__ - Printing 3 examples
06/24/2022 23:38:31 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/24/2022 23:38:31 - INFO - __main__ - ['Animal']
06/24/2022 23:38:31 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/24/2022 23:38:31 - INFO - __main__ - ['Animal']
06/24/2022 23:38:31 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/24/2022 23:38:31 - INFO - __main__ - ['Animal']
06/24/2022 23:38:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:38:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:38:32 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 23:38:36 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6747188920239386 on epoch=214
06/24/2022 23:38:36 - INFO - __main__ - save last model!
06/24/2022 23:38:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 23:38:36 - INFO - __main__ - Start tokenizing ... 3500 instances
06/24/2022 23:38:36 - INFO - __main__ - Printing 3 examples
06/24/2022 23:38:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/24/2022 23:38:36 - INFO - __main__ - ['Animal']
06/24/2022 23:38:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/24/2022 23:38:36 - INFO - __main__ - ['Animal']
06/24/2022 23:38:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/24/2022 23:38:36 - INFO - __main__ - ['Village']
06/24/2022 23:38:36 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:38:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:38:41 - INFO - __main__ - Loaded 3500 examples from test data
06/24/2022 23:38:47 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:38:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 23:38:48 - INFO - __main__ - Starting training!
06/24/2022 23:40:48 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/24/2022 23:40:48 - INFO - __main__ - Classification-F1 on test data: 0.4245
06/24/2022 23:40:48 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9818181818181818, test_performance=0.4245047155527624
06/24/2022 23:40:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/24/2022 23:40:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:40:49 - INFO - __main__ - Printing 3 examples
06/24/2022 23:40:49 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/24/2022 23:40:49 - INFO - __main__ - ['Animal']
06/24/2022 23:40:49 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/24/2022 23:40:49 - INFO - __main__ - ['Animal']
06/24/2022 23:40:49 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/24/2022 23:40:49 - INFO - __main__ - ['Animal']
06/24/2022 23:40:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:40:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:40:49 - INFO - __main__ - Loaded 224 examples from train data
06/24/2022 23:40:49 - INFO - __main__ - Start tokenizing ... 224 instances
06/24/2022 23:40:49 - INFO - __main__ - Printing 3 examples
06/24/2022 23:40:49 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/24/2022 23:40:49 - INFO - __main__ - ['Animal']
06/24/2022 23:40:49 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/24/2022 23:40:49 - INFO - __main__ - ['Animal']
06/24/2022 23:40:49 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/24/2022 23:40:49 - INFO - __main__ - ['Animal']
06/24/2022 23:40:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 23:40:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 23:40:50 - INFO - __main__ - Loaded 224 examples from dev data
06/24/2022 23:41:05 - INFO - __main__ - load prompt embedding from ckpt
06/24/2022 23:41:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/24/2022 23:41:06 - INFO - __main__ - Starting training!
06/24/2022 23:41:09 - INFO - __main__ - Step 10 Global step 10 Train loss 6.80 on epoch=0
06/24/2022 23:41:12 - INFO - __main__ - Step 20 Global step 20 Train loss 5.26 on epoch=1
06/24/2022 23:41:14 - INFO - __main__ - Step 30 Global step 30 Train loss 4.44 on epoch=2
06/24/2022 23:41:17 - INFO - __main__ - Step 40 Global step 40 Train loss 4.05 on epoch=2
06/24/2022 23:41:19 - INFO - __main__ - Step 50 Global step 50 Train loss 3.80 on epoch=3
06/24/2022 23:41:25 - INFO - __main__ - Global step 50 Train loss 4.87 Classification-F1 0.041288879369838896 on epoch=3
06/24/2022 23:41:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.041288879369838896 on epoch=3, global_step=50
06/24/2022 23:41:27 - INFO - __main__ - Step 60 Global step 60 Train loss 3.44 on epoch=4
06/24/2022 23:41:30 - INFO - __main__ - Step 70 Global step 70 Train loss 3.19 on epoch=4
06/24/2022 23:41:32 - INFO - __main__ - Step 80 Global step 80 Train loss 3.01 on epoch=5
06/24/2022 23:41:35 - INFO - __main__ - Step 90 Global step 90 Train loss 2.79 on epoch=6
06/24/2022 23:41:37 - INFO - __main__ - Step 100 Global step 100 Train loss 2.81 on epoch=7
06/24/2022 23:41:42 - INFO - __main__ - Global step 100 Train loss 3.05 Classification-F1 0.0698356110120816 on epoch=7
06/24/2022 23:41:42 - INFO - __main__ - Saving model with best Classification-F1: 0.041288879369838896 -> 0.0698356110120816 on epoch=7, global_step=100
06/24/2022 23:41:45 - INFO - __main__ - Step 110 Global step 110 Train loss 2.52 on epoch=7
06/24/2022 23:41:47 - INFO - __main__ - Step 120 Global step 120 Train loss 2.49 on epoch=8
06/24/2022 23:41:50 - INFO - __main__ - Step 130 Global step 130 Train loss 2.33 on epoch=9
06/24/2022 23:41:52 - INFO - __main__ - Step 140 Global step 140 Train loss 2.22 on epoch=9
06/24/2022 23:41:55 - INFO - __main__ - Step 150 Global step 150 Train loss 2.19 on epoch=10
06/24/2022 23:42:00 - INFO - __main__ - Global step 150 Train loss 2.35 Classification-F1 0.08675466443887496 on epoch=10
06/24/2022 23:42:00 - INFO - __main__ - Saving model with best Classification-F1: 0.0698356110120816 -> 0.08675466443887496 on epoch=10, global_step=150
06/24/2022 23:42:03 - INFO - __main__ - Step 160 Global step 160 Train loss 1.83 on epoch=11
06/24/2022 23:42:05 - INFO - __main__ - Step 170 Global step 170 Train loss 1.92 on epoch=12
06/24/2022 23:42:08 - INFO - __main__ - Step 180 Global step 180 Train loss 1.72 on epoch=12
06/24/2022 23:42:10 - INFO - __main__ - Step 190 Global step 190 Train loss 1.68 on epoch=13
06/24/2022 23:42:13 - INFO - __main__ - Step 200 Global step 200 Train loss 1.68 on epoch=14
06/24/2022 23:42:19 - INFO - __main__ - Global step 200 Train loss 1.77 Classification-F1 0.09769242629706683 on epoch=14
06/24/2022 23:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.08675466443887496 -> 0.09769242629706683 on epoch=14, global_step=200
06/24/2022 23:42:21 - INFO - __main__ - Step 210 Global step 210 Train loss 1.39 on epoch=14
06/24/2022 23:42:24 - INFO - __main__ - Step 220 Global step 220 Train loss 1.45 on epoch=15
06/24/2022 23:42:26 - INFO - __main__ - Step 230 Global step 230 Train loss 1.32 on epoch=16
06/24/2022 23:42:29 - INFO - __main__ - Step 240 Global step 240 Train loss 1.32 on epoch=17
06/24/2022 23:42:31 - INFO - __main__ - Step 250 Global step 250 Train loss 1.29 on epoch=17
06/24/2022 23:42:37 - INFO - __main__ - Global step 250 Train loss 1.35 Classification-F1 0.15522814773018448 on epoch=17
06/24/2022 23:42:37 - INFO - __main__ - Saving model with best Classification-F1: 0.09769242629706683 -> 0.15522814773018448 on epoch=17, global_step=250
06/24/2022 23:42:39 - INFO - __main__ - Step 260 Global step 260 Train loss 1.11 on epoch=18
06/24/2022 23:42:42 - INFO - __main__ - Step 270 Global step 270 Train loss 1.07 on epoch=19
06/24/2022 23:42:45 - INFO - __main__ - Step 280 Global step 280 Train loss 1.00 on epoch=19
06/24/2022 23:42:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.96 on epoch=20
06/24/2022 23:42:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=21
06/24/2022 23:42:56 - INFO - __main__ - Global step 300 Train loss 0.98 Classification-F1 0.21809865053788907 on epoch=21
06/24/2022 23:42:56 - INFO - __main__ - Saving model with best Classification-F1: 0.15522814773018448 -> 0.21809865053788907 on epoch=21, global_step=300
06/24/2022 23:42:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.96 on epoch=22
06/24/2022 23:43:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=22
06/24/2022 23:43:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.89 on epoch=23
06/24/2022 23:43:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=24
06/24/2022 23:43:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=24
06/24/2022 23:43:15 - INFO - __main__ - Global step 350 Train loss 0.79 Classification-F1 0.3243592641403312 on epoch=24
06/24/2022 23:43:15 - INFO - __main__ - Saving model with best Classification-F1: 0.21809865053788907 -> 0.3243592641403312 on epoch=24, global_step=350
06/24/2022 23:43:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=25
06/24/2022 23:43:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.62 on epoch=26
06/24/2022 23:43:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.75 on epoch=27
06/24/2022 23:43:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
06/24/2022 23:43:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=28
06/24/2022 23:43:34 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.4019000596159858 on epoch=28
06/24/2022 23:43:34 - INFO - __main__ - Saving model with best Classification-F1: 0.3243592641403312 -> 0.4019000596159858 on epoch=28, global_step=400
06/24/2022 23:43:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
06/24/2022 23:43:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=29
06/24/2022 23:43:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=30
06/24/2022 23:43:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=31
06/24/2022 23:43:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=32
06/24/2022 23:43:54 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.4672821677571107 on epoch=32
06/24/2022 23:43:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4019000596159858 -> 0.4672821677571107 on epoch=32, global_step=450
06/24/2022 23:43:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/24/2022 23:43:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
06/24/2022 23:44:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
06/24/2022 23:44:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=34
06/24/2022 23:44:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=35
06/24/2022 23:44:14 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.47438565363503327 on epoch=35
06/24/2022 23:44:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4672821677571107 -> 0.47438565363503327 on epoch=35, global_step=500
06/24/2022 23:44:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=36
06/24/2022 23:44:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
06/24/2022 23:44:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=37
06/24/2022 23:44:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
06/24/2022 23:44:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=39
06/24/2022 23:44:34 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.590140724378261 on epoch=39
06/24/2022 23:44:34 - INFO - __main__ - Saving model with best Classification-F1: 0.47438565363503327 -> 0.590140724378261 on epoch=39, global_step=550
06/24/2022 23:44:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
06/24/2022 23:44:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
06/24/2022 23:44:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=41
06/24/2022 23:44:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=42
06/24/2022 23:44:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
06/24/2022 23:44:54 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.5477822240094331 on epoch=42
06/24/2022 23:44:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.42 on epoch=43
06/24/2022 23:44:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=44
06/24/2022 23:45:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=44
06/24/2022 23:45:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=45
06/24/2022 23:45:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=46
06/24/2022 23:45:13 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.6709695228370949 on epoch=46
06/24/2022 23:45:13 - INFO - __main__ - Saving model with best Classification-F1: 0.590140724378261 -> 0.6709695228370949 on epoch=46, global_step=650
06/24/2022 23:45:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=47
06/24/2022 23:45:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/24/2022 23:45:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=48
06/24/2022 23:45:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/24/2022 23:45:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=49
06/24/2022 23:45:33 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6451831434694337 on epoch=49
06/24/2022 23:45:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/24/2022 23:45:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/24/2022 23:45:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=52
06/24/2022 23:45:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/24/2022 23:45:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=53
06/24/2022 23:45:53 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6622050705952741 on epoch=53
06/24/2022 23:45:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/24/2022 23:45:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=54
06/24/2022 23:46:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
06/24/2022 23:46:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=56
06/24/2022 23:46:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/24/2022 23:46:13 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.595753864300045 on epoch=57
06/24/2022 23:46:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/24/2022 23:46:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
06/24/2022 23:46:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
06/24/2022 23:46:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/24/2022 23:46:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=60
06/24/2022 23:46:32 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.6498213291101016 on epoch=60
06/24/2022 23:46:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
06/24/2022 23:46:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=62
06/24/2022 23:46:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
06/24/2022 23:46:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=63
06/24/2022 23:46:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
06/24/2022 23:46:52 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7216051772927303 on epoch=64
06/24/2022 23:46:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6709695228370949 -> 0.7216051772927303 on epoch=64, global_step=900
06/24/2022 23:46:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=64
06/24/2022 23:46:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/24/2022 23:47:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=66
06/24/2022 23:47:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/24/2022 23:47:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/24/2022 23:47:12 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6843354823193533 on epoch=67
06/24/2022 23:47:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/24/2022 23:47:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
06/24/2022 23:47:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=69
06/24/2022 23:47:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
06/24/2022 23:47:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/24/2022 23:47:31 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7252827132808157 on epoch=71
06/24/2022 23:47:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7216051772927303 -> 0.7252827132808157 on epoch=71, global_step=1000
06/24/2022 23:47:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
06/24/2022 23:47:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=72
06/24/2022 23:47:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
06/24/2022 23:47:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/24/2022 23:47:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
06/24/2022 23:47:51 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.682630426534601 on epoch=74
06/24/2022 23:47:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/24/2022 23:47:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/24/2022 23:47:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/24/2022 23:48:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
06/24/2022 23:48:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/24/2022 23:48:10 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6902989478430214 on epoch=78
06/24/2022 23:48:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/24/2022 23:48:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
06/24/2022 23:48:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/24/2022 23:48:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
06/24/2022 23:48:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/24/2022 23:48:30 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.7011925631434548 on epoch=82
06/24/2022 23:48:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/24/2022 23:48:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
06/24/2022 23:48:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
06/24/2022 23:48:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=84
06/24/2022 23:48:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/24/2022 23:48:50 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6369020083132986 on epoch=85
06/24/2022 23:48:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/24/2022 23:48:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/24/2022 23:48:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/24/2022 23:49:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/24/2022 23:49:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/24/2022 23:49:09 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6634012021745469 on epoch=89
06/24/2022 23:49:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/24/2022 23:49:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/24/2022 23:49:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/24/2022 23:49:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
06/24/2022 23:49:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/24/2022 23:49:29 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7198938307809275 on epoch=92
06/24/2022 23:49:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/24/2022 23:49:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/24/2022 23:49:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/24/2022 23:49:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/24/2022 23:49:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=96
06/24/2022 23:49:49 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.7003355713330246 on epoch=96
06/24/2022 23:49:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=97
06/24/2022 23:49:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=97
06/24/2022 23:49:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
06/24/2022 23:49:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/24/2022 23:50:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/24/2022 23:50:09 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.7006383973561643 on epoch=99
06/24/2022 23:50:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/24/2022 23:50:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/24/2022 23:50:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
06/24/2022 23:50:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/24/2022 23:50:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/24/2022 23:50:29 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7865230579035133 on epoch=103
06/24/2022 23:50:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7252827132808157 -> 0.7865230579035133 on epoch=103, global_step=1450
06/24/2022 23:50:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/24/2022 23:50:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/24/2022 23:50:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/24/2022 23:50:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/24/2022 23:50:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=107
06/24/2022 23:50:49 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7009273550445027 on epoch=107
06/24/2022 23:50:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/24/2022 23:50:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
06/24/2022 23:50:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=109
06/24/2022 23:50:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/24/2022 23:51:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/24/2022 23:51:08 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7969120472539304 on epoch=110
06/24/2022 23:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7865230579035133 -> 0.7969120472539304 on epoch=110, global_step=1550
06/24/2022 23:51:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/24/2022 23:51:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/24/2022 23:51:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/24/2022 23:51:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/24/2022 23:51:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/24/2022 23:51:28 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9015876507005539 on epoch=114
06/24/2022 23:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7969120472539304 -> 0.9015876507005539 on epoch=114, global_step=1600
06/24/2022 23:51:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
06/24/2022 23:51:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=115
06/24/2022 23:51:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/24/2022 23:51:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=117
06/24/2022 23:51:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/24/2022 23:51:48 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.9016934525520862 on epoch=117
06/24/2022 23:51:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9015876507005539 -> 0.9016934525520862 on epoch=117, global_step=1650
06/24/2022 23:51:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
06/24/2022 23:51:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/24/2022 23:51:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/24/2022 23:51:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/24/2022 23:52:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/24/2022 23:52:08 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9015876507005539 on epoch=121
06/24/2022 23:52:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/24/2022 23:52:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/24/2022 23:52:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/24/2022 23:52:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/24/2022 23:52:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/24/2022 23:52:28 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9682909160731741 on epoch=124
06/24/2022 23:52:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9016934525520862 -> 0.9682909160731741 on epoch=124, global_step=1750
06/24/2022 23:52:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/24/2022 23:52:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/24/2022 23:52:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/24/2022 23:52:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/24/2022 23:52:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/24/2022 23:52:47 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9682909160731741 on epoch=128
06/24/2022 23:52:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/24/2022 23:52:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
06/24/2022 23:52:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/24/2022 23:52:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/24/2022 23:53:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/24/2022 23:53:07 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.9682909160731741 on epoch=132
06/24/2022 23:53:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/24/2022 23:53:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/24/2022 23:53:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/24/2022 23:53:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=134
06/24/2022 23:53:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/24/2022 23:53:27 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.972903574919704 on epoch=135
06/24/2022 23:53:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9682909160731741 -> 0.972903574919704 on epoch=135, global_step=1900
06/24/2022 23:53:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/24/2022 23:53:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/24/2022 23:53:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/24/2022 23:53:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/24/2022 23:53:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/24/2022 23:53:47 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.9684042751998158 on epoch=139
06/24/2022 23:53:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/24/2022 23:53:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/24/2022 23:53:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/24/2022 23:53:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/24/2022 23:53:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/24/2022 23:54:06 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.972903574919704 on epoch=142
06/24/2022 23:54:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/24/2022 23:54:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/24/2022 23:54:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/24/2022 23:54:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=145
06/24/2022 23:54:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/24/2022 23:54:26 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8511684384164223 on epoch=146
06/24/2022 23:54:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/24/2022 23:54:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/24/2022 23:54:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/24/2022 23:54:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/24/2022 23:54:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/24/2022 23:54:45 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.972903574919704 on epoch=149
06/24/2022 23:54:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/24/2022 23:54:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/24/2022 23:54:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/24/2022 23:54:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/24/2022 23:54:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/24/2022 23:55:04 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9058927989573149 on epoch=153
06/24/2022 23:55:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/24/2022 23:55:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/24/2022 23:55:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/24/2022 23:55:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/24/2022 23:55:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/24/2022 23:55:24 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.972903574919704 on epoch=157
06/24/2022 23:55:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/24/2022 23:55:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/24/2022 23:55:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/24/2022 23:55:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/24/2022 23:55:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/24/2022 23:55:44 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.972903574919704 on epoch=160
06/24/2022 23:55:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/24/2022 23:55:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
06/24/2022 23:55:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/24/2022 23:55:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/24/2022 23:55:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/24/2022 23:56:04 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9100594656239819 on epoch=164
06/24/2022 23:56:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/24/2022 23:56:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/24/2022 23:56:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/24/2022 23:56:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/24/2022 23:56:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
06/24/2022 23:56:23 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9016934525520862 on epoch=167
06/24/2022 23:56:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/24/2022 23:56:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/24/2022 23:56:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/24/2022 23:56:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/24/2022 23:56:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/24/2022 23:56:43 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7464017369918171 on epoch=171
06/24/2022 23:56:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/24/2022 23:56:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/24/2022 23:56:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/24/2022 23:56:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/24/2022 23:56:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/24/2022 23:57:02 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9057583903551645 on epoch=174
06/24/2022 23:57:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/24/2022 23:57:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/24/2022 23:57:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/24/2022 23:57:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/24/2022 23:57:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/24/2022 23:57:23 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9684042751998158 on epoch=178
06/24/2022 23:57:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/24/2022 23:57:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
06/24/2022 23:57:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/24/2022 23:57:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/24/2022 23:57:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/24/2022 23:57:43 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9773678606339897 on epoch=182
06/24/2022 23:57:43 - INFO - __main__ - Saving model with best Classification-F1: 0.972903574919704 -> 0.9773678606339897 on epoch=182, global_step=2550
06/24/2022 23:57:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/24/2022 23:57:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/24/2022 23:57:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/24/2022 23:57:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/24/2022 23:57:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/24/2022 23:58:02 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9686852086875807 on epoch=185
06/24/2022 23:58:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/24/2022 23:58:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/24/2022 23:58:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/24/2022 23:58:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/24/2022 23:58:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/24/2022 23:58:22 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8976415483104287 on epoch=189
06/24/2022 23:58:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/24/2022 23:58:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/24/2022 23:58:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/24/2022 23:58:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/24/2022 23:58:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/24/2022 23:58:42 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9100423590746171 on epoch=192
06/24/2022 23:58:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/24/2022 23:58:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/24/2022 23:58:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/24/2022 23:58:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/24/2022 23:58:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/24/2022 23:59:01 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8426555215617716 on epoch=196
06/24/2022 23:59:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/24/2022 23:59:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/24/2022 23:59:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/24/2022 23:59:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/24/2022 23:59:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/24/2022 23:59:21 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8467152317811035 on epoch=199
06/24/2022 23:59:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/24/2022 23:59:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/24/2022 23:59:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/24/2022 23:59:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/24/2022 23:59:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/24/2022 23:59:40 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9013285565009703 on epoch=203
06/24/2022 23:59:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/24/2022 23:59:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/24/2022 23:59:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/24/2022 23:59:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/24/2022 23:59:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/25/2022 00:00:00 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9052963449848878 on epoch=207
06/25/2022 00:00:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/25/2022 00:00:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/25/2022 00:00:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/25/2022 00:00:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/25/2022 00:00:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/25/2022 00:00:19 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8970908076379842 on epoch=210
06/25/2022 00:00:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/25/2022 00:00:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/25/2022 00:00:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/25/2022 00:00:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/25/2022 00:00:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/25/2022 00:00:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:00:33 - INFO - __main__ - Printing 3 examples
06/25/2022 00:00:33 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/25/2022 00:00:33 - INFO - __main__ - ['Animal']
06/25/2022 00:00:33 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/25/2022 00:00:33 - INFO - __main__ - ['Animal']
06/25/2022 00:00:33 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/25/2022 00:00:33 - INFO - __main__ - ['Animal']
06/25/2022 00:00:33 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:00:34 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:00:34 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 00:00:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:00:34 - INFO - __main__ - Printing 3 examples
06/25/2022 00:00:34 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/25/2022 00:00:34 - INFO - __main__ - ['Animal']
06/25/2022 00:00:34 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/25/2022 00:00:34 - INFO - __main__ - ['Animal']
06/25/2022 00:00:34 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/25/2022 00:00:34 - INFO - __main__ - ['Animal']
06/25/2022 00:00:34 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:00:34 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:00:34 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 00:00:39 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9035948191593354 on epoch=214
06/25/2022 00:00:39 - INFO - __main__ - save last model!
06/25/2022 00:00:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 00:00:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 00:00:39 - INFO - __main__ - Printing 3 examples
06/25/2022 00:00:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 00:00:39 - INFO - __main__ - ['Animal']
06/25/2022 00:00:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 00:00:39 - INFO - __main__ - ['Animal']
06/25/2022 00:00:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 00:00:39 - INFO - __main__ - ['Village']
06/25/2022 00:00:39 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:00:41 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:00:44 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 00:00:53 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:00:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 00:00:54 - INFO - __main__ - Starting training!
06/25/2022 00:02:56 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/25/2022 00:02:56 - INFO - __main__ - Classification-F1 on test data: 0.5643
06/25/2022 00:02:56 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9773678606339897, test_performance=0.5643124935090912
06/25/2022 00:02:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/25/2022 00:02:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:02:57 - INFO - __main__ - Printing 3 examples
06/25/2022 00:02:57 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/25/2022 00:02:57 - INFO - __main__ - ['Animal']
06/25/2022 00:02:57 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/25/2022 00:02:57 - INFO - __main__ - ['Animal']
06/25/2022 00:02:57 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/25/2022 00:02:57 - INFO - __main__ - ['Animal']
06/25/2022 00:02:57 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:02:57 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:02:57 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 00:02:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:02:57 - INFO - __main__ - Printing 3 examples
06/25/2022 00:02:57 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/25/2022 00:02:57 - INFO - __main__ - ['Animal']
06/25/2022 00:02:57 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/25/2022 00:02:57 - INFO - __main__ - ['Animal']
06/25/2022 00:02:57 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/25/2022 00:02:57 - INFO - __main__ - ['Animal']
06/25/2022 00:02:57 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:02:57 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:02:58 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 00:03:13 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:03:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 00:03:14 - INFO - __main__ - Starting training!
06/25/2022 00:03:18 - INFO - __main__ - Step 10 Global step 10 Train loss 6.27 on epoch=0
06/25/2022 00:03:20 - INFO - __main__ - Step 20 Global step 20 Train loss 5.35 on epoch=1
06/25/2022 00:03:23 - INFO - __main__ - Step 30 Global step 30 Train loss 5.05 on epoch=2
06/25/2022 00:03:25 - INFO - __main__ - Step 40 Global step 40 Train loss 4.53 on epoch=2
06/25/2022 00:03:28 - INFO - __main__ - Step 50 Global step 50 Train loss 4.32 on epoch=3
06/25/2022 00:03:34 - INFO - __main__ - Global step 50 Train loss 5.10 Classification-F1 0.039595937340298246 on epoch=3
06/25/2022 00:03:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.039595937340298246 on epoch=3, global_step=50
06/25/2022 00:03:36 - INFO - __main__ - Step 60 Global step 60 Train loss 4.07 on epoch=4
06/25/2022 00:03:39 - INFO - __main__ - Step 70 Global step 70 Train loss 3.75 on epoch=4
06/25/2022 00:03:41 - INFO - __main__ - Step 80 Global step 80 Train loss 3.44 on epoch=5
06/25/2022 00:03:44 - INFO - __main__ - Step 90 Global step 90 Train loss 3.46 on epoch=6
06/25/2022 00:03:46 - INFO - __main__ - Step 100 Global step 100 Train loss 3.32 on epoch=7
06/25/2022 00:03:52 - INFO - __main__ - Global step 100 Train loss 3.61 Classification-F1 0.05549101600018741 on epoch=7
06/25/2022 00:03:52 - INFO - __main__ - Saving model with best Classification-F1: 0.039595937340298246 -> 0.05549101600018741 on epoch=7, global_step=100
06/25/2022 00:03:54 - INFO - __main__ - Step 110 Global step 110 Train loss 3.03 on epoch=7
06/25/2022 00:03:57 - INFO - __main__ - Step 120 Global step 120 Train loss 3.01 on epoch=8
06/25/2022 00:04:00 - INFO - __main__ - Step 130 Global step 130 Train loss 2.82 on epoch=9
06/25/2022 00:04:02 - INFO - __main__ - Step 140 Global step 140 Train loss 2.73 on epoch=9
06/25/2022 00:04:05 - INFO - __main__ - Step 150 Global step 150 Train loss 2.56 on epoch=10
06/25/2022 00:04:10 - INFO - __main__ - Global step 150 Train loss 2.83 Classification-F1 0.06737520128824477 on epoch=10
06/25/2022 00:04:10 - INFO - __main__ - Saving model with best Classification-F1: 0.05549101600018741 -> 0.06737520128824477 on epoch=10, global_step=150
06/25/2022 00:04:13 - INFO - __main__ - Step 160 Global step 160 Train loss 2.48 on epoch=11
06/25/2022 00:04:15 - INFO - __main__ - Step 170 Global step 170 Train loss 2.43 on epoch=12
06/25/2022 00:04:18 - INFO - __main__ - Step 180 Global step 180 Train loss 2.20 on epoch=12
06/25/2022 00:04:20 - INFO - __main__ - Step 190 Global step 190 Train loss 2.24 on epoch=13
06/25/2022 00:04:23 - INFO - __main__ - Step 200 Global step 200 Train loss 2.20 on epoch=14
06/25/2022 00:04:28 - INFO - __main__ - Global step 200 Train loss 2.31 Classification-F1 0.0835728903334537 on epoch=14
06/25/2022 00:04:28 - INFO - __main__ - Saving model with best Classification-F1: 0.06737520128824477 -> 0.0835728903334537 on epoch=14, global_step=200
06/25/2022 00:04:31 - INFO - __main__ - Step 210 Global step 210 Train loss 2.11 on epoch=14
06/25/2022 00:04:33 - INFO - __main__ - Step 220 Global step 220 Train loss 2.06 on epoch=15
06/25/2022 00:04:36 - INFO - __main__ - Step 230 Global step 230 Train loss 1.81 on epoch=16
06/25/2022 00:04:38 - INFO - __main__ - Step 240 Global step 240 Train loss 2.03 on epoch=17
06/25/2022 00:04:41 - INFO - __main__ - Step 250 Global step 250 Train loss 1.85 on epoch=17
06/25/2022 00:04:47 - INFO - __main__ - Global step 250 Train loss 1.97 Classification-F1 0.09214885727918787 on epoch=17
06/25/2022 00:04:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0835728903334537 -> 0.09214885727918787 on epoch=17, global_step=250
06/25/2022 00:04:49 - INFO - __main__ - Step 260 Global step 260 Train loss 1.75 on epoch=18
06/25/2022 00:04:52 - INFO - __main__ - Step 270 Global step 270 Train loss 1.73 on epoch=19
06/25/2022 00:04:54 - INFO - __main__ - Step 280 Global step 280 Train loss 1.59 on epoch=19
06/25/2022 00:04:57 - INFO - __main__ - Step 290 Global step 290 Train loss 1.64 on epoch=20
06/25/2022 00:05:00 - INFO - __main__ - Step 300 Global step 300 Train loss 1.47 on epoch=21
06/25/2022 00:05:05 - INFO - __main__ - Global step 300 Train loss 1.64 Classification-F1 0.10935784324988201 on epoch=21
06/25/2022 00:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.09214885727918787 -> 0.10935784324988201 on epoch=21, global_step=300
06/25/2022 00:05:08 - INFO - __main__ - Step 310 Global step 310 Train loss 1.44 on epoch=22
06/25/2022 00:05:10 - INFO - __main__ - Step 320 Global step 320 Train loss 1.39 on epoch=22
06/25/2022 00:05:13 - INFO - __main__ - Step 330 Global step 330 Train loss 1.41 on epoch=23
06/25/2022 00:05:16 - INFO - __main__ - Step 340 Global step 340 Train loss 1.41 on epoch=24
06/25/2022 00:05:18 - INFO - __main__ - Step 350 Global step 350 Train loss 1.11 on epoch=24
06/25/2022 00:05:24 - INFO - __main__ - Global step 350 Train loss 1.35 Classification-F1 0.1271614694808085 on epoch=24
06/25/2022 00:05:24 - INFO - __main__ - Saving model with best Classification-F1: 0.10935784324988201 -> 0.1271614694808085 on epoch=24, global_step=350
06/25/2022 00:05:26 - INFO - __main__ - Step 360 Global step 360 Train loss 1.25 on epoch=25
06/25/2022 00:05:29 - INFO - __main__ - Step 370 Global step 370 Train loss 1.10 on epoch=26
06/25/2022 00:05:32 - INFO - __main__ - Step 380 Global step 380 Train loss 1.08 on epoch=27
06/25/2022 00:05:34 - INFO - __main__ - Step 390 Global step 390 Train loss 1.11 on epoch=27
06/25/2022 00:05:37 - INFO - __main__ - Step 400 Global step 400 Train loss 1.03 on epoch=28
06/25/2022 00:05:43 - INFO - __main__ - Global step 400 Train loss 1.11 Classification-F1 0.18617790983823318 on epoch=28
06/25/2022 00:05:43 - INFO - __main__ - Saving model with best Classification-F1: 0.1271614694808085 -> 0.18617790983823318 on epoch=28, global_step=400
06/25/2022 00:05:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.98 on epoch=29
06/25/2022 00:05:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.89 on epoch=29
06/25/2022 00:05:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.88 on epoch=30
06/25/2022 00:05:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.76 on epoch=31
06/25/2022 00:05:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.95 on epoch=32
06/25/2022 00:06:02 - INFO - __main__ - Global step 450 Train loss 0.89 Classification-F1 0.28061937093409256 on epoch=32
06/25/2022 00:06:02 - INFO - __main__ - Saving model with best Classification-F1: 0.18617790983823318 -> 0.28061937093409256 on epoch=32, global_step=450
06/25/2022 00:06:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.85 on epoch=32
06/25/2022 00:06:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.68 on epoch=33
06/25/2022 00:06:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.73 on epoch=34
06/25/2022 00:06:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.77 on epoch=34
06/25/2022 00:06:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.66 on epoch=35
06/25/2022 00:06:22 - INFO - __main__ - Global step 500 Train loss 0.74 Classification-F1 0.3105602411424239 on epoch=35
06/25/2022 00:06:22 - INFO - __main__ - Saving model with best Classification-F1: 0.28061937093409256 -> 0.3105602411424239 on epoch=35, global_step=500
06/25/2022 00:06:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.66 on epoch=36
06/25/2022 00:06:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.62 on epoch=37
06/25/2022 00:06:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.72 on epoch=37
06/25/2022 00:06:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.65 on epoch=38
06/25/2022 00:06:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.66 on epoch=39
06/25/2022 00:06:42 - INFO - __main__ - Global step 550 Train loss 0.66 Classification-F1 0.339998768913185 on epoch=39
06/25/2022 00:06:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3105602411424239 -> 0.339998768913185 on epoch=39, global_step=550
06/25/2022 00:06:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=39
06/25/2022 00:06:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.54 on epoch=40
06/25/2022 00:06:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.53 on epoch=41
06/25/2022 00:06:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.51 on epoch=42
06/25/2022 00:06:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.52 on epoch=42
06/25/2022 00:07:02 - INFO - __main__ - Global step 600 Train loss 0.53 Classification-F1 0.35617390674251714 on epoch=42
06/25/2022 00:07:02 - INFO - __main__ - Saving model with best Classification-F1: 0.339998768913185 -> 0.35617390674251714 on epoch=42, global_step=600
06/25/2022 00:07:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.55 on epoch=43
06/25/2022 00:07:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.61 on epoch=44
06/25/2022 00:07:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.50 on epoch=44
06/25/2022 00:07:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.56 on epoch=45
06/25/2022 00:07:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=46
06/25/2022 00:07:22 - INFO - __main__ - Global step 650 Train loss 0.55 Classification-F1 0.44225474908674506 on epoch=46
06/25/2022 00:07:22 - INFO - __main__ - Saving model with best Classification-F1: 0.35617390674251714 -> 0.44225474908674506 on epoch=46, global_step=650
06/25/2022 00:07:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=47
06/25/2022 00:07:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.45 on epoch=47
06/25/2022 00:07:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=48
06/25/2022 00:07:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=49
06/25/2022 00:07:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=49
06/25/2022 00:07:43 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.4185544872154994 on epoch=49
06/25/2022 00:07:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.47 on epoch=50
06/25/2022 00:07:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=51
06/25/2022 00:07:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.43 on epoch=52
06/25/2022 00:07:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=52
06/25/2022 00:07:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/25/2022 00:08:03 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.5401921422030571 on epoch=53
06/25/2022 00:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.44225474908674506 -> 0.5401921422030571 on epoch=53, global_step=750
06/25/2022 00:08:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=54
06/25/2022 00:08:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.46 on epoch=54
06/25/2022 00:08:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=55
06/25/2022 00:08:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=56
06/25/2022 00:08:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.40 on epoch=57
06/25/2022 00:08:24 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.5357508140073007 on epoch=57
06/25/2022 00:08:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
06/25/2022 00:08:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=58
06/25/2022 00:08:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.35 on epoch=59
06/25/2022 00:08:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.36 on epoch=59
06/25/2022 00:08:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.43 on epoch=60
06/25/2022 00:08:44 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.5788025574132614 on epoch=60
06/25/2022 00:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5401921422030571 -> 0.5788025574132614 on epoch=60, global_step=850
06/25/2022 00:08:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.28 on epoch=61
06/25/2022 00:08:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.41 on epoch=62
06/25/2022 00:08:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=62
06/25/2022 00:08:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=63
06/25/2022 00:08:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=64
06/25/2022 00:09:05 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.5635334017140835 on epoch=64
06/25/2022 00:09:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=64
06/25/2022 00:09:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=65
06/25/2022 00:09:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=66
06/25/2022 00:09:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=67
06/25/2022 00:09:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=67
06/25/2022 00:09:25 - INFO - __main__ - Global step 950 Train loss 0.32 Classification-F1 0.547129782649887 on epoch=67
06/25/2022 00:09:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=68
06/25/2022 00:09:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=69
06/25/2022 00:09:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.26 on epoch=69
06/25/2022 00:09:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=70
06/25/2022 00:09:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=71
06/25/2022 00:09:46 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.6441539576015382 on epoch=71
06/25/2022 00:09:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5788025574132614 -> 0.6441539576015382 on epoch=71, global_step=1000
06/25/2022 00:09:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.31 on epoch=72
06/25/2022 00:09:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=72
06/25/2022 00:09:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/25/2022 00:09:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.37 on epoch=74
06/25/2022 00:09:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=74
06/25/2022 00:10:07 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.5938798507346894 on epoch=74
06/25/2022 00:10:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=75
06/25/2022 00:10:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=76
06/25/2022 00:10:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.29 on epoch=77
06/25/2022 00:10:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
06/25/2022 00:10:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=78
06/25/2022 00:10:27 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.633203504545822 on epoch=78
06/25/2022 00:10:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=79
06/25/2022 00:10:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=79
06/25/2022 00:10:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.28 on epoch=80
06/25/2022 00:10:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/25/2022 00:10:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=82
06/25/2022 00:10:47 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.5703214460840094 on epoch=82
06/25/2022 00:10:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/25/2022 00:10:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=83
06/25/2022 00:10:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.29 on epoch=84
06/25/2022 00:10:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=84
06/25/2022 00:11:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=85
06/25/2022 00:11:08 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.6015744730606482 on epoch=85
06/25/2022 00:11:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/25/2022 00:11:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=87
06/25/2022 00:11:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
06/25/2022 00:11:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=88
06/25/2022 00:11:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.30 on epoch=89
06/25/2022 00:11:28 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.6045535728139415 on epoch=89
06/25/2022 00:11:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=89
06/25/2022 00:11:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=90
06/25/2022 00:11:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
06/25/2022 00:11:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=92
06/25/2022 00:11:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=92
06/25/2022 00:11:49 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5661674587035189 on epoch=92
06/25/2022 00:11:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=93
06/25/2022 00:11:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=94
06/25/2022 00:11:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=94
06/25/2022 00:11:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=95
06/25/2022 00:12:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=96
06/25/2022 00:12:09 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.5661674587035189 on epoch=96
06/25/2022 00:12:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.27 on epoch=97
06/25/2022 00:12:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/25/2022 00:12:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/25/2022 00:12:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
06/25/2022 00:12:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=99
06/25/2022 00:12:30 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.6246958915531022 on epoch=99
06/25/2022 00:12:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=100
06/25/2022 00:12:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.22 on epoch=101
06/25/2022 00:12:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.24 on epoch=102
06/25/2022 00:12:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=102
06/25/2022 00:12:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=103
06/25/2022 00:12:50 - INFO - __main__ - Global step 1450 Train loss 0.20 Classification-F1 0.6278208915531023 on epoch=103
06/25/2022 00:12:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/25/2022 00:12:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=104
06/25/2022 00:12:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
06/25/2022 00:13:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/25/2022 00:13:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
06/25/2022 00:13:11 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.6278208915531023 on epoch=107
06/25/2022 00:13:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=107
06/25/2022 00:13:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.17 on epoch=108
06/25/2022 00:13:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.24 on epoch=109
06/25/2022 00:13:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=109
06/25/2022 00:13:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=110
06/25/2022 00:13:31 - INFO - __main__ - Global step 1550 Train loss 0.18 Classification-F1 0.659272415556746 on epoch=110
06/25/2022 00:13:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6441539576015382 -> 0.659272415556746 on epoch=110, global_step=1550
06/25/2022 00:13:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=111
06/25/2022 00:13:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.22 on epoch=112
06/25/2022 00:13:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/25/2022 00:13:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=113
06/25/2022 00:13:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=114
06/25/2022 00:13:51 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.5988324613302549 on epoch=114
06/25/2022 00:13:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/25/2022 00:13:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=115
06/25/2022 00:13:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=116
06/25/2022 00:14:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=117
06/25/2022 00:14:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=117
06/25/2022 00:14:12 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.7294270983075537 on epoch=117
06/25/2022 00:14:12 - INFO - __main__ - Saving model with best Classification-F1: 0.659272415556746 -> 0.7294270983075537 on epoch=117, global_step=1650
06/25/2022 00:14:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/25/2022 00:14:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=119
06/25/2022 00:14:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=119
06/25/2022 00:14:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=120
06/25/2022 00:14:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
06/25/2022 00:14:32 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.725279119467924 on epoch=121
06/25/2022 00:14:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
06/25/2022 00:14:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=122
06/25/2022 00:14:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=123
06/25/2022 00:14:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/25/2022 00:14:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/25/2022 00:14:53 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.755482077844257 on epoch=124
06/25/2022 00:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7294270983075537 -> 0.755482077844257 on epoch=124, global_step=1750
06/25/2022 00:14:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/25/2022 00:14:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=126
06/25/2022 00:15:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.17 on epoch=127
06/25/2022 00:15:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=127
06/25/2022 00:15:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=128
06/25/2022 00:15:13 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.7371000237252051 on epoch=128
06/25/2022 00:15:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=129
06/25/2022 00:15:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/25/2022 00:15:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
06/25/2022 00:15:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
06/25/2022 00:15:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=132
06/25/2022 00:15:33 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.7024467506009946 on epoch=132
06/25/2022 00:15:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=132
06/25/2022 00:15:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=133
06/25/2022 00:15:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.16 on epoch=134
06/25/2022 00:15:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=134
06/25/2022 00:15:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/25/2022 00:15:53 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.784786424017992 on epoch=135
06/25/2022 00:15:53 - INFO - __main__ - Saving model with best Classification-F1: 0.755482077844257 -> 0.784786424017992 on epoch=135, global_step=1900
06/25/2022 00:15:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
06/25/2022 00:15:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=137
06/25/2022 00:16:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/25/2022 00:16:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/25/2022 00:16:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/25/2022 00:16:14 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7957824555485877 on epoch=139
06/25/2022 00:16:14 - INFO - __main__ - Saving model with best Classification-F1: 0.784786424017992 -> 0.7957824555485877 on epoch=139, global_step=1950
06/25/2022 00:16:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
06/25/2022 00:16:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
06/25/2022 00:16:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=141
06/25/2022 00:16:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
06/25/2022 00:16:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
06/25/2022 00:16:34 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.7713621107066854 on epoch=142
06/25/2022 00:16:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
06/25/2022 00:16:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/25/2022 00:16:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/25/2022 00:16:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/25/2022 00:16:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
06/25/2022 00:16:54 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.7910959425180439 on epoch=146
06/25/2022 00:16:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=147
06/25/2022 00:16:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/25/2022 00:17:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
06/25/2022 00:17:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/25/2022 00:17:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=149
06/25/2022 00:17:14 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.8205240981392006 on epoch=149
06/25/2022 00:17:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7957824555485877 -> 0.8205240981392006 on epoch=149, global_step=2100
06/25/2022 00:17:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/25/2022 00:17:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
06/25/2022 00:17:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/25/2022 00:17:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/25/2022 00:17:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/25/2022 00:17:35 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.758642959785078 on epoch=153
06/25/2022 00:17:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=154
06/25/2022 00:17:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
06/25/2022 00:17:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/25/2022 00:17:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/25/2022 00:17:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=157
06/25/2022 00:17:55 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.7671991095176983 on epoch=157
06/25/2022 00:17:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=157
06/25/2022 00:18:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=158
06/25/2022 00:18:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=159
06/25/2022 00:18:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/25/2022 00:18:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
06/25/2022 00:18:15 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.7231129135699028 on epoch=160
06/25/2022 00:18:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/25/2022 00:18:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/25/2022 00:18:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=162
06/25/2022 00:18:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/25/2022 00:18:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/25/2022 00:18:36 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7823871620807663 on epoch=164
06/25/2022 00:18:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/25/2022 00:18:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.11 on epoch=165
06/25/2022 00:18:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/25/2022 00:18:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/25/2022 00:18:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=167
06/25/2022 00:18:56 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.7785751431847536 on epoch=167
06/25/2022 00:18:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/25/2022 00:19:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/25/2022 00:19:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=169
06/25/2022 00:19:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=170
06/25/2022 00:19:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/25/2022 00:19:16 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7430347336248138 on epoch=171
06/25/2022 00:19:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/25/2022 00:19:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/25/2022 00:19:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/25/2022 00:19:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/25/2022 00:19:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/25/2022 00:19:36 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.7867462529450475 on epoch=174
06/25/2022 00:19:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=175
06/25/2022 00:19:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/25/2022 00:19:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=177
06/25/2022 00:19:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/25/2022 00:19:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/25/2022 00:19:56 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.7894333226262494 on epoch=178
06/25/2022 00:19:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
06/25/2022 00:20:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
06/25/2022 00:20:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=180
06/25/2022 00:20:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/25/2022 00:20:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/25/2022 00:20:17 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7933332438160468 on epoch=182
06/25/2022 00:20:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.09 on epoch=182
06/25/2022 00:20:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=183
06/25/2022 00:20:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/25/2022 00:20:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/25/2022 00:20:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=185
06/25/2022 00:20:36 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.743133763135608 on epoch=185
06/25/2022 00:20:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/25/2022 00:20:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/25/2022 00:20:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/25/2022 00:20:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/25/2022 00:20:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/25/2022 00:20:56 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7492591747151552 on epoch=189
06/25/2022 00:20:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
06/25/2022 00:21:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=190
06/25/2022 00:21:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/25/2022 00:21:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/25/2022 00:21:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/25/2022 00:21:16 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7955004616992563 on epoch=192
06/25/2022 00:21:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/25/2022 00:21:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/25/2022 00:21:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
06/25/2022 00:21:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/25/2022 00:21:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/25/2022 00:21:36 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.7457739748352684 on epoch=196
06/25/2022 00:21:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
06/25/2022 00:21:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/25/2022 00:21:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
06/25/2022 00:21:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/25/2022 00:21:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
06/25/2022 00:21:56 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7992666930494814 on epoch=199
06/25/2022 00:21:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/25/2022 00:22:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/25/2022 00:22:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
06/25/2022 00:22:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/25/2022 00:22:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=203
06/25/2022 00:22:16 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.7471688227262231 on epoch=203
06/25/2022 00:22:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.11 on epoch=204
06/25/2022 00:22:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/25/2022 00:22:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/25/2022 00:22:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/25/2022 00:22:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/25/2022 00:22:37 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7934380985921818 on epoch=207
06/25/2022 00:22:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/25/2022 00:22:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/25/2022 00:22:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/25/2022 00:22:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/25/2022 00:22:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.15 on epoch=210
06/25/2022 00:22:57 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.7970133082171738 on epoch=210
06/25/2022 00:22:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/25/2022 00:23:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=212
06/25/2022 00:23:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/25/2022 00:23:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/25/2022 00:23:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/25/2022 00:23:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:23:11 - INFO - __main__ - Printing 3 examples
06/25/2022 00:23:11 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 00:23:11 - INFO - __main__ - ['Plant']
06/25/2022 00:23:11 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 00:23:11 - INFO - __main__ - ['Plant']
06/25/2022 00:23:11 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 00:23:11 - INFO - __main__ - ['Plant']
06/25/2022 00:23:11 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:23:11 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:23:11 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 00:23:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:23:11 - INFO - __main__ - Printing 3 examples
06/25/2022 00:23:11 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 00:23:11 - INFO - __main__ - ['Plant']
06/25/2022 00:23:11 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 00:23:11 - INFO - __main__ - ['Plant']
06/25/2022 00:23:11 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 00:23:11 - INFO - __main__ - ['Plant']
06/25/2022 00:23:11 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:23:12 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:23:12 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 00:23:16 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7499717109246943 on epoch=214
06/25/2022 00:23:16 - INFO - __main__ - save last model!
06/25/2022 00:23:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 00:23:17 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 00:23:17 - INFO - __main__ - Printing 3 examples
06/25/2022 00:23:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 00:23:17 - INFO - __main__ - ['Animal']
06/25/2022 00:23:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 00:23:17 - INFO - __main__ - ['Animal']
06/25/2022 00:23:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 00:23:17 - INFO - __main__ - ['Village']
06/25/2022 00:23:17 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:23:19 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:23:22 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 00:23:30 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:23:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 00:23:31 - INFO - __main__ - Starting training!
06/25/2022 00:25:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/25/2022 00:25:33 - INFO - __main__ - Classification-F1 on test data: 0.4087
06/25/2022 00:25:34 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.8205240981392006, test_performance=0.40873915316088105
06/25/2022 00:25:34 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/25/2022 00:25:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:25:35 - INFO - __main__ - Printing 3 examples
06/25/2022 00:25:35 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 00:25:35 - INFO - __main__ - ['Plant']
06/25/2022 00:25:35 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 00:25:35 - INFO - __main__ - ['Plant']
06/25/2022 00:25:35 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 00:25:35 - INFO - __main__ - ['Plant']
06/25/2022 00:25:35 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:25:35 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:25:35 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 00:25:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:25:35 - INFO - __main__ - Printing 3 examples
06/25/2022 00:25:35 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 00:25:35 - INFO - __main__ - ['Plant']
06/25/2022 00:25:35 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 00:25:35 - INFO - __main__ - ['Plant']
06/25/2022 00:25:35 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 00:25:35 - INFO - __main__ - ['Plant']
06/25/2022 00:25:35 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:25:35 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:25:35 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 00:25:50 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:25:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 00:25:51 - INFO - __main__ - Starting training!
06/25/2022 00:25:55 - INFO - __main__ - Step 10 Global step 10 Train loss 6.01 on epoch=0
06/25/2022 00:25:57 - INFO - __main__ - Step 20 Global step 20 Train loss 4.43 on epoch=1
06/25/2022 00:26:00 - INFO - __main__ - Step 30 Global step 30 Train loss 3.96 on epoch=2
06/25/2022 00:26:02 - INFO - __main__ - Step 40 Global step 40 Train loss 3.29 on epoch=2
06/25/2022 00:26:05 - INFO - __main__ - Step 50 Global step 50 Train loss 3.10 on epoch=3
06/25/2022 00:26:10 - INFO - __main__ - Global step 50 Train loss 4.16 Classification-F1 0.06665040945252788 on epoch=3
06/25/2022 00:26:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06665040945252788 on epoch=3, global_step=50
06/25/2022 00:26:13 - INFO - __main__ - Step 60 Global step 60 Train loss 2.66 on epoch=4
06/25/2022 00:26:16 - INFO - __main__ - Step 70 Global step 70 Train loss 2.55 on epoch=4
06/25/2022 00:26:18 - INFO - __main__ - Step 80 Global step 80 Train loss 2.12 on epoch=5
06/25/2022 00:26:21 - INFO - __main__ - Step 90 Global step 90 Train loss 1.97 on epoch=6
06/25/2022 00:26:24 - INFO - __main__ - Step 100 Global step 100 Train loss 1.89 on epoch=7
06/25/2022 00:26:29 - INFO - __main__ - Global step 100 Train loss 2.24 Classification-F1 0.10104312267321672 on epoch=7
06/25/2022 00:26:29 - INFO - __main__ - Saving model with best Classification-F1: 0.06665040945252788 -> 0.10104312267321672 on epoch=7, global_step=100
06/25/2022 00:26:32 - INFO - __main__ - Step 110 Global step 110 Train loss 1.58 on epoch=7
06/25/2022 00:26:34 - INFO - __main__ - Step 120 Global step 120 Train loss 1.66 on epoch=8
06/25/2022 00:26:37 - INFO - __main__ - Step 130 Global step 130 Train loss 1.35 on epoch=9
06/25/2022 00:26:40 - INFO - __main__ - Step 140 Global step 140 Train loss 1.38 on epoch=9
06/25/2022 00:26:42 - INFO - __main__ - Step 150 Global step 150 Train loss 1.16 on epoch=10
06/25/2022 00:26:48 - INFO - __main__ - Global step 150 Train loss 1.43 Classification-F1 0.1329491857555556 on epoch=10
06/25/2022 00:26:48 - INFO - __main__ - Saving model with best Classification-F1: 0.10104312267321672 -> 0.1329491857555556 on epoch=10, global_step=150
06/25/2022 00:26:51 - INFO - __main__ - Step 160 Global step 160 Train loss 1.19 on epoch=11
06/25/2022 00:26:53 - INFO - __main__ - Step 170 Global step 170 Train loss 1.01 on epoch=12
06/25/2022 00:26:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=12
06/25/2022 00:26:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=13
06/25/2022 00:27:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=14
06/25/2022 00:27:08 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.2910469021401732 on epoch=14
06/25/2022 00:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1329491857555556 -> 0.2910469021401732 on epoch=14, global_step=200
06/25/2022 00:27:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=14
06/25/2022 00:27:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=15
06/25/2022 00:27:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=16
06/25/2022 00:27:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=17
06/25/2022 00:27:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=17
06/25/2022 00:27:28 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.440140195990778 on epoch=17
06/25/2022 00:27:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2910469021401732 -> 0.440140195990778 on epoch=17, global_step=250
06/25/2022 00:27:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=18
06/25/2022 00:27:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=19
06/25/2022 00:27:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=19
06/25/2022 00:27:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=20
06/25/2022 00:27:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=21
06/25/2022 00:27:49 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.4272248308324125 on epoch=21
06/25/2022 00:27:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=22
06/25/2022 00:27:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/25/2022 00:27:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
06/25/2022 00:28:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=24
06/25/2022 00:28:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=24
06/25/2022 00:28:10 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.5367703143648574 on epoch=24
06/25/2022 00:28:10 - INFO - __main__ - Saving model with best Classification-F1: 0.440140195990778 -> 0.5367703143648574 on epoch=24, global_step=350
06/25/2022 00:28:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=25
06/25/2022 00:28:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
06/25/2022 00:28:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
06/25/2022 00:28:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
06/25/2022 00:28:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
06/25/2022 00:28:31 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6110676929534075 on epoch=28
06/25/2022 00:28:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5367703143648574 -> 0.6110676929534075 on epoch=28, global_step=400
06/25/2022 00:28:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/25/2022 00:28:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=29
06/25/2022 00:28:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/25/2022 00:28:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
06/25/2022 00:28:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=32
06/25/2022 00:28:52 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6045477990883998 on epoch=32
06/25/2022 00:28:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
06/25/2022 00:28:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=33
06/25/2022 00:28:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=34
06/25/2022 00:29:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
06/25/2022 00:29:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
06/25/2022 00:29:12 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.5509495347671108 on epoch=35
06/25/2022 00:29:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
06/25/2022 00:29:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=37
06/25/2022 00:29:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/25/2022 00:29:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/25/2022 00:29:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
06/25/2022 00:29:33 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.5764377441069799 on epoch=39
06/25/2022 00:29:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/25/2022 00:29:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/25/2022 00:29:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
06/25/2022 00:29:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=42
06/25/2022 00:29:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=42
06/25/2022 00:29:54 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.6046321803319366 on epoch=42
06/25/2022 00:29:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=43
06/25/2022 00:30:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/25/2022 00:30:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/25/2022 00:30:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/25/2022 00:30:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/25/2022 00:30:15 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5348010151063867 on epoch=46
06/25/2022 00:30:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/25/2022 00:30:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
06/25/2022 00:30:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/25/2022 00:30:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/25/2022 00:30:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/25/2022 00:30:36 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.620623164353652 on epoch=49
06/25/2022 00:30:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6110676929534075 -> 0.620623164353652 on epoch=49, global_step=700
06/25/2022 00:30:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/25/2022 00:30:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=51
06/25/2022 00:30:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/25/2022 00:30:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/25/2022 00:30:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=53
06/25/2022 00:30:57 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6930411384098627 on epoch=53
06/25/2022 00:30:57 - INFO - __main__ - Saving model with best Classification-F1: 0.620623164353652 -> 0.6930411384098627 on epoch=53, global_step=750
06/25/2022 00:31:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/25/2022 00:31:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/25/2022 00:31:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/25/2022 00:31:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/25/2022 00:31:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
06/25/2022 00:31:18 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7023694798587812 on epoch=57
06/25/2022 00:31:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6930411384098627 -> 0.7023694798587812 on epoch=57, global_step=800
06/25/2022 00:31:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/25/2022 00:31:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/25/2022 00:31:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/25/2022 00:31:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/25/2022 00:31:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/25/2022 00:31:39 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7057301640844186 on epoch=60
06/25/2022 00:31:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7023694798587812 -> 0.7057301640844186 on epoch=60, global_step=850
06/25/2022 00:31:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/25/2022 00:31:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/25/2022 00:31:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
06/25/2022 00:31:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
06/25/2022 00:31:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/25/2022 00:32:00 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7039725698036935 on epoch=64
06/25/2022 00:32:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/25/2022 00:32:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/25/2022 00:32:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
06/25/2022 00:32:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
06/25/2022 00:32:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/25/2022 00:32:22 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7743189327002176 on epoch=67
06/25/2022 00:32:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7057301640844186 -> 0.7743189327002176 on epoch=67, global_step=950
06/25/2022 00:32:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/25/2022 00:32:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/25/2022 00:32:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/25/2022 00:32:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/25/2022 00:32:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/25/2022 00:32:43 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7843742368731688 on epoch=71
06/25/2022 00:32:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7743189327002176 -> 0.7843742368731688 on epoch=71, global_step=1000
06/25/2022 00:32:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/25/2022 00:32:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/25/2022 00:32:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/25/2022 00:32:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
06/25/2022 00:32:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/25/2022 00:33:05 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7885495822249848 on epoch=74
06/25/2022 00:33:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7843742368731688 -> 0.7885495822249848 on epoch=74, global_step=1050
06/25/2022 00:33:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/25/2022 00:33:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/25/2022 00:33:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/25/2022 00:33:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/25/2022 00:33:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/25/2022 00:33:26 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8043799904429363 on epoch=78
06/25/2022 00:33:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7885495822249848 -> 0.8043799904429363 on epoch=78, global_step=1100
06/25/2022 00:33:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/25/2022 00:33:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/25/2022 00:33:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/25/2022 00:33:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/25/2022 00:33:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/25/2022 00:33:47 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8471786090308304 on epoch=82
06/25/2022 00:33:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8043799904429363 -> 0.8471786090308304 on epoch=82, global_step=1150
06/25/2022 00:33:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/25/2022 00:33:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/25/2022 00:33:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/25/2022 00:33:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/25/2022 00:34:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
06/25/2022 00:34:09 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.9058077206006279 on epoch=85
06/25/2022 00:34:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8471786090308304 -> 0.9058077206006279 on epoch=85, global_step=1200
06/25/2022 00:34:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/25/2022 00:34:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/25/2022 00:34:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/25/2022 00:34:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/25/2022 00:34:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/25/2022 00:34:30 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.836020581253029 on epoch=89
06/25/2022 00:34:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/25/2022 00:34:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/25/2022 00:34:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/25/2022 00:34:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/25/2022 00:34:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/25/2022 00:34:51 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7719645200158193 on epoch=92
06/25/2022 00:34:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/25/2022 00:34:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/25/2022 00:34:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/25/2022 00:35:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/25/2022 00:35:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/25/2022 00:35:12 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7187485048112909 on epoch=96
06/25/2022 00:35:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/25/2022 00:35:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/25/2022 00:35:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/25/2022 00:35:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/25/2022 00:35:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/25/2022 00:35:33 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6862397392159675 on epoch=99
06/25/2022 00:35:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/25/2022 00:35:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/25/2022 00:35:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/25/2022 00:35:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/25/2022 00:35:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/25/2022 00:35:54 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6615503021302873 on epoch=103
06/25/2022 00:35:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/25/2022 00:35:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/25/2022 00:36:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/25/2022 00:36:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/25/2022 00:36:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/25/2022 00:36:14 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6015267039900472 on epoch=107
06/25/2022 00:36:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/25/2022 00:36:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/25/2022 00:36:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/25/2022 00:36:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/25/2022 00:36:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/25/2022 00:36:35 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6433473377553401 on epoch=110
06/25/2022 00:36:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/25/2022 00:36:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/25/2022 00:36:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/25/2022 00:36:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/25/2022 00:36:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/25/2022 00:36:56 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7866867828917166 on epoch=114
06/25/2022 00:36:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/25/2022 00:37:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/25/2022 00:37:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/25/2022 00:37:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/25/2022 00:37:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/25/2022 00:37:17 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6625329193260882 on epoch=117
06/25/2022 00:37:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/25/2022 00:37:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
06/25/2022 00:37:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/25/2022 00:37:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/25/2022 00:37:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/25/2022 00:37:37 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6643870064601132 on epoch=121
06/25/2022 00:37:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/25/2022 00:37:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/25/2022 00:37:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/25/2022 00:37:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/25/2022 00:37:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/25/2022 00:37:57 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6530970863418682 on epoch=124
06/25/2022 00:38:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/25/2022 00:38:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
06/25/2022 00:38:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/25/2022 00:38:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/25/2022 00:38:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/25/2022 00:38:18 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6852804266179922 on epoch=128
06/25/2022 00:38:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/25/2022 00:38:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/25/2022 00:38:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/25/2022 00:38:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/25/2022 00:38:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/25/2022 00:38:38 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6277469021788107 on epoch=132
06/25/2022 00:38:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/25/2022 00:38:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/25/2022 00:38:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/25/2022 00:38:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/25/2022 00:38:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/25/2022 00:38:59 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.5847896632449441 on epoch=135
06/25/2022 00:39:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/25/2022 00:39:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/25/2022 00:39:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/25/2022 00:39:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/25/2022 00:39:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/25/2022 00:39:19 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.707541321822756 on epoch=139
06/25/2022 00:39:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/25/2022 00:39:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/25/2022 00:39:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/25/2022 00:39:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/25/2022 00:39:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/25/2022 00:39:39 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7091156388469881 on epoch=142
06/25/2022 00:39:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/25/2022 00:39:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/25/2022 00:39:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/25/2022 00:39:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/25/2022 00:39:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/25/2022 00:40:00 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8474409998603547 on epoch=146
06/25/2022 00:40:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/25/2022 00:40:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/25/2022 00:40:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/25/2022 00:40:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
06/25/2022 00:40:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/25/2022 00:40:20 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7107331194555304 on epoch=149
06/25/2022 00:40:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/25/2022 00:40:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/25/2022 00:40:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/25/2022 00:40:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/25/2022 00:40:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/25/2022 00:40:40 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.675554003606701 on epoch=153
06/25/2022 00:40:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/25/2022 00:40:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/25/2022 00:40:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/25/2022 00:40:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/25/2022 00:40:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/25/2022 00:41:01 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6941103837738213 on epoch=157
06/25/2022 00:41:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/25/2022 00:41:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/25/2022 00:41:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/25/2022 00:41:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/25/2022 00:41:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/25/2022 00:41:21 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7790262796510703 on epoch=160
06/25/2022 00:41:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/25/2022 00:41:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/25/2022 00:41:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/25/2022 00:41:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/25/2022 00:41:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/25/2022 00:41:42 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7417526842930068 on epoch=164
06/25/2022 00:41:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/25/2022 00:41:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/25/2022 00:41:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/25/2022 00:41:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/25/2022 00:41:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/25/2022 00:42:02 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7915890403082054 on epoch=167
06/25/2022 00:42:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/25/2022 00:42:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/25/2022 00:42:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/25/2022 00:42:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/25/2022 00:42:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/25/2022 00:42:23 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.855196878054741 on epoch=171
06/25/2022 00:42:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/25/2022 00:42:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/25/2022 00:42:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/25/2022 00:42:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/25/2022 00:42:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/25/2022 00:42:43 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8028750503133805 on epoch=174
06/25/2022 00:42:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/25/2022 00:42:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/25/2022 00:42:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/25/2022 00:42:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/25/2022 00:42:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/25/2022 00:43:03 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9018498552891342 on epoch=178
06/25/2022 00:43:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/25/2022 00:43:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/25/2022 00:43:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/25/2022 00:43:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/25/2022 00:43:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/25/2022 00:43:23 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8452238226668967 on epoch=182
06/25/2022 00:43:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/25/2022 00:43:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/25/2022 00:43:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/25/2022 00:43:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/25/2022 00:43:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/25/2022 00:43:44 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.795626963913045 on epoch=185
06/25/2022 00:43:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/25/2022 00:43:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/25/2022 00:43:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/25/2022 00:43:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/25/2022 00:43:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/25/2022 00:44:04 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9686808447719264 on epoch=189
06/25/2022 00:44:04 - INFO - __main__ - Saving model with best Classification-F1: 0.9058077206006279 -> 0.9686808447719264 on epoch=189, global_step=2650
06/25/2022 00:44:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/25/2022 00:44:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/25/2022 00:44:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/25/2022 00:44:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/25/2022 00:44:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/25/2022 00:44:24 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9022117488246522 on epoch=192
06/25/2022 00:44:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/25/2022 00:44:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/25/2022 00:44:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/25/2022 00:44:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/25/2022 00:44:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/25/2022 00:44:45 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9734099138189001 on epoch=196
06/25/2022 00:44:45 - INFO - __main__ - Saving model with best Classification-F1: 0.9686808447719264 -> 0.9734099138189001 on epoch=196, global_step=2750
06/25/2022 00:44:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/25/2022 00:44:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/25/2022 00:44:53 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/25/2022 00:44:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/25/2022 00:44:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/25/2022 00:45:05 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9731355298717729 on epoch=199
06/25/2022 00:45:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/25/2022 00:45:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/25/2022 00:45:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/25/2022 00:45:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/25/2022 00:45:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/25/2022 00:45:25 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9683481338232534 on epoch=203
06/25/2022 00:45:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/25/2022 00:45:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/25/2022 00:45:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/25/2022 00:45:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/25/2022 00:45:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/25/2022 00:45:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8475670079248708 on epoch=207
06/25/2022 00:45:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/25/2022 00:45:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/25/2022 00:45:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/25/2022 00:45:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/25/2022 00:45:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/25/2022 00:46:06 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=210
06/25/2022 00:46:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/25/2022 00:46:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/25/2022 00:46:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/25/2022 00:46:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/25/2022 00:46:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/25/2022 00:46:20 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:46:20 - INFO - __main__ - Printing 3 examples
06/25/2022 00:46:20 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 00:46:20 - INFO - __main__ - ['Plant']
06/25/2022 00:46:20 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 00:46:20 - INFO - __main__ - ['Plant']
06/25/2022 00:46:20 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 00:46:20 - INFO - __main__ - ['Plant']
06/25/2022 00:46:20 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:46:21 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:46:21 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 00:46:21 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:46:21 - INFO - __main__ - Printing 3 examples
06/25/2022 00:46:21 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 00:46:21 - INFO - __main__ - ['Plant']
06/25/2022 00:46:21 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 00:46:21 - INFO - __main__ - ['Plant']
06/25/2022 00:46:21 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 00:46:21 - INFO - __main__ - ['Plant']
06/25/2022 00:46:21 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:46:21 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:46:21 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 00:46:26 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=214
06/25/2022 00:46:26 - INFO - __main__ - save last model!
06/25/2022 00:46:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 00:46:26 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 00:46:26 - INFO - __main__ - Printing 3 examples
06/25/2022 00:46:26 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 00:46:26 - INFO - __main__ - ['Animal']
06/25/2022 00:46:26 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 00:46:26 - INFO - __main__ - ['Animal']
06/25/2022 00:46:26 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 00:46:26 - INFO - __main__ - ['Village']
06/25/2022 00:46:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:46:28 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:46:32 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 00:46:40 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:46:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 00:46:41 - INFO - __main__ - Starting training!
06/25/2022 00:48:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/25/2022 00:48:46 - INFO - __main__ - Classification-F1 on test data: 0.4522
06/25/2022 00:48:47 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9734099138189001, test_performance=0.45215774030300204
06/25/2022 00:48:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/25/2022 00:48:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:48:47 - INFO - __main__ - Printing 3 examples
06/25/2022 00:48:47 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 00:48:47 - INFO - __main__ - ['Plant']
06/25/2022 00:48:47 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 00:48:47 - INFO - __main__ - ['Plant']
06/25/2022 00:48:47 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 00:48:48 - INFO - __main__ - ['Plant']
06/25/2022 00:48:48 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:48:48 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:48:48 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 00:48:48 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 00:48:48 - INFO - __main__ - Printing 3 examples
06/25/2022 00:48:48 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 00:48:48 - INFO - __main__ - ['Plant']
06/25/2022 00:48:48 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 00:48:48 - INFO - __main__ - ['Plant']
06/25/2022 00:48:48 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 00:48:48 - INFO - __main__ - ['Plant']
06/25/2022 00:48:48 - INFO - __main__ - Tokenizing Input ...
06/25/2022 00:48:48 - INFO - __main__ - Tokenizing Output ...
06/25/2022 00:48:48 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 00:49:07 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 00:49:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 00:49:08 - INFO - __main__ - Starting training!
06/25/2022 00:49:11 - INFO - __main__ - Step 10 Global step 10 Train loss 6.38 on epoch=0
06/25/2022 00:49:14 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=1
06/25/2022 00:49:17 - INFO - __main__ - Step 30 Global step 30 Train loss 4.14 on epoch=2
06/25/2022 00:49:19 - INFO - __main__ - Step 40 Global step 40 Train loss 3.52 on epoch=2
06/25/2022 00:49:22 - INFO - __main__ - Step 50 Global step 50 Train loss 3.43 on epoch=3
06/25/2022 00:49:27 - INFO - __main__ - Global step 50 Train loss 4.40 Classification-F1 0.05710222277926614 on epoch=3
06/25/2022 00:49:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05710222277926614 on epoch=3, global_step=50
06/25/2022 00:49:30 - INFO - __main__ - Step 60 Global step 60 Train loss 2.85 on epoch=4
06/25/2022 00:49:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.72 on epoch=4
06/25/2022 00:49:35 - INFO - __main__ - Step 80 Global step 80 Train loss 2.34 on epoch=5
06/25/2022 00:49:38 - INFO - __main__ - Step 90 Global step 90 Train loss 2.30 on epoch=6
06/25/2022 00:49:41 - INFO - __main__ - Step 100 Global step 100 Train loss 2.25 on epoch=7
06/25/2022 00:49:46 - INFO - __main__ - Global step 100 Train loss 2.49 Classification-F1 0.08481479534111114 on epoch=7
06/25/2022 00:49:46 - INFO - __main__ - Saving model with best Classification-F1: 0.05710222277926614 -> 0.08481479534111114 on epoch=7, global_step=100
06/25/2022 00:49:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.94 on epoch=7
06/25/2022 00:49:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.94 on epoch=8
06/25/2022 00:49:54 - INFO - __main__ - Step 130 Global step 130 Train loss 1.75 on epoch=9
06/25/2022 00:49:57 - INFO - __main__ - Step 140 Global step 140 Train loss 1.58 on epoch=9
06/25/2022 00:50:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.42 on epoch=10
06/25/2022 00:50:05 - INFO - __main__ - Global step 150 Train loss 1.72 Classification-F1 0.10950000010580122 on epoch=10
06/25/2022 00:50:05 - INFO - __main__ - Saving model with best Classification-F1: 0.08481479534111114 -> 0.10950000010580122 on epoch=10, global_step=150
06/25/2022 00:50:08 - INFO - __main__ - Step 160 Global step 160 Train loss 1.44 on epoch=11
06/25/2022 00:50:11 - INFO - __main__ - Step 170 Global step 170 Train loss 1.19 on epoch=12
06/25/2022 00:50:13 - INFO - __main__ - Step 180 Global step 180 Train loss 1.21 on epoch=12
06/25/2022 00:50:16 - INFO - __main__ - Step 190 Global step 190 Train loss 1.13 on epoch=13
06/25/2022 00:50:18 - INFO - __main__ - Step 200 Global step 200 Train loss 1.07 on epoch=14
06/25/2022 00:50:25 - INFO - __main__ - Global step 200 Train loss 1.21 Classification-F1 0.18197574030907365 on epoch=14
06/25/2022 00:50:25 - INFO - __main__ - Saving model with best Classification-F1: 0.10950000010580122 -> 0.18197574030907365 on epoch=14, global_step=200
06/25/2022 00:50:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=14
06/25/2022 00:50:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=15
06/25/2022 00:50:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=16
06/25/2022 00:50:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=17
06/25/2022 00:50:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=17
06/25/2022 00:50:45 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.3097228517761136 on epoch=17
06/25/2022 00:50:45 - INFO - __main__ - Saving model with best Classification-F1: 0.18197574030907365 -> 0.3097228517761136 on epoch=17, global_step=250
06/25/2022 00:50:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=18
06/25/2022 00:50:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=19
06/25/2022 00:50:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=19
06/25/2022 00:50:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=20
06/25/2022 00:50:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=21
06/25/2022 00:51:05 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.3929424840126273 on epoch=21
06/25/2022 00:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3097228517761136 -> 0.3929424840126273 on epoch=21, global_step=300
06/25/2022 00:51:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=22
06/25/2022 00:51:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=22
06/25/2022 00:51:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/25/2022 00:51:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=24
06/25/2022 00:51:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/25/2022 00:51:26 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.46753896264020234 on epoch=24
06/25/2022 00:51:26 - INFO - __main__ - Saving model with best Classification-F1: 0.3929424840126273 -> 0.46753896264020234 on epoch=24, global_step=350
06/25/2022 00:51:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=25
06/25/2022 00:51:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=26
06/25/2022 00:51:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/25/2022 00:51:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
06/25/2022 00:51:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=28
06/25/2022 00:51:47 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.47865383501425174 on epoch=28
06/25/2022 00:51:47 - INFO - __main__ - Saving model with best Classification-F1: 0.46753896264020234 -> 0.47865383501425174 on epoch=28, global_step=400
06/25/2022 00:51:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
06/25/2022 00:51:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=29
06/25/2022 00:51:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
06/25/2022 00:51:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
06/25/2022 00:52:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
06/25/2022 00:52:07 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.5097955226086484 on epoch=32
06/25/2022 00:52:08 - INFO - __main__ - Saving model with best Classification-F1: 0.47865383501425174 -> 0.5097955226086484 on epoch=32, global_step=450
06/25/2022 00:52:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=32
06/25/2022 00:52:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
06/25/2022 00:52:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=34
06/25/2022 00:52:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/25/2022 00:52:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=35
06/25/2022 00:52:28 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.4872337228267622 on epoch=35
06/25/2022 00:52:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
06/25/2022 00:52:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/25/2022 00:52:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=37
06/25/2022 00:52:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/25/2022 00:52:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/25/2022 00:52:49 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.49582342217857134 on epoch=39
06/25/2022 00:52:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=39
06/25/2022 00:52:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/25/2022 00:52:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
06/25/2022 00:53:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/25/2022 00:53:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
06/25/2022 00:53:10 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.5005473890654715 on epoch=42
06/25/2022 00:53:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/25/2022 00:53:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
06/25/2022 00:53:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/25/2022 00:53:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/25/2022 00:53:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/25/2022 00:53:31 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6020635796784268 on epoch=46
06/25/2022 00:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5097955226086484 -> 0.6020635796784268 on epoch=46, global_step=650
06/25/2022 00:53:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
06/25/2022 00:53:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/25/2022 00:53:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
06/25/2022 00:53:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/25/2022 00:53:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
06/25/2022 00:53:52 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6440560099571104 on epoch=49
06/25/2022 00:53:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6020635796784268 -> 0.6440560099571104 on epoch=49, global_step=700
06/25/2022 00:53:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/25/2022 00:53:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/25/2022 00:54:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/25/2022 00:54:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/25/2022 00:54:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
06/25/2022 00:54:13 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6278460056959043 on epoch=53
06/25/2022 00:54:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/25/2022 00:54:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/25/2022 00:54:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/25/2022 00:54:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/25/2022 00:54:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
06/25/2022 00:54:34 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6472587517105506 on epoch=57
06/25/2022 00:54:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6440560099571104 -> 0.6472587517105506 on epoch=57, global_step=800
06/25/2022 00:54:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/25/2022 00:54:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/25/2022 00:54:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/25/2022 00:54:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/25/2022 00:54:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/25/2022 00:54:55 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6845936016890811 on epoch=60
06/25/2022 00:54:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6472587517105506 -> 0.6845936016890811 on epoch=60, global_step=850
06/25/2022 00:54:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/25/2022 00:55:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=62
06/25/2022 00:55:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
06/25/2022 00:55:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/25/2022 00:55:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
06/25/2022 00:55:16 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.6911295494014996 on epoch=64
06/25/2022 00:55:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6845936016890811 -> 0.6911295494014996 on epoch=64, global_step=900
06/25/2022 00:55:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/25/2022 00:55:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/25/2022 00:55:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/25/2022 00:55:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/25/2022 00:55:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/25/2022 00:55:36 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.6875344587096346 on epoch=67
06/25/2022 00:55:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/25/2022 00:55:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/25/2022 00:55:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/25/2022 00:55:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=70
06/25/2022 00:55:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
06/25/2022 00:55:57 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6420993499492486 on epoch=71
06/25/2022 00:56:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/25/2022 00:56:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/25/2022 00:56:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/25/2022 00:56:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=74
06/25/2022 00:56:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/25/2022 00:56:18 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6809756349093142 on epoch=74
06/25/2022 00:56:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/25/2022 00:56:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
06/25/2022 00:56:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/25/2022 00:56:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/25/2022 00:56:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/25/2022 00:56:39 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6649343662364666 on epoch=78
06/25/2022 00:56:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/25/2022 00:56:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/25/2022 00:56:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/25/2022 00:56:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/25/2022 00:56:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/25/2022 00:57:00 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6959361130276871 on epoch=82
06/25/2022 00:57:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6911295494014996 -> 0.6959361130276871 on epoch=82, global_step=1150
06/25/2022 00:57:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
06/25/2022 00:57:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/25/2022 00:57:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/25/2022 00:57:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/25/2022 00:57:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/25/2022 00:57:20 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6530415228079299 on epoch=85
06/25/2022 00:57:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/25/2022 00:57:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/25/2022 00:57:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/25/2022 00:57:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/25/2022 00:57:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/25/2022 00:57:40 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7257392380666607 on epoch=89
06/25/2022 00:57:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6959361130276871 -> 0.7257392380666607 on epoch=89, global_step=1250
06/25/2022 00:57:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/25/2022 00:57:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/25/2022 00:57:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/25/2022 00:57:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/25/2022 00:57:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/25/2022 00:58:01 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7186015681838929 on epoch=92
06/25/2022 00:58:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/25/2022 00:58:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
06/25/2022 00:58:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/25/2022 00:58:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/25/2022 00:58:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/25/2022 00:58:21 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7780524540807977 on epoch=96
06/25/2022 00:58:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7257392380666607 -> 0.7780524540807977 on epoch=96, global_step=1350
06/25/2022 00:58:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/25/2022 00:58:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/25/2022 00:58:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/25/2022 00:58:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/25/2022 00:58:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/25/2022 00:58:42 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7931569137145499 on epoch=99
06/25/2022 00:58:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7780524540807977 -> 0.7931569137145499 on epoch=99, global_step=1400
06/25/2022 00:58:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/25/2022 00:58:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
06/25/2022 00:58:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/25/2022 00:58:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
06/25/2022 00:58:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/25/2022 00:59:03 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.840266166634517 on epoch=103
06/25/2022 00:59:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7931569137145499 -> 0.840266166634517 on epoch=103, global_step=1450
06/25/2022 00:59:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/25/2022 00:59:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/25/2022 00:59:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/25/2022 00:59:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
06/25/2022 00:59:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/25/2022 00:59:23 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8402661666345171 on epoch=107
06/25/2022 00:59:23 - INFO - __main__ - Saving model with best Classification-F1: 0.840266166634517 -> 0.8402661666345171 on epoch=107, global_step=1500
06/25/2022 00:59:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/25/2022 00:59:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/25/2022 00:59:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/25/2022 00:59:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/25/2022 00:59:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/25/2022 00:59:43 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7692446528854534 on epoch=110
06/25/2022 00:59:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/25/2022 00:59:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/25/2022 00:59:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
06/25/2022 00:59:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/25/2022 00:59:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/25/2022 01:00:03 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7331006367324071 on epoch=114
06/25/2022 01:00:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/25/2022 01:00:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/25/2022 01:00:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/25/2022 01:00:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/25/2022 01:00:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/25/2022 01:00:23 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7131726590929627 on epoch=117
06/25/2022 01:00:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/25/2022 01:00:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/25/2022 01:00:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/25/2022 01:00:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/25/2022 01:00:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/25/2022 01:00:43 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7864732300158053 on epoch=121
06/25/2022 01:00:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/25/2022 01:00:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/25/2022 01:00:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/25/2022 01:00:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/25/2022 01:00:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/25/2022 01:01:03 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.765354041382385 on epoch=124
06/25/2022 01:01:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/25/2022 01:01:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/25/2022 01:01:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/25/2022 01:01:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/25/2022 01:01:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/25/2022 01:01:23 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7363212486486712 on epoch=128
06/25/2022 01:01:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/25/2022 01:01:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/25/2022 01:01:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/25/2022 01:01:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/25/2022 01:01:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/25/2022 01:01:43 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8347716611400117 on epoch=132
06/25/2022 01:01:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/25/2022 01:01:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/25/2022 01:01:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/25/2022 01:01:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/25/2022 01:01:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/25/2022 01:02:03 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8146741116306975 on epoch=135
06/25/2022 01:02:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/25/2022 01:02:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/25/2022 01:02:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/25/2022 01:02:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/25/2022 01:02:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/25/2022 01:02:23 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6881139367307348 on epoch=139
06/25/2022 01:02:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/25/2022 01:02:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/25/2022 01:02:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/25/2022 01:02:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/25/2022 01:02:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/25/2022 01:02:42 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8358381327947186 on epoch=142
06/25/2022 01:02:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/25/2022 01:02:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/25/2022 01:02:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/25/2022 01:02:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/25/2022 01:02:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/25/2022 01:03:02 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7813119396932244 on epoch=146
06/25/2022 01:03:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/25/2022 01:03:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/25/2022 01:03:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/25/2022 01:03:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/25/2022 01:03:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/25/2022 01:03:22 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7642797398163699 on epoch=149
06/25/2022 01:03:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/25/2022 01:03:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/25/2022 01:03:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/25/2022 01:03:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/25/2022 01:03:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/25/2022 01:03:41 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8383983505425631 on epoch=153
06/25/2022 01:03:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/25/2022 01:03:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
06/25/2022 01:03:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
06/25/2022 01:03:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/25/2022 01:03:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/25/2022 01:04:01 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8329038450480576 on epoch=157
06/25/2022 01:04:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/25/2022 01:04:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=158
06/25/2022 01:04:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/25/2022 01:04:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/25/2022 01:04:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/25/2022 01:04:20 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7834755637635423 on epoch=160
06/25/2022 01:04:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/25/2022 01:04:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/25/2022 01:04:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/25/2022 01:04:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/25/2022 01:04:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/25/2022 01:04:40 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7761986422997696 on epoch=164
06/25/2022 01:04:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/25/2022 01:04:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/25/2022 01:04:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/25/2022 01:04:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/25/2022 01:04:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/25/2022 01:05:00 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7827715181770245 on epoch=167
06/25/2022 01:05:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/25/2022 01:05:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/25/2022 01:05:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/25/2022 01:05:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/25/2022 01:05:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/25/2022 01:05:19 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8247110574435053 on epoch=171
06/25/2022 01:05:22 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/25/2022 01:05:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/25/2022 01:05:27 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/25/2022 01:05:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/25/2022 01:05:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/25/2022 01:05:39 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8357528478970604 on epoch=174
06/25/2022 01:05:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/25/2022 01:05:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
06/25/2022 01:05:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/25/2022 01:05:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/25/2022 01:05:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/25/2022 01:05:59 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7908387450677807 on epoch=178
06/25/2022 01:06:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/25/2022 01:06:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/25/2022 01:06:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/25/2022 01:06:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/25/2022 01:06:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/25/2022 01:06:19 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9055585495734683 on epoch=182
06/25/2022 01:06:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8402661666345171 -> 0.9055585495734683 on epoch=182, global_step=2550
06/25/2022 01:06:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/25/2022 01:06:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/25/2022 01:06:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/25/2022 01:06:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/25/2022 01:06:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/25/2022 01:06:38 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.781999778746128 on epoch=185
06/25/2022 01:06:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/25/2022 01:06:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/25/2022 01:06:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/25/2022 01:06:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/25/2022 01:06:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/25/2022 01:06:58 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8251274455896729 on epoch=189
06/25/2022 01:07:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/25/2022 01:07:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/25/2022 01:07:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/25/2022 01:07:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/25/2022 01:07:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/25/2022 01:07:18 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8410035805434288 on epoch=192
06/25/2022 01:07:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/25/2022 01:07:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/25/2022 01:07:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/25/2022 01:07:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/25/2022 01:07:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/25/2022 01:07:37 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8959141488679757 on epoch=196
06/25/2022 01:07:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/25/2022 01:07:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/25/2022 01:07:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/25/2022 01:07:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/25/2022 01:07:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/25/2022 01:07:57 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8489611402251265 on epoch=199
06/25/2022 01:08:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/25/2022 01:08:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/25/2022 01:08:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/25/2022 01:08:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/25/2022 01:08:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/25/2022 01:08:18 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9080106568531616 on epoch=203
06/25/2022 01:08:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9055585495734683 -> 0.9080106568531616 on epoch=203, global_step=2850
06/25/2022 01:08:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/25/2022 01:08:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/25/2022 01:08:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/25/2022 01:08:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/25/2022 01:08:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/25/2022 01:08:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8471055430970043 on epoch=207
06/25/2022 01:08:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/25/2022 01:08:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/25/2022 01:08:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/25/2022 01:08:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/25/2022 01:08:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/25/2022 01:08:57 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7848313848760329 on epoch=210
06/25/2022 01:09:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/25/2022 01:09:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/25/2022 01:09:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/25/2022 01:09:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/25/2022 01:09:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/25/2022 01:09:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:09:12 - INFO - __main__ - Printing 3 examples
06/25/2022 01:09:12 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 01:09:12 - INFO - __main__ - ['Plant']
06/25/2022 01:09:12 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 01:09:12 - INFO - __main__ - ['Plant']
06/25/2022 01:09:12 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 01:09:12 - INFO - __main__ - ['Plant']
06/25/2022 01:09:12 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:09:12 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:09:12 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 01:09:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:09:12 - INFO - __main__ - Printing 3 examples
06/25/2022 01:09:12 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 01:09:12 - INFO - __main__ - ['Plant']
06/25/2022 01:09:12 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 01:09:12 - INFO - __main__ - ['Plant']
06/25/2022 01:09:12 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 01:09:12 - INFO - __main__ - ['Plant']
06/25/2022 01:09:12 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:09:12 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:09:13 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 01:09:17 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8474651489994824 on epoch=214
06/25/2022 01:09:17 - INFO - __main__ - save last model!
06/25/2022 01:09:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:09:17 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 01:09:17 - INFO - __main__ - Printing 3 examples
06/25/2022 01:09:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 01:09:17 - INFO - __main__ - ['Animal']
06/25/2022 01:09:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 01:09:17 - INFO - __main__ - ['Animal']
06/25/2022 01:09:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 01:09:17 - INFO - __main__ - ['Village']
06/25/2022 01:09:17 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:09:19 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:09:23 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 01:09:31 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:09:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 01:09:32 - INFO - __main__ - Starting training!
06/25/2022 01:11:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/25/2022 01:11:33 - INFO - __main__ - Classification-F1 on test data: 0.4067
06/25/2022 01:11:33 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9080106568531616, test_performance=0.40668148491790707
06/25/2022 01:11:33 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/25/2022 01:11:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:11:34 - INFO - __main__ - Printing 3 examples
06/25/2022 01:11:34 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 01:11:34 - INFO - __main__ - ['Plant']
06/25/2022 01:11:34 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 01:11:34 - INFO - __main__ - ['Plant']
06/25/2022 01:11:34 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 01:11:34 - INFO - __main__ - ['Plant']
06/25/2022 01:11:34 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:11:34 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:11:35 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 01:11:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:11:35 - INFO - __main__ - Printing 3 examples
06/25/2022 01:11:35 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 01:11:35 - INFO - __main__ - ['Plant']
06/25/2022 01:11:35 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 01:11:35 - INFO - __main__ - ['Plant']
06/25/2022 01:11:35 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 01:11:35 - INFO - __main__ - ['Plant']
06/25/2022 01:11:35 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:11:35 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:11:35 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 01:11:51 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:11:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 01:11:52 - INFO - __main__ - Starting training!
06/25/2022 01:11:55 - INFO - __main__ - Step 10 Global step 10 Train loss 6.36 on epoch=0
06/25/2022 01:11:58 - INFO - __main__ - Step 20 Global step 20 Train loss 5.07 on epoch=1
06/25/2022 01:12:00 - INFO - __main__ - Step 30 Global step 30 Train loss 4.44 on epoch=2
06/25/2022 01:12:03 - INFO - __main__ - Step 40 Global step 40 Train loss 4.06 on epoch=2
06/25/2022 01:12:05 - INFO - __main__ - Step 50 Global step 50 Train loss 4.04 on epoch=3
06/25/2022 01:12:11 - INFO - __main__ - Global step 50 Train loss 4.79 Classification-F1 0.04488577990329788 on epoch=3
06/25/2022 01:12:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04488577990329788 on epoch=3, global_step=50
06/25/2022 01:12:14 - INFO - __main__ - Step 60 Global step 60 Train loss 3.33 on epoch=4
06/25/2022 01:12:16 - INFO - __main__ - Step 70 Global step 70 Train loss 3.26 on epoch=4
06/25/2022 01:12:19 - INFO - __main__ - Step 80 Global step 80 Train loss 2.77 on epoch=5
06/25/2022 01:12:21 - INFO - __main__ - Step 90 Global step 90 Train loss 2.80 on epoch=6
06/25/2022 01:12:24 - INFO - __main__ - Step 100 Global step 100 Train loss 2.64 on epoch=7
06/25/2022 01:12:29 - INFO - __main__ - Global step 100 Train loss 2.96 Classification-F1 0.06361636779094085 on epoch=7
06/25/2022 01:12:29 - INFO - __main__ - Saving model with best Classification-F1: 0.04488577990329788 -> 0.06361636779094085 on epoch=7, global_step=100
06/25/2022 01:12:32 - INFO - __main__ - Step 110 Global step 110 Train loss 2.31 on epoch=7
06/25/2022 01:12:34 - INFO - __main__ - Step 120 Global step 120 Train loss 2.46 on epoch=8
06/25/2022 01:12:37 - INFO - __main__ - Step 130 Global step 130 Train loss 2.12 on epoch=9
06/25/2022 01:12:40 - INFO - __main__ - Step 140 Global step 140 Train loss 2.28 on epoch=9
06/25/2022 01:12:42 - INFO - __main__ - Step 150 Global step 150 Train loss 1.86 on epoch=10
06/25/2022 01:12:48 - INFO - __main__ - Global step 150 Train loss 2.21 Classification-F1 0.08841327505070196 on epoch=10
06/25/2022 01:12:48 - INFO - __main__ - Saving model with best Classification-F1: 0.06361636779094085 -> 0.08841327505070196 on epoch=10, global_step=150
06/25/2022 01:12:50 - INFO - __main__ - Step 160 Global step 160 Train loss 1.90 on epoch=11
06/25/2022 01:12:53 - INFO - __main__ - Step 170 Global step 170 Train loss 1.87 on epoch=12
06/25/2022 01:12:55 - INFO - __main__ - Step 180 Global step 180 Train loss 1.52 on epoch=12
06/25/2022 01:12:58 - INFO - __main__ - Step 190 Global step 190 Train loss 1.70 on epoch=13
06/25/2022 01:13:00 - INFO - __main__ - Step 200 Global step 200 Train loss 1.45 on epoch=14
06/25/2022 01:13:06 - INFO - __main__ - Global step 200 Train loss 1.69 Classification-F1 0.10653691877273636 on epoch=14
06/25/2022 01:13:06 - INFO - __main__ - Saving model with best Classification-F1: 0.08841327505070196 -> 0.10653691877273636 on epoch=14, global_step=200
06/25/2022 01:13:09 - INFO - __main__ - Step 210 Global step 210 Train loss 1.49 on epoch=14
06/25/2022 01:13:12 - INFO - __main__ - Step 220 Global step 220 Train loss 1.24 on epoch=15
06/25/2022 01:13:14 - INFO - __main__ - Step 230 Global step 230 Train loss 1.27 on epoch=16
06/25/2022 01:13:17 - INFO - __main__ - Step 240 Global step 240 Train loss 1.10 on epoch=17
06/25/2022 01:13:19 - INFO - __main__ - Step 250 Global step 250 Train loss 1.13 on epoch=17
06/25/2022 01:13:25 - INFO - __main__ - Global step 250 Train loss 1.25 Classification-F1 0.1600807254528528 on epoch=17
06/25/2022 01:13:25 - INFO - __main__ - Saving model with best Classification-F1: 0.10653691877273636 -> 0.1600807254528528 on epoch=17, global_step=250
06/25/2022 01:13:28 - INFO - __main__ - Step 260 Global step 260 Train loss 1.09 on epoch=18
06/25/2022 01:13:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.92 on epoch=19
06/25/2022 01:13:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.95 on epoch=19
06/25/2022 01:13:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.88 on epoch=20
06/25/2022 01:13:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.92 on epoch=21
06/25/2022 01:13:45 - INFO - __main__ - Global step 300 Train loss 0.95 Classification-F1 0.2812342520907593 on epoch=21
06/25/2022 01:13:45 - INFO - __main__ - Saving model with best Classification-F1: 0.1600807254528528 -> 0.2812342520907593 on epoch=21, global_step=300
06/25/2022 01:13:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=22
06/25/2022 01:13:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=22
06/25/2022 01:13:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=23
06/25/2022 01:13:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=24
06/25/2022 01:13:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=24
06/25/2022 01:14:05 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.3649583696798571 on epoch=24
06/25/2022 01:14:05 - INFO - __main__ - Saving model with best Classification-F1: 0.2812342520907593 -> 0.3649583696798571 on epoch=24, global_step=350
06/25/2022 01:14:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=25
06/25/2022 01:14:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.59 on epoch=26
06/25/2022 01:14:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.62 on epoch=27
06/25/2022 01:14:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
06/25/2022 01:14:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=28
06/25/2022 01:14:25 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.4003878277320991 on epoch=28
06/25/2022 01:14:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3649583696798571 -> 0.4003878277320991 on epoch=28, global_step=400
06/25/2022 01:14:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.62 on epoch=29
06/25/2022 01:14:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=29
06/25/2022 01:14:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=30
06/25/2022 01:14:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=31
06/25/2022 01:14:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.48 on epoch=32
06/25/2022 01:14:45 - INFO - __main__ - Global step 450 Train loss 0.50 Classification-F1 0.5057122447340517 on epoch=32
06/25/2022 01:14:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4003878277320991 -> 0.5057122447340517 on epoch=32, global_step=450
06/25/2022 01:14:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=32
06/25/2022 01:14:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
06/25/2022 01:14:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=34
06/25/2022 01:14:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=34
06/25/2022 01:14:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=35
06/25/2022 01:15:06 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.5314386783583163 on epoch=35
06/25/2022 01:15:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5057122447340517 -> 0.5314386783583163 on epoch=35, global_step=500
06/25/2022 01:15:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=36
06/25/2022 01:15:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
06/25/2022 01:15:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/25/2022 01:15:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=38
06/25/2022 01:15:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=39
06/25/2022 01:15:26 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.6134491757483542 on epoch=39
06/25/2022 01:15:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5314386783583163 -> 0.6134491757483542 on epoch=39, global_step=550
06/25/2022 01:15:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=39
06/25/2022 01:15:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=40
06/25/2022 01:15:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=41
06/25/2022 01:15:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=42
06/25/2022 01:15:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=42
06/25/2022 01:15:47 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.6200516178530142 on epoch=42
06/25/2022 01:15:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6134491757483542 -> 0.6200516178530142 on epoch=42, global_step=600
06/25/2022 01:15:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/25/2022 01:15:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=44
06/25/2022 01:15:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
06/25/2022 01:15:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=45
06/25/2022 01:16:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
06/25/2022 01:16:08 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.6247231866852989 on epoch=46
06/25/2022 01:16:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6200516178530142 -> 0.6247231866852989 on epoch=46, global_step=650
06/25/2022 01:16:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=47
06/25/2022 01:16:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=47
06/25/2022 01:16:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=48
06/25/2022 01:16:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=49
06/25/2022 01:16:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=49
06/25/2022 01:16:29 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.6291511889780799 on epoch=49
06/25/2022 01:16:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6247231866852989 -> 0.6291511889780799 on epoch=49, global_step=700
06/25/2022 01:16:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=50
06/25/2022 01:16:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/25/2022 01:16:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/25/2022 01:16:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/25/2022 01:16:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/25/2022 01:16:50 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.6622644094506104 on epoch=53
06/25/2022 01:16:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6291511889780799 -> 0.6622644094506104 on epoch=53, global_step=750
06/25/2022 01:16:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=54
06/25/2022 01:16:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
06/25/2022 01:16:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/25/2022 01:17:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
06/25/2022 01:17:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=57
06/25/2022 01:17:10 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.6365854025491927 on epoch=57
06/25/2022 01:17:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=57
06/25/2022 01:17:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/25/2022 01:17:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
06/25/2022 01:17:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
06/25/2022 01:17:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/25/2022 01:17:31 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.5783357096769753 on epoch=60
06/25/2022 01:17:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/25/2022 01:17:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/25/2022 01:17:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/25/2022 01:17:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=63
06/25/2022 01:17:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/25/2022 01:17:51 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6418114771069291 on epoch=64
06/25/2022 01:17:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/25/2022 01:17:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/25/2022 01:17:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/25/2022 01:18:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=67
06/25/2022 01:18:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
06/25/2022 01:18:12 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.5733626382092932 on epoch=67
06/25/2022 01:18:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/25/2022 01:18:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=69
06/25/2022 01:18:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/25/2022 01:18:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/25/2022 01:18:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
06/25/2022 01:18:32 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.5825214934458632 on epoch=71
06/25/2022 01:18:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/25/2022 01:18:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/25/2022 01:18:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=73
06/25/2022 01:18:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
06/25/2022 01:18:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=74
06/25/2022 01:18:53 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.6466575630030856 on epoch=74
06/25/2022 01:18:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
06/25/2022 01:18:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/25/2022 01:19:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/25/2022 01:19:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/25/2022 01:19:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/25/2022 01:19:14 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6117763845350053 on epoch=78
06/25/2022 01:19:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/25/2022 01:19:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=79
06/25/2022 01:19:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=80
06/25/2022 01:19:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/25/2022 01:19:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/25/2022 01:19:35 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.6143246848529313 on epoch=82
06/25/2022 01:19:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/25/2022 01:19:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
06/25/2022 01:19:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/25/2022 01:19:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/25/2022 01:19:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=85
06/25/2022 01:19:56 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.645911015783974 on epoch=85
06/25/2022 01:19:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=86
06/25/2022 01:20:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/25/2022 01:20:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/25/2022 01:20:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=88
06/25/2022 01:20:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=89
06/25/2022 01:20:16 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.766014173998045 on epoch=89
06/25/2022 01:20:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6622644094506104 -> 0.766014173998045 on epoch=89, global_step=1250
06/25/2022 01:20:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/25/2022 01:20:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/25/2022 01:20:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
06/25/2022 01:20:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/25/2022 01:20:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=92
06/25/2022 01:20:37 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6198831088494893 on epoch=92
06/25/2022 01:20:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/25/2022 01:20:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/25/2022 01:20:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/25/2022 01:20:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=95
06/25/2022 01:20:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/25/2022 01:20:58 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.8311356448737854 on epoch=96
06/25/2022 01:20:58 - INFO - __main__ - Saving model with best Classification-F1: 0.766014173998045 -> 0.8311356448737854 on epoch=96, global_step=1350
06/25/2022 01:21:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/25/2022 01:21:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/25/2022 01:21:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
06/25/2022 01:21:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
06/25/2022 01:21:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/25/2022 01:21:18 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7214465859270848 on epoch=99
06/25/2022 01:21:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/25/2022 01:21:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/25/2022 01:21:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
06/25/2022 01:21:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/25/2022 01:21:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/25/2022 01:21:39 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.6470590183301589 on epoch=103
06/25/2022 01:21:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=104
06/25/2022 01:21:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=104
06/25/2022 01:21:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/25/2022 01:21:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
06/25/2022 01:21:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/25/2022 01:21:59 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7117517075705914 on epoch=107
06/25/2022 01:22:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/25/2022 01:22:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.16 on epoch=108
06/25/2022 01:22:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
06/25/2022 01:22:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/25/2022 01:22:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
06/25/2022 01:22:20 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7544185588423414 on epoch=110
06/25/2022 01:22:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/25/2022 01:22:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/25/2022 01:22:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/25/2022 01:22:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/25/2022 01:22:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/25/2022 01:22:40 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7020773516596763 on epoch=114
06/25/2022 01:22:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
06/25/2022 01:22:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/25/2022 01:22:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=116
06/25/2022 01:22:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/25/2022 01:22:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=117
06/25/2022 01:23:00 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7251053177794686 on epoch=117
06/25/2022 01:23:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/25/2022 01:23:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/25/2022 01:23:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/25/2022 01:23:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/25/2022 01:23:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/25/2022 01:23:20 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8125635429353097 on epoch=121
06/25/2022 01:23:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=122
06/25/2022 01:23:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/25/2022 01:23:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/25/2022 01:23:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/25/2022 01:23:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
06/25/2022 01:23:41 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6625999972240895 on epoch=124
06/25/2022 01:23:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/25/2022 01:23:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/25/2022 01:23:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/25/2022 01:23:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/25/2022 01:23:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=128
06/25/2022 01:24:01 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6952327302584165 on epoch=128
06/25/2022 01:24:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/25/2022 01:24:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
06/25/2022 01:24:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/25/2022 01:24:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/25/2022 01:24:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/25/2022 01:24:22 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.717266900182558 on epoch=132
06/25/2022 01:24:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/25/2022 01:24:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/25/2022 01:24:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/25/2022 01:24:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/25/2022 01:24:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/25/2022 01:24:42 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7622889072827682 on epoch=135
06/25/2022 01:24:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/25/2022 01:24:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/25/2022 01:24:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/25/2022 01:24:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/25/2022 01:24:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/25/2022 01:25:02 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7314784501784337 on epoch=139
06/25/2022 01:25:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/25/2022 01:25:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/25/2022 01:25:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/25/2022 01:25:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/25/2022 01:25:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/25/2022 01:25:22 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7743879984811499 on epoch=142
06/25/2022 01:25:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/25/2022 01:25:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/25/2022 01:25:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/25/2022 01:25:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/25/2022 01:25:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/25/2022 01:25:43 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7034766938704751 on epoch=146
06/25/2022 01:25:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/25/2022 01:25:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
06/25/2022 01:25:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/25/2022 01:25:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/25/2022 01:25:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/25/2022 01:26:03 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6956794229153094 on epoch=149
06/25/2022 01:26:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
06/25/2022 01:26:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/25/2022 01:26:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/25/2022 01:26:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/25/2022 01:26:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/25/2022 01:26:23 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8360327180725663 on epoch=153
06/25/2022 01:26:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8311356448737854 -> 0.8360327180725663 on epoch=153, global_step=2150
06/25/2022 01:26:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/25/2022 01:26:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/25/2022 01:26:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/25/2022 01:26:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.18 on epoch=156
06/25/2022 01:26:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/25/2022 01:26:44 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7952632700484024 on epoch=157
06/25/2022 01:26:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/25/2022 01:26:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/25/2022 01:26:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/25/2022 01:26:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/25/2022 01:26:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/25/2022 01:27:04 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.744937584026768 on epoch=160
06/25/2022 01:27:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=161
06/25/2022 01:27:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/25/2022 01:27:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
06/25/2022 01:27:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=163
06/25/2022 01:27:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
06/25/2022 01:27:24 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.8471177620608361 on epoch=164
06/25/2022 01:27:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8360327180725663 -> 0.8471177620608361 on epoch=164, global_step=2300
06/25/2022 01:27:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/25/2022 01:27:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/25/2022 01:27:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/25/2022 01:27:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
06/25/2022 01:27:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/25/2022 01:27:44 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7871014129301885 on epoch=167
06/25/2022 01:27:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/25/2022 01:27:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/25/2022 01:27:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/25/2022 01:27:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/25/2022 01:27:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/25/2022 01:28:04 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8529325513196482 on epoch=171
06/25/2022 01:28:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8471177620608361 -> 0.8529325513196482 on epoch=171, global_step=2400
06/25/2022 01:28:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/25/2022 01:28:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/25/2022 01:28:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/25/2022 01:28:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=174
06/25/2022 01:28:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/25/2022 01:28:24 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8530547409579667 on epoch=174
06/25/2022 01:28:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8529325513196482 -> 0.8530547409579667 on epoch=174, global_step=2450
06/25/2022 01:28:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.14 on epoch=175
06/25/2022 01:28:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/25/2022 01:28:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/25/2022 01:28:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
06/25/2022 01:28:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/25/2022 01:28:44 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8394645378516347 on epoch=178
06/25/2022 01:28:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/25/2022 01:28:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/25/2022 01:28:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/25/2022 01:28:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/25/2022 01:28:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/25/2022 01:29:04 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8254578517624058 on epoch=182
06/25/2022 01:29:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/25/2022 01:29:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
06/25/2022 01:29:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
06/25/2022 01:29:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/25/2022 01:29:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=185
06/25/2022 01:29:25 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7258283000218485 on epoch=185
06/25/2022 01:29:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/25/2022 01:29:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/25/2022 01:29:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/25/2022 01:29:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/25/2022 01:29:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
06/25/2022 01:29:44 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7043131433812437 on epoch=189
06/25/2022 01:29:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/25/2022 01:29:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/25/2022 01:29:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/25/2022 01:29:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/25/2022 01:29:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/25/2022 01:30:04 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6873818118936965 on epoch=192
06/25/2022 01:30:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/25/2022 01:30:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/25/2022 01:30:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/25/2022 01:30:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/25/2022 01:30:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/25/2022 01:30:24 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8406316253179905 on epoch=196
06/25/2022 01:30:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/25/2022 01:30:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/25/2022 01:30:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/25/2022 01:30:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/25/2022 01:30:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/25/2022 01:30:44 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7865126551070853 on epoch=199
06/25/2022 01:30:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/25/2022 01:30:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/25/2022 01:30:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/25/2022 01:30:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/25/2022 01:30:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/25/2022 01:31:03 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8376628121164534 on epoch=203
06/25/2022 01:31:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/25/2022 01:31:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/25/2022 01:31:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/25/2022 01:31:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/25/2022 01:31:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/25/2022 01:31:24 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8516114849532188 on epoch=207
06/25/2022 01:31:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/25/2022 01:31:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/25/2022 01:31:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/25/2022 01:31:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/25/2022 01:31:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/25/2022 01:31:43 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8448066925222917 on epoch=210
06/25/2022 01:31:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/25/2022 01:31:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/25/2022 01:31:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/25/2022 01:31:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/25/2022 01:31:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/25/2022 01:31:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:31:58 - INFO - __main__ - Printing 3 examples
06/25/2022 01:31:58 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 01:31:58 - INFO - __main__ - ['Plant']
06/25/2022 01:31:58 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 01:31:58 - INFO - __main__ - ['Plant']
06/25/2022 01:31:58 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 01:31:58 - INFO - __main__ - ['Plant']
06/25/2022 01:31:58 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:31:58 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:31:58 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 01:31:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:31:58 - INFO - __main__ - Printing 3 examples
06/25/2022 01:31:58 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 01:31:58 - INFO - __main__ - ['Plant']
06/25/2022 01:31:58 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 01:31:58 - INFO - __main__ - ['Plant']
06/25/2022 01:31:58 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 01:31:58 - INFO - __main__ - ['Plant']
06/25/2022 01:31:58 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:31:58 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:31:58 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 01:32:04 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8397610730509213 on epoch=214
06/25/2022 01:32:04 - INFO - __main__ - save last model!
06/25/2022 01:32:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:32:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 01:32:04 - INFO - __main__ - Printing 3 examples
06/25/2022 01:32:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 01:32:04 - INFO - __main__ - ['Animal']
06/25/2022 01:32:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 01:32:04 - INFO - __main__ - ['Animal']
06/25/2022 01:32:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 01:32:04 - INFO - __main__ - ['Village']
06/25/2022 01:32:04 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:32:06 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:32:09 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 01:32:17 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:32:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 01:32:18 - INFO - __main__ - Starting training!
06/25/2022 01:34:22 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/25/2022 01:34:22 - INFO - __main__ - Classification-F1 on test data: 0.4428
06/25/2022 01:34:22 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.8530547409579667, test_performance=0.4427773489284019
06/25/2022 01:34:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/25/2022 01:34:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:34:23 - INFO - __main__ - Printing 3 examples
06/25/2022 01:34:23 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/25/2022 01:34:23 - INFO - __main__ - ['Plant']
06/25/2022 01:34:23 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/25/2022 01:34:23 - INFO - __main__ - ['Plant']
06/25/2022 01:34:23 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/25/2022 01:34:23 - INFO - __main__ - ['Plant']
06/25/2022 01:34:23 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:34:23 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:34:24 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 01:34:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:34:24 - INFO - __main__ - Printing 3 examples
06/25/2022 01:34:24 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/25/2022 01:34:24 - INFO - __main__ - ['Plant']
06/25/2022 01:34:24 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/25/2022 01:34:24 - INFO - __main__ - ['Plant']
06/25/2022 01:34:24 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/25/2022 01:34:24 - INFO - __main__ - ['Plant']
06/25/2022 01:34:24 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:34:24 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:34:24 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 01:34:39 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:34:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 01:34:40 - INFO - __main__ - Starting training!
06/25/2022 01:34:44 - INFO - __main__ - Step 10 Global step 10 Train loss 6.98 on epoch=0
06/25/2022 01:34:46 - INFO - __main__ - Step 20 Global step 20 Train loss 5.52 on epoch=1
06/25/2022 01:34:49 - INFO - __main__ - Step 30 Global step 30 Train loss 5.04 on epoch=2
06/25/2022 01:34:51 - INFO - __main__ - Step 40 Global step 40 Train loss 4.46 on epoch=2
06/25/2022 01:34:54 - INFO - __main__ - Step 50 Global step 50 Train loss 4.37 on epoch=3
06/25/2022 01:35:00 - INFO - __main__ - Global step 50 Train loss 5.27 Classification-F1 0.04358357025216195 on epoch=3
06/25/2022 01:35:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04358357025216195 on epoch=3, global_step=50
06/25/2022 01:35:02 - INFO - __main__ - Step 60 Global step 60 Train loss 3.86 on epoch=4
06/25/2022 01:35:05 - INFO - __main__ - Step 70 Global step 70 Train loss 3.99 on epoch=4
06/25/2022 01:35:08 - INFO - __main__ - Step 80 Global step 80 Train loss 3.27 on epoch=5
06/25/2022 01:35:10 - INFO - __main__ - Step 90 Global step 90 Train loss 3.31 on epoch=6
06/25/2022 01:35:13 - INFO - __main__ - Step 100 Global step 100 Train loss 3.11 on epoch=7
06/25/2022 01:35:18 - INFO - __main__ - Global step 100 Train loss 3.51 Classification-F1 0.060809410475666265 on epoch=7
06/25/2022 01:35:18 - INFO - __main__ - Saving model with best Classification-F1: 0.04358357025216195 -> 0.060809410475666265 on epoch=7, global_step=100
06/25/2022 01:35:21 - INFO - __main__ - Step 110 Global step 110 Train loss 2.85 on epoch=7
06/25/2022 01:35:23 - INFO - __main__ - Step 120 Global step 120 Train loss 2.93 on epoch=8
06/25/2022 01:35:26 - INFO - __main__ - Step 130 Global step 130 Train loss 2.62 on epoch=9
06/25/2022 01:35:28 - INFO - __main__ - Step 140 Global step 140 Train loss 2.69 on epoch=9
06/25/2022 01:35:31 - INFO - __main__ - Step 150 Global step 150 Train loss 2.43 on epoch=10
06/25/2022 01:35:36 - INFO - __main__ - Global step 150 Train loss 2.70 Classification-F1 0.07653439490746644 on epoch=10
06/25/2022 01:35:36 - INFO - __main__ - Saving model with best Classification-F1: 0.060809410475666265 -> 0.07653439490746644 on epoch=10, global_step=150
06/25/2022 01:35:39 - INFO - __main__ - Step 160 Global step 160 Train loss 2.41 on epoch=11
06/25/2022 01:35:41 - INFO - __main__ - Step 170 Global step 170 Train loss 2.32 on epoch=12
06/25/2022 01:35:44 - INFO - __main__ - Step 180 Global step 180 Train loss 2.16 on epoch=12
06/25/2022 01:35:46 - INFO - __main__ - Step 190 Global step 190 Train loss 2.24 on epoch=13
06/25/2022 01:35:49 - INFO - __main__ - Step 200 Global step 200 Train loss 2.06 on epoch=14
06/25/2022 01:35:54 - INFO - __main__ - Global step 200 Train loss 2.24 Classification-F1 0.08936747150650894 on epoch=14
06/25/2022 01:35:54 - INFO - __main__ - Saving model with best Classification-F1: 0.07653439490746644 -> 0.08936747150650894 on epoch=14, global_step=200
06/25/2022 01:35:57 - INFO - __main__ - Step 210 Global step 210 Train loss 2.11 on epoch=14
06/25/2022 01:35:59 - INFO - __main__ - Step 220 Global step 220 Train loss 1.84 on epoch=15
06/25/2022 01:36:02 - INFO - __main__ - Step 230 Global step 230 Train loss 1.87 on epoch=16
06/25/2022 01:36:04 - INFO - __main__ - Step 240 Global step 240 Train loss 1.89 on epoch=17
06/25/2022 01:36:07 - INFO - __main__ - Step 250 Global step 250 Train loss 1.71 on epoch=17
06/25/2022 01:36:12 - INFO - __main__ - Global step 250 Train loss 1.88 Classification-F1 0.09861217214158391 on epoch=17
06/25/2022 01:36:12 - INFO - __main__ - Saving model with best Classification-F1: 0.08936747150650894 -> 0.09861217214158391 on epoch=17, global_step=250
06/25/2022 01:36:15 - INFO - __main__ - Step 260 Global step 260 Train loss 1.74 on epoch=18
06/25/2022 01:36:18 - INFO - __main__ - Step 270 Global step 270 Train loss 1.62 on epoch=19
06/25/2022 01:36:20 - INFO - __main__ - Step 280 Global step 280 Train loss 1.43 on epoch=19
06/25/2022 01:36:23 - INFO - __main__ - Step 290 Global step 290 Train loss 1.60 on epoch=20
06/25/2022 01:36:25 - INFO - __main__ - Step 300 Global step 300 Train loss 1.45 on epoch=21
06/25/2022 01:36:31 - INFO - __main__ - Global step 300 Train loss 1.57 Classification-F1 0.10732787876034434 on epoch=21
06/25/2022 01:36:31 - INFO - __main__ - Saving model with best Classification-F1: 0.09861217214158391 -> 0.10732787876034434 on epoch=21, global_step=300
06/25/2022 01:36:33 - INFO - __main__ - Step 310 Global step 310 Train loss 1.49 on epoch=22
06/25/2022 01:36:36 - INFO - __main__ - Step 320 Global step 320 Train loss 1.40 on epoch=22
06/25/2022 01:36:38 - INFO - __main__ - Step 330 Global step 330 Train loss 1.34 on epoch=23
06/25/2022 01:36:41 - INFO - __main__ - Step 340 Global step 340 Train loss 1.16 on epoch=24
06/25/2022 01:36:43 - INFO - __main__ - Step 350 Global step 350 Train loss 1.15 on epoch=24
06/25/2022 01:36:49 - INFO - __main__ - Global step 350 Train loss 1.31 Classification-F1 0.13842098426349067 on epoch=24
06/25/2022 01:36:49 - INFO - __main__ - Saving model with best Classification-F1: 0.10732787876034434 -> 0.13842098426349067 on epoch=24, global_step=350
06/25/2022 01:36:52 - INFO - __main__ - Step 360 Global step 360 Train loss 1.13 on epoch=25
06/25/2022 01:36:54 - INFO - __main__ - Step 370 Global step 370 Train loss 1.24 on epoch=26
06/25/2022 01:36:57 - INFO - __main__ - Step 380 Global step 380 Train loss 1.13 on epoch=27
06/25/2022 01:37:00 - INFO - __main__ - Step 390 Global step 390 Train loss 1.02 on epoch=27
06/25/2022 01:37:02 - INFO - __main__ - Step 400 Global step 400 Train loss 1.07 on epoch=28
06/25/2022 01:37:08 - INFO - __main__ - Global step 400 Train loss 1.12 Classification-F1 0.20285769207609605 on epoch=28
06/25/2022 01:37:08 - INFO - __main__ - Saving model with best Classification-F1: 0.13842098426349067 -> 0.20285769207609605 on epoch=28, global_step=400
06/25/2022 01:37:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.88 on epoch=29
06/25/2022 01:37:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.97 on epoch=29
06/25/2022 01:37:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.91 on epoch=30
06/25/2022 01:37:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.91 on epoch=31
06/25/2022 01:37:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.86 on epoch=32
06/25/2022 01:37:27 - INFO - __main__ - Global step 450 Train loss 0.91 Classification-F1 0.3018572113440255 on epoch=32
06/25/2022 01:37:27 - INFO - __main__ - Saving model with best Classification-F1: 0.20285769207609605 -> 0.3018572113440255 on epoch=32, global_step=450
06/25/2022 01:37:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.77 on epoch=32
06/25/2022 01:37:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.77 on epoch=33
06/25/2022 01:37:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.84 on epoch=34
06/25/2022 01:37:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.72 on epoch=34
06/25/2022 01:37:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.69 on epoch=35
06/25/2022 01:37:47 - INFO - __main__ - Global step 500 Train loss 0.76 Classification-F1 0.38206339903566217 on epoch=35
06/25/2022 01:37:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3018572113440255 -> 0.38206339903566217 on epoch=35, global_step=500
06/25/2022 01:37:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.63 on epoch=36
06/25/2022 01:37:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.65 on epoch=37
06/25/2022 01:37:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.56 on epoch=37
06/25/2022 01:37:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.64 on epoch=38
06/25/2022 01:38:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.60 on epoch=39
06/25/2022 01:38:07 - INFO - __main__ - Global step 550 Train loss 0.62 Classification-F1 0.3985940842480315 on epoch=39
06/25/2022 01:38:07 - INFO - __main__ - Saving model with best Classification-F1: 0.38206339903566217 -> 0.3985940842480315 on epoch=39, global_step=550
06/25/2022 01:38:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.62 on epoch=39
06/25/2022 01:38:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.60 on epoch=40
06/25/2022 01:38:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.48 on epoch=41
06/25/2022 01:38:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.58 on epoch=42
06/25/2022 01:38:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=42
06/25/2022 01:38:27 - INFO - __main__ - Global step 600 Train loss 0.55 Classification-F1 0.43762824042191467 on epoch=42
06/25/2022 01:38:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3985940842480315 -> 0.43762824042191467 on epoch=42, global_step=600
06/25/2022 01:38:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.52 on epoch=43
06/25/2022 01:38:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.49 on epoch=44
06/25/2022 01:38:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.48 on epoch=44
06/25/2022 01:38:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=45
06/25/2022 01:38:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=46
06/25/2022 01:38:47 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.4759356040854714 on epoch=46
06/25/2022 01:38:47 - INFO - __main__ - Saving model with best Classification-F1: 0.43762824042191467 -> 0.4759356040854714 on epoch=46, global_step=650
06/25/2022 01:38:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
06/25/2022 01:38:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=47
06/25/2022 01:38:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.51 on epoch=48
06/25/2022 01:38:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.38 on epoch=49
06/25/2022 01:39:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=49
06/25/2022 01:39:07 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.5442052665919062 on epoch=49
06/25/2022 01:39:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4759356040854714 -> 0.5442052665919062 on epoch=49, global_step=700
06/25/2022 01:39:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.44 on epoch=50
06/25/2022 01:39:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=51
06/25/2022 01:39:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=52
06/25/2022 01:39:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=52
06/25/2022 01:39:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.33 on epoch=53
06/25/2022 01:39:27 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.6135789035668366 on epoch=53
06/25/2022 01:39:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5442052665919062 -> 0.6135789035668366 on epoch=53, global_step=750
06/25/2022 01:39:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.42 on epoch=54
06/25/2022 01:39:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=54
06/25/2022 01:39:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.36 on epoch=55
06/25/2022 01:39:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=56
06/25/2022 01:39:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=57
06/25/2022 01:39:48 - INFO - __main__ - Global step 800 Train loss 0.37 Classification-F1 0.5904942482593507 on epoch=57
06/25/2022 01:39:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=57
06/25/2022 01:39:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.37 on epoch=58
06/25/2022 01:39:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=59
06/25/2022 01:39:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=59
06/25/2022 01:40:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=60
06/25/2022 01:40:08 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.5637041406728686 on epoch=60
06/25/2022 01:40:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=61
06/25/2022 01:40:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
06/25/2022 01:40:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=62
06/25/2022 01:40:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=63
06/25/2022 01:40:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.32 on epoch=64
06/25/2022 01:40:28 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.6140949412427525 on epoch=64
06/25/2022 01:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6135789035668366 -> 0.6140949412427525 on epoch=64, global_step=900
06/25/2022 01:40:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=64
06/25/2022 01:40:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.34 on epoch=65
06/25/2022 01:40:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.31 on epoch=66
06/25/2022 01:40:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.32 on epoch=67
06/25/2022 01:40:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=67
06/25/2022 01:40:48 - INFO - __main__ - Global step 950 Train loss 0.31 Classification-F1 0.5842954893556169 on epoch=67
06/25/2022 01:40:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.33 on epoch=68
06/25/2022 01:40:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=69
06/25/2022 01:40:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=69
06/25/2022 01:40:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/25/2022 01:41:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=71
06/25/2022 01:41:08 - INFO - __main__ - Global step 1000 Train loss 0.26 Classification-F1 0.6069957614884899 on epoch=71
06/25/2022 01:41:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=72
06/25/2022 01:41:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=72
06/25/2022 01:41:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=73
06/25/2022 01:41:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.25 on epoch=74
06/25/2022 01:41:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=74
06/25/2022 01:41:28 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.5863152955477761 on epoch=74
06/25/2022 01:41:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=75
06/25/2022 01:41:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/25/2022 01:41:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=77
06/25/2022 01:41:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=77
06/25/2022 01:41:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/25/2022 01:41:48 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.5342548230083424 on epoch=78
06/25/2022 01:41:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
06/25/2022 01:41:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=79
06/25/2022 01:41:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=80
06/25/2022 01:41:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.28 on epoch=81
06/25/2022 01:42:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=82
06/25/2022 01:42:08 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.5866165364283841 on epoch=82
06/25/2022 01:42:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/25/2022 01:42:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/25/2022 01:42:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=84
06/25/2022 01:42:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=84
06/25/2022 01:42:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=85
06/25/2022 01:42:28 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.5819061099585379 on epoch=85
06/25/2022 01:42:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.26 on epoch=86
06/25/2022 01:42:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=87
06/25/2022 01:42:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=87
06/25/2022 01:42:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/25/2022 01:42:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=89
06/25/2022 01:42:48 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.6408873451451462 on epoch=89
06/25/2022 01:42:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6140949412427525 -> 0.6408873451451462 on epoch=89, global_step=1250
06/25/2022 01:42:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.26 on epoch=89
06/25/2022 01:42:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.20 on epoch=90
06/25/2022 01:42:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=91
06/25/2022 01:42:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=92
06/25/2022 01:43:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=92
06/25/2022 01:43:08 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.6757841685960346 on epoch=92
06/25/2022 01:43:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6408873451451462 -> 0.6757841685960346 on epoch=92, global_step=1300
06/25/2022 01:43:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=93
06/25/2022 01:43:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=94
06/25/2022 01:43:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
06/25/2022 01:43:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=95
06/25/2022 01:43:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/25/2022 01:43:28 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6117763845350053 on epoch=96
06/25/2022 01:43:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
06/25/2022 01:43:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/25/2022 01:43:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=98
06/25/2022 01:43:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=99
06/25/2022 01:43:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=99
06/25/2022 01:43:48 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.6773230400911951 on epoch=99
06/25/2022 01:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6757841685960346 -> 0.6773230400911951 on epoch=99, global_step=1400
06/25/2022 01:43:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=100
06/25/2022 01:43:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=101
06/25/2022 01:43:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
06/25/2022 01:43:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.30 on epoch=102
06/25/2022 01:44:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=103
06/25/2022 01:44:09 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.6803134796238245 on epoch=103
06/25/2022 01:44:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6773230400911951 -> 0.6803134796238245 on epoch=103, global_step=1450
06/25/2022 01:44:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
06/25/2022 01:44:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=104
06/25/2022 01:44:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/25/2022 01:44:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=106
06/25/2022 01:44:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/25/2022 01:44:29 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.6782700568907465 on epoch=107
06/25/2022 01:44:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/25/2022 01:44:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=108
06/25/2022 01:44:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
06/25/2022 01:44:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
06/25/2022 01:44:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=110
06/25/2022 01:44:49 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.5827383678721768 on epoch=110
06/25/2022 01:44:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=111
06/25/2022 01:44:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
06/25/2022 01:44:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=112
06/25/2022 01:44:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.16 on epoch=113
06/25/2022 01:45:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=114
06/25/2022 01:45:09 - INFO - __main__ - Global step 1600 Train loss 0.15 Classification-F1 0.6512244927118953 on epoch=114
06/25/2022 01:45:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/25/2022 01:45:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=115
06/25/2022 01:45:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=116
06/25/2022 01:45:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/25/2022 01:45:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=117
06/25/2022 01:45:30 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.7705513073175978 on epoch=117
06/25/2022 01:45:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6803134796238245 -> 0.7705513073175978 on epoch=117, global_step=1650
06/25/2022 01:45:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/25/2022 01:45:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
06/25/2022 01:45:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/25/2022 01:45:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/25/2022 01:45:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=121
06/25/2022 01:45:50 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.5991936955229502 on epoch=121
06/25/2022 01:45:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/25/2022 01:45:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.20 on epoch=122
06/25/2022 01:45:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.21 on epoch=123
06/25/2022 01:46:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=124
06/25/2022 01:46:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=124
06/25/2022 01:46:11 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.7369964778981334 on epoch=124
06/25/2022 01:46:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
06/25/2022 01:46:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
06/25/2022 01:46:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/25/2022 01:46:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
06/25/2022 01:46:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=128
06/25/2022 01:46:31 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.5441520645330505 on epoch=128
06/25/2022 01:46:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=129
06/25/2022 01:46:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
06/25/2022 01:46:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
06/25/2022 01:46:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.14 on epoch=131
06/25/2022 01:46:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/25/2022 01:46:51 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.5921163707707232 on epoch=132
06/25/2022 01:46:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.16 on epoch=132
06/25/2022 01:46:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/25/2022 01:46:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/25/2022 01:47:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=134
06/25/2022 01:47:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=135
06/25/2022 01:47:11 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.5652089230265814 on epoch=135
06/25/2022 01:47:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.17 on epoch=136
06/25/2022 01:47:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/25/2022 01:47:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
06/25/2022 01:47:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
06/25/2022 01:47:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=139
06/25/2022 01:47:31 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.6987743891669163 on epoch=139
06/25/2022 01:47:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/25/2022 01:47:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=140
06/25/2022 01:47:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=141
06/25/2022 01:47:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=142
06/25/2022 01:47:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=142
06/25/2022 01:47:51 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.6566161899666275 on epoch=142
06/25/2022 01:47:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=143
06/25/2022 01:47:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/25/2022 01:47:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=144
06/25/2022 01:48:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/25/2022 01:48:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=146
06/25/2022 01:48:11 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.734756419089261 on epoch=146
06/25/2022 01:48:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/25/2022 01:48:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/25/2022 01:48:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=148
06/25/2022 01:48:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.16 on epoch=149
06/25/2022 01:48:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=149
06/25/2022 01:48:32 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.7862045419846571 on epoch=149
06/25/2022 01:48:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7705513073175978 -> 0.7862045419846571 on epoch=149, global_step=2100
06/25/2022 01:48:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=150
06/25/2022 01:48:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.15 on epoch=151
06/25/2022 01:48:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/25/2022 01:48:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=152
06/25/2022 01:48:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
06/25/2022 01:48:52 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.7148028977185557 on epoch=153
06/25/2022 01:48:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
06/25/2022 01:48:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/25/2022 01:49:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/25/2022 01:49:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.15 on epoch=156
06/25/2022 01:49:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
06/25/2022 01:49:12 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.7391143886967133 on epoch=157
06/25/2022 01:49:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=157
06/25/2022 01:49:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=158
06/25/2022 01:49:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
06/25/2022 01:49:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/25/2022 01:49:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=160
06/25/2022 01:49:32 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.7190357019513599 on epoch=160
06/25/2022 01:49:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=161
06/25/2022 01:49:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/25/2022 01:49:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/25/2022 01:49:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=163
06/25/2022 01:49:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=164
06/25/2022 01:49:53 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.676678774067015 on epoch=164
06/25/2022 01:49:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=164
06/25/2022 01:49:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=165
06/25/2022 01:50:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=166
06/25/2022 01:50:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
06/25/2022 01:50:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/25/2022 01:50:13 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.676678774067015 on epoch=167
06/25/2022 01:50:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/25/2022 01:50:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.15 on epoch=169
06/25/2022 01:50:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=169
06/25/2022 01:50:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/25/2022 01:50:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/25/2022 01:50:33 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.6743444559432233 on epoch=171
06/25/2022 01:50:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/25/2022 01:50:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/25/2022 01:50:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/25/2022 01:50:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/25/2022 01:50:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/25/2022 01:50:53 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.6977470920882417 on epoch=174
06/25/2022 01:50:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=175
06/25/2022 01:50:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.15 on epoch=176
06/25/2022 01:51:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/25/2022 01:51:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/25/2022 01:51:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/25/2022 01:51:13 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7019694125953918 on epoch=178
06/25/2022 01:51:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/25/2022 01:51:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/25/2022 01:51:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/25/2022 01:51:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.11 on epoch=181
06/25/2022 01:51:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
06/25/2022 01:51:33 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7019694125953918 on epoch=182
06/25/2022 01:51:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=182
06/25/2022 01:51:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/25/2022 01:51:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
06/25/2022 01:51:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/25/2022 01:51:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=185
06/25/2022 01:51:53 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.6961112890255979 on epoch=185
06/25/2022 01:51:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/25/2022 01:51:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/25/2022 01:52:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=187
06/25/2022 01:52:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/25/2022 01:52:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=189
06/25/2022 01:52:13 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.7462352030070701 on epoch=189
06/25/2022 01:52:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/25/2022 01:52:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/25/2022 01:52:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=191
06/25/2022 01:52:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/25/2022 01:52:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/25/2022 01:52:33 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.6583219223577792 on epoch=192
06/25/2022 01:52:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
06/25/2022 01:52:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/25/2022 01:52:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/25/2022 01:52:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/25/2022 01:52:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
06/25/2022 01:52:53 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6851209320936607 on epoch=196
06/25/2022 01:52:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/25/2022 01:52:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=197
06/25/2022 01:53:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.14 on epoch=198
06/25/2022 01:53:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/25/2022 01:53:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/25/2022 01:53:13 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.7409677132951358 on epoch=199
06/25/2022 01:53:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/25/2022 01:53:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=201
06/25/2022 01:53:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
06/25/2022 01:53:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
06/25/2022 01:53:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/25/2022 01:53:34 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.7036760559119424 on epoch=203
06/25/2022 01:53:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/25/2022 01:53:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/25/2022 01:53:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/25/2022 01:53:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=206
06/25/2022 01:53:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/25/2022 01:53:54 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7034766938704751 on epoch=207
06/25/2022 01:53:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=207
06/25/2022 01:53:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/25/2022 01:54:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/25/2022 01:54:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/25/2022 01:54:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.11 on epoch=210
06/25/2022 01:54:14 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7052709522436809 on epoch=210
06/25/2022 01:54:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
06/25/2022 01:54:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=212
06/25/2022 01:54:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
06/25/2022 01:54:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
06/25/2022 01:54:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.12 on epoch=214
06/25/2022 01:54:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:54:28 - INFO - __main__ - Printing 3 examples
06/25/2022 01:54:28 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 01:54:28 - INFO - __main__ - ['Company']
06/25/2022 01:54:28 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 01:54:28 - INFO - __main__ - ['Company']
06/25/2022 01:54:28 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 01:54:28 - INFO - __main__ - ['Company']
06/25/2022 01:54:28 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:54:28 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:54:28 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 01:54:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:54:28 - INFO - __main__ - Printing 3 examples
06/25/2022 01:54:28 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 01:54:28 - INFO - __main__ - ['Company']
06/25/2022 01:54:28 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 01:54:28 - INFO - __main__ - ['Company']
06/25/2022 01:54:28 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 01:54:28 - INFO - __main__ - ['Company']
06/25/2022 01:54:28 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:54:28 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:54:29 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 01:54:34 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.6971301651555253 on epoch=214
06/25/2022 01:54:34 - INFO - __main__ - save last model!
06/25/2022 01:54:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 01:54:34 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 01:54:34 - INFO - __main__ - Printing 3 examples
06/25/2022 01:54:34 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 01:54:34 - INFO - __main__ - ['Animal']
06/25/2022 01:54:34 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 01:54:34 - INFO - __main__ - ['Animal']
06/25/2022 01:54:34 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 01:54:34 - INFO - __main__ - ['Village']
06/25/2022 01:54:34 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:54:36 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:54:39 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 01:54:44 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:54:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 01:54:45 - INFO - __main__ - Starting training!
06/25/2022 01:56:51 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/25/2022 01:56:51 - INFO - __main__ - Classification-F1 on test data: 0.4011
06/25/2022 01:56:51 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.7862045419846571, test_performance=0.4011011559815408
06/25/2022 01:56:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/25/2022 01:56:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:56:52 - INFO - __main__ - Printing 3 examples
06/25/2022 01:56:52 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 01:56:52 - INFO - __main__ - ['Company']
06/25/2022 01:56:52 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 01:56:52 - INFO - __main__ - ['Company']
06/25/2022 01:56:52 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 01:56:52 - INFO - __main__ - ['Company']
06/25/2022 01:56:52 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:56:53 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:56:53 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 01:56:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 01:56:53 - INFO - __main__ - Printing 3 examples
06/25/2022 01:56:53 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 01:56:53 - INFO - __main__ - ['Company']
06/25/2022 01:56:53 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 01:56:53 - INFO - __main__ - ['Company']
06/25/2022 01:56:53 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 01:56:53 - INFO - __main__ - ['Company']
06/25/2022 01:56:53 - INFO - __main__ - Tokenizing Input ...
06/25/2022 01:56:53 - INFO - __main__ - Tokenizing Output ...
06/25/2022 01:56:53 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 01:57:08 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 01:57:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 01:57:09 - INFO - __main__ - Starting training!
06/25/2022 01:57:13 - INFO - __main__ - Step 10 Global step 10 Train loss 6.01 on epoch=0
06/25/2022 01:57:15 - INFO - __main__ - Step 20 Global step 20 Train loss 4.71 on epoch=1
06/25/2022 01:57:18 - INFO - __main__ - Step 30 Global step 30 Train loss 4.07 on epoch=2
06/25/2022 01:57:21 - INFO - __main__ - Step 40 Global step 40 Train loss 3.58 on epoch=2
06/25/2022 01:57:23 - INFO - __main__ - Step 50 Global step 50 Train loss 3.25 on epoch=3
06/25/2022 01:57:28 - INFO - __main__ - Global step 50 Train loss 4.32 Classification-F1 0.05069217723655844 on epoch=3
06/25/2022 01:57:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05069217723655844 on epoch=3, global_step=50
06/25/2022 01:57:31 - INFO - __main__ - Step 60 Global step 60 Train loss 3.03 on epoch=4
06/25/2022 01:57:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.74 on epoch=4
06/25/2022 01:57:36 - INFO - __main__ - Step 80 Global step 80 Train loss 2.36 on epoch=5
06/25/2022 01:57:38 - INFO - __main__ - Step 90 Global step 90 Train loss 2.21 on epoch=6
06/25/2022 01:57:41 - INFO - __main__ - Step 100 Global step 100 Train loss 2.06 on epoch=7
06/25/2022 01:57:47 - INFO - __main__ - Global step 100 Train loss 2.48 Classification-F1 0.09043505456224528 on epoch=7
06/25/2022 01:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.05069217723655844 -> 0.09043505456224528 on epoch=7, global_step=100
06/25/2022 01:57:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.97 on epoch=7
06/25/2022 01:57:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.60 on epoch=8
06/25/2022 01:57:54 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=9
06/25/2022 01:57:57 - INFO - __main__ - Step 140 Global step 140 Train loss 1.39 on epoch=9
06/25/2022 01:57:59 - INFO - __main__ - Step 150 Global step 150 Train loss 1.38 on epoch=10
06/25/2022 01:58:05 - INFO - __main__ - Global step 150 Train loss 1.58 Classification-F1 0.1398284825674412 on epoch=10
06/25/2022 01:58:05 - INFO - __main__ - Saving model with best Classification-F1: 0.09043505456224528 -> 0.1398284825674412 on epoch=10, global_step=150
06/25/2022 01:58:08 - INFO - __main__ - Step 160 Global step 160 Train loss 1.07 on epoch=11
06/25/2022 01:58:11 - INFO - __main__ - Step 170 Global step 170 Train loss 1.10 on epoch=12
06/25/2022 01:58:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=12
06/25/2022 01:58:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.96 on epoch=13
06/25/2022 01:58:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=14
06/25/2022 01:58:25 - INFO - __main__ - Global step 200 Train loss 1.00 Classification-F1 0.28304571783208177 on epoch=14
06/25/2022 01:58:25 - INFO - __main__ - Saving model with best Classification-F1: 0.1398284825674412 -> 0.28304571783208177 on epoch=14, global_step=200
06/25/2022 01:58:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=14
06/25/2022 01:58:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=15
06/25/2022 01:58:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=16
06/25/2022 01:58:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=17
06/25/2022 01:58:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=17
06/25/2022 01:58:45 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.32139562354012735 on epoch=17
06/25/2022 01:58:45 - INFO - __main__ - Saving model with best Classification-F1: 0.28304571783208177 -> 0.32139562354012735 on epoch=17, global_step=250
06/25/2022 01:58:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=18
06/25/2022 01:58:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=19
06/25/2022 01:58:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=19
06/25/2022 01:58:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=20
06/25/2022 01:58:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=21
06/25/2022 01:59:04 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.43473295243873666 on epoch=21
06/25/2022 01:59:04 - INFO - __main__ - Saving model with best Classification-F1: 0.32139562354012735 -> 0.43473295243873666 on epoch=21, global_step=300
06/25/2022 01:59:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=22
06/25/2022 01:59:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=22
06/25/2022 01:59:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=23
06/25/2022 01:59:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=24
06/25/2022 01:59:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
06/25/2022 01:59:24 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.5041588542878865 on epoch=24
06/25/2022 01:59:24 - INFO - __main__ - Saving model with best Classification-F1: 0.43473295243873666 -> 0.5041588542878865 on epoch=24, global_step=350
06/25/2022 01:59:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=25
06/25/2022 01:59:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/25/2022 01:59:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/25/2022 01:59:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=27
06/25/2022 01:59:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=28
06/25/2022 01:59:44 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5717003569387861 on epoch=28
06/25/2022 01:59:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5041588542878865 -> 0.5717003569387861 on epoch=28, global_step=400
06/25/2022 01:59:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=29
06/25/2022 01:59:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=29
06/25/2022 01:59:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=30
06/25/2022 01:59:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
06/25/2022 01:59:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=32
06/25/2022 02:00:04 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.5808700307783886 on epoch=32
06/25/2022 02:00:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5717003569387861 -> 0.5808700307783886 on epoch=32, global_step=450
06/25/2022 02:00:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=32
06/25/2022 02:00:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
06/25/2022 02:00:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=34
06/25/2022 02:00:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
06/25/2022 02:00:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=35
06/25/2022 02:00:25 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.525806026456351 on epoch=35
06/25/2022 02:00:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
06/25/2022 02:00:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
06/25/2022 02:00:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/25/2022 02:00:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=38
06/25/2022 02:00:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
06/25/2022 02:00:45 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7133351882246765 on epoch=39
06/25/2022 02:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5808700307783886 -> 0.7133351882246765 on epoch=39, global_step=550
06/25/2022 02:00:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=39
06/25/2022 02:00:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/25/2022 02:00:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/25/2022 02:00:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/25/2022 02:00:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=42
06/25/2022 02:01:05 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6206926406926406 on epoch=42
06/25/2022 02:01:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
06/25/2022 02:01:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=44
06/25/2022 02:01:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
06/25/2022 02:01:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=45
06/25/2022 02:01:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
06/25/2022 02:01:25 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.5973590951532127 on epoch=46
06/25/2022 02:01:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
06/25/2022 02:01:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/25/2022 02:01:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/25/2022 02:01:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
06/25/2022 02:01:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/25/2022 02:01:44 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6286459184123255 on epoch=49
06/25/2022 02:01:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/25/2022 02:01:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=51
06/25/2022 02:01:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=52
06/25/2022 02:01:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
06/25/2022 02:01:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/25/2022 02:02:04 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6265591879384983 on epoch=53
06/25/2022 02:02:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=54
06/25/2022 02:02:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/25/2022 02:02:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/25/2022 02:02:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/25/2022 02:02:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/25/2022 02:02:24 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.6256732521688416 on epoch=57
06/25/2022 02:02:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/25/2022 02:02:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
06/25/2022 02:02:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/25/2022 02:02:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/25/2022 02:02:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/25/2022 02:02:44 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6933550059986842 on epoch=60
06/25/2022 02:02:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
06/25/2022 02:02:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/25/2022 02:02:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/25/2022 02:02:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/25/2022 02:02:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/25/2022 02:03:04 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6984954649025839 on epoch=64
06/25/2022 02:03:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/25/2022 02:03:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/25/2022 02:03:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
06/25/2022 02:03:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=67
06/25/2022 02:03:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/25/2022 02:03:24 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7025836681777791 on epoch=67
06/25/2022 02:03:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/25/2022 02:03:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
06/25/2022 02:03:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/25/2022 02:03:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/25/2022 02:03:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/25/2022 02:03:43 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6937347601418791 on epoch=71
06/25/2022 02:03:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/25/2022 02:03:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/25/2022 02:03:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=73
06/25/2022 02:03:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=74
06/25/2022 02:03:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/25/2022 02:04:03 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6965292212696735 on epoch=74
06/25/2022 02:04:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/25/2022 02:04:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/25/2022 02:04:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/25/2022 02:04:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/25/2022 02:04:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
06/25/2022 02:04:23 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7382259375362824 on epoch=78
06/25/2022 02:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7133351882246765 -> 0.7382259375362824 on epoch=78, global_step=1100
06/25/2022 02:04:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/25/2022 02:04:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/25/2022 02:04:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/25/2022 02:04:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/25/2022 02:04:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/25/2022 02:04:43 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.704106470583843 on epoch=82
06/25/2022 02:04:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/25/2022 02:04:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/25/2022 02:04:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/25/2022 02:04:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/25/2022 02:04:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/25/2022 02:05:02 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7908165983216693 on epoch=85
06/25/2022 02:05:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7382259375362824 -> 0.7908165983216693 on epoch=85, global_step=1200
06/25/2022 02:05:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/25/2022 02:05:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/25/2022 02:05:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/25/2022 02:05:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/25/2022 02:05:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/25/2022 02:05:22 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.676076635843043 on epoch=89
06/25/2022 02:05:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/25/2022 02:05:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/25/2022 02:05:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/25/2022 02:05:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/25/2022 02:05:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/25/2022 02:05:42 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.806543614513254 on epoch=92
06/25/2022 02:05:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7908165983216693 -> 0.806543614513254 on epoch=92, global_step=1300
06/25/2022 02:05:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/25/2022 02:05:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/25/2022 02:05:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/25/2022 02:05:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/25/2022 02:05:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/25/2022 02:06:01 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.763419137612686 on epoch=96
06/25/2022 02:06:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/25/2022 02:06:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/25/2022 02:06:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/25/2022 02:06:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/25/2022 02:06:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/25/2022 02:06:21 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7598150816657491 on epoch=99
06/25/2022 02:06:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/25/2022 02:06:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/25/2022 02:06:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/25/2022 02:06:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/25/2022 02:06:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/25/2022 02:06:41 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8102351791156345 on epoch=103
06/25/2022 02:06:41 - INFO - __main__ - Saving model with best Classification-F1: 0.806543614513254 -> 0.8102351791156345 on epoch=103, global_step=1450
06/25/2022 02:06:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/25/2022 02:06:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/25/2022 02:06:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/25/2022 02:06:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/25/2022 02:06:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/25/2022 02:07:01 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8588204065122864 on epoch=107
06/25/2022 02:07:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8102351791156345 -> 0.8588204065122864 on epoch=107, global_step=1500
06/25/2022 02:07:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/25/2022 02:07:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/25/2022 02:07:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/25/2022 02:07:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/25/2022 02:07:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/25/2022 02:07:21 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9226979472140762 on epoch=110
06/25/2022 02:07:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8588204065122864 -> 0.9226979472140762 on epoch=110, global_step=1550
06/25/2022 02:07:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/25/2022 02:07:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/25/2022 02:07:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/25/2022 02:07:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/25/2022 02:07:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/25/2022 02:07:41 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7651026392961877 on epoch=114
06/25/2022 02:07:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/25/2022 02:07:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/25/2022 02:07:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/25/2022 02:07:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
06/25/2022 02:07:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/25/2022 02:08:01 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8589318147119299 on epoch=117
06/25/2022 02:08:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/25/2022 02:08:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/25/2022 02:08:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/25/2022 02:08:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/25/2022 02:08:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/25/2022 02:08:21 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8589318147119299 on epoch=121
06/25/2022 02:08:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/25/2022 02:08:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/25/2022 02:08:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/25/2022 02:08:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/25/2022 02:08:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/25/2022 02:08:42 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8630131964809384 on epoch=124
06/25/2022 02:08:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/25/2022 02:08:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/25/2022 02:08:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/25/2022 02:08:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/25/2022 02:08:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/25/2022 02:09:02 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8669232649071359 on epoch=128
06/25/2022 02:09:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/25/2022 02:09:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/25/2022 02:09:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/25/2022 02:09:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/25/2022 02:09:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/25/2022 02:09:23 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7631678295749487 on epoch=132
06/25/2022 02:09:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/25/2022 02:09:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/25/2022 02:09:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/25/2022 02:09:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/25/2022 02:09:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/25/2022 02:09:43 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7994454347395523 on epoch=135
06/25/2022 02:09:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/25/2022 02:09:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/25/2022 02:09:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/25/2022 02:09:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/25/2022 02:09:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/25/2022 02:10:03 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.810223678914381 on epoch=139
06/25/2022 02:10:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/25/2022 02:10:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/25/2022 02:10:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/25/2022 02:10:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/25/2022 02:10:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/25/2022 02:10:24 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8708333333333333 on epoch=142
06/25/2022 02:10:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/25/2022 02:10:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/25/2022 02:10:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=144
06/25/2022 02:10:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/25/2022 02:10:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/25/2022 02:10:44 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7702385366456556 on epoch=146
06/25/2022 02:10:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/25/2022 02:10:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/25/2022 02:10:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/25/2022 02:10:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/25/2022 02:10:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/25/2022 02:11:04 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.723878662172673 on epoch=149
06/25/2022 02:11:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/25/2022 02:11:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/25/2022 02:11:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/25/2022 02:11:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/25/2022 02:11:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/25/2022 02:11:23 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8137641546658102 on epoch=153
06/25/2022 02:11:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/25/2022 02:11:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/25/2022 02:11:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/25/2022 02:11:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/25/2022 02:11:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/25/2022 02:11:43 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8174442190669371 on epoch=157
06/25/2022 02:11:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/25/2022 02:11:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/25/2022 02:11:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/25/2022 02:11:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/25/2022 02:11:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/25/2022 02:12:03 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8708333333333333 on epoch=160
06/25/2022 02:12:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/25/2022 02:12:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/25/2022 02:12:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/25/2022 02:12:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/25/2022 02:12:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/25/2022 02:12:23 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7703703703703704 on epoch=164
06/25/2022 02:12:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/25/2022 02:12:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/25/2022 02:12:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/25/2022 02:12:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/25/2022 02:12:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/25/2022 02:12:42 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8177103099304238 on epoch=167
06/25/2022 02:12:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/25/2022 02:12:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/25/2022 02:12:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/25/2022 02:12:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/25/2022 02:12:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/25/2022 02:13:02 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7669056152927121 on epoch=171
06/25/2022 02:13:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/25/2022 02:13:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/25/2022 02:13:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/25/2022 02:13:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/25/2022 02:13:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/25/2022 02:13:22 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7635386119257087 on epoch=174
06/25/2022 02:13:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/25/2022 02:13:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/25/2022 02:13:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/25/2022 02:13:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/25/2022 02:13:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/25/2022 02:13:42 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7631678295749487 on epoch=178
06/25/2022 02:13:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/25/2022 02:13:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/25/2022 02:13:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/25/2022 02:13:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/25/2022 02:13:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/25/2022 02:14:02 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7670142283045509 on epoch=182
06/25/2022 02:14:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/25/2022 02:14:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/25/2022 02:14:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/25/2022 02:14:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/25/2022 02:14:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/25/2022 02:14:22 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8588204065122864 on epoch=185
06/25/2022 02:14:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/25/2022 02:14:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/25/2022 02:14:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/25/2022 02:14:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/25/2022 02:14:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/25/2022 02:14:41 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9226979472140762 on epoch=189
06/25/2022 02:14:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/25/2022 02:14:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/25/2022 02:14:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/25/2022 02:14:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/25/2022 02:14:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/25/2022 02:15:00 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7685782556750299 on epoch=192
06/25/2022 02:15:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/25/2022 02:15:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/25/2022 02:15:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/25/2022 02:15:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/25/2022 02:15:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/25/2022 02:15:20 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8140302455292968 on epoch=196
06/25/2022 02:15:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/25/2022 02:15:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/25/2022 02:15:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/25/2022 02:15:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/25/2022 02:15:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/25/2022 02:15:40 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8630131964809384 on epoch=199
06/25/2022 02:15:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/25/2022 02:15:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/25/2022 02:15:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/25/2022 02:15:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/25/2022 02:15:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/25/2022 02:16:00 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9183838383838382 on epoch=203
06/25/2022 02:16:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/25/2022 02:16:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/25/2022 02:16:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/25/2022 02:16:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/25/2022 02:16:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/25/2022 02:16:19 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9268686868686868 on epoch=207
06/25/2022 02:16:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9226979472140762 -> 0.9268686868686868 on epoch=207, global_step=2900
06/25/2022 02:16:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/25/2022 02:16:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/25/2022 02:16:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/25/2022 02:16:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/25/2022 02:16:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/25/2022 02:16:39 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=210
06/25/2022 02:16:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/25/2022 02:16:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/25/2022 02:16:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/25/2022 02:16:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/25/2022 02:16:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/25/2022 02:16:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:16:53 - INFO - __main__ - Printing 3 examples
06/25/2022 02:16:53 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 02:16:53 - INFO - __main__ - ['Company']
06/25/2022 02:16:53 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 02:16:53 - INFO - __main__ - ['Company']
06/25/2022 02:16:53 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 02:16:53 - INFO - __main__ - ['Company']
06/25/2022 02:16:53 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:16:53 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:16:53 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 02:16:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:16:53 - INFO - __main__ - Printing 3 examples
06/25/2022 02:16:53 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 02:16:53 - INFO - __main__ - ['Company']
06/25/2022 02:16:53 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 02:16:53 - INFO - __main__ - ['Company']
06/25/2022 02:16:53 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 02:16:53 - INFO - __main__ - ['Company']
06/25/2022 02:16:53 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:16:54 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:16:54 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 02:16:58 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9268686868686868 on epoch=214
06/25/2022 02:16:58 - INFO - __main__ - save last model!
06/25/2022 02:16:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 02:16:59 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 02:16:59 - INFO - __main__ - Printing 3 examples
06/25/2022 02:16:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 02:16:59 - INFO - __main__ - ['Animal']
06/25/2022 02:16:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 02:16:59 - INFO - __main__ - ['Animal']
06/25/2022 02:16:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 02:16:59 - INFO - __main__ - ['Village']
06/25/2022 02:16:59 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:17:01 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:17:04 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 02:17:09 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:17:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 02:17:10 - INFO - __main__ - Starting training!
06/25/2022 02:19:20 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/25/2022 02:19:20 - INFO - __main__ - Classification-F1 on test data: 0.5472
06/25/2022 02:19:20 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9268686868686868, test_performance=0.5471759696630637
06/25/2022 02:19:20 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/25/2022 02:19:21 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:19:21 - INFO - __main__ - Printing 3 examples
06/25/2022 02:19:21 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 02:19:21 - INFO - __main__ - ['Company']
06/25/2022 02:19:21 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 02:19:21 - INFO - __main__ - ['Company']
06/25/2022 02:19:21 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 02:19:21 - INFO - __main__ - ['Company']
06/25/2022 02:19:21 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:19:21 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:19:22 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 02:19:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:19:22 - INFO - __main__ - Printing 3 examples
06/25/2022 02:19:22 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 02:19:22 - INFO - __main__ - ['Company']
06/25/2022 02:19:22 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 02:19:22 - INFO - __main__ - ['Company']
06/25/2022 02:19:22 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 02:19:22 - INFO - __main__ - ['Company']
06/25/2022 02:19:22 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:19:22 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:19:22 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 02:19:37 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:19:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 02:19:38 - INFO - __main__ - Starting training!
06/25/2022 02:19:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.60 on epoch=0
06/25/2022 02:19:44 - INFO - __main__ - Step 20 Global step 20 Train loss 5.15 on epoch=1
06/25/2022 02:19:47 - INFO - __main__ - Step 30 Global step 30 Train loss 4.42 on epoch=2
06/25/2022 02:19:49 - INFO - __main__ - Step 40 Global step 40 Train loss 3.90 on epoch=2
06/25/2022 02:19:52 - INFO - __main__ - Step 50 Global step 50 Train loss 3.62 on epoch=3
06/25/2022 02:19:57 - INFO - __main__ - Global step 50 Train loss 4.74 Classification-F1 0.048387096774193554 on epoch=3
06/25/2022 02:19:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.048387096774193554 on epoch=3, global_step=50
06/25/2022 02:20:00 - INFO - __main__ - Step 60 Global step 60 Train loss 3.30 on epoch=4
06/25/2022 02:20:02 - INFO - __main__ - Step 70 Global step 70 Train loss 2.93 on epoch=4
06/25/2022 02:20:05 - INFO - __main__ - Step 80 Global step 80 Train loss 2.82 on epoch=5
06/25/2022 02:20:07 - INFO - __main__ - Step 90 Global step 90 Train loss 2.70 on epoch=6
06/25/2022 02:20:10 - INFO - __main__ - Step 100 Global step 100 Train loss 2.43 on epoch=7
06/25/2022 02:20:15 - INFO - __main__ - Global step 100 Train loss 2.84 Classification-F1 0.07484356588054637 on epoch=7
06/25/2022 02:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.048387096774193554 -> 0.07484356588054637 on epoch=7, global_step=100
06/25/2022 02:20:18 - INFO - __main__ - Step 110 Global step 110 Train loss 2.26 on epoch=7
06/25/2022 02:20:20 - INFO - __main__ - Step 120 Global step 120 Train loss 2.02 on epoch=8
06/25/2022 02:20:23 - INFO - __main__ - Step 130 Global step 130 Train loss 2.09 on epoch=9
06/25/2022 02:20:25 - INFO - __main__ - Step 140 Global step 140 Train loss 1.72 on epoch=9
06/25/2022 02:20:28 - INFO - __main__ - Step 150 Global step 150 Train loss 1.69 on epoch=10
06/25/2022 02:20:34 - INFO - __main__ - Global step 150 Train loss 1.96 Classification-F1 0.10038907092737114 on epoch=10
06/25/2022 02:20:34 - INFO - __main__ - Saving model with best Classification-F1: 0.07484356588054637 -> 0.10038907092737114 on epoch=10, global_step=150
06/25/2022 02:20:36 - INFO - __main__ - Step 160 Global step 160 Train loss 1.53 on epoch=11
06/25/2022 02:20:39 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=12
06/25/2022 02:20:41 - INFO - __main__ - Step 180 Global step 180 Train loss 1.45 on epoch=12
06/25/2022 02:20:44 - INFO - __main__ - Step 190 Global step 190 Train loss 1.23 on epoch=13
06/25/2022 02:20:46 - INFO - __main__ - Step 200 Global step 200 Train loss 1.29 on epoch=14
06/25/2022 02:20:52 - INFO - __main__ - Global step 200 Train loss 1.39 Classification-F1 0.17775266127806413 on epoch=14
06/25/2022 02:20:52 - INFO - __main__ - Saving model with best Classification-F1: 0.10038907092737114 -> 0.17775266127806413 on epoch=14, global_step=200
06/25/2022 02:20:55 - INFO - __main__ - Step 210 Global step 210 Train loss 1.07 on epoch=14
06/25/2022 02:20:57 - INFO - __main__ - Step 220 Global step 220 Train loss 1.04 on epoch=15
06/25/2022 02:21:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.97 on epoch=16
06/25/2022 02:21:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.90 on epoch=17
06/25/2022 02:21:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.77 on epoch=17
06/25/2022 02:21:12 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.27823342577072213 on epoch=17
06/25/2022 02:21:12 - INFO - __main__ - Saving model with best Classification-F1: 0.17775266127806413 -> 0.27823342577072213 on epoch=17, global_step=250
06/25/2022 02:21:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=18
06/25/2022 02:21:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=19
06/25/2022 02:21:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.65 on epoch=19
06/25/2022 02:21:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=20
06/25/2022 02:21:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.54 on epoch=21
06/25/2022 02:21:32 - INFO - __main__ - Global step 300 Train loss 0.65 Classification-F1 0.32878120677217215 on epoch=21
06/25/2022 02:21:32 - INFO - __main__ - Saving model with best Classification-F1: 0.27823342577072213 -> 0.32878120677217215 on epoch=21, global_step=300
06/25/2022 02:21:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=22
06/25/2022 02:21:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=22
06/25/2022 02:21:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/25/2022 02:21:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.48 on epoch=24
06/25/2022 02:21:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=24
06/25/2022 02:21:52 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.38730867757543663 on epoch=24
06/25/2022 02:21:52 - INFO - __main__ - Saving model with best Classification-F1: 0.32878120677217215 -> 0.38730867757543663 on epoch=24, global_step=350
06/25/2022 02:21:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.52 on epoch=25
06/25/2022 02:21:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=26
06/25/2022 02:21:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=27
06/25/2022 02:22:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
06/25/2022 02:22:05 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=28
06/25/2022 02:22:12 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.44066403438512797 on epoch=28
06/25/2022 02:22:12 - INFO - __main__ - Saving model with best Classification-F1: 0.38730867757543663 -> 0.44066403438512797 on epoch=28, global_step=400
06/25/2022 02:22:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=29
06/25/2022 02:22:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=29
06/25/2022 02:22:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=30
06/25/2022 02:22:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=31
06/25/2022 02:22:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
06/25/2022 02:22:32 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.48323855496531015 on epoch=32
06/25/2022 02:22:32 - INFO - __main__ - Saving model with best Classification-F1: 0.44066403438512797 -> 0.48323855496531015 on epoch=32, global_step=450
06/25/2022 02:22:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=32
06/25/2022 02:22:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=33
06/25/2022 02:22:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
06/25/2022 02:22:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=34
06/25/2022 02:22:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
06/25/2022 02:22:53 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.47894643988721686 on epoch=35
06/25/2022 02:22:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
06/25/2022 02:22:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=37
06/25/2022 02:23:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/25/2022 02:23:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=38
06/25/2022 02:23:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=39
06/25/2022 02:23:14 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.5874701946894461 on epoch=39
06/25/2022 02:23:14 - INFO - __main__ - Saving model with best Classification-F1: 0.48323855496531015 -> 0.5874701946894461 on epoch=39, global_step=550
06/25/2022 02:23:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=39
06/25/2022 02:23:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=40
06/25/2022 02:23:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=41
06/25/2022 02:23:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=42
06/25/2022 02:23:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
06/25/2022 02:23:35 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.597730412262432 on epoch=42
06/25/2022 02:23:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5874701946894461 -> 0.597730412262432 on epoch=42, global_step=600
06/25/2022 02:23:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/25/2022 02:23:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
06/25/2022 02:23:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=44
06/25/2022 02:23:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=45
06/25/2022 02:23:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
06/25/2022 02:23:56 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.5871603960389479 on epoch=46
06/25/2022 02:23:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/25/2022 02:24:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
06/25/2022 02:24:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/25/2022 02:24:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/25/2022 02:24:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
06/25/2022 02:24:17 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.6132252953557671 on epoch=49
06/25/2022 02:24:17 - INFO - __main__ - Saving model with best Classification-F1: 0.597730412262432 -> 0.6132252953557671 on epoch=49, global_step=700
06/25/2022 02:24:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
06/25/2022 02:24:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=51
06/25/2022 02:24:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=52
06/25/2022 02:24:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=52
06/25/2022 02:24:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
06/25/2022 02:24:38 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6830093047436238 on epoch=53
06/25/2022 02:24:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6132252953557671 -> 0.6830093047436238 on epoch=53, global_step=750
06/25/2022 02:24:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=54
06/25/2022 02:24:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/25/2022 02:24:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
06/25/2022 02:24:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
06/25/2022 02:24:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
06/25/2022 02:24:59 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6607154064397579 on epoch=57
06/25/2022 02:25:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/25/2022 02:25:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/25/2022 02:25:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/25/2022 02:25:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/25/2022 02:25:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/25/2022 02:25:20 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7288283621669924 on epoch=60
06/25/2022 02:25:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6830093047436238 -> 0.7288283621669924 on epoch=60, global_step=850
06/25/2022 02:25:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
06/25/2022 02:25:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
06/25/2022 02:25:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/25/2022 02:25:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=63
06/25/2022 02:25:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
06/25/2022 02:25:41 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6583486688749847 on epoch=64
06/25/2022 02:25:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=64
06/25/2022 02:25:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
06/25/2022 02:25:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/25/2022 02:25:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/25/2022 02:25:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
06/25/2022 02:26:02 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.7462528717145991 on epoch=67
06/25/2022 02:26:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7288283621669924 -> 0.7462528717145991 on epoch=67, global_step=950
06/25/2022 02:26:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/25/2022 02:26:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=69
06/25/2022 02:26:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/25/2022 02:26:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/25/2022 02:26:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=71
06/25/2022 02:26:22 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6962962962962964 on epoch=71
06/25/2022 02:26:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=72
06/25/2022 02:26:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/25/2022 02:26:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
06/25/2022 02:26:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=74
06/25/2022 02:26:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
06/25/2022 02:26:42 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.6993897120333901 on epoch=74
06/25/2022 02:26:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/25/2022 02:26:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/25/2022 02:26:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/25/2022 02:26:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/25/2022 02:26:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/25/2022 02:27:03 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.703943432402384 on epoch=78
06/25/2022 02:27:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/25/2022 02:27:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/25/2022 02:27:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/25/2022 02:27:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/25/2022 02:27:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
06/25/2022 02:27:23 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7099891840363709 on epoch=82
06/25/2022 02:27:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/25/2022 02:27:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/25/2022 02:27:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/25/2022 02:27:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
06/25/2022 02:27:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/25/2022 02:27:44 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.713877043187388 on epoch=85
06/25/2022 02:27:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/25/2022 02:27:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/25/2022 02:27:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=87
06/25/2022 02:27:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=88
06/25/2022 02:27:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/25/2022 02:28:04 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7008054672125863 on epoch=89
06/25/2022 02:28:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
06/25/2022 02:28:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/25/2022 02:28:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/25/2022 02:28:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/25/2022 02:28:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/25/2022 02:28:25 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7113159777230967 on epoch=92
06/25/2022 02:28:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
06/25/2022 02:28:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
06/25/2022 02:28:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/25/2022 02:28:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=95
06/25/2022 02:28:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/25/2022 02:28:45 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.7219694883766073 on epoch=96
06/25/2022 02:28:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/25/2022 02:28:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/25/2022 02:28:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/25/2022 02:28:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/25/2022 02:28:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
06/25/2022 02:29:06 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6958081192464426 on epoch=99
06/25/2022 02:29:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/25/2022 02:29:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/25/2022 02:29:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/25/2022 02:29:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
06/25/2022 02:29:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/25/2022 02:29:26 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6776251479137727 on epoch=103
06/25/2022 02:29:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
06/25/2022 02:29:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/25/2022 02:29:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/25/2022 02:29:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/25/2022 02:29:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/25/2022 02:29:47 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7617984120643164 on epoch=107
06/25/2022 02:29:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7462528717145991 -> 0.7617984120643164 on epoch=107, global_step=1500
06/25/2022 02:29:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/25/2022 02:29:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/25/2022 02:29:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/25/2022 02:29:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/25/2022 02:30:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/25/2022 02:30:07 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7871611205577049 on epoch=110
06/25/2022 02:30:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7617984120643164 -> 0.7871611205577049 on epoch=110, global_step=1550
06/25/2022 02:30:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=111
06/25/2022 02:30:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/25/2022 02:30:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/25/2022 02:30:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/25/2022 02:30:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
06/25/2022 02:30:28 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7020450260096651 on epoch=114
06/25/2022 02:30:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/25/2022 02:30:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/25/2022 02:30:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/25/2022 02:30:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/25/2022 02:30:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/25/2022 02:30:49 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7439535103606294 on epoch=117
06/25/2022 02:30:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/25/2022 02:30:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/25/2022 02:30:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/25/2022 02:30:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/25/2022 02:31:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/25/2022 02:31:09 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7397831051375926 on epoch=121
06/25/2022 02:31:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/25/2022 02:31:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/25/2022 02:31:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/25/2022 02:31:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/25/2022 02:31:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/25/2022 02:31:30 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7484127519166451 on epoch=124
06/25/2022 02:31:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/25/2022 02:31:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/25/2022 02:31:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/25/2022 02:31:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/25/2022 02:31:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/25/2022 02:31:50 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7987807453973242 on epoch=128
06/25/2022 02:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7871611205577049 -> 0.7987807453973242 on epoch=128, global_step=1800
06/25/2022 02:31:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/25/2022 02:31:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/25/2022 02:31:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/25/2022 02:32:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/25/2022 02:32:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/25/2022 02:32:10 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7108094157729631 on epoch=132
06/25/2022 02:32:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/25/2022 02:32:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/25/2022 02:32:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/25/2022 02:32:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/25/2022 02:32:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/25/2022 02:32:31 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.810223678914381 on epoch=135
06/25/2022 02:32:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7987807453973242 -> 0.810223678914381 on epoch=135, global_step=1900
06/25/2022 02:32:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/25/2022 02:32:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/25/2022 02:32:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/25/2022 02:32:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/25/2022 02:32:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/25/2022 02:32:52 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7521957391805062 on epoch=139
06/25/2022 02:32:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/25/2022 02:32:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/25/2022 02:33:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/25/2022 02:33:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/25/2022 02:33:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/25/2022 02:33:12 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7968969532397852 on epoch=142
06/25/2022 02:33:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/25/2022 02:33:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/25/2022 02:33:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/25/2022 02:33:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/25/2022 02:33:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/25/2022 02:33:33 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.808199643493761 on epoch=146
06/25/2022 02:33:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/25/2022 02:33:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/25/2022 02:33:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/25/2022 02:33:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/25/2022 02:33:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/25/2022 02:33:53 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7557107170010396 on epoch=149
06/25/2022 02:33:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/25/2022 02:33:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/25/2022 02:34:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/25/2022 02:34:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/25/2022 02:34:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/25/2022 02:34:14 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8140302455292968 on epoch=153
06/25/2022 02:34:14 - INFO - __main__ - Saving model with best Classification-F1: 0.810223678914381 -> 0.8140302455292968 on epoch=153, global_step=2150
06/25/2022 02:34:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/25/2022 02:34:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/25/2022 02:34:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/25/2022 02:34:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/25/2022 02:34:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
06/25/2022 02:34:34 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7991949859122535 on epoch=157
06/25/2022 02:34:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/25/2022 02:34:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/25/2022 02:34:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/25/2022 02:34:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/25/2022 02:34:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/25/2022 02:34:54 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6954692037759481 on epoch=160
06/25/2022 02:34:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/25/2022 02:35:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/25/2022 02:35:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/25/2022 02:35:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/25/2022 02:35:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/25/2022 02:35:15 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.745188198692092 on epoch=164
06/25/2022 02:35:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/25/2022 02:35:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/25/2022 02:35:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/25/2022 02:35:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/25/2022 02:35:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/25/2022 02:35:35 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7911900164983656 on epoch=167
06/25/2022 02:35:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/25/2022 02:35:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/25/2022 02:35:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/25/2022 02:35:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/25/2022 02:35:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/25/2022 02:35:55 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7463104159878353 on epoch=171
06/25/2022 02:35:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/25/2022 02:36:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/25/2022 02:36:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/25/2022 02:36:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/25/2022 02:36:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/25/2022 02:36:15 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7976779975594017 on epoch=174
06/25/2022 02:36:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/25/2022 02:36:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/25/2022 02:36:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/25/2022 02:36:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/25/2022 02:36:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/25/2022 02:36:35 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8066737105399345 on epoch=178
06/25/2022 02:36:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/25/2022 02:36:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/25/2022 02:36:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/25/2022 02:36:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/25/2022 02:36:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/25/2022 02:36:55 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8553082862543845 on epoch=182
06/25/2022 02:36:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8140302455292968 -> 0.8553082862543845 on epoch=182, global_step=2550
06/25/2022 02:36:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/25/2022 02:37:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/25/2022 02:37:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/25/2022 02:37:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/25/2022 02:37:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/25/2022 02:37:15 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8140338393421885 on epoch=185
06/25/2022 02:37:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/25/2022 02:37:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/25/2022 02:37:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/25/2022 02:37:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/25/2022 02:37:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/25/2022 02:37:35 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8521906856584276 on epoch=189
06/25/2022 02:37:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/25/2022 02:37:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/25/2022 02:37:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/25/2022 02:37:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/25/2022 02:37:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/25/2022 02:37:55 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8001678824022278 on epoch=192
06/25/2022 02:37:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/25/2022 02:38:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/25/2022 02:38:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/25/2022 02:38:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/25/2022 02:38:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/25/2022 02:38:15 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8075280112044818 on epoch=196
06/25/2022 02:38:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/25/2022 02:38:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/25/2022 02:38:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/25/2022 02:38:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/25/2022 02:38:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/25/2022 02:38:35 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=199
06/25/2022 02:38:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8553082862543845 -> 0.8591069464809384 on epoch=199, global_step=2800
06/25/2022 02:38:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/25/2022 02:38:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/25/2022 02:38:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/25/2022 02:38:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/25/2022 02:38:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/25/2022 02:38:56 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8591191654447703 on epoch=203
06/25/2022 02:38:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8591069464809384 -> 0.8591191654447703 on epoch=203, global_step=2850
06/25/2022 02:38:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/25/2022 02:39:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/25/2022 02:39:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/25/2022 02:39:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/25/2022 02:39:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/25/2022 02:39:16 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8630170149071359 on epoch=207
06/25/2022 02:39:16 - INFO - __main__ - Saving model with best Classification-F1: 0.8591191654447703 -> 0.8630170149071359 on epoch=207, global_step=2900
06/25/2022 02:39:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/25/2022 02:39:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/25/2022 02:39:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/25/2022 02:39:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/25/2022 02:39:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/25/2022 02:39:36 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=210
06/25/2022 02:39:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/25/2022 02:39:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/25/2022 02:39:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/25/2022 02:39:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/25/2022 02:39:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/25/2022 02:39:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:39:51 - INFO - __main__ - Printing 3 examples
06/25/2022 02:39:51 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 02:39:51 - INFO - __main__ - ['Company']
06/25/2022 02:39:51 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 02:39:51 - INFO - __main__ - ['Company']
06/25/2022 02:39:51 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 02:39:51 - INFO - __main__ - ['Company']
06/25/2022 02:39:51 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:39:51 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:39:51 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 02:39:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:39:51 - INFO - __main__ - Printing 3 examples
06/25/2022 02:39:51 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 02:39:51 - INFO - __main__ - ['Company']
06/25/2022 02:39:51 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 02:39:51 - INFO - __main__ - ['Company']
06/25/2022 02:39:51 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 02:39:51 - INFO - __main__ - ['Company']
06/25/2022 02:39:51 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:39:51 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:39:51 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 02:39:56 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8043799904429363 on epoch=214
06/25/2022 02:39:56 - INFO - __main__ - save last model!
06/25/2022 02:39:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 02:39:56 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 02:39:56 - INFO - __main__ - Printing 3 examples
06/25/2022 02:39:56 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 02:39:56 - INFO - __main__ - ['Animal']
06/25/2022 02:39:56 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 02:39:56 - INFO - __main__ - ['Animal']
06/25/2022 02:39:56 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 02:39:56 - INFO - __main__ - ['Village']
06/25/2022 02:39:56 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:39:58 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:40:02 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 02:40:07 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:40:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 02:40:07 - INFO - __main__ - Starting training!
06/25/2022 02:42:13 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/25/2022 02:42:13 - INFO - __main__ - Classification-F1 on test data: 0.4542
06/25/2022 02:42:14 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.8630170149071359, test_performance=0.45416775269474924
06/25/2022 02:42:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/25/2022 02:42:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:42:15 - INFO - __main__ - Printing 3 examples
06/25/2022 02:42:15 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 02:42:15 - INFO - __main__ - ['Company']
06/25/2022 02:42:15 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 02:42:15 - INFO - __main__ - ['Company']
06/25/2022 02:42:15 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 02:42:15 - INFO - __main__ - ['Company']
06/25/2022 02:42:15 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:42:15 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:42:15 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 02:42:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 02:42:15 - INFO - __main__ - Printing 3 examples
06/25/2022 02:42:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 02:42:15 - INFO - __main__ - ['Company']
06/25/2022 02:42:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 02:42:15 - INFO - __main__ - ['Company']
06/25/2022 02:42:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 02:42:15 - INFO - __main__ - ['Company']
06/25/2022 02:42:15 - INFO - __main__ - Tokenizing Input ...
06/25/2022 02:42:15 - INFO - __main__ - Tokenizing Output ...
06/25/2022 02:42:15 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 02:42:31 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 02:42:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 02:42:32 - INFO - __main__ - Starting training!
06/25/2022 02:42:35 - INFO - __main__ - Step 10 Global step 10 Train loss 6.82 on epoch=0
06/25/2022 02:42:38 - INFO - __main__ - Step 20 Global step 20 Train loss 5.26 on epoch=1
06/25/2022 02:42:41 - INFO - __main__ - Step 30 Global step 30 Train loss 5.06 on epoch=2
06/25/2022 02:42:43 - INFO - __main__ - Step 40 Global step 40 Train loss 4.24 on epoch=2
06/25/2022 02:42:46 - INFO - __main__ - Step 50 Global step 50 Train loss 3.85 on epoch=3
06/25/2022 02:42:51 - INFO - __main__ - Global step 50 Train loss 5.05 Classification-F1 0.04430794430794431 on epoch=3
06/25/2022 02:42:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04430794430794431 on epoch=3, global_step=50
06/25/2022 02:42:54 - INFO - __main__ - Step 60 Global step 60 Train loss 3.68 on epoch=4
06/25/2022 02:42:57 - INFO - __main__ - Step 70 Global step 70 Train loss 3.47 on epoch=4
06/25/2022 02:42:59 - INFO - __main__ - Step 80 Global step 80 Train loss 3.23 on epoch=5
06/25/2022 02:43:02 - INFO - __main__ - Step 90 Global step 90 Train loss 2.83 on epoch=6
06/25/2022 02:43:05 - INFO - __main__ - Step 100 Global step 100 Train loss 2.82 on epoch=7
06/25/2022 02:43:10 - INFO - __main__ - Global step 100 Train loss 3.21 Classification-F1 0.05630666167153918 on epoch=7
06/25/2022 02:43:10 - INFO - __main__ - Saving model with best Classification-F1: 0.04430794430794431 -> 0.05630666167153918 on epoch=7, global_step=100
06/25/2022 02:43:13 - INFO - __main__ - Step 110 Global step 110 Train loss 2.65 on epoch=7
06/25/2022 02:43:16 - INFO - __main__ - Step 120 Global step 120 Train loss 2.40 on epoch=8
06/25/2022 02:43:18 - INFO - __main__ - Step 130 Global step 130 Train loss 2.40 on epoch=9
06/25/2022 02:43:21 - INFO - __main__ - Step 140 Global step 140 Train loss 2.23 on epoch=9
06/25/2022 02:43:24 - INFO - __main__ - Step 150 Global step 150 Train loss 2.09 on epoch=10
06/25/2022 02:43:30 - INFO - __main__ - Global step 150 Train loss 2.35 Classification-F1 0.09591900659013414 on epoch=10
06/25/2022 02:43:30 - INFO - __main__ - Saving model with best Classification-F1: 0.05630666167153918 -> 0.09591900659013414 on epoch=10, global_step=150
06/25/2022 02:43:32 - INFO - __main__ - Step 160 Global step 160 Train loss 2.06 on epoch=11
06/25/2022 02:43:35 - INFO - __main__ - Step 170 Global step 170 Train loss 1.96 on epoch=12
06/25/2022 02:43:38 - INFO - __main__ - Step 180 Global step 180 Train loss 1.72 on epoch=12
06/25/2022 02:43:40 - INFO - __main__ - Step 190 Global step 190 Train loss 1.73 on epoch=13
06/25/2022 02:43:43 - INFO - __main__ - Step 200 Global step 200 Train loss 1.51 on epoch=14
06/25/2022 02:43:49 - INFO - __main__ - Global step 200 Train loss 1.80 Classification-F1 0.10552335827508873 on epoch=14
06/25/2022 02:43:49 - INFO - __main__ - Saving model with best Classification-F1: 0.09591900659013414 -> 0.10552335827508873 on epoch=14, global_step=200
06/25/2022 02:43:52 - INFO - __main__ - Step 210 Global step 210 Train loss 1.39 on epoch=14
06/25/2022 02:43:55 - INFO - __main__ - Step 220 Global step 220 Train loss 1.43 on epoch=15
06/25/2022 02:43:57 - INFO - __main__ - Step 230 Global step 230 Train loss 1.26 on epoch=16
06/25/2022 02:44:00 - INFO - __main__ - Step 240 Global step 240 Train loss 1.17 on epoch=17
06/25/2022 02:44:03 - INFO - __main__ - Step 250 Global step 250 Train loss 1.22 on epoch=17
06/25/2022 02:44:09 - INFO - __main__ - Global step 250 Train loss 1.29 Classification-F1 0.1333882137245196 on epoch=17
06/25/2022 02:44:09 - INFO - __main__ - Saving model with best Classification-F1: 0.10552335827508873 -> 0.1333882137245196 on epoch=17, global_step=250
06/25/2022 02:44:11 - INFO - __main__ - Step 260 Global step 260 Train loss 1.14 on epoch=18
06/25/2022 02:44:14 - INFO - __main__ - Step 270 Global step 270 Train loss 1.16 on epoch=19
06/25/2022 02:44:17 - INFO - __main__ - Step 280 Global step 280 Train loss 1.01 on epoch=19
06/25/2022 02:44:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.97 on epoch=20
06/25/2022 02:44:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.94 on epoch=21
06/25/2022 02:44:29 - INFO - __main__ - Global step 300 Train loss 1.04 Classification-F1 0.2302214226057385 on epoch=21
06/25/2022 02:44:29 - INFO - __main__ - Saving model with best Classification-F1: 0.1333882137245196 -> 0.2302214226057385 on epoch=21, global_step=300
06/25/2022 02:44:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.95 on epoch=22
06/25/2022 02:44:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.88 on epoch=22
06/25/2022 02:44:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.68 on epoch=23
06/25/2022 02:44:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.83 on epoch=24
06/25/2022 02:44:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=24
06/25/2022 02:44:50 - INFO - __main__ - Global step 350 Train loss 0.82 Classification-F1 0.3097109843280016 on epoch=24
06/25/2022 02:44:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2302214226057385 -> 0.3097109843280016 on epoch=24, global_step=350
06/25/2022 02:44:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=25
06/25/2022 02:44:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.79 on epoch=26
06/25/2022 02:44:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=27
06/25/2022 02:45:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=27
06/25/2022 02:45:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.59 on epoch=28
06/25/2022 02:45:11 - INFO - __main__ - Global step 400 Train loss 0.65 Classification-F1 0.38888109897401957 on epoch=28
06/25/2022 02:45:11 - INFO - __main__ - Saving model with best Classification-F1: 0.3097109843280016 -> 0.38888109897401957 on epoch=28, global_step=400
06/25/2022 02:45:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.54 on epoch=29
06/25/2022 02:45:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=29
06/25/2022 02:45:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=30
06/25/2022 02:45:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=31
06/25/2022 02:45:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.54 on epoch=32
06/25/2022 02:45:31 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.4617042115109442 on epoch=32
06/25/2022 02:45:31 - INFO - __main__ - Saving model with best Classification-F1: 0.38888109897401957 -> 0.4617042115109442 on epoch=32, global_step=450
06/25/2022 02:45:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/25/2022 02:45:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=33
06/25/2022 02:45:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=34
06/25/2022 02:45:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=34
06/25/2022 02:45:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=35
06/25/2022 02:45:52 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.4822102466196394 on epoch=35
06/25/2022 02:45:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4617042115109442 -> 0.4822102466196394 on epoch=35, global_step=500
06/25/2022 02:45:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=36
06/25/2022 02:45:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=37
06/25/2022 02:46:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.45 on epoch=37
06/25/2022 02:46:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
06/25/2022 02:46:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=39
06/25/2022 02:46:13 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.4677805162589758 on epoch=39
06/25/2022 02:46:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
06/25/2022 02:46:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
06/25/2022 02:46:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=41
06/25/2022 02:46:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=42
06/25/2022 02:46:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=42
06/25/2022 02:46:34 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.575901558526192 on epoch=42
06/25/2022 02:46:34 - INFO - __main__ - Saving model with best Classification-F1: 0.4822102466196394 -> 0.575901558526192 on epoch=42, global_step=600
06/25/2022 02:46:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=43
06/25/2022 02:46:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=44
06/25/2022 02:46:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=44
06/25/2022 02:46:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
06/25/2022 02:46:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
06/25/2022 02:46:55 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.546746789484424 on epoch=46
06/25/2022 02:46:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=47
06/25/2022 02:47:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
06/25/2022 02:47:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=48
06/25/2022 02:47:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
06/25/2022 02:47:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=49
06/25/2022 02:47:16 - INFO - __main__ - Global step 700 Train loss 0.32 Classification-F1 0.521788795077062 on epoch=49
06/25/2022 02:47:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=50
06/25/2022 02:47:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=51
06/25/2022 02:47:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=52
06/25/2022 02:47:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=52
06/25/2022 02:47:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/25/2022 02:47:37 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.5990106907508015 on epoch=53
06/25/2022 02:47:37 - INFO - __main__ - Saving model with best Classification-F1: 0.575901558526192 -> 0.5990106907508015 on epoch=53, global_step=750
06/25/2022 02:47:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
06/25/2022 02:47:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=54
06/25/2022 02:47:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=55
06/25/2022 02:47:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
06/25/2022 02:47:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=57
06/25/2022 02:47:57 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.5919654484114415 on epoch=57
06/25/2022 02:48:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=57
06/25/2022 02:48:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/25/2022 02:48:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=59
06/25/2022 02:48:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=59
06/25/2022 02:48:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
06/25/2022 02:48:18 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.5712315412850173 on epoch=60
06/25/2022 02:48:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/25/2022 02:48:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=62
06/25/2022 02:48:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/25/2022 02:48:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=63
06/25/2022 02:48:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=64
06/25/2022 02:48:38 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.601126063141567 on epoch=64
06/25/2022 02:48:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5990106907508015 -> 0.601126063141567 on epoch=64, global_step=900
06/25/2022 02:48:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
06/25/2022 02:48:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
06/25/2022 02:48:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=66
06/25/2022 02:48:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=67
06/25/2022 02:48:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=67
06/25/2022 02:48:58 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.6517901336413132 on epoch=67
06/25/2022 02:48:58 - INFO - __main__ - Saving model with best Classification-F1: 0.601126063141567 -> 0.6517901336413132 on epoch=67, global_step=950
06/25/2022 02:49:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
06/25/2022 02:49:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
06/25/2022 02:49:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=69
06/25/2022 02:49:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/25/2022 02:49:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/25/2022 02:49:19 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.6223901968748423 on epoch=71
06/25/2022 02:49:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=72
06/25/2022 02:49:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/25/2022 02:49:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=73
06/25/2022 02:49:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=74
06/25/2022 02:49:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/25/2022 02:49:39 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.6536454773296879 on epoch=74
06/25/2022 02:49:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6517901336413132 -> 0.6536454773296879 on epoch=74, global_step=1050
06/25/2022 02:49:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
06/25/2022 02:49:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
06/25/2022 02:49:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=77
06/25/2022 02:49:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
06/25/2022 02:49:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/25/2022 02:49:58 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.6933550059986842 on epoch=78
06/25/2022 02:49:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6536454773296879 -> 0.6933550059986842 on epoch=78, global_step=1100
06/25/2022 02:50:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.24 on epoch=79
06/25/2022 02:50:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=79
06/25/2022 02:50:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=80
06/25/2022 02:50:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=81
06/25/2022 02:50:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=82
06/25/2022 02:50:18 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.6583266703048917 on epoch=82
06/25/2022 02:50:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=82
06/25/2022 02:50:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=83
06/25/2022 02:50:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
06/25/2022 02:50:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=84
06/25/2022 02:50:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/25/2022 02:50:38 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.6909250213981569 on epoch=85
06/25/2022 02:50:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=86
06/25/2022 02:50:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/25/2022 02:50:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/25/2022 02:50:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/25/2022 02:50:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/25/2022 02:50:58 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7346456450918925 on epoch=89
06/25/2022 02:50:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6933550059986842 -> 0.7346456450918925 on epoch=89, global_step=1250
06/25/2022 02:51:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=89
06/25/2022 02:51:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/25/2022 02:51:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/25/2022 02:51:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=92
06/25/2022 02:51:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=92
06/25/2022 02:51:17 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.6961768754872204 on epoch=92
06/25/2022 02:51:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=93
06/25/2022 02:51:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/25/2022 02:51:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
06/25/2022 02:51:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
06/25/2022 02:51:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=96
06/25/2022 02:51:37 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.7371284563982333 on epoch=96
06/25/2022 02:51:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7346456450918925 -> 0.7371284563982333 on epoch=96, global_step=1350
06/25/2022 02:51:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/25/2022 02:51:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/25/2022 02:51:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/25/2022 02:51:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=99
06/25/2022 02:51:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/25/2022 02:51:56 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.6938319981423429 on epoch=99
06/25/2022 02:51:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
06/25/2022 02:52:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/25/2022 02:52:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/25/2022 02:52:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/25/2022 02:52:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=103
06/25/2022 02:52:16 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6323048354798114 on epoch=103
06/25/2022 02:52:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=104
06/25/2022 02:52:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
06/25/2022 02:52:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=105
06/25/2022 02:52:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/25/2022 02:52:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
06/25/2022 02:52:36 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7346456450918925 on epoch=107
06/25/2022 02:52:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/25/2022 02:52:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
06/25/2022 02:52:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
06/25/2022 02:52:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/25/2022 02:52:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/25/2022 02:52:56 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.7321917865021313 on epoch=110
06/25/2022 02:52:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/25/2022 02:53:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
06/25/2022 02:53:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/25/2022 02:53:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/25/2022 02:53:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/25/2022 02:53:16 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7308823884536029 on epoch=114
06/25/2022 02:53:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=114
06/25/2022 02:53:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
06/25/2022 02:53:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=116
06/25/2022 02:53:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/25/2022 02:53:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/25/2022 02:53:35 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7632996632996633 on epoch=117
06/25/2022 02:53:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7371284563982333 -> 0.7632996632996633 on epoch=117, global_step=1650
06/25/2022 02:53:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
06/25/2022 02:53:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/25/2022 02:53:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
06/25/2022 02:53:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/25/2022 02:53:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/25/2022 02:53:55 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8589725378787878 on epoch=121
06/25/2022 02:53:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7632996632996633 -> 0.8589725378787878 on epoch=121, global_step=1700
06/25/2022 02:53:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/25/2022 02:54:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/25/2022 02:54:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/25/2022 02:54:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/25/2022 02:54:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/25/2022 02:54:15 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7986542431835356 on epoch=124
06/25/2022 02:54:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
06/25/2022 02:54:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/25/2022 02:54:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/25/2022 02:54:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/25/2022 02:54:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=128
06/25/2022 02:54:35 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7884371865396533 on epoch=128
06/25/2022 02:54:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=129
06/25/2022 02:54:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/25/2022 02:54:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/25/2022 02:54:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/25/2022 02:54:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
06/25/2022 02:54:55 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.804264988430401 on epoch=132
06/25/2022 02:54:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/25/2022 02:55:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
06/25/2022 02:55:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/25/2022 02:55:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/25/2022 02:55:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=135
06/25/2022 02:55:15 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.8100876840775749 on epoch=135
06/25/2022 02:55:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=136
06/25/2022 02:55:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/25/2022 02:55:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/25/2022 02:55:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/25/2022 02:55:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/25/2022 02:55:35 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.802380541659479 on epoch=139
06/25/2022 02:55:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
06/25/2022 02:55:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/25/2022 02:55:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/25/2022 02:55:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
06/25/2022 02:55:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/25/2022 02:55:54 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7982099845477455 on epoch=142
06/25/2022 02:55:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/25/2022 02:55:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
06/25/2022 02:56:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/25/2022 02:56:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/25/2022 02:56:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/25/2022 02:56:14 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8102351791156345 on epoch=146
06/25/2022 02:56:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
06/25/2022 02:56:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/25/2022 02:56:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/25/2022 02:56:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/25/2022 02:56:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/25/2022 02:56:34 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7530551823655272 on epoch=149
06/25/2022 02:56:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/25/2022 02:56:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/25/2022 02:56:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/25/2022 02:56:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/25/2022 02:56:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/25/2022 02:56:54 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.759066859066859 on epoch=153
06/25/2022 02:56:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/25/2022 02:56:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/25/2022 02:57:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/25/2022 02:57:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/25/2022 02:57:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/25/2022 02:57:14 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.759834908222005 on epoch=157
06/25/2022 02:57:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/25/2022 02:57:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/25/2022 02:57:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/25/2022 02:57:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/25/2022 02:57:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/25/2022 02:57:33 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7633105246008471 on epoch=160
06/25/2022 02:57:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/25/2022 02:57:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/25/2022 02:57:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/25/2022 02:57:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/25/2022 02:57:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/25/2022 02:57:53 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.859103128054741 on epoch=164
06/25/2022 02:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8589725378787878 -> 0.859103128054741 on epoch=164, global_step=2300
06/25/2022 02:57:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=164
06/25/2022 02:57:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=165
06/25/2022 02:58:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/25/2022 02:58:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/25/2022 02:58:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/25/2022 02:58:13 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.9226979472140762 on epoch=167
06/25/2022 02:58:13 - INFO - __main__ - Saving model with best Classification-F1: 0.859103128054741 -> 0.9226979472140762 on epoch=167, global_step=2350
06/25/2022 02:58:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/25/2022 02:58:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/25/2022 02:58:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/25/2022 02:58:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/25/2022 02:58:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/25/2022 02:58:33 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.763419137612686 on epoch=171
06/25/2022 02:58:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/25/2022 02:58:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/25/2022 02:58:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/25/2022 02:58:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/25/2022 02:58:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/25/2022 02:58:53 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9183838383838382 on epoch=174
06/25/2022 02:58:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/25/2022 02:58:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=176
06/25/2022 02:59:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/25/2022 02:59:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/25/2022 02:59:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=178
06/25/2022 02:59:13 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8589687194525903 on epoch=178
06/25/2022 02:59:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/25/2022 02:59:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/25/2022 02:59:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/25/2022 02:59:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/25/2022 02:59:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=182
06/25/2022 02:59:32 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.9183838383838382 on epoch=182
06/25/2022 02:59:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/25/2022 02:59:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/25/2022 02:59:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=184
06/25/2022 02:59:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/25/2022 02:59:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/25/2022 02:59:52 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7174284685320339 on epoch=185
06/25/2022 02:59:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/25/2022 02:59:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/25/2022 03:00:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/25/2022 03:00:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/25/2022 03:00:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/25/2022 03:00:12 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8103537749410615 on epoch=189
06/25/2022 03:00:14 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/25/2022 03:00:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/25/2022 03:00:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/25/2022 03:00:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/25/2022 03:00:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/25/2022 03:00:32 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8008510148927606 on epoch=192
06/25/2022 03:00:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/25/2022 03:00:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/25/2022 03:00:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/25/2022 03:00:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/25/2022 03:00:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/25/2022 03:00:52 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8083376459088034 on epoch=196
06/25/2022 03:00:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/25/2022 03:00:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/25/2022 03:00:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/25/2022 03:01:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/25/2022 03:01:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/25/2022 03:01:11 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7670142283045508 on epoch=199
06/25/2022 03:01:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/25/2022 03:01:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/25/2022 03:01:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/25/2022 03:01:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=202
06/25/2022 03:01:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/25/2022 03:01:31 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7248340793332305 on epoch=203
06/25/2022 03:01:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=204
06/25/2022 03:01:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/25/2022 03:01:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/25/2022 03:01:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/25/2022 03:01:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/25/2022 03:01:51 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8141567477430854 on epoch=207
06/25/2022 03:01:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/25/2022 03:01:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/25/2022 03:01:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/25/2022 03:02:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/25/2022 03:02:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/25/2022 03:02:11 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7670142283045508 on epoch=210
06/25/2022 03:02:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/25/2022 03:02:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/25/2022 03:02:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/25/2022 03:02:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/25/2022 03:02:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/25/2022 03:02:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:02:25 - INFO - __main__ - Printing 3 examples
06/25/2022 03:02:25 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 03:02:25 - INFO - __main__ - ['Company']
06/25/2022 03:02:25 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 03:02:25 - INFO - __main__ - ['Company']
06/25/2022 03:02:25 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 03:02:25 - INFO - __main__ - ['Company']
06/25/2022 03:02:25 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:02:26 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:02:26 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 03:02:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:02:26 - INFO - __main__ - Printing 3 examples
06/25/2022 03:02:26 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 03:02:26 - INFO - __main__ - ['Company']
06/25/2022 03:02:26 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 03:02:26 - INFO - __main__ - ['Company']
06/25/2022 03:02:26 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 03:02:26 - INFO - __main__ - ['Company']
06/25/2022 03:02:26 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:02:26 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:02:26 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 03:02:31 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8670576735092864 on epoch=214
06/25/2022 03:02:31 - INFO - __main__ - save last model!
06/25/2022 03:02:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 03:02:31 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 03:02:31 - INFO - __main__ - Printing 3 examples
06/25/2022 03:02:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 03:02:31 - INFO - __main__ - ['Animal']
06/25/2022 03:02:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 03:02:31 - INFO - __main__ - ['Animal']
06/25/2022 03:02:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 03:02:31 - INFO - __main__ - ['Village']
06/25/2022 03:02:31 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:02:33 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:02:37 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 03:02:45 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 03:02:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 03:02:46 - INFO - __main__ - Starting training!
06/25/2022 03:04:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/25/2022 03:04:49 - INFO - __main__ - Classification-F1 on test data: 0.4549
06/25/2022 03:04:50 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9226979472140762, test_performance=0.45492206569399385
06/25/2022 03:04:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/25/2022 03:04:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:04:55 - INFO - __main__ - Printing 3 examples
06/25/2022 03:04:55 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/25/2022 03:04:55 - INFO - __main__ - ['Company']
06/25/2022 03:04:55 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/25/2022 03:04:55 - INFO - __main__ - ['Company']
06/25/2022 03:04:55 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/25/2022 03:04:55 - INFO - __main__ - ['Company']
06/25/2022 03:04:55 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:04:55 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:04:55 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 03:04:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:04:55 - INFO - __main__ - Printing 3 examples
06/25/2022 03:04:55 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/25/2022 03:04:55 - INFO - __main__ - ['Company']
06/25/2022 03:04:55 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/25/2022 03:04:55 - INFO - __main__ - ['Company']
06/25/2022 03:04:55 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/25/2022 03:04:55 - INFO - __main__ - ['Company']
06/25/2022 03:04:55 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:04:55 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:04:55 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 03:05:13 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 03:05:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 03:05:14 - INFO - __main__ - Starting training!
06/25/2022 03:05:18 - INFO - __main__ - Step 10 Global step 10 Train loss 7.36 on epoch=0
06/25/2022 03:05:20 - INFO - __main__ - Step 20 Global step 20 Train loss 6.36 on epoch=1
06/25/2022 03:05:23 - INFO - __main__ - Step 30 Global step 30 Train loss 5.35 on epoch=2
06/25/2022 03:05:25 - INFO - __main__ - Step 40 Global step 40 Train loss 4.75 on epoch=2
06/25/2022 03:05:28 - INFO - __main__ - Step 50 Global step 50 Train loss 4.49 on epoch=3
06/25/2022 03:05:34 - INFO - __main__ - Global step 50 Train loss 5.66 Classification-F1 0.03864833107079454 on epoch=3
06/25/2022 03:05:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03864833107079454 on epoch=3, global_step=50
06/25/2022 03:05:36 - INFO - __main__ - Step 60 Global step 60 Train loss 4.28 on epoch=4
06/25/2022 03:05:39 - INFO - __main__ - Step 70 Global step 70 Train loss 4.03 on epoch=4
06/25/2022 03:05:41 - INFO - __main__ - Step 80 Global step 80 Train loss 3.89 on epoch=5
06/25/2022 03:05:44 - INFO - __main__ - Step 90 Global step 90 Train loss 3.59 on epoch=6
06/25/2022 03:05:46 - INFO - __main__ - Step 100 Global step 100 Train loss 3.50 on epoch=7
06/25/2022 03:05:52 - INFO - __main__ - Global step 100 Train loss 3.86 Classification-F1 0.047967765361819764 on epoch=7
06/25/2022 03:05:52 - INFO - __main__ - Saving model with best Classification-F1: 0.03864833107079454 -> 0.047967765361819764 on epoch=7, global_step=100
06/25/2022 03:05:55 - INFO - __main__ - Step 110 Global step 110 Train loss 3.25 on epoch=7
06/25/2022 03:05:57 - INFO - __main__ - Step 120 Global step 120 Train loss 3.17 on epoch=8
06/25/2022 03:06:00 - INFO - __main__ - Step 130 Global step 130 Train loss 3.03 on epoch=9
06/25/2022 03:06:02 - INFO - __main__ - Step 140 Global step 140 Train loss 2.89 on epoch=9
06/25/2022 03:06:05 - INFO - __main__ - Step 150 Global step 150 Train loss 2.79 on epoch=10
06/25/2022 03:06:10 - INFO - __main__ - Global step 150 Train loss 3.03 Classification-F1 0.06347660783930671 on epoch=10
06/25/2022 03:06:10 - INFO - __main__ - Saving model with best Classification-F1: 0.047967765361819764 -> 0.06347660783930671 on epoch=10, global_step=150
06/25/2022 03:06:13 - INFO - __main__ - Step 160 Global step 160 Train loss 2.60 on epoch=11
06/25/2022 03:06:15 - INFO - __main__ - Step 170 Global step 170 Train loss 2.65 on epoch=12
06/25/2022 03:06:18 - INFO - __main__ - Step 180 Global step 180 Train loss 2.52 on epoch=12
06/25/2022 03:06:21 - INFO - __main__ - Step 190 Global step 190 Train loss 2.28 on epoch=13
06/25/2022 03:06:23 - INFO - __main__ - Step 200 Global step 200 Train loss 2.26 on epoch=14
06/25/2022 03:06:29 - INFO - __main__ - Global step 200 Train loss 2.46 Classification-F1 0.07331944631147976 on epoch=14
06/25/2022 03:06:29 - INFO - __main__ - Saving model with best Classification-F1: 0.06347660783930671 -> 0.07331944631147976 on epoch=14, global_step=200
06/25/2022 03:06:32 - INFO - __main__ - Step 210 Global step 210 Train loss 2.32 on epoch=14
06/25/2022 03:06:34 - INFO - __main__ - Step 220 Global step 220 Train loss 2.15 on epoch=15
06/25/2022 03:06:37 - INFO - __main__ - Step 230 Global step 230 Train loss 2.05 on epoch=16
06/25/2022 03:06:40 - INFO - __main__ - Step 240 Global step 240 Train loss 1.95 on epoch=17
06/25/2022 03:06:42 - INFO - __main__ - Step 250 Global step 250 Train loss 2.02 on epoch=17
06/25/2022 03:06:48 - INFO - __main__ - Global step 250 Train loss 2.10 Classification-F1 0.09125556718119883 on epoch=17
06/25/2022 03:06:48 - INFO - __main__ - Saving model with best Classification-F1: 0.07331944631147976 -> 0.09125556718119883 on epoch=17, global_step=250
06/25/2022 03:06:51 - INFO - __main__ - Step 260 Global step 260 Train loss 1.77 on epoch=18
06/25/2022 03:06:54 - INFO - __main__ - Step 270 Global step 270 Train loss 1.71 on epoch=19
06/25/2022 03:06:56 - INFO - __main__ - Step 280 Global step 280 Train loss 1.63 on epoch=19
06/25/2022 03:06:59 - INFO - __main__ - Step 290 Global step 290 Train loss 1.71 on epoch=20
06/25/2022 03:07:01 - INFO - __main__ - Step 300 Global step 300 Train loss 1.54 on epoch=21
06/25/2022 03:07:07 - INFO - __main__ - Global step 300 Train loss 1.67 Classification-F1 0.1094940278503562 on epoch=21
06/25/2022 03:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.09125556718119883 -> 0.1094940278503562 on epoch=21, global_step=300
06/25/2022 03:07:10 - INFO - __main__ - Step 310 Global step 310 Train loss 1.51 on epoch=22
06/25/2022 03:07:12 - INFO - __main__ - Step 320 Global step 320 Train loss 1.46 on epoch=22
06/25/2022 03:07:15 - INFO - __main__ - Step 330 Global step 330 Train loss 1.47 on epoch=23
06/25/2022 03:07:18 - INFO - __main__ - Step 340 Global step 340 Train loss 1.47 on epoch=24
06/25/2022 03:07:20 - INFO - __main__ - Step 350 Global step 350 Train loss 1.30 on epoch=24
06/25/2022 03:07:26 - INFO - __main__ - Global step 350 Train loss 1.44 Classification-F1 0.12384760317498661 on epoch=24
06/25/2022 03:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1094940278503562 -> 0.12384760317498661 on epoch=24, global_step=350
06/25/2022 03:07:29 - INFO - __main__ - Step 360 Global step 360 Train loss 1.21 on epoch=25
06/25/2022 03:07:32 - INFO - __main__ - Step 370 Global step 370 Train loss 1.24 on epoch=26
06/25/2022 03:07:34 - INFO - __main__ - Step 380 Global step 380 Train loss 1.10 on epoch=27
06/25/2022 03:07:37 - INFO - __main__ - Step 390 Global step 390 Train loss 1.17 on epoch=27
06/25/2022 03:07:40 - INFO - __main__ - Step 400 Global step 400 Train loss 1.18 on epoch=28
06/25/2022 03:07:46 - INFO - __main__ - Global step 400 Train loss 1.18 Classification-F1 0.1933224292289921 on epoch=28
06/25/2022 03:07:46 - INFO - __main__ - Saving model with best Classification-F1: 0.12384760317498661 -> 0.1933224292289921 on epoch=28, global_step=400
06/25/2022 03:07:48 - INFO - __main__ - Step 410 Global step 410 Train loss 1.13 on epoch=29
06/25/2022 03:07:51 - INFO - __main__ - Step 420 Global step 420 Train loss 1.06 on epoch=29
06/25/2022 03:07:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.97 on epoch=30
06/25/2022 03:07:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.99 on epoch=31
06/25/2022 03:07:59 - INFO - __main__ - Step 450 Global step 450 Train loss 1.06 on epoch=32
06/25/2022 03:08:05 - INFO - __main__ - Global step 450 Train loss 1.04 Classification-F1 0.23404604451158703 on epoch=32
06/25/2022 03:08:05 - INFO - __main__ - Saving model with best Classification-F1: 0.1933224292289921 -> 0.23404604451158703 on epoch=32, global_step=450
06/25/2022 03:08:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.92 on epoch=32
06/25/2022 03:08:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.89 on epoch=33
06/25/2022 03:08:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.81 on epoch=34
06/25/2022 03:08:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.77 on epoch=34
06/25/2022 03:08:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.77 on epoch=35
06/25/2022 03:08:25 - INFO - __main__ - Global step 500 Train loss 0.83 Classification-F1 0.2974564921593789 on epoch=35
06/25/2022 03:08:25 - INFO - __main__ - Saving model with best Classification-F1: 0.23404604451158703 -> 0.2974564921593789 on epoch=35, global_step=500
06/25/2022 03:08:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.76 on epoch=36
06/25/2022 03:08:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.71 on epoch=37
06/25/2022 03:08:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.61 on epoch=37
06/25/2022 03:08:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.73 on epoch=38
06/25/2022 03:08:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.70 on epoch=39
06/25/2022 03:08:45 - INFO - __main__ - Global step 550 Train loss 0.70 Classification-F1 0.35390368668572914 on epoch=39
06/25/2022 03:08:45 - INFO - __main__ - Saving model with best Classification-F1: 0.2974564921593789 -> 0.35390368668572914 on epoch=39, global_step=550
06/25/2022 03:08:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.58 on epoch=39
06/25/2022 03:08:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.66 on epoch=40
06/25/2022 03:08:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=41
06/25/2022 03:08:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.66 on epoch=42
06/25/2022 03:08:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.53 on epoch=42
06/25/2022 03:09:05 - INFO - __main__ - Global step 600 Train loss 0.60 Classification-F1 0.38146054176384103 on epoch=42
06/25/2022 03:09:05 - INFO - __main__ - Saving model with best Classification-F1: 0.35390368668572914 -> 0.38146054176384103 on epoch=42, global_step=600
06/25/2022 03:09:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.57 on epoch=43
06/25/2022 03:09:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.57 on epoch=44
06/25/2022 03:09:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=44
06/25/2022 03:09:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.46 on epoch=45
06/25/2022 03:09:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.48 on epoch=46
06/25/2022 03:09:25 - INFO - __main__ - Global step 650 Train loss 0.52 Classification-F1 0.3849938417150719 on epoch=46
06/25/2022 03:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.38146054176384103 -> 0.3849938417150719 on epoch=46, global_step=650
06/25/2022 03:09:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=47
06/25/2022 03:09:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.57 on epoch=47
06/25/2022 03:09:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.47 on epoch=48
06/25/2022 03:09:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.57 on epoch=49
06/25/2022 03:09:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=49
06/25/2022 03:09:45 - INFO - __main__ - Global step 700 Train loss 0.52 Classification-F1 0.4002482162875734 on epoch=49
06/25/2022 03:09:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3849938417150719 -> 0.4002482162875734 on epoch=49, global_step=700
06/25/2022 03:09:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.48 on epoch=50
06/25/2022 03:09:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.44 on epoch=51
06/25/2022 03:09:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.51 on epoch=52
06/25/2022 03:09:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.50 on epoch=52
06/25/2022 03:09:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/25/2022 03:10:05 - INFO - __main__ - Global step 750 Train loss 0.47 Classification-F1 0.4519766948113801 on epoch=53
06/25/2022 03:10:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4002482162875734 -> 0.4519766948113801 on epoch=53, global_step=750
06/25/2022 03:10:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.51 on epoch=54
06/25/2022 03:10:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=54
06/25/2022 03:10:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.43 on epoch=55
06/25/2022 03:10:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=56
06/25/2022 03:10:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.43 on epoch=57
06/25/2022 03:10:25 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.4587951986149145 on epoch=57
06/25/2022 03:10:25 - INFO - __main__ - Saving model with best Classification-F1: 0.4519766948113801 -> 0.4587951986149145 on epoch=57, global_step=800
06/25/2022 03:10:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.50 on epoch=57
06/25/2022 03:10:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.39 on epoch=58
06/25/2022 03:10:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=59
06/25/2022 03:10:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.45 on epoch=59
06/25/2022 03:10:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.40 on epoch=60
06/25/2022 03:10:45 - INFO - __main__ - Global step 850 Train loss 0.42 Classification-F1 0.4760835648881189 on epoch=60
06/25/2022 03:10:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4587951986149145 -> 0.4760835648881189 on epoch=60, global_step=850
06/25/2022 03:10:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.45 on epoch=61
06/25/2022 03:10:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.37 on epoch=62
06/25/2022 03:10:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=62
06/25/2022 03:10:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.40 on epoch=63
06/25/2022 03:10:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.36 on epoch=64
06/25/2022 03:11:06 - INFO - __main__ - Global step 900 Train loss 0.39 Classification-F1 0.5265833569755138 on epoch=64
06/25/2022 03:11:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4760835648881189 -> 0.5265833569755138 on epoch=64, global_step=900
06/25/2022 03:11:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.49 on epoch=64
06/25/2022 03:11:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.38 on epoch=65
06/25/2022 03:11:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.33 on epoch=66
06/25/2022 03:11:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=67
06/25/2022 03:11:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.36 on epoch=67
06/25/2022 03:11:26 - INFO - __main__ - Global step 950 Train loss 0.37 Classification-F1 0.5136151468298844 on epoch=67
06/25/2022 03:11:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=68
06/25/2022 03:11:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=69
06/25/2022 03:11:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.42 on epoch=69
06/25/2022 03:11:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.40 on epoch=70
06/25/2022 03:11:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=71
06/25/2022 03:11:46 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.5990106907508015 on epoch=71
06/25/2022 03:11:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5265833569755138 -> 0.5990106907508015 on epoch=71, global_step=1000
06/25/2022 03:11:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=72
06/25/2022 03:11:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=72
06/25/2022 03:11:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/25/2022 03:11:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.32 on epoch=74
06/25/2022 03:11:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=74
06/25/2022 03:12:06 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.6318463027844368 on epoch=74
06/25/2022 03:12:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5990106907508015 -> 0.6318463027844368 on epoch=74, global_step=1050
06/25/2022 03:12:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.37 on epoch=75
06/25/2022 03:12:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.33 on epoch=76
06/25/2022 03:12:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.36 on epoch=77
06/25/2022 03:12:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.36 on epoch=77
06/25/2022 03:12:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.34 on epoch=78
06/25/2022 03:12:27 - INFO - __main__ - Global step 1100 Train loss 0.35 Classification-F1 0.5485542590401925 on epoch=78
06/25/2022 03:12:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=79
06/25/2022 03:12:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.27 on epoch=79
06/25/2022 03:12:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=80
06/25/2022 03:12:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=81
06/25/2022 03:12:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.31 on epoch=82
06/25/2022 03:12:47 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.6309316686380952 on epoch=82
06/25/2022 03:12:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.30 on epoch=82
06/25/2022 03:12:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/25/2022 03:12:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.29 on epoch=84
06/25/2022 03:12:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.29 on epoch=84
06/25/2022 03:13:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=85
06/25/2022 03:13:08 - INFO - __main__ - Global step 1200 Train loss 0.28 Classification-F1 0.6241782355575459 on epoch=85
06/25/2022 03:13:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=86
06/25/2022 03:13:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=87
06/25/2022 03:13:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.27 on epoch=87
06/25/2022 03:13:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.26 on epoch=88
06/25/2022 03:13:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=89
06/25/2022 03:13:28 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.5580492733810811 on epoch=89
06/25/2022 03:13:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.28 on epoch=89
06/25/2022 03:13:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=90
06/25/2022 03:13:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=91
06/25/2022 03:13:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.27 on epoch=92
06/25/2022 03:13:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=92
06/25/2022 03:13:48 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.5235365418894831 on epoch=92
06/25/2022 03:13:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
06/25/2022 03:13:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=94
06/25/2022 03:13:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=94
06/25/2022 03:13:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=95
06/25/2022 03:14:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.21 on epoch=96
06/25/2022 03:14:09 - INFO - __main__ - Global step 1350 Train loss 0.22 Classification-F1 0.6303311512692852 on epoch=96
06/25/2022 03:14:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=97
06/25/2022 03:14:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.29 on epoch=97
06/25/2022 03:14:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=98
06/25/2022 03:14:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.23 on epoch=99
06/25/2022 03:14:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=99
06/25/2022 03:14:29 - INFO - __main__ - Global step 1400 Train loss 0.22 Classification-F1 0.5690581362211456 on epoch=99
06/25/2022 03:14:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=100
06/25/2022 03:14:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=101
06/25/2022 03:14:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=102
06/25/2022 03:14:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.23 on epoch=102
06/25/2022 03:14:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=103
06/25/2022 03:14:50 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.5735742442164502 on epoch=103
06/25/2022 03:14:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=104
06/25/2022 03:14:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.21 on epoch=104
06/25/2022 03:14:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.20 on epoch=105
06/25/2022 03:15:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/25/2022 03:15:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=107
06/25/2022 03:15:10 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.6062109027626269 on epoch=107
06/25/2022 03:15:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/25/2022 03:15:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.19 on epoch=108
06/25/2022 03:15:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
06/25/2022 03:15:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.21 on epoch=109
06/25/2022 03:15:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=110
06/25/2022 03:15:30 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.5438350754692584 on epoch=110
06/25/2022 03:15:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=111
06/25/2022 03:15:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=112
06/25/2022 03:15:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/25/2022 03:15:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=113
06/25/2022 03:15:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
06/25/2022 03:15:51 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.5489501649833248 on epoch=114
06/25/2022 03:15:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/25/2022 03:15:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=115
06/25/2022 03:15:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.20 on epoch=116
06/25/2022 03:16:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=117
06/25/2022 03:16:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.20 on epoch=117
06/25/2022 03:16:11 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.6346452752928784 on epoch=117
06/25/2022 03:16:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6318463027844368 -> 0.6346452752928784 on epoch=117, global_step=1650
06/25/2022 03:16:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/25/2022 03:16:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.20 on epoch=119
06/25/2022 03:16:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/25/2022 03:16:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=120
06/25/2022 03:16:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=121
06/25/2022 03:16:31 - INFO - __main__ - Global step 1700 Train loss 0.16 Classification-F1 0.5994443020218512 on epoch=121
06/25/2022 03:16:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=122
06/25/2022 03:16:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/25/2022 03:16:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=123
06/25/2022 03:16:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/25/2022 03:16:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.17 on epoch=124
06/25/2022 03:16:52 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.5735742442164503 on epoch=124
06/25/2022 03:16:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=125
06/25/2022 03:16:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.20 on epoch=126
06/25/2022 03:17:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/25/2022 03:17:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.19 on epoch=127
06/25/2022 03:17:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=128
06/25/2022 03:17:12 - INFO - __main__ - Global step 1800 Train loss 0.16 Classification-F1 0.6621997049866556 on epoch=128
06/25/2022 03:17:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6346452752928784 -> 0.6621997049866556 on epoch=128, global_step=1800
06/25/2022 03:17:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.16 on epoch=129
06/25/2022 03:17:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.20 on epoch=129
06/25/2022 03:17:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
06/25/2022 03:17:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
06/25/2022 03:17:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=132
06/25/2022 03:17:33 - INFO - __main__ - Global step 1850 Train loss 0.17 Classification-F1 0.6303311512692852 on epoch=132
06/25/2022 03:17:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=132
06/25/2022 03:17:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.15 on epoch=133
06/25/2022 03:17:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
06/25/2022 03:17:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=134
06/25/2022 03:17:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/25/2022 03:17:53 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.6980207106643889 on epoch=135
06/25/2022 03:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6621997049866556 -> 0.6980207106643889 on epoch=135, global_step=1900
06/25/2022 03:17:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=136
06/25/2022 03:17:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=137
06/25/2022 03:18:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/25/2022 03:18:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=138
06/25/2022 03:18:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=139
06/25/2022 03:18:14 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.6761564859186409 on epoch=139
06/25/2022 03:18:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/25/2022 03:18:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.16 on epoch=140
06/25/2022 03:18:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=141
06/25/2022 03:18:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
06/25/2022 03:18:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=142
06/25/2022 03:18:34 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.6419212609559608 on epoch=142
06/25/2022 03:18:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.21 on epoch=143
06/25/2022 03:18:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/25/2022 03:18:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=144
06/25/2022 03:18:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.14 on epoch=145
06/25/2022 03:18:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.15 on epoch=146
06/25/2022 03:18:54 - INFO - __main__ - Global step 2050 Train loss 0.15 Classification-F1 0.6355599094392197 on epoch=146
06/25/2022 03:18:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=147
06/25/2022 03:19:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=147
06/25/2022 03:19:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
06/25/2022 03:19:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=149
06/25/2022 03:19:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=149
06/25/2022 03:19:15 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.6731039982401144 on epoch=149
06/25/2022 03:19:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=150
06/25/2022 03:19:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=151
06/25/2022 03:19:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=152
06/25/2022 03:19:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
06/25/2022 03:19:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/25/2022 03:19:35 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6795433921795082 on epoch=153
06/25/2022 03:19:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=154
06/25/2022 03:19:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.14 on epoch=154
06/25/2022 03:19:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.16 on epoch=155
06/25/2022 03:19:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
06/25/2022 03:19:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/25/2022 03:19:55 - INFO - __main__ - Global step 2200 Train loss 0.13 Classification-F1 0.726195883767098 on epoch=157
06/25/2022 03:19:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6980207106643889 -> 0.726195883767098 on epoch=157, global_step=2200
06/25/2022 03:19:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.12 on epoch=157
06/25/2022 03:20:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/25/2022 03:20:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
06/25/2022 03:20:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
06/25/2022 03:20:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.17 on epoch=160
06/25/2022 03:20:15 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.7308690351793801 on epoch=160
06/25/2022 03:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.726195883767098 -> 0.7308690351793801 on epoch=160, global_step=2250
06/25/2022 03:20:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
06/25/2022 03:20:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/25/2022 03:20:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/25/2022 03:20:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/25/2022 03:20:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.15 on epoch=164
06/25/2022 03:20:36 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.7738613313664023 on epoch=164
06/25/2022 03:20:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7308690351793801 -> 0.7738613313664023 on epoch=164, global_step=2300
06/25/2022 03:20:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=164
06/25/2022 03:20:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=165
06/25/2022 03:20:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/25/2022 03:20:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/25/2022 03:20:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=167
06/25/2022 03:20:56 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.7649607195246141 on epoch=167
06/25/2022 03:20:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=168
06/25/2022 03:21:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
06/25/2022 03:21:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=169
06/25/2022 03:21:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
06/25/2022 03:21:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.22 on epoch=171
06/25/2022 03:21:17 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.7816721480007485 on epoch=171
06/25/2022 03:21:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7738613313664023 -> 0.7816721480007485 on epoch=171, global_step=2400
06/25/2022 03:21:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=172
06/25/2022 03:21:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/25/2022 03:21:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=173
06/25/2022 03:21:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=174
06/25/2022 03:21:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/25/2022 03:21:37 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.7237141530244978 on epoch=174
06/25/2022 03:21:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=175
06/25/2022 03:21:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=176
06/25/2022 03:21:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=177
06/25/2022 03:21:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/25/2022 03:21:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=178
06/25/2022 03:21:57 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7378543630850116 on epoch=178
06/25/2022 03:22:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/25/2022 03:22:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
06/25/2022 03:22:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=180
06/25/2022 03:22:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/25/2022 03:22:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=182
06/25/2022 03:22:17 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.725655020323009 on epoch=182
06/25/2022 03:22:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=182
06/25/2022 03:22:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/25/2022 03:22:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=184
06/25/2022 03:22:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
06/25/2022 03:22:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
06/25/2022 03:22:38 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7351310515381706 on epoch=185
06/25/2022 03:22:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/25/2022 03:22:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=187
06/25/2022 03:22:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/25/2022 03:22:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=188
06/25/2022 03:22:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
06/25/2022 03:22:58 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.7412381883349624 on epoch=189
06/25/2022 03:23:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.12 on epoch=189
06/25/2022 03:23:03 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/25/2022 03:23:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=191
06/25/2022 03:23:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=192
06/25/2022 03:23:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/25/2022 03:23:19 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.8390896549741345 on epoch=192
06/25/2022 03:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7816721480007485 -> 0.8390896549741345 on epoch=192, global_step=2700
06/25/2022 03:23:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=193
06/25/2022 03:23:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/25/2022 03:23:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
06/25/2022 03:23:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=195
06/25/2022 03:23:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=196
06/25/2022 03:23:39 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.7427102032705482 on epoch=196
06/25/2022 03:23:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/25/2022 03:23:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/25/2022 03:23:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=198
06/25/2022 03:23:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/25/2022 03:23:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
06/25/2022 03:23:59 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.8023559550223164 on epoch=199
06/25/2022 03:24:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/25/2022 03:24:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
06/25/2022 03:24:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=202
06/25/2022 03:24:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
06/25/2022 03:24:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=203
06/25/2022 03:24:19 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.7519057838301442 on epoch=203
06/25/2022 03:24:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/25/2022 03:24:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=204
06/25/2022 03:24:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/25/2022 03:24:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=206
06/25/2022 03:24:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/25/2022 03:24:39 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7577806241877432 on epoch=207
06/25/2022 03:24:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/25/2022 03:24:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=208
06/25/2022 03:24:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=209
06/25/2022 03:24:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
06/25/2022 03:24:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=210
06/25/2022 03:24:59 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.7462920875420875 on epoch=210
06/25/2022 03:25:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/25/2022 03:25:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/25/2022 03:25:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=212
06/25/2022 03:25:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/25/2022 03:25:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/25/2022 03:25:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:25:13 - INFO - __main__ - Printing 3 examples
06/25/2022 03:25:13 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 03:25:13 - INFO - __main__ - ['Film']
06/25/2022 03:25:13 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 03:25:13 - INFO - __main__ - ['Film']
06/25/2022 03:25:13 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 03:25:13 - INFO - __main__ - ['Film']
06/25/2022 03:25:13 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:25:14 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:25:14 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 03:25:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:25:14 - INFO - __main__ - Printing 3 examples
06/25/2022 03:25:14 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 03:25:14 - INFO - __main__ - ['Film']
06/25/2022 03:25:14 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 03:25:14 - INFO - __main__ - ['Film']
06/25/2022 03:25:14 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 03:25:14 - INFO - __main__ - ['Film']
06/25/2022 03:25:14 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:25:14 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:25:14 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 03:25:19 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.6998223521543206 on epoch=214
06/25/2022 03:25:19 - INFO - __main__ - save last model!
06/25/2022 03:25:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 03:25:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 03:25:19 - INFO - __main__ - Printing 3 examples
06/25/2022 03:25:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 03:25:19 - INFO - __main__ - ['Animal']
06/25/2022 03:25:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 03:25:19 - INFO - __main__ - ['Animal']
06/25/2022 03:25:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 03:25:19 - INFO - __main__ - ['Village']
06/25/2022 03:25:19 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:25:21 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:25:24 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 03:25:31 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 03:25:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 03:25:32 - INFO - __main__ - Starting training!
06/25/2022 03:27:31 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/25/2022 03:27:31 - INFO - __main__ - Classification-F1 on test data: 0.4342
06/25/2022 03:27:31 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.8390896549741345, test_performance=0.43416443233005203
06/25/2022 03:27:31 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/25/2022 03:27:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:27:32 - INFO - __main__ - Printing 3 examples
06/25/2022 03:27:32 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 03:27:32 - INFO - __main__ - ['Film']
06/25/2022 03:27:32 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 03:27:32 - INFO - __main__ - ['Film']
06/25/2022 03:27:32 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 03:27:32 - INFO - __main__ - ['Film']
06/25/2022 03:27:32 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:27:33 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:27:33 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 03:27:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:27:33 - INFO - __main__ - Printing 3 examples
06/25/2022 03:27:33 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 03:27:33 - INFO - __main__ - ['Film']
06/25/2022 03:27:33 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 03:27:33 - INFO - __main__ - ['Film']
06/25/2022 03:27:33 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 03:27:33 - INFO - __main__ - ['Film']
06/25/2022 03:27:33 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:27:33 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:27:33 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 03:27:52 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 03:27:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 03:27:53 - INFO - __main__ - Starting training!
06/25/2022 03:27:56 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=0
06/25/2022 03:27:59 - INFO - __main__ - Step 20 Global step 20 Train loss 4.75 on epoch=1
06/25/2022 03:28:02 - INFO - __main__ - Step 30 Global step 30 Train loss 4.19 on epoch=2
06/25/2022 03:28:04 - INFO - __main__ - Step 40 Global step 40 Train loss 3.45 on epoch=2
06/25/2022 03:28:07 - INFO - __main__ - Step 50 Global step 50 Train loss 3.42 on epoch=3
06/25/2022 03:28:13 - INFO - __main__ - Global step 50 Train loss 4.55 Classification-F1 0.056532235353866846 on epoch=3
06/25/2022 03:28:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.056532235353866846 on epoch=3, global_step=50
06/25/2022 03:28:16 - INFO - __main__ - Step 60 Global step 60 Train loss 3.07 on epoch=4
06/25/2022 03:28:18 - INFO - __main__ - Step 70 Global step 70 Train loss 2.52 on epoch=4
06/25/2022 03:28:21 - INFO - __main__ - Step 80 Global step 80 Train loss 2.77 on epoch=5
06/25/2022 03:28:23 - INFO - __main__ - Step 90 Global step 90 Train loss 2.23 on epoch=6
06/25/2022 03:28:26 - INFO - __main__ - Step 100 Global step 100 Train loss 2.11 on epoch=7
06/25/2022 03:28:32 - INFO - __main__ - Global step 100 Train loss 2.54 Classification-F1 0.1100615149384969 on epoch=7
06/25/2022 03:28:32 - INFO - __main__ - Saving model with best Classification-F1: 0.056532235353866846 -> 0.1100615149384969 on epoch=7, global_step=100
06/25/2022 03:28:34 - INFO - __main__ - Step 110 Global step 110 Train loss 1.87 on epoch=7
06/25/2022 03:28:37 - INFO - __main__ - Step 120 Global step 120 Train loss 1.98 on epoch=8
06/25/2022 03:28:40 - INFO - __main__ - Step 130 Global step 130 Train loss 1.67 on epoch=9
06/25/2022 03:28:42 - INFO - __main__ - Step 140 Global step 140 Train loss 1.36 on epoch=9
06/25/2022 03:28:45 - INFO - __main__ - Step 150 Global step 150 Train loss 1.52 on epoch=10
06/25/2022 03:28:51 - INFO - __main__ - Global step 150 Train loss 1.68 Classification-F1 0.1433356416896716 on epoch=10
06/25/2022 03:28:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1100615149384969 -> 0.1433356416896716 on epoch=10, global_step=150
06/25/2022 03:28:54 - INFO - __main__ - Step 160 Global step 160 Train loss 1.26 on epoch=11
06/25/2022 03:28:56 - INFO - __main__ - Step 170 Global step 170 Train loss 1.15 on epoch=12
06/25/2022 03:28:59 - INFO - __main__ - Step 180 Global step 180 Train loss 1.00 on epoch=12
06/25/2022 03:29:01 - INFO - __main__ - Step 190 Global step 190 Train loss 1.10 on epoch=13
06/25/2022 03:29:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=14
06/25/2022 03:29:10 - INFO - __main__ - Global step 200 Train loss 1.09 Classification-F1 0.2999043039096233 on epoch=14
06/25/2022 03:29:10 - INFO - __main__ - Saving model with best Classification-F1: 0.1433356416896716 -> 0.2999043039096233 on epoch=14, global_step=200
06/25/2022 03:29:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.81 on epoch=14
06/25/2022 03:29:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=15
06/25/2022 03:29:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.71 on epoch=16
06/25/2022 03:29:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=17
06/25/2022 03:29:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=17
06/25/2022 03:29:31 - INFO - __main__ - Global step 250 Train loss 0.69 Classification-F1 0.5050892487631224 on epoch=17
06/25/2022 03:29:31 - INFO - __main__ - Saving model with best Classification-F1: 0.2999043039096233 -> 0.5050892487631224 on epoch=17, global_step=250
06/25/2022 03:29:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=18
06/25/2022 03:29:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=19
06/25/2022 03:29:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=19
06/25/2022 03:29:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=20
06/25/2022 03:29:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=21
06/25/2022 03:29:51 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.5578351845279076 on epoch=21
06/25/2022 03:29:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5050892487631224 -> 0.5578351845279076 on epoch=21, global_step=300
06/25/2022 03:29:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=22
06/25/2022 03:29:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
06/25/2022 03:29:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=23
06/25/2022 03:30:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
06/25/2022 03:30:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/25/2022 03:30:11 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6991600577738599 on epoch=24
06/25/2022 03:30:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5578351845279076 -> 0.6991600577738599 on epoch=24, global_step=350
06/25/2022 03:30:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
06/25/2022 03:30:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/25/2022 03:30:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
06/25/2022 03:30:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=27
06/25/2022 03:30:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=28
06/25/2022 03:30:32 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.6312089109753182 on epoch=28
06/25/2022 03:30:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
06/25/2022 03:30:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
06/25/2022 03:30:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
06/25/2022 03:30:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=31
06/25/2022 03:30:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
06/25/2022 03:30:53 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.6237678920541825 on epoch=32
06/25/2022 03:30:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
06/25/2022 03:30:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/25/2022 03:31:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
06/25/2022 03:31:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/25/2022 03:31:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=35
06/25/2022 03:31:13 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.7038436228189551 on epoch=35
06/25/2022 03:31:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6991600577738599 -> 0.7038436228189551 on epoch=35, global_step=500
06/25/2022 03:31:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
06/25/2022 03:31:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
06/25/2022 03:31:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
06/25/2022 03:31:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/25/2022 03:31:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
06/25/2022 03:31:34 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.7338653426434963 on epoch=39
06/25/2022 03:31:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7038436228189551 -> 0.7338653426434963 on epoch=39, global_step=550
06/25/2022 03:31:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/25/2022 03:31:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/25/2022 03:31:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/25/2022 03:31:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/25/2022 03:31:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=42
06/25/2022 03:31:55 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6895855637791122 on epoch=42
06/25/2022 03:31:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
06/25/2022 03:32:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
06/25/2022 03:32:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=44
06/25/2022 03:32:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/25/2022 03:32:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/25/2022 03:32:15 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6586022586222327 on epoch=46
06/25/2022 03:32:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
06/25/2022 03:32:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/25/2022 03:32:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/25/2022 03:32:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/25/2022 03:32:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
06/25/2022 03:32:35 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6885690582327508 on epoch=49
06/25/2022 03:32:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
06/25/2022 03:32:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=51
06/25/2022 03:32:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=52
06/25/2022 03:32:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/25/2022 03:32:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/25/2022 03:32:56 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.8167340130487167 on epoch=53
06/25/2022 03:32:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7338653426434963 -> 0.8167340130487167 on epoch=53, global_step=750
06/25/2022 03:32:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/25/2022 03:33:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/25/2022 03:33:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/25/2022 03:33:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=56
06/25/2022 03:33:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=57
06/25/2022 03:33:16 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.6690557009268266 on epoch=57
06/25/2022 03:33:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/25/2022 03:33:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
06/25/2022 03:33:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=59
06/25/2022 03:33:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
06/25/2022 03:33:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/25/2022 03:33:37 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7590320462187037 on epoch=60
06/25/2022 03:33:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/25/2022 03:33:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
06/25/2022 03:33:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/25/2022 03:33:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
06/25/2022 03:33:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/25/2022 03:33:58 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6501307996574152 on epoch=64
06/25/2022 03:34:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/25/2022 03:34:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/25/2022 03:34:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/25/2022 03:34:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/25/2022 03:34:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
06/25/2022 03:34:19 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7516662970173407 on epoch=67
06/25/2022 03:34:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/25/2022 03:34:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/25/2022 03:34:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/25/2022 03:34:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/25/2022 03:34:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/25/2022 03:34:39 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6485178964316086 on epoch=71
06/25/2022 03:34:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/25/2022 03:34:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/25/2022 03:34:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/25/2022 03:34:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/25/2022 03:34:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/25/2022 03:34:59 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6299306428338687 on epoch=74
06/25/2022 03:35:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/25/2022 03:35:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
06/25/2022 03:35:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/25/2022 03:35:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
06/25/2022 03:35:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/25/2022 03:35:19 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.6741311376795249 on epoch=78
06/25/2022 03:35:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/25/2022 03:35:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/25/2022 03:35:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/25/2022 03:35:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/25/2022 03:35:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=82
06/25/2022 03:35:39 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6684340175953079 on epoch=82
06/25/2022 03:35:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/25/2022 03:35:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/25/2022 03:35:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=84
06/25/2022 03:35:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/25/2022 03:35:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/25/2022 03:36:00 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8009660169052959 on epoch=85
06/25/2022 03:36:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/25/2022 03:36:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/25/2022 03:36:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/25/2022 03:36:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/25/2022 03:36:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/25/2022 03:36:20 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7149560117302054 on epoch=89
06/25/2022 03:36:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/25/2022 03:36:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/25/2022 03:36:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/25/2022 03:36:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/25/2022 03:36:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/25/2022 03:36:40 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8066701167270428 on epoch=92
06/25/2022 03:36:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/25/2022 03:36:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=94
06/25/2022 03:36:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
06/25/2022 03:36:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/25/2022 03:36:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/25/2022 03:37:00 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7599469153904638 on epoch=96
06/25/2022 03:37:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/25/2022 03:37:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/25/2022 03:37:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/25/2022 03:37:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/25/2022 03:37:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/25/2022 03:37:20 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=99
06/25/2022 03:37:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8167340130487167 -> 0.8591069464809384 on epoch=99, global_step=1400
06/25/2022 03:37:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/25/2022 03:37:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/25/2022 03:37:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/25/2022 03:37:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/25/2022 03:37:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/25/2022 03:37:40 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7581514065385034 on epoch=103
06/25/2022 03:37:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/25/2022 03:37:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/25/2022 03:37:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/25/2022 03:37:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/25/2022 03:37:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/25/2022 03:38:00 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7213033088333128 on epoch=107
06/25/2022 03:38:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/25/2022 03:38:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/25/2022 03:38:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
06/25/2022 03:38:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/25/2022 03:38:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/25/2022 03:38:20 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9101857282502444 on epoch=110
06/25/2022 03:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8591069464809384 -> 0.9101857282502444 on epoch=110, global_step=1550
06/25/2022 03:38:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/25/2022 03:38:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/25/2022 03:38:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/25/2022 03:38:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/25/2022 03:38:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/25/2022 03:38:41 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=114
06/25/2022 03:38:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/25/2022 03:38:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/25/2022 03:38:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/25/2022 03:38:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/25/2022 03:38:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/25/2022 03:39:01 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8569525904203323 on epoch=117
06/25/2022 03:39:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/25/2022 03:39:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/25/2022 03:39:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/25/2022 03:39:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/25/2022 03:39:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/25/2022 03:39:22 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7503964374932117 on epoch=121
06/25/2022 03:39:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/25/2022 03:39:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/25/2022 03:39:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/25/2022 03:39:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/25/2022 03:39:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/25/2022 03:39:42 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8530425219941349 on epoch=124
06/25/2022 03:39:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/25/2022 03:39:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/25/2022 03:39:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/25/2022 03:39:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/25/2022 03:39:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/25/2022 03:40:03 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7932104581060938 on epoch=128
06/25/2022 03:40:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/25/2022 03:40:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/25/2022 03:40:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/25/2022 03:40:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/25/2022 03:40:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/25/2022 03:40:23 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7957653703384253 on epoch=132
06/25/2022 03:40:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/25/2022 03:40:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/25/2022 03:40:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/25/2022 03:40:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/25/2022 03:40:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/25/2022 03:40:44 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8007245126789719 on epoch=135
06/25/2022 03:40:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/25/2022 03:40:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/25/2022 03:40:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/25/2022 03:40:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/25/2022 03:40:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/25/2022 03:41:04 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7970444482778449 on epoch=139
06/25/2022 03:41:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/25/2022 03:41:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/25/2022 03:41:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/25/2022 03:41:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/25/2022 03:41:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/25/2022 03:41:24 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7522765661809044 on epoch=142
06/25/2022 03:41:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/25/2022 03:41:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/25/2022 03:41:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/25/2022 03:41:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/25/2022 03:41:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/25/2022 03:41:44 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.799183485711 on epoch=146
06/25/2022 03:41:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/25/2022 03:41:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/25/2022 03:41:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/25/2022 03:41:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/25/2022 03:41:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/25/2022 03:42:04 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7464081676984902 on epoch=149
06/25/2022 03:42:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/25/2022 03:42:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/25/2022 03:42:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/25/2022 03:42:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/25/2022 03:42:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/25/2022 03:42:24 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8006999260418093 on epoch=153
06/25/2022 03:42:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/25/2022 03:42:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/25/2022 03:42:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/25/2022 03:42:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/25/2022 03:42:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/25/2022 03:42:44 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9101857282502444 on epoch=157
06/25/2022 03:42:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/25/2022 03:42:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/25/2022 03:42:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/25/2022 03:42:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/25/2022 03:42:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/25/2022 03:43:04 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9060190615835777 on epoch=160
06/25/2022 03:43:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/25/2022 03:43:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/25/2022 03:43:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/25/2022 03:43:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/25/2022 03:43:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/25/2022 03:43:25 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9101898012381883 on epoch=164
06/25/2022 03:43:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9101857282502444 -> 0.9101898012381883 on epoch=164, global_step=2300
06/25/2022 03:43:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/25/2022 03:43:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/25/2022 03:43:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/25/2022 03:43:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/25/2022 03:43:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/25/2022 03:43:45 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8511608015640274 on epoch=167
06/25/2022 03:43:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/25/2022 03:43:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/25/2022 03:43:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/25/2022 03:43:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/25/2022 03:43:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/25/2022 03:44:06 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8448022407699827 on epoch=171
06/25/2022 03:44:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/25/2022 03:44:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/25/2022 03:44:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/25/2022 03:44:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/25/2022 03:44:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/25/2022 03:44:26 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7500589613492838 on epoch=174
06/25/2022 03:44:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/25/2022 03:44:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/25/2022 03:44:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/25/2022 03:44:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/25/2022 03:44:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/25/2022 03:44:47 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7915345740772686 on epoch=178
06/25/2022 03:44:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/25/2022 03:44:52 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/25/2022 03:44:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/25/2022 03:44:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/25/2022 03:44:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/25/2022 03:45:07 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7516756574104245 on epoch=182
06/25/2022 03:45:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/25/2022 03:45:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/25/2022 03:45:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/25/2022 03:45:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/25/2022 03:45:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/25/2022 03:45:27 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8020618217961671 on epoch=185
06/25/2022 03:45:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/25/2022 03:45:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/25/2022 03:45:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/25/2022 03:45:38 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/25/2022 03:45:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/25/2022 03:45:48 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8591069464809384 on epoch=189
06/25/2022 03:45:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/25/2022 03:45:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/25/2022 03:45:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/25/2022 03:45:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/25/2022 03:46:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/25/2022 03:46:08 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8065551147145075 on epoch=192
06/25/2022 03:46:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/25/2022 03:46:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/25/2022 03:46:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/25/2022 03:46:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/25/2022 03:46:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/25/2022 03:46:29 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7969971696726915 on epoch=196
06/25/2022 03:46:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/25/2022 03:46:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/25/2022 03:46:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/25/2022 03:46:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/25/2022 03:46:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/25/2022 03:46:50 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.859103128054741 on epoch=199
06/25/2022 03:46:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/25/2022 03:46:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/25/2022 03:46:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/25/2022 03:47:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/25/2022 03:47:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/25/2022 03:47:11 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8551930596285435 on epoch=203
06/25/2022 03:47:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/25/2022 03:47:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/25/2022 03:47:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/25/2022 03:47:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/25/2022 03:47:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/25/2022 03:47:31 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7968905225072208 on epoch=207
06/25/2022 03:47:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/25/2022 03:47:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/25/2022 03:47:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/25/2022 03:47:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/25/2022 03:47:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/25/2022 03:47:51 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7932104581060938 on epoch=210
06/25/2022 03:47:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/25/2022 03:47:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/25/2022 03:47:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/25/2022 03:48:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/25/2022 03:48:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/25/2022 03:48:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:48:06 - INFO - __main__ - Printing 3 examples
06/25/2022 03:48:06 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 03:48:06 - INFO - __main__ - ['Film']
06/25/2022 03:48:06 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 03:48:06 - INFO - __main__ - ['Film']
06/25/2022 03:48:06 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 03:48:06 - INFO - __main__ - ['Film']
06/25/2022 03:48:06 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:48:06 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:48:06 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 03:48:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:48:06 - INFO - __main__ - Printing 3 examples
06/25/2022 03:48:06 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 03:48:06 - INFO - __main__ - ['Film']
06/25/2022 03:48:06 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 03:48:06 - INFO - __main__ - ['Film']
06/25/2022 03:48:06 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 03:48:06 - INFO - __main__ - ['Film']
06/25/2022 03:48:06 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:48:06 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:48:06 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 03:48:12 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7464081676984904 on epoch=214
06/25/2022 03:48:12 - INFO - __main__ - save last model!
06/25/2022 03:48:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 03:48:13 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 03:48:13 - INFO - __main__ - Printing 3 examples
06/25/2022 03:48:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 03:48:13 - INFO - __main__ - ['Animal']
06/25/2022 03:48:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 03:48:13 - INFO - __main__ - ['Animal']
06/25/2022 03:48:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 03:48:13 - INFO - __main__ - ['Village']
06/25/2022 03:48:13 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:48:15 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:48:18 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 03:48:25 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 03:48:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 03:48:26 - INFO - __main__ - Starting training!
06/25/2022 03:50:43 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/25/2022 03:50:43 - INFO - __main__ - Classification-F1 on test data: 0.4566
06/25/2022 03:50:44 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9101898012381883, test_performance=0.4565835269392464
06/25/2022 03:50:44 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/25/2022 03:50:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:50:44 - INFO - __main__ - Printing 3 examples
06/25/2022 03:50:44 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 03:50:44 - INFO - __main__ - ['Film']
06/25/2022 03:50:44 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 03:50:44 - INFO - __main__ - ['Film']
06/25/2022 03:50:44 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 03:50:44 - INFO - __main__ - ['Film']
06/25/2022 03:50:44 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:50:45 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:50:45 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 03:50:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 03:50:45 - INFO - __main__ - Printing 3 examples
06/25/2022 03:50:45 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 03:50:45 - INFO - __main__ - ['Film']
06/25/2022 03:50:45 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 03:50:45 - INFO - __main__ - ['Film']
06/25/2022 03:50:45 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 03:50:45 - INFO - __main__ - ['Film']
06/25/2022 03:50:45 - INFO - __main__ - Tokenizing Input ...
06/25/2022 03:50:45 - INFO - __main__ - Tokenizing Output ...
06/25/2022 03:50:45 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 03:51:04 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 03:51:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 03:51:05 - INFO - __main__ - Starting training!
06/25/2022 03:51:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.98 on epoch=0
06/25/2022 03:51:11 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/25/2022 03:51:14 - INFO - __main__ - Step 30 Global step 30 Train loss 4.28 on epoch=2
06/25/2022 03:51:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.69 on epoch=2
06/25/2022 03:51:19 - INFO - __main__ - Step 50 Global step 50 Train loss 3.56 on epoch=3
06/25/2022 03:51:24 - INFO - __main__ - Global step 50 Train loss 4.67 Classification-F1 0.05455591626699621 on epoch=3
06/25/2022 03:51:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05455591626699621 on epoch=3, global_step=50
06/25/2022 03:51:27 - INFO - __main__ - Step 60 Global step 60 Train loss 3.30 on epoch=4
06/25/2022 03:51:29 - INFO - __main__ - Step 70 Global step 70 Train loss 2.75 on epoch=4
06/25/2022 03:51:32 - INFO - __main__ - Step 80 Global step 80 Train loss 2.88 on epoch=5
06/25/2022 03:51:35 - INFO - __main__ - Step 90 Global step 90 Train loss 2.47 on epoch=6
06/25/2022 03:51:37 - INFO - __main__ - Step 100 Global step 100 Train loss 2.35 on epoch=7
06/25/2022 03:51:43 - INFO - __main__ - Global step 100 Train loss 2.75 Classification-F1 0.09062398175301402 on epoch=7
06/25/2022 03:51:43 - INFO - __main__ - Saving model with best Classification-F1: 0.05455591626699621 -> 0.09062398175301402 on epoch=7, global_step=100
06/25/2022 03:51:46 - INFO - __main__ - Step 110 Global step 110 Train loss 2.03 on epoch=7
06/25/2022 03:51:48 - INFO - __main__ - Step 120 Global step 120 Train loss 2.21 on epoch=8
06/25/2022 03:51:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.95 on epoch=9
06/25/2022 03:51:54 - INFO - __main__ - Step 140 Global step 140 Train loss 1.63 on epoch=9
06/25/2022 03:51:56 - INFO - __main__ - Step 150 Global step 150 Train loss 1.84 on epoch=10
06/25/2022 03:52:02 - INFO - __main__ - Global step 150 Train loss 1.93 Classification-F1 0.1322176504769323 on epoch=10
06/25/2022 03:52:02 - INFO - __main__ - Saving model with best Classification-F1: 0.09062398175301402 -> 0.1322176504769323 on epoch=10, global_step=150
06/25/2022 03:52:05 - INFO - __main__ - Step 160 Global step 160 Train loss 1.58 on epoch=11
06/25/2022 03:52:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.53 on epoch=12
06/25/2022 03:52:10 - INFO - __main__ - Step 180 Global step 180 Train loss 1.32 on epoch=12
06/25/2022 03:52:13 - INFO - __main__ - Step 190 Global step 190 Train loss 1.33 on epoch=13
06/25/2022 03:52:15 - INFO - __main__ - Step 200 Global step 200 Train loss 1.30 on epoch=14
06/25/2022 03:52:21 - INFO - __main__ - Global step 200 Train loss 1.41 Classification-F1 0.1804386941850848 on epoch=14
06/25/2022 03:52:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1322176504769323 -> 0.1804386941850848 on epoch=14, global_step=200
06/25/2022 03:52:24 - INFO - __main__ - Step 210 Global step 210 Train loss 1.00 on epoch=14
06/25/2022 03:52:27 - INFO - __main__ - Step 220 Global step 220 Train loss 1.17 on epoch=15
06/25/2022 03:52:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.96 on epoch=16
06/25/2022 03:52:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.92 on epoch=17
06/25/2022 03:52:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.84 on epoch=17
06/25/2022 03:52:41 - INFO - __main__ - Global step 250 Train loss 0.98 Classification-F1 0.3012524731562308 on epoch=17
06/25/2022 03:52:41 - INFO - __main__ - Saving model with best Classification-F1: 0.1804386941850848 -> 0.3012524731562308 on epoch=17, global_step=250
06/25/2022 03:52:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.88 on epoch=18
06/25/2022 03:52:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=19
06/25/2022 03:52:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.72 on epoch=19
06/25/2022 03:52:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=20
06/25/2022 03:52:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=21
06/25/2022 03:53:02 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.41108463460982153 on epoch=21
06/25/2022 03:53:02 - INFO - __main__ - Saving model with best Classification-F1: 0.3012524731562308 -> 0.41108463460982153 on epoch=21, global_step=300
06/25/2022 03:53:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=22
06/25/2022 03:53:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
06/25/2022 03:53:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.68 on epoch=23
06/25/2022 03:53:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
06/25/2022 03:53:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=24
06/25/2022 03:53:22 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.46461001974317423 on epoch=24
06/25/2022 03:53:22 - INFO - __main__ - Saving model with best Classification-F1: 0.41108463460982153 -> 0.46461001974317423 on epoch=24, global_step=350
06/25/2022 03:53:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=25
06/25/2022 03:53:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/25/2022 03:53:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=27
06/25/2022 03:53:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=27
06/25/2022 03:53:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=28
06/25/2022 03:53:43 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.703277946930467 on epoch=28
06/25/2022 03:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.46461001974317423 -> 0.703277946930467 on epoch=28, global_step=400
06/25/2022 03:53:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=29
06/25/2022 03:53:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=29
06/25/2022 03:53:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=30
06/25/2022 03:53:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=31
06/25/2022 03:53:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
06/25/2022 03:54:04 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.806635612139992 on epoch=32
06/25/2022 03:54:04 - INFO - __main__ - Saving model with best Classification-F1: 0.703277946930467 -> 0.806635612139992 on epoch=32, global_step=450
06/25/2022 03:54:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=32
06/25/2022 03:54:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=33
06/25/2022 03:54:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=34
06/25/2022 03:54:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
06/25/2022 03:54:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
06/25/2022 03:54:25 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.7163749912024139 on epoch=35
06/25/2022 03:54:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
06/25/2022 03:54:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=37
06/25/2022 03:54:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/25/2022 03:54:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=38
06/25/2022 03:54:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=39
06/25/2022 03:54:46 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.8023899627478257 on epoch=39
06/25/2022 03:54:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=39
06/25/2022 03:54:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/25/2022 03:54:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=41
06/25/2022 03:54:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
06/25/2022 03:54:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
06/25/2022 03:55:07 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.8668478624123785 on epoch=42
06/25/2022 03:55:07 - INFO - __main__ - Saving model with best Classification-F1: 0.806635612139992 -> 0.8668478624123785 on epoch=42, global_step=600
06/25/2022 03:55:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=43
06/25/2022 03:55:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
06/25/2022 03:55:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=44
06/25/2022 03:55:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
06/25/2022 03:55:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=46
06/25/2022 03:55:27 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.8658567239212402 on epoch=46
06/25/2022 03:55:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/25/2022 03:55:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=47
06/25/2022 03:55:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=48
06/25/2022 03:55:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=49
06/25/2022 03:55:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=49
06/25/2022 03:55:48 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.8753990210332557 on epoch=49
06/25/2022 03:55:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8668478624123785 -> 0.8753990210332557 on epoch=49, global_step=700
06/25/2022 03:55:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/25/2022 03:55:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=51
06/25/2022 03:55:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=52
06/25/2022 03:55:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
06/25/2022 03:56:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/25/2022 03:56:09 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.8733334848863732 on epoch=53
06/25/2022 03:56:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
06/25/2022 03:56:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=54
06/25/2022 03:56:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/25/2022 03:56:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
06/25/2022 03:56:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=57
06/25/2022 03:56:29 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.839645027121308 on epoch=57
06/25/2022 03:56:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=57
06/25/2022 03:56:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
06/25/2022 03:56:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/25/2022 03:56:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=59
06/25/2022 03:56:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/25/2022 03:56:50 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.8422147609805395 on epoch=60
06/25/2022 03:56:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
06/25/2022 03:56:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/25/2022 03:56:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
06/25/2022 03:57:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
06/25/2022 03:57:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
06/25/2022 03:57:10 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6969974168661709 on epoch=64
06/25/2022 03:57:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
06/25/2022 03:57:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/25/2022 03:57:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/25/2022 03:57:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
06/25/2022 03:57:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
06/25/2022 03:57:31 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.8401520582165745 on epoch=67
06/25/2022 03:57:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
06/25/2022 03:57:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/25/2022 03:57:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
06/25/2022 03:57:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/25/2022 03:57:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
06/25/2022 03:57:52 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7813402047035825 on epoch=71
06/25/2022 03:57:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/25/2022 03:57:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/25/2022 03:58:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/25/2022 03:58:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/25/2022 03:58:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=74
06/25/2022 03:58:13 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7424417868489169 on epoch=74
06/25/2022 03:58:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=75
06/25/2022 03:58:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/25/2022 03:58:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/25/2022 03:58:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/25/2022 03:58:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/25/2022 03:58:33 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.7875602093869976 on epoch=78
06/25/2022 03:58:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
06/25/2022 03:58:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/25/2022 03:58:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
06/25/2022 03:58:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/25/2022 03:58:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/25/2022 03:58:54 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7243546762068336 on epoch=82
06/25/2022 03:58:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/25/2022 03:58:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=83
06/25/2022 03:59:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/25/2022 03:59:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=84
06/25/2022 03:59:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
06/25/2022 03:59:15 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7069693349263242 on epoch=85
06/25/2022 03:59:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
06/25/2022 03:59:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/25/2022 03:59:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/25/2022 03:59:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/25/2022 03:59:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/25/2022 03:59:36 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7874472803274057 on epoch=89
06/25/2022 03:59:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
06/25/2022 03:59:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/25/2022 03:59:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
06/25/2022 03:59:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/25/2022 03:59:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/25/2022 03:59:57 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7012296136235016 on epoch=92
06/25/2022 03:59:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/25/2022 04:00:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/25/2022 04:00:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/25/2022 04:00:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/25/2022 04:00:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/25/2022 04:00:17 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7146022059434624 on epoch=96
06/25/2022 04:00:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/25/2022 04:00:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/25/2022 04:00:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/25/2022 04:00:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/25/2022 04:00:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/25/2022 04:00:38 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7456675940546909 on epoch=99
06/25/2022 04:00:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/25/2022 04:00:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/25/2022 04:00:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/25/2022 04:00:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/25/2022 04:00:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/25/2022 04:00:58 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7562165968172643 on epoch=103
06/25/2022 04:01:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/25/2022 04:01:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/25/2022 04:01:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/25/2022 04:01:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/25/2022 04:01:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/25/2022 04:01:19 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7599435212338439 on epoch=107
06/25/2022 04:01:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/25/2022 04:01:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/25/2022 04:01:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/25/2022 04:01:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/25/2022 04:01:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/25/2022 04:01:39 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9185272075594656 on epoch=110
06/25/2022 04:01:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8753990210332557 -> 0.9185272075594656 on epoch=110, global_step=1550
06/25/2022 04:01:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/25/2022 04:01:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/25/2022 04:01:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/25/2022 04:01:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/25/2022 04:01:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/25/2022 04:02:00 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7248340793332305 on epoch=114
06/25/2022 04:02:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/25/2022 04:02:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/25/2022 04:02:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/25/2022 04:02:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/25/2022 04:02:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/25/2022 04:02:20 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8103501811281698 on epoch=117
06/25/2022 04:02:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/25/2022 04:02:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
06/25/2022 04:02:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/25/2022 04:02:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/25/2022 04:02:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/25/2022 04:02:40 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8140302455292968 on epoch=121
06/25/2022 04:02:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/25/2022 04:02:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/25/2022 04:02:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/25/2022 04:02:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/25/2022 04:02:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/25/2022 04:02:59 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7598240469208212 on epoch=124
06/25/2022 04:03:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/25/2022 04:03:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/25/2022 04:03:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/25/2022 04:03:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/25/2022 04:03:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/25/2022 04:03:19 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8045195790926342 on epoch=128
06/25/2022 04:03:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/25/2022 04:03:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/25/2022 04:03:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/25/2022 04:03:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/25/2022 04:03:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/25/2022 04:03:39 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7598240469208212 on epoch=132
06/25/2022 04:03:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/25/2022 04:03:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/25/2022 04:03:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/25/2022 04:03:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/25/2022 04:03:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/25/2022 04:03:58 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=135
06/25/2022 04:04:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/25/2022 04:04:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/25/2022 04:04:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/25/2022 04:04:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/25/2022 04:04:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/25/2022 04:04:18 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=139
06/25/2022 04:04:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/25/2022 04:04:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/25/2022 04:04:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/25/2022 04:04:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/25/2022 04:04:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/25/2022 04:04:39 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.802863550112127 on epoch=142
06/25/2022 04:04:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/25/2022 04:04:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/25/2022 04:04:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/25/2022 04:04:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/25/2022 04:04:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/25/2022 04:04:59 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.802863550112127 on epoch=146
06/25/2022 04:05:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/25/2022 04:05:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/25/2022 04:05:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/25/2022 04:05:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/25/2022 04:05:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/25/2022 04:05:19 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8551930596285435 on epoch=149
06/25/2022 04:05:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/25/2022 04:05:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/25/2022 04:05:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/25/2022 04:05:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/25/2022 04:05:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/25/2022 04:05:40 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.802863550112127 on epoch=153
06/25/2022 04:05:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/25/2022 04:05:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/25/2022 04:05:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/25/2022 04:05:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/25/2022 04:05:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/25/2022 04:06:00 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8508658610577409 on epoch=157
06/25/2022 04:06:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/25/2022 04:06:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/25/2022 04:06:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/25/2022 04:06:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/25/2022 04:06:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/25/2022 04:06:20 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.855058651026393 on epoch=160
06/25/2022 04:06:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/25/2022 04:06:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/25/2022 04:06:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/25/2022 04:06:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/25/2022 04:06:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/25/2022 04:06:40 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8025974592486403 on epoch=164
06/25/2022 04:06:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/25/2022 04:06:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/25/2022 04:06:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/25/2022 04:06:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/25/2022 04:06:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/25/2022 04:07:00 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9100423590746171 on epoch=167
06/25/2022 04:07:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/25/2022 04:07:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/25/2022 04:07:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/25/2022 04:07:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/25/2022 04:07:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/25/2022 04:07:20 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9100423590746171 on epoch=171
06/25/2022 04:07:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/25/2022 04:07:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/25/2022 04:07:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/25/2022 04:07:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/25/2022 04:07:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/25/2022 04:07:40 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9773495321882419 on epoch=174
06/25/2022 04:07:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9185272075594656 -> 0.9773495321882419 on epoch=174, global_step=2450
06/25/2022 04:07:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/25/2022 04:07:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/25/2022 04:07:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/25/2022 04:07:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/25/2022 04:07:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/25/2022 04:08:00 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=178
06/25/2022 04:08:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9773495321882419 -> 0.9776304656760065 on epoch=178, global_step=2500
06/25/2022 04:08:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/25/2022 04:08:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/25/2022 04:08:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/25/2022 04:08:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/25/2022 04:08:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/25/2022 04:08:21 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9773495321882419 on epoch=182
06/25/2022 04:08:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/25/2022 04:08:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/25/2022 04:08:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/25/2022 04:08:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/25/2022 04:08:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/25/2022 04:08:41 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9685395565850976 on epoch=185
06/25/2022 04:08:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/25/2022 04:08:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/25/2022 04:08:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/25/2022 04:08:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/25/2022 04:08:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/25/2022 04:09:01 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9142130987292278 on epoch=189
06/25/2022 04:09:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/25/2022 04:09:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/25/2022 04:09:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/25/2022 04:09:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/25/2022 04:09:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/25/2022 04:09:21 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9142130987292278 on epoch=192
06/25/2022 04:09:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/25/2022 04:09:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/25/2022 04:09:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/25/2022 04:09:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/25/2022 04:09:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/25/2022 04:09:41 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9058797653958945 on epoch=196
06/25/2022 04:09:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/25/2022 04:09:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/25/2022 04:09:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
06/25/2022 04:09:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/25/2022 04:09:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/25/2022 04:10:01 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8469557926315435 on epoch=199
06/25/2022 04:10:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/25/2022 04:10:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/25/2022 04:10:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/25/2022 04:10:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/25/2022 04:10:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/25/2022 04:10:21 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9015181455330641 on epoch=203
06/25/2022 04:10:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/25/2022 04:10:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/25/2022 04:10:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/25/2022 04:10:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/25/2022 04:10:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/25/2022 04:10:41 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8469557926315435 on epoch=207
06/25/2022 04:10:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/25/2022 04:10:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/25/2022 04:10:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/25/2022 04:10:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/25/2022 04:10:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/25/2022 04:11:02 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9058716194200066 on epoch=210
06/25/2022 04:11:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/25/2022 04:11:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/25/2022 04:11:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/25/2022 04:11:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/25/2022 04:11:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/25/2022 04:11:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:11:16 - INFO - __main__ - Printing 3 examples
06/25/2022 04:11:16 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 04:11:16 - INFO - __main__ - ['Film']
06/25/2022 04:11:16 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 04:11:16 - INFO - __main__ - ['Film']
06/25/2022 04:11:16 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 04:11:16 - INFO - __main__ - ['Film']
06/25/2022 04:11:17 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:11:17 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:11:17 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 04:11:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:11:17 - INFO - __main__ - Printing 3 examples
06/25/2022 04:11:17 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 04:11:17 - INFO - __main__ - ['Film']
06/25/2022 04:11:17 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 04:11:17 - INFO - __main__ - ['Film']
06/25/2022 04:11:17 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 04:11:17 - INFO - __main__ - ['Film']
06/25/2022 04:11:17 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:11:17 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:11:17 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 04:11:22 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7948166950064485 on epoch=214
06/25/2022 04:11:22 - INFO - __main__ - save last model!
06/25/2022 04:11:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 04:11:22 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 04:11:22 - INFO - __main__ - Printing 3 examples
06/25/2022 04:11:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 04:11:22 - INFO - __main__ - ['Animal']
06/25/2022 04:11:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 04:11:22 - INFO - __main__ - ['Animal']
06/25/2022 04:11:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 04:11:22 - INFO - __main__ - ['Village']
06/25/2022 04:11:22 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:11:24 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:11:27 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 04:11:33 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 04:11:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 04:11:33 - INFO - __main__ - Starting training!
06/25/2022 04:13:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/25/2022 04:13:49 - INFO - __main__ - Classification-F1 on test data: 0.5685
06/25/2022 04:13:49 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9776304656760065, test_performance=0.5684765030959318
06/25/2022 04:13:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/25/2022 04:13:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:13:50 - INFO - __main__ - Printing 3 examples
06/25/2022 04:13:50 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 04:13:50 - INFO - __main__ - ['Film']
06/25/2022 04:13:50 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 04:13:50 - INFO - __main__ - ['Film']
06/25/2022 04:13:50 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 04:13:50 - INFO - __main__ - ['Film']
06/25/2022 04:13:50 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:13:51 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:13:51 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 04:13:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:13:51 - INFO - __main__ - Printing 3 examples
06/25/2022 04:13:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 04:13:51 - INFO - __main__ - ['Film']
06/25/2022 04:13:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 04:13:51 - INFO - __main__ - ['Film']
06/25/2022 04:13:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 04:13:51 - INFO - __main__ - ['Film']
06/25/2022 04:13:51 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:13:51 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:13:51 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 04:14:10 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 04:14:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 04:14:11 - INFO - __main__ - Starting training!
06/25/2022 04:14:15 - INFO - __main__ - Step 10 Global step 10 Train loss 7.27 on epoch=0
06/25/2022 04:14:18 - INFO - __main__ - Step 20 Global step 20 Train loss 5.73 on epoch=1
06/25/2022 04:14:20 - INFO - __main__ - Step 30 Global step 30 Train loss 4.98 on epoch=2
06/25/2022 04:14:23 - INFO - __main__ - Step 40 Global step 40 Train loss 4.14 on epoch=2
06/25/2022 04:14:26 - INFO - __main__ - Step 50 Global step 50 Train loss 4.16 on epoch=3
06/25/2022 04:14:31 - INFO - __main__ - Global step 50 Train loss 5.26 Classification-F1 0.06493845275943588 on epoch=3
06/25/2022 04:14:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06493845275943588 on epoch=3, global_step=50
06/25/2022 04:14:34 - INFO - __main__ - Step 60 Global step 60 Train loss 3.78 on epoch=4
06/25/2022 04:14:37 - INFO - __main__ - Step 70 Global step 70 Train loss 3.13 on epoch=4
06/25/2022 04:14:39 - INFO - __main__ - Step 80 Global step 80 Train loss 3.37 on epoch=5
06/25/2022 04:14:42 - INFO - __main__ - Step 90 Global step 90 Train loss 2.89 on epoch=6
06/25/2022 04:14:44 - INFO - __main__ - Step 100 Global step 100 Train loss 2.64 on epoch=7
06/25/2022 04:14:49 - INFO - __main__ - Global step 100 Train loss 3.16 Classification-F1 0.0724668045167789 on epoch=7
06/25/2022 04:14:49 - INFO - __main__ - Saving model with best Classification-F1: 0.06493845275943588 -> 0.0724668045167789 on epoch=7, global_step=100
06/25/2022 04:14:52 - INFO - __main__ - Step 110 Global step 110 Train loss 2.53 on epoch=7
06/25/2022 04:14:55 - INFO - __main__ - Step 120 Global step 120 Train loss 2.63 on epoch=8
06/25/2022 04:14:57 - INFO - __main__ - Step 130 Global step 130 Train loss 2.50 on epoch=9
06/25/2022 04:15:00 - INFO - __main__ - Step 140 Global step 140 Train loss 2.02 on epoch=9
06/25/2022 04:15:03 - INFO - __main__ - Step 150 Global step 150 Train loss 2.42 on epoch=10
06/25/2022 04:15:08 - INFO - __main__ - Global step 150 Train loss 2.42 Classification-F1 0.11936476009056654 on epoch=10
06/25/2022 04:15:09 - INFO - __main__ - Saving model with best Classification-F1: 0.0724668045167789 -> 0.11936476009056654 on epoch=10, global_step=150
06/25/2022 04:15:11 - INFO - __main__ - Step 160 Global step 160 Train loss 2.08 on epoch=11
06/25/2022 04:15:14 - INFO - __main__ - Step 170 Global step 170 Train loss 2.03 on epoch=12
06/25/2022 04:15:16 - INFO - __main__ - Step 180 Global step 180 Train loss 1.64 on epoch=12
06/25/2022 04:15:19 - INFO - __main__ - Step 190 Global step 190 Train loss 1.85 on epoch=13
06/25/2022 04:15:22 - INFO - __main__ - Step 200 Global step 200 Train loss 1.77 on epoch=14
06/25/2022 04:15:28 - INFO - __main__ - Global step 200 Train loss 1.87 Classification-F1 0.12407047066961853 on epoch=14
06/25/2022 04:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.11936476009056654 -> 0.12407047066961853 on epoch=14, global_step=200
06/25/2022 04:15:30 - INFO - __main__ - Step 210 Global step 210 Train loss 1.50 on epoch=14
06/25/2022 04:15:33 - INFO - __main__ - Step 220 Global step 220 Train loss 1.63 on epoch=15
06/25/2022 04:15:36 - INFO - __main__ - Step 230 Global step 230 Train loss 1.42 on epoch=16
06/25/2022 04:15:38 - INFO - __main__ - Step 240 Global step 240 Train loss 1.38 on epoch=17
06/25/2022 04:15:41 - INFO - __main__ - Step 250 Global step 250 Train loss 1.27 on epoch=17
06/25/2022 04:15:47 - INFO - __main__ - Global step 250 Train loss 1.44 Classification-F1 0.15785830465043432 on epoch=17
06/25/2022 04:15:47 - INFO - __main__ - Saving model with best Classification-F1: 0.12407047066961853 -> 0.15785830465043432 on epoch=17, global_step=250
06/25/2022 04:15:49 - INFO - __main__ - Step 260 Global step 260 Train loss 1.20 on epoch=18
06/25/2022 04:15:52 - INFO - __main__ - Step 270 Global step 270 Train loss 1.13 on epoch=19
06/25/2022 04:15:55 - INFO - __main__ - Step 280 Global step 280 Train loss 1.01 on epoch=19
06/25/2022 04:15:57 - INFO - __main__ - Step 290 Global step 290 Train loss 1.19 on epoch=20
06/25/2022 04:16:00 - INFO - __main__ - Step 300 Global step 300 Train loss 1.00 on epoch=21
06/25/2022 04:16:06 - INFO - __main__ - Global step 300 Train loss 1.11 Classification-F1 0.25438952149218075 on epoch=21
06/25/2022 04:16:06 - INFO - __main__ - Saving model with best Classification-F1: 0.15785830465043432 -> 0.25438952149218075 on epoch=21, global_step=300
06/25/2022 04:16:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.96 on epoch=22
06/25/2022 04:16:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.83 on epoch=22
06/25/2022 04:16:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.92 on epoch=23
06/25/2022 04:16:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.83 on epoch=24
06/25/2022 04:16:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=24
06/25/2022 04:16:27 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.3107318433161554 on epoch=24
06/25/2022 04:16:27 - INFO - __main__ - Saving model with best Classification-F1: 0.25438952149218075 -> 0.3107318433161554 on epoch=24, global_step=350
06/25/2022 04:16:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.78 on epoch=25
06/25/2022 04:16:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=26
06/25/2022 04:16:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.65 on epoch=27
06/25/2022 04:16:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.67 on epoch=27
06/25/2022 04:16:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.73 on epoch=28
06/25/2022 04:16:48 - INFO - __main__ - Global step 400 Train loss 0.69 Classification-F1 0.453976620055239 on epoch=28
06/25/2022 04:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.3107318433161554 -> 0.453976620055239 on epoch=28, global_step=400
06/25/2022 04:16:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=29
06/25/2022 04:16:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=29
06/25/2022 04:16:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=30
06/25/2022 04:16:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=31
06/25/2022 04:17:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=32
06/25/2022 04:17:09 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.47225864572134874 on epoch=32
06/25/2022 04:17:09 - INFO - __main__ - Saving model with best Classification-F1: 0.453976620055239 -> 0.47225864572134874 on epoch=32, global_step=450
06/25/2022 04:17:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=32
06/25/2022 04:17:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=33
06/25/2022 04:17:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.53 on epoch=34
06/25/2022 04:17:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=34
06/25/2022 04:17:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=35
06/25/2022 04:17:30 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.5407290331451235 on epoch=35
06/25/2022 04:17:30 - INFO - __main__ - Saving model with best Classification-F1: 0.47225864572134874 -> 0.5407290331451235 on epoch=35, global_step=500
06/25/2022 04:17:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=36
06/25/2022 04:17:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=37
06/25/2022 04:17:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=37
06/25/2022 04:17:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.45 on epoch=38
06/25/2022 04:17:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
06/25/2022 04:17:51 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.5730489543269294 on epoch=39
06/25/2022 04:17:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5407290331451235 -> 0.5730489543269294 on epoch=39, global_step=550
06/25/2022 04:17:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=39
06/25/2022 04:17:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
06/25/2022 04:17:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=41
06/25/2022 04:18:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.45 on epoch=42
06/25/2022 04:18:04 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=42
06/25/2022 04:18:12 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.6747513475592278 on epoch=42
06/25/2022 04:18:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5730489543269294 -> 0.6747513475592278 on epoch=42, global_step=600
06/25/2022 04:18:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
06/25/2022 04:18:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=44
06/25/2022 04:18:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.43 on epoch=44
06/25/2022 04:18:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=45
06/25/2022 04:18:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=46
06/25/2022 04:18:33 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.7180632994741694 on epoch=46
06/25/2022 04:18:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6747513475592278 -> 0.7180632994741694 on epoch=46, global_step=650
06/25/2022 04:18:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=47
06/25/2022 04:18:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/25/2022 04:18:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=48
06/25/2022 04:18:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=49
06/25/2022 04:18:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=49
06/25/2022 04:18:53 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.6634058552165015 on epoch=49
06/25/2022 04:18:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/25/2022 04:18:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=51
06/25/2022 04:19:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=52
06/25/2022 04:19:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.29 on epoch=52
06/25/2022 04:19:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=53
06/25/2022 04:19:14 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.8086021505376344 on epoch=53
06/25/2022 04:19:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7180632994741694 -> 0.8086021505376344 on epoch=53, global_step=750
06/25/2022 04:19:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
06/25/2022 04:19:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=54
06/25/2022 04:19:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/25/2022 04:19:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
06/25/2022 04:19:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
06/25/2022 04:19:35 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.8077652935961264 on epoch=57
06/25/2022 04:19:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/25/2022 04:19:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/25/2022 04:19:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=59
06/25/2022 04:19:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=59
06/25/2022 04:19:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=60
06/25/2022 04:19:56 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.8297816878462041 on epoch=60
06/25/2022 04:19:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8086021505376344 -> 0.8297816878462041 on epoch=60, global_step=850
06/25/2022 04:19:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=61
06/25/2022 04:20:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=62
06/25/2022 04:20:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=62
06/25/2022 04:20:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=63
06/25/2022 04:20:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/25/2022 04:20:16 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.7900671803423227 on epoch=64
06/25/2022 04:20:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
06/25/2022 04:20:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
06/25/2022 04:20:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/25/2022 04:20:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/25/2022 04:20:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/25/2022 04:20:37 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.8475623311587623 on epoch=67
06/25/2022 04:20:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8297816878462041 -> 0.8475623311587623 on epoch=67, global_step=950
06/25/2022 04:20:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=68
06/25/2022 04:20:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
06/25/2022 04:20:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=69
06/25/2022 04:20:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
06/25/2022 04:20:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/25/2022 04:20:58 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.7786724485763608 on epoch=71
06/25/2022 04:21:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/25/2022 04:21:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=72
06/25/2022 04:21:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
06/25/2022 04:21:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=74
06/25/2022 04:21:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
06/25/2022 04:21:18 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.7718597262952102 on epoch=74
06/25/2022 04:21:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
06/25/2022 04:21:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
06/25/2022 04:21:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
06/25/2022 04:21:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
06/25/2022 04:21:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=78
06/25/2022 04:21:39 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.7337388404297075 on epoch=78
06/25/2022 04:21:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=79
06/25/2022 04:21:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=79
06/25/2022 04:21:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=80
06/25/2022 04:21:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
06/25/2022 04:21:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=82
06/25/2022 04:21:59 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.6896960193331161 on epoch=82
06/25/2022 04:22:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/25/2022 04:22:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/25/2022 04:22:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/25/2022 04:22:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=84
06/25/2022 04:22:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=85
06/25/2022 04:22:20 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.6964366577269803 on epoch=85
06/25/2022 04:22:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/25/2022 04:22:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/25/2022 04:22:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/25/2022 04:22:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=88
06/25/2022 04:22:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.26 on epoch=89
06/25/2022 04:22:41 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.7329137097108502 on epoch=89
06/25/2022 04:22:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/25/2022 04:22:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/25/2022 04:22:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
06/25/2022 04:22:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
06/25/2022 04:22:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/25/2022 04:23:01 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.7707179031218153 on epoch=92
06/25/2022 04:23:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=93
06/25/2022 04:23:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=94
06/25/2022 04:23:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/25/2022 04:23:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/25/2022 04:23:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
06/25/2022 04:23:22 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.7301494204720012 on epoch=96
06/25/2022 04:23:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
06/25/2022 04:23:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
06/25/2022 04:23:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/25/2022 04:23:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=99
06/25/2022 04:23:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/25/2022 04:23:42 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.7374035199462144 on epoch=99
06/25/2022 04:23:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/25/2022 04:23:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/25/2022 04:23:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/25/2022 04:23:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=102
06/25/2022 04:23:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=103
06/25/2022 04:24:03 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6621164149177732 on epoch=103
06/25/2022 04:24:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/25/2022 04:24:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
06/25/2022 04:24:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/25/2022 04:24:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/25/2022 04:24:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
06/25/2022 04:24:23 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.6935049418920387 on epoch=107
06/25/2022 04:24:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
06/25/2022 04:24:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
06/25/2022 04:24:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
06/25/2022 04:24:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/25/2022 04:24:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/25/2022 04:24:43 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7429195725210905 on epoch=110
06/25/2022 04:24:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/25/2022 04:24:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/25/2022 04:24:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/25/2022 04:24:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
06/25/2022 04:24:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
06/25/2022 04:25:04 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7016462629365855 on epoch=114
06/25/2022 04:25:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
06/25/2022 04:25:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
06/25/2022 04:25:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
06/25/2022 04:25:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=117
06/25/2022 04:25:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=117
06/25/2022 04:25:24 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6557751878160927 on epoch=117
06/25/2022 04:25:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=118
06/25/2022 04:25:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/25/2022 04:25:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/25/2022 04:25:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
06/25/2022 04:25:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
06/25/2022 04:25:45 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.6614901793170044 on epoch=121
06/25/2022 04:25:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
06/25/2022 04:25:50 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/25/2022 04:25:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=123
06/25/2022 04:25:55 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/25/2022 04:25:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/25/2022 04:26:05 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7154858728546268 on epoch=124
06/25/2022 04:26:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/25/2022 04:26:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/25/2022 04:26:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=127
06/25/2022 04:26:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/25/2022 04:26:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=128
06/25/2022 04:26:26 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.6689188902911065 on epoch=128
06/25/2022 04:26:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/25/2022 04:26:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/25/2022 04:26:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
06/25/2022 04:26:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/25/2022 04:26:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
06/25/2022 04:26:46 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.6728654769002317 on epoch=132
06/25/2022 04:26:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/25/2022 04:26:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.14 on epoch=133
06/25/2022 04:26:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
06/25/2022 04:26:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/25/2022 04:27:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/25/2022 04:27:07 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6795368041747748 on epoch=135
06/25/2022 04:27:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/25/2022 04:27:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/25/2022 04:27:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/25/2022 04:27:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/25/2022 04:27:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/25/2022 04:27:28 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6860460030349701 on epoch=139
06/25/2022 04:27:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/25/2022 04:27:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/25/2022 04:27:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/25/2022 04:27:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/25/2022 04:27:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/25/2022 04:27:48 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7367111980015206 on epoch=142
06/25/2022 04:27:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/25/2022 04:27:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/25/2022 04:27:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/25/2022 04:27:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
06/25/2022 04:28:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/25/2022 04:28:09 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7908573400034501 on epoch=146
06/25/2022 04:28:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/25/2022 04:28:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/25/2022 04:28:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/25/2022 04:28:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/25/2022 04:28:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/25/2022 04:28:29 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7239520273476132 on epoch=149
06/25/2022 04:28:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/25/2022 04:28:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/25/2022 04:28:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
06/25/2022 04:28:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/25/2022 04:28:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/25/2022 04:28:49 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7274276437264553 on epoch=153
06/25/2022 04:28:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/25/2022 04:28:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/25/2022 04:28:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/25/2022 04:29:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=156
06/25/2022 04:29:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/25/2022 04:29:10 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7939945949054108 on epoch=157
06/25/2022 04:29:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/25/2022 04:29:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/25/2022 04:29:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/25/2022 04:29:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/25/2022 04:29:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/25/2022 04:29:30 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6661681329423266 on epoch=160
06/25/2022 04:29:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/25/2022 04:29:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/25/2022 04:29:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/25/2022 04:29:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/25/2022 04:29:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/25/2022 04:29:51 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7533594004561747 on epoch=164
06/25/2022 04:29:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/25/2022 04:29:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/25/2022 04:29:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/25/2022 04:30:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/25/2022 04:30:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/25/2022 04:30:11 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7976746593065379 on epoch=167
06/25/2022 04:30:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/25/2022 04:30:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/25/2022 04:30:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=169
06/25/2022 04:30:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/25/2022 04:30:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/25/2022 04:30:32 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8005705869083478 on epoch=171
06/25/2022 04:30:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/25/2022 04:30:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/25/2022 04:30:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/25/2022 04:30:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/25/2022 04:30:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/25/2022 04:30:52 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8608626588465298 on epoch=174
06/25/2022 04:30:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8475623311587623 -> 0.8608626588465298 on epoch=174, global_step=2450
06/25/2022 04:30:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/25/2022 04:30:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/25/2022 04:31:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/25/2022 04:31:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/25/2022 04:31:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/25/2022 04:31:13 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7471758255769476 on epoch=178
06/25/2022 04:31:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/25/2022 04:31:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
06/25/2022 04:31:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/25/2022 04:31:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/25/2022 04:31:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/25/2022 04:31:33 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.8057418861972941 on epoch=182
06/25/2022 04:31:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/25/2022 04:31:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/25/2022 04:31:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/25/2022 04:31:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=184
06/25/2022 04:31:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/25/2022 04:31:53 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8057418861972941 on epoch=185
06/25/2022 04:31:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/25/2022 04:31:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/25/2022 04:32:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/25/2022 04:32:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/25/2022 04:32:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/25/2022 04:32:13 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7609784480752223 on epoch=189
06/25/2022 04:32:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/25/2022 04:32:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/25/2022 04:32:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/25/2022 04:32:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/25/2022 04:32:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/25/2022 04:32:34 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.810223678914381 on epoch=192
06/25/2022 04:32:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/25/2022 04:32:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/25/2022 04:32:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/25/2022 04:32:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
06/25/2022 04:32:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/25/2022 04:32:54 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8080600548440633 on epoch=196
06/25/2022 04:32:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/25/2022 04:32:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/25/2022 04:33:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/25/2022 04:33:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/25/2022 04:33:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/25/2022 04:33:14 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7526188268123752 on epoch=199
06/25/2022 04:33:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/25/2022 04:33:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/25/2022 04:33:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/25/2022 04:33:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/25/2022 04:33:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/25/2022 04:33:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=203
06/25/2022 04:33:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8608626588465298 -> 0.9226979472140762 on epoch=203, global_step=2850
06/25/2022 04:33:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/25/2022 04:33:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=204
06/25/2022 04:33:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/25/2022 04:33:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/25/2022 04:33:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/25/2022 04:33:54 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8608626588465298 on epoch=207
06/25/2022 04:33:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/25/2022 04:34:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/25/2022 04:34:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/25/2022 04:34:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/25/2022 04:34:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/25/2022 04:34:14 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8608626588465298 on epoch=210
06/25/2022 04:34:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/25/2022 04:34:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/25/2022 04:34:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/25/2022 04:34:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/25/2022 04:34:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/25/2022 04:34:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:34:29 - INFO - __main__ - Printing 3 examples
06/25/2022 04:34:29 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 04:34:29 - INFO - __main__ - ['Film']
06/25/2022 04:34:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 04:34:29 - INFO - __main__ - ['Film']
06/25/2022 04:34:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 04:34:29 - INFO - __main__ - ['Film']
06/25/2022 04:34:29 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:34:29 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:34:30 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 04:34:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:34:30 - INFO - __main__ - Printing 3 examples
06/25/2022 04:34:30 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 04:34:30 - INFO - __main__ - ['Film']
06/25/2022 04:34:30 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 04:34:30 - INFO - __main__ - ['Film']
06/25/2022 04:34:30 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 04:34:30 - INFO - __main__ - ['Film']
06/25/2022 04:34:30 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:34:30 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:34:30 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 04:34:35 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9226979472140762 on epoch=214
06/25/2022 04:34:35 - INFO - __main__ - save last model!
06/25/2022 04:34:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 04:34:35 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 04:34:35 - INFO - __main__ - Printing 3 examples
06/25/2022 04:34:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 04:34:35 - INFO - __main__ - ['Animal']
06/25/2022 04:34:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 04:34:35 - INFO - __main__ - ['Animal']
06/25/2022 04:34:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 04:34:35 - INFO - __main__ - ['Village']
06/25/2022 04:34:35 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:34:37 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:34:40 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 04:34:49 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 04:34:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 04:34:50 - INFO - __main__ - Starting training!
06/25/2022 04:36:55 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/25/2022 04:36:55 - INFO - __main__ - Classification-F1 on test data: 0.5466
06/25/2022 04:36:56 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9226979472140762, test_performance=0.5466386744168896
06/25/2022 04:36:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/25/2022 04:36:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:36:57 - INFO - __main__ - Printing 3 examples
06/25/2022 04:36:57 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/25/2022 04:36:57 - INFO - __main__ - ['Film']
06/25/2022 04:36:57 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/25/2022 04:36:57 - INFO - __main__ - ['Film']
06/25/2022 04:36:57 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/25/2022 04:36:57 - INFO - __main__ - ['Film']
06/25/2022 04:36:57 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:36:57 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:36:57 - INFO - __main__ - Loaded 224 examples from train data
06/25/2022 04:36:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/25/2022 04:36:57 - INFO - __main__ - Printing 3 examples
06/25/2022 04:36:57 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/25/2022 04:36:57 - INFO - __main__ - ['Film']
06/25/2022 04:36:57 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/25/2022 04:36:57 - INFO - __main__ - ['Film']
06/25/2022 04:36:57 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/25/2022 04:36:57 - INFO - __main__ - ['Film']
06/25/2022 04:36:57 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:36:57 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:36:57 - INFO - __main__ - Loaded 224 examples from dev data
06/25/2022 04:37:16 - INFO - __main__ - load prompt embedding from ckpt
06/25/2022 04:37:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/25/2022 04:37:17 - INFO - __main__ - Starting training!
06/25/2022 04:37:21 - INFO - __main__ - Step 10 Global step 10 Train loss 7.42 on epoch=0
06/25/2022 04:37:23 - INFO - __main__ - Step 20 Global step 20 Train loss 6.01 on epoch=1
06/25/2022 04:37:26 - INFO - __main__ - Step 30 Global step 30 Train loss 5.09 on epoch=2
06/25/2022 04:37:29 - INFO - __main__ - Step 40 Global step 40 Train loss 4.44 on epoch=2
06/25/2022 04:37:31 - INFO - __main__ - Step 50 Global step 50 Train loss 4.87 on epoch=3
06/25/2022 04:37:38 - INFO - __main__ - Global step 50 Train loss 5.57 Classification-F1 0.041227863046044866 on epoch=3
06/25/2022 04:37:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.041227863046044866 on epoch=3, global_step=50
06/25/2022 04:37:41 - INFO - __main__ - Step 60 Global step 60 Train loss 4.42 on epoch=4
06/25/2022 04:37:43 - INFO - __main__ - Step 70 Global step 70 Train loss 3.65 on epoch=4
06/25/2022 04:37:46 - INFO - __main__ - Step 80 Global step 80 Train loss 3.99 on epoch=5
06/25/2022 04:37:49 - INFO - __main__ - Step 90 Global step 90 Train loss 3.50 on epoch=6
06/25/2022 04:37:51 - INFO - __main__ - Step 100 Global step 100 Train loss 3.40 on epoch=7
06/25/2022 04:37:56 - INFO - __main__ - Global step 100 Train loss 3.79 Classification-F1 0.05414154472978002 on epoch=7
06/25/2022 04:37:56 - INFO - __main__ - Saving model with best Classification-F1: 0.041227863046044866 -> 0.05414154472978002 on epoch=7, global_step=100
06/25/2022 04:37:59 - INFO - __main__ - Step 110 Global step 110 Train loss 3.01 on epoch=7
06/25/2022 04:38:02 - INFO - __main__ - Step 120 Global step 120 Train loss 3.14 on epoch=8
06/25/2022 04:38:04 - INFO - __main__ - Step 130 Global step 130 Train loss 3.02 on epoch=9
06/25/2022 04:38:07 - INFO - __main__ - Step 140 Global step 140 Train loss 2.80 on epoch=9
06/25/2022 04:38:10 - INFO - __main__ - Step 150 Global step 150 Train loss 3.01 on epoch=10
06/25/2022 04:38:15 - INFO - __main__ - Global step 150 Train loss 3.00 Classification-F1 0.0780171509361063 on epoch=10
06/25/2022 04:38:15 - INFO - __main__ - Saving model with best Classification-F1: 0.05414154472978002 -> 0.0780171509361063 on epoch=10, global_step=150
06/25/2022 04:38:18 - INFO - __main__ - Step 160 Global step 160 Train loss 2.62 on epoch=11
06/25/2022 04:38:20 - INFO - __main__ - Step 170 Global step 170 Train loss 2.60 on epoch=12
06/25/2022 04:38:23 - INFO - __main__ - Step 180 Global step 180 Train loss 2.23 on epoch=12
06/25/2022 04:38:26 - INFO - __main__ - Step 190 Global step 190 Train loss 2.45 on epoch=13
06/25/2022 04:38:28 - INFO - __main__ - Step 200 Global step 200 Train loss 2.29 on epoch=14
06/25/2022 04:38:34 - INFO - __main__ - Global step 200 Train loss 2.44 Classification-F1 0.08842318635665411 on epoch=14
06/25/2022 04:38:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0780171509361063 -> 0.08842318635665411 on epoch=14, global_step=200
06/25/2022 04:38:37 - INFO - __main__ - Step 210 Global step 210 Train loss 1.99 on epoch=14
06/25/2022 04:38:39 - INFO - __main__ - Step 220 Global step 220 Train loss 2.41 on epoch=15
06/25/2022 04:38:42 - INFO - __main__ - Step 230 Global step 230 Train loss 2.01 on epoch=16
06/25/2022 04:38:45 - INFO - __main__ - Step 240 Global step 240 Train loss 2.00 on epoch=17
06/25/2022 04:38:47 - INFO - __main__ - Step 250 Global step 250 Train loss 1.70 on epoch=17
06/25/2022 04:38:53 - INFO - __main__ - Global step 250 Train loss 2.02 Classification-F1 0.11750191142849652 on epoch=17
06/25/2022 04:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.08842318635665411 -> 0.11750191142849652 on epoch=17, global_step=250
06/25/2022 04:38:56 - INFO - __main__ - Step 260 Global step 260 Train loss 1.92 on epoch=18
06/25/2022 04:38:59 - INFO - __main__ - Step 270 Global step 270 Train loss 1.84 on epoch=19
06/25/2022 04:39:01 - INFO - __main__ - Step 280 Global step 280 Train loss 1.63 on epoch=19
06/25/2022 04:39:04 - INFO - __main__ - Step 290 Global step 290 Train loss 1.82 on epoch=20
06/25/2022 04:39:07 - INFO - __main__ - Step 300 Global step 300 Train loss 1.63 on epoch=21
06/25/2022 04:39:13 - INFO - __main__ - Global step 300 Train loss 1.77 Classification-F1 0.12026445699276624 on epoch=21
06/25/2022 04:39:13 - INFO - __main__ - Saving model with best Classification-F1: 0.11750191142849652 -> 0.12026445699276624 on epoch=21, global_step=300
06/25/2022 04:39:15 - INFO - __main__ - Step 310 Global step 310 Train loss 1.58 on epoch=22
06/25/2022 04:39:18 - INFO - __main__ - Step 320 Global step 320 Train loss 1.40 on epoch=22
06/25/2022 04:39:21 - INFO - __main__ - Step 330 Global step 330 Train loss 1.47 on epoch=23
06/25/2022 04:39:23 - INFO - __main__ - Step 340 Global step 340 Train loss 1.47 on epoch=24
06/25/2022 04:39:26 - INFO - __main__ - Step 350 Global step 350 Train loss 1.25 on epoch=24
06/25/2022 04:39:32 - INFO - __main__ - Global step 350 Train loss 1.43 Classification-F1 0.1379983828004972 on epoch=24
06/25/2022 04:39:32 - INFO - __main__ - Saving model with best Classification-F1: 0.12026445699276624 -> 0.1379983828004972 on epoch=24, global_step=350
06/25/2022 04:39:35 - INFO - __main__ - Step 360 Global step 360 Train loss 1.39 on epoch=25
06/25/2022 04:39:37 - INFO - __main__ - Step 370 Global step 370 Train loss 1.29 on epoch=26
06/25/2022 04:39:40 - INFO - __main__ - Step 380 Global step 380 Train loss 1.26 on epoch=27
06/25/2022 04:39:43 - INFO - __main__ - Step 390 Global step 390 Train loss 1.03 on epoch=27
06/25/2022 04:39:45 - INFO - __main__ - Step 400 Global step 400 Train loss 1.21 on epoch=28
06/25/2022 04:39:52 - INFO - __main__ - Global step 400 Train loss 1.23 Classification-F1 0.17469815602243446 on epoch=28
06/25/2022 04:39:52 - INFO - __main__ - Saving model with best Classification-F1: 0.1379983828004972 -> 0.17469815602243446 on epoch=28, global_step=400
06/25/2022 04:39:54 - INFO - __main__ - Step 410 Global step 410 Train loss 1.20 on epoch=29
06/25/2022 04:39:57 - INFO - __main__ - Step 420 Global step 420 Train loss 1.08 on epoch=29
06/25/2022 04:40:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.96 on epoch=30
06/25/2022 04:40:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.92 on epoch=31
06/25/2022 04:40:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.93 on epoch=32
06/25/2022 04:40:11 - INFO - __main__ - Global step 450 Train loss 1.02 Classification-F1 0.29634033647916597 on epoch=32
06/25/2022 04:40:12 - INFO - __main__ - Saving model with best Classification-F1: 0.17469815602243446 -> 0.29634033647916597 on epoch=32, global_step=450
06/25/2022 04:40:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.82 on epoch=32
06/25/2022 04:40:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.89 on epoch=33
06/25/2022 04:40:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.86 on epoch=34
06/25/2022 04:40:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.79 on epoch=34
06/25/2022 04:40:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.85 on epoch=35
06/25/2022 04:40:32 - INFO - __main__ - Global step 500 Train loss 0.84 Classification-F1 0.345675351336582 on epoch=35
06/25/2022 04:40:32 - INFO - __main__ - Saving model with best Classification-F1: 0.29634033647916597 -> 0.345675351336582 on epoch=35, global_step=500
06/25/2022 04:40:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.78 on epoch=36
06/25/2022 04:40:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.73 on epoch=37
06/25/2022 04:40:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.64 on epoch=37
06/25/2022 04:40:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.63 on epoch=38
06/25/2022 04:40:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.74 on epoch=39
06/25/2022 04:40:52 - INFO - __main__ - Global step 550 Train loss 0.70 Classification-F1 0.4308254571518317 on epoch=39
06/25/2022 04:40:52 - INFO - __main__ - Saving model with best Classification-F1: 0.345675351336582 -> 0.4308254571518317 on epoch=39, global_step=550
06/25/2022 04:40:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.64 on epoch=39
06/25/2022 04:40:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.63 on epoch=40
06/25/2022 04:41:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.63 on epoch=41
06/25/2022 04:41:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.67 on epoch=42
06/25/2022 04:41:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=42
06/25/2022 04:41:13 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.41477527512269746 on epoch=42
06/25/2022 04:41:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.61 on epoch=43
06/25/2022 04:41:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=44
06/25/2022 04:41:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.58 on epoch=44
06/25/2022 04:41:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=45
06/25/2022 04:41:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.58 on epoch=46
06/25/2022 04:41:33 - INFO - __main__ - Global step 650 Train loss 0.56 Classification-F1 0.5415062905048207 on epoch=46
06/25/2022 04:41:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4308254571518317 -> 0.5415062905048207 on epoch=46, global_step=650
06/25/2022 04:41:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.48 on epoch=47
06/25/2022 04:41:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.54 on epoch=47
06/25/2022 04:41:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.45 on epoch=48
06/25/2022 04:41:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.47 on epoch=49
06/25/2022 04:41:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.51 on epoch=49
06/25/2022 04:41:54 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.6310849521236642 on epoch=49
06/25/2022 04:41:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5415062905048207 -> 0.6310849521236642 on epoch=49, global_step=700
06/25/2022 04:41:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.52 on epoch=50
06/25/2022 04:42:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=51
06/25/2022 04:42:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.46 on epoch=52
06/25/2022 04:42:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.45 on epoch=52
06/25/2022 04:42:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=53
06/25/2022 04:42:16 - INFO - __main__ - Global step 750 Train loss 0.46 Classification-F1 0.5705463512117371 on epoch=53
06/25/2022 04:42:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.40 on epoch=54
06/25/2022 04:42:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.44 on epoch=54
06/25/2022 04:42:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.38 on epoch=55
06/25/2022 04:42:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=56
06/25/2022 04:42:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.46 on epoch=57
06/25/2022 04:42:36 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.7623376033887094 on epoch=57
06/25/2022 04:42:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6310849521236642 -> 0.7623376033887094 on epoch=57, global_step=800
06/25/2022 04:42:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=57
06/25/2022 04:42:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.40 on epoch=58
06/25/2022 04:42:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=59
06/25/2022 04:42:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.36 on epoch=59
06/25/2022 04:42:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.42 on epoch=60
06/25/2022 04:42:57 - INFO - __main__ - Global step 850 Train loss 0.38 Classification-F1 0.7169319852787596 on epoch=60
06/25/2022 04:43:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.38 on epoch=61
06/25/2022 04:43:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
06/25/2022 04:43:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.38 on epoch=62
06/25/2022 04:43:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=63
06/25/2022 04:43:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.33 on epoch=64
06/25/2022 04:43:18 - INFO - __main__ - Global step 900 Train loss 0.35 Classification-F1 0.8100866875060424 on epoch=64
06/25/2022 04:43:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7623376033887094 -> 0.8100866875060424 on epoch=64, global_step=900
06/25/2022 04:43:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.49 on epoch=64
06/25/2022 04:43:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.42 on epoch=65
06/25/2022 04:43:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.33 on epoch=66
06/25/2022 04:43:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=67
06/25/2022 04:43:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=67
06/25/2022 04:43:39 - INFO - __main__ - Global step 950 Train loss 0.36 Classification-F1 0.7587353450954301 on epoch=67
06/25/2022 04:43:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.35 on epoch=68
06/25/2022 04:43:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.39 on epoch=69
06/25/2022 04:43:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=69
06/25/2022 04:43:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.37 on epoch=70
06/25/2022 04:43:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=71
06/25/2022 04:43:59 - INFO - __main__ - Global step 1000 Train loss 0.36 Classification-F1 0.8510997624628975 on epoch=71
06/25/2022 04:43:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8100866875060424 -> 0.8510997624628975 on epoch=71, global_step=1000
06/25/2022 04:44:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=72
06/25/2022 04:44:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.32 on epoch=72
06/25/2022 04:44:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.37 on epoch=73
06/25/2022 04:44:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
06/25/2022 04:44:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=74
06/25/2022 04:44:20 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.8681844947167529 on epoch=74
06/25/2022 04:44:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8510997624628975 -> 0.8681844947167529 on epoch=74, global_step=1050
06/25/2022 04:44:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.27 on epoch=75
06/25/2022 04:44:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/25/2022 04:44:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=77
06/25/2022 04:44:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
06/25/2022 04:44:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/25/2022 04:44:41 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.8724945305590469 on epoch=78
06/25/2022 04:44:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8681844947167529 -> 0.8724945305590469 on epoch=78, global_step=1100
06/25/2022 04:44:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=79
06/25/2022 04:44:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.26 on epoch=79
06/25/2022 04:44:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.27 on epoch=80
06/25/2022 04:44:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/25/2022 04:44:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=82
06/25/2022 04:45:02 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.8825811759398098 on epoch=82
06/25/2022 04:45:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8724945305590469 -> 0.8825811759398098 on epoch=82, global_step=1150
06/25/2022 04:45:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/25/2022 04:45:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.31 on epoch=83
06/25/2022 04:45:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=84
06/25/2022 04:45:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.31 on epoch=84
06/25/2022 04:45:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.22 on epoch=85
06/25/2022 04:45:23 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.8666956782485665 on epoch=85
06/25/2022 04:45:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/25/2022 04:45:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=87
06/25/2022 04:45:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=87
06/25/2022 04:45:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.25 on epoch=88
06/25/2022 04:45:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=89
06/25/2022 04:45:44 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.7966751274787456 on epoch=89
06/25/2022 04:45:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.25 on epoch=89
06/25/2022 04:45:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=90
06/25/2022 04:45:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.24 on epoch=91
06/25/2022 04:45:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=92
06/25/2022 04:45:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=92
06/25/2022 04:46:05 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.8475623311587623 on epoch=92
06/25/2022 04:46:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.26 on epoch=93
06/25/2022 04:46:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.22 on epoch=94
06/25/2022 04:46:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=94
06/25/2022 04:46:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=95
06/25/2022 04:46:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.25 on epoch=96
06/25/2022 04:46:26 - INFO - __main__ - Global step 1350 Train loss 0.23 Classification-F1 0.7916085048415431 on epoch=96
06/25/2022 04:46:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=97
06/25/2022 04:46:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
06/25/2022 04:46:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=98
06/25/2022 04:46:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
06/25/2022 04:46:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.22 on epoch=99
06/25/2022 04:46:47 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.7925773748552789 on epoch=99
06/25/2022 04:46:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=100
06/25/2022 04:46:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.28 on epoch=101
06/25/2022 04:46:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.23 on epoch=102
06/25/2022 04:46:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=102
06/25/2022 04:47:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.24 on epoch=103
06/25/2022 04:47:07 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.788532897826931 on epoch=103
06/25/2022 04:47:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/25/2022 04:47:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.24 on epoch=104
06/25/2022 04:47:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
06/25/2022 04:47:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.20 on epoch=106
06/25/2022 04:47:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
06/25/2022 04:47:28 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.7925735564290814 on epoch=107
06/25/2022 04:47:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=107
06/25/2022 04:47:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=108
06/25/2022 04:47:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.21 on epoch=109
06/25/2022 04:47:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=109
06/25/2022 04:47:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.22 on epoch=110
06/25/2022 04:47:49 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.7390731079891599 on epoch=110
06/25/2022 04:47:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.20 on epoch=111
06/25/2022 04:47:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=112
06/25/2022 04:47:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=112
06/25/2022 04:47:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
06/25/2022 04:48:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=114
06/25/2022 04:48:09 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.741184137389071 on epoch=114
06/25/2022 04:48:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=114
06/25/2022 04:48:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.18 on epoch=115
06/25/2022 04:48:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=116
06/25/2022 04:48:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.22 on epoch=117
06/25/2022 04:48:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.16 on epoch=117
06/25/2022 04:48:30 - INFO - __main__ - Global step 1650 Train loss 0.18 Classification-F1 0.7320509742549276 on epoch=117
06/25/2022 04:48:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
06/25/2022 04:48:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
06/25/2022 04:48:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/25/2022 04:48:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
06/25/2022 04:48:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=121
06/25/2022 04:48:51 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.7292904488573649 on epoch=121
06/25/2022 04:48:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.19 on epoch=122
06/25/2022 04:48:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=122
06/25/2022 04:48:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.23 on epoch=123
06/25/2022 04:49:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/25/2022 04:49:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/25/2022 04:49:11 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.7777147885456213 on epoch=124
06/25/2022 04:49:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/25/2022 04:49:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.22 on epoch=126
06/25/2022 04:49:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/25/2022 04:49:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
06/25/2022 04:49:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.19 on epoch=128
06/25/2022 04:49:32 - INFO - __main__ - Global step 1800 Train loss 0.16 Classification-F1 0.7338653426434963 on epoch=128
06/25/2022 04:49:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=129
06/25/2022 04:49:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
06/25/2022 04:49:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/25/2022 04:49:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
06/25/2022 04:49:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=132
06/25/2022 04:49:52 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.6942130457472708 on epoch=132
06/25/2022 04:49:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/25/2022 04:49:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/25/2022 04:50:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.15 on epoch=134
06/25/2022 04:50:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=134
06/25/2022 04:50:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/25/2022 04:50:13 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.6676718401276477 on epoch=135
06/25/2022 04:50:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
06/25/2022 04:50:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
06/25/2022 04:50:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/25/2022 04:50:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=138
06/25/2022 04:50:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/25/2022 04:50:34 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.6287612544847443 on epoch=139
06/25/2022 04:50:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.16 on epoch=139
06/25/2022 04:50:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=140
06/25/2022 04:50:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.14 on epoch=141
06/25/2022 04:50:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/25/2022 04:50:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=142
06/25/2022 04:50:55 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.6716010545831779 on epoch=142
06/25/2022 04:50:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
06/25/2022 04:51:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/25/2022 04:51:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=144
06/25/2022 04:51:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/25/2022 04:51:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/25/2022 04:51:15 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.6362929101259273 on epoch=146
06/25/2022 04:51:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/25/2022 04:51:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
06/25/2022 04:51:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=148
06/25/2022 04:51:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=149
06/25/2022 04:51:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.14 on epoch=149
06/25/2022 04:51:36 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.6948641561544788 on epoch=149
06/25/2022 04:51:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
06/25/2022 04:51:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=151
06/25/2022 04:51:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/25/2022 04:51:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=152
06/25/2022 04:51:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=153
06/25/2022 04:51:57 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.6699882648948863 on epoch=153
06/25/2022 04:52:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.17 on epoch=154
06/25/2022 04:52:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.13 on epoch=154
06/25/2022 04:52:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/25/2022 04:52:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=156
06/25/2022 04:52:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=157
06/25/2022 04:52:18 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.6725043590518474 on epoch=157
06/25/2022 04:52:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=157
06/25/2022 04:52:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/25/2022 04:52:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.13 on epoch=159
06/25/2022 04:52:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=159
06/25/2022 04:52:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
06/25/2022 04:52:39 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.7156754436324329 on epoch=160
06/25/2022 04:52:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
06/25/2022 04:52:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/25/2022 04:52:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
06/25/2022 04:52:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/25/2022 04:52:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.13 on epoch=164
06/25/2022 04:53:00 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.6730728995584684 on epoch=164
06/25/2022 04:53:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=164
06/25/2022 04:53:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/25/2022 04:53:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/25/2022 04:53:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/25/2022 04:53:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/25/2022 04:53:21 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.6811214108527601 on epoch=167
06/25/2022 04:53:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
06/25/2022 04:53:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/25/2022 04:53:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=169
06/25/2022 04:53:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/25/2022 04:53:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=171
06/25/2022 04:53:41 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.7194626895249419 on epoch=171
06/25/2022 04:53:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/25/2022 04:53:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/25/2022 04:53:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/25/2022 04:53:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=174
06/25/2022 04:53:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/25/2022 04:54:02 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.6827533138339618 on epoch=174
06/25/2022 04:54:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/25/2022 04:54:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
06/25/2022 04:54:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/25/2022 04:54:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/25/2022 04:54:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=178
06/25/2022 04:54:22 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.8329126518642648 on epoch=178
06/25/2022 04:54:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=179
06/25/2022 04:54:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=179
06/25/2022 04:54:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=180
06/25/2022 04:54:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/25/2022 04:54:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/25/2022 04:54:43 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.7886368540861229 on epoch=182
06/25/2022 04:54:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/25/2022 04:54:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
06/25/2022 04:54:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.15 on epoch=184
06/25/2022 04:54:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/25/2022 04:54:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=185
06/25/2022 04:55:03 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.7968905225072208 on epoch=185
06/25/2022 04:55:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/25/2022 04:55:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/25/2022 04:55:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/25/2022 04:55:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=188
06/25/2022 04:55:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=189
06/25/2022 04:55:24 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.806543614513254 on epoch=189
06/25/2022 04:55:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=189
06/25/2022 04:55:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/25/2022 04:55:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=191
06/25/2022 04:55:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=192
06/25/2022 04:55:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/25/2022 04:55:45 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.8569525904203323 on epoch=192
06/25/2022 04:55:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/25/2022 04:55:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/25/2022 04:55:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=194
06/25/2022 04:55:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/25/2022 04:55:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/25/2022 04:56:05 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.7596922131961065 on epoch=196
06/25/2022 04:56:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=197
06/25/2022 04:56:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/25/2022 04:56:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=198
06/25/2022 04:56:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/25/2022 04:56:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.11 on epoch=199
06/25/2022 04:56:25 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.7631678295749487 on epoch=199
06/25/2022 04:56:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/25/2022 04:56:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=201
06/25/2022 04:56:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=202
06/25/2022 04:56:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/25/2022 04:56:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/25/2022 04:56:46 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.810223678914381 on epoch=203
06/25/2022 04:56:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/25/2022 04:56:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/25/2022 04:56:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/25/2022 04:56:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
06/25/2022 04:57:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/25/2022 04:57:08 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.8043799904429363 on epoch=207
06/25/2022 04:57:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/25/2022 04:57:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/25/2022 04:57:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/25/2022 04:57:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.13 on epoch=209
06/25/2022 04:57:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/25/2022 04:57:28 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.806543614513254 on epoch=210
06/25/2022 04:57:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.13 on epoch=211
06/25/2022 04:57:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=212
06/25/2022 04:57:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/25/2022 04:57:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=213
06/25/2022 04:57:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/25/2022 04:57:48 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.7598240469208211 on epoch=214
06/25/2022 04:57:48 - INFO - __main__ - save last model!
06/25/2022 04:57:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/25/2022 04:57:48 - INFO - __main__ - Start tokenizing ... 3500 instances
06/25/2022 04:57:48 - INFO - __main__ - Printing 3 examples
06/25/2022 04:57:48 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/25/2022 04:57:48 - INFO - __main__ - ['Animal']
06/25/2022 04:57:48 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/25/2022 04:57:48 - INFO - __main__ - ['Animal']
06/25/2022 04:57:48 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/25/2022 04:57:48 - INFO - __main__ - ['Village']
06/25/2022 04:57:48 - INFO - __main__ - Tokenizing Input ...
06/25/2022 04:57:50 - INFO - __main__ - Tokenizing Output ...
06/25/2022 04:57:54 - INFO - __main__ - Loaded 3500 examples from test data
06/25/2022 05:00:03 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-3-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/25/2022 05:00:03 - INFO - __main__ - Classification-F1 on test data: 0.4526
06/25/2022 05:00:03 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.8825811759398098, test_performance=0.45261208543589504
