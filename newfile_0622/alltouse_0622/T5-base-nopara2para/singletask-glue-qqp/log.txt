05/15/2022 18:54:48 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-nopara2para', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-nopara2para/singletask-glue-qqp', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/glue-qqp/', task_name='glue-qqp', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
05/15/2022 18:54:48 - INFO - __main__ - models/T5-large-nopara2para/singletask-glue-qqp
06/24/2022 05:52:52 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-nopara2para', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-nopara2para/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
06/24/2022 05:52:53 - INFO - __main__ - models/T5-base-nopara2para/singletask-glue-qqp
06/24/2022 05:52:53 - INFO - __main__ - Namespace(task_dir='data/glue-qqp/', task_name='glue-qqp', identifier='T5-base-nopara2para', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-nopara2para/singletask-glue-qqp', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
06/24/2022 05:52:53 - INFO - __main__ - models/T5-base-nopara2para/singletask-glue-qqp
06/24/2022 05:52:53 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/24/2022 05:52:53 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/24/2022 05:52:53 - INFO - __main__ - args.device: cuda:0
06/24/2022 05:52:53 - INFO - __main__ - args.device: cuda:1
06/24/2022 05:52:53 - INFO - __main__ - Using 2 gpus
06/24/2022 05:52:53 - INFO - __main__ - Using 2 gpus
06/24/2022 05:52:53 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/24/2022 05:52:53 - INFO - __main__ - Fine-tuning the following samples: ['glue-qqp_16_100', 'glue-qqp_16_13', 'glue-qqp_16_21', 'glue-qqp_16_42', 'glue-qqp_16_87']
06/24/2022 05:52:58 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.5, bsz=8 ...
06/24/2022 05:52:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 05:52:59 - INFO - __main__ - Printing 3 examples
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:52:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 05:52:59 - INFO - __main__ - Printing 3 examples
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:52:59 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 05:52:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 05:52:59 - INFO - __main__ - Printing 3 examples
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:52:59 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 05:52:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 05:52:59 - INFO - __main__ - Printing 3 examples
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:52:59 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 05:52:59 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:52:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:52:59 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 05:52:59 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 05:53:05 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 05:53:05 - INFO - __main__ - task name: glue-qqp
06/24/2022 05:53:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 05:53:05 - INFO - __main__ - Starting training!
06/24/2022 05:53:05 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 05:53:05 - INFO - __main__ - task name: glue-qqp
06/24/2022 05:53:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 05:53:06 - INFO - __main__ - Starting training!
06/24/2022 05:53:07 - INFO - __main__ - Step 10 Global step 10 Train loss 5.26 on epoch=4
06/24/2022 05:53:09 - INFO - __main__ - Step 20 Global step 20 Train loss 1.45 on epoch=9
06/24/2022 05:53:10 - INFO - __main__ - Step 30 Global step 30 Train loss 0.68 on epoch=14
06/24/2022 05:53:11 - INFO - __main__ - Step 40 Global step 40 Train loss 0.50 on epoch=19
06/24/2022 05:53:13 - INFO - __main__ - Step 50 Global step 50 Train loss 0.46 on epoch=24
06/24/2022 05:53:13 - INFO - __main__ - Global step 50 Train loss 1.67 ACC 0.46875 on epoch=24
06/24/2022 05:53:13 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
06/24/2022 05:53:15 - INFO - __main__ - Step 60 Global step 60 Train loss 0.37 on epoch=29
06/24/2022 05:53:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.35 on epoch=34
06/24/2022 05:53:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.34 on epoch=39
06/24/2022 05:53:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=44
06/24/2022 05:53:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.35 on epoch=49
06/24/2022 05:53:20 - INFO - __main__ - Global step 100 Train loss 0.34 ACC 0.5 on epoch=49
06/24/2022 05:53:21 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=49, global_step=100
06/24/2022 05:53:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=54
06/24/2022 05:53:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=59
06/24/2022 05:53:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=64
06/24/2022 05:53:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.30 on epoch=69
06/24/2022 05:53:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.27 on epoch=74
06/24/2022 05:53:27 - INFO - __main__ - Global step 150 Train loss 0.30 ACC 0.53125 on epoch=74
06/24/2022 05:53:27 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=74, global_step=150
06/24/2022 05:53:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.25 on epoch=79
06/24/2022 05:53:30 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=84
06/24/2022 05:53:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.23 on epoch=89
06/24/2022 05:53:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=94
06/24/2022 05:53:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=99
06/24/2022 05:53:34 - INFO - __main__ - Global step 200 Train loss 0.27 ACC 0.5 on epoch=99
06/24/2022 05:53:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.32 on epoch=104
06/24/2022 05:53:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=109
06/24/2022 05:53:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=114
06/24/2022 05:53:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=119
06/24/2022 05:53:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=124
06/24/2022 05:53:41 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.5 on epoch=124
06/24/2022 05:53:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.25 on epoch=129
06/24/2022 05:53:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=134
06/24/2022 05:53:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=139
06/24/2022 05:53:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=144
06/24/2022 05:53:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=149
06/24/2022 05:53:48 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5 on epoch=149
06/24/2022 05:53:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 05:53:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/24/2022 05:53:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=164
06/24/2022 05:53:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/24/2022 05:53:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=174
06/24/2022 05:53:55 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.5 on epoch=174
06/24/2022 05:53:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=179
06/24/2022 05:53:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=184
06/24/2022 05:53:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 05:54:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=194
06/24/2022 05:54:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=199
06/24/2022 05:54:02 - INFO - __main__ - Global step 400 Train loss 0.25 ACC 0.5 on epoch=199
06/24/2022 05:54:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=204
06/24/2022 05:54:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=209
06/24/2022 05:54:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=214
06/24/2022 05:54:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=219
06/24/2022 05:54:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=224
06/24/2022 05:54:09 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.46875 on epoch=224
06/24/2022 05:54:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=229
06/24/2022 05:54:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=234
06/24/2022 05:54:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=239
06/24/2022 05:54:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=244
06/24/2022 05:54:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=249
06/24/2022 05:54:16 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/24/2022 05:54:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=254
06/24/2022 05:54:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=259
06/24/2022 05:54:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 05:54:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=269
06/24/2022 05:54:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=274
06/24/2022 05:54:23 - INFO - __main__ - Global step 550 Train loss 0.22 ACC 0.4375 on epoch=274
06/24/2022 05:54:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=279
06/24/2022 05:54:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=284
06/24/2022 05:54:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=289
06/24/2022 05:54:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=294
06/24/2022 05:54:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=299
06/24/2022 05:54:30 - INFO - __main__ - Global step 600 Train loss 0.22 ACC 0.5 on epoch=299
06/24/2022 05:54:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=304
06/24/2022 05:54:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=309
06/24/2022 05:54:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=314
06/24/2022 05:54:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=319
06/24/2022 05:54:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=324
06/24/2022 05:54:37 - INFO - __main__ - Global step 650 Train loss 0.22 ACC 0.4375 on epoch=324
06/24/2022 05:54:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=329
06/24/2022 05:54:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=334
06/24/2022 05:54:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=339
06/24/2022 05:54:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=344
06/24/2022 05:54:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=349
06/24/2022 05:54:44 - INFO - __main__ - Global step 700 Train loss 0.22 ACC 0.40625 on epoch=349
06/24/2022 05:54:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=354
06/24/2022 05:54:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=359
06/24/2022 05:54:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=364
06/24/2022 05:54:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=369
06/24/2022 05:54:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=374
06/24/2022 05:54:51 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.4375 on epoch=374
06/24/2022 05:54:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=379
06/24/2022 05:54:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=384
06/24/2022 05:54:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=389
06/24/2022 05:54:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=394
06/24/2022 05:54:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=399
06/24/2022 05:54:58 - INFO - __main__ - Global step 800 Train loss 0.22 ACC 0.5 on epoch=399
06/24/2022 05:54:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=404
06/24/2022 05:55:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=409
06/24/2022 05:55:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=414
06/24/2022 05:55:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=419
06/24/2022 05:55:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=424
06/24/2022 05:55:05 - INFO - __main__ - Global step 850 Train loss 0.21 ACC 0.46875 on epoch=424
06/24/2022 05:55:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=429
06/24/2022 05:55:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=434
06/24/2022 05:55:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=439
06/24/2022 05:55:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=444
06/24/2022 05:55:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=449
06/24/2022 05:55:12 - INFO - __main__ - Global step 900 Train loss 0.20 ACC 0.46875 on epoch=449
06/24/2022 05:55:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=454
06/24/2022 05:55:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=459
06/24/2022 05:55:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=464
06/24/2022 05:55:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=469
06/24/2022 05:55:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=474
06/24/2022 05:55:19 - INFO - __main__ - Global step 950 Train loss 0.20 ACC 0.40625 on epoch=474
06/24/2022 05:55:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=479
06/24/2022 05:55:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=484
06/24/2022 05:55:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=489
06/24/2022 05:55:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=494
06/24/2022 05:55:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=499
06/24/2022 05:55:26 - INFO - __main__ - Global step 1000 Train loss 0.17 ACC 0.4375 on epoch=499
06/24/2022 05:55:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=504
06/24/2022 05:55:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=509
06/24/2022 05:55:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=514
06/24/2022 05:55:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=519
06/24/2022 05:55:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=524
06/24/2022 05:55:33 - INFO - __main__ - Global step 1050 Train loss 0.18 ACC 0.46875 on epoch=524
06/24/2022 05:55:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=529
06/24/2022 05:55:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.00 on epoch=534
06/24/2022 05:55:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.86 on epoch=539
06/24/2022 05:55:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.94 on epoch=544
06/24/2022 05:55:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.65 on epoch=549
06/24/2022 05:55:39 - INFO - __main__ - Global step 1100 Train loss 0.91 ACC 0.5 on epoch=549
06/24/2022 05:55:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.76 on epoch=554
06/24/2022 05:55:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.76 on epoch=559
06/24/2022 05:55:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.46 on epoch=564
06/24/2022 05:55:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.55 on epoch=569
06/24/2022 05:55:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.81 on epoch=574
06/24/2022 05:55:46 - INFO - __main__ - Global step 1150 Train loss 0.67 ACC 0.5 on epoch=574
06/24/2022 05:55:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.00 on epoch=579
06/24/2022 05:55:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.46 on epoch=584
06/24/2022 05:55:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.32 on epoch=589
06/24/2022 05:55:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.33 on epoch=594
06/24/2022 05:55:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.61 on epoch=599
06/24/2022 05:55:53 - INFO - __main__ - Global step 1200 Train loss 0.55 ACC 0.53125 on epoch=599
06/24/2022 05:55:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.64 on epoch=604
06/24/2022 05:55:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.71 on epoch=609
06/24/2022 05:55:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.52 on epoch=614
06/24/2022 05:55:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.34 on epoch=619
06/24/2022 05:56:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.38 on epoch=624
06/24/2022 05:56:00 - INFO - __main__ - Global step 1250 Train loss 0.52 ACC 0.5 on epoch=624
06/24/2022 05:56:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.43 on epoch=629
06/24/2022 05:56:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.36 on epoch=634
06/24/2022 05:56:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.41 on epoch=639
06/24/2022 05:56:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.36 on epoch=644
06/24/2022 05:56:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.36 on epoch=649
06/24/2022 05:56:07 - INFO - __main__ - Global step 1300 Train loss 0.38 ACC 0.5 on epoch=649
06/24/2022 05:56:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.36 on epoch=654
06/24/2022 05:56:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.43 on epoch=659
06/24/2022 05:56:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.52 on epoch=664
06/24/2022 05:56:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.33 on epoch=669
06/24/2022 05:56:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.41 on epoch=674
06/24/2022 05:56:14 - INFO - __main__ - Global step 1350 Train loss 0.41 ACC 0.5 on epoch=674
06/24/2022 05:56:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.52 on epoch=679
06/24/2022 05:56:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.57 on epoch=684
06/24/2022 05:56:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.66 on epoch=689
06/24/2022 05:56:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.72 on epoch=694
06/24/2022 05:56:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.94 on epoch=699
06/24/2022 05:56:21 - INFO - __main__ - Global step 1400 Train loss 0.68 ACC 0.5 on epoch=699
06/24/2022 05:56:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.83 on epoch=704
06/24/2022 05:56:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.78 on epoch=709
06/24/2022 05:56:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.73 on epoch=714
06/24/2022 05:56:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.62 on epoch=719
06/24/2022 05:56:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.49 on epoch=724
06/24/2022 05:56:28 - INFO - __main__ - Global step 1450 Train loss 0.69 ACC 0.5 on epoch=724
06/24/2022 05:56:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.48 on epoch=729
06/24/2022 05:56:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.54 on epoch=734
06/24/2022 05:56:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.54 on epoch=739
06/24/2022 05:56:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.52 on epoch=744
06/24/2022 05:56:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.55 on epoch=749
06/24/2022 05:56:35 - INFO - __main__ - Global step 1500 Train loss 0.53 ACC 0.5 on epoch=749
06/24/2022 05:56:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.46 on epoch=754
06/24/2022 05:56:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.40 on epoch=759
06/24/2022 05:56:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.43 on epoch=764
06/24/2022 05:56:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.43 on epoch=769
06/24/2022 05:56:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.51 on epoch=774
06/24/2022 05:56:42 - INFO - __main__ - Global step 1550 Train loss 0.44 ACC 0.5 on epoch=774
06/24/2022 05:56:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.41 on epoch=779
06/24/2022 05:56:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.42 on epoch=784
06/24/2022 05:56:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.52 on epoch=789
06/24/2022 05:56:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.53 on epoch=794
06/24/2022 05:56:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.45 on epoch=799
06/24/2022 05:56:49 - INFO - __main__ - Global step 1600 Train loss 0.47 ACC 0.5 on epoch=799
06/24/2022 05:56:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.41 on epoch=804
06/24/2022 05:56:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.43 on epoch=809
06/24/2022 05:56:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.44 on epoch=814
06/24/2022 05:56:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.39 on epoch=819
06/24/2022 05:56:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.44 on epoch=824
06/24/2022 05:56:56 - INFO - __main__ - Global step 1650 Train loss 0.42 ACC 0.5 on epoch=824
06/24/2022 05:56:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.36 on epoch=829
06/24/2022 05:56:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.38 on epoch=834
06/24/2022 05:56:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.30 on epoch=839
06/24/2022 05:57:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.31 on epoch=844
06/24/2022 05:57:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.33 on epoch=849
06/24/2022 05:57:02 - INFO - __main__ - Global step 1700 Train loss 0.34 ACC 0.5 on epoch=849
06/24/2022 05:57:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.37 on epoch=854
06/24/2022 05:57:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.33 on epoch=859
06/24/2022 05:57:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.39 on epoch=864
06/24/2022 05:57:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.34 on epoch=869
06/24/2022 05:57:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.38 on epoch=874
06/24/2022 05:57:09 - INFO - __main__ - Global step 1750 Train loss 0.36 ACC 0.5 on epoch=874
06/24/2022 05:57:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.33 on epoch=879
06/24/2022 05:57:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.25 on epoch=884
06/24/2022 05:57:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.37 on epoch=889
06/24/2022 05:57:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.34 on epoch=894
06/24/2022 05:57:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.31 on epoch=899
06/24/2022 05:57:16 - INFO - __main__ - Global step 1800 Train loss 0.32 ACC 0.5 on epoch=899
06/24/2022 05:57:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.32 on epoch=904
06/24/2022 05:57:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.38 on epoch=909
06/24/2022 05:57:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.31 on epoch=914
06/24/2022 05:57:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.36 on epoch=919
06/24/2022 05:57:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.28 on epoch=924
06/24/2022 05:57:23 - INFO - __main__ - Global step 1850 Train loss 0.33 ACC 0.5 on epoch=924
06/24/2022 05:57:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.26 on epoch=929
06/24/2022 05:57:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.31 on epoch=934
06/24/2022 05:57:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.28 on epoch=939
06/24/2022 05:57:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.28 on epoch=944
06/24/2022 05:57:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.31 on epoch=949
06/24/2022 05:57:30 - INFO - __main__ - Global step 1900 Train loss 0.29 ACC 0.5 on epoch=949
06/24/2022 05:57:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.30 on epoch=954
06/24/2022 05:57:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.35 on epoch=959
06/24/2022 05:57:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.29 on epoch=964
06/24/2022 05:57:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.28 on epoch=969
06/24/2022 05:57:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.24 on epoch=974
06/24/2022 05:57:37 - INFO - __main__ - Global step 1950 Train loss 0.29 ACC 0.5 on epoch=974
06/24/2022 05:57:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.31 on epoch=979
06/24/2022 05:57:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.27 on epoch=984
06/24/2022 05:57:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.34 on epoch=989
06/24/2022 05:57:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.32 on epoch=994
06/24/2022 05:57:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.28 on epoch=999
06/24/2022 05:57:44 - INFO - __main__ - Global step 2000 Train loss 0.30 ACC 0.5 on epoch=999
06/24/2022 05:57:44 - INFO - __main__ - save last model!
06/24/2022 05:57:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 05:57:44 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 05:57:44 - INFO - __main__ - Printing 3 examples
06/24/2022 05:57:44 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 05:57:44 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:44 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 05:57:44 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:44 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 05:57:44 - INFO - __main__ - ['duplicate']
06/24/2022 05:57:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:57:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 05:57:45 - INFO - __main__ - Printing 3 examples
06/24/2022 05:57:45 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 05:57:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:45 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 05:57:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:45 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 05:57:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:57:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:57:45 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 05:57:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 05:57:45 - INFO - __main__ - Printing 3 examples
06/24/2022 05:57:45 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 05:57:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:45 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 05:57:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:45 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 05:57:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 05:57:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 05:57:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:57:45 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 05:57:51 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 05:57:51 - INFO - __main__ - task name: glue-qqp
06/24/2022 05:57:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 05:57:51 - INFO - __main__ - Starting training!
06/24/2022 05:58:03 - INFO - __main__ - Tokenizing Output ...
06/24/2022 05:58:43 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 06:10:47 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_100_0.5_8_predictions.txt
06/24/2022 06:10:47 - INFO - __main__ - ACC on test data: 0.3692
06/24/2022 06:10:48 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.5, bsz=8, dev_performance=0.53125, test_performance=0.36923076923076925
06/24/2022 06:10:48 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.4, bsz=8 ...
06/24/2022 06:10:49 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:10:49 - INFO - __main__ - Printing 3 examples
06/24/2022 06:10:49 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:10:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:10:49 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:10:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:10:49 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:10:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:10:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:10:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:10:49 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:10:49 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:10:49 - INFO - __main__ - Printing 3 examples
06/24/2022 06:10:49 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:10:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:10:49 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:10:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:10:49 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:10:49 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:10:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:10:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:10:49 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:10:55 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 06:10:55 - INFO - __main__ - task name: glue-qqp
06/24/2022 06:10:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:10:55 - INFO - __main__ - Starting training!
06/24/2022 06:10:56 - INFO - __main__ - Step 10 Global step 10 Train loss 5.77 on epoch=4
06/24/2022 06:10:58 - INFO - __main__ - Step 20 Global step 20 Train loss 2.17 on epoch=9
06/24/2022 06:10:59 - INFO - __main__ - Step 30 Global step 30 Train loss 0.92 on epoch=14
06/24/2022 06:11:00 - INFO - __main__ - Step 40 Global step 40 Train loss 0.64 on epoch=19
06/24/2022 06:11:01 - INFO - __main__ - Step 50 Global step 50 Train loss 0.47 on epoch=24
06/24/2022 06:11:02 - INFO - __main__ - Global step 50 Train loss 1.99 ACC 0.46875 on epoch=24
06/24/2022 06:11:02 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
06/24/2022 06:11:03 - INFO - __main__ - Step 60 Global step 60 Train loss 0.42 on epoch=29
06/24/2022 06:11:04 - INFO - __main__ - Step 70 Global step 70 Train loss 0.41 on epoch=34
06/24/2022 06:11:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.36 on epoch=39
06/24/2022 06:11:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.35 on epoch=44
06/24/2022 06:11:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=49
06/24/2022 06:11:09 - INFO - __main__ - Global step 100 Train loss 0.37 ACC 0.5625 on epoch=49
06/24/2022 06:11:09 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5625 on epoch=49, global_step=100
06/24/2022 06:11:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.29 on epoch=54
06/24/2022 06:11:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.29 on epoch=59
06/24/2022 06:11:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=64
06/24/2022 06:11:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=69
06/24/2022 06:11:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=74
06/24/2022 06:11:15 - INFO - __main__ - Global step 150 Train loss 0.28 ACC 0.5 on epoch=74
06/24/2022 06:11:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.30 on epoch=79
06/24/2022 06:11:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.28 on epoch=84
06/24/2022 06:11:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=89
06/24/2022 06:11:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=94
06/24/2022 06:11:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=99
06/24/2022 06:11:22 - INFO - __main__ - Global step 200 Train loss 0.26 ACC 0.5 on epoch=99
06/24/2022 06:11:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=104
06/24/2022 06:11:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=109
06/24/2022 06:11:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=114
06/24/2022 06:11:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=119
06/24/2022 06:11:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=124
06/24/2022 06:11:29 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.53125 on epoch=124
06/24/2022 06:11:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=129
06/24/2022 06:11:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/24/2022 06:11:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=139
06/24/2022 06:11:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=144
06/24/2022 06:11:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=149
06/24/2022 06:11:36 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5 on epoch=149
06/24/2022 06:11:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 06:11:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/24/2022 06:11:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/24/2022 06:11:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/24/2022 06:11:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/24/2022 06:11:43 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.5 on epoch=174
06/24/2022 06:11:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 06:11:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=184
06/24/2022 06:11:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 06:11:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=194
06/24/2022 06:11:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/24/2022 06:11:49 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.46875 on epoch=199
06/24/2022 06:11:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=204
06/24/2022 06:11:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=209
06/24/2022 06:11:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=214
06/24/2022 06:11:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/24/2022 06:11:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=224
06/24/2022 06:11:56 - INFO - __main__ - Global step 450 Train loss 0.21 ACC 0.59375 on epoch=224
06/24/2022 06:11:56 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=224, global_step=450
06/24/2022 06:11:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=229
06/24/2022 06:11:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=234
06/24/2022 06:12:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=239
06/24/2022 06:12:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=244
06/24/2022 06:12:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=249
06/24/2022 06:12:03 - INFO - __main__ - Global step 500 Train loss 0.22 ACC 0.4375 on epoch=249
06/24/2022 06:12:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/24/2022 06:12:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=259
06/24/2022 06:12:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=264
06/24/2022 06:12:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=269
06/24/2022 06:12:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/24/2022 06:12:10 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.53125 on epoch=274
06/24/2022 06:12:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=279
06/24/2022 06:12:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=284
06/24/2022 06:12:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=289
06/24/2022 06:12:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=294
06/24/2022 06:12:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=299
06/24/2022 06:12:17 - INFO - __main__ - Global step 600 Train loss 0.22 ACC 0.4375 on epoch=299
06/24/2022 06:12:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=304
06/24/2022 06:12:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=309
06/24/2022 06:12:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=314
06/24/2022 06:12:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=319
06/24/2022 06:12:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=324
06/24/2022 06:12:23 - INFO - __main__ - Global step 650 Train loss 0.20 ACC 0.4375 on epoch=324
06/24/2022 06:12:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=329
06/24/2022 06:12:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/24/2022 06:12:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=339
06/24/2022 06:12:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=344
06/24/2022 06:12:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=349
06/24/2022 06:12:30 - INFO - __main__ - Global step 700 Train loss 0.20 ACC 0.4375 on epoch=349
06/24/2022 06:12:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=354
06/24/2022 06:12:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/24/2022 06:12:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=364
06/24/2022 06:12:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=369
06/24/2022 06:12:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=374
06/24/2022 06:12:36 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.5 on epoch=374
06/24/2022 06:12:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=379
06/24/2022 06:12:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=384
06/24/2022 06:12:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=389
06/24/2022 06:12:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=394
06/24/2022 06:12:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=399
06/24/2022 06:12:43 - INFO - __main__ - Global step 800 Train loss 0.22 ACC 0.4375 on epoch=399
06/24/2022 06:12:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=404
06/24/2022 06:12:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=409
06/24/2022 06:12:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=414
06/24/2022 06:12:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=419
06/24/2022 06:12:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=424
06/24/2022 06:12:50 - INFO - __main__ - Global step 850 Train loss 0.19 ACC 0.375 on epoch=424
06/24/2022 06:12:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=429
06/24/2022 06:12:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=434
06/24/2022 06:12:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=439
06/24/2022 06:12:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=444
06/24/2022 06:12:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=449
06/24/2022 06:12:57 - INFO - __main__ - Global step 900 Train loss 0.18 ACC 0.4375 on epoch=449
06/24/2022 06:12:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=454
06/24/2022 06:12:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=459
06/24/2022 06:13:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=464
06/24/2022 06:13:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=469
06/24/2022 06:13:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=474
06/24/2022 06:13:03 - INFO - __main__ - Global step 950 Train loss 0.16 ACC 0.46875 on epoch=474
06/24/2022 06:13:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=479
06/24/2022 06:13:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=484
06/24/2022 06:13:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=489
06/24/2022 06:13:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=494
06/24/2022 06:13:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=499
06/24/2022 06:13:10 - INFO - __main__ - Global step 1000 Train loss 0.13 ACC 0.65625 on epoch=499
06/24/2022 06:13:10 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.65625 on epoch=499, global_step=1000
06/24/2022 06:13:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=504
06/24/2022 06:13:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=509
06/24/2022 06:13:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=514
06/24/2022 06:13:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=519
06/24/2022 06:13:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=524
06/24/2022 06:13:17 - INFO - __main__ - Global step 1050 Train loss 0.11 ACC 0.59375 on epoch=524
06/24/2022 06:13:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=529
06/24/2022 06:13:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=534
06/24/2022 06:13:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=539
06/24/2022 06:13:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=544
06/24/2022 06:13:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=549
06/24/2022 06:13:24 - INFO - __main__ - Global step 1100 Train loss 0.09 ACC 0.53125 on epoch=549
06/24/2022 06:13:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=554
06/24/2022 06:13:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=559
06/24/2022 06:13:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=564
06/24/2022 06:13:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/24/2022 06:13:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=574
06/24/2022 06:13:30 - INFO - __main__ - Global step 1150 Train loss 0.05 ACC 0.53125 on epoch=574
06/24/2022 06:13:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=579
06/24/2022 06:13:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 06:13:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=589
06/24/2022 06:13:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 06:13:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
06/24/2022 06:13:37 - INFO - __main__ - Global step 1200 Train loss 0.03 ACC 0.59375 on epoch=599
06/24/2022 06:13:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 06:13:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=609
06/24/2022 06:13:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 06:13:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/24/2022 06:13:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=624
06/24/2022 06:13:44 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.40625 on epoch=624
06/24/2022 06:13:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 06:13:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=634
06/24/2022 06:13:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 06:13:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 06:13:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 06:13:50 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.53125 on epoch=649
06/24/2022 06:13:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=654
06/24/2022 06:13:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 06:13:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 06:13:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/24/2022 06:13:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 06:13:57 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.53125 on epoch=674
06/24/2022 06:13:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
06/24/2022 06:13:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 06:14:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 06:14:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 06:14:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=699
06/24/2022 06:14:04 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.5 on epoch=699
06/24/2022 06:14:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 06:14:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 06:14:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=714
06/24/2022 06:14:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=719
06/24/2022 06:14:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 06:14:10 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.46875 on epoch=724
06/24/2022 06:14:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 06:14:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=734
06/24/2022 06:14:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 06:14:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 06:14:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
06/24/2022 06:14:17 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.5625 on epoch=749
06/24/2022 06:14:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 06:14:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/24/2022 06:14:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 06:14:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 06:14:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 06:14:24 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.53125 on epoch=774
06/24/2022 06:14:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 06:14:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=784
06/24/2022 06:14:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 06:14:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
06/24/2022 06:14:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 06:14:31 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.5625 on epoch=799
06/24/2022 06:14:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 06:14:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=809
06/24/2022 06:14:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=814
06/24/2022 06:14:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=819
06/24/2022 06:14:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=824
06/24/2022 06:14:37 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.46875 on epoch=824
06/24/2022 06:14:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 06:14:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=834
06/24/2022 06:14:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/24/2022 06:14:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 06:14:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=849
06/24/2022 06:14:44 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.53125 on epoch=849
06/24/2022 06:14:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
06/24/2022 06:14:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 06:14:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 06:14:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 06:14:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 06:14:51 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.5 on epoch=874
06/24/2022 06:14:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 06:14:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=884
06/24/2022 06:14:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 06:14:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 06:14:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
06/24/2022 06:14:57 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.53125 on epoch=899
06/24/2022 06:14:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
06/24/2022 06:15:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 06:15:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
06/24/2022 06:15:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 06:15:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 06:15:04 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.53125 on epoch=924
06/24/2022 06:15:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 06:15:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 06:15:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 06:15:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=944
06/24/2022 06:15:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 06:15:10 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.5 on epoch=949
06/24/2022 06:15:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 06:15:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 06:15:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/24/2022 06:15:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 06:15:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 06:15:17 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.5 on epoch=974
06/24/2022 06:15:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 06:15:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 06:15:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 06:15:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 06:15:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 06:15:24 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.5 on epoch=999
06/24/2022 06:15:24 - INFO - __main__ - save last model!
06/24/2022 06:15:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 06:15:24 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 06:15:24 - INFO - __main__ - Printing 3 examples
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 06:15:24 - INFO - __main__ - ['duplicate']
06/24/2022 06:15:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:15:24 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:15:24 - INFO - __main__ - Printing 3 examples
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:15:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:15:24 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:15:24 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:15:24 - INFO - __main__ - Printing 3 examples
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:15:24 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:15:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:15:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:15:24 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:15:31 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 06:15:31 - INFO - __main__ - task name: glue-qqp
06/24/2022 06:15:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:15:31 - INFO - __main__ - Starting training!
06/24/2022 06:15:42 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:16:23 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 06:29:12 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_100_0.4_8_predictions.txt
06/24/2022 06:29:13 - INFO - __main__ - ACC on test data: 0.5673
06/24/2022 06:29:13 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.4, bsz=8, dev_performance=0.65625, test_performance=0.5672520405639376
06/24/2022 06:29:13 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.3, bsz=8 ...
06/24/2022 06:29:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:29:14 - INFO - __main__ - Printing 3 examples
06/24/2022 06:29:14 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:29:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:29:14 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:29:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:29:14 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:29:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:29:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:29:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:29:14 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:29:14 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:29:14 - INFO - __main__ - Printing 3 examples
06/24/2022 06:29:14 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:29:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:29:14 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:29:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:29:14 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:29:14 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:29:14 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:29:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:29:14 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:29:20 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 06:29:20 - INFO - __main__ - task name: glue-qqp
06/24/2022 06:29:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:29:20 - INFO - __main__ - Starting training!
06/24/2022 06:29:21 - INFO - __main__ - Step 10 Global step 10 Train loss 6.37 on epoch=4
06/24/2022 06:29:22 - INFO - __main__ - Step 20 Global step 20 Train loss 2.83 on epoch=9
06/24/2022 06:29:24 - INFO - __main__ - Step 30 Global step 30 Train loss 1.05 on epoch=14
06/24/2022 06:29:25 - INFO - __main__ - Step 40 Global step 40 Train loss 0.63 on epoch=19
06/24/2022 06:29:26 - INFO - __main__ - Step 50 Global step 50 Train loss 0.63 on epoch=24
06/24/2022 06:29:26 - INFO - __main__ - Global step 50 Train loss 2.30 ACC 0.5 on epoch=24
06/24/2022 06:29:26 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 06:29:28 - INFO - __main__ - Step 60 Global step 60 Train loss 0.42 on epoch=29
06/24/2022 06:29:29 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=34
06/24/2022 06:29:30 - INFO - __main__ - Step 80 Global step 80 Train loss 0.38 on epoch=39
06/24/2022 06:29:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.33 on epoch=44
06/24/2022 06:29:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.41 on epoch=49
06/24/2022 06:29:33 - INFO - __main__ - Global step 100 Train loss 0.39 ACC 0.5 on epoch=49
06/24/2022 06:29:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.38 on epoch=54
06/24/2022 06:29:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
06/24/2022 06:29:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=64
06/24/2022 06:29:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
06/24/2022 06:29:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.31 on epoch=74
06/24/2022 06:29:40 - INFO - __main__ - Global step 150 Train loss 0.33 ACC 0.5 on epoch=74
06/24/2022 06:29:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.30 on epoch=79
06/24/2022 06:29:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=84
06/24/2022 06:29:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=89
06/24/2022 06:29:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.24 on epoch=94
06/24/2022 06:29:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=99
06/24/2022 06:29:46 - INFO - __main__ - Global step 200 Train loss 0.27 ACC 0.5 on epoch=99
06/24/2022 06:29:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.30 on epoch=104
06/24/2022 06:29:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=109
06/24/2022 06:29:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=114
06/24/2022 06:29:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=119
06/24/2022 06:29:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=124
06/24/2022 06:29:53 - INFO - __main__ - Global step 250 Train loss 0.32 ACC 0.4375 on epoch=124
06/24/2022 06:29:54 - INFO - __main__ - Step 260 Global step 260 Train loss 3.20 on epoch=129
06/24/2022 06:29:55 - INFO - __main__ - Step 270 Global step 270 Train loss 2.23 on epoch=134
06/24/2022 06:29:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=139
06/24/2022 06:29:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 06:29:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=149
06/24/2022 06:29:59 - INFO - __main__ - Global step 300 Train loss 1.27 ACC 0.5 on epoch=149
06/24/2022 06:30:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=154
06/24/2022 06:30:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=159
06/24/2022 06:30:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=164
06/24/2022 06:30:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=169
06/24/2022 06:30:05 - INFO - __main__ - Step 350 Global step 350 Train loss 2.15 on epoch=174
06/24/2022 06:30:06 - INFO - __main__ - Global step 350 Train loss 0.72 ACC 0.53125 on epoch=174
06/24/2022 06:30:06 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=174, global_step=350
06/24/2022 06:30:07 - INFO - __main__ - Step 360 Global step 360 Train loss 2.13 on epoch=179
06/24/2022 06:30:08 - INFO - __main__ - Step 370 Global step 370 Train loss 2.07 on epoch=184
06/24/2022 06:30:10 - INFO - __main__ - Step 380 Global step 380 Train loss 1.20 on epoch=189
06/24/2022 06:30:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.99 on epoch=194
06/24/2022 06:30:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.69 on epoch=199
06/24/2022 06:30:13 - INFO - __main__ - Global step 400 Train loss 1.42 ACC 0.5 on epoch=199
06/24/2022 06:30:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.58 on epoch=204
06/24/2022 06:30:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.75 on epoch=209
06/24/2022 06:30:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=214
06/24/2022 06:30:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=219
06/24/2022 06:30:19 - INFO - __main__ - Step 450 Global step 450 Train loss 1.24 on epoch=224
06/24/2022 06:30:20 - INFO - __main__ - Global step 450 Train loss 0.70 ACC 0.4375 on epoch=224
06/24/2022 06:30:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.92 on epoch=229
06/24/2022 06:30:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.71 on epoch=234
06/24/2022 06:30:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.93 on epoch=239
06/24/2022 06:30:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.83 on epoch=244
06/24/2022 06:30:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.89 on epoch=249
06/24/2022 06:30:26 - INFO - __main__ - Global step 500 Train loss 0.86 ACC 0.5 on epoch=249
06/24/2022 06:30:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.66 on epoch=254
06/24/2022 06:30:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.46 on epoch=259
06/24/2022 06:30:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.47 on epoch=264
06/24/2022 06:30:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=269
06/24/2022 06:30:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.42 on epoch=274
06/24/2022 06:30:33 - INFO - __main__ - Global step 550 Train loss 0.47 ACC 0.4375 on epoch=274
06/24/2022 06:30:34 - INFO - __main__ - Step 560 Global step 560 Train loss 1.10 on epoch=279
06/24/2022 06:30:35 - INFO - __main__ - Step 570 Global step 570 Train loss 3.01 on epoch=284
06/24/2022 06:30:36 - INFO - __main__ - Step 580 Global step 580 Train loss 3.53 on epoch=289
06/24/2022 06:30:38 - INFO - __main__ - Step 590 Global step 590 Train loss 2.60 on epoch=294
06/24/2022 06:30:39 - INFO - __main__ - Step 600 Global step 600 Train loss 3.21 on epoch=299
06/24/2022 06:30:41 - INFO - __main__ - Global step 600 Train loss 2.69 ACC 0.46875 on epoch=299
06/24/2022 06:30:42 - INFO - __main__ - Step 610 Global step 610 Train loss 3.43 on epoch=304
06/24/2022 06:30:43 - INFO - __main__ - Step 620 Global step 620 Train loss 1.67 on epoch=309
06/24/2022 06:30:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.86 on epoch=314
06/24/2022 06:30:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.91 on epoch=319
06/24/2022 06:30:47 - INFO - __main__ - Step 650 Global step 650 Train loss 2.00 on epoch=324
06/24/2022 06:30:47 - INFO - __main__ - Global step 650 Train loss 1.77 ACC 0.5 on epoch=324
06/24/2022 06:30:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.83 on epoch=329
06/24/2022 06:30:50 - INFO - __main__ - Step 670 Global step 670 Train loss 1.26 on epoch=334
06/24/2022 06:30:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.82 on epoch=339
06/24/2022 06:30:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.49 on epoch=344
06/24/2022 06:30:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.46 on epoch=349
06/24/2022 06:30:54 - INFO - __main__ - Global step 700 Train loss 0.77 ACC 0.5 on epoch=349
06/24/2022 06:30:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.42 on epoch=354
06/24/2022 06:30:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=359
06/24/2022 06:30:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=364
06/24/2022 06:30:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.37 on epoch=369
06/24/2022 06:31:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=374
06/24/2022 06:31:01 - INFO - __main__ - Global step 750 Train loss 0.36 ACC 0.5 on epoch=374
06/24/2022 06:31:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=379
06/24/2022 06:31:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=384
06/24/2022 06:31:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=389
06/24/2022 06:31:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=394
06/24/2022 06:31:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=399
06/24/2022 06:31:07 - INFO - __main__ - Global step 800 Train loss 0.32 ACC 0.5 on epoch=399
06/24/2022 06:31:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.28 on epoch=404
06/24/2022 06:31:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=409
06/24/2022 06:31:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.30 on epoch=414
06/24/2022 06:31:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=419
06/24/2022 06:31:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.42 on epoch=424
06/24/2022 06:31:14 - INFO - __main__ - Global step 850 Train loss 0.32 ACC 0.5 on epoch=424
06/24/2022 06:31:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=429
06/24/2022 06:31:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=434
06/24/2022 06:31:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=439
06/24/2022 06:31:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=444
06/24/2022 06:31:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.29 on epoch=449
06/24/2022 06:31:20 - INFO - __main__ - Global step 900 Train loss 0.30 ACC 0.5 on epoch=449
06/24/2022 06:31:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.37 on epoch=454
06/24/2022 06:31:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=459
06/24/2022 06:31:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.35 on epoch=464
06/24/2022 06:31:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=469
06/24/2022 06:31:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.34 on epoch=474
06/24/2022 06:31:27 - INFO - __main__ - Global step 950 Train loss 0.33 ACC 0.5 on epoch=474
06/24/2022 06:31:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.30 on epoch=479
06/24/2022 06:31:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=484
06/24/2022 06:31:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.38 on epoch=489
06/24/2022 06:31:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=494
06/24/2022 06:31:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.31 on epoch=499
06/24/2022 06:31:33 - INFO - __main__ - Global step 1000 Train loss 0.31 ACC 0.5 on epoch=499
06/24/2022 06:31:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.29 on epoch=504
06/24/2022 06:31:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=509
06/24/2022 06:31:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=514
06/24/2022 06:31:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=519
06/24/2022 06:31:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.31 on epoch=524
06/24/2022 06:31:40 - INFO - __main__ - Global step 1050 Train loss 0.29 ACC 0.5 on epoch=524
06/24/2022 06:31:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.29 on epoch=529
06/24/2022 06:31:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=534
06/24/2022 06:31:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=539
06/24/2022 06:31:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.32 on epoch=544
06/24/2022 06:31:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.32 on epoch=549
06/24/2022 06:31:47 - INFO - __main__ - Global step 1100 Train loss 0.30 ACC 0.5 on epoch=549
06/24/2022 06:31:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.30 on epoch=554
06/24/2022 06:31:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.31 on epoch=559
06/24/2022 06:31:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=564
06/24/2022 06:31:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.27 on epoch=569
06/24/2022 06:31:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.29 on epoch=574
06/24/2022 06:31:53 - INFO - __main__ - Global step 1150 Train loss 0.29 ACC 0.5 on epoch=574
06/24/2022 06:31:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.32 on epoch=579
06/24/2022 06:31:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.36 on epoch=584
06/24/2022 06:31:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=589
06/24/2022 06:31:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.27 on epoch=594
06/24/2022 06:31:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.24 on epoch=599
06/24/2022 06:32:00 - INFO - __main__ - Global step 1200 Train loss 0.29 ACC 0.5 on epoch=599
06/24/2022 06:32:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.29 on epoch=604
06/24/2022 06:32:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.28 on epoch=609
06/24/2022 06:32:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.29 on epoch=614
06/24/2022 06:32:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.26 on epoch=619
06/24/2022 06:32:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.31 on epoch=624
06/24/2022 06:32:06 - INFO - __main__ - Global step 1250 Train loss 0.29 ACC 0.5 on epoch=624
06/24/2022 06:32:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.24 on epoch=629
06/24/2022 06:32:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.26 on epoch=634
06/24/2022 06:32:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.31 on epoch=639
06/24/2022 06:32:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=644
06/24/2022 06:32:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.28 on epoch=649
06/24/2022 06:32:13 - INFO - __main__ - Global step 1300 Train loss 0.27 ACC 0.5 on epoch=649
06/24/2022 06:32:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=654
06/24/2022 06:32:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.33 on epoch=659
06/24/2022 06:32:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.33 on epoch=664
06/24/2022 06:32:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.29 on epoch=669
06/24/2022 06:32:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.30 on epoch=674
06/24/2022 06:32:19 - INFO - __main__ - Global step 1350 Train loss 0.29 ACC 0.5 on epoch=674
06/24/2022 06:32:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=679
06/24/2022 06:32:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.29 on epoch=684
06/24/2022 06:32:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.32 on epoch=689
06/24/2022 06:32:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.25 on epoch=694
06/24/2022 06:32:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.28 on epoch=699
06/24/2022 06:32:26 - INFO - __main__ - Global step 1400 Train loss 0.28 ACC 0.5 on epoch=699
06/24/2022 06:32:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.23 on epoch=704
06/24/2022 06:32:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.28 on epoch=709
06/24/2022 06:32:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.28 on epoch=714
06/24/2022 06:32:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.25 on epoch=719
06/24/2022 06:32:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.28 on epoch=724
06/24/2022 06:32:32 - INFO - __main__ - Global step 1450 Train loss 0.26 ACC 0.5 on epoch=724
06/24/2022 06:32:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.24 on epoch=729
06/24/2022 06:32:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.28 on epoch=734
06/24/2022 06:32:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.26 on epoch=739
06/24/2022 06:32:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.25 on epoch=744
06/24/2022 06:32:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.28 on epoch=749
06/24/2022 06:32:39 - INFO - __main__ - Global step 1500 Train loss 0.26 ACC 0.5 on epoch=749
06/24/2022 06:32:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.27 on epoch=754
06/24/2022 06:32:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.26 on epoch=759
06/24/2022 06:32:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.28 on epoch=764
06/24/2022 06:32:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.24 on epoch=769
06/24/2022 06:32:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.29 on epoch=774
06/24/2022 06:32:46 - INFO - __main__ - Global step 1550 Train loss 0.27 ACC 0.5 on epoch=774
06/24/2022 06:32:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.27 on epoch=779
06/24/2022 06:32:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.30 on epoch=784
06/24/2022 06:32:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.30 on epoch=789
06/24/2022 06:32:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.24 on epoch=794
06/24/2022 06:32:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.26 on epoch=799
06/24/2022 06:32:52 - INFO - __main__ - Global step 1600 Train loss 0.27 ACC 0.5 on epoch=799
06/24/2022 06:32:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.28 on epoch=804
06/24/2022 06:32:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.31 on epoch=809
06/24/2022 06:32:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.26 on epoch=814
06/24/2022 06:32:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.25 on epoch=819
06/24/2022 06:32:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.27 on epoch=824
06/24/2022 06:32:59 - INFO - __main__ - Global step 1650 Train loss 0.27 ACC 0.5 on epoch=824
06/24/2022 06:33:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.23 on epoch=829
06/24/2022 06:33:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.30 on epoch=834
06/24/2022 06:33:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.29 on epoch=839
06/24/2022 06:33:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.26 on epoch=844
06/24/2022 06:33:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.26 on epoch=849
06/24/2022 06:33:05 - INFO - __main__ - Global step 1700 Train loss 0.27 ACC 0.5 on epoch=849
06/24/2022 06:33:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.26 on epoch=854
06/24/2022 06:33:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.20 on epoch=859
06/24/2022 06:33:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.28 on epoch=864
06/24/2022 06:33:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.26 on epoch=869
06/24/2022 06:33:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.24 on epoch=874
06/24/2022 06:33:12 - INFO - __main__ - Global step 1750 Train loss 0.25 ACC 0.5 on epoch=874
06/24/2022 06:33:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.26 on epoch=879
06/24/2022 06:33:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.27 on epoch=884
06/24/2022 06:33:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.25 on epoch=889
06/24/2022 06:33:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.22 on epoch=894
06/24/2022 06:33:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.28 on epoch=899
06/24/2022 06:33:18 - INFO - __main__ - Global step 1800 Train loss 0.25 ACC 0.5 on epoch=899
06/24/2022 06:33:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.33 on epoch=904
06/24/2022 06:33:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.26 on epoch=909
06/24/2022 06:33:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.24 on epoch=914
06/24/2022 06:33:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.27 on epoch=919
06/24/2022 06:33:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.24 on epoch=924
06/24/2022 06:33:25 - INFO - __main__ - Global step 1850 Train loss 0.27 ACC 0.5 on epoch=924
06/24/2022 06:33:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.26 on epoch=929
06/24/2022 06:33:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.21 on epoch=934
06/24/2022 06:33:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.25 on epoch=939
06/24/2022 06:33:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.24 on epoch=944
06/24/2022 06:33:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.24 on epoch=949
06/24/2022 06:33:32 - INFO - __main__ - Global step 1900 Train loss 0.24 ACC 0.5 on epoch=949
06/24/2022 06:33:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.27 on epoch=954
06/24/2022 06:33:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.23 on epoch=959
06/24/2022 06:33:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.24 on epoch=964
06/24/2022 06:33:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.23 on epoch=969
06/24/2022 06:33:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.28 on epoch=974
06/24/2022 06:33:38 - INFO - __main__ - Global step 1950 Train loss 0.25 ACC 0.5 on epoch=974
06/24/2022 06:33:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.26 on epoch=979
06/24/2022 06:33:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.31 on epoch=984
06/24/2022 06:33:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.27 on epoch=989
06/24/2022 06:33:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.33 on epoch=994
06/24/2022 06:33:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.27 on epoch=999
06/24/2022 06:33:45 - INFO - __main__ - Global step 2000 Train loss 0.29 ACC 0.5 on epoch=999
06/24/2022 06:33:45 - INFO - __main__ - save last model!
06/24/2022 06:33:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 06:33:45 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 06:33:45 - INFO - __main__ - Printing 3 examples
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 06:33:45 - INFO - __main__ - ['duplicate']
06/24/2022 06:33:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:33:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:33:45 - INFO - __main__ - Printing 3 examples
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:33:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:33:45 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:33:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:33:45 - INFO - __main__ - Printing 3 examples
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:33:45 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:33:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:33:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:33:45 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:33:51 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 06:33:51 - INFO - __main__ - task name: glue-qqp
06/24/2022 06:33:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:33:51 - INFO - __main__ - Starting training!
06/24/2022 06:34:03 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:34:44 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 06:46:56 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_100_0.3_8_predictions.txt
06/24/2022 06:46:56 - INFO - __main__ - ACC on test data: 0.3683
06/24/2022 06:46:56 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.3, bsz=8, dev_performance=0.53125, test_performance=0.36829087311402425
06/24/2022 06:46:56 - INFO - __main__ - Running ... prefix=glue-qqp_16_100, lr=0.2, bsz=8 ...
06/24/2022 06:46:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:46:57 - INFO - __main__ - Printing 3 examples
06/24/2022 06:46:57 - INFO - __main__ -  [glue-qqp] question 1: Calculus required for physics? [SEP] question 2: Can two algebraic structures of different cardinalities be homomorphic?
06/24/2022 06:46:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:46:57 - INFO - __main__ -  [glue-qqp] question 1: Why has Thailand never retained all their lost land taken by the French and the English? [SEP] question 2: Why is Thailand called the Land of Smiles?
06/24/2022 06:46:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:46:57 - INFO - __main__ -  [glue-qqp] question 1: How do I integrate the Stanford parser in a Java program? [SEP] question 2: Why isn't the Stanford Parser available in CPP?
06/24/2022 06:46:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:46:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:46:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:46:57 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:46:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:46:57 - INFO - __main__ - Printing 3 examples
06/24/2022 06:46:57 - INFO - __main__ -  [glue-qqp] question 1: Were I can find chicken roasted? [SEP] question 2: How do I roast a chicken?
06/24/2022 06:46:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:46:57 - INFO - __main__ -  [glue-qqp] question 1: What are some tips on making it through the job interview process at First Merchants? [SEP] question 2: What are some tips on making it through the job interview process at Lowe's?
06/24/2022 06:46:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:46:57 - INFO - __main__ -  [glue-qqp] question 1: If you could only read answers and interact with 10 people on Quora, who would they be? Why? [SEP] question 2: How do I an 18 year old women develop confidence to travel alone?
06/24/2022 06:46:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:46:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:46:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:46:57 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:47:03 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 06:47:03 - INFO - __main__ - task name: glue-qqp
06/24/2022 06:47:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:47:03 - INFO - __main__ - Starting training!
06/24/2022 06:47:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.14 on epoch=4
06/24/2022 06:47:06 - INFO - __main__ - Step 20 Global step 20 Train loss 4.36 on epoch=9
06/24/2022 06:47:07 - INFO - __main__ - Step 30 Global step 30 Train loss 2.80 on epoch=14
06/24/2022 06:47:08 - INFO - __main__ - Step 40 Global step 40 Train loss 1.74 on epoch=19
06/24/2022 06:47:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.18 on epoch=24
06/24/2022 06:47:10 - INFO - __main__ - Global step 50 Train loss 3.24 ACC 0.5 on epoch=24
06/24/2022 06:47:10 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 06:47:11 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=29
06/24/2022 06:47:12 - INFO - __main__ - Step 70 Global step 70 Train loss 0.88 on epoch=34
06/24/2022 06:47:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.59 on epoch=39
06/24/2022 06:47:15 - INFO - __main__ - Step 90 Global step 90 Train loss 0.60 on epoch=44
06/24/2022 06:47:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.44 on epoch=49
06/24/2022 06:47:16 - INFO - __main__ - Global step 100 Train loss 0.69 ACC 0.5625 on epoch=49
06/24/2022 06:47:17 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=49, global_step=100
06/24/2022 06:47:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.47 on epoch=54
06/24/2022 06:47:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.44 on epoch=59
06/24/2022 06:47:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=64
06/24/2022 06:47:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.41 on epoch=69
06/24/2022 06:47:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.38 on epoch=74
06/24/2022 06:47:23 - INFO - __main__ - Global step 150 Train loss 0.44 ACC 0.5 on epoch=74
06/24/2022 06:47:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.35 on epoch=79
06/24/2022 06:47:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=84
06/24/2022 06:47:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=89
06/24/2022 06:47:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.33 on epoch=94
06/24/2022 06:47:29 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=99
06/24/2022 06:47:30 - INFO - __main__ - Global step 200 Train loss 0.36 ACC 0.46875 on epoch=99
06/24/2022 06:47:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=104
06/24/2022 06:47:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.33 on epoch=109
06/24/2022 06:47:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=114
06/24/2022 06:47:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.39 on epoch=119
06/24/2022 06:47:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=124
06/24/2022 06:47:37 - INFO - __main__ - Global step 250 Train loss 0.36 ACC 0.40625 on epoch=124
06/24/2022 06:47:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=129
06/24/2022 06:47:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.30 on epoch=134
06/24/2022 06:47:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=139
06/24/2022 06:47:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=144
06/24/2022 06:47:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/24/2022 06:47:44 - INFO - __main__ - Global step 300 Train loss 0.28 ACC 0.4375 on epoch=149
06/24/2022 06:47:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=154
06/24/2022 06:47:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=159
06/24/2022 06:47:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=164
06/24/2022 06:47:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/24/2022 06:47:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=174
06/24/2022 06:47:51 - INFO - __main__ - Global step 350 Train loss 0.30 ACC 0.4375 on epoch=174
06/24/2022 06:47:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=179
06/24/2022 06:47:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=184
06/24/2022 06:47:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=189
06/24/2022 06:47:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=194
06/24/2022 06:47:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=199
06/24/2022 06:47:58 - INFO - __main__ - Global step 400 Train loss 0.29 ACC 0.4375 on epoch=199
06/24/2022 06:47:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=204
06/24/2022 06:48:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=209
06/24/2022 06:48:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=214
06/24/2022 06:48:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=219
06/24/2022 06:48:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=224
06/24/2022 06:48:05 - INFO - __main__ - Global step 450 Train loss 0.29 ACC 0.4375 on epoch=224
06/24/2022 06:48:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=229
06/24/2022 06:48:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=234
06/24/2022 06:48:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=239
06/24/2022 06:48:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=244
06/24/2022 06:48:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=249
06/24/2022 06:48:12 - INFO - __main__ - Global step 500 Train loss 0.26 ACC 0.5 on epoch=249
06/24/2022 06:48:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=254
06/24/2022 06:48:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=259
06/24/2022 06:48:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=264
06/24/2022 06:48:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=269
06/24/2022 06:48:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=274
06/24/2022 06:48:19 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.46875 on epoch=274
06/24/2022 06:48:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=279
06/24/2022 06:48:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=284
06/24/2022 06:48:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=289
06/24/2022 06:48:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=294
06/24/2022 06:48:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=299
06/24/2022 06:48:26 - INFO - __main__ - Global step 600 Train loss 0.26 ACC 0.40625 on epoch=299
06/24/2022 06:48:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=304
06/24/2022 06:48:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=309
06/24/2022 06:48:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=314
06/24/2022 06:48:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=319
06/24/2022 06:48:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=324
06/24/2022 06:48:33 - INFO - __main__ - Global step 650 Train loss 0.24 ACC 0.5 on epoch=324
06/24/2022 06:48:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=329
06/24/2022 06:48:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=334
06/24/2022 06:48:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=339
06/24/2022 06:48:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=344
06/24/2022 06:48:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=349
06/24/2022 06:48:39 - INFO - __main__ - Global step 700 Train loss 0.19 ACC 0.53125 on epoch=349
06/24/2022 06:48:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=354
06/24/2022 06:48:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=359
06/24/2022 06:48:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=364
06/24/2022 06:48:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=369
06/24/2022 06:48:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=374
06/24/2022 06:48:46 - INFO - __main__ - Global step 750 Train loss 0.17 ACC 0.5 on epoch=374
06/24/2022 06:48:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=379
06/24/2022 06:48:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=384
06/24/2022 06:48:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=389
06/24/2022 06:48:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=394
06/24/2022 06:48:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=399
06/24/2022 06:48:53 - INFO - __main__ - Global step 800 Train loss 0.17 ACC 0.5625 on epoch=399
06/24/2022 06:48:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=404
06/24/2022 06:48:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=409
06/24/2022 06:48:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=414
06/24/2022 06:48:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=419
06/24/2022 06:49:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=424
06/24/2022 06:49:00 - INFO - __main__ - Global step 850 Train loss 0.18 ACC 0.53125 on epoch=424
06/24/2022 06:49:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=429
06/24/2022 06:49:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=434
06/24/2022 06:49:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=439
06/24/2022 06:49:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=444
06/24/2022 06:49:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=449
06/24/2022 06:49:07 - INFO - __main__ - Global step 900 Train loss 0.10 ACC 0.46875 on epoch=449
06/24/2022 06:49:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=454
06/24/2022 06:49:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=459
06/24/2022 06:49:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=464
06/24/2022 06:49:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=469
06/24/2022 06:49:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=474
06/24/2022 06:49:14 - INFO - __main__ - Global step 950 Train loss 0.10 ACC 0.46875 on epoch=474
06/24/2022 06:49:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=479
06/24/2022 06:49:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=484
06/24/2022 06:49:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=489
06/24/2022 06:49:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=494
06/24/2022 06:49:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=499
06/24/2022 06:49:21 - INFO - __main__ - Global step 1000 Train loss 0.09 ACC 0.46875 on epoch=499
06/24/2022 06:49:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=504
06/24/2022 06:49:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=509
06/24/2022 06:49:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=514
06/24/2022 06:49:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=519
06/24/2022 06:49:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=524
06/24/2022 06:49:28 - INFO - __main__ - Global step 1050 Train loss 0.10 ACC 0.5 on epoch=524
06/24/2022 06:49:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=529
06/24/2022 06:49:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
06/24/2022 06:49:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/24/2022 06:49:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=544
06/24/2022 06:49:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=549
06/24/2022 06:49:35 - INFO - __main__ - Global step 1100 Train loss 0.06 ACC 0.53125 on epoch=549
06/24/2022 06:49:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=554
06/24/2022 06:49:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=559
06/24/2022 06:49:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=564
06/24/2022 06:49:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=569
06/24/2022 06:49:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=574
06/24/2022 06:49:41 - INFO - __main__ - Global step 1150 Train loss 0.09 ACC 0.5625 on epoch=574
06/24/2022 06:49:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=579
06/24/2022 06:49:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=584
06/24/2022 06:49:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
06/24/2022 06:49:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=594
06/24/2022 06:49:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=599
06/24/2022 06:49:48 - INFO - __main__ - Global step 1200 Train loss 0.07 ACC 0.5 on epoch=599
06/24/2022 06:49:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=604
06/24/2022 06:49:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=609
06/24/2022 06:49:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=614
06/24/2022 06:49:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=619
06/24/2022 06:49:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=624
06/24/2022 06:49:55 - INFO - __main__ - Global step 1250 Train loss 0.06 ACC 0.53125 on epoch=624
06/24/2022 06:49:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=629
06/24/2022 06:49:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=634
06/24/2022 06:49:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=639
06/24/2022 06:50:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=644
06/24/2022 06:50:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=649
06/24/2022 06:50:02 - INFO - __main__ - Global step 1300 Train loss 0.05 ACC 0.53125 on epoch=649
06/24/2022 06:50:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=654
06/24/2022 06:50:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=659
06/24/2022 06:50:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=664
06/24/2022 06:50:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/24/2022 06:50:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 06:50:09 - INFO - __main__ - Global step 1350 Train loss 0.05 ACC 0.53125 on epoch=674
06/24/2022 06:50:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=679
06/24/2022 06:50:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
06/24/2022 06:50:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=689
06/24/2022 06:50:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 06:50:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=699
06/24/2022 06:50:16 - INFO - __main__ - Global step 1400 Train loss 0.03 ACC 0.5625 on epoch=699
06/24/2022 06:50:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=704
06/24/2022 06:50:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 06:50:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 06:50:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=719
06/24/2022 06:50:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=724
06/24/2022 06:50:23 - INFO - __main__ - Global step 1450 Train loss 0.04 ACC 0.5625 on epoch=724
06/24/2022 06:50:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=729
06/24/2022 06:50:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=734
06/24/2022 06:50:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=739
06/24/2022 06:50:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=744
06/24/2022 06:50:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
06/24/2022 06:50:30 - INFO - __main__ - Global step 1500 Train loss 0.04 ACC 0.5625 on epoch=749
06/24/2022 06:50:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=754
06/24/2022 06:50:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=759
06/24/2022 06:50:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=764
06/24/2022 06:50:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=769
06/24/2022 06:50:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=774
06/24/2022 06:50:37 - INFO - __main__ - Global step 1550 Train loss 0.06 ACC 0.5625 on epoch=774
06/24/2022 06:50:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=779
06/24/2022 06:50:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=784
06/24/2022 06:50:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=789
06/24/2022 06:50:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=794
06/24/2022 06:50:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=799
06/24/2022 06:50:44 - INFO - __main__ - Global step 1600 Train loss 0.04 ACC 0.53125 on epoch=799
06/24/2022 06:50:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=804
06/24/2022 06:50:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=809
06/24/2022 06:50:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
06/24/2022 06:50:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=819
06/24/2022 06:50:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 06:50:51 - INFO - __main__ - Global step 1650 Train loss 0.04 ACC 0.53125 on epoch=824
06/24/2022 06:50:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=829
06/24/2022 06:50:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=834
06/24/2022 06:50:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 06:50:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=844
06/24/2022 06:50:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/24/2022 06:50:58 - INFO - __main__ - Global step 1700 Train loss 0.03 ACC 0.5625 on epoch=849
06/24/2022 06:50:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 06:51:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=859
06/24/2022 06:51:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=864
06/24/2022 06:51:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
06/24/2022 06:51:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=874
06/24/2022 06:51:05 - INFO - __main__ - Global step 1750 Train loss 0.03 ACC 0.5 on epoch=874
06/24/2022 06:51:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=879
06/24/2022 06:51:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 06:51:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=889
06/24/2022 06:51:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=894
06/24/2022 06:51:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
06/24/2022 06:51:12 - INFO - __main__ - Global step 1800 Train loss 0.03 ACC 0.53125 on epoch=899
06/24/2022 06:51:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=904
06/24/2022 06:51:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=909
06/24/2022 06:51:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 06:51:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=919
06/24/2022 06:51:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=924
06/24/2022 06:51:19 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.46875 on epoch=924
06/24/2022 06:51:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 06:51:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
06/24/2022 06:51:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=939
06/24/2022 06:51:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=944
06/24/2022 06:51:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 06:51:26 - INFO - __main__ - Global step 1900 Train loss 0.03 ACC 0.5 on epoch=949
06/24/2022 06:51:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=954
06/24/2022 06:51:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=959
06/24/2022 06:51:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=964
06/24/2022 06:51:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=969
06/24/2022 06:51:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=974
06/24/2022 06:51:32 - INFO - __main__ - Global step 1950 Train loss 0.03 ACC 0.46875 on epoch=974
06/24/2022 06:51:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=979
06/24/2022 06:51:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=984
06/24/2022 06:51:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=989
06/24/2022 06:51:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=994
06/24/2022 06:51:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 06:51:39 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.53125 on epoch=999
06/24/2022 06:51:39 - INFO - __main__ - save last model!
06/24/2022 06:51:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 06:51:40 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 06:51:40 - INFO - __main__ - Printing 3 examples
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 06:51:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 06:51:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:51:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:51:40 - INFO - __main__ - Printing 3 examples
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:51:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:51:40 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 06:51:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 06:51:40 - INFO - __main__ - Printing 3 examples
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 06:51:40 - INFO - __main__ - ['duplicate']
06/24/2022 06:51:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 06:51:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:51:40 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 06:51:45 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 06:51:45 - INFO - __main__ - task name: glue-qqp
06/24/2022 06:51:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 06:51:46 - INFO - __main__ - Starting training!
06/24/2022 06:51:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 06:52:39 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 07:05:53 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_100_0.2_8_predictions.txt
06/24/2022 07:05:53 - INFO - __main__ - ACC on test data: 0.4954
06/24/2022 07:05:53 - INFO - __main__ - prefix=glue-qqp_16_100, lr=0.2, bsz=8, dev_performance=0.5625, test_performance=0.495424189957952
06/24/2022 07:05:53 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.5, bsz=8 ...
06/24/2022 07:05:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:05:54 - INFO - __main__ - Printing 3 examples
06/24/2022 07:05:54 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:05:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:05:54 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:05:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:05:54 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:05:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:05:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:05:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:05:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:05:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:05:54 - INFO - __main__ - Printing 3 examples
06/24/2022 07:05:54 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:05:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:05:54 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:05:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:05:54 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:05:54 - INFO - __main__ - ['duplicate']
06/24/2022 07:05:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:05:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:05:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:06:00 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 07:06:00 - INFO - __main__ - task name: glue-qqp
06/24/2022 07:06:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:06:01 - INFO - __main__ - Starting training!
06/24/2022 07:06:02 - INFO - __main__ - Step 10 Global step 10 Train loss 5.19 on epoch=4
06/24/2022 07:06:03 - INFO - __main__ - Step 20 Global step 20 Train loss 1.42 on epoch=9
06/24/2022 07:06:04 - INFO - __main__ - Step 30 Global step 30 Train loss 0.67 on epoch=14
06/24/2022 07:06:06 - INFO - __main__ - Step 40 Global step 40 Train loss 0.49 on epoch=19
06/24/2022 07:06:07 - INFO - __main__ - Step 50 Global step 50 Train loss 0.40 on epoch=24
06/24/2022 07:06:08 - INFO - __main__ - Global step 50 Train loss 1.64 ACC 0.46875 on epoch=24
06/24/2022 07:06:08 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
06/24/2022 07:06:09 - INFO - __main__ - Step 60 Global step 60 Train loss 0.33 on epoch=29
06/24/2022 07:06:10 - INFO - __main__ - Step 70 Global step 70 Train loss 0.48 on epoch=34
06/24/2022 07:06:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.27 on epoch=39
06/24/2022 07:06:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.42 on epoch=44
06/24/2022 07:06:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=49
06/24/2022 07:06:14 - INFO - __main__ - Global step 100 Train loss 0.37 ACC 0.5 on epoch=49
06/24/2022 07:06:14 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=49, global_step=100
06/24/2022 07:06:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.30 on epoch=54
06/24/2022 07:06:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
06/24/2022 07:06:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
06/24/2022 07:06:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=69
06/24/2022 07:06:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.34 on epoch=74
06/24/2022 07:06:21 - INFO - __main__ - Global step 150 Train loss 0.30 ACC 0.5 on epoch=74
06/24/2022 07:06:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.28 on epoch=79
06/24/2022 07:06:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=84
06/24/2022 07:06:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=89
06/24/2022 07:06:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=94
06/24/2022 07:06:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
06/24/2022 07:06:28 - INFO - __main__ - Global step 200 Train loss 0.26 ACC 0.15625 on epoch=99
06/24/2022 07:06:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=104
06/24/2022 07:06:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.23 on epoch=109
06/24/2022 07:06:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=114
06/24/2022 07:06:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=119
06/24/2022 07:06:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=124
06/24/2022 07:06:34 - INFO - __main__ - Global step 250 Train loss 0.27 ACC 0.46875 on epoch=124
06/24/2022 07:06:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=129
06/24/2022 07:06:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.21 on epoch=134
06/24/2022 07:06:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.19 on epoch=139
06/24/2022 07:06:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.21 on epoch=144
06/24/2022 07:06:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=149
06/24/2022 07:06:41 - INFO - __main__ - Global step 300 Train loss 0.23 ACC 0.1875 on epoch=149
06/24/2022 07:06:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=154
06/24/2022 07:06:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/24/2022 07:06:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=164
06/24/2022 07:06:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=169
06/24/2022 07:06:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=174
06/24/2022 07:06:48 - INFO - __main__ - Global step 350 Train loss 0.23 ACC 0.1875 on epoch=174
06/24/2022 07:06:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=179
06/24/2022 07:06:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=184
06/24/2022 07:06:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=189
06/24/2022 07:06:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=194
06/24/2022 07:06:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=199
06/24/2022 07:06:54 - INFO - __main__ - Global step 400 Train loss 0.21 ACC 0.34375 on epoch=199
06/24/2022 07:06:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=204
06/24/2022 07:06:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=209
06/24/2022 07:06:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=214
06/24/2022 07:06:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=219
06/24/2022 07:07:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=224
06/24/2022 07:07:01 - INFO - __main__ - Global step 450 Train loss 0.22 ACC 0.53125 on epoch=224
06/24/2022 07:07:01 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=224, global_step=450
06/24/2022 07:07:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=229
06/24/2022 07:07:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.54 on epoch=234
06/24/2022 07:07:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.44 on epoch=239
06/24/2022 07:07:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=244
06/24/2022 07:07:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=249
06/24/2022 07:07:08 - INFO - __main__ - Global step 500 Train loss 0.33 ACC 0.5 on epoch=249
06/24/2022 07:07:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=254
06/24/2022 07:07:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=259
06/24/2022 07:07:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 07:07:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=269
06/24/2022 07:07:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=274
06/24/2022 07:07:14 - INFO - __main__ - Global step 550 Train loss 0.19 ACC 0.5 on epoch=274
06/24/2022 07:07:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/24/2022 07:07:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=284
06/24/2022 07:07:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=289
06/24/2022 07:07:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=294
06/24/2022 07:07:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=299
06/24/2022 07:07:21 - INFO - __main__ - Global step 600 Train loss 0.18 ACC 0.53125 on epoch=299
06/24/2022 07:07:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=304
06/24/2022 07:07:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=309
06/24/2022 07:07:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=314
06/24/2022 07:07:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=319
06/24/2022 07:07:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=324
06/24/2022 07:07:28 - INFO - __main__ - Global step 650 Train loss 0.18 ACC 0.5 on epoch=324
06/24/2022 07:07:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=329
06/24/2022 07:07:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=334
06/24/2022 07:07:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=339
06/24/2022 07:07:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=344
06/24/2022 07:07:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=349
06/24/2022 07:07:34 - INFO - __main__ - Global step 700 Train loss 0.17 ACC 0.5 on epoch=349
06/24/2022 07:07:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=354
06/24/2022 07:07:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/24/2022 07:07:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=364
06/24/2022 07:07:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=369
06/24/2022 07:07:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=374
06/24/2022 07:07:41 - INFO - __main__ - Global step 750 Train loss 0.17 ACC 0.40625 on epoch=374
06/24/2022 07:07:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=379
06/24/2022 07:07:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=384
06/24/2022 07:07:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=389
06/24/2022 07:07:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=394
06/24/2022 07:07:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=399
06/24/2022 07:07:48 - INFO - __main__ - Global step 800 Train loss 0.21 ACC 0.15625 on epoch=399
06/24/2022 07:07:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=404
06/24/2022 07:07:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.35 on epoch=409
06/24/2022 07:07:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=414
06/24/2022 07:07:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=419
06/24/2022 07:07:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=424
06/24/2022 07:07:54 - INFO - __main__ - Global step 850 Train loss 0.24 ACC 0.15625 on epoch=424
06/24/2022 07:07:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=429
06/24/2022 07:07:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=434
06/24/2022 07:07:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=439
06/24/2022 07:07:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=444
06/24/2022 07:08:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=449
06/24/2022 07:08:01 - INFO - __main__ - Global step 900 Train loss 0.23 ACC 0.46875 on epoch=449
06/24/2022 07:08:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=454
06/24/2022 07:08:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=459
06/24/2022 07:08:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=464
06/24/2022 07:08:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=469
06/24/2022 07:08:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=474
06/24/2022 07:08:08 - INFO - __main__ - Global step 950 Train loss 0.22 ACC 0.15625 on epoch=474
06/24/2022 07:08:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.25 on epoch=479
06/24/2022 07:08:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=484
06/24/2022 07:08:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=489
06/24/2022 07:08:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=494
06/24/2022 07:08:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=499
06/24/2022 07:08:14 - INFO - __main__ - Global step 1000 Train loss 0.23 ACC 0.15625 on epoch=499
06/24/2022 07:08:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=504
06/24/2022 07:08:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=509
06/24/2022 07:08:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=514
06/24/2022 07:08:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.01 on epoch=519
06/24/2022 07:08:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=524
06/24/2022 07:08:21 - INFO - __main__ - Global step 1050 Train loss 0.37 ACC 0.1875 on epoch=524
06/24/2022 07:08:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=529
06/24/2022 07:08:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=534
06/24/2022 07:08:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=539
06/24/2022 07:08:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.23 on epoch=544
06/24/2022 07:08:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=549
06/24/2022 07:08:28 - INFO - __main__ - Global step 1100 Train loss 0.20 ACC 0.25 on epoch=549
06/24/2022 07:08:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=554
06/24/2022 07:08:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=559
06/24/2022 07:08:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=564
06/24/2022 07:08:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=569
06/24/2022 07:08:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=574
06/24/2022 07:08:34 - INFO - __main__ - Global step 1150 Train loss 0.18 ACC 0.53125 on epoch=574
06/24/2022 07:08:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=579
06/24/2022 07:08:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=584
06/24/2022 07:08:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=589
06/24/2022 07:08:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=594
06/24/2022 07:08:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=599
06/24/2022 07:08:41 - INFO - __main__ - Global step 1200 Train loss 0.15 ACC 0.5625 on epoch=599
06/24/2022 07:08:41 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=599, global_step=1200
06/24/2022 07:08:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=604
06/24/2022 07:08:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=609
06/24/2022 07:08:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=614
06/24/2022 07:08:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=619
06/24/2022 07:08:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=624
06/24/2022 07:08:48 - INFO - __main__ - Global step 1250 Train loss 0.13 ACC 0.53125 on epoch=624
06/24/2022 07:08:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=629
06/24/2022 07:08:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=634
06/24/2022 07:08:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=639
06/24/2022 07:08:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=644
06/24/2022 07:08:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=649
06/24/2022 07:08:54 - INFO - __main__ - Global step 1300 Train loss 0.15 ACC 0.5625 on epoch=649
06/24/2022 07:08:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=654
06/24/2022 07:08:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=659
06/24/2022 07:08:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=664
06/24/2022 07:08:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=669
06/24/2022 07:09:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=674
06/24/2022 07:09:01 - INFO - __main__ - Global step 1350 Train loss 0.15 ACC 0.46875 on epoch=674
06/24/2022 07:09:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=679
06/24/2022 07:09:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=684
06/24/2022 07:09:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=689
06/24/2022 07:09:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=694
06/24/2022 07:09:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=699
06/24/2022 07:09:08 - INFO - __main__ - Global step 1400 Train loss 0.10 ACC 0.5625 on epoch=699
06/24/2022 07:09:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=704
06/24/2022 07:09:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=709
06/24/2022 07:09:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=714
06/24/2022 07:09:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=719
06/24/2022 07:09:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=724
06/24/2022 07:09:14 - INFO - __main__ - Global step 1450 Train loss 0.09 ACC 0.59375 on epoch=724
06/24/2022 07:09:14 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=724, global_step=1450
06/24/2022 07:09:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=729
06/24/2022 07:09:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=734
06/24/2022 07:09:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=739
06/24/2022 07:09:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=744
06/24/2022 07:09:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=749
06/24/2022 07:09:21 - INFO - __main__ - Global step 1500 Train loss 0.11 ACC 0.5625 on epoch=749
06/24/2022 07:09:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=754
06/24/2022 07:09:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=759
06/24/2022 07:09:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=764
06/24/2022 07:09:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=769
06/24/2022 07:09:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=774
06/24/2022 07:09:28 - INFO - __main__ - Global step 1550 Train loss 0.08 ACC 0.5625 on epoch=774
06/24/2022 07:09:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=779
06/24/2022 07:09:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=784
06/24/2022 07:09:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=789
06/24/2022 07:09:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=794
06/24/2022 07:09:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.37 on epoch=799
06/24/2022 07:09:35 - INFO - __main__ - Global step 1600 Train loss 0.13 ACC 0.15625 on epoch=799
06/24/2022 07:09:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.32 on epoch=804
06/24/2022 07:09:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=809
06/24/2022 07:09:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=814
06/24/2022 07:09:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=819
06/24/2022 07:09:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=824
06/24/2022 07:09:41 - INFO - __main__ - Global step 1650 Train loss 0.18 ACC 0.5625 on epoch=824
06/24/2022 07:09:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=829
06/24/2022 07:09:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=834
06/24/2022 07:09:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=839
06/24/2022 07:09:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=844
06/24/2022 07:09:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=849
06/24/2022 07:09:48 - INFO - __main__ - Global step 1700 Train loss 0.11 ACC 0.3125 on epoch=849
06/24/2022 07:09:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=854
06/24/2022 07:09:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=859
06/24/2022 07:09:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=864
06/24/2022 07:09:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=869
06/24/2022 07:09:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=874
06/24/2022 07:09:55 - INFO - __main__ - Global step 1750 Train loss 0.09 ACC 0.53125 on epoch=874
06/24/2022 07:09:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=879
06/24/2022 07:09:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=884
06/24/2022 07:09:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=889
06/24/2022 07:10:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=894
06/24/2022 07:10:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=899
06/24/2022 07:10:02 - INFO - __main__ - Global step 1800 Train loss 0.04 ACC 0.5625 on epoch=899
06/24/2022 07:10:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=904
06/24/2022 07:10:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
06/24/2022 07:10:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=914
06/24/2022 07:10:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=919
06/24/2022 07:10:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=924
06/24/2022 07:10:08 - INFO - __main__ - Global step 1850 Train loss 0.05 ACC 0.53125 on epoch=924
06/24/2022 07:10:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=929
06/24/2022 07:10:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=934
06/24/2022 07:10:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=939
06/24/2022 07:10:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=944
06/24/2022 07:10:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=949
06/24/2022 07:10:15 - INFO - __main__ - Global step 1900 Train loss 0.05 ACC 0.4375 on epoch=949
06/24/2022 07:10:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=954
06/24/2022 07:10:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=959
06/24/2022 07:10:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=964
06/24/2022 07:10:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=969
06/24/2022 07:10:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=974
06/24/2022 07:10:22 - INFO - __main__ - Global step 1950 Train loss 0.05 ACC 0.375 on epoch=974
06/24/2022 07:10:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=979
06/24/2022 07:10:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=984
06/24/2022 07:10:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=989
06/24/2022 07:10:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=994
06/24/2022 07:10:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=999
06/24/2022 07:10:28 - INFO - __main__ - Global step 2000 Train loss 0.04 ACC 0.4375 on epoch=999
06/24/2022 07:10:28 - INFO - __main__ - save last model!
06/24/2022 07:10:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:10:28 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:10:28 - INFO - __main__ - Printing 3 examples
06/24/2022 07:10:28 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:10:28 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:10:29 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:10:29 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:10:29 - INFO - __main__ - Printing 3 examples
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:10:29 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:10:29 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:10:29 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:10:29 - INFO - __main__ - Printing 3 examples
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:10:29 - INFO - __main__ - ['duplicate']
06/24/2022 07:10:29 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:10:29 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:10:29 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:10:35 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 07:10:35 - INFO - __main__ - task name: glue-qqp
06/24/2022 07:10:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:10:36 - INFO - __main__ - Starting training!
06/24/2022 07:10:47 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:11:27 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 07:23:56 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_13_0.5_8_predictions.txt
06/24/2022 07:23:57 - INFO - __main__ - ACC on test data: 0.5048
06/24/2022 07:23:57 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.5, bsz=8, dev_performance=0.59375, test_performance=0.5048478852337374
06/24/2022 07:23:57 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.4, bsz=8 ...
06/24/2022 07:23:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:23:58 - INFO - __main__ - Printing 3 examples
06/24/2022 07:23:58 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:23:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:23:58 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:23:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:23:58 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:23:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:23:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:23:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:23:58 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:23:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:23:58 - INFO - __main__ - Printing 3 examples
06/24/2022 07:23:58 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:23:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:23:58 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:23:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:23:58 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:23:58 - INFO - __main__ - ['duplicate']
06/24/2022 07:23:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:23:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:23:58 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:24:03 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 07:24:03 - INFO - __main__ - task name: glue-qqp
06/24/2022 07:24:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:24:04 - INFO - __main__ - Starting training!
06/24/2022 07:24:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.29 on epoch=4
06/24/2022 07:24:06 - INFO - __main__ - Step 20 Global step 20 Train loss 2.47 on epoch=9
06/24/2022 07:24:08 - INFO - __main__ - Step 30 Global step 30 Train loss 0.89 on epoch=14
06/24/2022 07:24:09 - INFO - __main__ - Step 40 Global step 40 Train loss 0.54 on epoch=19
06/24/2022 07:24:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.43 on epoch=24
06/24/2022 07:24:11 - INFO - __main__ - Global step 50 Train loss 2.12 ACC 0.5 on epoch=24
06/24/2022 07:24:11 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 07:24:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.37 on epoch=29
06/24/2022 07:24:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.43 on epoch=34
06/24/2022 07:24:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.31 on epoch=39
06/24/2022 07:24:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.35 on epoch=44
06/24/2022 07:24:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.27 on epoch=49
06/24/2022 07:24:18 - INFO - __main__ - Global step 100 Train loss 0.35 ACC 0.5 on epoch=49
06/24/2022 07:24:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=54
06/24/2022 07:24:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.30 on epoch=59
06/24/2022 07:24:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=64
06/24/2022 07:24:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.29 on epoch=69
06/24/2022 07:24:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.31 on epoch=74
06/24/2022 07:24:24 - INFO - __main__ - Global step 150 Train loss 0.29 ACC 0.4375 on epoch=74
06/24/2022 07:24:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=79
06/24/2022 07:24:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.22 on epoch=84
06/24/2022 07:24:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=89
06/24/2022 07:24:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=94
06/24/2022 07:24:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.29 on epoch=99
06/24/2022 07:24:31 - INFO - __main__ - Global step 200 Train loss 0.26 ACC 0.25 on epoch=99
06/24/2022 07:24:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
06/24/2022 07:24:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.21 on epoch=109
06/24/2022 07:24:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.28 on epoch=114
06/24/2022 07:24:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 07:24:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=124
06/24/2022 07:24:38 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.1875 on epoch=124
06/24/2022 07:24:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.25 on epoch=129
06/24/2022 07:24:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/24/2022 07:24:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=139
06/24/2022 07:24:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/24/2022 07:24:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/24/2022 07:24:44 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.5 on epoch=149
06/24/2022 07:24:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/24/2022 07:24:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=159
06/24/2022 07:24:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=164
06/24/2022 07:24:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=169
06/24/2022 07:24:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=174
06/24/2022 07:24:51 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.21875 on epoch=174
06/24/2022 07:24:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=179
06/24/2022 07:24:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=184
06/24/2022 07:24:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=189
06/24/2022 07:24:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=194
06/24/2022 07:24:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=199
06/24/2022 07:24:58 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.21875 on epoch=199
06/24/2022 07:24:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=204
06/24/2022 07:25:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=209
06/24/2022 07:25:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=214
06/24/2022 07:25:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/24/2022 07:25:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=224
06/24/2022 07:25:05 - INFO - __main__ - Global step 450 Train loss 0.22 ACC 0.21875 on epoch=224
06/24/2022 07:25:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=229
06/24/2022 07:25:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=234
06/24/2022 07:25:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=239
06/24/2022 07:25:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=244
06/24/2022 07:25:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=249
06/24/2022 07:25:11 - INFO - __main__ - Global step 500 Train loss 0.23 ACC 0.1875 on epoch=249
06/24/2022 07:25:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/24/2022 07:25:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=259
06/24/2022 07:25:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 07:25:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=269
06/24/2022 07:25:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/24/2022 07:25:18 - INFO - __main__ - Global step 550 Train loss 0.23 ACC 0.21875 on epoch=274
06/24/2022 07:25:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=279
06/24/2022 07:25:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=284
06/24/2022 07:25:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=289
06/24/2022 07:25:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=294
06/24/2022 07:25:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=299
06/24/2022 07:25:25 - INFO - __main__ - Global step 600 Train loss 0.22 ACC 0.21875 on epoch=299
06/24/2022 07:25:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=304
06/24/2022 07:25:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=309
06/24/2022 07:25:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=314
06/24/2022 07:25:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=319
06/24/2022 07:25:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=324
06/24/2022 07:25:31 - INFO - __main__ - Global step 650 Train loss 0.20 ACC 0.25 on epoch=324
06/24/2022 07:25:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=329
06/24/2022 07:25:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=334
06/24/2022 07:25:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=339
06/24/2022 07:25:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=344
06/24/2022 07:25:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=349
06/24/2022 07:25:38 - INFO - __main__ - Global step 700 Train loss 0.21 ACC 0.28125 on epoch=349
06/24/2022 07:25:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=354
06/24/2022 07:25:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=359
06/24/2022 07:25:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=364
06/24/2022 07:25:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=369
06/24/2022 07:25:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=374
06/24/2022 07:25:45 - INFO - __main__ - Global step 750 Train loss 0.20 ACC 0.25 on epoch=374
06/24/2022 07:25:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=379
06/24/2022 07:25:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=384
06/24/2022 07:25:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=389
06/24/2022 07:25:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=394
06/24/2022 07:25:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=399
06/24/2022 07:25:52 - INFO - __main__ - Global step 800 Train loss 0.19 ACC 0.25 on epoch=399
06/24/2022 07:25:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=404
06/24/2022 07:25:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=409
06/24/2022 07:25:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=414
06/24/2022 07:25:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=419
06/24/2022 07:25:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=424
06/24/2022 07:25:58 - INFO - __main__ - Global step 850 Train loss 0.15 ACC 0.25 on epoch=424
06/24/2022 07:26:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=429
06/24/2022 07:26:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=434
06/24/2022 07:26:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=439
06/24/2022 07:26:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=444
06/24/2022 07:26:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=449
06/24/2022 07:26:05 - INFO - __main__ - Global step 900 Train loss 0.14 ACC 0.40625 on epoch=449
06/24/2022 07:26:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=454
06/24/2022 07:26:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=459
06/24/2022 07:26:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=464
06/24/2022 07:26:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=469
06/24/2022 07:26:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=474
06/24/2022 07:26:12 - INFO - __main__ - Global step 950 Train loss 0.12 ACC 0.28125 on epoch=474
06/24/2022 07:26:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=479
06/24/2022 07:26:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=484
06/24/2022 07:26:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=489
06/24/2022 07:26:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=494
06/24/2022 07:26:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=499
06/24/2022 07:26:19 - INFO - __main__ - Global step 1000 Train loss 0.10 ACC 0.25 on epoch=499
06/24/2022 07:26:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=504
06/24/2022 07:26:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=509
06/24/2022 07:26:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=514
06/24/2022 07:26:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=519
06/24/2022 07:26:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=524
06/24/2022 07:26:25 - INFO - __main__ - Global step 1050 Train loss 0.06 ACC 0.21875 on epoch=524
06/24/2022 07:26:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/24/2022 07:26:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=534
06/24/2022 07:26:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=539
06/24/2022 07:26:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
06/24/2022 07:26:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=549
06/24/2022 07:26:32 - INFO - __main__ - Global step 1100 Train loss 0.07 ACC 0.21875 on epoch=549
06/24/2022 07:26:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=554
06/24/2022 07:26:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=559
06/24/2022 07:26:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=564
06/24/2022 07:26:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=569
06/24/2022 07:26:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=574
06/24/2022 07:26:39 - INFO - __main__ - Global step 1150 Train loss 0.07 ACC 0.25 on epoch=574
06/24/2022 07:26:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=579
06/24/2022 07:26:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=584
06/24/2022 07:26:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
06/24/2022 07:26:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=594
06/24/2022 07:26:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=599
06/24/2022 07:26:45 - INFO - __main__ - Global step 1200 Train loss 0.05 ACC 0.21875 on epoch=599
06/24/2022 07:26:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 07:26:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=609
06/24/2022 07:26:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 07:26:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=619
06/24/2022 07:26:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/24/2022 07:26:53 - INFO - __main__ - Global step 1250 Train loss 0.04 ACC 0.1875 on epoch=624
06/24/2022 07:26:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=629
06/24/2022 07:26:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=634
06/24/2022 07:26:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 07:26:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
06/24/2022 07:26:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=649
06/24/2022 07:27:00 - INFO - __main__ - Global step 1300 Train loss 0.03 ACC 0.3125 on epoch=649
06/24/2022 07:27:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.66 on epoch=654
06/24/2022 07:27:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=659
06/24/2022 07:27:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=664
06/24/2022 07:27:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 07:27:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=674
06/24/2022 07:27:07 - INFO - __main__ - Global step 1350 Train loss 0.16 ACC 0.21875 on epoch=674
06/24/2022 07:27:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=679
06/24/2022 07:27:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=684
06/24/2022 07:27:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
06/24/2022 07:27:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 07:27:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 07:27:15 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.1875 on epoch=699
06/24/2022 07:27:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 07:27:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 07:27:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=714
06/24/2022 07:27:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=719
06/24/2022 07:27:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=724
06/24/2022 07:27:23 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.25 on epoch=724
06/24/2022 07:27:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=729
06/24/2022 07:27:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/24/2022 07:27:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
06/24/2022 07:27:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 07:27:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=749
06/24/2022 07:27:30 - INFO - __main__ - Global step 1500 Train loss 0.02 ACC 0.28125 on epoch=749
06/24/2022 07:27:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=754
06/24/2022 07:27:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=759
06/24/2022 07:27:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=764
06/24/2022 07:27:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=769
06/24/2022 07:27:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
06/24/2022 07:27:36 - INFO - __main__ - Global step 1550 Train loss 0.04 ACC 0.25 on epoch=774
06/24/2022 07:27:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 07:27:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
06/24/2022 07:27:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
06/24/2022 07:27:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=794
06/24/2022 07:27:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=799
06/24/2022 07:27:43 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.25 on epoch=799
06/24/2022 07:27:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
06/24/2022 07:27:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/24/2022 07:27:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
06/24/2022 07:27:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
06/24/2022 07:27:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 07:27:50 - INFO - __main__ - Global step 1650 Train loss 0.02 ACC 0.28125 on epoch=824
06/24/2022 07:27:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 07:27:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=834
06/24/2022 07:27:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/24/2022 07:27:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/24/2022 07:27:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/24/2022 07:27:56 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.25 on epoch=849
06/24/2022 07:27:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 07:27:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 07:28:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=864
06/24/2022 07:28:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=869
06/24/2022 07:28:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 07:28:03 - INFO - __main__ - Global step 1750 Train loss 0.01 ACC 0.25 on epoch=874
06/24/2022 07:28:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 07:28:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 07:28:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 07:28:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 07:28:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 07:28:10 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.15625 on epoch=899
06/24/2022 07:28:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 07:28:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=909
06/24/2022 07:28:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=914
06/24/2022 07:28:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 07:28:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/24/2022 07:28:18 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.21875 on epoch=924
06/24/2022 07:28:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 07:28:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 07:28:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 07:28:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 07:28:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 07:28:25 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.21875 on epoch=949
06/24/2022 07:28:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=954
06/24/2022 07:28:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=959
06/24/2022 07:28:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=964
06/24/2022 07:28:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=969
06/24/2022 07:28:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=974
06/24/2022 07:28:32 - INFO - __main__ - Global step 1950 Train loss 0.06 ACC 0.28125 on epoch=974
06/24/2022 07:28:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=979
06/24/2022 07:28:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 07:28:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=989
06/24/2022 07:28:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 07:28:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=999
06/24/2022 07:28:39 - INFO - __main__ - Global step 2000 Train loss 0.04 ACC 0.1875 on epoch=999
06/24/2022 07:28:39 - INFO - __main__ - save last model!
06/24/2022 07:28:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:28:39 - INFO - __main__ - Printing 3 examples
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:28:39 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:28:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:28:39 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:28:39 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:28:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:28:39 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:28:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:28:39 - INFO - __main__ - Printing 3 examples
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:28:39 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:28:39 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:28:39 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:28:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:28:39 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:28:39 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:28:39 - INFO - __main__ - Printing 3 examples
06/24/2022 07:28:39 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:28:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:28:40 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:28:40 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:28:40 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:28:40 - INFO - __main__ - ['duplicate']
06/24/2022 07:28:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:28:45 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 07:28:45 - INFO - __main__ - task name: glue-qqp
06/24/2022 07:28:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:28:45 - INFO - __main__ - Starting training!
06/24/2022 07:28:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:29:39 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 07:54:18 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_13_0.4_8_predictions.txt
06/24/2022 07:54:18 - INFO - __main__ - ACC on test data: 0.5466
06/24/2022 07:54:18 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.4, bsz=8, dev_performance=0.5, test_performance=0.5465743259955479
06/24/2022 07:54:18 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.3, bsz=8 ...
06/24/2022 07:54:19 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:54:19 - INFO - __main__ - Printing 3 examples
06/24/2022 07:54:19 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:54:19 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:19 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:54:19 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:19 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:54:19 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:54:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:54:19 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:54:19 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:54:19 - INFO - __main__ - Printing 3 examples
06/24/2022 07:54:19 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:54:19 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:19 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:54:19 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:19 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:54:19 - INFO - __main__ - ['duplicate']
06/24/2022 07:54:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:54:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:54:20 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:54:26 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 07:54:26 - INFO - __main__ - task name: glue-qqp
06/24/2022 07:54:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:54:26 - INFO - __main__ - Starting training!
06/24/2022 07:54:27 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=4
06/24/2022 07:54:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.48 on epoch=9
06/24/2022 07:54:30 - INFO - __main__ - Step 30 Global step 30 Train loss 1.34 on epoch=14
06/24/2022 07:54:31 - INFO - __main__ - Step 40 Global step 40 Train loss 0.73 on epoch=19
06/24/2022 07:54:32 - INFO - __main__ - Step 50 Global step 50 Train loss 0.55 on epoch=24
06/24/2022 07:54:33 - INFO - __main__ - Global step 50 Train loss 2.55 ACC 0.46875 on epoch=24
06/24/2022 07:54:33 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.46875 on epoch=24, global_step=50
06/24/2022 07:54:34 - INFO - __main__ - Step 60 Global step 60 Train loss 0.46 on epoch=29
06/24/2022 07:54:36 - INFO - __main__ - Step 70 Global step 70 Train loss 0.46 on epoch=34
06/24/2022 07:54:37 - INFO - __main__ - Step 80 Global step 80 Train loss 0.41 on epoch=39
06/24/2022 07:54:38 - INFO - __main__ - Step 90 Global step 90 Train loss 0.33 on epoch=44
06/24/2022 07:54:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.41 on epoch=49
06/24/2022 07:54:40 - INFO - __main__ - Global step 100 Train loss 0.41 ACC 0.5 on epoch=49
06/24/2022 07:54:40 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=49, global_step=100
06/24/2022 07:54:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=54
06/24/2022 07:54:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.29 on epoch=59
06/24/2022 07:54:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/24/2022 07:54:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.35 on epoch=69
06/24/2022 07:54:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
06/24/2022 07:54:47 - INFO - __main__ - Global step 150 Train loss 0.32 ACC 0.21875 on epoch=74
06/24/2022 07:54:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.32 on epoch=79
06/24/2022 07:54:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=84
06/24/2022 07:54:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=89
06/24/2022 07:54:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=94
06/24/2022 07:54:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=99
06/24/2022 07:54:54 - INFO - __main__ - Global step 200 Train loss 0.27 ACC 0.21875 on epoch=99
06/24/2022 07:54:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.27 on epoch=104
06/24/2022 07:54:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=109
06/24/2022 07:54:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=114
06/24/2022 07:54:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=119
06/24/2022 07:55:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=124
06/24/2022 07:55:00 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.40625 on epoch=124
06/24/2022 07:55:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.25 on epoch=129
06/24/2022 07:55:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=134
06/24/2022 07:55:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=139
06/24/2022 07:55:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/24/2022 07:55:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=149
06/24/2022 07:55:07 - INFO - __main__ - Global step 300 Train loss 0.25 ACC 0.375 on epoch=149
06/24/2022 07:55:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/24/2022 07:55:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.73 on epoch=159
06/24/2022 07:55:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=164
06/24/2022 07:55:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=169
06/24/2022 07:55:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=174
06/24/2022 07:55:14 - INFO - __main__ - Global step 350 Train loss 0.34 ACC 0.40625 on epoch=174
06/24/2022 07:55:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=179
06/24/2022 07:55:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=184
06/24/2022 07:55:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=189
06/24/2022 07:55:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=194
06/24/2022 07:55:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/24/2022 07:55:21 - INFO - __main__ - Global step 400 Train loss 0.24 ACC 0.15625 on epoch=199
06/24/2022 07:55:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=204
06/24/2022 07:55:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=209
06/24/2022 07:55:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=214
06/24/2022 07:55:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=219
06/24/2022 07:55:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/24/2022 07:55:28 - INFO - __main__ - Global step 450 Train loss 0.24 ACC 0.1875 on epoch=224
06/24/2022 07:55:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 07:55:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=234
06/24/2022 07:55:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=239
06/24/2022 07:55:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=244
06/24/2022 07:55:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=249
06/24/2022 07:55:35 - INFO - __main__ - Global step 500 Train loss 0.25 ACC 0.375 on epoch=249
06/24/2022 07:55:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=254
06/24/2022 07:55:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=259
06/24/2022 07:55:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=264
06/24/2022 07:55:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=269
06/24/2022 07:55:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=274
06/24/2022 07:55:42 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.25 on epoch=274
06/24/2022 07:55:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=279
06/24/2022 07:55:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=284
06/24/2022 07:55:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=289
06/24/2022 07:55:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=294
06/24/2022 07:55:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=299
06/24/2022 07:55:49 - INFO - __main__ - Global step 600 Train loss 0.23 ACC 0.21875 on epoch=299
06/24/2022 07:55:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=304
06/24/2022 07:55:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=309
06/24/2022 07:55:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=314
06/24/2022 07:55:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=319
06/24/2022 07:55:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=324
06/24/2022 07:55:56 - INFO - __main__ - Global step 650 Train loss 0.22 ACC 0.34375 on epoch=324
06/24/2022 07:55:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=329
06/24/2022 07:55:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=334
06/24/2022 07:55:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=339
06/24/2022 07:56:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=344
06/24/2022 07:56:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=349
06/24/2022 07:56:02 - INFO - __main__ - Global step 700 Train loss 0.19 ACC 0.15625 on epoch=349
06/24/2022 07:56:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=354
06/24/2022 07:56:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/24/2022 07:56:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=364
06/24/2022 07:56:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=369
06/24/2022 07:56:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=374
06/24/2022 07:56:09 - INFO - __main__ - Global step 750 Train loss 0.21 ACC 0.21875 on epoch=374
06/24/2022 07:56:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=379
06/24/2022 07:56:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=384
06/24/2022 07:56:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=389
06/24/2022 07:56:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=394
06/24/2022 07:56:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=399
06/24/2022 07:56:16 - INFO - __main__ - Global step 800 Train loss 0.22 ACC 0.34375 on epoch=399
06/24/2022 07:56:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=404
06/24/2022 07:56:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=409
06/24/2022 07:56:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=414
06/24/2022 07:56:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=419
06/24/2022 07:56:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=424
06/24/2022 07:56:23 - INFO - __main__ - Global step 850 Train loss 0.21 ACC 0.25 on epoch=424
06/24/2022 07:56:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=429
06/24/2022 07:56:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=434
06/24/2022 07:56:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=439
06/24/2022 07:56:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=444
06/24/2022 07:56:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=449
06/24/2022 07:56:30 - INFO - __main__ - Global step 900 Train loss 0.20 ACC 0.1875 on epoch=449
06/24/2022 07:56:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=454
06/24/2022 07:56:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=459
06/24/2022 07:56:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=464
06/24/2022 07:56:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=469
06/24/2022 07:56:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=474
06/24/2022 07:56:37 - INFO - __main__ - Global step 950 Train loss 0.20 ACC 0.25 on epoch=474
06/24/2022 07:56:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=479
06/24/2022 07:56:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=484
06/24/2022 07:56:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=489
06/24/2022 07:56:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=494
06/24/2022 07:56:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=499
06/24/2022 07:56:44 - INFO - __main__ - Global step 1000 Train loss 0.19 ACC 0.28125 on epoch=499
06/24/2022 07:56:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=504
06/24/2022 07:56:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=509
06/24/2022 07:56:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=514
06/24/2022 07:56:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=519
06/24/2022 07:56:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=524
06/24/2022 07:56:51 - INFO - __main__ - Global step 1050 Train loss 0.18 ACC 0.375 on epoch=524
06/24/2022 07:56:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=529
06/24/2022 07:56:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=534
06/24/2022 07:56:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=539
06/24/2022 07:56:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=544
06/24/2022 07:56:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=549
06/24/2022 07:56:57 - INFO - __main__ - Global step 1100 Train loss 0.15 ACC 0.28125 on epoch=549
06/24/2022 07:56:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=554
06/24/2022 07:57:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=559
06/24/2022 07:57:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=564
06/24/2022 07:57:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=569
06/24/2022 07:57:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=574
06/24/2022 07:57:04 - INFO - __main__ - Global step 1150 Train loss 0.15 ACC 0.25 on epoch=574
06/24/2022 07:57:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=579
06/24/2022 07:57:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=584
06/24/2022 07:57:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=589
06/24/2022 07:57:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=594
06/24/2022 07:57:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=599
06/24/2022 07:57:11 - INFO - __main__ - Global step 1200 Train loss 0.13 ACC 0.46875 on epoch=599
06/24/2022 07:57:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=604
06/24/2022 07:57:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=609
06/24/2022 07:57:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=614
06/24/2022 07:57:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=619
06/24/2022 07:57:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=624
06/24/2022 07:57:18 - INFO - __main__ - Global step 1250 Train loss 0.12 ACC 0.375 on epoch=624
06/24/2022 07:57:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=629
06/24/2022 07:57:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=634
06/24/2022 07:57:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=639
06/24/2022 07:57:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.29 on epoch=644
06/24/2022 07:57:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.26 on epoch=649
06/24/2022 07:57:25 - INFO - __main__ - Global step 1300 Train loss 0.19 ACC 0.40625 on epoch=649
06/24/2022 07:57:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=654
06/24/2022 07:57:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=659
06/24/2022 07:57:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=664
06/24/2022 07:57:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=669
06/24/2022 07:57:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=674
06/24/2022 07:57:32 - INFO - __main__ - Global step 1350 Train loss 0.08 ACC 0.3125 on epoch=674
06/24/2022 07:57:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=679
06/24/2022 07:57:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=684
06/24/2022 07:57:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=689
06/24/2022 07:57:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=694
06/24/2022 07:57:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=699
06/24/2022 07:57:39 - INFO - __main__ - Global step 1400 Train loss 0.10 ACC 0.53125 on epoch=699
06/24/2022 07:57:39 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=699, global_step=1400
06/24/2022 07:57:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=704
06/24/2022 07:57:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=709
06/24/2022 07:57:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=714
06/24/2022 07:57:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=719
06/24/2022 07:57:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=724
06/24/2022 07:57:46 - INFO - __main__ - Global step 1450 Train loss 0.05 ACC 0.46875 on epoch=724
06/24/2022 07:57:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=729
06/24/2022 07:57:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=734
06/24/2022 07:57:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=739
06/24/2022 07:57:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=744
06/24/2022 07:57:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=749
06/24/2022 07:57:52 - INFO - __main__ - Global step 1500 Train loss 0.07 ACC 0.5 on epoch=749
06/24/2022 07:57:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=754
06/24/2022 07:57:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=759
06/24/2022 07:57:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=764
06/24/2022 07:57:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=769
06/24/2022 07:57:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=774
06/24/2022 07:57:59 - INFO - __main__ - Global step 1550 Train loss 0.07 ACC 0.59375 on epoch=774
06/24/2022 07:57:59 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=774, global_step=1550
06/24/2022 07:58:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=779
06/24/2022 07:58:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=784
06/24/2022 07:58:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
06/24/2022 07:58:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=794
06/24/2022 07:58:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=799
06/24/2022 07:58:06 - INFO - __main__ - Global step 1600 Train loss 0.05 ACC 0.5 on epoch=799
06/24/2022 07:58:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=804
06/24/2022 07:58:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/24/2022 07:58:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=814
06/24/2022 07:58:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=819
06/24/2022 07:58:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=824
06/24/2022 07:58:13 - INFO - __main__ - Global step 1650 Train loss 0.05 ACC 0.5 on epoch=824
06/24/2022 07:58:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=829
06/24/2022 07:58:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=834
06/24/2022 07:58:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=839
06/24/2022 07:58:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=844
06/24/2022 07:58:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=849
06/24/2022 07:58:20 - INFO - __main__ - Global step 1700 Train loss 0.04 ACC 0.46875 on epoch=849
06/24/2022 07:58:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
06/24/2022 07:58:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=859
06/24/2022 07:58:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=864
06/24/2022 07:58:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
06/24/2022 07:58:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=874
06/24/2022 07:58:27 - INFO - __main__ - Global step 1750 Train loss 0.04 ACC 0.46875 on epoch=874
06/24/2022 07:58:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=879
06/24/2022 07:58:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=884
06/24/2022 07:58:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=889
06/24/2022 07:58:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=894
06/24/2022 07:58:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=899
06/24/2022 07:58:34 - INFO - __main__ - Global step 1800 Train loss 0.07 ACC 0.5 on epoch=899
06/24/2022 07:58:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 07:58:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=909
06/24/2022 07:58:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=914
06/24/2022 07:58:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=919
06/24/2022 07:58:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=924
06/24/2022 07:58:41 - INFO - __main__ - Global step 1850 Train loss 0.04 ACC 0.4375 on epoch=924
06/24/2022 07:58:42 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=929
06/24/2022 07:58:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=934
06/24/2022 07:58:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=939
06/24/2022 07:58:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=944
06/24/2022 07:58:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
06/24/2022 07:58:48 - INFO - __main__ - Global step 1900 Train loss 0.03 ACC 0.4375 on epoch=949
06/24/2022 07:58:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=954
06/24/2022 07:58:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/24/2022 07:58:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/24/2022 07:58:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=969
06/24/2022 07:58:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 07:58:54 - INFO - __main__ - Global step 1950 Train loss 0.02 ACC 0.46875 on epoch=974
06/24/2022 07:58:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=979
06/24/2022 07:58:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=984
06/24/2022 07:58:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=989
06/24/2022 07:59:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=994
06/24/2022 07:59:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=999
06/24/2022 07:59:01 - INFO - __main__ - Global step 2000 Train loss 0.07 ACC 0.40625 on epoch=999
06/24/2022 07:59:01 - INFO - __main__ - save last model!
06/24/2022 07:59:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 07:59:02 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 07:59:02 - INFO - __main__ - Printing 3 examples
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 07:59:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 07:59:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:59:02 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:59:02 - INFO - __main__ - Printing 3 examples
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:59:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:59:02 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 07:59:02 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 07:59:02 - INFO - __main__ - Printing 3 examples
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 07:59:02 - INFO - __main__ - ['duplicate']
06/24/2022 07:59:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 07:59:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 07:59:02 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 07:59:08 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 07:59:08 - INFO - __main__ - task name: glue-qqp
06/24/2022 07:59:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 07:59:09 - INFO - __main__ - Starting training!
06/24/2022 07:59:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:00:01 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 08:13:06 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_13_0.3_8_predictions.txt
06/24/2022 08:13:06 - INFO - __main__ - ACC on test data: 0.5375
06/24/2022 08:13:06 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.3, bsz=8, dev_performance=0.59375, test_performance=0.5374721741281226
06/24/2022 08:13:06 - INFO - __main__ - Running ... prefix=glue-qqp_16_13, lr=0.2, bsz=8 ...
06/24/2022 08:13:07 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:13:07 - INFO - __main__ - Printing 3 examples
06/24/2022 08:13:07 - INFO - __main__ -  [glue-qqp] question 1: Can I develope mobile apps with c++? [SEP] question 2: How can I develop mobile apps with C++?
06/24/2022 08:13:07 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:07 - INFO - __main__ -  [glue-qqp] question 1: What is the disadvantage of option subject anthropology? [SEP] question 2: What are disadvantages of anthropology?
06/24/2022 08:13:07 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:07 - INFO - __main__ -  [glue-qqp] question 1: Why the banning of 500 and 1000 rupees notes? [SEP] question 2: Why did GOI demobilise 500 and 1000 rupee notes?
06/24/2022 08:13:07 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:07 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:13:07 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:13:07 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:13:07 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:13:07 - INFO - __main__ - Printing 3 examples
06/24/2022 08:13:07 - INFO - __main__ -  [glue-qqp] question 1: What, according to you, is the best Disney film? [SEP] question 2: What is the best Disney movie?
06/24/2022 08:13:07 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:07 - INFO - __main__ -  [glue-qqp] question 1: How do I stop masturbation and forget women? [SEP] question 2: How can I stop masturbating?
06/24/2022 08:13:07 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:07 - INFO - __main__ -  [glue-qqp] question 1: How do I commit suicide with no pain? [SEP] question 2: What is the best way to commit suicide in India?
06/24/2022 08:13:07 - INFO - __main__ - ['duplicate']
06/24/2022 08:13:07 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:13:07 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:13:07 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:13:13 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 08:13:13 - INFO - __main__ - task name: glue-qqp
06/24/2022 08:13:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:13:13 - INFO - __main__ - Starting training!
06/24/2022 08:13:15 - INFO - __main__ - Step 10 Global step 10 Train loss 6.81 on epoch=4
06/24/2022 08:13:16 - INFO - __main__ - Step 20 Global step 20 Train loss 4.36 on epoch=9
06/24/2022 08:13:17 - INFO - __main__ - Step 30 Global step 30 Train loss 2.48 on epoch=14
06/24/2022 08:13:19 - INFO - __main__ - Step 40 Global step 40 Train loss 1.48 on epoch=19
06/24/2022 08:13:20 - INFO - __main__ - Step 50 Global step 50 Train loss 1.04 on epoch=24
06/24/2022 08:13:21 - INFO - __main__ - Global step 50 Train loss 3.24 ACC 0.4375 on epoch=24
06/24/2022 08:13:21 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
06/24/2022 08:13:22 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=29
06/24/2022 08:13:23 - INFO - __main__ - Step 70 Global step 70 Train loss 0.62 on epoch=34
06/24/2022 08:13:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.54 on epoch=39
06/24/2022 08:13:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.49 on epoch=44
06/24/2022 08:13:27 - INFO - __main__ - Step 100 Global step 100 Train loss 0.46 on epoch=49
06/24/2022 08:13:28 - INFO - __main__ - Global step 100 Train loss 0.60 ACC 0.375 on epoch=49
06/24/2022 08:13:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.53 on epoch=54
06/24/2022 08:13:30 - INFO - __main__ - Step 120 Global step 120 Train loss 0.47 on epoch=59
06/24/2022 08:13:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.49 on epoch=64
06/24/2022 08:13:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.45 on epoch=69
06/24/2022 08:13:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.41 on epoch=74
06/24/2022 08:13:35 - INFO - __main__ - Global step 150 Train loss 0.47 ACC 0.4375 on epoch=74
06/24/2022 08:13:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.39 on epoch=79
06/24/2022 08:13:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=84
06/24/2022 08:13:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=89
06/24/2022 08:13:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.38 on epoch=94
06/24/2022 08:13:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.33 on epoch=99
06/24/2022 08:13:41 - INFO - __main__ - Global step 200 Train loss 0.37 ACC 0.46875 on epoch=99
06/24/2022 08:13:42 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.46875 on epoch=99, global_step=200
06/24/2022 08:13:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.31 on epoch=104
06/24/2022 08:13:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=109
06/24/2022 08:13:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=114
06/24/2022 08:13:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=119
06/24/2022 08:13:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=124
06/24/2022 08:13:48 - INFO - __main__ - Global step 250 Train loss 0.35 ACC 0.4375 on epoch=124
06/24/2022 08:13:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=129
06/24/2022 08:13:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=134
06/24/2022 08:13:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=139
06/24/2022 08:13:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=144
06/24/2022 08:13:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/24/2022 08:13:55 - INFO - __main__ - Global step 300 Train loss 0.33 ACC 0.46875 on epoch=149
06/24/2022 08:13:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/24/2022 08:13:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=159
06/24/2022 08:13:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=164
06/24/2022 08:14:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=169
06/24/2022 08:14:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=174
06/24/2022 08:14:02 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.46875 on epoch=174
06/24/2022 08:14:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=179
06/24/2022 08:14:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=184
06/24/2022 08:14:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=189
06/24/2022 08:14:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=194
06/24/2022 08:14:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/24/2022 08:14:09 - INFO - __main__ - Global step 400 Train loss 0.27 ACC 0.25 on epoch=199
06/24/2022 08:14:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=204
06/24/2022 08:14:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=209
06/24/2022 08:14:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=214
06/24/2022 08:14:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=219
06/24/2022 08:14:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=224
06/24/2022 08:14:16 - INFO - __main__ - Global step 450 Train loss 0.29 ACC 0.46875 on epoch=224
06/24/2022 08:14:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=229
06/24/2022 08:14:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=234
06/24/2022 08:14:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=239
06/24/2022 08:14:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=244
06/24/2022 08:14:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=249
06/24/2022 08:14:23 - INFO - __main__ - Global step 500 Train loss 0.25 ACC 0.15625 on epoch=249
06/24/2022 08:14:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=254
06/24/2022 08:14:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=259
06/24/2022 08:14:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=264
06/24/2022 08:14:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=269
06/24/2022 08:14:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=274
06/24/2022 08:14:30 - INFO - __main__ - Global step 550 Train loss 0.28 ACC 0.1875 on epoch=274
06/24/2022 08:14:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=279
06/24/2022 08:14:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=284
06/24/2022 08:14:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=289
06/24/2022 08:14:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=294
06/24/2022 08:14:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=299
06/24/2022 08:14:37 - INFO - __main__ - Global step 600 Train loss 0.26 ACC 0.15625 on epoch=299
06/24/2022 08:14:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=304
06/24/2022 08:14:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=309
06/24/2022 08:14:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=314
06/24/2022 08:14:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=319
06/24/2022 08:14:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=324
06/24/2022 08:14:44 - INFO - __main__ - Global step 650 Train loss 0.23 ACC 0.1875 on epoch=324
06/24/2022 08:14:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=329
06/24/2022 08:14:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=334
06/24/2022 08:14:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=339
06/24/2022 08:14:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=344
06/24/2022 08:14:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.54 on epoch=349
06/24/2022 08:14:51 - INFO - __main__ - Global step 700 Train loss 0.33 ACC 0.1875 on epoch=349
06/24/2022 08:14:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=354
06/24/2022 08:14:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=359
06/24/2022 08:14:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=364
06/24/2022 08:14:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=369
06/24/2022 08:14:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=374
06/24/2022 08:14:58 - INFO - __main__ - Global step 750 Train loss 0.25 ACC 0.15625 on epoch=374
06/24/2022 08:14:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=379
06/24/2022 08:15:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=384
06/24/2022 08:15:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=389
06/24/2022 08:15:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=394
06/24/2022 08:15:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=399
06/24/2022 08:15:05 - INFO - __main__ - Global step 800 Train loss 0.22 ACC 0.1875 on epoch=399
06/24/2022 08:15:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=404
06/24/2022 08:15:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=409
06/24/2022 08:15:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=414
06/24/2022 08:15:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=419
06/24/2022 08:15:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=424
06/24/2022 08:15:12 - INFO - __main__ - Global step 850 Train loss 0.21 ACC 0.15625 on epoch=424
06/24/2022 08:15:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=429
06/24/2022 08:15:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=434
06/24/2022 08:15:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/24/2022 08:15:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=444
06/24/2022 08:15:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=449
06/24/2022 08:15:19 - INFO - __main__ - Global step 900 Train loss 0.22 ACC 0.25 on epoch=449
06/24/2022 08:15:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=454
06/24/2022 08:15:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=459
06/24/2022 08:15:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=464
06/24/2022 08:15:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=469
06/24/2022 08:15:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=474
06/24/2022 08:15:26 - INFO - __main__ - Global step 950 Train loss 0.22 ACC 0.15625 on epoch=474
06/24/2022 08:15:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=479
06/24/2022 08:15:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=484
06/24/2022 08:15:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=489
06/24/2022 08:15:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=494
06/24/2022 08:15:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=499
06/24/2022 08:15:33 - INFO - __main__ - Global step 1000 Train loss 0.22 ACC 0.25 on epoch=499
06/24/2022 08:15:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=504
06/24/2022 08:15:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=509
06/24/2022 08:15:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=514
06/24/2022 08:15:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=519
06/24/2022 08:15:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=524
06/24/2022 08:15:40 - INFO - __main__ - Global step 1050 Train loss 0.21 ACC 0.15625 on epoch=524
06/24/2022 08:15:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.23 on epoch=529
06/24/2022 08:15:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=534
06/24/2022 08:15:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.27 on epoch=539
06/24/2022 08:15:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=544
06/24/2022 08:15:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=549
06/24/2022 08:15:47 - INFO - __main__ - Global step 1100 Train loss 0.24 ACC 0.1875 on epoch=549
06/24/2022 08:15:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=554
06/24/2022 08:15:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=559
06/24/2022 08:15:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=564
06/24/2022 08:15:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=569
06/24/2022 08:15:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=574
06/24/2022 08:15:54 - INFO - __main__ - Global step 1150 Train loss 0.23 ACC 0.1875 on epoch=574
06/24/2022 08:15:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=579
06/24/2022 08:15:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=584
06/24/2022 08:15:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=589
06/24/2022 08:15:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=594
06/24/2022 08:16:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=599
06/24/2022 08:16:01 - INFO - __main__ - Global step 1200 Train loss 0.24 ACC 0.1875 on epoch=599
06/24/2022 08:16:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.25 on epoch=604
06/24/2022 08:16:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=609
06/24/2022 08:16:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=614
06/24/2022 08:16:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=619
06/24/2022 08:16:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=624
06/24/2022 08:16:08 - INFO - __main__ - Global step 1250 Train loss 0.20 ACC 0.15625 on epoch=624
06/24/2022 08:16:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=629
06/24/2022 08:16:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=634
06/24/2022 08:16:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=639
06/24/2022 08:16:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=644
06/24/2022 08:16:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=649
06/24/2022 08:16:15 - INFO - __main__ - Global step 1300 Train loss 0.20 ACC 0.46875 on epoch=649
06/24/2022 08:16:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=654
06/24/2022 08:16:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=659
06/24/2022 08:16:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=664
06/24/2022 08:16:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=669
06/24/2022 08:16:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=674
06/24/2022 08:16:22 - INFO - __main__ - Global step 1350 Train loss 0.19 ACC 0.40625 on epoch=674
06/24/2022 08:16:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=679
06/24/2022 08:16:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=684
06/24/2022 08:16:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=689
06/24/2022 08:16:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=694
06/24/2022 08:16:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.22 on epoch=699
06/24/2022 08:16:29 - INFO - __main__ - Global step 1400 Train loss 0.19 ACC 0.3125 on epoch=699
06/24/2022 08:16:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=704
06/24/2022 08:16:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=709
06/24/2022 08:16:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=714
06/24/2022 08:16:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=719
06/24/2022 08:16:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=724
06/24/2022 08:16:36 - INFO - __main__ - Global step 1450 Train loss 0.14 ACC 0.34375 on epoch=724
06/24/2022 08:16:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=729
06/24/2022 08:16:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=734
06/24/2022 08:16:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=739
06/24/2022 08:16:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=744
06/24/2022 08:16:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=749
06/24/2022 08:16:43 - INFO - __main__ - Global step 1500 Train loss 0.15 ACC 0.4375 on epoch=749
06/24/2022 08:16:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=754
06/24/2022 08:16:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=759
06/24/2022 08:16:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=764
06/24/2022 08:16:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.16 on epoch=769
06/24/2022 08:16:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=774
06/24/2022 08:16:50 - INFO - __main__ - Global step 1550 Train loss 0.12 ACC 0.5 on epoch=774
06/24/2022 08:16:50 - INFO - __main__ - Saving model with best ACC: 0.46875 -> 0.5 on epoch=774, global_step=1550
06/24/2022 08:16:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=779
06/24/2022 08:16:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=784
06/24/2022 08:16:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=789
06/24/2022 08:16:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=794
06/24/2022 08:16:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=799
06/24/2022 08:16:57 - INFO - __main__ - Global step 1600 Train loss 0.12 ACC 0.4375 on epoch=799
06/24/2022 08:16:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=804
06/24/2022 08:17:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=809
06/24/2022 08:17:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=814
06/24/2022 08:17:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=819
06/24/2022 08:17:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=824
06/24/2022 08:17:04 - INFO - __main__ - Global step 1650 Train loss 0.09 ACC 0.46875 on epoch=824
06/24/2022 08:17:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=829
06/24/2022 08:17:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=834
06/24/2022 08:17:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=839
06/24/2022 08:17:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=844
06/24/2022 08:17:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=849
06/24/2022 08:17:11 - INFO - __main__ - Global step 1700 Train loss 0.09 ACC 0.5 on epoch=849
06/24/2022 08:17:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=854
06/24/2022 08:17:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=859
06/24/2022 08:17:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=864
06/24/2022 08:17:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=869
06/24/2022 08:17:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=874
06/24/2022 08:17:18 - INFO - __main__ - Global step 1750 Train loss 0.06 ACC 0.4375 on epoch=874
06/24/2022 08:17:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=879
06/24/2022 08:17:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=884
06/24/2022 08:17:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=889
06/24/2022 08:17:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=894
06/24/2022 08:17:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=899
06/24/2022 08:17:25 - INFO - __main__ - Global step 1800 Train loss 0.06 ACC 0.40625 on epoch=899
06/24/2022 08:17:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=904
06/24/2022 08:17:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=909
06/24/2022 08:17:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=914
06/24/2022 08:17:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=919
06/24/2022 08:17:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=924
06/24/2022 08:17:32 - INFO - __main__ - Global step 1850 Train loss 0.05 ACC 0.5 on epoch=924
06/24/2022 08:17:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 08:17:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=934
06/24/2022 08:17:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=939
06/24/2022 08:17:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=944
06/24/2022 08:17:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=949
06/24/2022 08:17:39 - INFO - __main__ - Global step 1900 Train loss 0.03 ACC 0.46875 on epoch=949
06/24/2022 08:17:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=954
06/24/2022 08:17:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=959
06/24/2022 08:17:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=964
06/24/2022 08:17:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=969
06/24/2022 08:17:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 08:17:46 - INFO - __main__ - Global step 1950 Train loss 0.03 ACC 0.46875 on epoch=974
06/24/2022 08:17:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=979
06/24/2022 08:17:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=984
06/24/2022 08:17:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=989
06/24/2022 08:17:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/24/2022 08:17:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 08:17:53 - INFO - __main__ - Global step 2000 Train loss 0.04 ACC 0.4375 on epoch=999
06/24/2022 08:17:53 - INFO - __main__ - save last model!
06/24/2022 08:17:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 08:17:53 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 08:17:53 - INFO - __main__ - Printing 3 examples
06/24/2022 08:17:53 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 08:17:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:53 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 08:17:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:53 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 08:17:53 - INFO - __main__ - ['duplicate']
06/24/2022 08:17:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:17:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:17:53 - INFO - __main__ - Printing 3 examples
06/24/2022 08:17:53 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:17:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:53 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:17:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:53 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:17:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:17:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:17:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:17:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:17:54 - INFO - __main__ - Printing 3 examples
06/24/2022 08:17:54 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:17:54 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:54 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:17:54 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:54 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:17:54 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:17:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:17:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:17:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:17:59 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 08:17:59 - INFO - __main__ - task name: glue-qqp
06/24/2022 08:17:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:17:59 - INFO - __main__ - Starting training!
06/24/2022 08:18:12 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:18:52 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 08:30:53 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_13_0.2_8_predictions.txt
06/24/2022 08:30:54 - INFO - __main__ - ACC on test data: 0.4236
06/24/2022 08:30:54 - INFO - __main__ - prefix=glue-qqp_16_13, lr=0.2, bsz=8, dev_performance=0.5, test_performance=0.4235963393519664
06/24/2022 08:30:54 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.5, bsz=8 ...
06/24/2022 08:30:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:30:55 - INFO - __main__ - Printing 3 examples
06/24/2022 08:30:55 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:30:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:30:55 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:30:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:30:55 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:30:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:30:55 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:30:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:30:55 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:30:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:30:55 - INFO - __main__ - Printing 3 examples
06/24/2022 08:30:55 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:30:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:30:55 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:30:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:30:55 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:30:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:30:55 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:30:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:30:55 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:31:01 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 08:31:01 - INFO - __main__ - task name: glue-qqp
06/24/2022 08:31:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:31:01 - INFO - __main__ - Starting training!
06/24/2022 08:31:03 - INFO - __main__ - Step 10 Global step 10 Train loss 5.59 on epoch=4
06/24/2022 08:31:04 - INFO - __main__ - Step 20 Global step 20 Train loss 2.62 on epoch=9
06/24/2022 08:31:05 - INFO - __main__ - Step 30 Global step 30 Train loss 1.87 on epoch=14
06/24/2022 08:31:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.03 on epoch=19
06/24/2022 08:31:08 - INFO - __main__ - Step 50 Global step 50 Train loss 0.75 on epoch=24
06/24/2022 08:31:08 - INFO - __main__ - Global step 50 Train loss 2.37 ACC 0.5 on epoch=24
06/24/2022 08:31:08 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 08:31:09 - INFO - __main__ - Step 60 Global step 60 Train loss 0.62 on epoch=29
06/24/2022 08:31:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.52 on epoch=34
06/24/2022 08:31:12 - INFO - __main__ - Step 80 Global step 80 Train loss 0.48 on epoch=39
06/24/2022 08:31:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.38 on epoch=44
06/24/2022 08:31:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.39 on epoch=49
06/24/2022 08:31:15 - INFO - __main__ - Global step 100 Train loss 0.48 ACC 0.5 on epoch=49
06/24/2022 08:31:16 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=54
06/24/2022 08:31:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.37 on epoch=59
06/24/2022 08:31:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.30 on epoch=64
06/24/2022 08:31:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.34 on epoch=69
06/24/2022 08:31:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=74
06/24/2022 08:31:21 - INFO - __main__ - Global step 150 Train loss 0.33 ACC 0.5 on epoch=74
06/24/2022 08:31:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=79
06/24/2022 08:31:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.30 on epoch=84
06/24/2022 08:31:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=89
06/24/2022 08:31:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=94
06/24/2022 08:31:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.29 on epoch=99
06/24/2022 08:31:28 - INFO - __main__ - Global step 200 Train loss 0.28 ACC 0.5 on epoch=99
06/24/2022 08:31:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=104
06/24/2022 08:31:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=109
06/24/2022 08:31:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=114
06/24/2022 08:31:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=119
06/24/2022 08:31:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=124
06/24/2022 08:31:34 - INFO - __main__ - Global step 250 Train loss 0.26 ACC 0.5 on epoch=124
06/24/2022 08:31:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/24/2022 08:31:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.21 on epoch=134
06/24/2022 08:31:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=139
06/24/2022 08:31:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=144
06/24/2022 08:31:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=149
06/24/2022 08:31:41 - INFO - __main__ - Global step 300 Train loss 0.27 ACC 0.5 on epoch=149
06/24/2022 08:31:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=154
06/24/2022 08:31:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=159
06/24/2022 08:31:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.18 on epoch=164
06/24/2022 08:31:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=169
06/24/2022 08:31:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=174
06/24/2022 08:31:47 - INFO - __main__ - Global step 350 Train loss 0.24 ACC 0.5 on epoch=174
06/24/2022 08:31:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=179
06/24/2022 08:31:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=184
06/24/2022 08:31:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 08:31:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=194
06/24/2022 08:31:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=199
06/24/2022 08:31:54 - INFO - __main__ - Global step 400 Train loss 0.25 ACC 0.5 on epoch=199
06/24/2022 08:31:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/24/2022 08:31:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=209
06/24/2022 08:31:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=214
06/24/2022 08:31:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=219
06/24/2022 08:32:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=224
06/24/2022 08:32:01 - INFO - __main__ - Global step 450 Train loss 0.22 ACC 0.5 on epoch=224
06/24/2022 08:32:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=229
06/24/2022 08:32:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=234
06/24/2022 08:32:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=239
06/24/2022 08:32:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=244
06/24/2022 08:32:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=249
06/24/2022 08:32:08 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/24/2022 08:32:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/24/2022 08:32:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=259
06/24/2022 08:32:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 08:32:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=269
06/24/2022 08:32:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/24/2022 08:32:15 - INFO - __main__ - Global step 550 Train loss 0.23 ACC 0.65625 on epoch=274
06/24/2022 08:32:15 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.65625 on epoch=274, global_step=550
06/24/2022 08:32:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=279
06/24/2022 08:32:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=284
06/24/2022 08:32:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=289
06/24/2022 08:32:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=294
06/24/2022 08:32:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=299
06/24/2022 08:32:22 - INFO - __main__ - Global step 600 Train loss 0.21 ACC 0.53125 on epoch=299
06/24/2022 08:32:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=304
06/24/2022 08:32:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=309
06/24/2022 08:32:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=314
06/24/2022 08:32:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=319
06/24/2022 08:32:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=324
06/24/2022 08:32:29 - INFO - __main__ - Global step 650 Train loss 0.21 ACC 0.53125 on epoch=324
06/24/2022 08:32:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=329
06/24/2022 08:32:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=334
06/24/2022 08:32:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=339
06/24/2022 08:32:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=344
06/24/2022 08:32:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=349
06/24/2022 08:32:36 - INFO - __main__ - Global step 700 Train loss 0.19 ACC 0.46875 on epoch=349
06/24/2022 08:32:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=354
06/24/2022 08:32:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=359
06/24/2022 08:32:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=364
06/24/2022 08:32:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=369
06/24/2022 08:32:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=374
06/24/2022 08:32:43 - INFO - __main__ - Global step 750 Train loss 0.10 ACC 0.5625 on epoch=374
06/24/2022 08:32:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
06/24/2022 08:32:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=384
06/24/2022 08:32:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=389
06/24/2022 08:32:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
06/24/2022 08:32:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=399
06/24/2022 08:32:50 - INFO - __main__ - Global step 800 Train loss 0.06 ACC 0.40625 on epoch=399
06/24/2022 08:32:51 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=404
06/24/2022 08:32:53 - INFO - __main__ - Step 820 Global step 820 Train loss 2.17 on epoch=409
06/24/2022 08:32:54 - INFO - __main__ - Step 830 Global step 830 Train loss 2.24 on epoch=414
06/24/2022 08:32:55 - INFO - __main__ - Step 840 Global step 840 Train loss 2.79 on epoch=419
06/24/2022 08:32:56 - INFO - __main__ - Step 850 Global step 850 Train loss 3.60 on epoch=424
06/24/2022 08:32:57 - INFO - __main__ - Global step 850 Train loss 2.44 ACC 0.28125 on epoch=424
06/24/2022 08:32:58 - INFO - __main__ - Step 860 Global step 860 Train loss 3.92 on epoch=429
06/24/2022 08:33:00 - INFO - __main__ - Step 870 Global step 870 Train loss 3.96 on epoch=434
06/24/2022 08:33:01 - INFO - __main__ - Step 880 Global step 880 Train loss 4.19 on epoch=439
06/24/2022 08:33:02 - INFO - __main__ - Step 890 Global step 890 Train loss 3.84 on epoch=444
06/24/2022 08:33:03 - INFO - __main__ - Step 900 Global step 900 Train loss 2.47 on epoch=449
06/24/2022 08:33:04 - INFO - __main__ - Global step 900 Train loss 3.68 ACC 0.5 on epoch=449
06/24/2022 08:33:06 - INFO - __main__ - Step 910 Global step 910 Train loss 2.45 on epoch=454
06/24/2022 08:33:07 - INFO - __main__ - Step 920 Global step 920 Train loss 2.21 on epoch=459
06/24/2022 08:33:08 - INFO - __main__ - Step 930 Global step 930 Train loss 2.51 on epoch=464
06/24/2022 08:33:09 - INFO - __main__ - Step 940 Global step 940 Train loss 3.19 on epoch=469
06/24/2022 08:33:11 - INFO - __main__ - Step 950 Global step 950 Train loss 2.88 on epoch=474
06/24/2022 08:33:12 - INFO - __main__ - Global step 950 Train loss 2.65 ACC 0.5 on epoch=474
06/24/2022 08:33:14 - INFO - __main__ - Step 960 Global step 960 Train loss 2.02 on epoch=479
06/24/2022 08:33:15 - INFO - __main__ - Step 970 Global step 970 Train loss 2.19 on epoch=484
06/24/2022 08:33:16 - INFO - __main__ - Step 980 Global step 980 Train loss 2.08 on epoch=489
06/24/2022 08:33:17 - INFO - __main__ - Step 990 Global step 990 Train loss 2.08 on epoch=494
06/24/2022 08:33:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.04 on epoch=499
06/24/2022 08:33:19 - INFO - __main__ - Global step 1000 Train loss 2.08 ACC 0.5 on epoch=499
06/24/2022 08:33:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.52 on epoch=504
06/24/2022 08:33:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.25 on epoch=509
06/24/2022 08:33:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.14 on epoch=514
06/24/2022 08:33:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.10 on epoch=519
06/24/2022 08:33:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.97 on epoch=524
06/24/2022 08:33:26 - INFO - __main__ - Global step 1050 Train loss 1.20 ACC 0.5 on epoch=524
06/24/2022 08:33:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.87 on epoch=529
06/24/2022 08:33:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.90 on epoch=534
06/24/2022 08:33:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.02 on epoch=539
06/24/2022 08:33:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.29 on epoch=544
06/24/2022 08:33:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.05 on epoch=549
06/24/2022 08:33:33 - INFO - __main__ - Global step 1100 Train loss 1.03 ACC 0.5 on epoch=549
06/24/2022 08:33:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.82 on epoch=554
06/24/2022 08:33:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.72 on epoch=559
06/24/2022 08:33:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.81 on epoch=564
06/24/2022 08:33:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.70 on epoch=569
06/24/2022 08:33:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.74 on epoch=574
06/24/2022 08:33:40 - INFO - __main__ - Global step 1150 Train loss 0.76 ACC 0.5 on epoch=574
06/24/2022 08:33:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.72 on epoch=579
06/24/2022 08:33:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.61 on epoch=584
06/24/2022 08:33:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.68 on epoch=589
06/24/2022 08:33:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.77 on epoch=594
06/24/2022 08:33:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.58 on epoch=599
06/24/2022 08:33:47 - INFO - __main__ - Global step 1200 Train loss 0.67 ACC 0.5 on epoch=599
06/24/2022 08:33:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.59 on epoch=604
06/24/2022 08:33:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.56 on epoch=609
06/24/2022 08:33:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.57 on epoch=614
06/24/2022 08:33:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.57 on epoch=619
06/24/2022 08:33:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.54 on epoch=624
06/24/2022 08:33:54 - INFO - __main__ - Global step 1250 Train loss 0.57 ACC 0.5 on epoch=624
06/24/2022 08:33:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.57 on epoch=629
06/24/2022 08:33:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.49 on epoch=634
06/24/2022 08:33:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.45 on epoch=639
06/24/2022 08:33:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.47 on epoch=644
06/24/2022 08:34:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.46 on epoch=649
06/24/2022 08:34:01 - INFO - __main__ - Global step 1300 Train loss 0.49 ACC 0.5 on epoch=649
06/24/2022 08:34:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.47 on epoch=654
06/24/2022 08:34:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.43 on epoch=659
06/24/2022 08:34:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.60 on epoch=664
06/24/2022 08:34:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.61 on epoch=669
06/24/2022 08:34:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.75 on epoch=674
06/24/2022 08:34:08 - INFO - __main__ - Global step 1350 Train loss 0.57 ACC 0.5 on epoch=674
06/24/2022 08:34:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.64 on epoch=679
06/24/2022 08:34:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.55 on epoch=684
06/24/2022 08:34:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.54 on epoch=689
06/24/2022 08:34:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.50 on epoch=694
06/24/2022 08:34:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.60 on epoch=699
06/24/2022 08:34:15 - INFO - __main__ - Global step 1400 Train loss 0.57 ACC 0.5 on epoch=699
06/24/2022 08:34:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.63 on epoch=704
06/24/2022 08:34:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.73 on epoch=709
06/24/2022 08:34:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.51 on epoch=714
06/24/2022 08:34:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.53 on epoch=719
06/24/2022 08:34:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.46 on epoch=724
06/24/2022 08:34:22 - INFO - __main__ - Global step 1450 Train loss 0.57 ACC 0.5 on epoch=724
06/24/2022 08:34:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.54 on epoch=729
06/24/2022 08:34:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.50 on epoch=734
06/24/2022 08:34:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.57 on epoch=739
06/24/2022 08:34:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.58 on epoch=744
06/24/2022 08:34:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.60 on epoch=749
06/24/2022 08:34:29 - INFO - __main__ - Global step 1500 Train loss 0.56 ACC 0.5 on epoch=749
06/24/2022 08:34:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.43 on epoch=754
06/24/2022 08:34:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.48 on epoch=759
06/24/2022 08:34:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.70 on epoch=764
06/24/2022 08:34:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.57 on epoch=769
06/24/2022 08:34:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.84 on epoch=774
06/24/2022 08:34:36 - INFO - __main__ - Global step 1550 Train loss 0.61 ACC 0.5 on epoch=774
06/24/2022 08:34:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.72 on epoch=779
06/24/2022 08:34:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.47 on epoch=784
06/24/2022 08:34:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.34 on epoch=789
06/24/2022 08:34:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.49 on epoch=794
06/24/2022 08:34:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.47 on epoch=799
06/24/2022 08:34:43 - INFO - __main__ - Global step 1600 Train loss 0.50 ACC 0.5 on epoch=799
06/24/2022 08:34:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.40 on epoch=804
06/24/2022 08:34:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.50 on epoch=809
06/24/2022 08:34:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.45 on epoch=814
06/24/2022 08:34:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.48 on epoch=819
06/24/2022 08:34:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.42 on epoch=824
06/24/2022 08:34:50 - INFO - __main__ - Global step 1650 Train loss 0.45 ACC 0.5 on epoch=824
06/24/2022 08:34:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.51 on epoch=829
06/24/2022 08:34:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.46 on epoch=834
06/24/2022 08:34:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.44 on epoch=839
06/24/2022 08:34:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.50 on epoch=844
06/24/2022 08:34:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.49 on epoch=849
06/24/2022 08:34:56 - INFO - __main__ - Global step 1700 Train loss 0.48 ACC 0.5 on epoch=849
06/24/2022 08:34:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.42 on epoch=854
06/24/2022 08:34:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.47 on epoch=859
06/24/2022 08:35:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.43 on epoch=864
06/24/2022 08:35:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.44 on epoch=869
06/24/2022 08:35:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.42 on epoch=874
06/24/2022 08:35:03 - INFO - __main__ - Global step 1750 Train loss 0.44 ACC 0.5 on epoch=874
06/24/2022 08:35:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.41 on epoch=879
06/24/2022 08:35:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.43 on epoch=884
06/24/2022 08:35:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.39 on epoch=889
06/24/2022 08:35:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.39 on epoch=894
06/24/2022 08:35:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.35 on epoch=899
06/24/2022 08:35:10 - INFO - __main__ - Global step 1800 Train loss 0.39 ACC 0.5 on epoch=899
06/24/2022 08:35:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.42 on epoch=904
06/24/2022 08:35:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.40 on epoch=909
06/24/2022 08:35:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.42 on epoch=914
06/24/2022 08:35:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.35 on epoch=919
06/24/2022 08:35:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.36 on epoch=924
06/24/2022 08:35:17 - INFO - __main__ - Global step 1850 Train loss 0.39 ACC 0.5 on epoch=924
06/24/2022 08:35:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.38 on epoch=929
06/24/2022 08:35:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.30 on epoch=934
06/24/2022 08:35:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.27 on epoch=939
06/24/2022 08:35:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.30 on epoch=944
06/24/2022 08:35:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.36 on epoch=949
06/24/2022 08:35:24 - INFO - __main__ - Global step 1900 Train loss 0.32 ACC 0.5 on epoch=949
06/24/2022 08:35:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.35 on epoch=954
06/24/2022 08:35:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.40 on epoch=959
06/24/2022 08:35:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.32 on epoch=964
06/24/2022 08:35:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.41 on epoch=969
06/24/2022 08:35:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.41 on epoch=974
06/24/2022 08:35:31 - INFO - __main__ - Global step 1950 Train loss 0.38 ACC 0.5 on epoch=974
06/24/2022 08:35:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.36 on epoch=979
06/24/2022 08:35:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.33 on epoch=984
06/24/2022 08:35:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.35 on epoch=989
06/24/2022 08:35:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.37 on epoch=994
06/24/2022 08:35:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.32 on epoch=999
06/24/2022 08:35:38 - INFO - __main__ - Global step 2000 Train loss 0.34 ACC 0.5 on epoch=999
06/24/2022 08:35:38 - INFO - __main__ - save last model!
06/24/2022 08:35:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 08:35:38 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 08:35:38 - INFO - __main__ - Printing 3 examples
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 08:35:38 - INFO - __main__ - ['duplicate']
06/24/2022 08:35:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:35:38 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:35:38 - INFO - __main__ - Printing 3 examples
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:35:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:35:38 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:35:38 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:35:38 - INFO - __main__ - Printing 3 examples
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:35:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:35:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:35:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:35:39 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:35:44 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 08:35:44 - INFO - __main__ - task name: glue-qqp
06/24/2022 08:35:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:35:44 - INFO - __main__ - Starting training!
06/24/2022 08:35:56 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:36:37 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 08:48:32 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_21_0.5_8_predictions.txt
06/24/2022 08:48:32 - INFO - __main__ - ACC on test data: 0.3815
06/24/2022 08:48:32 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.5, bsz=8, dev_performance=0.65625, test_performance=0.38147415285678954
06/24/2022 08:48:32 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.4, bsz=8 ...
06/24/2022 08:48:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:48:33 - INFO - __main__ - Printing 3 examples
06/24/2022 08:48:33 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:48:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:48:33 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:48:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:48:33 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:48:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:48:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:48:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:48:33 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:48:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:48:33 - INFO - __main__ - Printing 3 examples
06/24/2022 08:48:33 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:48:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:48:33 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:48:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:48:33 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:48:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:48:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:48:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:48:33 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:48:39 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 08:48:39 - INFO - __main__ - task name: glue-qqp
06/24/2022 08:48:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:48:39 - INFO - __main__ - Starting training!
06/24/2022 08:48:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.18 on epoch=4
06/24/2022 08:48:42 - INFO - __main__ - Step 20 Global step 20 Train loss 3.57 on epoch=9
06/24/2022 08:48:43 - INFO - __main__ - Step 30 Global step 30 Train loss 6.10 on epoch=14
06/24/2022 08:48:45 - INFO - __main__ - Step 40 Global step 40 Train loss 6.41 on epoch=19
06/24/2022 08:48:46 - INFO - __main__ - Step 50 Global step 50 Train loss 6.55 on epoch=24
06/24/2022 08:48:47 - INFO - __main__ - Global step 50 Train loss 5.76 ACC 0.0 on epoch=24
06/24/2022 08:48:47 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.0 on epoch=24, global_step=50
06/24/2022 08:48:49 - INFO - __main__ - Step 60 Global step 60 Train loss 6.52 on epoch=29
06/24/2022 08:48:50 - INFO - __main__ - Step 70 Global step 70 Train loss 6.53 on epoch=34
06/24/2022 08:48:51 - INFO - __main__ - Step 80 Global step 80 Train loss 6.52 on epoch=39
06/24/2022 08:48:52 - INFO - __main__ - Step 90 Global step 90 Train loss 6.48 on epoch=44
06/24/2022 08:48:54 - INFO - __main__ - Step 100 Global step 100 Train loss 6.51 on epoch=49
06/24/2022 08:49:04 - INFO - __main__ - Global step 100 Train loss 6.51 ACC 0.0 on epoch=49
06/24/2022 08:49:05 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=54
06/24/2022 08:49:06 - INFO - __main__ - Step 120 Global step 120 Train loss 6.65 on epoch=59
06/24/2022 08:49:08 - INFO - __main__ - Step 130 Global step 130 Train loss 6.62 on epoch=64
06/24/2022 08:49:09 - INFO - __main__ - Step 140 Global step 140 Train loss 6.72 on epoch=69
06/24/2022 08:49:10 - INFO - __main__ - Step 150 Global step 150 Train loss 6.59 on epoch=74
06/24/2022 08:49:17 - INFO - __main__ - Global step 150 Train loss 6.64 ACC 0.0 on epoch=74
06/24/2022 08:49:18 - INFO - __main__ - Step 160 Global step 160 Train loss 6.74 on epoch=79
06/24/2022 08:49:19 - INFO - __main__ - Step 170 Global step 170 Train loss 6.65 on epoch=84
06/24/2022 08:49:20 - INFO - __main__ - Step 180 Global step 180 Train loss 6.75 on epoch=89
06/24/2022 08:49:22 - INFO - __main__ - Step 190 Global step 190 Train loss 6.70 on epoch=94
06/24/2022 08:49:23 - INFO - __main__ - Step 200 Global step 200 Train loss 6.72 on epoch=99
06/24/2022 08:49:25 - INFO - __main__ - Global step 200 Train loss 6.71 ACC 0.0 on epoch=99
06/24/2022 08:49:26 - INFO - __main__ - Step 210 Global step 210 Train loss 6.68 on epoch=104
06/24/2022 08:49:27 - INFO - __main__ - Step 220 Global step 220 Train loss 6.65 on epoch=109
06/24/2022 08:49:28 - INFO - __main__ - Step 230 Global step 230 Train loss 6.71 on epoch=114
06/24/2022 08:49:30 - INFO - __main__ - Step 240 Global step 240 Train loss 6.80 on epoch=119
06/24/2022 08:49:31 - INFO - __main__ - Step 250 Global step 250 Train loss 6.68 on epoch=124
06/24/2022 08:49:34 - INFO - __main__ - Global step 250 Train loss 6.70 ACC 0.0 on epoch=124
06/24/2022 08:49:35 - INFO - __main__ - Step 260 Global step 260 Train loss 6.67 on epoch=129
06/24/2022 08:49:36 - INFO - __main__ - Step 270 Global step 270 Train loss 6.75 on epoch=134
06/24/2022 08:49:38 - INFO - __main__ - Step 280 Global step 280 Train loss 6.76 on epoch=139
06/24/2022 08:49:39 - INFO - __main__ - Step 290 Global step 290 Train loss 6.72 on epoch=144
06/24/2022 08:49:40 - INFO - __main__ - Step 300 Global step 300 Train loss 6.75 on epoch=149
06/24/2022 08:49:42 - INFO - __main__ - Global step 300 Train loss 6.73 ACC 0.0 on epoch=149
06/24/2022 08:49:44 - INFO - __main__ - Step 310 Global step 310 Train loss 6.74 on epoch=154
06/24/2022 08:49:45 - INFO - __main__ - Step 320 Global step 320 Train loss 6.66 on epoch=159
06/24/2022 08:49:46 - INFO - __main__ - Step 330 Global step 330 Train loss 6.65 on epoch=164
06/24/2022 08:49:47 - INFO - __main__ - Step 340 Global step 340 Train loss 6.69 on epoch=169
06/24/2022 08:49:49 - INFO - __main__ - Step 350 Global step 350 Train loss 6.68 on epoch=174
06/24/2022 08:49:58 - INFO - __main__ - Global step 350 Train loss 6.68 ACC 0.0 on epoch=174
06/24/2022 08:49:59 - INFO - __main__ - Step 360 Global step 360 Train loss 6.65 on epoch=179
06/24/2022 08:50:01 - INFO - __main__ - Step 370 Global step 370 Train loss 6.66 on epoch=184
06/24/2022 08:50:02 - INFO - __main__ - Step 380 Global step 380 Train loss 6.71 on epoch=189
06/24/2022 08:50:03 - INFO - __main__ - Step 390 Global step 390 Train loss 6.68 on epoch=194
06/24/2022 08:50:05 - INFO - __main__ - Step 400 Global step 400 Train loss 6.71 on epoch=199
06/24/2022 08:50:15 - INFO - __main__ - Global step 400 Train loss 6.68 ACC 0.0 on epoch=199
06/24/2022 08:50:16 - INFO - __main__ - Step 410 Global step 410 Train loss 6.63 on epoch=204
06/24/2022 08:50:17 - INFO - __main__ - Step 420 Global step 420 Train loss 6.65 on epoch=209
06/24/2022 08:50:18 - INFO - __main__ - Step 430 Global step 430 Train loss 6.65 on epoch=214
06/24/2022 08:50:20 - INFO - __main__ - Step 440 Global step 440 Train loss 6.65 on epoch=219
06/24/2022 08:50:21 - INFO - __main__ - Step 450 Global step 450 Train loss 6.61 on epoch=224
06/24/2022 08:50:31 - INFO - __main__ - Global step 450 Train loss 6.64 ACC 0.0 on epoch=224
06/24/2022 08:50:32 - INFO - __main__ - Step 460 Global step 460 Train loss 6.67 on epoch=229
06/24/2022 08:50:34 - INFO - __main__ - Step 470 Global step 470 Train loss 6.62 on epoch=234
06/24/2022 08:50:35 - INFO - __main__ - Step 480 Global step 480 Train loss 6.72 on epoch=239
06/24/2022 08:50:36 - INFO - __main__ - Step 490 Global step 490 Train loss 6.67 on epoch=244
06/24/2022 08:50:37 - INFO - __main__ - Step 500 Global step 500 Train loss 6.71 on epoch=249
06/24/2022 08:50:39 - INFO - __main__ - Global step 500 Train loss 6.68 ACC 0.0 on epoch=249
06/24/2022 08:50:41 - INFO - __main__ - Step 510 Global step 510 Train loss 6.72 on epoch=254
06/24/2022 08:50:42 - INFO - __main__ - Step 520 Global step 520 Train loss 6.66 on epoch=259
06/24/2022 08:50:43 - INFO - __main__ - Step 530 Global step 530 Train loss 6.70 on epoch=264
06/24/2022 08:50:45 - INFO - __main__ - Step 540 Global step 540 Train loss 6.72 on epoch=269
06/24/2022 08:50:46 - INFO - __main__ - Step 550 Global step 550 Train loss 6.78 on epoch=274
06/24/2022 08:50:47 - INFO - __main__ - Global step 550 Train loss 6.72 ACC 0.0 on epoch=274
06/24/2022 08:50:48 - INFO - __main__ - Step 560 Global step 560 Train loss 6.72 on epoch=279
06/24/2022 08:50:49 - INFO - __main__ - Step 570 Global step 570 Train loss 6.67 on epoch=284
06/24/2022 08:50:50 - INFO - __main__ - Step 580 Global step 580 Train loss 6.63 on epoch=289
06/24/2022 08:50:52 - INFO - __main__ - Step 590 Global step 590 Train loss 6.68 on epoch=294
06/24/2022 08:50:53 - INFO - __main__ - Step 600 Global step 600 Train loss 6.76 on epoch=299
06/24/2022 08:50:55 - INFO - __main__ - Global step 600 Train loss 6.69 ACC 0.0 on epoch=299
06/24/2022 08:50:56 - INFO - __main__ - Step 610 Global step 610 Train loss 6.63 on epoch=304
06/24/2022 08:50:58 - INFO - __main__ - Step 620 Global step 620 Train loss 6.69 on epoch=309
06/24/2022 08:50:59 - INFO - __main__ - Step 630 Global step 630 Train loss 6.66 on epoch=314
06/24/2022 08:51:00 - INFO - __main__ - Step 640 Global step 640 Train loss 6.57 on epoch=319
06/24/2022 08:51:01 - INFO - __main__ - Step 650 Global step 650 Train loss 6.58 on epoch=324
06/24/2022 08:51:06 - INFO - __main__ - Global step 650 Train loss 6.63 ACC 0.0 on epoch=324
06/24/2022 08:51:07 - INFO - __main__ - Step 660 Global step 660 Train loss 6.65 on epoch=329
06/24/2022 08:51:09 - INFO - __main__ - Step 670 Global step 670 Train loss 6.60 on epoch=334
06/24/2022 08:51:10 - INFO - __main__ - Step 680 Global step 680 Train loss 6.53 on epoch=339
06/24/2022 08:51:11 - INFO - __main__ - Step 690 Global step 690 Train loss 6.52 on epoch=344
06/24/2022 08:51:12 - INFO - __main__ - Step 700 Global step 700 Train loss 6.65 on epoch=349
06/24/2022 08:51:20 - INFO - __main__ - Global step 700 Train loss 6.59 ACC 0.0 on epoch=349
06/24/2022 08:51:21 - INFO - __main__ - Step 710 Global step 710 Train loss 6.62 on epoch=354
06/24/2022 08:51:23 - INFO - __main__ - Step 720 Global step 720 Train loss 6.51 on epoch=359
06/24/2022 08:51:24 - INFO - __main__ - Step 730 Global step 730 Train loss 6.57 on epoch=364
06/24/2022 08:51:25 - INFO - __main__ - Step 740 Global step 740 Train loss 6.48 on epoch=369
06/24/2022 08:51:26 - INFO - __main__ - Step 750 Global step 750 Train loss 6.56 on epoch=374
06/24/2022 08:51:33 - INFO - __main__ - Global step 750 Train loss 6.55 ACC 0.0 on epoch=374
06/24/2022 08:51:34 - INFO - __main__ - Step 760 Global step 760 Train loss 6.58 on epoch=379
06/24/2022 08:51:35 - INFO - __main__ - Step 770 Global step 770 Train loss 6.54 on epoch=384
06/24/2022 08:51:36 - INFO - __main__ - Step 780 Global step 780 Train loss 6.55 on epoch=389
06/24/2022 08:51:38 - INFO - __main__ - Step 790 Global step 790 Train loss 6.51 on epoch=394
06/24/2022 08:51:39 - INFO - __main__ - Step 800 Global step 800 Train loss 6.52 on epoch=399
06/24/2022 08:51:45 - INFO - __main__ - Global step 800 Train loss 6.54 ACC 0.0 on epoch=399
06/24/2022 08:51:46 - INFO - __main__ - Step 810 Global step 810 Train loss 6.47 on epoch=404
06/24/2022 08:51:48 - INFO - __main__ - Step 820 Global step 820 Train loss 6.56 on epoch=409
06/24/2022 08:51:49 - INFO - __main__ - Step 830 Global step 830 Train loss 6.48 on epoch=414
06/24/2022 08:51:50 - INFO - __main__ - Step 840 Global step 840 Train loss 6.53 on epoch=419
06/24/2022 08:51:51 - INFO - __main__ - Step 850 Global step 850 Train loss 6.42 on epoch=424
06/24/2022 08:51:57 - INFO - __main__ - Global step 850 Train loss 6.49 ACC 0.0 on epoch=424
06/24/2022 08:51:58 - INFO - __main__ - Step 860 Global step 860 Train loss 6.46 on epoch=429
06/24/2022 08:51:59 - INFO - __main__ - Step 870 Global step 870 Train loss 6.46 on epoch=434
06/24/2022 08:52:01 - INFO - __main__ - Step 880 Global step 880 Train loss 6.42 on epoch=439
06/24/2022 08:52:02 - INFO - __main__ - Step 890 Global step 890 Train loss 6.47 on epoch=444
06/24/2022 08:52:03 - INFO - __main__ - Step 900 Global step 900 Train loss 6.51 on epoch=449
06/24/2022 08:52:08 - INFO - __main__ - Global step 900 Train loss 6.47 ACC 0.0 on epoch=449
06/24/2022 08:52:09 - INFO - __main__ - Step 910 Global step 910 Train loss 6.44 on epoch=454
06/24/2022 08:52:10 - INFO - __main__ - Step 920 Global step 920 Train loss 6.43 on epoch=459
06/24/2022 08:52:11 - INFO - __main__ - Step 930 Global step 930 Train loss 6.33 on epoch=464
06/24/2022 08:52:13 - INFO - __main__ - Step 940 Global step 940 Train loss 6.44 on epoch=469
06/24/2022 08:52:14 - INFO - __main__ - Step 950 Global step 950 Train loss 6.32 on epoch=474
06/24/2022 08:52:16 - INFO - __main__ - Global step 950 Train loss 6.39 ACC 0.0 on epoch=474
06/24/2022 08:52:17 - INFO - __main__ - Step 960 Global step 960 Train loss 6.30 on epoch=479
06/24/2022 08:52:18 - INFO - __main__ - Step 970 Global step 970 Train loss 6.26 on epoch=484
06/24/2022 08:52:20 - INFO - __main__ - Step 980 Global step 980 Train loss 6.37 on epoch=489
06/24/2022 08:52:21 - INFO - __main__ - Step 990 Global step 990 Train loss 6.42 on epoch=494
06/24/2022 08:52:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 6.39 on epoch=499
06/24/2022 08:52:24 - INFO - __main__ - Global step 1000 Train loss 6.35 ACC 0.0 on epoch=499
06/24/2022 08:52:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 6.31 on epoch=504
06/24/2022 08:52:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 6.31 on epoch=509
06/24/2022 08:52:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 6.32 on epoch=514
06/24/2022 08:52:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 6.37 on epoch=519
06/24/2022 08:52:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 6.21 on epoch=524
06/24/2022 08:52:38 - INFO - __main__ - Global step 1050 Train loss 6.30 ACC 0.0 on epoch=524
06/24/2022 08:52:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 6.22 on epoch=529
06/24/2022 08:52:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 6.28 on epoch=534
06/24/2022 08:52:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 6.21 on epoch=539
06/24/2022 08:52:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 6.25 on epoch=544
06/24/2022 08:52:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 6.23 on epoch=549
06/24/2022 08:52:48 - INFO - __main__ - Global step 1100 Train loss 6.24 ACC 0.0 on epoch=549
06/24/2022 08:52:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 6.29 on epoch=554
06/24/2022 08:52:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 6.38 on epoch=559
06/24/2022 08:52:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 6.36 on epoch=564
06/24/2022 08:52:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 6.28 on epoch=569
06/24/2022 08:52:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 6.19 on epoch=574
06/24/2022 08:52:57 - INFO - __main__ - Global step 1150 Train loss 6.30 ACC 0.0 on epoch=574
06/24/2022 08:52:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 6.26 on epoch=579
06/24/2022 08:52:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 6.26 on epoch=584
06/24/2022 08:53:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 6.27 on epoch=589
06/24/2022 08:53:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 6.31 on epoch=594
06/24/2022 08:53:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 6.31 on epoch=599
06/24/2022 08:53:05 - INFO - __main__ - Global step 1200 Train loss 6.28 ACC 0.0 on epoch=599
06/24/2022 08:53:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 6.21 on epoch=604
06/24/2022 08:53:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 6.30 on epoch=609
06/24/2022 08:53:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 6.30 on epoch=614
06/24/2022 08:53:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 6.16 on epoch=619
06/24/2022 08:53:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 6.33 on epoch=624
06/24/2022 08:53:13 - INFO - __main__ - Global step 1250 Train loss 6.26 ACC 0.0 on epoch=624
06/24/2022 08:53:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 6.25 on epoch=629
06/24/2022 08:53:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 6.20 on epoch=634
06/24/2022 08:53:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 6.26 on epoch=639
06/24/2022 08:53:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 6.37 on epoch=644
06/24/2022 08:53:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 6.29 on epoch=649
06/24/2022 08:53:26 - INFO - __main__ - Global step 1300 Train loss 6.27 ACC 0.0 on epoch=649
06/24/2022 08:53:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 6.20 on epoch=654
06/24/2022 08:53:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 6.21 on epoch=659
06/24/2022 08:53:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 6.14 on epoch=664
06/24/2022 08:53:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 6.05 on epoch=669
06/24/2022 08:53:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 6.14 on epoch=674
06/24/2022 08:53:36 - INFO - __main__ - Global step 1350 Train loss 6.15 ACC 0.0 on epoch=674
06/24/2022 08:53:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 6.11 on epoch=679
06/24/2022 08:53:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 6.13 on epoch=684
06/24/2022 08:53:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 6.09 on epoch=689
06/24/2022 08:53:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 6.21 on epoch=694
06/24/2022 08:53:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 6.08 on epoch=699
06/24/2022 08:53:45 - INFO - __main__ - Global step 1400 Train loss 6.12 ACC 0.0 on epoch=699
06/24/2022 08:53:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 6.10 on epoch=704
06/24/2022 08:53:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 6.03 on epoch=709
06/24/2022 08:53:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 5.93 on epoch=714
06/24/2022 08:53:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 5.93 on epoch=719
06/24/2022 08:53:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 5.96 on epoch=724
06/24/2022 08:53:57 - INFO - __main__ - Global step 1450 Train loss 5.99 ACC 0.0 on epoch=724
06/24/2022 08:53:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 5.95 on epoch=729
06/24/2022 08:54:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 5.92 on epoch=734
06/24/2022 08:54:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 6.00 on epoch=739
06/24/2022 08:54:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 5.85 on epoch=744
06/24/2022 08:54:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 5.94 on epoch=749
06/24/2022 08:54:07 - INFO - __main__ - Global step 1500 Train loss 5.93 ACC 0.0 on epoch=749
06/24/2022 08:54:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 5.93 on epoch=754
06/24/2022 08:54:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 5.86 on epoch=759
06/24/2022 08:54:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 5.93 on epoch=764
06/24/2022 08:54:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 5.85 on epoch=769
06/24/2022 08:54:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 5.90 on epoch=774
06/24/2022 08:54:24 - INFO - __main__ - Global step 1550 Train loss 5.89 ACC 0.0 on epoch=774
06/24/2022 08:54:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 5.94 on epoch=779
06/24/2022 08:54:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 5.83 on epoch=784
06/24/2022 08:54:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 5.93 on epoch=789
06/24/2022 08:54:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 5.77 on epoch=794
06/24/2022 08:54:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 5.78 on epoch=799
06/24/2022 08:54:36 - INFO - __main__ - Global step 1600 Train loss 5.85 ACC 0.0 on epoch=799
06/24/2022 08:54:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 5.74 on epoch=804
06/24/2022 08:54:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 5.81 on epoch=809
06/24/2022 08:54:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 5.76 on epoch=814
06/24/2022 08:54:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 5.64 on epoch=819
06/24/2022 08:54:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 5.64 on epoch=824
06/24/2022 08:54:46 - INFO - __main__ - Global step 1650 Train loss 5.72 ACC 0.0 on epoch=824
06/24/2022 08:54:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 5.67 on epoch=829
06/24/2022 08:54:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 5.65 on epoch=834
06/24/2022 08:54:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 5.50 on epoch=839
06/24/2022 08:54:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 5.63 on epoch=844
06/24/2022 08:54:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 5.44 on epoch=849
06/24/2022 08:54:54 - INFO - __main__ - Global step 1700 Train loss 5.58 ACC 0.0 on epoch=849
06/24/2022 08:54:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 5.50 on epoch=854
06/24/2022 08:54:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 5.48 on epoch=859
06/24/2022 08:54:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 5.36 on epoch=864
06/24/2022 08:54:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 5.34 on epoch=869
06/24/2022 08:55:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 5.45 on epoch=874
06/24/2022 08:55:06 - INFO - __main__ - Global step 1750 Train loss 5.43 ACC 0.0 on epoch=874
06/24/2022 08:55:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 5.31 on epoch=879
06/24/2022 08:55:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 5.37 on epoch=884
06/24/2022 08:55:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 5.35 on epoch=889
06/24/2022 08:55:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 5.30 on epoch=894
06/24/2022 08:55:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 5.43 on epoch=899
06/24/2022 08:55:15 - INFO - __main__ - Global step 1800 Train loss 5.35 ACC 0.0 on epoch=899
06/24/2022 08:55:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 5.22 on epoch=904
06/24/2022 08:55:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 5.29 on epoch=909
06/24/2022 08:55:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 5.36 on epoch=914
06/24/2022 08:55:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 5.26 on epoch=919
06/24/2022 08:55:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 5.26 on epoch=924
06/24/2022 08:55:28 - INFO - __main__ - Global step 1850 Train loss 5.28 ACC 0.0 on epoch=924
06/24/2022 08:55:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 5.20 on epoch=929
06/24/2022 08:55:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 5.40 on epoch=934
06/24/2022 08:55:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 5.34 on epoch=939
06/24/2022 08:55:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 5.29 on epoch=944
06/24/2022 08:55:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 5.37 on epoch=949
06/24/2022 08:55:37 - INFO - __main__ - Global step 1900 Train loss 5.32 ACC 0.0 on epoch=949
06/24/2022 08:55:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 5.19 on epoch=954
06/24/2022 08:55:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 5.23 on epoch=959
06/24/2022 08:55:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 5.23 on epoch=964
06/24/2022 08:55:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 5.24 on epoch=969
06/24/2022 08:55:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 5.25 on epoch=974
06/24/2022 08:55:47 - INFO - __main__ - Global step 1950 Train loss 5.23 ACC 0.0 on epoch=974
06/24/2022 08:55:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 5.22 on epoch=979
06/24/2022 08:55:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 5.14 on epoch=984
06/24/2022 08:55:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 5.28 on epoch=989
06/24/2022 08:55:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 5.18 on epoch=994
06/24/2022 08:55:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 5.10 on epoch=999
06/24/2022 08:55:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:55:55 - INFO - __main__ - Printing 3 examples
06/24/2022 08:55:55 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 08:55:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:55 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 08:55:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:55 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 08:55:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:55 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:55:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:55:55 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 08:55:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 08:55:55 - INFO - __main__ - Printing 3 examples
06/24/2022 08:55:55 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 08:55:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:55 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 08:55:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:55 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 08:55:55 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:55 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:55:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:55:55 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 08:55:56 - INFO - __main__ - Global step 2000 Train loss 5.18 ACC 0.0 on epoch=999
06/24/2022 08:55:56 - INFO - __main__ - save last model!
06/24/2022 08:55:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 08:55:57 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 08:55:57 - INFO - __main__ - Printing 3 examples
06/24/2022 08:55:57 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 08:55:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:57 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 08:55:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 08:55:57 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 08:55:57 - INFO - __main__ - ['duplicate']
06/24/2022 08:55:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 08:56:00 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 08:56:00 - INFO - __main__ - task name: glue-qqp
06/24/2022 08:56:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 08:56:01 - INFO - __main__ - Starting training!
06/24/2022 08:56:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 08:56:56 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 10:08:51 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_21_0.4_8_predictions.txt
06/24/2022 10:08:52 - INFO - __main__ - ACC on test data: 0.0000
06/24/2022 10:08:52 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.4, bsz=8, dev_performance=0.0, test_performance=0.0
06/24/2022 10:08:52 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.3, bsz=8 ...
06/24/2022 10:08:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:08:53 - INFO - __main__ - Printing 3 examples
06/24/2022 10:08:53 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 10:08:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:08:53 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 10:08:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:08:53 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 10:08:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:08:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:08:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:08:53 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:08:53 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:08:53 - INFO - __main__ - Printing 3 examples
06/24/2022 10:08:53 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 10:08:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:08:53 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 10:08:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:08:53 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 10:08:53 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:08:53 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:08:53 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:08:53 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:08:59 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 10:08:59 - INFO - __main__ - task name: glue-qqp
06/24/2022 10:08:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:08:59 - INFO - __main__ - Starting training!
06/24/2022 10:09:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.32 on epoch=4
06/24/2022 10:09:02 - INFO - __main__ - Step 20 Global step 20 Train loss 3.23 on epoch=9
06/24/2022 10:09:03 - INFO - __main__ - Step 30 Global step 30 Train loss 1.41 on epoch=14
06/24/2022 10:09:04 - INFO - __main__ - Step 40 Global step 40 Train loss 0.65 on epoch=19
06/24/2022 10:09:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.50 on epoch=24
06/24/2022 10:09:06 - INFO - __main__ - Global step 50 Train loss 2.42 ACC 0.53125 on epoch=24
06/24/2022 10:09:06 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.53125 on epoch=24, global_step=50
06/24/2022 10:09:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.52 on epoch=29
06/24/2022 10:09:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.42 on epoch=34
06/24/2022 10:09:10 - INFO - __main__ - Step 80 Global step 80 Train loss 0.36 on epoch=39
06/24/2022 10:09:11 - INFO - __main__ - Step 90 Global step 90 Train loss 0.32 on epoch=44
06/24/2022 10:09:12 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=49
06/24/2022 10:09:13 - INFO - __main__ - Global step 100 Train loss 0.39 ACC 0.5 on epoch=49
06/24/2022 10:09:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.33 on epoch=54
06/24/2022 10:09:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=59
06/24/2022 10:09:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.32 on epoch=64
06/24/2022 10:09:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.36 on epoch=69
06/24/2022 10:09:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=74
06/24/2022 10:09:20 - INFO - __main__ - Global step 150 Train loss 0.33 ACC 0.5 on epoch=74
06/24/2022 10:09:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=79
06/24/2022 10:09:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/24/2022 10:09:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.30 on epoch=89
06/24/2022 10:09:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=94
06/24/2022 10:09:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=99
06/24/2022 10:09:27 - INFO - __main__ - Global step 200 Train loss 0.30 ACC 0.5 on epoch=99
06/24/2022 10:09:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=104
06/24/2022 10:09:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
06/24/2022 10:09:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.29 on epoch=114
06/24/2022 10:09:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=119
06/24/2022 10:09:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=124
06/24/2022 10:09:34 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/24/2022 10:09:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=129
06/24/2022 10:09:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/24/2022 10:09:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=139
06/24/2022 10:09:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=144
06/24/2022 10:09:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=149
06/24/2022 10:09:41 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.5 on epoch=149
06/24/2022 10:09:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/24/2022 10:09:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=159
06/24/2022 10:09:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=164
06/24/2022 10:09:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=169
06/24/2022 10:09:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=174
06/24/2022 10:09:48 - INFO - __main__ - Global step 350 Train loss 0.22 ACC 0.59375 on epoch=174
06/24/2022 10:09:48 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=174, global_step=350
06/24/2022 10:09:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=179
06/24/2022 10:09:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=184
06/24/2022 10:09:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=189
06/24/2022 10:09:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=194
06/24/2022 10:09:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=199
06/24/2022 10:09:55 - INFO - __main__ - Global step 400 Train loss 0.23 ACC 0.53125 on epoch=199
06/24/2022 10:09:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=204
06/24/2022 10:09:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=209
06/24/2022 10:09:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=214
06/24/2022 10:10:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=219
06/24/2022 10:10:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=224
06/24/2022 10:10:02 - INFO - __main__ - Global step 450 Train loss 0.20 ACC 0.5625 on epoch=224
06/24/2022 10:10:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=229
06/24/2022 10:10:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=234
06/24/2022 10:10:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=239
06/24/2022 10:10:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=244
06/24/2022 10:10:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=249
06/24/2022 10:10:08 - INFO - __main__ - Global step 500 Train loss 0.15 ACC 0.5625 on epoch=249
06/24/2022 10:10:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=254
06/24/2022 10:10:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=259
06/24/2022 10:10:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=264
06/24/2022 10:10:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=269
06/24/2022 10:10:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=274
06/24/2022 10:10:15 - INFO - __main__ - Global step 550 Train loss 0.11 ACC 0.46875 on epoch=274
06/24/2022 10:10:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=279
06/24/2022 10:10:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=284
06/24/2022 10:10:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=289
06/24/2022 10:10:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=294
06/24/2022 10:10:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=299
06/24/2022 10:10:22 - INFO - __main__ - Global step 600 Train loss 0.07 ACC 0.46875 on epoch=299
06/24/2022 10:10:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.04 on epoch=304
06/24/2022 10:10:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=309
06/24/2022 10:10:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=314
06/24/2022 10:10:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=319
06/24/2022 10:10:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=324
06/24/2022 10:10:29 - INFO - __main__ - Global step 650 Train loss 0.05 ACC 0.46875 on epoch=324
06/24/2022 10:10:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=329
06/24/2022 10:10:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=334
06/24/2022 10:10:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=339
06/24/2022 10:10:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=344
06/24/2022 10:10:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=349
06/24/2022 10:10:36 - INFO - __main__ - Global step 700 Train loss 0.02 ACC 0.40625 on epoch=349
06/24/2022 10:10:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=354
06/24/2022 10:10:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=359
06/24/2022 10:10:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=364
06/24/2022 10:10:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=369
06/24/2022 10:10:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=374
06/24/2022 10:10:43 - INFO - __main__ - Global step 750 Train loss 0.03 ACC 0.5625 on epoch=374
06/24/2022 10:10:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=379
06/24/2022 10:10:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=384
06/24/2022 10:10:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=389
06/24/2022 10:10:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
06/24/2022 10:10:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=399
06/24/2022 10:10:49 - INFO - __main__ - Global step 800 Train loss 0.03 ACC 0.5 on epoch=399
06/24/2022 10:10:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=404
06/24/2022 10:10:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=409
06/24/2022 10:10:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=414
06/24/2022 10:10:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=419
06/24/2022 10:10:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=424
06/24/2022 10:10:56 - INFO - __main__ - Global step 850 Train loss 0.02 ACC 0.4375 on epoch=424
06/24/2022 10:10:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=429
06/24/2022 10:10:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=434
06/24/2022 10:11:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=439
06/24/2022 10:11:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=444
06/24/2022 10:11:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=449
06/24/2022 10:11:03 - INFO - __main__ - Global step 900 Train loss 0.05 ACC 0.40625 on epoch=449
06/24/2022 10:11:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=454
06/24/2022 10:11:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/24/2022 10:11:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 10:11:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=469
06/24/2022 10:11:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=474
06/24/2022 10:11:10 - INFO - __main__ - Global step 950 Train loss 0.02 ACC 0.3125 on epoch=474
06/24/2022 10:11:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
06/24/2022 10:11:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=484
06/24/2022 10:11:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=489
06/24/2022 10:11:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=494
06/24/2022 10:11:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=499
06/24/2022 10:11:17 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.46875 on epoch=499
06/24/2022 10:11:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 10:11:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=509
06/24/2022 10:11:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=514
06/24/2022 10:11:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=519
06/24/2022 10:11:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
06/24/2022 10:11:23 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.4375 on epoch=524
06/24/2022 10:11:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/24/2022 10:11:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=534
06/24/2022 10:11:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/24/2022 10:11:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 10:11:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=549
06/24/2022 10:11:30 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.34375 on epoch=549
06/24/2022 10:11:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=554
06/24/2022 10:11:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 10:11:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 10:11:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=569
06/24/2022 10:11:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=574
06/24/2022 10:11:37 - INFO - __main__ - Global step 1150 Train loss 0.01 ACC 0.5 on epoch=574
06/24/2022 10:11:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 10:11:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 10:11:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
06/24/2022 10:11:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 10:11:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 10:11:44 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.4375 on epoch=599
06/24/2022 10:11:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 10:11:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 10:11:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/24/2022 10:11:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 10:11:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 10:11:50 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.40625 on epoch=624
06/24/2022 10:11:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/24/2022 10:11:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 10:11:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
06/24/2022 10:11:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 10:11:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 10:11:57 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.375 on epoch=649
06/24/2022 10:11:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 10:12:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 10:12:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 10:12:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 10:12:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 10:12:04 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.34375 on epoch=674
06/24/2022 10:12:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 10:12:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 10:12:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 10:12:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=694
06/24/2022 10:12:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 10:12:11 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.46875 on epoch=699
06/24/2022 10:12:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 10:12:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 10:12:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 10:12:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 10:12:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 10:12:18 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.4375 on epoch=724
06/24/2022 10:12:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 10:12:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 10:12:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=739
06/24/2022 10:12:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 10:12:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 10:12:24 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.40625 on epoch=749
06/24/2022 10:12:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 10:12:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 10:12:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 10:12:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 10:12:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 10:12:31 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.4375 on epoch=774
06/24/2022 10:12:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 10:12:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 10:12:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 10:12:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 10:12:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 10:12:38 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.46875 on epoch=799
06/24/2022 10:12:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 10:12:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 10:12:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 10:12:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 10:12:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 10:12:45 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.46875 on epoch=824
06/24/2022 10:12:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 10:12:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 10:12:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 10:12:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/24/2022 10:12:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 10:12:52 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.4375 on epoch=849
06/24/2022 10:12:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 10:12:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 10:12:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 10:12:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 10:12:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 10:12:58 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.40625 on epoch=874
06/24/2022 10:13:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 10:13:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 10:13:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 10:13:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 10:13:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=899
06/24/2022 10:13:05 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.46875 on epoch=899
06/24/2022 10:13:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 10:13:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 10:13:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 10:13:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 10:13:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 10:13:12 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.3125 on epoch=924
06/24/2022 10:13:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 10:13:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 10:13:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 10:13:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 10:13:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 10:13:19 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.40625 on epoch=949
06/24/2022 10:13:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 10:13:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 10:13:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 10:13:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 10:13:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 10:13:26 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.40625 on epoch=974
06/24/2022 10:13:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 10:13:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 10:13:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 10:13:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 10:13:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 10:13:32 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.34375 on epoch=999
06/24/2022 10:13:32 - INFO - __main__ - save last model!
06/24/2022 10:13:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 10:13:33 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 10:13:33 - INFO - __main__ - Printing 3 examples
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 10:13:33 - INFO - __main__ - ['duplicate']
06/24/2022 10:13:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:13:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:13:33 - INFO - __main__ - Printing 3 examples
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:13:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:13:33 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:13:33 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:13:33 - INFO - __main__ - Printing 3 examples
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 10:13:33 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:13:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:13:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:13:33 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:13:39 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 10:13:39 - INFO - __main__ - task name: glue-qqp
06/24/2022 10:13:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:13:40 - INFO - __main__ - Starting training!
06/24/2022 10:13:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:14:31 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 10:27:19 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_21_0.3_8_predictions.txt
06/24/2022 10:27:19 - INFO - __main__ - ACC on test data: 0.5284
06/24/2022 10:27:19 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.3, bsz=8, dev_performance=0.59375, test_performance=0.5283947563690329
06/24/2022 10:27:19 - INFO - __main__ - Running ... prefix=glue-qqp_16_21, lr=0.2, bsz=8 ...
06/24/2022 10:27:20 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:27:20 - INFO - __main__ - Printing 3 examples
06/24/2022 10:27:20 - INFO - __main__ -  [glue-qqp] question 1: How long before the space shuttle Challenger explosion/disaster would the crew on board have known they were going to die? [SEP] question 2: Did the Columbia crew in the shuttle know that they were going to die during the last fifteen minutes?
06/24/2022 10:27:20 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:27:20 - INFO - __main__ -  [glue-qqp] question 1: What's the best strategy for new products launch? [SEP] question 2: What should be the right strategy to launch a new product in the FMCG market in the lamp category?
06/24/2022 10:27:20 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:27:20 - INFO - __main__ -  [glue-qqp] question 1: Which one should I buy, a GoPro or DSLR camera? [SEP] question 2: Should I buy Nikon DSLR camera from Amazon?
06/24/2022 10:27:20 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:27:20 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:27:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:27:20 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:27:20 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:27:20 - INFO - __main__ - Printing 3 examples
06/24/2022 10:27:20 - INFO - __main__ -  [glue-qqp] question 1: What are some mind-blowing facts about Yahoo? [SEP] question 2: What are the mind-blowing facts about Yahoo?
06/24/2022 10:27:20 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:27:20 - INFO - __main__ -  [glue-qqp] question 1: Which is the best book for investment in mutual funds in India? [SEP] question 2: Who is the best mutual fund manager in India?
06/24/2022 10:27:20 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:27:20 - INFO - __main__ -  [glue-qqp] question 1: What are different types of yogurt and how are they different? [SEP] question 2: What are the differences between Greek yogurt and normal yogurt?
06/24/2022 10:27:20 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:27:20 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:27:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:27:20 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:27:26 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 10:27:26 - INFO - __main__ - task name: glue-qqp
06/24/2022 10:27:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:27:26 - INFO - __main__ - Starting training!
06/24/2022 10:27:28 - INFO - __main__ - Step 10 Global step 10 Train loss 6.78 on epoch=4
06/24/2022 10:27:29 - INFO - __main__ - Step 20 Global step 20 Train loss 4.52 on epoch=9
06/24/2022 10:27:30 - INFO - __main__ - Step 30 Global step 30 Train loss 2.45 on epoch=14
06/24/2022 10:27:32 - INFO - __main__ - Step 40 Global step 40 Train loss 1.22 on epoch=19
06/24/2022 10:27:33 - INFO - __main__ - Step 50 Global step 50 Train loss 0.92 on epoch=24
06/24/2022 10:27:33 - INFO - __main__ - Global step 50 Train loss 3.18 ACC 0.71875 on epoch=24
06/24/2022 10:27:34 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.71875 on epoch=24, global_step=50
06/24/2022 10:27:35 - INFO - __main__ - Step 60 Global step 60 Train loss 0.65 on epoch=29
06/24/2022 10:27:36 - INFO - __main__ - Step 70 Global step 70 Train loss 0.50 on epoch=34
06/24/2022 10:27:37 - INFO - __main__ - Step 80 Global step 80 Train loss 0.47 on epoch=39
06/24/2022 10:27:38 - INFO - __main__ - Step 90 Global step 90 Train loss 0.43 on epoch=44
06/24/2022 10:27:40 - INFO - __main__ - Step 100 Global step 100 Train loss 0.39 on epoch=49
06/24/2022 10:27:40 - INFO - __main__ - Global step 100 Train loss 0.49 ACC 0.5 on epoch=49
06/24/2022 10:27:42 - INFO - __main__ - Step 110 Global step 110 Train loss 0.48 on epoch=54
06/24/2022 10:27:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.47 on epoch=59
06/24/2022 10:27:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.33 on epoch=64
06/24/2022 10:27:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
06/24/2022 10:27:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.33 on epoch=74
06/24/2022 10:27:47 - INFO - __main__ - Global step 150 Train loss 0.39 ACC 0.5 on epoch=74
06/24/2022 10:27:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.32 on epoch=79
06/24/2022 10:27:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.28 on epoch=84
06/24/2022 10:27:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=89
06/24/2022 10:27:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.24 on epoch=94
06/24/2022 10:27:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.30 on epoch=99
06/24/2022 10:27:54 - INFO - __main__ - Global step 200 Train loss 0.28 ACC 0.53125 on epoch=99
06/24/2022 10:27:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.30 on epoch=104
06/24/2022 10:27:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=109
06/24/2022 10:27:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=114
06/24/2022 10:27:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.30 on epoch=119
06/24/2022 10:28:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=124
06/24/2022 10:28:01 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/24/2022 10:28:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/24/2022 10:28:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/24/2022 10:28:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=139
06/24/2022 10:28:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/24/2022 10:28:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=149
06/24/2022 10:28:08 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.5 on epoch=149
06/24/2022 10:28:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=154
06/24/2022 10:28:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/24/2022 10:28:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/24/2022 10:28:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/24/2022 10:28:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=174
06/24/2022 10:28:14 - INFO - __main__ - Global step 350 Train loss 0.26 ACC 0.5 on epoch=174
06/24/2022 10:28:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=179
06/24/2022 10:28:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=184
06/24/2022 10:28:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 10:28:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=194
06/24/2022 10:28:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=199
06/24/2022 10:28:21 - INFO - __main__ - Global step 400 Train loss 0.24 ACC 0.53125 on epoch=199
06/24/2022 10:28:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=204
06/24/2022 10:28:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=209
06/24/2022 10:28:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=214
06/24/2022 10:28:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=219
06/24/2022 10:28:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=224
06/24/2022 10:28:28 - INFO - __main__ - Global step 450 Train loss 0.25 ACC 0.5 on epoch=224
06/24/2022 10:28:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=229
06/24/2022 10:28:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=234
06/24/2022 10:28:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=239
06/24/2022 10:28:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=244
06/24/2022 10:28:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=249
06/24/2022 10:28:35 - INFO - __main__ - Global step 500 Train loss 0.24 ACC 0.5 on epoch=249
06/24/2022 10:28:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/24/2022 10:28:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=259
06/24/2022 10:28:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=264
06/24/2022 10:28:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=269
06/24/2022 10:28:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/24/2022 10:28:42 - INFO - __main__ - Global step 550 Train loss 0.23 ACC 0.5 on epoch=274
06/24/2022 10:28:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=279
06/24/2022 10:28:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=284
06/24/2022 10:28:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=289
06/24/2022 10:28:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=294
06/24/2022 10:28:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=299
06/24/2022 10:28:49 - INFO - __main__ - Global step 600 Train loss 0.21 ACC 0.53125 on epoch=299
06/24/2022 10:28:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=304
06/24/2022 10:28:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=309
06/24/2022 10:28:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=314
06/24/2022 10:28:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=319
06/24/2022 10:28:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=324
06/24/2022 10:28:56 - INFO - __main__ - Global step 650 Train loss 0.23 ACC 0.53125 on epoch=324
06/24/2022 10:28:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=329
06/24/2022 10:28:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=334
06/24/2022 10:29:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=339
06/24/2022 10:29:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=344
06/24/2022 10:29:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=349
06/24/2022 10:29:03 - INFO - __main__ - Global step 700 Train loss 0.21 ACC 0.53125 on epoch=349
06/24/2022 10:29:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=354
06/24/2022 10:29:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=359
06/24/2022 10:29:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=364
06/24/2022 10:29:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=369
06/24/2022 10:29:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=374
06/24/2022 10:29:10 - INFO - __main__ - Global step 750 Train loss 0.22 ACC 0.53125 on epoch=374
06/24/2022 10:29:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=379
06/24/2022 10:29:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=384
06/24/2022 10:29:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=389
06/24/2022 10:29:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=394
06/24/2022 10:29:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=399
06/24/2022 10:29:16 - INFO - __main__ - Global step 800 Train loss 0.20 ACC 0.53125 on epoch=399
06/24/2022 10:29:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=404
06/24/2022 10:29:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=409
06/24/2022 10:29:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=414
06/24/2022 10:29:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=419
06/24/2022 10:29:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=424
06/24/2022 10:29:23 - INFO - __main__ - Global step 850 Train loss 0.21 ACC 0.46875 on epoch=424
06/24/2022 10:29:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=429
06/24/2022 10:29:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=434
06/24/2022 10:29:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/24/2022 10:29:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=444
06/24/2022 10:29:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=449
06/24/2022 10:29:30 - INFO - __main__ - Global step 900 Train loss 0.18 ACC 0.53125 on epoch=449
06/24/2022 10:29:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=454
06/24/2022 10:29:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=459
06/24/2022 10:29:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=464
06/24/2022 10:29:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=469
06/24/2022 10:29:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=474
06/24/2022 10:29:37 - INFO - __main__ - Global step 950 Train loss 0.18 ACC 0.53125 on epoch=474
06/24/2022 10:29:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=479
06/24/2022 10:29:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=484
06/24/2022 10:29:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=489
06/24/2022 10:29:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=494
06/24/2022 10:29:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=499
06/24/2022 10:29:44 - INFO - __main__ - Global step 1000 Train loss 0.16 ACC 0.5 on epoch=499
06/24/2022 10:29:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=504
06/24/2022 10:29:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=509
06/24/2022 10:29:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=514
06/24/2022 10:29:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=519
06/24/2022 10:29:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=524
06/24/2022 10:29:51 - INFO - __main__ - Global step 1050 Train loss 0.13 ACC 0.4375 on epoch=524
06/24/2022 10:29:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=529
06/24/2022 10:29:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=534
06/24/2022 10:29:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=539
06/24/2022 10:29:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=544
06/24/2022 10:29:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=549
06/24/2022 10:29:57 - INFO - __main__ - Global step 1100 Train loss 0.12 ACC 0.53125 on epoch=549
06/24/2022 10:29:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=554
06/24/2022 10:30:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=559
06/24/2022 10:30:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=564
06/24/2022 10:30:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=569
06/24/2022 10:30:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=574
06/24/2022 10:30:04 - INFO - __main__ - Global step 1150 Train loss 0.11 ACC 0.4375 on epoch=574
06/24/2022 10:30:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=579
06/24/2022 10:30:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=584
06/24/2022 10:30:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=589
06/24/2022 10:30:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=594
06/24/2022 10:30:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=599
06/24/2022 10:30:11 - INFO - __main__ - Global step 1200 Train loss 0.10 ACC 0.5 on epoch=599
06/24/2022 10:30:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=604
06/24/2022 10:30:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=609
06/24/2022 10:30:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=614
06/24/2022 10:30:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=619
06/24/2022 10:30:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=624
06/24/2022 10:30:18 - INFO - __main__ - Global step 1250 Train loss 0.08 ACC 0.46875 on epoch=624
06/24/2022 10:30:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=629
06/24/2022 10:30:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=634
06/24/2022 10:30:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=639
06/24/2022 10:30:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=644
06/24/2022 10:30:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=649
06/24/2022 10:30:25 - INFO - __main__ - Global step 1300 Train loss 0.09 ACC 0.5 on epoch=649
06/24/2022 10:30:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=654
06/24/2022 10:30:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=659
06/24/2022 10:30:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=664
06/24/2022 10:30:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=669
06/24/2022 10:30:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=674
06/24/2022 10:30:32 - INFO - __main__ - Global step 1350 Train loss 0.06 ACC 0.5 on epoch=674
06/24/2022 10:30:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=679
06/24/2022 10:30:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=684
06/24/2022 10:30:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=689
06/24/2022 10:30:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=694
06/24/2022 10:30:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=699
06/24/2022 10:30:38 - INFO - __main__ - Global step 1400 Train loss 0.05 ACC 0.5 on epoch=699
06/24/2022 10:30:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=704
06/24/2022 10:30:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=709
06/24/2022 10:30:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=714
06/24/2022 10:30:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=719
06/24/2022 10:30:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=724
06/24/2022 10:30:45 - INFO - __main__ - Global step 1450 Train loss 0.05 ACC 0.5 on epoch=724
06/24/2022 10:30:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/24/2022 10:30:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=734
06/24/2022 10:30:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=739
06/24/2022 10:30:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=744
06/24/2022 10:30:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=749
06/24/2022 10:30:52 - INFO - __main__ - Global step 1500 Train loss 0.06 ACC 0.5 on epoch=749
06/24/2022 10:30:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=754
06/24/2022 10:30:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=759
06/24/2022 10:30:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=764
06/24/2022 10:30:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=769
06/24/2022 10:30:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=774
06/24/2022 10:30:59 - INFO - __main__ - Global step 1550 Train loss 0.04 ACC 0.5 on epoch=774
06/24/2022 10:31:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=779
06/24/2022 10:31:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=784
06/24/2022 10:31:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=789
06/24/2022 10:31:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=794
06/24/2022 10:31:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=799
06/24/2022 10:31:06 - INFO - __main__ - Global step 1600 Train loss 0.04 ACC 0.5 on epoch=799
06/24/2022 10:31:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=804
06/24/2022 10:31:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=809
06/24/2022 10:31:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=814
06/24/2022 10:31:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=819
06/24/2022 10:31:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=824
06/24/2022 10:31:13 - INFO - __main__ - Global step 1650 Train loss 0.04 ACC 0.5 on epoch=824
06/24/2022 10:31:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 10:31:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=834
06/24/2022 10:31:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=839
06/24/2022 10:31:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/24/2022 10:31:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=849
06/24/2022 10:31:20 - INFO - __main__ - Global step 1700 Train loss 0.03 ACC 0.5 on epoch=849
06/24/2022 10:31:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=854
06/24/2022 10:31:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=859
06/24/2022 10:31:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=864
06/24/2022 10:31:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=869
06/24/2022 10:31:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=874
06/24/2022 10:31:27 - INFO - __main__ - Global step 1750 Train loss 0.03 ACC 0.46875 on epoch=874
06/24/2022 10:31:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=879
06/24/2022 10:31:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
06/24/2022 10:31:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=889
06/24/2022 10:31:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=894
06/24/2022 10:31:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=899
06/24/2022 10:31:34 - INFO - __main__ - Global step 1800 Train loss 0.02 ACC 0.46875 on epoch=899
06/24/2022 10:31:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=904
06/24/2022 10:31:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=909
06/24/2022 10:31:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 10:31:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=919
06/24/2022 10:31:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/24/2022 10:31:41 - INFO - __main__ - Global step 1850 Train loss 0.02 ACC 0.5 on epoch=924
06/24/2022 10:31:42 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 10:31:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/24/2022 10:31:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=939
06/24/2022 10:31:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 10:31:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 10:31:48 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
06/24/2022 10:31:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 10:31:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=959
06/24/2022 10:31:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=964
06/24/2022 10:31:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=969
06/24/2022 10:31:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=974
06/24/2022 10:31:55 - INFO - __main__ - Global step 1950 Train loss 0.04 ACC 0.5625 on epoch=974
06/24/2022 10:31:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
06/24/2022 10:31:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=984
06/24/2022 10:31:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 10:32:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/24/2022 10:32:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=999
06/24/2022 10:32:02 - INFO - __main__ - Global step 2000 Train loss 0.02 ACC 0.46875 on epoch=999
06/24/2022 10:32:02 - INFO - __main__ - save last model!
06/24/2022 10:32:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 10:32:02 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 10:32:02 - INFO - __main__ - Printing 3 examples
06/24/2022 10:32:02 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 10:32:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:32:02 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 10:32:02 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:32:02 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 10:32:02 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:32:02 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:32:02 - INFO - __main__ - Printing 3 examples
06/24/2022 10:32:02 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:32:02 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:02 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:32:02 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:02 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:32:02 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:32:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:32:03 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:32:03 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:32:03 - INFO - __main__ - Printing 3 examples
06/24/2022 10:32:03 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:32:03 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:03 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:32:03 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:03 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:32:03 - INFO - __main__ - ['duplicate']
06/24/2022 10:32:03 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:32:03 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:32:03 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:32:08 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 10:32:08 - INFO - __main__ - task name: glue-qqp
06/24/2022 10:32:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:32:08 - INFO - __main__ - Starting training!
06/24/2022 10:32:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:33:01 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 10:45:32 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_21_0.2_8_predictions.txt
06/24/2022 10:45:33 - INFO - __main__ - ACC on test data: 0.4025
06/24/2022 10:45:33 - INFO - __main__ - prefix=glue-qqp_16_21, lr=0.2, bsz=8, dev_performance=0.71875, test_performance=0.40249814494187486
06/24/2022 10:45:33 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.5, bsz=8 ...
06/24/2022 10:45:34 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:45:34 - INFO - __main__ - Printing 3 examples
06/24/2022 10:45:34 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:45:34 - INFO - __main__ - ['duplicate']
06/24/2022 10:45:34 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:45:34 - INFO - __main__ - ['duplicate']
06/24/2022 10:45:34 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:45:34 - INFO - __main__ - ['duplicate']
06/24/2022 10:45:34 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:45:34 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:45:34 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:45:34 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:45:34 - INFO - __main__ - Printing 3 examples
06/24/2022 10:45:34 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:45:34 - INFO - __main__ - ['duplicate']
06/24/2022 10:45:34 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:45:34 - INFO - __main__ - ['duplicate']
06/24/2022 10:45:34 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:45:34 - INFO - __main__ - ['duplicate']
06/24/2022 10:45:34 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:45:34 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:45:34 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:45:40 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 10:45:40 - INFO - __main__ - task name: glue-qqp
06/24/2022 10:45:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:45:40 - INFO - __main__ - Starting training!
06/24/2022 10:45:42 - INFO - __main__ - Step 10 Global step 10 Train loss 5.54 on epoch=4
06/24/2022 10:45:43 - INFO - __main__ - Step 20 Global step 20 Train loss 1.92 on epoch=9
06/24/2022 10:45:44 - INFO - __main__ - Step 30 Global step 30 Train loss 1.45 on epoch=14
06/24/2022 10:45:45 - INFO - __main__ - Step 40 Global step 40 Train loss 0.84 on epoch=19
06/24/2022 10:45:47 - INFO - __main__ - Step 50 Global step 50 Train loss 0.67 on epoch=24
06/24/2022 10:45:47 - INFO - __main__ - Global step 50 Train loss 2.08 ACC 0.5 on epoch=24
06/24/2022 10:45:47 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 10:45:48 - INFO - __main__ - Step 60 Global step 60 Train loss 0.55 on epoch=29
06/24/2022 10:45:50 - INFO - __main__ - Step 70 Global step 70 Train loss 0.47 on epoch=34
06/24/2022 10:45:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.44 on epoch=39
06/24/2022 10:45:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.41 on epoch=44
06/24/2022 10:45:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.37 on epoch=49
06/24/2022 10:45:54 - INFO - __main__ - Global step 100 Train loss 0.45 ACC 0.40625 on epoch=49
06/24/2022 10:45:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.32 on epoch=54
06/24/2022 10:45:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=59
06/24/2022 10:45:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.37 on epoch=64
06/24/2022 10:45:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.33 on epoch=69
06/24/2022 10:46:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.39 on epoch=74
06/24/2022 10:46:01 - INFO - __main__ - Global step 150 Train loss 0.35 ACC 0.5 on epoch=74
06/24/2022 10:46:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.37 on epoch=79
06/24/2022 10:46:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.37 on epoch=84
06/24/2022 10:46:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=89
06/24/2022 10:46:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.31 on epoch=94
06/24/2022 10:46:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=99
06/24/2022 10:46:08 - INFO - __main__ - Global step 200 Train loss 0.32 ACC 0.5 on epoch=99
06/24/2022 10:46:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=104
06/24/2022 10:46:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=109
06/24/2022 10:46:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/24/2022 10:46:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 10:46:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=124
06/24/2022 10:46:15 - INFO - __main__ - Global step 250 Train loss 0.30 ACC 0.5 on epoch=124
06/24/2022 10:46:16 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=129
06/24/2022 10:46:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/24/2022 10:46:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=139
06/24/2022 10:46:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=144
06/24/2022 10:46:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=149
06/24/2022 10:46:22 - INFO - __main__ - Global step 300 Train loss 0.28 ACC 0.5 on epoch=149
06/24/2022 10:46:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=154
06/24/2022 10:46:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=159
06/24/2022 10:46:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=164
06/24/2022 10:46:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=169
06/24/2022 10:46:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=174
06/24/2022 10:46:29 - INFO - __main__ - Global step 350 Train loss 0.28 ACC 0.5 on epoch=174
06/24/2022 10:46:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=179
06/24/2022 10:46:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=184
06/24/2022 10:46:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=189
06/24/2022 10:46:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=194
06/24/2022 10:46:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=199
06/24/2022 10:46:36 - INFO - __main__ - Global step 400 Train loss 0.28 ACC 0.5 on epoch=199
06/24/2022 10:46:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/24/2022 10:46:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=209
06/24/2022 10:46:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=214
06/24/2022 10:46:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=219
06/24/2022 10:46:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=224
06/24/2022 10:46:43 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.5 on epoch=224
06/24/2022 10:46:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=229
06/24/2022 10:46:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=234
06/24/2022 10:46:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=239
06/24/2022 10:46:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=244
06/24/2022 10:46:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=249
06/24/2022 10:46:50 - INFO - __main__ - Global step 500 Train loss 0.25 ACC 0.5 on epoch=249
06/24/2022 10:46:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=254
06/24/2022 10:46:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=259
06/24/2022 10:46:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=264
06/24/2022 10:46:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=269
06/24/2022 10:46:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=274
06/24/2022 10:46:56 - INFO - __main__ - Global step 550 Train loss 0.24 ACC 0.5 on epoch=274
06/24/2022 10:46:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=279
06/24/2022 10:46:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=284
06/24/2022 10:47:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=289
06/24/2022 10:47:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=294
06/24/2022 10:47:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=299
06/24/2022 10:47:03 - INFO - __main__ - Global step 600 Train loss 0.26 ACC 0.5 on epoch=299
06/24/2022 10:47:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=304
06/24/2022 10:47:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=309
06/24/2022 10:47:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=314
06/24/2022 10:47:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=319
06/24/2022 10:47:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=324
06/24/2022 10:47:10 - INFO - __main__ - Global step 650 Train loss 0.24 ACC 0.5 on epoch=324
06/24/2022 10:47:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=329
06/24/2022 10:47:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=334
06/24/2022 10:47:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=339
06/24/2022 10:47:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=344
06/24/2022 10:47:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=349
06/24/2022 10:47:17 - INFO - __main__ - Global step 700 Train loss 0.26 ACC 0.53125 on epoch=349
06/24/2022 10:47:17 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=349, global_step=700
06/24/2022 10:47:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=354
06/24/2022 10:47:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=359
06/24/2022 10:47:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=364
06/24/2022 10:47:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=369
06/24/2022 10:47:24 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=374
06/24/2022 10:47:24 - INFO - __main__ - Global step 750 Train loss 0.23 ACC 0.5 on epoch=374
06/24/2022 10:47:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=379
06/24/2022 10:47:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=384
06/24/2022 10:47:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=389
06/24/2022 10:47:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=394
06/24/2022 10:47:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=399
06/24/2022 10:47:31 - INFO - __main__ - Global step 800 Train loss 0.25 ACC 0.5 on epoch=399
06/24/2022 10:47:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=404
06/24/2022 10:47:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=409
06/24/2022 10:47:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.24 on epoch=414
06/24/2022 10:47:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=419
06/24/2022 10:47:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=424
06/24/2022 10:47:38 - INFO - __main__ - Global step 850 Train loss 0.23 ACC 0.5 on epoch=424
06/24/2022 10:47:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=429
06/24/2022 10:47:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=434
06/24/2022 10:47:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=439
06/24/2022 10:47:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=444
06/24/2022 10:47:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=449
06/24/2022 10:47:45 - INFO - __main__ - Global step 900 Train loss 0.23 ACC 0.5 on epoch=449
06/24/2022 10:47:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=454
06/24/2022 10:47:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=459
06/24/2022 10:47:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=464
06/24/2022 10:47:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=469
06/24/2022 10:47:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=474
06/24/2022 10:47:52 - INFO - __main__ - Global step 950 Train loss 0.23 ACC 0.5 on epoch=474
06/24/2022 10:47:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=479
06/24/2022 10:47:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=484
06/24/2022 10:47:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=489
06/24/2022 10:47:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=494
06/24/2022 10:47:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=499
06/24/2022 10:47:59 - INFO - __main__ - Global step 1000 Train loss 0.18 ACC 0.5625 on epoch=499
06/24/2022 10:47:59 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=499, global_step=1000
06/24/2022 10:48:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=504
06/24/2022 10:48:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=509
06/24/2022 10:48:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=514
06/24/2022 10:48:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=519
06/24/2022 10:48:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=524
06/24/2022 10:48:06 - INFO - __main__ - Global step 1050 Train loss 0.12 ACC 0.59375 on epoch=524
06/24/2022 10:48:06 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=524, global_step=1050
06/24/2022 10:48:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/24/2022 10:48:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=534
06/24/2022 10:48:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=539
06/24/2022 10:48:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=544
06/24/2022 10:48:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=549
06/24/2022 10:48:13 - INFO - __main__ - Global step 1100 Train loss 0.05 ACC 0.5 on epoch=549
06/24/2022 10:48:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
06/24/2022 10:48:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=559
06/24/2022 10:48:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 10:48:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=569
06/24/2022 10:48:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/24/2022 10:48:20 - INFO - __main__ - Global step 1150 Train loss 0.03 ACC 0.59375 on epoch=574
06/24/2022 10:48:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=579
06/24/2022 10:48:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 10:48:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/24/2022 10:48:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=594
06/24/2022 10:48:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/24/2022 10:48:27 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.59375 on epoch=599
06/24/2022 10:48:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=604
06/24/2022 10:48:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/24/2022 10:48:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 10:48:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/24/2022 10:48:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 10:48:34 - INFO - __main__ - Global step 1250 Train loss 0.01 ACC 0.5625 on epoch=624
06/24/2022 10:48:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 10:48:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 10:48:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=639
06/24/2022 10:48:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=644
06/24/2022 10:48:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 10:48:41 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.59375 on epoch=649
06/24/2022 10:48:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 10:48:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 10:48:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 10:48:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=669
06/24/2022 10:48:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 10:48:48 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.53125 on epoch=674
06/24/2022 10:48:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 10:48:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
06/24/2022 10:48:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 10:48:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=694
06/24/2022 10:48:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 10:48:55 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.625 on epoch=699
06/24/2022 10:48:55 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=699, global_step=1400
06/24/2022 10:48:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 10:48:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 10:48:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 10:49:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 10:49:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 10:49:02 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.59375 on epoch=724
06/24/2022 10:49:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 10:49:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 10:49:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 10:49:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 10:49:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 10:49:09 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.53125 on epoch=749
06/24/2022 10:49:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 10:49:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=759
06/24/2022 10:49:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 10:49:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=769
06/24/2022 10:49:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=774
06/24/2022 10:49:16 - INFO - __main__ - Global step 1550 Train loss 0.02 ACC 0.59375 on epoch=774
06/24/2022 10:49:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 10:49:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 10:49:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 10:49:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 10:49:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 10:49:23 - INFO - __main__ - Global step 1600 Train loss 0.00 ACC 0.625 on epoch=799
06/24/2022 10:49:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 10:49:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 10:49:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 10:49:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 10:49:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 10:49:30 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.53125 on epoch=824
06/24/2022 10:49:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 10:49:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 10:49:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 10:49:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 10:49:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 10:49:37 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.625 on epoch=849
06/24/2022 10:49:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 10:49:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=859
06/24/2022 10:49:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 10:49:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 10:49:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 10:49:44 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
06/24/2022 10:49:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 10:49:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 10:49:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 10:49:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 10:49:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 10:49:51 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.625 on epoch=899
06/24/2022 10:49:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 10:49:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 10:49:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 10:49:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 10:49:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 10:49:58 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.5625 on epoch=924
06/24/2022 10:50:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 10:50:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 10:50:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 10:50:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=944
06/24/2022 10:50:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 10:50:05 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.5625 on epoch=949
06/24/2022 10:50:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 10:50:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 10:50:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 10:50:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 10:50:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 10:50:12 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.5625 on epoch=974
06/24/2022 10:50:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 10:50:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 10:50:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 10:50:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 10:50:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 10:50:19 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.59375 on epoch=999
06/24/2022 10:50:19 - INFO - __main__ - save last model!
06/24/2022 10:50:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 10:50:19 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 10:50:19 - INFO - __main__ - Printing 3 examples
06/24/2022 10:50:19 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 10:50:19 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:50:19 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 10:50:19 - INFO - __main__ - ['not_duplicate']
06/24/2022 10:50:19 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 10:50:19 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:50:20 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:50:20 - INFO - __main__ - Printing 3 examples
06/24/2022 10:50:20 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 10:50:20 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:20 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 10:50:20 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:20 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 10:50:20 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:20 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:50:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:50:20 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 10:50:20 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 10:50:20 - INFO - __main__ - Printing 3 examples
06/24/2022 10:50:20 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 10:50:20 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:20 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 10:50:20 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:20 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 10:50:20 - INFO - __main__ - ['duplicate']
06/24/2022 10:50:20 - INFO - __main__ - Tokenizing Input ...
06/24/2022 10:50:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:50:20 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 10:50:25 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 10:50:25 - INFO - __main__ - task name: glue-qqp
06/24/2022 10:50:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 10:50:25 - INFO - __main__ - Starting training!
06/24/2022 10:50:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 10:51:18 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:04:30 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_42_0.5_8_predictions.txt
06/24/2022 11:04:30 - INFO - __main__ - ACC on test data: 0.5444
06/24/2022 11:04:30 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.5, bsz=8, dev_performance=0.625, test_performance=0.5444471926787039
06/24/2022 11:04:30 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.4, bsz=8 ...
06/24/2022 11:04:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:04:31 - INFO - __main__ - Printing 3 examples
06/24/2022 11:04:31 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 11:04:31 - INFO - __main__ - ['duplicate']
06/24/2022 11:04:31 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 11:04:31 - INFO - __main__ - ['duplicate']
06/24/2022 11:04:31 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 11:04:31 - INFO - __main__ - ['duplicate']
06/24/2022 11:04:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:04:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:04:31 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:04:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:04:31 - INFO - __main__ - Printing 3 examples
06/24/2022 11:04:31 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 11:04:31 - INFO - __main__ - ['duplicate']
06/24/2022 11:04:31 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 11:04:31 - INFO - __main__ - ['duplicate']
06/24/2022 11:04:31 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 11:04:31 - INFO - __main__ - ['duplicate']
06/24/2022 11:04:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:04:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:04:31 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:04:37 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 11:04:37 - INFO - __main__ - task name: glue-qqp
06/24/2022 11:04:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:04:38 - INFO - __main__ - Starting training!
06/24/2022 11:04:39 - INFO - __main__ - Step 10 Global step 10 Train loss 6.00 on epoch=4
06/24/2022 11:04:40 - INFO - __main__ - Step 20 Global step 20 Train loss 3.09 on epoch=9
06/24/2022 11:04:42 - INFO - __main__ - Step 30 Global step 30 Train loss 1.39 on epoch=14
06/24/2022 11:04:43 - INFO - __main__ - Step 40 Global step 40 Train loss 0.80 on epoch=19
06/24/2022 11:04:44 - INFO - __main__ - Step 50 Global step 50 Train loss 0.63 on epoch=24
06/24/2022 11:04:45 - INFO - __main__ - Global step 50 Train loss 2.38 ACC 0.5 on epoch=24
06/24/2022 11:04:45 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 11:04:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.57 on epoch=29
06/24/2022 11:04:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=34
06/24/2022 11:04:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.47 on epoch=39
06/24/2022 11:04:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=44
06/24/2022 11:04:51 - INFO - __main__ - Step 100 Global step 100 Train loss 0.37 on epoch=49
06/24/2022 11:04:51 - INFO - __main__ - Global step 100 Train loss 0.42 ACC 0.5 on epoch=49
06/24/2022 11:04:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.37 on epoch=54
06/24/2022 11:04:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.32 on epoch=59
06/24/2022 11:04:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.34 on epoch=64
06/24/2022 11:04:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=69
06/24/2022 11:04:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.31 on epoch=74
06/24/2022 11:04:58 - INFO - __main__ - Global step 150 Train loss 0.32 ACC 0.5 on epoch=74
06/24/2022 11:04:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.34 on epoch=79
06/24/2022 11:05:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.31 on epoch=84
06/24/2022 11:05:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=89
06/24/2022 11:05:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=94
06/24/2022 11:05:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.34 on epoch=99
06/24/2022 11:05:05 - INFO - __main__ - Global step 200 Train loss 0.30 ACC 0.5 on epoch=99
06/24/2022 11:05:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.28 on epoch=104
06/24/2022 11:05:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=109
06/24/2022 11:05:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/24/2022 11:05:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 11:05:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=124
06/24/2022 11:05:11 - INFO - __main__ - Global step 250 Train loss 0.30 ACC 0.5 on epoch=124
06/24/2022 11:05:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/24/2022 11:05:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=134
06/24/2022 11:05:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=139
06/24/2022 11:05:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=144
06/24/2022 11:05:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=149
06/24/2022 11:05:18 - INFO - __main__ - Global step 300 Train loss 0.27 ACC 0.5 on epoch=149
06/24/2022 11:05:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/24/2022 11:05:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=159
06/24/2022 11:05:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=164
06/24/2022 11:05:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=169
06/24/2022 11:05:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=174
06/24/2022 11:05:25 - INFO - __main__ - Global step 350 Train loss 0.26 ACC 0.5 on epoch=174
06/24/2022 11:05:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 11:05:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=184
06/24/2022 11:05:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=189
06/24/2022 11:05:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=194
06/24/2022 11:05:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/24/2022 11:05:31 - INFO - __main__ - Global step 400 Train loss 0.27 ACC 0.5 on epoch=199
06/24/2022 11:05:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=204
06/24/2022 11:05:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=209
06/24/2022 11:05:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=214
06/24/2022 11:05:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=219
06/24/2022 11:05:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=224
06/24/2022 11:05:38 - INFO - __main__ - Global step 450 Train loss 0.24 ACC 0.5 on epoch=224
06/24/2022 11:05:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 11:05:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=234
06/24/2022 11:05:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=239
06/24/2022 11:05:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=244
06/24/2022 11:05:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=249
06/24/2022 11:05:45 - INFO - __main__ - Global step 500 Train loss 0.25 ACC 0.5 on epoch=249
06/24/2022 11:05:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=254
06/24/2022 11:05:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=259
06/24/2022 11:05:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=264
06/24/2022 11:05:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=269
06/24/2022 11:05:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=274
06/24/2022 11:05:51 - INFO - __main__ - Global step 550 Train loss 0.25 ACC 0.5 on epoch=274
06/24/2022 11:05:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=279
06/24/2022 11:05:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=284
06/24/2022 11:05:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=289
06/24/2022 11:05:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=294
06/24/2022 11:05:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=299
06/24/2022 11:05:58 - INFO - __main__ - Global step 600 Train loss 0.24 ACC 0.5 on epoch=299
06/24/2022 11:05:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=304
06/24/2022 11:06:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=309
06/24/2022 11:06:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=314
06/24/2022 11:06:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=319
06/24/2022 11:06:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=324
06/24/2022 11:06:05 - INFO - __main__ - Global step 650 Train loss 0.24 ACC 0.5 on epoch=324
06/24/2022 11:06:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=329
06/24/2022 11:06:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=334
06/24/2022 11:06:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=339
06/24/2022 11:06:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=344
06/24/2022 11:06:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=349
06/24/2022 11:06:11 - INFO - __main__ - Global step 700 Train loss 0.22 ACC 0.5 on epoch=349
06/24/2022 11:06:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=354
06/24/2022 11:06:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=359
06/24/2022 11:06:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=364
06/24/2022 11:06:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=369
06/24/2022 11:06:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=374
06/24/2022 11:06:18 - INFO - __main__ - Global step 750 Train loss 0.23 ACC 0.53125 on epoch=374
06/24/2022 11:06:18 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=374, global_step=750
06/24/2022 11:06:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=379
06/24/2022 11:06:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=384
06/24/2022 11:06:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=389
06/24/2022 11:06:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=394
06/24/2022 11:06:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=399
06/24/2022 11:06:25 - INFO - __main__ - Global step 800 Train loss 0.23 ACC 0.5 on epoch=399
06/24/2022 11:06:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=404
06/24/2022 11:06:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=409
06/24/2022 11:06:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=414
06/24/2022 11:06:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=419
06/24/2022 11:06:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=424
06/24/2022 11:06:31 - INFO - __main__ - Global step 850 Train loss 0.22 ACC 0.5 on epoch=424
06/24/2022 11:06:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=429
06/24/2022 11:06:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=434
06/24/2022 11:06:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=439
06/24/2022 11:06:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=444
06/24/2022 11:06:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=449
06/24/2022 11:06:38 - INFO - __main__ - Global step 900 Train loss 0.18 ACC 0.71875 on epoch=449
06/24/2022 11:06:38 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.71875 on epoch=449, global_step=900
06/24/2022 11:06:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=454
06/24/2022 11:06:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=459
06/24/2022 11:06:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=464
06/24/2022 11:06:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=469
06/24/2022 11:06:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=474
06/24/2022 11:06:45 - INFO - __main__ - Global step 950 Train loss 0.13 ACC 0.59375 on epoch=474
06/24/2022 11:06:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=479
06/24/2022 11:06:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=484
06/24/2022 11:06:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=489
06/24/2022 11:06:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=494
06/24/2022 11:06:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=499
06/24/2022 11:06:52 - INFO - __main__ - Global step 1000 Train loss 0.08 ACC 0.6875 on epoch=499
06/24/2022 11:06:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=504
06/24/2022 11:06:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=509
06/24/2022 11:06:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=514
06/24/2022 11:06:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=519
06/24/2022 11:06:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=524
06/24/2022 11:06:59 - INFO - __main__ - Global step 1050 Train loss 0.03 ACC 0.6875 on epoch=524
06/24/2022 11:07:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=529
06/24/2022 11:07:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=534
06/24/2022 11:07:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=539
06/24/2022 11:07:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=544
06/24/2022 11:07:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=549
06/24/2022 11:07:05 - INFO - __main__ - Global step 1100 Train loss 0.02 ACC 0.6875 on epoch=549
06/24/2022 11:07:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=554
06/24/2022 11:07:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=559
06/24/2022 11:07:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=564
06/24/2022 11:07:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/24/2022 11:07:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=574
06/24/2022 11:07:12 - INFO - __main__ - Global step 1150 Train loss 0.04 ACC 0.6875 on epoch=574
06/24/2022 11:07:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 11:07:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 11:07:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=589
06/24/2022 11:07:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
06/24/2022 11:07:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=599
06/24/2022 11:07:20 - INFO - __main__ - Global step 1200 Train loss 0.01 ACC 0.625 on epoch=599
06/24/2022 11:07:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=604
06/24/2022 11:07:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=609
06/24/2022 11:07:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=614
06/24/2022 11:07:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=619
06/24/2022 11:07:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=624
06/24/2022 11:07:28 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.75 on epoch=624
06/24/2022 11:07:28 - INFO - __main__ - Saving model with best ACC: 0.71875 -> 0.75 on epoch=624, global_step=1250
06/24/2022 11:07:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 11:07:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/24/2022 11:07:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 11:07:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
06/24/2022 11:07:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 11:07:37 - INFO - __main__ - Global step 1300 Train loss 0.01 ACC 0.65625 on epoch=649
06/24/2022 11:07:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/24/2022 11:07:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 11:07:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 11:07:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 11:07:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 11:07:44 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.71875 on epoch=674
06/24/2022 11:07:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 11:07:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 11:07:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 11:07:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=694
06/24/2022 11:07:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 11:07:51 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.6875 on epoch=699
06/24/2022 11:07:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 11:07:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 11:07:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=714
06/24/2022 11:07:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 11:07:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 11:07:59 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.6875 on epoch=724
06/24/2022 11:08:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 11:08:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 11:08:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 11:08:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 11:08:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 11:08:07 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.59375 on epoch=749
06/24/2022 11:08:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=754
06/24/2022 11:08:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 11:08:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 11:08:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=769
06/24/2022 11:08:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 11:08:14 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.46875 on epoch=774
06/24/2022 11:08:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=779
06/24/2022 11:08:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=784
06/24/2022 11:08:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 11:08:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 11:08:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=799
06/24/2022 11:08:22 - INFO - __main__ - Global step 1600 Train loss 0.02 ACC 0.6875 on epoch=799
06/24/2022 11:08:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=804
06/24/2022 11:08:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 11:08:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 11:08:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 11:08:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=824
06/24/2022 11:08:30 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.65625 on epoch=824
06/24/2022 11:08:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 11:08:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 11:08:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 11:08:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 11:08:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 11:08:38 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.6875 on epoch=849
06/24/2022 11:08:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/24/2022 11:08:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=859
06/24/2022 11:08:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 11:08:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 11:08:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 11:08:45 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.6875 on epoch=874
06/24/2022 11:08:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 11:08:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 11:08:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 11:08:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 11:08:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=899
06/24/2022 11:08:51 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.65625 on epoch=899
06/24/2022 11:08:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 11:08:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 11:08:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 11:08:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=919
06/24/2022 11:08:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 11:08:58 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.625 on epoch=924
06/24/2022 11:08:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 11:09:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 11:09:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 11:09:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 11:09:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 11:09:05 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/24/2022 11:09:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 11:09:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 11:09:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 11:09:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 11:09:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 11:09:12 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.65625 on epoch=974
06/24/2022 11:09:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 11:09:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 11:09:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 11:09:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 11:09:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 11:09:18 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.625 on epoch=999
06/24/2022 11:09:18 - INFO - __main__ - save last model!
06/24/2022 11:09:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 11:09:18 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 11:09:18 - INFO - __main__ - Printing 3 examples
06/24/2022 11:09:18 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 11:09:18 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:09:18 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 11:09:18 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:09:18 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 11:09:18 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:18 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:09:19 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:09:19 - INFO - __main__ - Printing 3 examples
06/24/2022 11:09:19 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 11:09:19 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:19 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 11:09:19 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:19 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 11:09:19 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:09:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:09:19 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:09:19 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:09:19 - INFO - __main__ - Printing 3 examples
06/24/2022 11:09:19 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 11:09:19 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:19 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 11:09:19 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:19 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 11:09:19 - INFO - __main__ - ['duplicate']
06/24/2022 11:09:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:09:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:09:19 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:09:25 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 11:09:25 - INFO - __main__ - task name: glue-qqp
06/24/2022 11:09:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:09:25 - INFO - __main__ - Starting training!
06/24/2022 11:09:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:10:17 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:23:14 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_42_0.4_8_predictions.txt
06/24/2022 11:23:14 - INFO - __main__ - ACC on test data: 0.6324
06/24/2022 11:23:14 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.4, bsz=8, dev_performance=0.75, test_performance=0.6324016819193669
06/24/2022 11:23:14 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.3, bsz=8 ...
06/24/2022 11:23:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:23:15 - INFO - __main__ - Printing 3 examples
06/24/2022 11:23:15 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 11:23:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:23:15 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 11:23:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:23:15 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 11:23:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:23:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:23:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:23:15 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:23:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:23:15 - INFO - __main__ - Printing 3 examples
06/24/2022 11:23:15 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 11:23:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:23:15 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 11:23:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:23:15 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 11:23:15 - INFO - __main__ - ['duplicate']
06/24/2022 11:23:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:23:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:23:15 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:23:21 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 11:23:21 - INFO - __main__ - task name: glue-qqp
06/24/2022 11:23:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:23:22 - INFO - __main__ - Starting training!
06/24/2022 11:23:23 - INFO - __main__ - Step 10 Global step 10 Train loss 6.62 on epoch=4
06/24/2022 11:23:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.37 on epoch=9
06/24/2022 11:23:26 - INFO - __main__ - Step 30 Global step 30 Train loss 1.82 on epoch=14
06/24/2022 11:23:27 - INFO - __main__ - Step 40 Global step 40 Train loss 0.88 on epoch=19
06/24/2022 11:23:28 - INFO - __main__ - Step 50 Global step 50 Train loss 0.54 on epoch=24
06/24/2022 11:23:29 - INFO - __main__ - Global step 50 Train loss 2.65 ACC 0.5 on epoch=24
06/24/2022 11:23:29 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 11:23:30 - INFO - __main__ - Step 60 Global step 60 Train loss 0.53 on epoch=29
06/24/2022 11:23:31 - INFO - __main__ - Step 70 Global step 70 Train loss 0.46 on epoch=34
06/24/2022 11:23:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.46 on epoch=39
06/24/2022 11:23:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.45 on epoch=44
06/24/2022 11:23:35 - INFO - __main__ - Step 100 Global step 100 Train loss 0.43 on epoch=49
06/24/2022 11:23:35 - INFO - __main__ - Global step 100 Train loss 0.47 ACC 0.5 on epoch=49
06/24/2022 11:23:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=54
06/24/2022 11:23:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=59
06/24/2022 11:23:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.32 on epoch=64
06/24/2022 11:23:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.37 on epoch=69
06/24/2022 11:23:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.37 on epoch=74
06/24/2022 11:23:42 - INFO - __main__ - Global step 150 Train loss 0.34 ACC 0.5 on epoch=74
06/24/2022 11:23:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.30 on epoch=79
06/24/2022 11:23:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.35 on epoch=84
06/24/2022 11:23:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.32 on epoch=89
06/24/2022 11:23:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=94
06/24/2022 11:23:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=99
06/24/2022 11:23:49 - INFO - __main__ - Global step 200 Train loss 0.33 ACC 0.5 on epoch=99
06/24/2022 11:23:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.31 on epoch=104
06/24/2022 11:23:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=109
06/24/2022 11:23:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.29 on epoch=114
06/24/2022 11:23:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 11:23:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=124
06/24/2022 11:23:56 - INFO - __main__ - Global step 250 Train loss 0.29 ACC 0.5 on epoch=124
06/24/2022 11:23:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=129
06/24/2022 11:23:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/24/2022 11:24:00 - INFO - __main__ - Step 280 Global step 280 Train loss 1.08 on epoch=139
06/24/2022 11:24:01 - INFO - __main__ - Step 290 Global step 290 Train loss 2.88 on epoch=144
06/24/2022 11:24:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=149
06/24/2022 11:24:03 - INFO - __main__ - Global step 300 Train loss 0.95 ACC 0.5 on epoch=149
06/24/2022 11:24:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=154
06/24/2022 11:24:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=159
06/24/2022 11:24:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=164
06/24/2022 11:24:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=169
06/24/2022 11:24:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=174
06/24/2022 11:24:10 - INFO - __main__ - Global step 350 Train loss 0.28 ACC 0.5 on epoch=174
06/24/2022 11:24:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 11:24:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=184
06/24/2022 11:24:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=189
06/24/2022 11:24:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=194
06/24/2022 11:24:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=199
06/24/2022 11:24:16 - INFO - __main__ - Global step 400 Train loss 0.26 ACC 0.5 on epoch=199
06/24/2022 11:24:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=204
06/24/2022 11:24:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=209
06/24/2022 11:24:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=214
06/24/2022 11:24:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=219
06/24/2022 11:24:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=224
06/24/2022 11:24:23 - INFO - __main__ - Global step 450 Train loss 0.27 ACC 0.5 on epoch=224
06/24/2022 11:24:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=229
06/24/2022 11:24:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=234
06/24/2022 11:24:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=239
06/24/2022 11:24:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=244
06/24/2022 11:24:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=249
06/24/2022 11:24:30 - INFO - __main__ - Global step 500 Train loss 0.27 ACC 0.46875 on epoch=249
06/24/2022 11:24:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=254
06/24/2022 11:24:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=259
06/24/2022 11:24:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=264
06/24/2022 11:24:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=269
06/24/2022 11:24:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=274
06/24/2022 11:24:37 - INFO - __main__ - Global step 550 Train loss 0.26 ACC 0.5 on epoch=274
06/24/2022 11:24:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=279
06/24/2022 11:24:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=284
06/24/2022 11:24:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=289
06/24/2022 11:24:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=294
06/24/2022 11:24:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=299
06/24/2022 11:24:43 - INFO - __main__ - Global step 600 Train loss 0.26 ACC 0.5 on epoch=299
06/24/2022 11:24:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=304
06/24/2022 11:24:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=309
06/24/2022 11:24:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=314
06/24/2022 11:24:48 - INFO - __main__ - Step 640 Global step 640 Train loss 1.77 on epoch=319
06/24/2022 11:24:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.98 on epoch=324
06/24/2022 11:24:50 - INFO - __main__ - Global step 650 Train loss 0.71 ACC 0.5 on epoch=324
06/24/2022 11:24:51 - INFO - __main__ - Step 660 Global step 660 Train loss 2.23 on epoch=329
06/24/2022 11:24:53 - INFO - __main__ - Step 670 Global step 670 Train loss 3.06 on epoch=334
06/24/2022 11:24:54 - INFO - __main__ - Step 680 Global step 680 Train loss 4.21 on epoch=339
06/24/2022 11:24:55 - INFO - __main__ - Step 690 Global step 690 Train loss 4.60 on epoch=344
06/24/2022 11:24:56 - INFO - __main__ - Step 700 Global step 700 Train loss 4.62 on epoch=349
06/24/2022 11:24:57 - INFO - __main__ - Global step 700 Train loss 3.74 ACC 0.4375 on epoch=349
06/24/2022 11:24:58 - INFO - __main__ - Step 710 Global step 710 Train loss 3.92 on epoch=354
06/24/2022 11:25:00 - INFO - __main__ - Step 720 Global step 720 Train loss 4.42 on epoch=359
06/24/2022 11:25:01 - INFO - __main__ - Step 730 Global step 730 Train loss 4.18 on epoch=364
06/24/2022 11:25:02 - INFO - __main__ - Step 740 Global step 740 Train loss 4.24 on epoch=369
06/24/2022 11:25:03 - INFO - __main__ - Step 750 Global step 750 Train loss 3.92 on epoch=374
06/24/2022 11:25:04 - INFO - __main__ - Global step 750 Train loss 4.14 ACC 0.46875 on epoch=374
06/24/2022 11:25:05 - INFO - __main__ - Step 760 Global step 760 Train loss 3.13 on epoch=379
06/24/2022 11:25:07 - INFO - __main__ - Step 770 Global step 770 Train loss 4.24 on epoch=384
06/24/2022 11:25:08 - INFO - __main__ - Step 780 Global step 780 Train loss 4.13 on epoch=389
06/24/2022 11:25:09 - INFO - __main__ - Step 790 Global step 790 Train loss 4.55 on epoch=394
06/24/2022 11:25:10 - INFO - __main__ - Step 800 Global step 800 Train loss 5.34 on epoch=399
06/24/2022 11:25:12 - INFO - __main__ - Global step 800 Train loss 4.28 ACC 0.0 on epoch=399
06/24/2022 11:25:13 - INFO - __main__ - Step 810 Global step 810 Train loss 5.50 on epoch=404
06/24/2022 11:25:14 - INFO - __main__ - Step 820 Global step 820 Train loss 5.20 on epoch=409
06/24/2022 11:25:16 - INFO - __main__ - Step 830 Global step 830 Train loss 5.43 on epoch=414
06/24/2022 11:25:17 - INFO - __main__ - Step 840 Global step 840 Train loss 5.50 on epoch=419
06/24/2022 11:25:18 - INFO - __main__ - Step 850 Global step 850 Train loss 5.67 on epoch=424
06/24/2022 11:25:24 - INFO - __main__ - Global step 850 Train loss 5.46 ACC 0.0 on epoch=424
06/24/2022 11:25:26 - INFO - __main__ - Step 860 Global step 860 Train loss 5.58 on epoch=429
06/24/2022 11:25:27 - INFO - __main__ - Step 870 Global step 870 Train loss 5.39 on epoch=434
06/24/2022 11:25:28 - INFO - __main__ - Step 880 Global step 880 Train loss 5.23 on epoch=439
06/24/2022 11:25:29 - INFO - __main__ - Step 890 Global step 890 Train loss 5.35 on epoch=444
06/24/2022 11:25:30 - INFO - __main__ - Step 900 Global step 900 Train loss 5.36 on epoch=449
06/24/2022 11:25:32 - INFO - __main__ - Global step 900 Train loss 5.38 ACC 0.0 on epoch=449
06/24/2022 11:25:33 - INFO - __main__ - Step 910 Global step 910 Train loss 5.49 on epoch=454
06/24/2022 11:25:34 - INFO - __main__ - Step 920 Global step 920 Train loss 5.55 on epoch=459
06/24/2022 11:25:36 - INFO - __main__ - Step 930 Global step 930 Train loss 5.66 on epoch=464
06/24/2022 11:25:37 - INFO - __main__ - Step 940 Global step 940 Train loss 5.88 on epoch=469
06/24/2022 11:25:38 - INFO - __main__ - Step 950 Global step 950 Train loss 5.85 on epoch=474
06/24/2022 11:25:40 - INFO - __main__ - Global step 950 Train loss 5.68 ACC 0.0 on epoch=474
06/24/2022 11:25:41 - INFO - __main__ - Step 960 Global step 960 Train loss 5.46 on epoch=479
06/24/2022 11:25:42 - INFO - __main__ - Step 970 Global step 970 Train loss 5.73 on epoch=484
06/24/2022 11:25:43 - INFO - __main__ - Step 980 Global step 980 Train loss 5.50 on epoch=489
06/24/2022 11:25:45 - INFO - __main__ - Step 990 Global step 990 Train loss 5.59 on epoch=494
06/24/2022 11:25:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 5.50 on epoch=499
06/24/2022 11:25:48 - INFO - __main__ - Global step 1000 Train loss 5.55 ACC 0.0 on epoch=499
06/24/2022 11:25:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 5.11 on epoch=504
06/24/2022 11:25:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 5.30 on epoch=509
06/24/2022 11:25:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 5.32 on epoch=514
06/24/2022 11:25:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 5.31 on epoch=519
06/24/2022 11:25:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 5.26 on epoch=524
06/24/2022 11:25:56 - INFO - __main__ - Global step 1050 Train loss 5.26 ACC 0.0 on epoch=524
06/24/2022 11:25:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 5.22 on epoch=529
06/24/2022 11:25:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 5.25 on epoch=534
06/24/2022 11:26:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.94 on epoch=539
06/24/2022 11:26:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.79 on epoch=544
06/24/2022 11:26:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.90 on epoch=549
06/24/2022 11:26:08 - INFO - __main__ - Global step 1100 Train loss 5.02 ACC 0.0 on epoch=549
06/24/2022 11:26:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 5.19 on epoch=554
06/24/2022 11:26:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 5.08 on epoch=559
06/24/2022 11:26:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.86 on epoch=564
06/24/2022 11:26:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.68 on epoch=569
06/24/2022 11:26:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.49 on epoch=574
06/24/2022 11:26:20 - INFO - __main__ - Global step 1150 Train loss 4.86 ACC 0.0 on epoch=574
06/24/2022 11:26:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.88 on epoch=579
06/24/2022 11:26:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.74 on epoch=584
06/24/2022 11:26:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.64 on epoch=589
06/24/2022 11:26:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.79 on epoch=594
06/24/2022 11:26:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.54 on epoch=599
06/24/2022 11:26:27 - INFO - __main__ - Global step 1200 Train loss 4.72 ACC 0.0 on epoch=599
06/24/2022 11:26:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.51 on epoch=604
06/24/2022 11:26:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.47 on epoch=609
06/24/2022 11:26:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.56 on epoch=614
06/24/2022 11:26:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.43 on epoch=619
06/24/2022 11:26:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.79 on epoch=624
06/24/2022 11:26:35 - INFO - __main__ - Global step 1250 Train loss 4.55 ACC 0.0 on epoch=624
06/24/2022 11:26:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.40 on epoch=629
06/24/2022 11:26:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.48 on epoch=634
06/24/2022 11:26:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.67 on epoch=639
06/24/2022 11:26:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.57 on epoch=644
06/24/2022 11:26:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 4.40 on epoch=649
06/24/2022 11:26:43 - INFO - __main__ - Global step 1300 Train loss 4.50 ACC 0.0 on epoch=649
06/24/2022 11:26:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.48 on epoch=654
06/24/2022 11:26:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.44 on epoch=659
06/24/2022 11:26:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 4.53 on epoch=664
06/24/2022 11:26:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.53 on epoch=669
06/24/2022 11:26:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 4.66 on epoch=674
06/24/2022 11:26:51 - INFO - __main__ - Global step 1350 Train loss 4.53 ACC 0.0 on epoch=674
06/24/2022 11:26:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 4.51 on epoch=679
06/24/2022 11:26:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 4.48 on epoch=684
06/24/2022 11:26:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 4.26 on epoch=689
06/24/2022 11:26:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 4.27 on epoch=694
06/24/2022 11:26:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 4.59 on epoch=699
06/24/2022 11:27:03 - INFO - __main__ - Global step 1400 Train loss 4.42 ACC 0.0 on epoch=699
06/24/2022 11:27:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 4.25 on epoch=704
06/24/2022 11:27:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 4.35 on epoch=709
06/24/2022 11:27:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 4.22 on epoch=714
06/24/2022 11:27:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 4.16 on epoch=719
06/24/2022 11:27:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.97 on epoch=724
06/24/2022 11:27:09 - INFO - __main__ - Global step 1450 Train loss 4.19 ACC 0.0 on epoch=724
06/24/2022 11:27:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.96 on epoch=729
06/24/2022 11:27:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.91 on epoch=734
06/24/2022 11:27:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.81 on epoch=739
06/24/2022 11:27:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.80 on epoch=744
06/24/2022 11:27:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.89 on epoch=749
06/24/2022 11:27:17 - INFO - __main__ - Global step 1500 Train loss 3.87 ACC 0.0 on epoch=749
06/24/2022 11:27:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.76 on epoch=754
06/24/2022 11:27:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.76 on epoch=759
06/24/2022 11:27:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.80 on epoch=764
06/24/2022 11:27:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.77 on epoch=769
06/24/2022 11:27:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.71 on epoch=774
06/24/2022 11:27:24 - INFO - __main__ - Global step 1550 Train loss 3.76 ACC 0.0 on epoch=774
06/24/2022 11:27:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.61 on epoch=779
06/24/2022 11:27:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.67 on epoch=784
06/24/2022 11:27:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.71 on epoch=789
06/24/2022 11:27:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.75 on epoch=794
06/24/2022 11:27:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.69 on epoch=799
06/24/2022 11:27:31 - INFO - __main__ - Global step 1600 Train loss 3.69 ACC 0.0 on epoch=799
06/24/2022 11:27:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.57 on epoch=804
06/24/2022 11:27:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.69 on epoch=809
06/24/2022 11:27:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.63 on epoch=814
06/24/2022 11:27:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.74 on epoch=819
06/24/2022 11:27:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.60 on epoch=824
06/24/2022 11:27:38 - INFO - __main__ - Global step 1650 Train loss 3.64 ACC 0.0 on epoch=824
06/24/2022 11:27:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.72 on epoch=829
06/24/2022 11:27:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.56 on epoch=834
06/24/2022 11:27:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.62 on epoch=839
06/24/2022 11:27:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.66 on epoch=844
06/24/2022 11:27:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.68 on epoch=849
06/24/2022 11:27:45 - INFO - __main__ - Global step 1700 Train loss 3.65 ACC 0.03125 on epoch=849
06/24/2022 11:27:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.79 on epoch=854
06/24/2022 11:27:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.69 on epoch=859
06/24/2022 11:27:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.63 on epoch=864
06/24/2022 11:27:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.64 on epoch=869
06/24/2022 11:27:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.38 on epoch=874
06/24/2022 11:27:52 - INFO - __main__ - Global step 1750 Train loss 3.63 ACC 0.0625 on epoch=874
06/24/2022 11:27:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.51 on epoch=879
06/24/2022 11:27:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.43 on epoch=884
06/24/2022 11:27:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.38 on epoch=889
06/24/2022 11:27:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.36 on epoch=894
06/24/2022 11:27:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.50 on epoch=899
06/24/2022 11:27:59 - INFO - __main__ - Global step 1800 Train loss 3.44 ACC 0.25 on epoch=899
06/24/2022 11:28:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.31 on epoch=904
06/24/2022 11:28:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.27 on epoch=909
06/24/2022 11:28:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.27 on epoch=914
06/24/2022 11:28:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.32 on epoch=919
06/24/2022 11:28:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.29 on epoch=924
06/24/2022 11:28:06 - INFO - __main__ - Global step 1850 Train loss 3.29 ACC 0.125 on epoch=924
06/24/2022 11:28:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.28 on epoch=929
06/24/2022 11:28:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.36 on epoch=934
06/24/2022 11:28:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.36 on epoch=939
06/24/2022 11:28:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=944
06/24/2022 11:28:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.31 on epoch=949
06/24/2022 11:28:13 - INFO - __main__ - Global step 1900 Train loss 3.33 ACC 0.0 on epoch=949
06/24/2022 11:28:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.26 on epoch=954
06/24/2022 11:28:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.16 on epoch=959
06/24/2022 11:28:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.10 on epoch=964
06/24/2022 11:28:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.97 on epoch=969
06/24/2022 11:28:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.97 on epoch=974
06/24/2022 11:28:21 - INFO - __main__ - Global step 1950 Train loss 3.09 ACC 0.09375 on epoch=974
06/24/2022 11:28:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.05 on epoch=979
06/24/2022 11:28:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.92 on epoch=984
06/24/2022 11:28:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.07 on epoch=989
06/24/2022 11:28:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.98 on epoch=994
06/24/2022 11:28:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.00 on epoch=999
06/24/2022 11:28:27 - INFO - __main__ - Global step 2000 Train loss 3.00 ACC 0.34375 on epoch=999
06/24/2022 11:28:27 - INFO - __main__ - save last model!
06/24/2022 11:28:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 11:28:28 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 11:28:28 - INFO - __main__ - Printing 3 examples
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 11:28:28 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 11:28:28 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:28:28 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:28:28 - INFO - __main__ - Printing 3 examples
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:28:28 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:28:28 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:28:28 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:28:28 - INFO - __main__ - Printing 3 examples
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 11:28:28 - INFO - __main__ - ['duplicate']
06/24/2022 11:28:28 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:28:28 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:28:28 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:28:33 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 11:28:33 - INFO - __main__ - task name: glue-qqp
06/24/2022 11:28:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:28:34 - INFO - __main__ - Starting training!
06/24/2022 11:28:46 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:29:26 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 11:44:54 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_42_0.3_8_predictions.txt
06/24/2022 11:44:54 - INFO - __main__ - ACC on test data: 0.2881
06/24/2022 11:44:54 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.3, bsz=8, dev_performance=0.5, test_performance=0.28805342567400444
06/24/2022 11:44:54 - INFO - __main__ - Running ... prefix=glue-qqp_16_42, lr=0.2, bsz=8 ...
06/24/2022 11:44:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:44:55 - INFO - __main__ - Printing 3 examples
06/24/2022 11:44:55 - INFO - __main__ -  [glue-qqp] question 1: Why do some people think that having a baby is a blessing? [SEP] question 2: Why is having a baby a blessing?
06/24/2022 11:44:55 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:55 - INFO - __main__ -  [glue-qqp] question 1: Why don't I get answers for some of my questions on Quora? [SEP] question 2: Why do some questions get more answers here in Quora?
06/24/2022 11:44:55 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:55 - INFO - __main__ -  [glue-qqp] question 1: Which is the best and free small business accounting software for my business? [SEP] question 2: Which is the best free accounting software for a small firm?
06/24/2022 11:44:55 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:55 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:44:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:44:55 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:44:55 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:44:55 - INFO - __main__ - Printing 3 examples
06/24/2022 11:44:55 - INFO - __main__ -  [glue-qqp] question 1: Have you heard about the Delta Charting Group out of Tucson, Arizona? [SEP] question 2: What are the good things about Delta Charting Group out of Tucson, Arizona?
06/24/2022 11:44:55 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:55 - INFO - __main__ -  [glue-qqp] question 1: How many mark should a student obtain in JEE to get a seat in IIST? [SEP] question 2: How many marks are required in JEE to get in IIST?
06/24/2022 11:44:55 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:55 - INFO - __main__ -  [glue-qqp] question 1: Why do people ask questions whose answer can be easily found on the internet? [SEP] question 2: Why do people ask basic questions instead of searching them?
06/24/2022 11:44:55 - INFO - __main__ - ['duplicate']
06/24/2022 11:44:55 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:44:55 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:44:55 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:45:01 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 11:45:01 - INFO - __main__ - task name: glue-qqp
06/24/2022 11:45:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:45:02 - INFO - __main__ - Starting training!
06/24/2022 11:45:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.69 on epoch=4
06/24/2022 11:45:04 - INFO - __main__ - Step 20 Global step 20 Train loss 3.94 on epoch=9
06/24/2022 11:45:06 - INFO - __main__ - Step 30 Global step 30 Train loss 1.89 on epoch=14
06/24/2022 11:45:07 - INFO - __main__ - Step 40 Global step 40 Train loss 1.05 on epoch=19
06/24/2022 11:45:08 - INFO - __main__ - Step 50 Global step 50 Train loss 0.66 on epoch=24
06/24/2022 11:45:09 - INFO - __main__ - Global step 50 Train loss 2.85 ACC 0.5 on epoch=24
06/24/2022 11:45:09 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 11:45:10 - INFO - __main__ - Step 60 Global step 60 Train loss 0.63 on epoch=29
06/24/2022 11:45:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.52 on epoch=34
06/24/2022 11:45:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.55 on epoch=39
06/24/2022 11:45:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.65 on epoch=44
06/24/2022 11:45:15 - INFO - __main__ - Step 100 Global step 100 Train loss 0.54 on epoch=49
06/24/2022 11:45:16 - INFO - __main__ - Global step 100 Train loss 0.58 ACC 0.5 on epoch=49
06/24/2022 11:45:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
06/24/2022 11:45:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.43 on epoch=59
06/24/2022 11:45:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.50 on epoch=64
06/24/2022 11:45:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.41 on epoch=69
06/24/2022 11:45:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.42 on epoch=74
06/24/2022 11:45:23 - INFO - __main__ - Global step 150 Train loss 0.43 ACC 0.5 on epoch=74
06/24/2022 11:45:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.35 on epoch=79
06/24/2022 11:45:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/24/2022 11:45:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=89
06/24/2022 11:45:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.38 on epoch=94
06/24/2022 11:45:29 - INFO - __main__ - Step 200 Global step 200 Train loss 0.34 on epoch=99
06/24/2022 11:45:30 - INFO - __main__ - Global step 200 Train loss 0.36 ACC 0.5 on epoch=99
06/24/2022 11:45:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=104
06/24/2022 11:45:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=109
06/24/2022 11:45:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=114
06/24/2022 11:45:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.34 on epoch=119
06/24/2022 11:45:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=124
06/24/2022 11:45:37 - INFO - __main__ - Global step 250 Train loss 0.32 ACC 0.46875 on epoch=124
06/24/2022 11:45:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/24/2022 11:45:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=134
06/24/2022 11:45:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=139
06/24/2022 11:45:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 11:45:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=149
06/24/2022 11:45:44 - INFO - __main__ - Global step 300 Train loss 0.29 ACC 0.5 on epoch=149
06/24/2022 11:45:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=154
06/24/2022 11:45:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=159
06/24/2022 11:45:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=164
06/24/2022 11:45:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=169
06/24/2022 11:45:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=174
06/24/2022 11:45:51 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.5 on epoch=174
06/24/2022 11:45:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 11:45:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=184
06/24/2022 11:45:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 11:45:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=194
06/24/2022 11:45:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=199
06/24/2022 11:45:58 - INFO - __main__ - Global step 400 Train loss 0.27 ACC 0.5 on epoch=199
06/24/2022 11:46:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=204
06/24/2022 11:46:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=209
06/24/2022 11:46:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=214
06/24/2022 11:46:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=219
06/24/2022 11:46:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=224
06/24/2022 11:46:05 - INFO - __main__ - Global step 450 Train loss 0.26 ACC 0.5 on epoch=224
06/24/2022 11:46:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=229
06/24/2022 11:46:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=234
06/24/2022 11:46:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=239
06/24/2022 11:46:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=244
06/24/2022 11:46:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=249
06/24/2022 11:46:13 - INFO - __main__ - Global step 500 Train loss 0.28 ACC 0.5 on epoch=249
06/24/2022 11:46:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=254
06/24/2022 11:46:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=259
06/24/2022 11:46:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=264
06/24/2022 11:46:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=269
06/24/2022 11:46:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=274
06/24/2022 11:46:20 - INFO - __main__ - Global step 550 Train loss 0.34 ACC 0.5 on epoch=274
06/24/2022 11:46:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=279
06/24/2022 11:46:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=284
06/24/2022 11:46:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=289
06/24/2022 11:46:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=294
06/24/2022 11:46:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=299
06/24/2022 11:46:27 - INFO - __main__ - Global step 600 Train loss 0.27 ACC 0.5 on epoch=299
06/24/2022 11:46:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=304
06/24/2022 11:46:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=309
06/24/2022 11:46:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=314
06/24/2022 11:46:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=319
06/24/2022 11:46:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=324
06/24/2022 11:46:34 - INFO - __main__ - Global step 650 Train loss 0.26 ACC 0.53125 on epoch=324
06/24/2022 11:46:34 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=324, global_step=650
06/24/2022 11:46:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=329
06/24/2022 11:46:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=334
06/24/2022 11:46:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=339
06/24/2022 11:46:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=344
06/24/2022 11:46:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=349
06/24/2022 11:46:41 - INFO - __main__ - Global step 700 Train loss 0.28 ACC 0.53125 on epoch=349
06/24/2022 11:46:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=354
06/24/2022 11:46:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=359
06/24/2022 11:46:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=364
06/24/2022 11:46:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=369
06/24/2022 11:46:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=374
06/24/2022 11:46:48 - INFO - __main__ - Global step 750 Train loss 0.25 ACC 0.5 on epoch=374
06/24/2022 11:46:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=379
06/24/2022 11:46:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.30 on epoch=384
06/24/2022 11:46:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=389
06/24/2022 11:46:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=394
06/24/2022 11:46:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=399
06/24/2022 11:46:55 - INFO - __main__ - Global step 800 Train loss 0.28 ACC 0.5 on epoch=399
06/24/2022 11:46:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=404
06/24/2022 11:46:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=409
06/24/2022 11:46:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=414
06/24/2022 11:47:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=419
06/24/2022 11:47:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=424
06/24/2022 11:47:02 - INFO - __main__ - Global step 850 Train loss 0.25 ACC 0.53125 on epoch=424
06/24/2022 11:47:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=429
06/24/2022 11:47:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=434
06/24/2022 11:47:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=439
06/24/2022 11:47:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=444
06/24/2022 11:47:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=449
06/24/2022 11:47:09 - INFO - __main__ - Global step 900 Train loss 0.23 ACC 0.5 on epoch=449
06/24/2022 11:47:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=454
06/24/2022 11:47:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.24 on epoch=459
06/24/2022 11:47:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=464
06/24/2022 11:47:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=469
06/24/2022 11:47:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=474
06/24/2022 11:47:16 - INFO - __main__ - Global step 950 Train loss 0.26 ACC 0.53125 on epoch=474
06/24/2022 11:47:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=479
06/24/2022 11:47:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=484
06/24/2022 11:47:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=489
06/24/2022 11:47:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=494
06/24/2022 11:47:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=499
06/24/2022 11:47:23 - INFO - __main__ - Global step 1000 Train loss 0.24 ACC 0.5 on epoch=499
06/24/2022 11:47:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=504
06/24/2022 11:47:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.26 on epoch=509
06/24/2022 11:47:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=514
06/24/2022 11:47:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=519
06/24/2022 11:47:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=524
06/24/2022 11:47:30 - INFO - __main__ - Global step 1050 Train loss 0.23 ACC 0.5 on epoch=524
06/24/2022 11:47:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=529
06/24/2022 11:47:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.25 on epoch=534
06/24/2022 11:47:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=539
06/24/2022 11:47:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=544
06/24/2022 11:47:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=549
06/24/2022 11:47:37 - INFO - __main__ - Global step 1100 Train loss 0.22 ACC 0.5 on epoch=549
06/24/2022 11:47:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=554
06/24/2022 11:47:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=559
06/24/2022 11:47:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=564
06/24/2022 11:47:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=569
06/24/2022 11:47:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=574
06/24/2022 11:47:44 - INFO - __main__ - Global step 1150 Train loss 0.23 ACC 0.5 on epoch=574
06/24/2022 11:47:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=579
06/24/2022 11:47:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=584
06/24/2022 11:47:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=589
06/24/2022 11:47:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=594
06/24/2022 11:47:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=599
06/24/2022 11:47:51 - INFO - __main__ - Global step 1200 Train loss 0.20 ACC 0.5 on epoch=599
06/24/2022 11:47:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.19 on epoch=604
06/24/2022 11:47:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=609
06/24/2022 11:47:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=614
06/24/2022 11:47:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=619
06/24/2022 11:47:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=624
06/24/2022 11:47:57 - INFO - __main__ - Global step 1250 Train loss 0.19 ACC 0.46875 on epoch=624
06/24/2022 11:47:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=629
06/24/2022 11:48:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=634
06/24/2022 11:48:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=639
06/24/2022 11:48:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=644
06/24/2022 11:48:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=649
06/24/2022 11:48:05 - INFO - __main__ - Global step 1300 Train loss 0.20 ACC 0.53125 on epoch=649
06/24/2022 11:48:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=654
06/24/2022 11:48:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=659
06/24/2022 11:48:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=664
06/24/2022 11:48:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=669
06/24/2022 11:48:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=674
06/24/2022 11:48:11 - INFO - __main__ - Global step 1350 Train loss 0.15 ACC 0.5 on epoch=674
06/24/2022 11:48:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=679
06/24/2022 11:48:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=684
06/24/2022 11:48:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=689
06/24/2022 11:48:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=694
06/24/2022 11:48:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=699
06/24/2022 11:48:19 - INFO - __main__ - Global step 1400 Train loss 0.12 ACC 0.5 on epoch=699
06/24/2022 11:48:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=704
06/24/2022 11:48:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=709
06/24/2022 11:48:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=714
06/24/2022 11:48:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.22 on epoch=719
06/24/2022 11:48:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=724
06/24/2022 11:48:26 - INFO - __main__ - Global step 1450 Train loss 0.17 ACC 0.53125 on epoch=724
06/24/2022 11:48:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=729
06/24/2022 11:48:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=734
06/24/2022 11:48:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=739
06/24/2022 11:48:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=744
06/24/2022 11:48:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=749
06/24/2022 11:48:33 - INFO - __main__ - Global step 1500 Train loss 0.13 ACC 0.53125 on epoch=749
06/24/2022 11:48:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=754
06/24/2022 11:48:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=759
06/24/2022 11:48:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=764
06/24/2022 11:48:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=769
06/24/2022 11:48:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=774
06/24/2022 11:48:40 - INFO - __main__ - Global step 1550 Train loss 0.09 ACC 0.5625 on epoch=774
06/24/2022 11:48:40 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=774, global_step=1550
06/24/2022 11:48:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=779
06/24/2022 11:48:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=784
06/24/2022 11:48:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=789
06/24/2022 11:48:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=794
06/24/2022 11:48:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=799
06/24/2022 11:48:47 - INFO - __main__ - Global step 1600 Train loss 0.07 ACC 0.53125 on epoch=799
06/24/2022 11:48:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=804
06/24/2022 11:48:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=809
06/24/2022 11:48:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.17 on epoch=814
06/24/2022 11:48:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=819
06/24/2022 11:48:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=824
06/24/2022 11:48:54 - INFO - __main__ - Global step 1650 Train loss 0.08 ACC 0.53125 on epoch=824
06/24/2022 11:48:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=829
06/24/2022 11:48:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=834
06/24/2022 11:48:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=839
06/24/2022 11:48:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=844
06/24/2022 11:49:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/24/2022 11:49:01 - INFO - __main__ - Global step 1700 Train loss 0.05 ACC 0.5625 on epoch=849
06/24/2022 11:49:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=854
06/24/2022 11:49:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=859
06/24/2022 11:49:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=864
06/24/2022 11:49:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=869
06/24/2022 11:49:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=874
06/24/2022 11:49:08 - INFO - __main__ - Global step 1750 Train loss 0.05 ACC 0.5625 on epoch=874
06/24/2022 11:49:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=879
06/24/2022 11:49:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=884
06/24/2022 11:49:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 11:49:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=894
06/24/2022 11:49:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=899
06/24/2022 11:49:15 - INFO - __main__ - Global step 1800 Train loss 0.05 ACC 0.53125 on epoch=899
06/24/2022 11:49:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=904
06/24/2022 11:49:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=909
06/24/2022 11:49:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=914
06/24/2022 11:49:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=919
06/24/2022 11:49:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=924
06/24/2022 11:49:22 - INFO - __main__ - Global step 1850 Train loss 0.04 ACC 0.5625 on epoch=924
06/24/2022 11:49:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=929
06/24/2022 11:49:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=934
06/24/2022 11:49:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=939
06/24/2022 11:49:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 11:49:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=949
06/24/2022 11:49:29 - INFO - __main__ - Global step 1900 Train loss 0.03 ACC 0.59375 on epoch=949
06/24/2022 11:49:29 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=949, global_step=1900
06/24/2022 11:49:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=954
06/24/2022 11:49:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=959
06/24/2022 11:49:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=964
06/24/2022 11:49:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=969
06/24/2022 11:49:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=974
06/24/2022 11:49:36 - INFO - __main__ - Global step 1950 Train loss 0.05 ACC 0.5625 on epoch=974
06/24/2022 11:49:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=979
06/24/2022 11:49:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=984
06/24/2022 11:49:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=989
06/24/2022 11:49:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=994
06/24/2022 11:49:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=999
06/24/2022 11:49:44 - INFO - __main__ - Global step 2000 Train loss 0.03 ACC 0.5625 on epoch=999
06/24/2022 11:49:44 - INFO - __main__ - save last model!
06/24/2022 11:49:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 11:49:44 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 11:49:44 - INFO - __main__ - Printing 3 examples
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 11:49:44 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 11:49:44 - INFO - __main__ - ['not_duplicate']
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:49:44 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:49:44 - INFO - __main__ - Printing 3 examples
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:49:44 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:49:44 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 11:49:44 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 11:49:44 - INFO - __main__ - Printing 3 examples
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 11:49:44 - INFO - __main__ - ['duplicate']
06/24/2022 11:49:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 11:49:44 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:49:44 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 11:49:50 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 11:49:50 - INFO - __main__ - task name: glue-qqp
06/24/2022 11:49:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 11:49:51 - INFO - __main__ - Starting training!
06/24/2022 11:50:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 11:50:43 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 12:08:56 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_42_0.2_8_predictions.txt
06/24/2022 12:08:56 - INFO - __main__ - ACC on test data: 0.4716
06/24/2022 12:08:57 - INFO - __main__ - prefix=glue-qqp_16_42, lr=0.2, bsz=8, dev_performance=0.59375, test_performance=0.47155577541429633
06/24/2022 12:08:57 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.5, bsz=8 ...
06/24/2022 12:08:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:08:58 - INFO - __main__ - Printing 3 examples
06/24/2022 12:08:58 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:08:58 - INFO - __main__ - ['duplicate']
06/24/2022 12:08:58 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:08:58 - INFO - __main__ - ['duplicate']
06/24/2022 12:08:58 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:08:58 - INFO - __main__ - ['duplicate']
06/24/2022 12:08:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:08:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:08:58 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:08:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:08:58 - INFO - __main__ - Printing 3 examples
06/24/2022 12:08:58 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:08:58 - INFO - __main__ - ['duplicate']
06/24/2022 12:08:58 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:08:58 - INFO - __main__ - ['duplicate']
06/24/2022 12:08:58 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:08:58 - INFO - __main__ - ['duplicate']
06/24/2022 12:08:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:08:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:08:58 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:09:04 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 12:09:04 - INFO - __main__ - task name: glue-qqp
06/24/2022 12:09:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:09:04 - INFO - __main__ - Starting training!
06/24/2022 12:09:05 - INFO - __main__ - Step 10 Global step 10 Train loss 5.24 on epoch=4
06/24/2022 12:09:07 - INFO - __main__ - Step 20 Global step 20 Train loss 1.23 on epoch=9
06/24/2022 12:09:08 - INFO - __main__ - Step 30 Global step 30 Train loss 0.59 on epoch=14
06/24/2022 12:09:09 - INFO - __main__ - Step 40 Global step 40 Train loss 0.47 on epoch=19
06/24/2022 12:09:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.42 on epoch=24
06/24/2022 12:09:11 - INFO - __main__ - Global step 50 Train loss 1.59 ACC 0.5 on epoch=24
06/24/2022 12:09:11 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 12:09:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.39 on epoch=29
06/24/2022 12:09:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=34
06/24/2022 12:09:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=39
06/24/2022 12:09:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.37 on epoch=44
06/24/2022 12:09:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.26 on epoch=49
06/24/2022 12:09:18 - INFO - __main__ - Global step 100 Train loss 0.36 ACC 0.5 on epoch=49
06/24/2022 12:09:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.30 on epoch=54
06/24/2022 12:09:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.38 on epoch=59
06/24/2022 12:09:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=64
06/24/2022 12:09:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=69
06/24/2022 12:09:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.36 on epoch=74
06/24/2022 12:09:25 - INFO - __main__ - Global step 150 Train loss 0.32 ACC 0.5 on epoch=74
06/24/2022 12:09:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=79
06/24/2022 12:09:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=84
06/24/2022 12:09:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.33 on epoch=89
06/24/2022 12:09:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=94
06/24/2022 12:09:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=99
06/24/2022 12:09:31 - INFO - __main__ - Global step 200 Train loss 0.29 ACC 0.53125 on epoch=99
06/24/2022 12:09:31 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=99, global_step=200
06/24/2022 12:09:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.32 on epoch=104
06/24/2022 12:09:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=109
06/24/2022 12:09:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=114
06/24/2022 12:09:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=119
06/24/2022 12:09:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=124
06/24/2022 12:09:38 - INFO - __main__ - Global step 250 Train loss 0.29 ACC 0.5 on epoch=124
06/24/2022 12:09:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=129
06/24/2022 12:09:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=134
06/24/2022 12:09:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=139
06/24/2022 12:09:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=144
06/24/2022 12:09:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=149
06/24/2022 12:09:45 - INFO - __main__ - Global step 300 Train loss 0.26 ACC 0.5 on epoch=149
06/24/2022 12:09:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=154
06/24/2022 12:09:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=159
06/24/2022 12:09:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=164
06/24/2022 12:09:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=169
06/24/2022 12:09:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=174
06/24/2022 12:09:52 - INFO - __main__ - Global step 350 Train loss 0.28 ACC 0.5 on epoch=174
06/24/2022 12:09:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=179
06/24/2022 12:09:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=184
06/24/2022 12:09:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 12:09:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=194
06/24/2022 12:09:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=199
06/24/2022 12:09:59 - INFO - __main__ - Global step 400 Train loss 0.26 ACC 0.53125 on epoch=199
06/24/2022 12:10:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=204
06/24/2022 12:10:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=209
06/24/2022 12:10:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=214
06/24/2022 12:10:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=219
06/24/2022 12:10:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=224
06/24/2022 12:10:05 - INFO - __main__ - Global step 450 Train loss 0.25 ACC 0.5 on epoch=224
06/24/2022 12:10:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=229
06/24/2022 12:10:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=234
06/24/2022 12:10:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=239
06/24/2022 12:10:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=244
06/24/2022 12:10:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=249
06/24/2022 12:10:12 - INFO - __main__ - Global step 500 Train loss 0.22 ACC 0.53125 on epoch=249
06/24/2022 12:10:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=254
06/24/2022 12:10:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=259
06/24/2022 12:10:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=264
06/24/2022 12:10:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=269
06/24/2022 12:10:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=274
06/24/2022 12:10:19 - INFO - __main__ - Global step 550 Train loss 0.23 ACC 0.5 on epoch=274
06/24/2022 12:10:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=279
06/24/2022 12:10:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=284
06/24/2022 12:10:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=289
06/24/2022 12:10:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=294
06/24/2022 12:10:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=299
06/24/2022 12:10:26 - INFO - __main__ - Global step 600 Train loss 0.21 ACC 0.5 on epoch=299
06/24/2022 12:10:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=304
06/24/2022 12:10:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=309
06/24/2022 12:10:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=314
06/24/2022 12:10:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=319
06/24/2022 12:10:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=324
06/24/2022 12:10:32 - INFO - __main__ - Global step 650 Train loss 0.19 ACC 0.5 on epoch=324
06/24/2022 12:10:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=329
06/24/2022 12:10:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=334
06/24/2022 12:10:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=339
06/24/2022 12:10:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=344
06/24/2022 12:10:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=349
06/24/2022 12:10:39 - INFO - __main__ - Global step 700 Train loss 0.15 ACC 0.625 on epoch=349
06/24/2022 12:10:39 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.625 on epoch=349, global_step=700
06/24/2022 12:10:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=354
06/24/2022 12:10:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=359
06/24/2022 12:10:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=364
06/24/2022 12:10:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=369
06/24/2022 12:10:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=374
06/24/2022 12:10:46 - INFO - __main__ - Global step 750 Train loss 0.11 ACC 0.625 on epoch=374
06/24/2022 12:10:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=379
06/24/2022 12:10:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=384
06/24/2022 12:10:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=389
06/24/2022 12:10:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=394
06/24/2022 12:10:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=399
06/24/2022 12:10:53 - INFO - __main__ - Global step 800 Train loss 0.07 ACC 0.59375 on epoch=399
06/24/2022 12:10:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=404
06/24/2022 12:10:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=409
06/24/2022 12:10:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=414
06/24/2022 12:10:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=419
06/24/2022 12:10:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=424
06/24/2022 12:11:00 - INFO - __main__ - Global step 850 Train loss 0.04 ACC 0.53125 on epoch=424
06/24/2022 12:11:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=429
06/24/2022 12:11:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=434
06/24/2022 12:11:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=439
06/24/2022 12:11:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=444
06/24/2022 12:11:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=449
06/24/2022 12:11:07 - INFO - __main__ - Global step 900 Train loss 0.03 ACC 0.5625 on epoch=449
06/24/2022 12:11:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=454
06/24/2022 12:11:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=459
06/24/2022 12:11:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=464
06/24/2022 12:11:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=469
06/24/2022 12:11:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=474
06/24/2022 12:11:14 - INFO - __main__ - Global step 950 Train loss 0.01 ACC 0.53125 on epoch=474
06/24/2022 12:11:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=479
06/24/2022 12:11:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=484
06/24/2022 12:11:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=489
06/24/2022 12:11:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=494
06/24/2022 12:11:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=499
06/24/2022 12:11:21 - INFO - __main__ - Global step 1000 Train loss 0.02 ACC 0.59375 on epoch=499
06/24/2022 12:11:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=504
06/24/2022 12:11:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=509
06/24/2022 12:11:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=514
06/24/2022 12:11:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=519
06/24/2022 12:11:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=524
06/24/2022 12:11:28 - INFO - __main__ - Global step 1050 Train loss 0.01 ACC 0.65625 on epoch=524
06/24/2022 12:11:28 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=524, global_step=1050
06/24/2022 12:11:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=529
06/24/2022 12:11:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=534
06/24/2022 12:11:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=539
06/24/2022 12:11:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=544
06/24/2022 12:11:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=549
06/24/2022 12:11:34 - INFO - __main__ - Global step 1100 Train loss 0.01 ACC 0.625 on epoch=549
06/24/2022 12:11:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=554
06/24/2022 12:11:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=559
06/24/2022 12:11:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=564
06/24/2022 12:11:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=569
06/24/2022 12:11:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=574
06/24/2022 12:11:41 - INFO - __main__ - Global step 1150 Train loss 0.00 ACC 0.5625 on epoch=574
06/24/2022 12:11:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=579
06/24/2022 12:11:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=584
06/24/2022 12:11:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=589
06/24/2022 12:11:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=594
06/24/2022 12:11:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=599
06/24/2022 12:11:48 - INFO - __main__ - Global step 1200 Train loss 0.00 ACC 0.625 on epoch=599
06/24/2022 12:11:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=604
06/24/2022 12:11:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=609
06/24/2022 12:11:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=614
06/24/2022 12:11:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=619
06/24/2022 12:11:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=624
06/24/2022 12:11:55 - INFO - __main__ - Global step 1250 Train loss 0.00 ACC 0.625 on epoch=624
06/24/2022 12:11:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=629
06/24/2022 12:11:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=634
06/24/2022 12:11:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=639
06/24/2022 12:12:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=644
06/24/2022 12:12:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=649
06/24/2022 12:12:02 - INFO - __main__ - Global step 1300 Train loss 0.00 ACC 0.59375 on epoch=649
06/24/2022 12:12:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 12:12:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=659
06/24/2022 12:12:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=664
06/24/2022 12:12:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 12:12:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=674
06/24/2022 12:12:09 - INFO - __main__ - Global step 1350 Train loss 0.00 ACC 0.46875 on epoch=674
06/24/2022 12:12:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=679
06/24/2022 12:12:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=684
06/24/2022 12:12:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=689
06/24/2022 12:12:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 12:12:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=699
06/24/2022 12:12:15 - INFO - __main__ - Global step 1400 Train loss 0.00 ACC 0.5 on epoch=699
06/24/2022 12:12:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=704
06/24/2022 12:12:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=709
06/24/2022 12:12:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 12:12:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 12:12:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 12:12:22 - INFO - __main__ - Global step 1450 Train loss 0.00 ACC 0.46875 on epoch=724
06/24/2022 12:12:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=729
06/24/2022 12:12:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=734
06/24/2022 12:12:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=739
06/24/2022 12:12:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 12:12:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 12:12:29 - INFO - __main__ - Global step 1500 Train loss 0.00 ACC 0.53125 on epoch=749
06/24/2022 12:12:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 12:12:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 12:12:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 12:12:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/24/2022 12:12:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 12:12:36 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.5625 on epoch=774
06/24/2022 12:12:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 12:12:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=784
06/24/2022 12:12:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=789
06/24/2022 12:12:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 12:12:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 12:12:43 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.5625 on epoch=799
06/24/2022 12:12:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 12:12:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 12:12:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=814
06/24/2022 12:12:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 12:12:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 12:12:50 - INFO - __main__ - Global step 1650 Train loss 0.00 ACC 0.53125 on epoch=824
06/24/2022 12:12:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=829
06/24/2022 12:12:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 12:12:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=839
06/24/2022 12:12:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=844
06/24/2022 12:12:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 12:12:57 - INFO - __main__ - Global step 1700 Train loss 0.01 ACC 0.53125 on epoch=849
06/24/2022 12:12:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 12:12:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 12:13:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 12:13:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 12:13:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 12:13:04 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.46875 on epoch=874
06/24/2022 12:13:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 12:13:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=884
06/24/2022 12:13:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 12:13:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 12:13:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 12:13:11 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5625 on epoch=899
06/24/2022 12:13:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 12:13:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 12:13:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 12:13:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=919
06/24/2022 12:13:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 12:13:18 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.59375 on epoch=924
06/24/2022 12:13:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 12:13:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 12:13:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 12:13:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=944
06/24/2022 12:13:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=949
06/24/2022 12:13:25 - INFO - __main__ - Global step 1900 Train loss 0.00 ACC 0.59375 on epoch=949
06/24/2022 12:13:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 12:13:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 12:13:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=964
06/24/2022 12:13:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 12:13:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 12:13:31 - INFO - __main__ - Global step 1950 Train loss 0.00 ACC 0.53125 on epoch=974
06/24/2022 12:13:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 12:13:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 12:13:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 12:13:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 12:13:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 12:13:38 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.625 on epoch=999
06/24/2022 12:13:38 - INFO - __main__ - save last model!
06/24/2022 12:13:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 12:13:38 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 12:13:38 - INFO - __main__ - Printing 3 examples
06/24/2022 12:13:38 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 12:13:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:13:38 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 12:13:38 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:13:38 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 12:13:38 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:38 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:13:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:13:39 - INFO - __main__ - Printing 3 examples
06/24/2022 12:13:39 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:13:39 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:39 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:13:39 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:39 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:13:39 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:13:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:13:39 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:13:39 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:13:39 - INFO - __main__ - Printing 3 examples
06/24/2022 12:13:39 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:13:39 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:39 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:13:39 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:39 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:13:39 - INFO - __main__ - ['duplicate']
06/24/2022 12:13:39 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:13:39 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:13:39 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:13:45 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 12:13:45 - INFO - __main__ - task name: glue-qqp
06/24/2022 12:13:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:13:45 - INFO - __main__ - Starting training!
06/24/2022 12:13:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:14:38 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 12:27:49 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_87_0.5_8_predictions.txt
06/24/2022 12:27:49 - INFO - __main__ - ACC on test data: 0.5616
06/24/2022 12:27:50 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.5, bsz=8, dev_performance=0.65625, test_performance=0.5616126638634678
06/24/2022 12:27:50 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.4, bsz=8 ...
06/24/2022 12:27:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:27:51 - INFO - __main__ - Printing 3 examples
06/24/2022 12:27:51 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:27:51 - INFO - __main__ - ['duplicate']
06/24/2022 12:27:51 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:27:51 - INFO - __main__ - ['duplicate']
06/24/2022 12:27:51 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:27:51 - INFO - __main__ - ['duplicate']
06/24/2022 12:27:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:27:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:27:51 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:27:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:27:51 - INFO - __main__ - Printing 3 examples
06/24/2022 12:27:51 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:27:51 - INFO - __main__ - ['duplicate']
06/24/2022 12:27:51 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:27:51 - INFO - __main__ - ['duplicate']
06/24/2022 12:27:51 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:27:51 - INFO - __main__ - ['duplicate']
06/24/2022 12:27:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:27:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:27:51 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:27:56 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 12:27:56 - INFO - __main__ - task name: glue-qqp
06/24/2022 12:27:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:27:57 - INFO - __main__ - Starting training!
06/24/2022 12:27:58 - INFO - __main__ - Step 10 Global step 10 Train loss 6.00 on epoch=4
06/24/2022 12:28:00 - INFO - __main__ - Step 20 Global step 20 Train loss 2.51 on epoch=9
06/24/2022 12:28:01 - INFO - __main__ - Step 30 Global step 30 Train loss 1.15 on epoch=14
06/24/2022 12:28:02 - INFO - __main__ - Step 40 Global step 40 Train loss 0.80 on epoch=19
06/24/2022 12:28:03 - INFO - __main__ - Step 50 Global step 50 Train loss 0.54 on epoch=24
06/24/2022 12:28:04 - INFO - __main__ - Global step 50 Train loss 2.20 ACC 0.5 on epoch=24
06/24/2022 12:28:04 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 12:28:05 - INFO - __main__ - Step 60 Global step 60 Train loss 0.49 on epoch=29
06/24/2022 12:28:06 - INFO - __main__ - Step 70 Global step 70 Train loss 2.17 on epoch=34
06/24/2022 12:28:08 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=39
06/24/2022 12:28:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.56 on epoch=44
06/24/2022 12:28:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.40 on epoch=49
06/24/2022 12:28:11 - INFO - __main__ - Global step 100 Train loss 0.91 ACC 0.5 on epoch=49
06/24/2022 12:28:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.38 on epoch=54
06/24/2022 12:28:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=59
06/24/2022 12:28:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/24/2022 12:28:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.32 on epoch=69
06/24/2022 12:28:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.42 on epoch=74
06/24/2022 12:28:18 - INFO - __main__ - Global step 150 Train loss 0.39 ACC 0.5 on epoch=74
06/24/2022 12:28:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.32 on epoch=79
06/24/2022 12:28:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.39 on epoch=84
06/24/2022 12:28:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=89
06/24/2022 12:28:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.36 on epoch=94
06/24/2022 12:28:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=99
06/24/2022 12:28:24 - INFO - __main__ - Global step 200 Train loss 0.36 ACC 0.5 on epoch=99
06/24/2022 12:28:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=104
06/24/2022 12:28:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=109
06/24/2022 12:28:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.32 on epoch=114
06/24/2022 12:28:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=119
06/24/2022 12:28:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=124
06/24/2022 12:28:31 - INFO - __main__ - Global step 250 Train loss 0.32 ACC 0.5 on epoch=124
06/24/2022 12:28:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/24/2022 12:28:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=134
06/24/2022 12:28:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=139
06/24/2022 12:28:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=144
06/24/2022 12:28:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=149
06/24/2022 12:28:38 - INFO - __main__ - Global step 300 Train loss 0.30 ACC 0.53125 on epoch=149
06/24/2022 12:28:38 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=149, global_step=300
06/24/2022 12:28:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=154
06/24/2022 12:28:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=159
06/24/2022 12:28:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=164
06/24/2022 12:28:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=169
06/24/2022 12:28:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=174
06/24/2022 12:28:45 - INFO - __main__ - Global step 350 Train loss 0.29 ACC 0.5 on epoch=174
06/24/2022 12:28:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=179
06/24/2022 12:28:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=184
06/24/2022 12:28:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=189
06/24/2022 12:28:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=194
06/24/2022 12:28:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=199
06/24/2022 12:28:52 - INFO - __main__ - Global step 400 Train loss 0.31 ACC 0.5 on epoch=199
06/24/2022 12:28:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=204
06/24/2022 12:28:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=209
06/24/2022 12:28:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=214
06/24/2022 12:28:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=219
06/24/2022 12:28:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=224
06/24/2022 12:28:59 - INFO - __main__ - Global step 450 Train loss 0.30 ACC 0.5 on epoch=224
06/24/2022 12:29:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=229
06/24/2022 12:29:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=234
06/24/2022 12:29:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=239
06/24/2022 12:29:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=244
06/24/2022 12:29:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=249
06/24/2022 12:29:06 - INFO - __main__ - Global step 500 Train loss 0.28 ACC 0.5 on epoch=249
06/24/2022 12:29:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=254
06/24/2022 12:29:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=259
06/24/2022 12:29:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=264
06/24/2022 12:29:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=269
06/24/2022 12:29:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=274
06/24/2022 12:29:12 - INFO - __main__ - Global step 550 Train loss 0.29 ACC 0.5 on epoch=274
06/24/2022 12:29:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=279
06/24/2022 12:29:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=284
06/24/2022 12:29:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=289
06/24/2022 12:29:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=294
06/24/2022 12:29:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=299
06/24/2022 12:29:19 - INFO - __main__ - Global step 600 Train loss 0.28 ACC 0.5 on epoch=299
06/24/2022 12:29:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=304
06/24/2022 12:29:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=309
06/24/2022 12:29:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=314
06/24/2022 12:29:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=319
06/24/2022 12:29:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=324
06/24/2022 12:29:26 - INFO - __main__ - Global step 650 Train loss 0.29 ACC 0.5 on epoch=324
06/24/2022 12:29:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=329
06/24/2022 12:29:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=334
06/24/2022 12:29:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=339
06/24/2022 12:29:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=344
06/24/2022 12:29:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=349
06/24/2022 12:29:33 - INFO - __main__ - Global step 700 Train loss 0.25 ACC 0.5 on epoch=349
06/24/2022 12:29:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=354
06/24/2022 12:29:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=359
06/24/2022 12:29:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=364
06/24/2022 12:29:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=369
06/24/2022 12:29:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=374
06/24/2022 12:29:40 - INFO - __main__ - Global step 750 Train loss 0.26 ACC 0.5 on epoch=374
06/24/2022 12:29:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=379
06/24/2022 12:29:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=384
06/24/2022 12:29:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=389
06/24/2022 12:29:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=394
06/24/2022 12:29:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=399
06/24/2022 12:29:47 - INFO - __main__ - Global step 800 Train loss 0.26 ACC 0.5 on epoch=399
06/24/2022 12:29:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=404
06/24/2022 12:29:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=409
06/24/2022 12:29:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=414
06/24/2022 12:29:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=419
06/24/2022 12:29:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=424
06/24/2022 12:29:54 - INFO - __main__ - Global step 850 Train loss 0.24 ACC 0.5 on epoch=424
06/24/2022 12:29:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=429
06/24/2022 12:29:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=434
06/24/2022 12:29:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=439
06/24/2022 12:29:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=444
06/24/2022 12:30:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=449
06/24/2022 12:30:01 - INFO - __main__ - Global step 900 Train loss 0.23 ACC 0.5 on epoch=449
06/24/2022 12:30:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=454
06/24/2022 12:30:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=459
06/24/2022 12:30:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=464
06/24/2022 12:30:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=469
06/24/2022 12:30:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=474
06/24/2022 12:30:07 - INFO - __main__ - Global step 950 Train loss 0.24 ACC 0.5 on epoch=474
06/24/2022 12:30:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=479
06/24/2022 12:30:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=484
06/24/2022 12:30:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=489
06/24/2022 12:30:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=494
06/24/2022 12:30:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=499
06/24/2022 12:30:14 - INFO - __main__ - Global step 1000 Train loss 0.18 ACC 0.5 on epoch=499
06/24/2022 12:30:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=504
06/24/2022 12:30:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=509
06/24/2022 12:30:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=514
06/24/2022 12:30:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=519
06/24/2022 12:30:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=524
06/24/2022 12:30:21 - INFO - __main__ - Global step 1050 Train loss 0.16 ACC 0.59375 on epoch=524
06/24/2022 12:30:21 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.59375 on epoch=524, global_step=1050
06/24/2022 12:30:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=529
06/24/2022 12:30:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=534
06/24/2022 12:30:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=539
06/24/2022 12:30:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=544
06/24/2022 12:30:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=549
06/24/2022 12:30:28 - INFO - __main__ - Global step 1100 Train loss 0.13 ACC 0.53125 on epoch=549
06/24/2022 12:30:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=554
06/24/2022 12:30:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
06/24/2022 12:30:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=564
06/24/2022 12:30:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=569
06/24/2022 12:30:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=574
06/24/2022 12:30:35 - INFO - __main__ - Global step 1150 Train loss 0.05 ACC 0.5625 on epoch=574
06/24/2022 12:30:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=579
06/24/2022 12:30:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=584
06/24/2022 12:30:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=589
06/24/2022 12:30:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=594
06/24/2022 12:30:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=599
06/24/2022 12:30:42 - INFO - __main__ - Global step 1200 Train loss 0.04 ACC 0.5 on epoch=599
06/24/2022 12:30:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=604
06/24/2022 12:30:45 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
06/24/2022 12:30:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 12:30:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/24/2022 12:30:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=624
06/24/2022 12:30:49 - INFO - __main__ - Global step 1250 Train loss 0.03 ACC 0.53125 on epoch=624
06/24/2022 12:30:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=629
06/24/2022 12:30:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=634
06/24/2022 12:30:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=639
06/24/2022 12:30:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=644
06/24/2022 12:30:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=649
06/24/2022 12:30:56 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.5625 on epoch=649
06/24/2022 12:30:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=654
06/24/2022 12:30:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=659
06/24/2022 12:31:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 12:31:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=669
06/24/2022 12:31:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=674
06/24/2022 12:31:03 - INFO - __main__ - Global step 1350 Train loss 0.01 ACC 0.53125 on epoch=674
06/24/2022 12:31:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 12:31:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=684
06/24/2022 12:31:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=689
06/24/2022 12:31:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=694
06/24/2022 12:31:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 12:31:10 - INFO - __main__ - Global step 1400 Train loss 0.01 ACC 0.53125 on epoch=699
06/24/2022 12:31:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 12:31:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=709
06/24/2022 12:31:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=714
06/24/2022 12:31:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=719
06/24/2022 12:31:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=724
06/24/2022 12:31:17 - INFO - __main__ - Global step 1450 Train loss 0.01 ACC 0.46875 on epoch=724
06/24/2022 12:31:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=729
06/24/2022 12:31:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/24/2022 12:31:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=739
06/24/2022 12:31:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=744
06/24/2022 12:31:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=749
06/24/2022 12:31:24 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.53125 on epoch=749
06/24/2022 12:31:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=754
06/24/2022 12:31:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=759
06/24/2022 12:31:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=764
06/24/2022 12:31:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=769
06/24/2022 12:31:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=774
06/24/2022 12:31:31 - INFO - __main__ - Global step 1550 Train loss 0.00 ACC 0.53125 on epoch=774
06/24/2022 12:31:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=779
06/24/2022 12:31:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=784
06/24/2022 12:31:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=789
06/24/2022 12:31:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=794
06/24/2022 12:31:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=799
06/24/2022 12:31:37 - INFO - __main__ - Global step 1600 Train loss 0.04 ACC 0.53125 on epoch=799
06/24/2022 12:31:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=804
06/24/2022 12:31:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=809
06/24/2022 12:31:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
06/24/2022 12:31:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=819
06/24/2022 12:31:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=824
06/24/2022 12:31:44 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.53125 on epoch=824
06/24/2022 12:31:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 12:31:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=834
06/24/2022 12:31:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=839
06/24/2022 12:31:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=844
06/24/2022 12:31:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=849
06/24/2022 12:31:51 - INFO - __main__ - Global step 1700 Train loss 0.00 ACC 0.5625 on epoch=849
06/24/2022 12:31:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=854
06/24/2022 12:31:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=859
06/24/2022 12:31:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 12:31:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=869
06/24/2022 12:31:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=874
06/24/2022 12:31:58 - INFO - __main__ - Global step 1750 Train loss 0.00 ACC 0.5625 on epoch=874
06/24/2022 12:31:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=879
06/24/2022 12:32:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=884
06/24/2022 12:32:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=889
06/24/2022 12:32:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 12:32:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 12:32:05 - INFO - __main__ - Global step 1800 Train loss 0.00 ACC 0.5 on epoch=899
06/24/2022 12:32:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=904
06/24/2022 12:32:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 12:32:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=914
06/24/2022 12:32:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 12:32:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 12:32:11 - INFO - __main__ - Global step 1850 Train loss 0.00 ACC 0.46875 on epoch=924
06/24/2022 12:32:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=929
06/24/2022 12:32:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=934
06/24/2022 12:32:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=939
06/24/2022 12:32:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 12:32:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 12:32:18 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.40625 on epoch=949
06/24/2022 12:32:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=954
06/24/2022 12:32:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=959
06/24/2022 12:32:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=964
06/24/2022 12:32:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 12:32:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=974
06/24/2022 12:32:25 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.53125 on epoch=974
06/24/2022 12:32:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 12:32:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=984
06/24/2022 12:32:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=989
06/24/2022 12:32:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 12:32:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 12:32:32 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.53125 on epoch=999
06/24/2022 12:32:32 - INFO - __main__ - save last model!
06/24/2022 12:32:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 12:32:32 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 12:32:32 - INFO - __main__ - Printing 3 examples
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 12:32:32 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 12:32:32 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:32:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:32:32 - INFO - __main__ - Printing 3 examples
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:32:32 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:32:32 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:32:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:32:32 - INFO - __main__ - Printing 3 examples
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:32:32 - INFO - __main__ - ['duplicate']
06/24/2022 12:32:32 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:32:32 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:32:32 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:32:38 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 12:32:38 - INFO - __main__ - task name: glue-qqp
06/24/2022 12:32:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:32:39 - INFO - __main__ - Starting training!
06/24/2022 12:32:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:33:31 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 12:46:38 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_87_0.4_8_predictions.txt
06/24/2022 12:46:39 - INFO - __main__ - ACC on test data: 0.5437
06/24/2022 12:46:39 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.4, bsz=8, dev_performance=0.59375, test_performance=0.5437299035369775
06/24/2022 12:46:39 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.3, bsz=8 ...
06/24/2022 12:46:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:46:40 - INFO - __main__ - Printing 3 examples
06/24/2022 12:46:40 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:46:40 - INFO - __main__ - ['duplicate']
06/24/2022 12:46:40 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:46:40 - INFO - __main__ - ['duplicate']
06/24/2022 12:46:40 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:46:40 - INFO - __main__ - ['duplicate']
06/24/2022 12:46:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:46:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:46:40 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:46:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:46:40 - INFO - __main__ - Printing 3 examples
06/24/2022 12:46:40 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:46:40 - INFO - __main__ - ['duplicate']
06/24/2022 12:46:40 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:46:40 - INFO - __main__ - ['duplicate']
06/24/2022 12:46:40 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:46:40 - INFO - __main__ - ['duplicate']
06/24/2022 12:46:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:46:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:46:40 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:46:46 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 12:46:46 - INFO - __main__ - task name: glue-qqp
06/24/2022 12:46:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:46:46 - INFO - __main__ - Starting training!
06/24/2022 12:46:47 - INFO - __main__ - Step 10 Global step 10 Train loss 6.51 on epoch=4
06/24/2022 12:46:49 - INFO - __main__ - Step 20 Global step 20 Train loss 3.03 on epoch=9
06/24/2022 12:46:50 - INFO - __main__ - Step 30 Global step 30 Train loss 1.42 on epoch=14
06/24/2022 12:46:51 - INFO - __main__ - Step 40 Global step 40 Train loss 0.81 on epoch=19
06/24/2022 12:46:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.69 on epoch=24
06/24/2022 12:46:53 - INFO - __main__ - Global step 50 Train loss 2.49 ACC 0.5 on epoch=24
06/24/2022 12:46:53 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.5 on epoch=24, global_step=50
06/24/2022 12:46:54 - INFO - __main__ - Step 60 Global step 60 Train loss 0.50 on epoch=29
06/24/2022 12:46:55 - INFO - __main__ - Step 70 Global step 70 Train loss 0.56 on epoch=34
06/24/2022 12:46:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.43 on epoch=39
06/24/2022 12:46:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.37 on epoch=44
06/24/2022 12:46:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.35 on epoch=49
06/24/2022 12:46:59 - INFO - __main__ - Global step 100 Train loss 0.44 ACC 0.5 on epoch=49
06/24/2022 12:47:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.41 on epoch=54
06/24/2022 12:47:02 - INFO - __main__ - Step 120 Global step 120 Train loss 0.42 on epoch=59
06/24/2022 12:47:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=64
06/24/2022 12:47:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.40 on epoch=69
06/24/2022 12:47:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.41 on epoch=74
06/24/2022 12:47:06 - INFO - __main__ - Global step 150 Train loss 0.40 ACC 0.5 on epoch=74
06/24/2022 12:47:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=79
06/24/2022 12:47:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.33 on epoch=84
06/24/2022 12:47:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=89
06/24/2022 12:47:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=94
06/24/2022 12:47:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.34 on epoch=99
06/24/2022 12:47:13 - INFO - __main__ - Global step 200 Train loss 0.34 ACC 0.5 on epoch=99
06/24/2022 12:47:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=104
06/24/2022 12:47:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=109
06/24/2022 12:47:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=114
06/24/2022 12:47:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=119
06/24/2022 12:47:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=124
06/24/2022 12:47:20 - INFO - __main__ - Global step 250 Train loss 0.28 ACC 0.5 on epoch=124
06/24/2022 12:47:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=129
06/24/2022 12:47:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=134
06/24/2022 12:47:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=139
06/24/2022 12:47:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.28 on epoch=144
06/24/2022 12:47:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=149
06/24/2022 12:47:26 - INFO - __main__ - Global step 300 Train loss 0.28 ACC 0.46875 on epoch=149
06/24/2022 12:47:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=154
06/24/2022 12:47:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=159
06/24/2022 12:47:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=164
06/24/2022 12:47:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=169
06/24/2022 12:47:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=174
06/24/2022 12:47:33 - INFO - __main__ - Global step 350 Train loss 0.27 ACC 0.5 on epoch=174
06/24/2022 12:47:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=179
06/24/2022 12:47:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=184
06/24/2022 12:47:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=189
06/24/2022 12:47:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=194
06/24/2022 12:47:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=199
06/24/2022 12:47:40 - INFO - __main__ - Global step 400 Train loss 0.25 ACC 0.5625 on epoch=199
06/24/2022 12:47:40 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.5625 on epoch=199, global_step=400
06/24/2022 12:47:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=204
06/24/2022 12:47:43 - INFO - __main__ - Step 420 Global step 420 Train loss 1.28 on epoch=209
06/24/2022 12:47:44 - INFO - __main__ - Step 430 Global step 430 Train loss 3.88 on epoch=214
06/24/2022 12:47:45 - INFO - __main__ - Step 440 Global step 440 Train loss 3.99 on epoch=219
06/24/2022 12:47:46 - INFO - __main__ - Step 450 Global step 450 Train loss 3.42 on epoch=224
06/24/2022 12:47:47 - INFO - __main__ - Global step 450 Train loss 2.58 ACC 0.40625 on epoch=224
06/24/2022 12:47:48 - INFO - __main__ - Step 460 Global step 460 Train loss 2.88 on epoch=229
06/24/2022 12:47:49 - INFO - __main__ - Step 470 Global step 470 Train loss 4.30 on epoch=234
06/24/2022 12:47:51 - INFO - __main__ - Step 480 Global step 480 Train loss 2.62 on epoch=239
06/24/2022 12:47:52 - INFO - __main__ - Step 490 Global step 490 Train loss 3.59 on epoch=244
06/24/2022 12:47:53 - INFO - __main__ - Step 500 Global step 500 Train loss 3.63 on epoch=249
06/24/2022 12:47:54 - INFO - __main__ - Global step 500 Train loss 3.40 ACC 0.5 on epoch=249
06/24/2022 12:47:55 - INFO - __main__ - Step 510 Global step 510 Train loss 1.64 on epoch=254
06/24/2022 12:47:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.80 on epoch=259
06/24/2022 12:47:57 - INFO - __main__ - Step 530 Global step 530 Train loss 1.45 on epoch=264
06/24/2022 12:47:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.61 on epoch=269
06/24/2022 12:48:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=274
06/24/2022 12:48:00 - INFO - __main__ - Global step 550 Train loss 0.99 ACC 0.5 on epoch=274
06/24/2022 12:48:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=279
06/24/2022 12:48:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=284
06/24/2022 12:48:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.34 on epoch=289
06/24/2022 12:48:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.81 on epoch=294
06/24/2022 12:48:06 - INFO - __main__ - Step 600 Global step 600 Train loss 1.05 on epoch=299
06/24/2022 12:48:07 - INFO - __main__ - Global step 600 Train loss 0.58 ACC 0.5 on epoch=299
06/24/2022 12:48:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.48 on epoch=304
06/24/2022 12:48:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.45 on epoch=309
06/24/2022 12:48:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=314
06/24/2022 12:48:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.40 on epoch=319
06/24/2022 12:48:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=324
06/24/2022 12:48:13 - INFO - __main__ - Global step 650 Train loss 0.40 ACC 0.5 on epoch=324
06/24/2022 12:48:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=329
06/24/2022 12:48:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=334
06/24/2022 12:48:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=339
06/24/2022 12:48:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=344
06/24/2022 12:48:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=349
06/24/2022 12:48:20 - INFO - __main__ - Global step 700 Train loss 0.32 ACC 0.5 on epoch=349
06/24/2022 12:48:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.32 on epoch=354
06/24/2022 12:48:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=359
06/24/2022 12:48:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=364
06/24/2022 12:48:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=369
06/24/2022 12:48:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=374
06/24/2022 12:48:27 - INFO - __main__ - Global step 750 Train loss 0.30 ACC 0.53125 on epoch=374
06/24/2022 12:48:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=379
06/24/2022 12:48:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=384
06/24/2022 12:48:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=389
06/24/2022 12:48:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=394
06/24/2022 12:48:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=399
06/24/2022 12:48:34 - INFO - __main__ - Global step 800 Train loss 0.28 ACC 0.6875 on epoch=399
06/24/2022 12:48:34 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.6875 on epoch=399, global_step=800
06/24/2022 12:48:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=404
06/24/2022 12:48:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=409
06/24/2022 12:48:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=414
06/24/2022 12:48:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=419
06/24/2022 12:48:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=424
06/24/2022 12:48:41 - INFO - __main__ - Global step 850 Train loss 0.25 ACC 0.53125 on epoch=424
06/24/2022 12:48:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=429
06/24/2022 12:48:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=434
06/24/2022 12:48:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=439
06/24/2022 12:48:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=444
06/24/2022 12:48:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=449
06/24/2022 12:48:47 - INFO - __main__ - Global step 900 Train loss 0.25 ACC 0.5625 on epoch=449
06/24/2022 12:48:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=454
06/24/2022 12:48:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=459
06/24/2022 12:48:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=464
06/24/2022 12:48:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=469
06/24/2022 12:48:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=474
06/24/2022 12:48:54 - INFO - __main__ - Global step 950 Train loss 0.26 ACC 0.625 on epoch=474
06/24/2022 12:48:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=479
06/24/2022 12:48:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=484
06/24/2022 12:48:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=489
06/24/2022 12:48:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=494
06/24/2022 12:49:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.24 on epoch=499
06/24/2022 12:49:01 - INFO - __main__ - Global step 1000 Train loss 0.25 ACC 0.5625 on epoch=499
06/24/2022 12:49:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=504
06/24/2022 12:49:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=509
06/24/2022 12:49:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=514
06/24/2022 12:49:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=519
06/24/2022 12:49:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=524
06/24/2022 12:49:08 - INFO - __main__ - Global step 1050 Train loss 0.25 ACC 0.5625 on epoch=524
06/24/2022 12:49:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=529
06/24/2022 12:49:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=534
06/24/2022 12:49:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=539
06/24/2022 12:49:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=544
06/24/2022 12:49:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=549
06/24/2022 12:49:15 - INFO - __main__ - Global step 1100 Train loss 0.21 ACC 0.59375 on epoch=549
06/24/2022 12:49:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.22 on epoch=554
06/24/2022 12:49:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=559
06/24/2022 12:49:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.22 on epoch=564
06/24/2022 12:49:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=569
06/24/2022 12:49:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=574
06/24/2022 12:49:21 - INFO - __main__ - Global step 1150 Train loss 0.20 ACC 0.59375 on epoch=574
06/24/2022 12:49:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=579
06/24/2022 12:49:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.24 on epoch=584
06/24/2022 12:49:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=589
06/24/2022 12:49:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=594
06/24/2022 12:49:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.23 on epoch=599
06/24/2022 12:49:28 - INFO - __main__ - Global step 1200 Train loss 0.24 ACC 0.65625 on epoch=599
06/24/2022 12:49:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.26 on epoch=604
06/24/2022 12:49:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=609
06/24/2022 12:49:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=614
06/24/2022 12:49:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=619
06/24/2022 12:49:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=624
06/24/2022 12:49:35 - INFO - __main__ - Global step 1250 Train loss 0.23 ACC 0.71875 on epoch=624
06/24/2022 12:49:35 - INFO - __main__ - Saving model with best ACC: 0.6875 -> 0.71875 on epoch=624, global_step=1250
06/24/2022 12:49:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=629
06/24/2022 12:49:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=634
06/24/2022 12:49:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.21 on epoch=639
06/24/2022 12:49:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.22 on epoch=644
06/24/2022 12:49:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.23 on epoch=649
06/24/2022 12:49:42 - INFO - __main__ - Global step 1300 Train loss 0.21 ACC 0.65625 on epoch=649
06/24/2022 12:49:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=654
06/24/2022 12:49:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=659
06/24/2022 12:49:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=664
06/24/2022 12:49:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=669
06/24/2022 12:49:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=674
06/24/2022 12:49:49 - INFO - __main__ - Global step 1350 Train loss 0.18 ACC 0.59375 on epoch=674
06/24/2022 12:49:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=679
06/24/2022 12:49:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=684
06/24/2022 12:49:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=689
06/24/2022 12:49:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.21 on epoch=694
06/24/2022 12:49:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=699
06/24/2022 12:49:56 - INFO - __main__ - Global step 1400 Train loss 0.21 ACC 0.59375 on epoch=699
06/24/2022 12:49:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=704
06/24/2022 12:49:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=709
06/24/2022 12:49:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=714
06/24/2022 12:50:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=719
06/24/2022 12:50:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=724
06/24/2022 12:50:02 - INFO - __main__ - Global step 1450 Train loss 0.17 ACC 0.6875 on epoch=724
06/24/2022 12:50:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=729
06/24/2022 12:50:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.21 on epoch=734
06/24/2022 12:50:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=739
06/24/2022 12:50:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=744
06/24/2022 12:50:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=749
06/24/2022 12:50:09 - INFO - __main__ - Global step 1500 Train loss 0.18 ACC 0.625 on epoch=749
06/24/2022 12:50:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=754
06/24/2022 12:50:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=759
06/24/2022 12:50:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.17 on epoch=764
06/24/2022 12:50:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.20 on epoch=769
06/24/2022 12:50:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.22 on epoch=774
06/24/2022 12:50:16 - INFO - __main__ - Global step 1550 Train loss 0.18 ACC 0.625 on epoch=774
06/24/2022 12:50:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=779
06/24/2022 12:50:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=784
06/24/2022 12:50:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=789
06/24/2022 12:50:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.17 on epoch=794
06/24/2022 12:50:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=799
06/24/2022 12:50:23 - INFO - __main__ - Global step 1600 Train loss 0.14 ACC 0.53125 on epoch=799
06/24/2022 12:50:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=804
06/24/2022 12:50:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=809
06/24/2022 12:50:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.17 on epoch=814
06/24/2022 12:50:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=819
06/24/2022 12:50:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.18 on epoch=824
06/24/2022 12:50:30 - INFO - __main__ - Global step 1650 Train loss 0.15 ACC 0.65625 on epoch=824
06/24/2022 12:50:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=829
06/24/2022 12:50:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.15 on epoch=834
06/24/2022 12:50:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=839
06/24/2022 12:50:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=844
06/24/2022 12:50:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=849
06/24/2022 12:50:36 - INFO - __main__ - Global step 1700 Train loss 0.14 ACC 0.625 on epoch=849
06/24/2022 12:50:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=854
06/24/2022 12:50:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=859
06/24/2022 12:50:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=864
06/24/2022 12:50:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=869
06/24/2022 12:50:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=874
06/24/2022 12:50:43 - INFO - __main__ - Global step 1750 Train loss 0.12 ACC 0.59375 on epoch=874
06/24/2022 12:50:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=879
06/24/2022 12:50:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=884
06/24/2022 12:50:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=889
06/24/2022 12:50:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.18 on epoch=894
06/24/2022 12:50:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=899
06/24/2022 12:50:50 - INFO - __main__ - Global step 1800 Train loss 0.13 ACC 0.65625 on epoch=899
06/24/2022 12:50:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=904
06/24/2022 12:50:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=909
06/24/2022 12:50:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=914
06/24/2022 12:50:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=919
06/24/2022 12:50:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=924
06/24/2022 12:50:57 - INFO - __main__ - Global step 1850 Train loss 0.12 ACC 0.625 on epoch=924
06/24/2022 12:50:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=929
06/24/2022 12:50:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=934
06/24/2022 12:51:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=939
06/24/2022 12:51:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=944
06/24/2022 12:51:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=949
06/24/2022 12:51:03 - INFO - __main__ - Global step 1900 Train loss 0.10 ACC 0.59375 on epoch=949
06/24/2022 12:51:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.17 on epoch=954
06/24/2022 12:51:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=959
06/24/2022 12:51:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=964
06/24/2022 12:51:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=969
06/24/2022 12:51:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=974
06/24/2022 12:51:10 - INFO - __main__ - Global step 1950 Train loss 0.12 ACC 0.53125 on epoch=974
06/24/2022 12:51:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=979
06/24/2022 12:51:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.15 on epoch=984
06/24/2022 12:51:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=989
06/24/2022 12:51:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=994
06/24/2022 12:51:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.22 on epoch=999
06/24/2022 12:51:17 - INFO - __main__ - Global step 2000 Train loss 0.12 ACC 0.59375 on epoch=999
06/24/2022 12:51:17 - INFO - __main__ - save last model!
06/24/2022 12:51:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 12:51:17 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 12:51:17 - INFO - __main__ - Printing 3 examples
06/24/2022 12:51:17 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 12:51:17 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:51:17 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 12:51:17 - INFO - __main__ - ['not_duplicate']
06/24/2022 12:51:17 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 12:51:17 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:17 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:51:18 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:51:18 - INFO - __main__ - Printing 3 examples
06/24/2022 12:51:18 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:51:18 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:18 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 12:51:18 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:18 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 12:51:18 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:18 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:51:18 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:51:18 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 12:51:18 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 12:51:18 - INFO - __main__ - Printing 3 examples
06/24/2022 12:51:18 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 12:51:18 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:18 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 12:51:18 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:18 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 12:51:18 - INFO - __main__ - ['duplicate']
06/24/2022 12:51:18 - INFO - __main__ - Tokenizing Input ...
06/24/2022 12:51:18 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:51:18 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 12:51:23 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 12:51:23 - INFO - __main__ - task name: glue-qqp
06/24/2022 12:51:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 12:51:24 - INFO - __main__ - Starting training!
06/24/2022 12:51:36 - INFO - __main__ - Tokenizing Output ...
06/24/2022 12:52:16 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 13:05:14 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_87_0.3_8_predictions.txt
06/24/2022 13:05:14 - INFO - __main__ - ACC on test data: 0.5625
06/24/2022 13:05:15 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.3, bsz=8, dev_performance=0.71875, test_performance=0.5624536235468711
06/24/2022 13:05:15 - INFO - __main__ - Running ... prefix=glue-qqp_16_87, lr=0.2, bsz=8 ...
06/24/2022 13:05:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:05:16 - INFO - __main__ - Printing 3 examples
06/24/2022 13:05:16 - INFO - __main__ -  [glue-qqp] question 1: What do you think about Modi government banning 500 & 1000 currency note from 9th November? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 13:05:16 - INFO - __main__ - ['duplicate']
06/24/2022 13:05:16 - INFO - __main__ -  [glue-qqp] question 1: What are the techniques of ASO in 2016? [SEP] question 2: Which are the techniques that helps to do ASO?
06/24/2022 13:05:16 - INFO - __main__ - ['duplicate']
06/24/2022 13:05:16 - INFO - __main__ -  [glue-qqp] question 1: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued? [SEP] question 2: What do you think about banning 500 and 1000 rupee notes in India?
06/24/2022 13:05:16 - INFO - __main__ - ['duplicate']
06/24/2022 13:05:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:05:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:05:16 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:05:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:05:16 - INFO - __main__ - Printing 3 examples
06/24/2022 13:05:16 - INFO - __main__ -  [glue-qqp] question 1: Why do so may people ask questions on Quora that can easily be found by a simple Google searh? [SEP] question 2: Why do people bother to ask questions on Quora they could just google to get the answer?
06/24/2022 13:05:16 - INFO - __main__ - ['duplicate']
06/24/2022 13:05:16 - INFO - __main__ -  [glue-qqp] question 1: What is the importance of conserving natural resources? [SEP] question 2: What is the necessity of conservation of natural resources?
06/24/2022 13:05:16 - INFO - __main__ - ['duplicate']
06/24/2022 13:05:16 - INFO - __main__ -  [glue-qqp] question 1: What was the best day of your life so far? [SEP] question 2: Can you share best day of your life?
06/24/2022 13:05:16 - INFO - __main__ - ['duplicate']
06/24/2022 13:05:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:05:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:05:16 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:05:22 - INFO - __main__ - try to initialize prompt embeddings
06/24/2022 13:05:22 - INFO - __main__ - task name: glue-qqp
06/24/2022 13:05:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/24/2022 13:05:22 - INFO - __main__ - Starting training!
06/24/2022 13:05:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.35 on epoch=4
06/24/2022 13:05:25 - INFO - __main__ - Step 20 Global step 20 Train loss 5.54 on epoch=9
06/24/2022 13:05:26 - INFO - __main__ - Step 30 Global step 30 Train loss 4.40 on epoch=14
06/24/2022 13:05:27 - INFO - __main__ - Step 40 Global step 40 Train loss 3.05 on epoch=19
06/24/2022 13:05:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.84 on epoch=24
06/24/2022 13:05:29 - INFO - __main__ - Global step 50 Train loss 4.44 ACC 0.4375 on epoch=24
06/24/2022 13:05:29 - INFO - __main__ - Saving model with best ACC: -1.0 -> 0.4375 on epoch=24, global_step=50
06/24/2022 13:05:31 - INFO - __main__ - Step 60 Global step 60 Train loss 1.37 on epoch=29
06/24/2022 13:05:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=34
06/24/2022 13:05:33 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=39
06/24/2022 13:05:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.80 on epoch=44
06/24/2022 13:05:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=49
06/24/2022 13:05:36 - INFO - __main__ - Global step 100 Train loss 0.97 ACC 0.5 on epoch=49
06/24/2022 13:05:36 - INFO - __main__ - Saving model with best ACC: 0.4375 -> 0.5 on epoch=49, global_step=100
06/24/2022 13:05:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.56 on epoch=54
06/24/2022 13:05:39 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=59
06/24/2022 13:05:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.55 on epoch=64
06/24/2022 13:05:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.55 on epoch=69
06/24/2022 13:05:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=74
06/24/2022 13:05:43 - INFO - __main__ - Global step 150 Train loss 0.54 ACC 0.5 on epoch=74
06/24/2022 13:05:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.53 on epoch=79
06/24/2022 13:05:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=84
06/24/2022 13:05:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=89
06/24/2022 13:05:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=94
06/24/2022 13:05:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=99
06/24/2022 13:05:50 - INFO - __main__ - Global step 200 Train loss 0.50 ACC 0.5 on epoch=99
06/24/2022 13:05:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=104
06/24/2022 13:05:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=109
06/24/2022 13:05:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=114
06/24/2022 13:05:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=119
06/24/2022 13:05:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=124
06/24/2022 13:05:57 - INFO - __main__ - Global step 250 Train loss 0.38 ACC 0.53125 on epoch=124
06/24/2022 13:05:57 - INFO - __main__ - Saving model with best ACC: 0.5 -> 0.53125 on epoch=124, global_step=250
06/24/2022 13:05:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=129
06/24/2022 13:05:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=134
06/24/2022 13:06:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=139
06/24/2022 13:06:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=144
06/24/2022 13:06:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=149
06/24/2022 13:06:04 - INFO - __main__ - Global step 300 Train loss 0.37 ACC 0.5625 on epoch=149
06/24/2022 13:06:04 - INFO - __main__ - Saving model with best ACC: 0.53125 -> 0.5625 on epoch=149, global_step=300
06/24/2022 13:06:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=154
06/24/2022 13:06:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=159
06/24/2022 13:06:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=164
06/24/2022 13:06:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=169
06/24/2022 13:06:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=174
06/24/2022 13:06:11 - INFO - __main__ - Global step 350 Train loss 0.35 ACC 0.5 on epoch=174
06/24/2022 13:06:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=179
06/24/2022 13:06:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=184
06/24/2022 13:06:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=189
06/24/2022 13:06:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=194
06/24/2022 13:06:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=199
06/24/2022 13:06:17 - INFO - __main__ - Global step 400 Train loss 0.32 ACC 0.5 on epoch=199
06/24/2022 13:06:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=204
06/24/2022 13:06:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=209
06/24/2022 13:06:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=214
06/24/2022 13:06:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=219
06/24/2022 13:06:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=224
06/24/2022 13:06:24 - INFO - __main__ - Global step 450 Train loss 0.30 ACC 0.59375 on epoch=224
06/24/2022 13:06:24 - INFO - __main__ - Saving model with best ACC: 0.5625 -> 0.59375 on epoch=224, global_step=450
06/24/2022 13:06:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=229
06/24/2022 13:06:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=234
06/24/2022 13:06:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=239
06/24/2022 13:06:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=244
06/24/2022 13:06:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=249
06/24/2022 13:06:31 - INFO - __main__ - Global step 500 Train loss 0.30 ACC 0.59375 on epoch=249
06/24/2022 13:06:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=254
06/24/2022 13:06:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=259
06/24/2022 13:06:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=264
06/24/2022 13:06:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=269
06/24/2022 13:06:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=274
06/24/2022 13:06:38 - INFO - __main__ - Global step 550 Train loss 0.30 ACC 0.53125 on epoch=274
06/24/2022 13:06:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=279
06/24/2022 13:06:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=284
06/24/2022 13:06:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=289
06/24/2022 13:06:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=294
06/24/2022 13:06:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=299
06/24/2022 13:06:45 - INFO - __main__ - Global step 600 Train loss 0.33 ACC 0.53125 on epoch=299
06/24/2022 13:06:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=304
06/24/2022 13:06:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=309
06/24/2022 13:06:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=314
06/24/2022 13:06:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=319
06/24/2022 13:06:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=324
06/24/2022 13:06:52 - INFO - __main__ - Global step 650 Train loss 0.32 ACC 0.625 on epoch=324
06/24/2022 13:06:52 - INFO - __main__ - Saving model with best ACC: 0.59375 -> 0.625 on epoch=324, global_step=650
06/24/2022 13:06:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=329
06/24/2022 13:06:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=334
06/24/2022 13:06:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=339
06/24/2022 13:06:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=344
06/24/2022 13:06:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=349
06/24/2022 13:06:59 - INFO - __main__ - Global step 700 Train loss 0.26 ACC 0.59375 on epoch=349
06/24/2022 13:07:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=354
06/24/2022 13:07:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=359
06/24/2022 13:07:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=364
06/24/2022 13:07:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=369
06/24/2022 13:07:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=374
06/24/2022 13:07:06 - INFO - __main__ - Global step 750 Train loss 0.25 ACC 0.65625 on epoch=374
06/24/2022 13:07:06 - INFO - __main__ - Saving model with best ACC: 0.625 -> 0.65625 on epoch=374, global_step=750
06/24/2022 13:07:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=379
06/24/2022 13:07:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=384
06/24/2022 13:07:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=389
06/24/2022 13:07:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=394
06/24/2022 13:07:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=399
06/24/2022 13:07:13 - INFO - __main__ - Global step 800 Train loss 0.21 ACC 0.625 on epoch=399
06/24/2022 13:07:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=404
06/24/2022 13:07:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=409
06/24/2022 13:07:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=414
06/24/2022 13:07:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=419
06/24/2022 13:07:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=424
06/24/2022 13:07:20 - INFO - __main__ - Global step 850 Train loss 0.16 ACC 0.5625 on epoch=424
06/24/2022 13:07:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=429
06/24/2022 13:07:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=434
06/24/2022 13:07:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=439
06/24/2022 13:07:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=444
06/24/2022 13:07:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=449
06/24/2022 13:07:27 - INFO - __main__ - Global step 900 Train loss 0.11 ACC 0.59375 on epoch=449
06/24/2022 13:07:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=454
06/24/2022 13:07:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=459
06/24/2022 13:07:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=464
06/24/2022 13:07:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=469
06/24/2022 13:07:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=474
06/24/2022 13:07:34 - INFO - __main__ - Global step 950 Train loss 0.12 ACC 0.5625 on epoch=474
06/24/2022 13:07:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=479
06/24/2022 13:07:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=484
06/24/2022 13:07:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=489
06/24/2022 13:07:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=494
06/24/2022 13:07:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=499
06/24/2022 13:07:41 - INFO - __main__ - Global step 1000 Train loss 0.09 ACC 0.59375 on epoch=499
06/24/2022 13:07:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=504
06/24/2022 13:07:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=509
06/24/2022 13:07:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=514
06/24/2022 13:07:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=519
06/24/2022 13:07:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=524
06/24/2022 13:07:48 - INFO - __main__ - Global step 1050 Train loss 0.05 ACC 0.5625 on epoch=524
06/24/2022 13:07:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=529
06/24/2022 13:07:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=534
06/24/2022 13:07:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=539
06/24/2022 13:07:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=544
06/24/2022 13:07:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=549
06/24/2022 13:07:55 - INFO - __main__ - Global step 1100 Train loss 0.06 ACC 0.625 on epoch=549
06/24/2022 13:07:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=554
06/24/2022 13:07:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=559
06/24/2022 13:07:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=564
06/24/2022 13:08:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=569
06/24/2022 13:08:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=574
06/24/2022 13:08:02 - INFO - __main__ - Global step 1150 Train loss 0.04 ACC 0.53125 on epoch=574
06/24/2022 13:08:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=579
06/24/2022 13:08:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=584
06/24/2022 13:08:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=589
06/24/2022 13:08:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=594
06/24/2022 13:08:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=599
06/24/2022 13:08:09 - INFO - __main__ - Global step 1200 Train loss 0.02 ACC 0.5625 on epoch=599
06/24/2022 13:08:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=604
06/24/2022 13:08:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=609
06/24/2022 13:08:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=614
06/24/2022 13:08:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=619
06/24/2022 13:08:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=624
06/24/2022 13:08:16 - INFO - __main__ - Global step 1250 Train loss 0.02 ACC 0.5 on epoch=624
06/24/2022 13:08:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=629
06/24/2022 13:08:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=634
06/24/2022 13:08:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=639
06/24/2022 13:08:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=644
06/24/2022 13:08:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=649
06/24/2022 13:08:22 - INFO - __main__ - Global step 1300 Train loss 0.02 ACC 0.375 on epoch=649
06/24/2022 13:08:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=654
06/24/2022 13:08:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=659
06/24/2022 13:08:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=664
06/24/2022 13:08:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=669
06/24/2022 13:08:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=674
06/24/2022 13:08:29 - INFO - __main__ - Global step 1350 Train loss 0.02 ACC 0.5625 on epoch=674
06/24/2022 13:08:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=679
06/24/2022 13:08:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=684
06/24/2022 13:08:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=689
06/24/2022 13:08:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=694
06/24/2022 13:08:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=699
06/24/2022 13:08:37 - INFO - __main__ - Global step 1400 Train loss 0.02 ACC 0.46875 on epoch=699
06/24/2022 13:08:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=704
06/24/2022 13:08:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=709
06/24/2022 13:08:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=714
06/24/2022 13:08:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=719
06/24/2022 13:08:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=724
06/24/2022 13:08:43 - INFO - __main__ - Global step 1450 Train loss 0.02 ACC 0.46875 on epoch=724
06/24/2022 13:08:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=729
06/24/2022 13:08:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=734
06/24/2022 13:08:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=739
06/24/2022 13:08:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=744
06/24/2022 13:08:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=749
06/24/2022 13:08:50 - INFO - __main__ - Global step 1500 Train loss 0.01 ACC 0.46875 on epoch=749
06/24/2022 13:08:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=754
06/24/2022 13:08:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=759
06/24/2022 13:08:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=764
06/24/2022 13:08:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=769
06/24/2022 13:08:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=774
06/24/2022 13:08:57 - INFO - __main__ - Global step 1550 Train loss 0.01 ACC 0.4375 on epoch=774
06/24/2022 13:08:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=779
06/24/2022 13:08:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=784
06/24/2022 13:09:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=789
06/24/2022 13:09:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=794
06/24/2022 13:09:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=799
06/24/2022 13:09:03 - INFO - __main__ - Global step 1600 Train loss 0.01 ACC 0.5 on epoch=799
06/24/2022 13:09:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=804
06/24/2022 13:09:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=809
06/24/2022 13:09:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=814
06/24/2022 13:09:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=819
06/24/2022 13:09:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=824
06/24/2022 13:09:10 - INFO - __main__ - Global step 1650 Train loss 0.01 ACC 0.53125 on epoch=824
06/24/2022 13:09:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=829
06/24/2022 13:09:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=834
06/24/2022 13:09:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=839
06/24/2022 13:09:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=844
06/24/2022 13:09:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=849
06/24/2022 13:09:17 - INFO - __main__ - Global step 1700 Train loss 0.02 ACC 0.5 on epoch=849
06/24/2022 13:09:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=854
06/24/2022 13:09:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=859
06/24/2022 13:09:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=864
06/24/2022 13:09:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=869
06/24/2022 13:09:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=874
06/24/2022 13:09:23 - INFO - __main__ - Global step 1750 Train loss 0.02 ACC 0.5 on epoch=874
06/24/2022 13:09:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=879
06/24/2022 13:09:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=884
06/24/2022 13:09:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=889
06/24/2022 13:09:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=894
06/24/2022 13:09:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=899
06/24/2022 13:09:30 - INFO - __main__ - Global step 1800 Train loss 0.01 ACC 0.4375 on epoch=899
06/24/2022 13:09:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=904
06/24/2022 13:09:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=909
06/24/2022 13:09:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=914
06/24/2022 13:09:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=919
06/24/2022 13:09:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=924
06/24/2022 13:09:37 - INFO - __main__ - Global step 1850 Train loss 0.01 ACC 0.40625 on epoch=924
06/24/2022 13:09:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=929
06/24/2022 13:09:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=934
06/24/2022 13:09:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=939
06/24/2022 13:09:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=944
06/24/2022 13:09:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=949
06/24/2022 13:09:44 - INFO - __main__ - Global step 1900 Train loss 0.01 ACC 0.46875 on epoch=949
06/24/2022 13:09:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=954
06/24/2022 13:09:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=959
06/24/2022 13:09:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=964
06/24/2022 13:09:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=969
06/24/2022 13:09:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=974
06/24/2022 13:09:50 - INFO - __main__ - Global step 1950 Train loss 0.01 ACC 0.46875 on epoch=974
06/24/2022 13:09:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=979
06/24/2022 13:09:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=984
06/24/2022 13:09:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=989
06/24/2022 13:09:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=994
06/24/2022 13:09:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=999
06/24/2022 13:09:57 - INFO - __main__ - Global step 2000 Train loss 0.00 ACC 0.46875 on epoch=999
06/24/2022 13:09:57 - INFO - __main__ - save last model!
06/24/2022 13:09:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/24/2022 13:09:57 - INFO - __main__ - Start tokenizing ... 40430 instances
06/24/2022 13:09:57 - INFO - __main__ - Printing 3 examples
06/24/2022 13:09:57 - INFO - __main__ -  [glue-qqp] question 1: Why are African-Americans so beautiful? [SEP] question 2: Why are hispanics so beautiful?
06/24/2022 13:09:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 13:09:57 - INFO - __main__ -  [glue-qqp] question 1: I want to pursue PhD in Computer Science about social network,what is the open problem in social networks? [SEP] question 2: I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?
06/24/2022 13:09:57 - INFO - __main__ - ['not_duplicate']
06/24/2022 13:09:57 - INFO - __main__ -  [glue-qqp] question 1: Is there a reason why we should travel alone? [SEP] question 2: What are some reasons to travel alone?
06/24/2022 13:09:57 - INFO - __main__ - ['duplicate']
06/24/2022 13:09:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:10:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:10:56 - INFO - __main__ - Loaded 40430 examples from test data
06/24/2022 13:23:17 - INFO - __main__ - Saved prediction in models/T5-base-nopara2para/singletask-glue-qqp/glue-qqp_16_87_0.2_8_predictions.txt
06/24/2022 13:23:18 - INFO - __main__ - ACC on test data: 0.3446
06/24/2022 13:23:18 - INFO - __main__ - prefix=glue-qqp_16_87, lr=0.2, bsz=8, dev_performance=0.65625, test_performance=0.3446450655453871
