05/15/2022 18:55:50 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=False, bsz_list=[4], cache_dir='/data/qin/cache/', checkpoint='None', cuda='4', dataset='nlp_forest_single', debug=False, dev_file='data', do_lowercase=False, do_predict=True, do_train=True, eval_period=50, freeze_embeds=False, gradient_accumulation_steps=2, identifier='T5-large-ft-nopara2para', learning_rate=0.5, learning_rate_list=[0.5], lm_adapted_path='/data/qin/lm_adapted_t5model/torch_ckpt/large/pytorch_model.bin', local_rank=0, log_step=10, max_grad_norm=1.0, max_input_length=512, max_output_length=128, model='google/t5-v1_1-large', num_beams=4, num_train_epochs=1000.0, output_dir='models/T5-large-ft-nopara2para/singletask-glue-mrpc', predict_batch_size=16, predict_checkpoint='best-model.pt', prefix='', prompt_number=100, quiet=False, seed=42, task_dir='data/glue-mrpc/', task_name='glue-mrpc', test_file='data', total_steps=3000, train_batch_size=4, train_file='data', wait_step=10000000000, warmup_steps=50, weight_decay=1e-05)
05/15/2022 18:55:50 - INFO - __main__ - models/T5-large-ft-nopara2para/singletask-glue-mrpc
06/24/2022 13:01:17 - INFO - __main__ - Namespace(task_dir='data/glue-mrpc/', task_name='glue-mrpc', identifier='T5-base-ft-nopara2para', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-ft-nopara2para/singletask-glue-mrpc', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-base', cuda='6,7')
06/24/2022 13:01:17 - INFO - __main__ - models/T5-base-ft-nopara2para/singletask-glue-mrpc
06/24/2022 13:01:17 - INFO - __main__ - Namespace(task_dir='data/glue-mrpc/', task_name='glue-mrpc', identifier='T5-base-ft-nopara2para', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-ft-nopara2para/singletask-glue-mrpc', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-base', cuda='6,7')
06/24/2022 13:01:17 - INFO - __main__ - models/T5-base-ft-nopara2para/singletask-glue-mrpc
06/24/2022 13:01:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/24/2022 13:01:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/24/2022 13:01:19 - INFO - __main__ - args.device: cuda:1
06/24/2022 13:01:19 - INFO - __main__ - args.device: cuda:0
06/24/2022 13:01:19 - INFO - __main__ - Using 2 gpus
06/24/2022 13:01:19 - INFO - __main__ - Using 2 gpus
06/24/2022 13:01:19 - INFO - __main__ - Fine-tuning the following samples: ['glue-mrpc_16_100', 'glue-mrpc_16_13', 'glue-mrpc_16_21', 'glue-mrpc_16_42', 'glue-mrpc_16_87']
06/24/2022 13:01:19 - INFO - __main__ - Fine-tuning the following samples: ['glue-mrpc_16_100', 'glue-mrpc_16_13', 'glue-mrpc_16_21', 'glue-mrpc_16_42', 'glue-mrpc_16_87']
06/24/2022 13:01:24 - INFO - __main__ - Running ... prefix=glue-mrpc_16_100, lr=0.0005, bsz=8 ...
06/24/2022 13:01:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:01:25 - INFO - __main__ - Printing 3 examples
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:01:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:01:25 - INFO - __main__ - Printing 3 examples
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:01:25 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:01:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:01:25 - INFO - __main__ - Printing 3 examples
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:01:25 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:01:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:01:25 - INFO - __main__ - Printing 3 examples
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:01:25 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:01:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:01:25 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:01:25 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:01:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:01:29 - INFO - __main__ - Starting training!
06/24/2022 13:01:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:01:29 - INFO - __main__ - Starting training!
06/24/2022 13:01:32 - INFO - __main__ - Step 10 Global step 10 Train loss 15.758972 on epoch=4
06/24/2022 13:01:34 - INFO - __main__ - Step 20 Global step 20 Train loss 11.300932 on epoch=9
06/24/2022 13:01:36 - INFO - __main__ - Step 30 Global step 30 Train loss 5.852479 on epoch=14
06/24/2022 13:01:39 - INFO - __main__ - Step 40 Global step 40 Train loss 3.657104 on epoch=19
06/24/2022 13:01:41 - INFO - __main__ - Step 50 Global step 50 Train loss 2.539168 on epoch=24
06/24/2022 13:01:42 - INFO - __main__ - Global step 50 Train loss 7.821732 ACC 0.5 on epoch=24
06/24/2022 13:01:45 - INFO - __main__ - Step 60 Global step 60 Train loss 1.757793 on epoch=29
06/24/2022 13:01:47 - INFO - __main__ - Step 70 Global step 70 Train loss 1.304571 on epoch=34
06/24/2022 13:01:49 - INFO - __main__ - Step 80 Global step 80 Train loss 1.263317 on epoch=39
06/24/2022 13:01:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.985309 on epoch=44
06/24/2022 13:01:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.507924 on epoch=49
06/24/2022 13:01:55 - INFO - __main__ - Global step 100 Train loss 1.163783 ACC 0.5 on epoch=49
06/24/2022 13:01:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.623975 on epoch=54
06/24/2022 13:02:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.566541 on epoch=59
06/24/2022 13:02:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.521851 on epoch=64
06/24/2022 13:02:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.663815 on epoch=69
06/24/2022 13:02:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.330235 on epoch=74
06/24/2022 13:02:07 - INFO - __main__ - Global step 150 Train loss 0.541283 ACC 0.5 on epoch=74
06/24/2022 13:02:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.445822 on epoch=79
06/24/2022 13:02:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.467130 on epoch=84
06/24/2022 13:02:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.421894 on epoch=89
06/24/2022 13:02:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.598824 on epoch=94
06/24/2022 13:02:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.428862 on epoch=99
06/24/2022 13:02:20 - INFO - __main__ - Global step 200 Train loss 0.472506 ACC 0.5 on epoch=99
06/24/2022 13:02:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.335485 on epoch=104
06/24/2022 13:02:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.418117 on epoch=109
06/24/2022 13:02:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.396459 on epoch=114
06/24/2022 13:02:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.390026 on epoch=119
06/24/2022 13:02:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.502809 on epoch=124
06/24/2022 13:02:33 - INFO - __main__ - Global step 250 Train loss 0.408579 ACC 0.53125 on epoch=124
06/24/2022 13:02:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.361520 on epoch=129
06/24/2022 13:02:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.376828 on epoch=134
06/24/2022 13:02:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.370527 on epoch=139
06/24/2022 13:02:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.338626 on epoch=144
06/24/2022 13:02:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.329265 on epoch=149
06/24/2022 13:02:46 - INFO - __main__ - Global step 300 Train loss 0.355353 ACC 0.59375 on epoch=149
06/24/2022 13:02:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.395881 on epoch=154
06/24/2022 13:02:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.324081 on epoch=159
06/24/2022 13:02:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.212415 on epoch=164
06/24/2022 13:02:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.251254 on epoch=169
06/24/2022 13:02:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.313249 on epoch=174
06/24/2022 13:03:00 - INFO - __main__ - Global step 350 Train loss 0.299376 ACC 0.5 on epoch=174
06/24/2022 13:03:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.276431 on epoch=179
06/24/2022 13:03:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.250467 on epoch=184
06/24/2022 13:03:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.243612 on epoch=189
06/24/2022 13:03:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.245029 on epoch=194
06/24/2022 13:03:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.141459 on epoch=199
06/24/2022 13:03:12 - INFO - __main__ - Global step 400 Train loss 0.231400 ACC 0.59375 on epoch=199
06/24/2022 13:03:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.102107 on epoch=204
06/24/2022 13:03:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.124273 on epoch=209
06/24/2022 13:03:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.119167 on epoch=214
06/24/2022 13:03:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.087444 on epoch=219
06/24/2022 13:03:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.124322 on epoch=224
06/24/2022 13:03:25 - INFO - __main__ - Global step 450 Train loss 0.111462 ACC 0.75 on epoch=224
06/24/2022 13:03:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.055999 on epoch=229
06/24/2022 13:03:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.093461 on epoch=234
06/24/2022 13:03:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.072203 on epoch=239
06/24/2022 13:03:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.085943 on epoch=244
06/24/2022 13:03:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.032119 on epoch=249
06/24/2022 13:03:38 - INFO - __main__ - Global step 500 Train loss 0.067945 ACC 0.625 on epoch=249
06/24/2022 13:03:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.037056 on epoch=254
06/24/2022 13:03:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.043355 on epoch=259
06/24/2022 13:03:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.029380 on epoch=264
06/24/2022 13:03:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.024328 on epoch=269
06/24/2022 13:03:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.024529 on epoch=274
06/24/2022 13:03:51 - INFO - __main__ - Global step 550 Train loss 0.031729 ACC 0.625 on epoch=274
06/24/2022 13:03:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.018113 on epoch=279
06/24/2022 13:03:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.022986 on epoch=284
06/24/2022 13:03:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.010400 on epoch=289
06/24/2022 13:04:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.012364 on epoch=294
06/24/2022 13:04:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.004013 on epoch=299
06/24/2022 13:04:03 - INFO - __main__ - Global step 600 Train loss 0.013575 ACC 0.59375 on epoch=299
06/24/2022 13:04:03 - INFO - __main__ - save last model!
06/24/2022 13:04:04 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:04:04 - INFO - __main__ - Printing 3 examples
06/24/2022 13:04:04 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:04:04 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:04 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:04:04 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:04 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:04:04 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:04 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:04:04 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:04:04 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:04:04 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:04:04 - INFO - __main__ - Printing 3 examples
06/24/2022 13:04:04 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:04:04 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:04 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:04:04 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:04 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:04:04 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:04 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:04:04 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:04:04 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:04:06 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:04:06 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:04:07 - INFO - __main__ - Printing 3 examples
06/24/2022 13:04:07 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:04:07 - INFO - __main__ - ['equivalent']
06/24/2022 13:04:07 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:04:07 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:07 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:04:07 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:07 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:04:07 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:04:07 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:04:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:04:08 - INFO - __main__ - Starting training!
06/24/2022 13:04:12 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_100_0.0005_8_predictions.txt
06/24/2022 13:04:12 - INFO - __main__ - ACC on test data: 0.5515
06/24/2022 13:04:12 - INFO - __main__ - prefix=glue-mrpc_16_100, lr=0.0005, bsz=8, dev_performance=0.75, test_performance=0.5514705882352942
06/24/2022 13:04:12 - INFO - __main__ - Running ... prefix=glue-mrpc_16_100, lr=0.0003, bsz=8 ...
06/24/2022 13:04:13 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:04:13 - INFO - __main__ - Printing 3 examples
06/24/2022 13:04:13 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:04:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:13 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:04:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:13 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:04:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:13 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:04:13 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:04:13 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:04:13 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:04:13 - INFO - __main__ - Printing 3 examples
06/24/2022 13:04:13 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:04:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:13 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:04:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:13 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:04:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:04:13 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:04:14 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:04:14 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:04:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:04:17 - INFO - __main__ - Starting training!
06/24/2022 13:04:19 - INFO - __main__ - Step 10 Global step 10 Train loss 15.452395 on epoch=4
06/24/2022 13:04:21 - INFO - __main__ - Step 20 Global step 20 Train loss 10.847142 on epoch=9
06/24/2022 13:04:24 - INFO - __main__ - Step 30 Global step 30 Train loss 7.301808 on epoch=14
06/24/2022 13:04:26 - INFO - __main__ - Step 40 Global step 40 Train loss 5.995261 on epoch=19
06/24/2022 13:04:29 - INFO - __main__ - Step 50 Global step 50 Train loss 4.796272 on epoch=24
06/24/2022 13:04:29 - INFO - __main__ - Global step 50 Train loss 8.878575 ACC 0.28125 on epoch=24
06/24/2022 13:04:32 - INFO - __main__ - Step 60 Global step 60 Train loss 4.069953 on epoch=29
06/24/2022 13:04:34 - INFO - __main__ - Step 70 Global step 70 Train loss 2.971880 on epoch=34
06/24/2022 13:04:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.381011 on epoch=39
06/24/2022 13:04:39 - INFO - __main__ - Step 90 Global step 90 Train loss 1.580632 on epoch=44
06/24/2022 13:04:42 - INFO - __main__ - Step 100 Global step 100 Train loss 1.419468 on epoch=49
06/24/2022 13:04:42 - INFO - __main__ - Global step 100 Train loss 2.284589 ACC 0.4375 on epoch=49
06/24/2022 13:04:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.381645 on epoch=54
06/24/2022 13:04:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.886517 on epoch=59
06/24/2022 13:04:50 - INFO - __main__ - Step 130 Global step 130 Train loss 1.127266 on epoch=64
06/24/2022 13:04:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.782483 on epoch=69
06/24/2022 13:04:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.788453 on epoch=74
06/24/2022 13:04:55 - INFO - __main__ - Global step 150 Train loss 0.993273 ACC 0.53125 on epoch=74
06/24/2022 13:04:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.645452 on epoch=79
06/24/2022 13:05:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.807365 on epoch=84
06/24/2022 13:05:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.528547 on epoch=89
06/24/2022 13:05:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.578807 on epoch=94
06/24/2022 13:05:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.444811 on epoch=99
06/24/2022 13:05:09 - INFO - __main__ - Global step 200 Train loss 0.600997 ACC 0.5 on epoch=99
06/24/2022 13:05:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.372433 on epoch=104
06/24/2022 13:05:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.585447 on epoch=109
06/24/2022 13:05:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.465815 on epoch=114
06/24/2022 13:05:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.555582 on epoch=119
06/24/2022 13:05:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.474929 on epoch=124
06/24/2022 13:05:21 - INFO - __main__ - Global step 250 Train loss 0.490841 ACC 0.59375 on epoch=124
06/24/2022 13:05:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.542072 on epoch=129
06/24/2022 13:05:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.523403 on epoch=134
06/24/2022 13:05:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.292778 on epoch=139
06/24/2022 13:05:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.377296 on epoch=144
06/24/2022 13:05:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.407546 on epoch=149
06/24/2022 13:05:34 - INFO - __main__ - Global step 300 Train loss 0.428619 ACC 0.53125 on epoch=149
06/24/2022 13:05:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.323308 on epoch=154
06/24/2022 13:05:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.378435 on epoch=159
06/24/2022 13:05:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.373702 on epoch=164
06/24/2022 13:05:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.430914 on epoch=169
06/24/2022 13:05:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.369559 on epoch=174
06/24/2022 13:05:47 - INFO - __main__ - Global step 350 Train loss 0.375184 ACC 0.53125 on epoch=174
06/24/2022 13:05:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.264899 on epoch=179
06/24/2022 13:05:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.511994 on epoch=184
06/24/2022 13:05:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.446737 on epoch=189
06/24/2022 13:05:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.391319 on epoch=194
06/24/2022 13:05:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.255931 on epoch=199
06/24/2022 13:06:00 - INFO - __main__ - Global step 400 Train loss 0.374176 ACC 0.59375 on epoch=199
06/24/2022 13:06:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.405479 on epoch=204
06/24/2022 13:06:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.460231 on epoch=209
06/24/2022 13:06:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.310228 on epoch=214
06/24/2022 13:06:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.308213 on epoch=219
06/24/2022 13:06:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.336993 on epoch=224
06/24/2022 13:06:12 - INFO - __main__ - Global step 450 Train loss 0.364229 ACC 0.53125 on epoch=224
06/24/2022 13:06:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.236630 on epoch=229
06/24/2022 13:06:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.250639 on epoch=234
06/24/2022 13:06:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.334758 on epoch=239
06/24/2022 13:06:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.333430 on epoch=244
06/24/2022 13:06:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.231467 on epoch=249
06/24/2022 13:06:25 - INFO - __main__ - Global step 500 Train loss 0.277385 ACC 0.5625 on epoch=249
06/24/2022 13:06:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.205643 on epoch=254
06/24/2022 13:06:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.242037 on epoch=259
06/24/2022 13:06:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.229085 on epoch=264
06/24/2022 13:06:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.170801 on epoch=269
06/24/2022 13:06:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.234483 on epoch=274
06/24/2022 13:06:38 - INFO - __main__ - Global step 550 Train loss 0.216410 ACC 0.5 on epoch=274
06/24/2022 13:06:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.263630 on epoch=279
06/24/2022 13:06:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.195696 on epoch=284
06/24/2022 13:06:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.159166 on epoch=289
06/24/2022 13:06:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.206626 on epoch=294
06/24/2022 13:06:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.158136 on epoch=299
06/24/2022 13:06:50 - INFO - __main__ - Global step 600 Train loss 0.196650 ACC 0.5625 on epoch=299
06/24/2022 13:06:50 - INFO - __main__ - save last model!
06/24/2022 13:06:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:06:51 - INFO - __main__ - Printing 3 examples
06/24/2022 13:06:51 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:06:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:51 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:06:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:51 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:06:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:06:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:06:51 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:06:51 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:06:51 - INFO - __main__ - Printing 3 examples
06/24/2022 13:06:51 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:06:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:51 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:06:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:51 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:06:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:06:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:06:51 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:06:53 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:06:54 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:06:54 - INFO - __main__ - Printing 3 examples
06/24/2022 13:06:54 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:06:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:06:54 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:06:54 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:54 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:06:54 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:06:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:06:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:06:54 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:06:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:06:56 - INFO - __main__ - Starting training!
06/24/2022 13:06:59 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_100_0.0003_8_predictions.txt
06/24/2022 13:06:59 - INFO - __main__ - ACC on test data: 0.6520
06/24/2022 13:06:59 - INFO - __main__ - prefix=glue-mrpc_16_100, lr=0.0003, bsz=8, dev_performance=0.59375, test_performance=0.6519607843137255
06/24/2022 13:06:59 - INFO - __main__ - Running ... prefix=glue-mrpc_16_100, lr=0.0002, bsz=8 ...
06/24/2022 13:07:00 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:07:00 - INFO - __main__ - Printing 3 examples
06/24/2022 13:07:00 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:07:00 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:07:00 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:07:00 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:07:00 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:07:00 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:07:00 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:07:00 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:07:00 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:07:00 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:07:00 - INFO - __main__ - Printing 3 examples
06/24/2022 13:07:00 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:07:00 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:07:00 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:07:00 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:07:00 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:07:00 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:07:00 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:07:00 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:07:00 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:07:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:07:04 - INFO - __main__ - Starting training!
06/24/2022 13:07:06 - INFO - __main__ - Step 10 Global step 10 Train loss 15.947950 on epoch=4
06/24/2022 13:07:08 - INFO - __main__ - Step 20 Global step 20 Train loss 13.376551 on epoch=9
06/24/2022 13:07:11 - INFO - __main__ - Step 30 Global step 30 Train loss 7.978387 on epoch=14
06/24/2022 13:07:13 - INFO - __main__ - Step 40 Global step 40 Train loss 6.754299 on epoch=19
06/24/2022 13:07:16 - INFO - __main__ - Step 50 Global step 50 Train loss 5.323020 on epoch=24
06/24/2022 13:07:17 - INFO - __main__ - Global step 50 Train loss 9.876041 ACC 0.0 on epoch=24
06/24/2022 13:07:20 - INFO - __main__ - Step 60 Global step 60 Train loss 4.365619 on epoch=29
06/24/2022 13:07:22 - INFO - __main__ - Step 70 Global step 70 Train loss 3.853290 on epoch=34
06/24/2022 13:07:24 - INFO - __main__ - Step 80 Global step 80 Train loss 3.630177 on epoch=39
06/24/2022 13:07:27 - INFO - __main__ - Step 90 Global step 90 Train loss 2.222097 on epoch=44
06/24/2022 13:07:30 - INFO - __main__ - Step 100 Global step 100 Train loss 1.805123 on epoch=49
06/24/2022 13:07:30 - INFO - __main__ - Global step 100 Train loss 3.175261 ACC 0.5 on epoch=49
06/24/2022 13:07:33 - INFO - __main__ - Step 110 Global step 110 Train loss 1.559830 on epoch=54
06/24/2022 13:07:35 - INFO - __main__ - Step 120 Global step 120 Train loss 1.233554 on epoch=59
06/24/2022 13:07:38 - INFO - __main__ - Step 130 Global step 130 Train loss 1.104978 on epoch=64
06/24/2022 13:07:40 - INFO - __main__ - Step 140 Global step 140 Train loss 1.239435 on epoch=69
06/24/2022 13:07:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.863762 on epoch=74
06/24/2022 13:07:43 - INFO - __main__ - Global step 150 Train loss 1.200312 ACC 0.46875 on epoch=74
06/24/2022 13:07:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.903449 on epoch=79
06/24/2022 13:07:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.632460 on epoch=84
06/24/2022 13:07:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.656910 on epoch=89
06/24/2022 13:07:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.528917 on epoch=94
06/24/2022 13:07:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.729220 on epoch=99
06/24/2022 13:07:56 - INFO - __main__ - Global step 200 Train loss 0.690192 ACC 0.5 on epoch=99
06/24/2022 13:07:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.474743 on epoch=104
06/24/2022 13:08:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.375693 on epoch=109
06/24/2022 13:08:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.608474 on epoch=114
06/24/2022 13:08:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.480587 on epoch=119
06/24/2022 13:08:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.334627 on epoch=124
06/24/2022 13:08:09 - INFO - __main__ - Global step 250 Train loss 0.454825 ACC 0.6875 on epoch=124
06/24/2022 13:08:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.359038 on epoch=129
06/24/2022 13:08:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.315003 on epoch=134
06/24/2022 13:08:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.321146 on epoch=139
06/24/2022 13:08:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.346055 on epoch=144
06/24/2022 13:08:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.282338 on epoch=149
06/24/2022 13:08:23 - INFO - __main__ - Global step 300 Train loss 0.324716 ACC 0.5625 on epoch=149
06/24/2022 13:08:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.264686 on epoch=154
06/24/2022 13:08:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.363930 on epoch=159
06/24/2022 13:08:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.357096 on epoch=164
06/24/2022 13:08:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.365043 on epoch=169
06/24/2022 13:08:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.209361 on epoch=174
06/24/2022 13:08:36 - INFO - __main__ - Global step 350 Train loss 0.312023 ACC 0.53125 on epoch=174
06/24/2022 13:08:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.172649 on epoch=179
06/24/2022 13:08:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.176148 on epoch=184
06/24/2022 13:08:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.108987 on epoch=189
06/24/2022 13:08:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.117052 on epoch=194
06/24/2022 13:08:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.194501 on epoch=199
06/24/2022 13:08:49 - INFO - __main__ - Global step 400 Train loss 0.153867 ACC 0.59375 on epoch=199
06/24/2022 13:08:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.097054 on epoch=204
06/24/2022 13:08:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.075728 on epoch=209
06/24/2022 13:08:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.043926 on epoch=214
06/24/2022 13:08:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.036826 on epoch=219
06/24/2022 13:09:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.061828 on epoch=224
06/24/2022 13:09:02 - INFO - __main__ - Global step 450 Train loss 0.063072 ACC 0.59375 on epoch=224
06/24/2022 13:09:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.020010 on epoch=229
06/24/2022 13:09:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.048801 on epoch=234
06/24/2022 13:09:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.071162 on epoch=239
06/24/2022 13:09:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.010295 on epoch=244
06/24/2022 13:09:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.062454 on epoch=249
06/24/2022 13:09:15 - INFO - __main__ - Global step 500 Train loss 0.042544 ACC 0.5625 on epoch=249
06/24/2022 13:09:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.034448 on epoch=254
06/24/2022 13:09:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.066116 on epoch=259
06/24/2022 13:09:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.135928 on epoch=264
06/24/2022 13:09:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.023895 on epoch=269
06/24/2022 13:09:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.011429 on epoch=274
06/24/2022 13:09:28 - INFO - __main__ - Global step 550 Train loss 0.054363 ACC 0.625 on epoch=274
06/24/2022 13:09:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.059420 on epoch=279
06/24/2022 13:09:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.031220 on epoch=284
06/24/2022 13:09:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.045169 on epoch=289
06/24/2022 13:09:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.033160 on epoch=294
06/24/2022 13:09:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.018512 on epoch=299
06/24/2022 13:09:41 - INFO - __main__ - Global step 600 Train loss 0.037496 ACC 0.65625 on epoch=299
06/24/2022 13:09:41 - INFO - __main__ - save last model!
06/24/2022 13:09:41 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:09:41 - INFO - __main__ - Printing 3 examples
06/24/2022 13:09:41 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:09:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:41 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:09:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:41 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:09:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:41 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:09:41 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:09:41 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:09:41 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:09:41 - INFO - __main__ - Printing 3 examples
06/24/2022 13:09:41 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:09:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:41 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:09:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:41 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:09:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:41 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:09:41 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:09:41 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:09:43 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:09:44 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:09:44 - INFO - __main__ - Printing 3 examples
06/24/2022 13:09:44 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:09:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:09:44 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:09:44 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:44 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:09:44 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:09:44 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:09:44 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:09:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:09:45 - INFO - __main__ - Starting training!
06/24/2022 13:09:49 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_100_0.0002_8_predictions.txt
06/24/2022 13:09:49 - INFO - __main__ - ACC on test data: 0.4534
06/24/2022 13:09:49 - INFO - __main__ - prefix=glue-mrpc_16_100, lr=0.0002, bsz=8, dev_performance=0.6875, test_performance=0.4534313725490196
06/24/2022 13:09:49 - INFO - __main__ - Running ... prefix=glue-mrpc_16_100, lr=0.0001, bsz=8 ...
06/24/2022 13:09:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:09:50 - INFO - __main__ - Printing 3 examples
06/24/2022 13:09:50 - INFO - __main__ -  [glue-mrpc] sentence 1: In court papers filed Tuesday , Lee asked for an injunction against Viacom 's use of the name , saying he had never given his consent for it to be used . [SEP] sentence 2: In papers filed Tuesday in Manhattan 's state Supreme Court , Lee asked for an injunction against Viacom 's use of the name Spike for TNN .
06/24/2022 13:09:50 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:50 - INFO - __main__ -  [glue-mrpc] sentence 1: Lt. Scotty Smither , a county firefighter , was struck by lightning . [SEP] sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .
06/24/2022 13:09:50 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:50 - INFO - __main__ -  [glue-mrpc] sentence 1: " These are defining moments for players and organizations , " Anaheim coach Mike Babcock said . [SEP] sentence 2: " There are defining moments for players and organizations where you are measured .
06/24/2022 13:09:50 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:50 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:09:50 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:09:50 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:09:50 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:09:50 - INFO - __main__ - Printing 3 examples
06/24/2022 13:09:50 - INFO - __main__ -  [glue-mrpc] sentence 1: The hall will be home to the Los Angeles Philharmonic and the LA Master Chorale . [SEP] sentence 2: The Los Angeles Master Chorale and the Los Angeles Philharmonic Brass Ensemble also performed .
06/24/2022 13:09:50 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:51 - INFO - __main__ -  [glue-mrpc] sentence 1: She appeared in federal court there Monday and was expected to be transferred to Houston in two weeks . [SEP] sentence 2: Holloway surrendered in Cleveland on Friday and was expected to be transferred to Houston in two weeks .
06/24/2022 13:09:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:51 - INFO - __main__ -  [glue-mrpc] sentence 1: Against the Swiss franc CHF = , the dollar was at 1.3172 francs , down 0.60 percent . [SEP] sentence 2: Against the yen the dollar was down 0.7 percent at 110.73 yen .
06/24/2022 13:09:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:09:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:09:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:09:51 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:09:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:09:54 - INFO - __main__ - Starting training!
06/24/2022 13:09:56 - INFO - __main__ - Step 10 Global step 10 Train loss 15.700514 on epoch=4
06/24/2022 13:09:59 - INFO - __main__ - Step 20 Global step 20 Train loss 13.980951 on epoch=9
06/24/2022 13:10:01 - INFO - __main__ - Step 30 Global step 30 Train loss 12.288737 on epoch=14
06/24/2022 13:10:03 - INFO - __main__ - Step 40 Global step 40 Train loss 8.914417 on epoch=19
06/24/2022 13:10:06 - INFO - __main__ - Step 50 Global step 50 Train loss 7.622079 on epoch=24
06/24/2022 13:10:08 - INFO - __main__ - Global step 50 Train loss 11.701339 ACC 0.0 on epoch=24
06/24/2022 13:10:11 - INFO - __main__ - Step 60 Global step 60 Train loss 7.070422 on epoch=29
06/24/2022 13:10:14 - INFO - __main__ - Step 70 Global step 70 Train loss 6.704043 on epoch=34
06/24/2022 13:10:16 - INFO - __main__ - Step 80 Global step 80 Train loss 6.262274 on epoch=39
06/24/2022 13:10:18 - INFO - __main__ - Step 90 Global step 90 Train loss 5.863819 on epoch=44
06/24/2022 13:10:21 - INFO - __main__ - Step 100 Global step 100 Train loss 5.197189 on epoch=49
06/24/2022 13:10:21 - INFO - __main__ - Global step 100 Train loss 6.219550 ACC 0.15625 on epoch=49
06/24/2022 13:10:24 - INFO - __main__ - Step 110 Global step 110 Train loss 4.770746 on epoch=54
06/24/2022 13:10:27 - INFO - __main__ - Step 120 Global step 120 Train loss 4.276522 on epoch=59
06/24/2022 13:10:29 - INFO - __main__ - Step 130 Global step 130 Train loss 4.130580 on epoch=64
06/24/2022 13:10:32 - INFO - __main__ - Step 140 Global step 140 Train loss 3.852044 on epoch=69
06/24/2022 13:10:34 - INFO - __main__ - Step 150 Global step 150 Train loss 3.560636 on epoch=74
06/24/2022 13:10:35 - INFO - __main__ - Global step 150 Train loss 4.118106 ACC 0.21875 on epoch=74
06/24/2022 13:10:37 - INFO - __main__ - Step 160 Global step 160 Train loss 3.589387 on epoch=79
06/24/2022 13:10:40 - INFO - __main__ - Step 170 Global step 170 Train loss 3.184564 on epoch=84
06/24/2022 13:10:42 - INFO - __main__ - Step 180 Global step 180 Train loss 2.632162 on epoch=89
06/24/2022 13:10:45 - INFO - __main__ - Step 190 Global step 190 Train loss 2.493997 on epoch=94
06/24/2022 13:10:47 - INFO - __main__ - Step 200 Global step 200 Train loss 2.274417 on epoch=99
06/24/2022 13:10:47 - INFO - __main__ - Global step 200 Train loss 2.834906 ACC 0.5 on epoch=99
06/24/2022 13:10:50 - INFO - __main__ - Step 210 Global step 210 Train loss 1.862114 on epoch=104
06/24/2022 13:10:53 - INFO - __main__ - Step 220 Global step 220 Train loss 2.152361 on epoch=109
06/24/2022 13:10:55 - INFO - __main__ - Step 230 Global step 230 Train loss 1.920807 on epoch=114
06/24/2022 13:10:58 - INFO - __main__ - Step 240 Global step 240 Train loss 1.736175 on epoch=119
06/24/2022 13:11:00 - INFO - __main__ - Step 250 Global step 250 Train loss 1.551162 on epoch=124
06/24/2022 13:11:01 - INFO - __main__ - Global step 250 Train loss 1.844524 ACC 0.5 on epoch=124
06/24/2022 13:11:03 - INFO - __main__ - Step 260 Global step 260 Train loss 1.542275 on epoch=129
06/24/2022 13:11:06 - INFO - __main__ - Step 270 Global step 270 Train loss 1.803636 on epoch=134
06/24/2022 13:11:08 - INFO - __main__ - Step 280 Global step 280 Train loss 1.419750 on epoch=139
06/24/2022 13:11:11 - INFO - __main__ - Step 290 Global step 290 Train loss 1.409351 on epoch=144
06/24/2022 13:11:13 - INFO - __main__ - Step 300 Global step 300 Train loss 1.146216 on epoch=149
06/24/2022 13:11:13 - INFO - __main__ - Global step 300 Train loss 1.464246 ACC 0.5 on epoch=149
06/24/2022 13:11:16 - INFO - __main__ - Step 310 Global step 310 Train loss 1.332970 on epoch=154
06/24/2022 13:11:18 - INFO - __main__ - Step 320 Global step 320 Train loss 1.217557 on epoch=159
06/24/2022 13:11:21 - INFO - __main__ - Step 330 Global step 330 Train loss 1.111411 on epoch=164
06/24/2022 13:11:23 - INFO - __main__ - Step 340 Global step 340 Train loss 1.125092 on epoch=169
06/24/2022 13:11:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.803813 on epoch=174
06/24/2022 13:11:26 - INFO - __main__ - Global step 350 Train loss 1.118169 ACC 0.5 on epoch=174
06/24/2022 13:11:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.847276 on epoch=179
06/24/2022 13:11:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.810549 on epoch=184
06/24/2022 13:11:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.673797 on epoch=189
06/24/2022 13:11:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.538370 on epoch=194
06/24/2022 13:11:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.776575 on epoch=199
06/24/2022 13:11:39 - INFO - __main__ - Global step 400 Train loss 0.729313 ACC 0.625 on epoch=199
06/24/2022 13:11:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.820401 on epoch=204
06/24/2022 13:11:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.699943 on epoch=209
06/24/2022 13:11:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.792334 on epoch=214
06/24/2022 13:11:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.597704 on epoch=219
06/24/2022 13:11:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.588973 on epoch=224
06/24/2022 13:11:52 - INFO - __main__ - Global step 450 Train loss 0.699871 ACC 0.53125 on epoch=224
06/24/2022 13:11:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.427345 on epoch=229
06/24/2022 13:11:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.470591 on epoch=234
06/24/2022 13:11:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.448708 on epoch=239
06/24/2022 13:12:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.391758 on epoch=244
06/24/2022 13:12:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.665138 on epoch=249
06/24/2022 13:12:04 - INFO - __main__ - Global step 500 Train loss 0.480708 ACC 0.53125 on epoch=249
06/24/2022 13:12:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.649415 on epoch=254
06/24/2022 13:12:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.487022 on epoch=259
06/24/2022 13:12:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.447560 on epoch=264
06/24/2022 13:12:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.309363 on epoch=269
06/24/2022 13:12:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.359781 on epoch=274
06/24/2022 13:12:17 - INFO - __main__ - Global step 550 Train loss 0.450628 ACC 0.5625 on epoch=274
06/24/2022 13:12:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.487611 on epoch=279
06/24/2022 13:12:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.597439 on epoch=284
06/24/2022 13:12:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.414053 on epoch=289
06/24/2022 13:12:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.478989 on epoch=294
06/24/2022 13:12:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.351843 on epoch=299
06/24/2022 13:12:30 - INFO - __main__ - Global step 600 Train loss 0.465987 ACC 0.5625 on epoch=299
06/24/2022 13:12:30 - INFO - __main__ - save last model!
06/24/2022 13:12:30 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:12:30 - INFO - __main__ - Printing 3 examples
06/24/2022 13:12:30 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:12:30 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:30 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:12:30 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:30 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:12:30 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:30 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:12:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:12:31 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:12:31 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:12:31 - INFO - __main__ - Printing 3 examples
06/24/2022 13:12:31 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:12:31 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:31 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:12:31 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:31 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:12:31 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:31 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:12:31 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:12:31 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:12:32 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:12:33 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:12:33 - INFO - __main__ - Printing 3 examples
06/24/2022 13:12:33 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:12:33 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:33 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:12:33 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:12:33 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:12:33 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:12:33 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:12:33 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:12:33 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:12:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:12:34 - INFO - __main__ - Starting training!
06/24/2022 13:12:38 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_100_0.0001_8_predictions.txt
06/24/2022 13:12:38 - INFO - __main__ - ACC on test data: 0.4828
06/24/2022 13:12:39 - INFO - __main__ - prefix=glue-mrpc_16_100, lr=0.0001, bsz=8, dev_performance=0.625, test_performance=0.48284313725490197
06/24/2022 13:12:39 - INFO - __main__ - Running ... prefix=glue-mrpc_16_13, lr=0.0005, bsz=8 ...
06/24/2022 13:12:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:12:40 - INFO - __main__ - Printing 3 examples
06/24/2022 13:12:40 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:12:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:40 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:12:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:40 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:12:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:12:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:12:40 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:12:40 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:12:40 - INFO - __main__ - Printing 3 examples
06/24/2022 13:12:40 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:12:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:40 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:12:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:40 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:12:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:12:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:12:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:12:40 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:12:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:12:43 - INFO - __main__ - Starting training!
06/24/2022 13:12:45 - INFO - __main__ - Step 10 Global step 10 Train loss 16.250891 on epoch=4
06/24/2022 13:12:48 - INFO - __main__ - Step 20 Global step 20 Train loss 12.012247 on epoch=9
06/24/2022 13:12:50 - INFO - __main__ - Step 30 Global step 30 Train loss 6.830044 on epoch=14
06/24/2022 13:12:53 - INFO - __main__ - Step 40 Global step 40 Train loss 4.600336 on epoch=19
06/24/2022 13:12:55 - INFO - __main__ - Step 50 Global step 50 Train loss 3.668097 on epoch=24
06/24/2022 13:12:56 - INFO - __main__ - Global step 50 Train loss 8.672323 ACC 0.3125 on epoch=24
06/24/2022 13:12:59 - INFO - __main__ - Step 60 Global step 60 Train loss 2.788155 on epoch=29
06/24/2022 13:13:01 - INFO - __main__ - Step 70 Global step 70 Train loss 1.727443 on epoch=34
06/24/2022 13:13:04 - INFO - __main__ - Step 80 Global step 80 Train loss 1.929770 on epoch=39
06/24/2022 13:13:06 - INFO - __main__ - Step 90 Global step 90 Train loss 1.407163 on epoch=44
06/24/2022 13:13:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.916625 on epoch=49
06/24/2022 13:13:09 - INFO - __main__ - Global step 100 Train loss 1.753832 ACC 0.5 on epoch=49
06/24/2022 13:13:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.722805 on epoch=54
06/24/2022 13:13:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.607715 on epoch=59
06/24/2022 13:13:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.697580 on epoch=64
06/24/2022 13:13:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.509464 on epoch=69
06/24/2022 13:13:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.698256 on epoch=74
06/24/2022 13:13:22 - INFO - __main__ - Global step 150 Train loss 0.647164 ACC 0.59375 on epoch=74
06/24/2022 13:13:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.768704 on epoch=79
06/24/2022 13:13:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.643544 on epoch=84
06/24/2022 13:13:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.631276 on epoch=89
06/24/2022 13:13:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.508205 on epoch=94
06/24/2022 13:13:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.467354 on epoch=99
06/24/2022 13:13:35 - INFO - __main__ - Global step 200 Train loss 0.603817 ACC 0.375 on epoch=99
06/24/2022 13:13:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.519869 on epoch=104
06/24/2022 13:13:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.464909 on epoch=109
06/24/2022 13:13:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.433371 on epoch=114
06/24/2022 13:13:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.539843 on epoch=119
06/24/2022 13:13:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.557467 on epoch=124
06/24/2022 13:13:48 - INFO - __main__ - Global step 250 Train loss 0.503092 ACC 0.53125 on epoch=124
06/24/2022 13:13:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.489164 on epoch=129
06/24/2022 13:13:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.374028 on epoch=134
06/24/2022 13:13:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.475245 on epoch=139
06/24/2022 13:13:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.415912 on epoch=144
06/24/2022 13:14:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.438812 on epoch=149
06/24/2022 13:14:00 - INFO - __main__ - Global step 300 Train loss 0.438632 ACC 0.5625 on epoch=149
06/24/2022 13:14:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.506268 on epoch=154
06/24/2022 13:14:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.388625 on epoch=159
06/24/2022 13:14:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.438347 on epoch=164
06/24/2022 13:14:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.532155 on epoch=169
06/24/2022 13:14:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.281507 on epoch=174
06/24/2022 13:14:13 - INFO - __main__ - Global step 350 Train loss 0.429380 ACC 0.5 on epoch=174
06/24/2022 13:14:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.301832 on epoch=179
06/24/2022 13:14:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.255444 on epoch=184
06/24/2022 13:14:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.309653 on epoch=189
06/24/2022 13:14:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.400428 on epoch=194
06/24/2022 13:14:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.264118 on epoch=199
06/24/2022 13:14:26 - INFO - __main__ - Global step 400 Train loss 0.306295 ACC 0.46875 on epoch=199
06/24/2022 13:14:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.273768 on epoch=204
06/24/2022 13:14:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.266306 on epoch=209
06/24/2022 13:14:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.316668 on epoch=214
06/24/2022 13:14:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.294442 on epoch=219
06/24/2022 13:14:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.249058 on epoch=224
06/24/2022 13:14:38 - INFO - __main__ - Global step 450 Train loss 0.280049 ACC 0.53125 on epoch=224
06/24/2022 13:14:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.254714 on epoch=229
06/24/2022 13:14:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.336856 on epoch=234
06/24/2022 13:14:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.248281 on epoch=239
06/24/2022 13:14:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.262826 on epoch=244
06/24/2022 13:14:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.249474 on epoch=249
06/24/2022 13:14:51 - INFO - __main__ - Global step 500 Train loss 0.270430 ACC 0.53125 on epoch=249
06/24/2022 13:14:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.263767 on epoch=254
06/24/2022 13:14:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.249875 on epoch=259
06/24/2022 13:14:59 - INFO - __main__ - Step 530 Global step 530 Train loss 0.267393 on epoch=264
06/24/2022 13:15:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.233044 on epoch=269
06/24/2022 13:15:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.146698 on epoch=274
06/24/2022 13:15:04 - INFO - __main__ - Global step 550 Train loss 0.232156 ACC 0.4375 on epoch=274
06/24/2022 13:15:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.210126 on epoch=279
06/24/2022 13:15:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.171009 on epoch=284
06/24/2022 13:15:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.177165 on epoch=289
06/24/2022 13:15:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.144729 on epoch=294
06/24/2022 13:15:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.125816 on epoch=299
06/24/2022 13:15:16 - INFO - __main__ - Global step 600 Train loss 0.165769 ACC 0.4375 on epoch=299
06/24/2022 13:15:16 - INFO - __main__ - save last model!
06/24/2022 13:15:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:15:17 - INFO - __main__ - Printing 3 examples
06/24/2022 13:15:17 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:15:17 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:17 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:15:17 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:17 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:15:17 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:17 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:15:17 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:15:17 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:15:17 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:15:17 - INFO - __main__ - Printing 3 examples
06/24/2022 13:15:17 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:15:17 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:17 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:15:17 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:17 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:15:17 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:17 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:15:17 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:15:17 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:15:19 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:15:19 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:15:19 - INFO - __main__ - Printing 3 examples
06/24/2022 13:15:19 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:15:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:19 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:15:19 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:15:19 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:15:19 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:15:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:15:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:15:20 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:15:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:15:22 - INFO - __main__ - Starting training!
06/24/2022 13:15:26 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_13_0.0005_8_predictions.txt
06/24/2022 13:15:26 - INFO - __main__ - ACC on test data: 0.4632
06/24/2022 13:15:26 - INFO - __main__ - prefix=glue-mrpc_16_13, lr=0.0005, bsz=8, dev_performance=0.59375, test_performance=0.4632352941176471
06/24/2022 13:15:26 - INFO - __main__ - Running ... prefix=glue-mrpc_16_13, lr=0.0003, bsz=8 ...
06/24/2022 13:15:27 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:15:27 - INFO - __main__ - Printing 3 examples
06/24/2022 13:15:27 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:15:27 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:27 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:15:27 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:27 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:15:27 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:27 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:15:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:15:27 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:15:27 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:15:27 - INFO - __main__ - Printing 3 examples
06/24/2022 13:15:27 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:15:27 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:27 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:15:27 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:27 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:15:27 - INFO - __main__ - ['equivalent']
06/24/2022 13:15:27 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:15:27 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:15:27 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:15:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:15:31 - INFO - __main__ - Starting training!
06/24/2022 13:15:33 - INFO - __main__ - Step 10 Global step 10 Train loss 16.649475 on epoch=4
06/24/2022 13:15:35 - INFO - __main__ - Step 20 Global step 20 Train loss 12.060805 on epoch=9
06/24/2022 13:15:37 - INFO - __main__ - Step 30 Global step 30 Train loss 8.614456 on epoch=14
06/24/2022 13:15:40 - INFO - __main__ - Step 40 Global step 40 Train loss 6.940703 on epoch=19
06/24/2022 13:15:42 - INFO - __main__ - Step 50 Global step 50 Train loss 4.883762 on epoch=24
06/24/2022 13:15:43 - INFO - __main__ - Global step 50 Train loss 9.829841 ACC 0.0625 on epoch=24
06/24/2022 13:15:45 - INFO - __main__ - Step 60 Global step 60 Train loss 3.811897 on epoch=29
06/24/2022 13:15:48 - INFO - __main__ - Step 70 Global step 70 Train loss 3.446158 on epoch=34
06/24/2022 13:15:50 - INFO - __main__ - Step 80 Global step 80 Train loss 2.458899 on epoch=39
06/24/2022 13:15:53 - INFO - __main__ - Step 90 Global step 90 Train loss 2.746387 on epoch=44
06/24/2022 13:15:55 - INFO - __main__ - Step 100 Global step 100 Train loss 1.495736 on epoch=49
06/24/2022 13:15:56 - INFO - __main__ - Global step 100 Train loss 2.791815 ACC 0.5 on epoch=49
06/24/2022 13:15:59 - INFO - __main__ - Step 110 Global step 110 Train loss 1.302874 on epoch=54
06/24/2022 13:16:01 - INFO - __main__ - Step 120 Global step 120 Train loss 1.038483 on epoch=59
06/24/2022 13:16:04 - INFO - __main__ - Step 130 Global step 130 Train loss 1.098457 on epoch=64
06/24/2022 13:16:06 - INFO - __main__ - Step 140 Global step 140 Train loss 1.078774 on epoch=69
06/24/2022 13:16:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.867334 on epoch=74
06/24/2022 13:16:09 - INFO - __main__ - Global step 150 Train loss 1.077185 ACC 0.5 on epoch=74
06/24/2022 13:16:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.840120 on epoch=79
06/24/2022 13:16:14 - INFO - __main__ - Step 170 Global step 170 Train loss 1.014433 on epoch=84
06/24/2022 13:16:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.694789 on epoch=89
06/24/2022 13:16:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.742606 on epoch=94
06/24/2022 13:16:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.739459 on epoch=99
06/24/2022 13:16:22 - INFO - __main__ - Global step 200 Train loss 0.806281 ACC 0.53125 on epoch=99
06/24/2022 13:16:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.436763 on epoch=104
06/24/2022 13:16:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.795800 on epoch=109
06/24/2022 13:16:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.657723 on epoch=114
06/24/2022 13:16:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.506854 on epoch=119
06/24/2022 13:16:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.590037 on epoch=124
06/24/2022 13:16:35 - INFO - __main__ - Global step 250 Train loss 0.597435 ACC 0.53125 on epoch=124
06/24/2022 13:16:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.567879 on epoch=129
06/24/2022 13:16:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.421712 on epoch=134
06/24/2022 13:16:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.736990 on epoch=139
06/24/2022 13:16:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.563351 on epoch=144
06/24/2022 13:16:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.564739 on epoch=149
06/24/2022 13:16:48 - INFO - __main__ - Global step 300 Train loss 0.570934 ACC 0.5 on epoch=149
06/24/2022 13:16:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.582952 on epoch=154
06/24/2022 13:16:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.479042 on epoch=159
06/24/2022 13:16:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.416961 on epoch=164
06/24/2022 13:16:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.627742 on epoch=169
06/24/2022 13:17:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.468273 on epoch=174
06/24/2022 13:17:01 - INFO - __main__ - Global step 350 Train loss 0.514994 ACC 0.46875 on epoch=174
06/24/2022 13:17:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.550319 on epoch=179
06/24/2022 13:17:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.522378 on epoch=184
06/24/2022 13:17:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.551243 on epoch=189
06/24/2022 13:17:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.384563 on epoch=194
06/24/2022 13:17:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.522462 on epoch=199
06/24/2022 13:17:14 - INFO - __main__ - Global step 400 Train loss 0.506193 ACC 0.5 on epoch=199
06/24/2022 13:17:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.584971 on epoch=204
06/24/2022 13:17:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.475546 on epoch=209
06/24/2022 13:17:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.504078 on epoch=214
06/24/2022 13:17:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.448386 on epoch=219
06/24/2022 13:17:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.435023 on epoch=224
06/24/2022 13:17:27 - INFO - __main__ - Global step 450 Train loss 0.489601 ACC 0.5 on epoch=224
06/24/2022 13:17:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.449661 on epoch=229
06/24/2022 13:17:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.392744 on epoch=234
06/24/2022 13:17:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.407468 on epoch=239
06/24/2022 13:17:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.353532 on epoch=244
06/24/2022 13:17:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.550309 on epoch=249
06/24/2022 13:17:40 - INFO - __main__ - Global step 500 Train loss 0.430743 ACC 0.46875 on epoch=249
06/24/2022 13:17:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.437259 on epoch=254
06/24/2022 13:17:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.422469 on epoch=259
06/24/2022 13:17:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.382512 on epoch=264
06/24/2022 13:17:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.485974 on epoch=269
06/24/2022 13:17:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.435183 on epoch=274
06/24/2022 13:17:53 - INFO - __main__ - Global step 550 Train loss 0.432680 ACC 0.5 on epoch=274
06/24/2022 13:17:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.321884 on epoch=279
06/24/2022 13:17:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.532016 on epoch=284
06/24/2022 13:18:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.340597 on epoch=289
06/24/2022 13:18:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.389981 on epoch=294
06/24/2022 13:18:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.387072 on epoch=299
06/24/2022 13:18:06 - INFO - __main__ - Global step 600 Train loss 0.394310 ACC 0.5625 on epoch=299
06/24/2022 13:18:06 - INFO - __main__ - save last model!
06/24/2022 13:18:06 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:18:06 - INFO - __main__ - Printing 3 examples
06/24/2022 13:18:06 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:18:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:06 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:18:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:06 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:18:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:06 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:18:07 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:18:07 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:18:07 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:18:07 - INFO - __main__ - Printing 3 examples
06/24/2022 13:18:07 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:18:07 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:07 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:18:07 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:07 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:18:07 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:07 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:18:07 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:18:07 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:18:09 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:18:09 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:18:09 - INFO - __main__ - Printing 3 examples
06/24/2022 13:18:09 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:18:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:09 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:18:09 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:18:09 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:18:09 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:18:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:18:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:18:10 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:18:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:18:11 - INFO - __main__ - Starting training!
06/24/2022 13:18:15 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_13_0.0003_8_predictions.txt
06/24/2022 13:18:15 - INFO - __main__ - ACC on test data: 0.4485
06/24/2022 13:18:15 - INFO - __main__ - prefix=glue-mrpc_16_13, lr=0.0003, bsz=8, dev_performance=0.5625, test_performance=0.4485294117647059
06/24/2022 13:18:15 - INFO - __main__ - Running ... prefix=glue-mrpc_16_13, lr=0.0002, bsz=8 ...
06/24/2022 13:18:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:18:16 - INFO - __main__ - Printing 3 examples
06/24/2022 13:18:16 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:18:16 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:16 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:18:16 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:16 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:18:16 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:18:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:18:16 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:18:16 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:18:16 - INFO - __main__ - Printing 3 examples
06/24/2022 13:18:16 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:18:16 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:16 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:18:16 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:16 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:18:16 - INFO - __main__ - ['equivalent']
06/24/2022 13:18:16 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:18:16 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:18:16 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:18:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:18:20 - INFO - __main__ - Starting training!
06/24/2022 13:18:22 - INFO - __main__ - Step 10 Global step 10 Train loss 15.972918 on epoch=4
06/24/2022 13:18:24 - INFO - __main__ - Step 20 Global step 20 Train loss 13.872093 on epoch=9
06/24/2022 13:18:27 - INFO - __main__ - Step 30 Global step 30 Train loss 9.081735 on epoch=14
06/24/2022 13:18:29 - INFO - __main__ - Step 40 Global step 40 Train loss 7.423144 on epoch=19
06/24/2022 13:18:32 - INFO - __main__ - Step 50 Global step 50 Train loss 6.060874 on epoch=24
06/24/2022 13:18:33 - INFO - __main__ - Global step 50 Train loss 10.482153 ACC 0.09375 on epoch=24
06/24/2022 13:18:36 - INFO - __main__ - Step 60 Global step 60 Train loss 5.740721 on epoch=29
06/24/2022 13:18:38 - INFO - __main__ - Step 70 Global step 70 Train loss 4.539741 on epoch=34
06/24/2022 13:18:41 - INFO - __main__ - Step 80 Global step 80 Train loss 3.886717 on epoch=39
06/24/2022 13:18:43 - INFO - __main__ - Step 90 Global step 90 Train loss 2.995070 on epoch=44
06/24/2022 13:18:46 - INFO - __main__ - Step 100 Global step 100 Train loss 2.187322 on epoch=49
06/24/2022 13:18:46 - INFO - __main__ - Global step 100 Train loss 3.869914 ACC 0.5 on epoch=49
06/24/2022 13:18:49 - INFO - __main__ - Step 110 Global step 110 Train loss 2.055948 on epoch=54
06/24/2022 13:18:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.939883 on epoch=59
06/24/2022 13:18:54 - INFO - __main__ - Step 130 Global step 130 Train loss 1.513589 on epoch=64
06/24/2022 13:18:56 - INFO - __main__ - Step 140 Global step 140 Train loss 1.688634 on epoch=69
06/24/2022 13:18:59 - INFO - __main__ - Step 150 Global step 150 Train loss 1.309568 on epoch=74
06/24/2022 13:18:59 - INFO - __main__ - Global step 150 Train loss 1.701524 ACC 0.5 on epoch=74
06/24/2022 13:19:02 - INFO - __main__ - Step 160 Global step 160 Train loss 1.759523 on epoch=79
06/24/2022 13:19:04 - INFO - __main__ - Step 170 Global step 170 Train loss 1.277818 on epoch=84
06/24/2022 13:19:07 - INFO - __main__ - Step 180 Global step 180 Train loss 1.191850 on epoch=89
06/24/2022 13:19:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.893156 on epoch=94
06/24/2022 13:19:12 - INFO - __main__ - Step 200 Global step 200 Train loss 1.076413 on epoch=99
06/24/2022 13:19:12 - INFO - __main__ - Global step 200 Train loss 1.239752 ACC 0.5 on epoch=99
06/24/2022 13:19:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.916139 on epoch=104
06/24/2022 13:19:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.896207 on epoch=109
06/24/2022 13:19:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.571176 on epoch=114
06/24/2022 13:19:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.695814 on epoch=119
06/24/2022 13:19:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.607266 on epoch=124
06/24/2022 13:19:25 - INFO - __main__ - Global step 250 Train loss 0.737320 ACC 0.5 on epoch=124
06/24/2022 13:19:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.609997 on epoch=129
06/24/2022 13:19:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.564872 on epoch=134
06/24/2022 13:19:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.355903 on epoch=139
06/24/2022 13:19:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.606620 on epoch=144
06/24/2022 13:19:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.465142 on epoch=149
06/24/2022 13:19:38 - INFO - __main__ - Global step 300 Train loss 0.520507 ACC 0.5 on epoch=149
06/24/2022 13:19:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.474429 on epoch=154
06/24/2022 13:19:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.474934 on epoch=159
06/24/2022 13:19:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.389654 on epoch=164
06/24/2022 13:19:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.513131 on epoch=169
06/24/2022 13:19:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.406778 on epoch=174
06/24/2022 13:19:51 - INFO - __main__ - Global step 350 Train loss 0.451785 ACC 0.5 on epoch=174
06/24/2022 13:19:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.470969 on epoch=179
06/24/2022 13:19:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.383301 on epoch=184
06/24/2022 13:19:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.330787 on epoch=189
06/24/2022 13:20:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.349108 on epoch=194
06/24/2022 13:20:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.212886 on epoch=199
06/24/2022 13:20:04 - INFO - __main__ - Global step 400 Train loss 0.349410 ACC 0.53125 on epoch=199
06/24/2022 13:20:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.309599 on epoch=204
06/24/2022 13:20:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.363313 on epoch=209
06/24/2022 13:20:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.233756 on epoch=214
06/24/2022 13:20:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.257287 on epoch=219
06/24/2022 13:20:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.231830 on epoch=224
06/24/2022 13:20:17 - INFO - __main__ - Global step 450 Train loss 0.279157 ACC 0.5625 on epoch=224
06/24/2022 13:20:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.220015 on epoch=229
06/24/2022 13:20:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.175791 on epoch=234
06/24/2022 13:20:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.248759 on epoch=239
06/24/2022 13:20:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.161878 on epoch=244
06/24/2022 13:20:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.168833 on epoch=249
06/24/2022 13:20:30 - INFO - __main__ - Global step 500 Train loss 0.195055 ACC 0.53125 on epoch=249
06/24/2022 13:20:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.160236 on epoch=254
06/24/2022 13:20:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.147328 on epoch=259
06/24/2022 13:20:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.143753 on epoch=264
06/24/2022 13:20:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.104383 on epoch=269
06/24/2022 13:20:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.136429 on epoch=274
06/24/2022 13:20:43 - INFO - __main__ - Global step 550 Train loss 0.138426 ACC 0.53125 on epoch=274
06/24/2022 13:20:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.113761 on epoch=279
06/24/2022 13:20:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.128451 on epoch=284
06/24/2022 13:20:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.026913 on epoch=289
06/24/2022 13:20:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.038289 on epoch=294
06/24/2022 13:20:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.064677 on epoch=299
06/24/2022 13:20:56 - INFO - __main__ - Global step 600 Train loss 0.074418 ACC 0.5625 on epoch=299
06/24/2022 13:20:56 - INFO - __main__ - save last model!
06/24/2022 13:20:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:20:57 - INFO - __main__ - Printing 3 examples
06/24/2022 13:20:57 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:20:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:57 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:20:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:57 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:20:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:20:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:20:57 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:20:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:20:57 - INFO - __main__ - Printing 3 examples
06/24/2022 13:20:57 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:20:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:57 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:20:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:57 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:20:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:20:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:20:57 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:20:59 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:20:59 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:20:59 - INFO - __main__ - Printing 3 examples
06/24/2022 13:20:59 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:20:59 - INFO - __main__ - ['equivalent']
06/24/2022 13:20:59 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:20:59 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:20:59 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:20:59 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:20:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:20:59 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:21:00 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:21:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:21:01 - INFO - __main__ - Starting training!
06/24/2022 13:21:05 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_13_0.0002_8_predictions.txt
06/24/2022 13:21:05 - INFO - __main__ - ACC on test data: 0.6593
06/24/2022 13:21:05 - INFO - __main__ - prefix=glue-mrpc_16_13, lr=0.0002, bsz=8, dev_performance=0.5625, test_performance=0.6593137254901961
06/24/2022 13:21:05 - INFO - __main__ - Running ... prefix=glue-mrpc_16_13, lr=0.0001, bsz=8 ...
06/24/2022 13:21:06 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:21:06 - INFO - __main__ - Printing 3 examples
06/24/2022 13:21:06 - INFO - __main__ -  [glue-mrpc] sentence 1: The court 's 1992 decision reaffirmed the basic findings of Roe protecting abortion choice but lessened the standards of protection guaranteed to women by Roe . [SEP] sentence 2: In a 1992 case , the Supreme Court reaffirmed the basic findings of Roe protecting abortion choice , but lessened the standards of protection guaranteed to women by Roe .
06/24/2022 13:21:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:21:06 - INFO - __main__ -  [glue-mrpc] sentence 1: Several cities are competing for the headquarters , including Miami ; Panama City ; Atlanta ; Port-of-Spain , Trinidad ; and Puebla , Mexico . [SEP] sentence 2: But Miami is competing with eight other cities , including Atlanta ; Panama City ; Port-of-Spain , Trinidad ; and Cancn , Mexico .
06/24/2022 13:21:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:21:06 - INFO - __main__ -  [glue-mrpc] sentence 1: Feral 's group was behind a successful tourism boycott about a decade ago that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 . [SEP] sentence 2: Friends of Animals , which touts 200,000 members , was behind a successful tourism boycott that resulted in then-Gov . Walter J. Hickel imposing a moratorium on wolf control in 1992 .
06/24/2022 13:21:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:21:06 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:21:06 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:21:06 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:21:06 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:21:06 - INFO - __main__ - Printing 3 examples
06/24/2022 13:21:06 - INFO - __main__ -  [glue-mrpc] sentence 1: The retailer said it came to the decision after hearing the opinions of customers and associates . [SEP] sentence 2: The decision came after " listening to our customers and associates , " Melissa Berryhill , a spokeswoman for Wal-Mart , said .
06/24/2022 13:21:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:21:06 - INFO - __main__ -  [glue-mrpc] sentence 1: The vast majority of trades will be priced at 20 cents per contract or less depending on participation in incentive schemes . " [SEP] sentence 2: Eurex said " the vast majority " of trades on Eurex US would be priced at 20 cents per contract or less depending on " participation in incentive schemes " .
06/24/2022 13:21:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:21:06 - INFO - __main__ -  [glue-mrpc] sentence 1: A grief-stricken old woman , disconsolate with grief , smeared her face with dirt , uttering : " My child , my child . " [SEP] sentence 2: One old woman , disconsolate with grief , smeared her face with dirt , only able to utter : " My child , my child . "
06/24/2022 13:21:06 - INFO - __main__ - ['equivalent']
06/24/2022 13:21:06 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:21:06 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:21:06 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:21:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:21:10 - INFO - __main__ - Starting training!
06/24/2022 13:21:12 - INFO - __main__ - Step 10 Global step 10 Train loss 16.569094 on epoch=4
06/24/2022 13:21:14 - INFO - __main__ - Step 20 Global step 20 Train loss 14.411240 on epoch=9
06/24/2022 13:21:17 - INFO - __main__ - Step 30 Global step 30 Train loss 10.153823 on epoch=14
06/24/2022 13:21:19 - INFO - __main__ - Step 40 Global step 40 Train loss 8.524346 on epoch=19
06/24/2022 13:21:21 - INFO - __main__ - Step 50 Global step 50 Train loss 7.598200 on epoch=24
06/24/2022 13:21:25 - INFO - __main__ - Global step 50 Train loss 11.451341 ACC 0.0 on epoch=24
06/24/2022 13:21:27 - INFO - __main__ - Step 60 Global step 60 Train loss 7.008420 on epoch=29
06/24/2022 13:21:30 - INFO - __main__ - Step 70 Global step 70 Train loss 6.250839 on epoch=34
06/24/2022 13:21:32 - INFO - __main__ - Step 80 Global step 80 Train loss 5.965562 on epoch=39
06/24/2022 13:21:35 - INFO - __main__ - Step 90 Global step 90 Train loss 5.431690 on epoch=44
06/24/2022 13:21:37 - INFO - __main__ - Step 100 Global step 100 Train loss 5.073416 on epoch=49
06/24/2022 13:21:38 - INFO - __main__ - Global step 100 Train loss 5.945986 ACC 0.21875 on epoch=49
06/24/2022 13:21:42 - INFO - __main__ - Step 110 Global step 110 Train loss 4.313345 on epoch=54
06/24/2022 13:21:44 - INFO - __main__ - Step 120 Global step 120 Train loss 4.593355 on epoch=59
06/24/2022 13:21:47 - INFO - __main__ - Step 130 Global step 130 Train loss 4.113497 on epoch=64
06/24/2022 13:21:49 - INFO - __main__ - Step 140 Global step 140 Train loss 3.992549 on epoch=69
06/24/2022 13:21:51 - INFO - __main__ - Step 150 Global step 150 Train loss 3.345209 on epoch=74
06/24/2022 13:21:52 - INFO - __main__ - Global step 150 Train loss 4.071591 ACC 0.34375 on epoch=74
06/24/2022 13:21:55 - INFO - __main__ - Step 160 Global step 160 Train loss 2.484226 on epoch=79
06/24/2022 13:21:57 - INFO - __main__ - Step 170 Global step 170 Train loss 3.633284 on epoch=84
06/24/2022 13:22:00 - INFO - __main__ - Step 180 Global step 180 Train loss 2.351732 on epoch=89
06/24/2022 13:22:02 - INFO - __main__ - Step 190 Global step 190 Train loss 3.048569 on epoch=94
06/24/2022 13:22:05 - INFO - __main__ - Step 200 Global step 200 Train loss 2.206678 on epoch=99
06/24/2022 13:22:05 - INFO - __main__ - Global step 200 Train loss 2.744898 ACC 0.5 on epoch=99
06/24/2022 13:22:08 - INFO - __main__ - Step 210 Global step 210 Train loss 1.397110 on epoch=104
06/24/2022 13:22:11 - INFO - __main__ - Step 220 Global step 220 Train loss 1.690982 on epoch=109
06/24/2022 13:22:13 - INFO - __main__ - Step 230 Global step 230 Train loss 1.646285 on epoch=114
06/24/2022 13:22:16 - INFO - __main__ - Step 240 Global step 240 Train loss 1.169910 on epoch=119
06/24/2022 13:22:18 - INFO - __main__ - Step 250 Global step 250 Train loss 1.224917 on epoch=124
06/24/2022 13:22:18 - INFO - __main__ - Global step 250 Train loss 1.425841 ACC 0.5 on epoch=124
06/24/2022 13:22:21 - INFO - __main__ - Step 260 Global step 260 Train loss 1.466514 on epoch=129
06/24/2022 13:22:23 - INFO - __main__ - Step 270 Global step 270 Train loss 1.823963 on epoch=134
06/24/2022 13:22:26 - INFO - __main__ - Step 280 Global step 280 Train loss 1.639396 on epoch=139
06/24/2022 13:22:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.869367 on epoch=144
06/24/2022 13:22:31 - INFO - __main__ - Step 300 Global step 300 Train loss 1.226807 on epoch=149
06/24/2022 13:22:31 - INFO - __main__ - Global step 300 Train loss 1.405209 ACC 0.5 on epoch=149
06/24/2022 13:22:33 - INFO - __main__ - Step 310 Global step 310 Train loss 1.444451 on epoch=154
06/24/2022 13:22:36 - INFO - __main__ - Step 320 Global step 320 Train loss 1.500834 on epoch=159
06/24/2022 13:22:38 - INFO - __main__ - Step 330 Global step 330 Train loss 1.104483 on epoch=164
06/24/2022 13:22:41 - INFO - __main__ - Step 340 Global step 340 Train loss 1.118659 on epoch=169
06/24/2022 13:22:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.874939 on epoch=174
06/24/2022 13:22:44 - INFO - __main__ - Global step 350 Train loss 1.208673 ACC 0.5 on epoch=174
06/24/2022 13:22:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.879857 on epoch=179
06/24/2022 13:22:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.810293 on epoch=184
06/24/2022 13:22:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.682563 on epoch=189
06/24/2022 13:22:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.925585 on epoch=194
06/24/2022 13:22:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.595928 on epoch=199
06/24/2022 13:22:56 - INFO - __main__ - Global step 400 Train loss 0.778845 ACC 0.5 on epoch=199
06/24/2022 13:22:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.731870 on epoch=204
06/24/2022 13:23:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.716127 on epoch=209
06/24/2022 13:23:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.641199 on epoch=214
06/24/2022 13:23:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.723332 on epoch=219
06/24/2022 13:23:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.734564 on epoch=224
06/24/2022 13:23:09 - INFO - __main__ - Global step 450 Train loss 0.709418 ACC 0.46875 on epoch=224
06/24/2022 13:23:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.811117 on epoch=229
06/24/2022 13:23:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.728975 on epoch=234
06/24/2022 13:23:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.632268 on epoch=239
06/24/2022 13:23:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.522981 on epoch=244
06/24/2022 13:23:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.573231 on epoch=249
06/24/2022 13:23:22 - INFO - __main__ - Global step 500 Train loss 0.653715 ACC 0.53125 on epoch=249
06/24/2022 13:23:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.586331 on epoch=254
06/24/2022 13:23:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.407296 on epoch=259
06/24/2022 13:23:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.605652 on epoch=264
06/24/2022 13:23:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.453097 on epoch=269
06/24/2022 13:23:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.645851 on epoch=274
06/24/2022 13:23:35 - INFO - __main__ - Global step 550 Train loss 0.539645 ACC 0.53125 on epoch=274
06/24/2022 13:23:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.423748 on epoch=279
06/24/2022 13:23:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.491587 on epoch=284
06/24/2022 13:23:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.477374 on epoch=289
06/24/2022 13:23:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.504891 on epoch=294
06/24/2022 13:23:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.497537 on epoch=299
06/24/2022 13:23:48 - INFO - __main__ - Global step 600 Train loss 0.479027 ACC 0.53125 on epoch=299
06/24/2022 13:23:48 - INFO - __main__ - save last model!
06/24/2022 13:23:49 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:23:49 - INFO - __main__ - Printing 3 examples
06/24/2022 13:23:49 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:23:49 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:49 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:23:49 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:49 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:23:49 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:23:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:23:49 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:23:49 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:23:49 - INFO - __main__ - Printing 3 examples
06/24/2022 13:23:49 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:23:49 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:49 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:23:49 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:49 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:23:49 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:49 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:23:49 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:23:49 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:23:51 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:23:51 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:23:51 - INFO - __main__ - Printing 3 examples
06/24/2022 13:23:51 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:23:51 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:51 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:23:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:23:51 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:23:51 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:23:51 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:23:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:23:52 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:23:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:23:53 - INFO - __main__ - Starting training!
06/24/2022 13:23:57 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_13_0.0001_8_predictions.txt
06/24/2022 13:23:57 - INFO - __main__ - ACC on test data: 0.5245
06/24/2022 13:23:57 - INFO - __main__ - prefix=glue-mrpc_16_13, lr=0.0001, bsz=8, dev_performance=0.53125, test_performance=0.5245098039215687
06/24/2022 13:23:57 - INFO - __main__ - Running ... prefix=glue-mrpc_16_21, lr=0.0005, bsz=8 ...
06/24/2022 13:23:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:23:58 - INFO - __main__ - Printing 3 examples
06/24/2022 13:23:58 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:23:58 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:58 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:23:58 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:58 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:23:58 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:23:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:23:58 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:23:58 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:23:58 - INFO - __main__ - Printing 3 examples
06/24/2022 13:23:58 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:23:58 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:58 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:23:58 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:58 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:23:58 - INFO - __main__ - ['equivalent']
06/24/2022 13:23:58 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:23:58 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:23:58 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:24:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:24:03 - INFO - __main__ - Starting training!
06/24/2022 13:24:05 - INFO - __main__ - Step 10 Global step 10 Train loss 16.269009 on epoch=4
06/24/2022 13:24:07 - INFO - __main__ - Step 20 Global step 20 Train loss 13.600550 on epoch=9
06/24/2022 13:24:10 - INFO - __main__ - Step 30 Global step 30 Train loss 7.213983 on epoch=14
06/24/2022 13:24:12 - INFO - __main__ - Step 40 Global step 40 Train loss 4.816021 on epoch=19
06/24/2022 13:24:14 - INFO - __main__ - Step 50 Global step 50 Train loss 2.624086 on epoch=24
06/24/2022 13:24:15 - INFO - __main__ - Global step 50 Train loss 8.904730 ACC 0.5 on epoch=24
06/24/2022 13:24:17 - INFO - __main__ - Step 60 Global step 60 Train loss 3.559724 on epoch=29
06/24/2022 13:24:20 - INFO - __main__ - Step 70 Global step 70 Train loss 1.646412 on epoch=34
06/24/2022 13:24:22 - INFO - __main__ - Step 80 Global step 80 Train loss 2.022491 on epoch=39
06/24/2022 13:24:25 - INFO - __main__ - Step 90 Global step 90 Train loss 1.683522 on epoch=44
06/24/2022 13:24:27 - INFO - __main__ - Step 100 Global step 100 Train loss 1.113569 on epoch=49
06/24/2022 13:24:28 - INFO - __main__ - Global step 100 Train loss 2.005144 ACC 0.46875 on epoch=49
06/24/2022 13:24:30 - INFO - __main__ - Step 110 Global step 110 Train loss 1.150459 on epoch=54
06/24/2022 13:24:33 - INFO - __main__ - Step 120 Global step 120 Train loss 1.277932 on epoch=59
06/24/2022 13:24:35 - INFO - __main__ - Step 130 Global step 130 Train loss 1.089730 on epoch=64
06/24/2022 13:24:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.756667 on epoch=69
06/24/2022 13:24:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.807453 on epoch=74
06/24/2022 13:24:41 - INFO - __main__ - Global step 150 Train loss 1.016448 ACC 0.625 on epoch=74
06/24/2022 13:24:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.611895 on epoch=79
06/24/2022 13:24:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.579008 on epoch=84
06/24/2022 13:24:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.503556 on epoch=89
06/24/2022 13:24:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.548112 on epoch=94
06/24/2022 13:24:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.700304 on epoch=99
06/24/2022 13:24:54 - INFO - __main__ - Global step 200 Train loss 0.588575 ACC 0.59375 on epoch=99
06/24/2022 13:24:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.385986 on epoch=104
06/24/2022 13:24:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.474990 on epoch=109
06/24/2022 13:25:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.448761 on epoch=114
06/24/2022 13:25:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.449645 on epoch=119
06/24/2022 13:25:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.340770 on epoch=124
06/24/2022 13:25:07 - INFO - __main__ - Global step 250 Train loss 0.420030 ACC 0.59375 on epoch=124
06/24/2022 13:25:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.260515 on epoch=129
06/24/2022 13:25:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.456586 on epoch=134
06/24/2022 13:25:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.359980 on epoch=139
06/24/2022 13:25:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.250250 on epoch=144
06/24/2022 13:25:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.241698 on epoch=149
06/24/2022 13:25:20 - INFO - __main__ - Global step 300 Train loss 0.313806 ACC 0.59375 on epoch=149
06/24/2022 13:25:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.189774 on epoch=154
06/24/2022 13:25:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.251005 on epoch=159
06/24/2022 13:25:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.246890 on epoch=164
06/24/2022 13:25:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.194808 on epoch=169
06/24/2022 13:25:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.169705 on epoch=174
06/24/2022 13:25:32 - INFO - __main__ - Global step 350 Train loss 0.210436 ACC 0.625 on epoch=174
06/24/2022 13:25:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.252082 on epoch=179
06/24/2022 13:25:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.226344 on epoch=184
06/24/2022 13:25:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.076267 on epoch=189
06/24/2022 13:25:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.143078 on epoch=194
06/24/2022 13:25:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.018444 on epoch=199
06/24/2022 13:25:45 - INFO - __main__ - Global step 400 Train loss 0.143243 ACC 0.65625 on epoch=199
06/24/2022 13:25:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.026261 on epoch=204
06/24/2022 13:25:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.033909 on epoch=209
06/24/2022 13:25:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.058827 on epoch=214
06/24/2022 13:25:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.017641 on epoch=219
06/24/2022 13:25:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.031388 on epoch=224
06/24/2022 13:25:58 - INFO - __main__ - Global step 450 Train loss 0.033605 ACC 0.59375 on epoch=224
06/24/2022 13:26:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.040782 on epoch=229
06/24/2022 13:26:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.013654 on epoch=234
06/24/2022 13:26:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.023157 on epoch=239
06/24/2022 13:26:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.009267 on epoch=244
06/24/2022 13:26:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.020085 on epoch=249
06/24/2022 13:26:11 - INFO - __main__ - Global step 500 Train loss 0.021389 ACC 0.65625 on epoch=249
06/24/2022 13:26:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.017609 on epoch=254
06/24/2022 13:26:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.016439 on epoch=259
06/24/2022 13:26:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.036158 on epoch=264
06/24/2022 13:26:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.009759 on epoch=269
06/24/2022 13:26:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.031095 on epoch=274
06/24/2022 13:26:24 - INFO - __main__ - Global step 550 Train loss 0.022212 ACC 0.65625 on epoch=274
06/24/2022 13:26:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.017492 on epoch=279
06/24/2022 13:26:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.006276 on epoch=284
06/24/2022 13:26:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000585 on epoch=289
06/24/2022 13:26:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.010125 on epoch=294
06/24/2022 13:26:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.016509 on epoch=299
06/24/2022 13:26:37 - INFO - __main__ - Global step 600 Train loss 0.010197 ACC 0.625 on epoch=299
06/24/2022 13:26:37 - INFO - __main__ - save last model!
06/24/2022 13:26:37 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:26:37 - INFO - __main__ - Printing 3 examples
06/24/2022 13:26:37 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:26:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:37 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:26:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:37 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:26:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:26:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:26:37 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:26:37 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:26:37 - INFO - __main__ - Printing 3 examples
06/24/2022 13:26:37 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:26:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:37 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:26:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:37 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:26:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:26:38 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:26:38 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:26:40 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:26:40 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:26:40 - INFO - __main__ - Printing 3 examples
06/24/2022 13:26:40 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:26:40 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:40 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:26:40 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:26:40 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:26:40 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:26:40 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:26:40 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:26:40 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:26:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:26:41 - INFO - __main__ - Starting training!
06/24/2022 13:26:45 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_21_0.0005_8_predictions.txt
06/24/2022 13:26:46 - INFO - __main__ - ACC on test data: 0.6078
06/24/2022 13:26:46 - INFO - __main__ - prefix=glue-mrpc_16_21, lr=0.0005, bsz=8, dev_performance=0.65625, test_performance=0.6078431372549019
06/24/2022 13:26:46 - INFO - __main__ - Running ... prefix=glue-mrpc_16_21, lr=0.0003, bsz=8 ...
06/24/2022 13:26:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:26:47 - INFO - __main__ - Printing 3 examples
06/24/2022 13:26:47 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:26:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:47 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:26:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:47 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:26:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:47 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:26:47 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:26:47 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:26:47 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:26:47 - INFO - __main__ - Printing 3 examples
06/24/2022 13:26:47 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:26:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:47 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:26:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:47 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:26:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:26:47 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:26:47 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:26:47 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:26:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:26:51 - INFO - __main__ - Starting training!
06/24/2022 13:26:53 - INFO - __main__ - Step 10 Global step 10 Train loss 16.417582 on epoch=4
06/24/2022 13:26:55 - INFO - __main__ - Step 20 Global step 20 Train loss 13.570015 on epoch=9
06/24/2022 13:26:57 - INFO - __main__ - Step 30 Global step 30 Train loss 7.751677 on epoch=14
06/24/2022 13:27:00 - INFO - __main__ - Step 40 Global step 40 Train loss 6.114939 on epoch=19
06/24/2022 13:27:02 - INFO - __main__ - Step 50 Global step 50 Train loss 4.725837 on epoch=24
06/24/2022 13:27:03 - INFO - __main__ - Global step 50 Train loss 9.716010 ACC 0.0 on epoch=24
06/24/2022 13:27:05 - INFO - __main__ - Step 60 Global step 60 Train loss 3.686312 on epoch=29
06/24/2022 13:27:08 - INFO - __main__ - Step 70 Global step 70 Train loss 2.275886 on epoch=34
06/24/2022 13:27:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.827136 on epoch=39
06/24/2022 13:27:13 - INFO - __main__ - Step 90 Global step 90 Train loss 1.451385 on epoch=44
06/24/2022 13:27:15 - INFO - __main__ - Step 100 Global step 100 Train loss 1.442074 on epoch=49
06/24/2022 13:27:16 - INFO - __main__ - Global step 100 Train loss 2.136559 ACC 0.5 on epoch=49
06/24/2022 13:27:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.899167 on epoch=54
06/24/2022 13:27:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.917892 on epoch=59
06/24/2022 13:27:24 - INFO - __main__ - Step 130 Global step 130 Train loss 1.058774 on epoch=64
06/24/2022 13:27:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.701531 on epoch=69
06/24/2022 13:27:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.858973 on epoch=74
06/24/2022 13:27:29 - INFO - __main__ - Global step 150 Train loss 0.887267 ACC 0.5 on epoch=74
06/24/2022 13:27:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.724260 on epoch=79
06/24/2022 13:27:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.586017 on epoch=84
06/24/2022 13:27:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.451157 on epoch=89
06/24/2022 13:27:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.462196 on epoch=94
06/24/2022 13:27:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.453334 on epoch=99
06/24/2022 13:27:42 - INFO - __main__ - Global step 200 Train loss 0.535393 ACC 0.59375 on epoch=99
06/24/2022 13:27:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.577752 on epoch=104
06/24/2022 13:27:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.506072 on epoch=109
06/24/2022 13:27:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.647708 on epoch=114
06/24/2022 13:27:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.322354 on epoch=119
06/24/2022 13:27:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.488308 on epoch=124
06/24/2022 13:27:55 - INFO - __main__ - Global step 250 Train loss 0.508439 ACC 0.5625 on epoch=124
06/24/2022 13:27:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.289471 on epoch=129
06/24/2022 13:28:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.446529 on epoch=134
06/24/2022 13:28:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.348857 on epoch=139
06/24/2022 13:28:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.357278 on epoch=144
06/24/2022 13:28:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.510135 on epoch=149
06/24/2022 13:28:08 - INFO - __main__ - Global step 300 Train loss 0.390454 ACC 0.5625 on epoch=149
06/24/2022 13:28:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.417855 on epoch=154
06/24/2022 13:28:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.332886 on epoch=159
06/24/2022 13:28:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.303565 on epoch=164
06/24/2022 13:28:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.336778 on epoch=169
06/24/2022 13:28:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.253135 on epoch=174
06/24/2022 13:28:21 - INFO - __main__ - Global step 350 Train loss 0.328844 ACC 0.625 on epoch=174
06/24/2022 13:28:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.282159 on epoch=179
06/24/2022 13:28:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.343439 on epoch=184
06/24/2022 13:28:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.223640 on epoch=189
06/24/2022 13:28:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.165915 on epoch=194
06/24/2022 13:28:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.140494 on epoch=199
06/24/2022 13:28:34 - INFO - __main__ - Global step 400 Train loss 0.231130 ACC 0.625 on epoch=199
06/24/2022 13:28:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.135343 on epoch=204
06/24/2022 13:28:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.121904 on epoch=209
06/24/2022 13:28:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.073627 on epoch=214
06/24/2022 13:28:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.072017 on epoch=219
06/24/2022 13:28:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.107587 on epoch=224
06/24/2022 13:28:47 - INFO - __main__ - Global step 450 Train loss 0.102096 ACC 0.625 on epoch=224
06/24/2022 13:28:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.111678 on epoch=229
06/24/2022 13:28:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.085141 on epoch=234
06/24/2022 13:28:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.076306 on epoch=239
06/24/2022 13:28:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.044439 on epoch=244
06/24/2022 13:28:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.055396 on epoch=249
06/24/2022 13:29:00 - INFO - __main__ - Global step 500 Train loss 0.074592 ACC 0.625 on epoch=249
06/24/2022 13:29:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.051034 on epoch=254
06/24/2022 13:29:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.012018 on epoch=259
06/24/2022 13:29:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.016443 on epoch=264
06/24/2022 13:29:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.066758 on epoch=269
06/24/2022 13:29:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.024591 on epoch=274
06/24/2022 13:29:12 - INFO - __main__ - Global step 550 Train loss 0.034169 ACC 0.59375 on epoch=274
06/24/2022 13:29:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.014401 on epoch=279
06/24/2022 13:29:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.042449 on epoch=284
06/24/2022 13:29:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.017467 on epoch=289
06/24/2022 13:29:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.029623 on epoch=294
06/24/2022 13:29:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.006864 on epoch=299
06/24/2022 13:29:25 - INFO - __main__ - Global step 600 Train loss 0.022161 ACC 0.625 on epoch=299
06/24/2022 13:29:25 - INFO - __main__ - save last model!
06/24/2022 13:29:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:29:26 - INFO - __main__ - Printing 3 examples
06/24/2022 13:29:26 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:29:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:26 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:29:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:26 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:29:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:29:26 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:29:26 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:29:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:29:26 - INFO - __main__ - Printing 3 examples
06/24/2022 13:29:26 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:29:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:26 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:29:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:26 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:29:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:29:26 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:29:26 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:29:28 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:29:28 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:29:28 - INFO - __main__ - Printing 3 examples
06/24/2022 13:29:28 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:29:28 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:28 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:29:28 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:29:28 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:29:28 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:29:28 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:29:28 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:29:29 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:29:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:29:30 - INFO - __main__ - Starting training!
06/24/2022 13:29:34 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_21_0.0003_8_predictions.txt
06/24/2022 13:29:34 - INFO - __main__ - ACC on test data: 0.6569
06/24/2022 13:29:34 - INFO - __main__ - prefix=glue-mrpc_16_21, lr=0.0003, bsz=8, dev_performance=0.625, test_performance=0.6568627450980392
06/24/2022 13:29:34 - INFO - __main__ - Running ... prefix=glue-mrpc_16_21, lr=0.0002, bsz=8 ...
06/24/2022 13:29:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:29:35 - INFO - __main__ - Printing 3 examples
06/24/2022 13:29:35 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:29:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:35 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:29:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:35 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:29:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:29:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:29:35 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:29:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:29:35 - INFO - __main__ - Printing 3 examples
06/24/2022 13:29:35 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:29:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:35 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:29:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:35 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:29:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:29:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:29:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:29:35 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:29:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:29:39 - INFO - __main__ - Starting training!
06/24/2022 13:29:41 - INFO - __main__ - Step 10 Global step 10 Train loss 15.946652 on epoch=4
06/24/2022 13:29:43 - INFO - __main__ - Step 20 Global step 20 Train loss 14.217108 on epoch=9
06/24/2022 13:29:45 - INFO - __main__ - Step 30 Global step 30 Train loss 10.312651 on epoch=14
06/24/2022 13:29:48 - INFO - __main__ - Step 40 Global step 40 Train loss 7.768369 on epoch=19
06/24/2022 13:29:51 - INFO - __main__ - Step 50 Global step 50 Train loss 6.367254 on epoch=24
06/24/2022 13:29:52 - INFO - __main__ - Global step 50 Train loss 10.922406 ACC 0.0 on epoch=24
06/24/2022 13:29:55 - INFO - __main__ - Step 60 Global step 60 Train loss 5.945690 on epoch=29
06/24/2022 13:29:57 - INFO - __main__ - Step 70 Global step 70 Train loss 5.340730 on epoch=34
06/24/2022 13:30:00 - INFO - __main__ - Step 80 Global step 80 Train loss 4.040781 on epoch=39
06/24/2022 13:30:02 - INFO - __main__ - Step 90 Global step 90 Train loss 3.610175 on epoch=44
06/24/2022 13:30:05 - INFO - __main__ - Step 100 Global step 100 Train loss 2.606601 on epoch=49
06/24/2022 13:30:05 - INFO - __main__ - Global step 100 Train loss 4.308795 ACC 0.46875 on epoch=49
06/24/2022 13:30:08 - INFO - __main__ - Step 110 Global step 110 Train loss 2.756520 on epoch=54
06/24/2022 13:30:11 - INFO - __main__ - Step 120 Global step 120 Train loss 1.681145 on epoch=59
06/24/2022 13:30:13 - INFO - __main__ - Step 130 Global step 130 Train loss 1.741554 on epoch=64
06/24/2022 13:30:16 - INFO - __main__ - Step 140 Global step 140 Train loss 2.332321 on epoch=69
06/24/2022 13:30:18 - INFO - __main__ - Step 150 Global step 150 Train loss 1.902946 on epoch=74
06/24/2022 13:30:19 - INFO - __main__ - Global step 150 Train loss 2.082897 ACC 0.5 on epoch=74
06/24/2022 13:30:21 - INFO - __main__ - Step 160 Global step 160 Train loss 2.287931 on epoch=79
06/24/2022 13:30:24 - INFO - __main__ - Step 170 Global step 170 Train loss 1.345162 on epoch=84
06/24/2022 13:30:27 - INFO - __main__ - Step 180 Global step 180 Train loss 1.040812 on epoch=89
06/24/2022 13:30:29 - INFO - __main__ - Step 190 Global step 190 Train loss 1.501074 on epoch=94
06/24/2022 13:30:32 - INFO - __main__ - Step 200 Global step 200 Train loss 1.108976 on epoch=99
06/24/2022 13:30:32 - INFO - __main__ - Global step 200 Train loss 1.456791 ACC 0.5 on epoch=99
06/24/2022 13:30:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.880691 on epoch=104
06/24/2022 13:30:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.770534 on epoch=109
06/24/2022 13:30:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.568568 on epoch=114
06/24/2022 13:30:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.926232 on epoch=119
06/24/2022 13:30:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.698112 on epoch=124
06/24/2022 13:30:45 - INFO - __main__ - Global step 250 Train loss 0.768827 ACC 0.5 on epoch=124
06/24/2022 13:30:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.600248 on epoch=129
06/24/2022 13:30:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.621124 on epoch=134
06/24/2022 13:30:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.415622 on epoch=139
06/24/2022 13:30:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.579641 on epoch=144
06/24/2022 13:30:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.633485 on epoch=149
06/24/2022 13:30:57 - INFO - __main__ - Global step 300 Train loss 0.570024 ACC 0.5 on epoch=149
06/24/2022 13:31:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.626800 on epoch=154
06/24/2022 13:31:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.510653 on epoch=159
06/24/2022 13:31:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.645536 on epoch=164
06/24/2022 13:31:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.547301 on epoch=169
06/24/2022 13:31:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.450714 on epoch=174
06/24/2022 13:31:10 - INFO - __main__ - Global step 350 Train loss 0.556201 ACC 0.625 on epoch=174
06/24/2022 13:31:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.515506 on epoch=179
06/24/2022 13:31:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.527322 on epoch=184
06/24/2022 13:31:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.351386 on epoch=189
06/24/2022 13:31:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.491950 on epoch=194
06/24/2022 13:31:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.373037 on epoch=199
06/24/2022 13:31:23 - INFO - __main__ - Global step 400 Train loss 0.451840 ACC 0.6875 on epoch=199
06/24/2022 13:31:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.306817 on epoch=204
06/24/2022 13:31:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.456990 on epoch=209
06/24/2022 13:31:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.494563 on epoch=214
06/24/2022 13:31:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.321185 on epoch=219
06/24/2022 13:31:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.330766 on epoch=224
06/24/2022 13:31:36 - INFO - __main__ - Global step 450 Train loss 0.382064 ACC 0.6875 on epoch=224
06/24/2022 13:31:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.354771 on epoch=229
06/24/2022 13:31:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.325210 on epoch=234
06/24/2022 13:31:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.370488 on epoch=239
06/24/2022 13:31:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.349464 on epoch=244
06/24/2022 13:31:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.457603 on epoch=249
06/24/2022 13:31:49 - INFO - __main__ - Global step 500 Train loss 0.371507 ACC 0.6875 on epoch=249
06/24/2022 13:31:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.241362 on epoch=254
06/24/2022 13:31:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.236380 on epoch=259
06/24/2022 13:31:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.268285 on epoch=264
06/24/2022 13:31:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.288117 on epoch=269
06/24/2022 13:32:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.289544 on epoch=274
06/24/2022 13:32:02 - INFO - __main__ - Global step 550 Train loss 0.264738 ACC 0.6875 on epoch=274
06/24/2022 13:32:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.387223 on epoch=279
06/24/2022 13:32:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.241139 on epoch=284
06/24/2022 13:32:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.201352 on epoch=289
06/24/2022 13:32:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.278025 on epoch=294
06/24/2022 13:32:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.208798 on epoch=299
06/24/2022 13:32:15 - INFO - __main__ - Global step 600 Train loss 0.263307 ACC 0.625 on epoch=299
06/24/2022 13:32:15 - INFO - __main__ - save last model!
06/24/2022 13:32:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:32:15 - INFO - __main__ - Printing 3 examples
06/24/2022 13:32:15 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:32:15 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:15 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:32:15 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:15 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:32:15 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:32:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:32:15 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:32:15 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:32:15 - INFO - __main__ - Printing 3 examples
06/24/2022 13:32:15 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:32:15 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:15 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:32:15 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:15 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:32:15 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:15 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:32:15 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:32:15 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:32:17 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:32:18 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:32:18 - INFO - __main__ - Printing 3 examples
06/24/2022 13:32:18 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:32:18 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:18 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:32:18 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:32:18 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:32:18 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:32:18 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:32:18 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:32:18 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:32:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:32:20 - INFO - __main__ - Starting training!
06/24/2022 13:32:23 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_21_0.0002_8_predictions.txt
06/24/2022 13:32:23 - INFO - __main__ - ACC on test data: 0.5441
06/24/2022 13:32:23 - INFO - __main__ - prefix=glue-mrpc_16_21, lr=0.0002, bsz=8, dev_performance=0.6875, test_performance=0.5441176470588235
06/24/2022 13:32:23 - INFO - __main__ - Running ... prefix=glue-mrpc_16_21, lr=0.0001, bsz=8 ...
06/24/2022 13:32:24 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:32:24 - INFO - __main__ - Printing 3 examples
06/24/2022 13:32:24 - INFO - __main__ -  [glue-mrpc] sentence 1: The national denomination of the Episcopal Church , with 2.3 million members , is the U.S. branch of the 77 million-member Anglican Communion . [SEP] sentence 2: The Episcopal Church , with 2.3 million members , is the American branch of the worldwide Anglican Communion , which has 77 million adherents .
06/24/2022 13:32:24 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:24 - INFO - __main__ -  [glue-mrpc] sentence 1: With all precincts reporting , Fletcher — a three-term congressman from Lexington — had an overwhelming 57 percent of the vote . [SEP] sentence 2: With all precincts reporting , Fletcher had 88,747 votes , or 57 percent of the total .
06/24/2022 13:32:24 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:24 - INFO - __main__ -  [glue-mrpc] sentence 1: Handset market share for the second quarter , it said , is higher than the first quarter . [SEP] sentence 2: Nokia 's market share for the second quarter is estimated to be higher than the first quarter , 2003 . "
06/24/2022 13:32:24 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:32:24 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:32:24 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:32:24 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:32:24 - INFO - __main__ - Printing 3 examples
06/24/2022 13:32:24 - INFO - __main__ -  [glue-mrpc] sentence 1: He planned Monday to formally announce the effort alongside several union presidents . [SEP] sentence 2: He plans to announce the effort formally tomorrow in Cincinnati alongside several union presidents .
06/24/2022 13:32:24 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:24 - INFO - __main__ -  [glue-mrpc] sentence 1: They named the man charged as Noureddinne Mouleff , a 36-year-old of North African origin who was arrested in the southern coastal town of Eastbourne last week . [SEP] sentence 2: Last week , Nur al-Din Muliff , a 36-year-old of North African origin , was arrested in the southern coastal town of Eastbourne .
06/24/2022 13:32:24 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:24 - INFO - __main__ -  [glue-mrpc] sentence 1: Most of that - $ 51 billion - was for American troops in Iraq , while another $ 10 billion was for U.S. forces in Afghanistan . [SEP] sentence 2: Most of that – $ US51 billion – was for American troops in Iraq , while another $ US10 billion was for US forces in Afghanistan .
06/24/2022 13:32:24 - INFO - __main__ - ['equivalent']
06/24/2022 13:32:24 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:32:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:32:25 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:32:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:32:29 - INFO - __main__ - Starting training!
06/24/2022 13:32:31 - INFO - __main__ - Step 10 Global step 10 Train loss 16.106421 on epoch=4
06/24/2022 13:32:33 - INFO - __main__ - Step 20 Global step 20 Train loss 14.239408 on epoch=9
06/24/2022 13:32:36 - INFO - __main__ - Step 30 Global step 30 Train loss 11.241466 on epoch=14
06/24/2022 13:32:38 - INFO - __main__ - Step 40 Global step 40 Train loss 9.309595 on epoch=19
06/24/2022 13:32:40 - INFO - __main__ - Step 50 Global step 50 Train loss 8.900849 on epoch=24
06/24/2022 13:32:43 - INFO - __main__ - Global step 50 Train loss 11.959547 ACC 0.0 on epoch=24
06/24/2022 13:32:46 - INFO - __main__ - Step 60 Global step 60 Train loss 7.647282 on epoch=29
06/24/2022 13:32:49 - INFO - __main__ - Step 70 Global step 70 Train loss 7.437879 on epoch=34
06/24/2022 13:32:51 - INFO - __main__ - Step 80 Global step 80 Train loss 6.066802 on epoch=39
06/24/2022 13:32:54 - INFO - __main__ - Step 90 Global step 90 Train loss 5.912650 on epoch=44
06/24/2022 13:32:56 - INFO - __main__ - Step 100 Global step 100 Train loss 5.698222 on epoch=49
06/24/2022 13:32:57 - INFO - __main__ - Global step 100 Train loss 6.552567 ACC 0.0 on epoch=49
06/24/2022 13:33:00 - INFO - __main__ - Step 110 Global step 110 Train loss 5.482762 on epoch=54
06/24/2022 13:33:02 - INFO - __main__ - Step 120 Global step 120 Train loss 4.707146 on epoch=59
06/24/2022 13:33:05 - INFO - __main__ - Step 130 Global step 130 Train loss 3.877069 on epoch=64
06/24/2022 13:33:07 - INFO - __main__ - Step 140 Global step 140 Train loss 4.357677 on epoch=69
06/24/2022 13:33:10 - INFO - __main__ - Step 150 Global step 150 Train loss 3.808189 on epoch=74
06/24/2022 13:33:10 - INFO - __main__ - Global step 150 Train loss 4.446569 ACC 0.03125 on epoch=74
06/24/2022 13:33:13 - INFO - __main__ - Step 160 Global step 160 Train loss 3.394341 on epoch=79
06/24/2022 13:33:16 - INFO - __main__ - Step 170 Global step 170 Train loss 3.816647 on epoch=84
06/24/2022 13:33:18 - INFO - __main__ - Step 180 Global step 180 Train loss 3.672714 on epoch=89
06/24/2022 13:33:21 - INFO - __main__ - Step 190 Global step 190 Train loss 2.907238 on epoch=94
06/24/2022 13:33:23 - INFO - __main__ - Step 200 Global step 200 Train loss 2.618507 on epoch=99
06/24/2022 13:33:24 - INFO - __main__ - Global step 200 Train loss 3.281889 ACC 0.5 on epoch=99
06/24/2022 13:33:27 - INFO - __main__ - Step 210 Global step 210 Train loss 2.410140 on epoch=104
06/24/2022 13:33:29 - INFO - __main__ - Step 220 Global step 220 Train loss 2.666181 on epoch=109
06/24/2022 13:33:32 - INFO - __main__ - Step 230 Global step 230 Train loss 2.136355 on epoch=114
06/24/2022 13:33:34 - INFO - __main__ - Step 240 Global step 240 Train loss 1.710012 on epoch=119
06/24/2022 13:33:37 - INFO - __main__ - Step 250 Global step 250 Train loss 2.042216 on epoch=124
06/24/2022 13:33:37 - INFO - __main__ - Global step 250 Train loss 2.192981 ACC 0.5 on epoch=124
06/24/2022 13:33:39 - INFO - __main__ - Step 260 Global step 260 Train loss 1.504922 on epoch=129
06/24/2022 13:33:42 - INFO - __main__ - Step 270 Global step 270 Train loss 2.203824 on epoch=134
06/24/2022 13:33:44 - INFO - __main__ - Step 280 Global step 280 Train loss 1.352420 on epoch=139
06/24/2022 13:33:47 - INFO - __main__ - Step 290 Global step 290 Train loss 1.682593 on epoch=144
06/24/2022 13:33:49 - INFO - __main__ - Step 300 Global step 300 Train loss 2.010936 on epoch=149
06/24/2022 13:33:50 - INFO - __main__ - Global step 300 Train loss 1.750939 ACC 0.5 on epoch=149
06/24/2022 13:33:52 - INFO - __main__ - Step 310 Global step 310 Train loss 1.744583 on epoch=154
06/24/2022 13:33:55 - INFO - __main__ - Step 320 Global step 320 Train loss 1.450496 on epoch=159
06/24/2022 13:33:57 - INFO - __main__ - Step 330 Global step 330 Train loss 1.061571 on epoch=164
06/24/2022 13:34:00 - INFO - __main__ - Step 340 Global step 340 Train loss 1.707029 on epoch=169
06/24/2022 13:34:02 - INFO - __main__ - Step 350 Global step 350 Train loss 1.627110 on epoch=174
06/24/2022 13:34:03 - INFO - __main__ - Global step 350 Train loss 1.518158 ACC 0.5 on epoch=174
06/24/2022 13:34:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.987504 on epoch=179
06/24/2022 13:34:08 - INFO - __main__ - Step 370 Global step 370 Train loss 1.203983 on epoch=184
06/24/2022 13:34:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.694109 on epoch=189
06/24/2022 13:34:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.879059 on epoch=194
06/24/2022 13:34:15 - INFO - __main__ - Step 400 Global step 400 Train loss 1.074278 on epoch=199
06/24/2022 13:34:16 - INFO - __main__ - Global step 400 Train loss 0.967786 ACC 0.625 on epoch=199
06/24/2022 13:34:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.631307 on epoch=204
06/24/2022 13:34:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.936733 on epoch=209
06/24/2022 13:34:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.873947 on epoch=214
06/24/2022 13:34:26 - INFO - __main__ - Step 440 Global step 440 Train loss 1.051990 on epoch=219
06/24/2022 13:34:29 - INFO - __main__ - Step 450 Global step 450 Train loss 1.144198 on epoch=224
06/24/2022 13:34:29 - INFO - __main__ - Global step 450 Train loss 0.927635 ACC 0.5 on epoch=224
06/24/2022 13:34:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.611449 on epoch=229
06/24/2022 13:34:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.844063 on epoch=234
06/24/2022 13:34:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.669733 on epoch=239
06/24/2022 13:34:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.699862 on epoch=244
06/24/2022 13:34:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.573456 on epoch=249
06/24/2022 13:34:42 - INFO - __main__ - Global step 500 Train loss 0.679713 ACC 0.65625 on epoch=249
06/24/2022 13:34:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.818210 on epoch=254
06/24/2022 13:34:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.652266 on epoch=259
06/24/2022 13:34:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.487865 on epoch=264
06/24/2022 13:34:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.532714 on epoch=269
06/24/2022 13:34:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.728492 on epoch=274
06/24/2022 13:34:55 - INFO - __main__ - Global step 550 Train loss 0.643910 ACC 0.53125 on epoch=274
06/24/2022 13:34:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.558461 on epoch=279
06/24/2022 13:35:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.501436 on epoch=284
06/24/2022 13:35:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.660338 on epoch=289
06/24/2022 13:35:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.629107 on epoch=294
06/24/2022 13:35:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.500841 on epoch=299
06/24/2022 13:35:08 - INFO - __main__ - Global step 600 Train loss 0.570037 ACC 0.53125 on epoch=299
06/24/2022 13:35:08 - INFO - __main__ - save last model!
06/24/2022 13:35:09 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:35:09 - INFO - __main__ - Printing 3 examples
06/24/2022 13:35:09 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:35:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:09 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:35:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:09 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:35:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:35:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:35:09 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:35:09 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:35:09 - INFO - __main__ - Printing 3 examples
06/24/2022 13:35:09 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:35:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:09 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:35:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:09 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:35:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:35:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:35:09 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:35:11 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:35:11 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:35:11 - INFO - __main__ - Printing 3 examples
06/24/2022 13:35:11 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:35:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:11 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:35:11 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:35:11 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:35:11 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:35:11 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:35:11 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:35:12 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:35:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:35:13 - INFO - __main__ - Starting training!
06/24/2022 13:35:18 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_21_0.0001_8_predictions.txt
06/24/2022 13:35:18 - INFO - __main__ - ACC on test data: 0.3750
06/24/2022 13:35:18 - INFO - __main__ - prefix=glue-mrpc_16_21, lr=0.0001, bsz=8, dev_performance=0.65625, test_performance=0.375
06/24/2022 13:35:18 - INFO - __main__ - Running ... prefix=glue-mrpc_16_42, lr=0.0005, bsz=8 ...
06/24/2022 13:35:19 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:35:19 - INFO - __main__ - Printing 3 examples
06/24/2022 13:35:19 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:35:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:19 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:35:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:19 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:35:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:35:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:35:19 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:35:19 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:35:19 - INFO - __main__ - Printing 3 examples
06/24/2022 13:35:19 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:35:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:19 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:35:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:19 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:35:19 - INFO - __main__ - ['equivalent']
06/24/2022 13:35:19 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:35:19 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:35:19 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:35:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:35:23 - INFO - __main__ - Starting training!
06/24/2022 13:35:25 - INFO - __main__ - Step 10 Global step 10 Train loss 16.234646 on epoch=4
06/24/2022 13:35:27 - INFO - __main__ - Step 20 Global step 20 Train loss 12.204785 on epoch=9
06/24/2022 13:35:29 - INFO - __main__ - Step 30 Global step 30 Train loss 8.561868 on epoch=14
06/24/2022 13:35:32 - INFO - __main__ - Step 40 Global step 40 Train loss 5.923984 on epoch=19
06/24/2022 13:35:34 - INFO - __main__ - Step 50 Global step 50 Train loss 4.564265 on epoch=24
06/24/2022 13:35:35 - INFO - __main__ - Global step 50 Train loss 9.497909 ACC 0.0625 on epoch=24
06/24/2022 13:35:37 - INFO - __main__ - Step 60 Global step 60 Train loss 3.316148 on epoch=29
06/24/2022 13:35:40 - INFO - __main__ - Step 70 Global step 70 Train loss 2.009087 on epoch=34
06/24/2022 13:35:42 - INFO - __main__ - Step 80 Global step 80 Train loss 1.695267 on epoch=39
06/24/2022 13:35:45 - INFO - __main__ - Step 90 Global step 90 Train loss 1.362106 on epoch=44
06/24/2022 13:35:47 - INFO - __main__ - Step 100 Global step 100 Train loss 1.525232 on epoch=49
06/24/2022 13:35:47 - INFO - __main__ - Global step 100 Train loss 1.981568 ACC 0.5 on epoch=49
06/24/2022 13:35:50 - INFO - __main__ - Step 110 Global step 110 Train loss 1.451583 on epoch=54
06/24/2022 13:35:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.931936 on epoch=59
06/24/2022 13:35:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.810828 on epoch=64
06/24/2022 13:35:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.585294 on epoch=69
06/24/2022 13:36:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.522471 on epoch=74
06/24/2022 13:36:00 - INFO - __main__ - Global step 150 Train loss 0.860422 ACC 0.5 on epoch=74
06/24/2022 13:36:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.631875 on epoch=79
06/24/2022 13:36:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.452117 on epoch=84
06/24/2022 13:36:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.548881 on epoch=89
06/24/2022 13:36:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.521384 on epoch=94
06/24/2022 13:36:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.459353 on epoch=99
06/24/2022 13:36:13 - INFO - __main__ - Global step 200 Train loss 0.522722 ACC 0.59375 on epoch=99
06/24/2022 13:36:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.471909 on epoch=104
06/24/2022 13:36:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.510411 on epoch=109
06/24/2022 13:36:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.568186 on epoch=114
06/24/2022 13:36:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.411903 on epoch=119
06/24/2022 13:36:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.423749 on epoch=124
06/24/2022 13:36:26 - INFO - __main__ - Global step 250 Train loss 0.477232 ACC 0.53125 on epoch=124
06/24/2022 13:36:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.402667 on epoch=129
06/24/2022 13:36:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.363932 on epoch=134
06/24/2022 13:36:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.473684 on epoch=139
06/24/2022 13:36:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.371763 on epoch=144
06/24/2022 13:36:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.472603 on epoch=149
06/24/2022 13:36:38 - INFO - __main__ - Global step 300 Train loss 0.416930 ACC 0.65625 on epoch=149
06/24/2022 13:36:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.260708 on epoch=154
06/24/2022 13:36:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.441304 on epoch=159
06/24/2022 13:36:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.360497 on epoch=164
06/24/2022 13:36:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.327656 on epoch=169
06/24/2022 13:36:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.247908 on epoch=174
06/24/2022 13:36:51 - INFO - __main__ - Global step 350 Train loss 0.327615 ACC 0.78125 on epoch=174
06/24/2022 13:36:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.218949 on epoch=179
06/24/2022 13:36:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.221599 on epoch=184
06/24/2022 13:36:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.233334 on epoch=189
06/24/2022 13:37:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.198285 on epoch=194
06/24/2022 13:37:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.102478 on epoch=199
06/24/2022 13:37:04 - INFO - __main__ - Global step 400 Train loss 0.194929 ACC 0.75 on epoch=199
06/24/2022 13:37:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.094985 on epoch=204
06/24/2022 13:37:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.068897 on epoch=209
06/24/2022 13:37:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.062553 on epoch=214
06/24/2022 13:37:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.055410 on epoch=219
06/24/2022 13:37:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.075229 on epoch=224
06/24/2022 13:37:16 - INFO - __main__ - Global step 450 Train loss 0.071415 ACC 0.6875 on epoch=224
06/24/2022 13:37:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.043315 on epoch=229
06/24/2022 13:37:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.098777 on epoch=234
06/24/2022 13:37:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.037874 on epoch=239
06/24/2022 13:37:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.056978 on epoch=244
06/24/2022 13:37:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.063091 on epoch=249
06/24/2022 13:37:28 - INFO - __main__ - Global step 500 Train loss 0.060007 ACC 0.5625 on epoch=249
06/24/2022 13:37:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.073302 on epoch=254
06/24/2022 13:37:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.141443 on epoch=259
06/24/2022 13:37:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.396551 on epoch=264
06/24/2022 13:37:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.185244 on epoch=269
06/24/2022 13:37:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.222947 on epoch=274
06/24/2022 13:37:41 - INFO - __main__ - Global step 550 Train loss 0.203897 ACC 0.71875 on epoch=274
06/24/2022 13:37:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.140913 on epoch=279
06/24/2022 13:37:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.140943 on epoch=284
06/24/2022 13:37:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.084142 on epoch=289
06/24/2022 13:37:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.068847 on epoch=294
06/24/2022 13:37:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.045450 on epoch=299
06/24/2022 13:37:53 - INFO - __main__ - Global step 600 Train loss 0.096059 ACC 0.6875 on epoch=299
06/24/2022 13:37:53 - INFO - __main__ - save last model!
06/24/2022 13:37:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:37:54 - INFO - __main__ - Printing 3 examples
06/24/2022 13:37:54 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:37:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:54 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:37:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:54 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:37:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:37:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:37:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:37:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:37:54 - INFO - __main__ - Printing 3 examples
06/24/2022 13:37:54 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:37:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:54 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:37:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:54 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:37:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:37:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:37:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:37:56 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:37:56 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:37:56 - INFO - __main__ - Printing 3 examples
06/24/2022 13:37:56 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:37:56 - INFO - __main__ - ['equivalent']
06/24/2022 13:37:56 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:37:56 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:37:56 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:37:56 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:37:56 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:37:56 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:37:57 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:37:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:37:58 - INFO - __main__ - Starting training!
06/24/2022 13:38:02 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_42_0.0005_8_predictions.txt
06/24/2022 13:38:02 - INFO - __main__ - ACC on test data: 0.6422
06/24/2022 13:38:02 - INFO - __main__ - prefix=glue-mrpc_16_42, lr=0.0005, bsz=8, dev_performance=0.78125, test_performance=0.6421568627450981
06/24/2022 13:38:02 - INFO - __main__ - Running ... prefix=glue-mrpc_16_42, lr=0.0003, bsz=8 ...
06/24/2022 13:38:03 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:38:03 - INFO - __main__ - Printing 3 examples
06/24/2022 13:38:03 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:38:03 - INFO - __main__ - ['equivalent']
06/24/2022 13:38:03 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:38:03 - INFO - __main__ - ['equivalent']
06/24/2022 13:38:03 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:38:03 - INFO - __main__ - ['equivalent']
06/24/2022 13:38:03 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:38:03 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:38:03 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:38:03 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:38:03 - INFO - __main__ - Printing 3 examples
06/24/2022 13:38:03 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:38:03 - INFO - __main__ - ['equivalent']
06/24/2022 13:38:03 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:38:03 - INFO - __main__ - ['equivalent']
06/24/2022 13:38:03 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:38:03 - INFO - __main__ - ['equivalent']
06/24/2022 13:38:03 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:38:03 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:38:03 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:38:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:38:07 - INFO - __main__ - Starting training!
06/24/2022 13:38:09 - INFO - __main__ - Step 10 Global step 10 Train loss 16.218563 on epoch=4
06/24/2022 13:38:11 - INFO - __main__ - Step 20 Global step 20 Train loss 13.267202 on epoch=9
06/24/2022 13:38:14 - INFO - __main__ - Step 30 Global step 30 Train loss 8.345491 on epoch=14
06/24/2022 13:38:16 - INFO - __main__ - Step 40 Global step 40 Train loss 6.409716 on epoch=19
06/24/2022 13:38:19 - INFO - __main__ - Step 50 Global step 50 Train loss 4.520921 on epoch=24
06/24/2022 13:38:19 - INFO - __main__ - Global step 50 Train loss 9.752378 ACC 0.28125 on epoch=24
06/24/2022 13:38:22 - INFO - __main__ - Step 60 Global step 60 Train loss 3.776409 on epoch=29
06/24/2022 13:38:24 - INFO - __main__ - Step 70 Global step 70 Train loss 2.509772 on epoch=34
06/24/2022 13:38:27 - INFO - __main__ - Step 80 Global step 80 Train loss 1.763500 on epoch=39
06/24/2022 13:38:29 - INFO - __main__ - Step 90 Global step 90 Train loss 2.116827 on epoch=44
06/24/2022 13:38:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.989752 on epoch=49
06/24/2022 13:38:32 - INFO - __main__ - Global step 100 Train loss 2.231252 ACC 0.46875 on epoch=49
06/24/2022 13:38:35 - INFO - __main__ - Step 110 Global step 110 Train loss 1.160567 on epoch=54
06/24/2022 13:38:38 - INFO - __main__ - Step 120 Global step 120 Train loss 1.139190 on epoch=59
06/24/2022 13:38:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.805499 on epoch=64
06/24/2022 13:38:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.728041 on epoch=69
06/24/2022 13:38:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.611842 on epoch=74
06/24/2022 13:38:46 - INFO - __main__ - Global step 150 Train loss 0.889028 ACC 0.5 on epoch=74
06/24/2022 13:38:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.479829 on epoch=79
06/24/2022 13:38:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.550220 on epoch=84
06/24/2022 13:38:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.609957 on epoch=89
06/24/2022 13:38:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.712518 on epoch=94
06/24/2022 13:38:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.541396 on epoch=99
06/24/2022 13:38:59 - INFO - __main__ - Global step 200 Train loss 0.578784 ACC 0.5 on epoch=99
06/24/2022 13:39:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.489155 on epoch=104
06/24/2022 13:39:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.754072 on epoch=109
06/24/2022 13:39:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.529747 on epoch=114
06/24/2022 13:39:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.464694 on epoch=119
06/24/2022 13:39:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.602012 on epoch=124
06/24/2022 13:39:12 - INFO - __main__ - Global step 250 Train loss 0.567936 ACC 0.6875 on epoch=124
06/24/2022 13:39:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.355923 on epoch=129
06/24/2022 13:39:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.465133 on epoch=134
06/24/2022 13:39:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.422556 on epoch=139
06/24/2022 13:39:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.303574 on epoch=144
06/24/2022 13:39:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.276864 on epoch=149
06/24/2022 13:39:25 - INFO - __main__ - Global step 300 Train loss 0.364810 ACC 0.6875 on epoch=149
06/24/2022 13:39:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.280093 on epoch=154
06/24/2022 13:39:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.460006 on epoch=159
06/24/2022 13:39:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.366592 on epoch=164
06/24/2022 13:39:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.214396 on epoch=169
06/24/2022 13:39:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.186181 on epoch=174
06/24/2022 13:39:38 - INFO - __main__ - Global step 350 Train loss 0.301453 ACC 0.78125 on epoch=174
06/24/2022 13:39:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.186970 on epoch=179
06/24/2022 13:39:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.125374 on epoch=184
06/24/2022 13:39:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.100010 on epoch=189
06/24/2022 13:39:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.078246 on epoch=194
06/24/2022 13:39:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.029988 on epoch=199
06/24/2022 13:39:52 - INFO - __main__ - Global step 400 Train loss 0.104118 ACC 0.59375 on epoch=199
06/24/2022 13:39:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.262017 on epoch=204
06/24/2022 13:39:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.187382 on epoch=209
06/24/2022 13:39:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.051036 on epoch=214
06/24/2022 13:40:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.073568 on epoch=219
06/24/2022 13:40:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.049137 on epoch=224
06/24/2022 13:40:05 - INFO - __main__ - Global step 450 Train loss 0.124628 ACC 0.75 on epoch=224
06/24/2022 13:40:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.126053 on epoch=229
06/24/2022 13:40:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.045949 on epoch=234
06/24/2022 13:40:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.031431 on epoch=239
06/24/2022 13:40:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.013905 on epoch=244
06/24/2022 13:40:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.035435 on epoch=249
06/24/2022 13:40:18 - INFO - __main__ - Global step 500 Train loss 0.050554 ACC 0.71875 on epoch=249
06/24/2022 13:40:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.032796 on epoch=254
06/24/2022 13:40:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.006448 on epoch=259
06/24/2022 13:40:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.045551 on epoch=264
06/24/2022 13:40:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.025470 on epoch=269
06/24/2022 13:40:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.035779 on epoch=274
06/24/2022 13:40:31 - INFO - __main__ - Global step 550 Train loss 0.029209 ACC 0.75 on epoch=274
06/24/2022 13:40:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.059188 on epoch=279
06/24/2022 13:40:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.012595 on epoch=284
06/24/2022 13:40:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.004981 on epoch=289
06/24/2022 13:40:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.008067 on epoch=294
06/24/2022 13:40:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.013451 on epoch=299
06/24/2022 13:40:44 - INFO - __main__ - Global step 600 Train loss 0.019657 ACC 0.75 on epoch=299
06/24/2022 13:40:44 - INFO - __main__ - save last model!
06/24/2022 13:40:44 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:40:44 - INFO - __main__ - Printing 3 examples
06/24/2022 13:40:44 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:40:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:44 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:40:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:44 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:40:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:40:44 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:40:45 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:40:45 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:40:45 - INFO - __main__ - Printing 3 examples
06/24/2022 13:40:45 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:40:45 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:45 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:40:45 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:45 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:40:45 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:45 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:40:45 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:40:45 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:40:46 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:40:47 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:40:47 - INFO - __main__ - Printing 3 examples
06/24/2022 13:40:47 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:40:47 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:47 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:40:47 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:40:47 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:40:47 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:40:47 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:40:47 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:40:47 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:40:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:40:48 - INFO - __main__ - Starting training!
06/24/2022 13:40:52 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_42_0.0003_8_predictions.txt
06/24/2022 13:40:52 - INFO - __main__ - ACC on test data: 0.6078
06/24/2022 13:40:53 - INFO - __main__ - prefix=glue-mrpc_16_42, lr=0.0003, bsz=8, dev_performance=0.78125, test_performance=0.6078431372549019
06/24/2022 13:40:53 - INFO - __main__ - Running ... prefix=glue-mrpc_16_42, lr=0.0002, bsz=8 ...
06/24/2022 13:40:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:40:54 - INFO - __main__ - Printing 3 examples
06/24/2022 13:40:54 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:40:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:54 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:40:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:54 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:40:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:40:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:40:54 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:40:54 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:40:54 - INFO - __main__ - Printing 3 examples
06/24/2022 13:40:54 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:40:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:54 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:40:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:54 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:40:54 - INFO - __main__ - ['equivalent']
06/24/2022 13:40:54 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:40:54 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:40:54 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:40:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:40:58 - INFO - __main__ - Starting training!
06/24/2022 13:41:00 - INFO - __main__ - Step 10 Global step 10 Train loss 16.042181 on epoch=4
06/24/2022 13:41:02 - INFO - __main__ - Step 20 Global step 20 Train loss 13.285515 on epoch=9
06/24/2022 13:41:04 - INFO - __main__ - Step 30 Global step 30 Train loss 10.708364 on epoch=14
06/24/2022 13:41:07 - INFO - __main__ - Step 40 Global step 40 Train loss 8.797954 on epoch=19
06/24/2022 13:41:09 - INFO - __main__ - Step 50 Global step 50 Train loss 6.728058 on epoch=24
06/24/2022 13:41:11 - INFO - __main__ - Global step 50 Train loss 11.112414 ACC 0.0 on epoch=24
06/24/2022 13:41:13 - INFO - __main__ - Step 60 Global step 60 Train loss 6.375790 on epoch=29
06/24/2022 13:41:16 - INFO - __main__ - Step 70 Global step 70 Train loss 5.311072 on epoch=34
06/24/2022 13:41:18 - INFO - __main__ - Step 80 Global step 80 Train loss 5.023088 on epoch=39
06/24/2022 13:41:21 - INFO - __main__ - Step 90 Global step 90 Train loss 4.306609 on epoch=44
06/24/2022 13:41:23 - INFO - __main__ - Step 100 Global step 100 Train loss 3.936186 on epoch=49
06/24/2022 13:41:24 - INFO - __main__ - Global step 100 Train loss 4.990549 ACC 0.15625 on epoch=49
06/24/2022 13:41:27 - INFO - __main__ - Step 110 Global step 110 Train loss 3.446099 on epoch=54
06/24/2022 13:41:29 - INFO - __main__ - Step 120 Global step 120 Train loss 3.120851 on epoch=59
06/24/2022 13:41:32 - INFO - __main__ - Step 130 Global step 130 Train loss 2.488034 on epoch=64
06/24/2022 13:41:34 - INFO - __main__ - Step 140 Global step 140 Train loss 2.063346 on epoch=69
06/24/2022 13:41:37 - INFO - __main__ - Step 150 Global step 150 Train loss 2.081718 on epoch=74
06/24/2022 13:41:37 - INFO - __main__ - Global step 150 Train loss 2.640010 ACC 0.5 on epoch=74
06/24/2022 13:41:40 - INFO - __main__ - Step 160 Global step 160 Train loss 1.298694 on epoch=79
06/24/2022 13:41:43 - INFO - __main__ - Step 170 Global step 170 Train loss 1.541119 on epoch=84
06/24/2022 13:41:45 - INFO - __main__ - Step 180 Global step 180 Train loss 1.343921 on epoch=89
06/24/2022 13:41:48 - INFO - __main__ - Step 190 Global step 190 Train loss 1.512270 on epoch=94
06/24/2022 13:41:50 - INFO - __main__ - Step 200 Global step 200 Train loss 1.306502 on epoch=99
06/24/2022 13:41:50 - INFO - __main__ - Global step 200 Train loss 1.400501 ACC 0.5 on epoch=99
06/24/2022 13:41:53 - INFO - __main__ - Step 210 Global step 210 Train loss 1.047872 on epoch=104
06/24/2022 13:41:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.868897 on epoch=109
06/24/2022 13:41:58 - INFO - __main__ - Step 230 Global step 230 Train loss 1.461754 on epoch=114
06/24/2022 13:42:00 - INFO - __main__ - Step 240 Global step 240 Train loss 1.012024 on epoch=119
06/24/2022 13:42:03 - INFO - __main__ - Step 250 Global step 250 Train loss 1.000284 on epoch=124
06/24/2022 13:42:03 - INFO - __main__ - Global step 250 Train loss 1.078166 ACC 0.5 on epoch=124
06/24/2022 13:42:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.787098 on epoch=129
06/24/2022 13:42:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.827283 on epoch=134
06/24/2022 13:42:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.742814 on epoch=139
06/24/2022 13:42:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.661855 on epoch=144
06/24/2022 13:42:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.578401 on epoch=149
06/24/2022 13:42:16 - INFO - __main__ - Global step 300 Train loss 0.719490 ACC 0.5 on epoch=149
06/24/2022 13:42:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.543317 on epoch=154
06/24/2022 13:42:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.661214 on epoch=159
06/24/2022 13:42:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.709982 on epoch=164
06/24/2022 13:42:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.571265 on epoch=169
06/24/2022 13:42:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.411617 on epoch=174
06/24/2022 13:42:30 - INFO - __main__ - Global step 350 Train loss 0.579479 ACC 0.65625 on epoch=174
06/24/2022 13:42:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.553015 on epoch=179
06/24/2022 13:42:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.424075 on epoch=184
06/24/2022 13:42:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.412140 on epoch=189
06/24/2022 13:42:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.468264 on epoch=194
06/24/2022 13:42:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.492457 on epoch=199
06/24/2022 13:42:43 - INFO - __main__ - Global step 400 Train loss 0.469990 ACC 0.5 on epoch=199
06/24/2022 13:42:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.510298 on epoch=204
06/24/2022 13:42:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.454581 on epoch=209
06/24/2022 13:42:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.478903 on epoch=214
06/24/2022 13:42:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.518880 on epoch=219
06/24/2022 13:42:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.528003 on epoch=224
06/24/2022 13:42:56 - INFO - __main__ - Global step 450 Train loss 0.498133 ACC 0.6875 on epoch=224
06/24/2022 13:42:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.365121 on epoch=229
06/24/2022 13:43:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.504984 on epoch=234
06/24/2022 13:43:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.412041 on epoch=239
06/24/2022 13:43:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.319648 on epoch=244
06/24/2022 13:43:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.428809 on epoch=249
06/24/2022 13:43:09 - INFO - __main__ - Global step 500 Train loss 0.406120 ACC 0.53125 on epoch=249
06/24/2022 13:43:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.551253 on epoch=254
06/24/2022 13:43:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.422643 on epoch=259
06/24/2022 13:43:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.295352 on epoch=264
06/24/2022 13:43:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.431387 on epoch=269
06/24/2022 13:43:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.355336 on epoch=274
06/24/2022 13:43:22 - INFO - __main__ - Global step 550 Train loss 0.411194 ACC 0.5 on epoch=274
06/24/2022 13:43:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.444188 on epoch=279
06/24/2022 13:43:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.337588 on epoch=284
06/24/2022 13:43:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.340361 on epoch=289
06/24/2022 13:43:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.320985 on epoch=294
06/24/2022 13:43:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.270162 on epoch=299
06/24/2022 13:43:34 - INFO - __main__ - Global step 600 Train loss 0.342657 ACC 0.5625 on epoch=299
06/24/2022 13:43:34 - INFO - __main__ - save last model!
06/24/2022 13:43:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:43:35 - INFO - __main__ - Printing 3 examples
06/24/2022 13:43:35 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:43:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:35 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:43:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:35 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:43:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:43:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:43:35 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:43:35 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:43:35 - INFO - __main__ - Printing 3 examples
06/24/2022 13:43:35 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:43:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:35 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:43:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:35 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:43:35 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:35 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:43:35 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:43:35 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:43:37 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:43:37 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:43:37 - INFO - __main__ - Printing 3 examples
06/24/2022 13:43:37 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:43:37 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:37 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:43:37 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:43:37 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:43:37 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:43:37 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:43:37 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:43:38 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:43:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:43:39 - INFO - __main__ - Starting training!
06/24/2022 13:43:43 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_42_0.0002_8_predictions.txt
06/24/2022 13:43:43 - INFO - __main__ - ACC on test data: 0.4975
06/24/2022 13:43:43 - INFO - __main__ - prefix=glue-mrpc_16_42, lr=0.0002, bsz=8, dev_performance=0.6875, test_performance=0.49754901960784315
06/24/2022 13:43:43 - INFO - __main__ - Running ... prefix=glue-mrpc_16_42, lr=0.0001, bsz=8 ...
06/24/2022 13:43:44 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:43:44 - INFO - __main__ - Printing 3 examples
06/24/2022 13:43:44 - INFO - __main__ -  [glue-mrpc] sentence 1: Tibco has used the Rendezvous name since 1994 for several of its technology products , according to the Palo Alto , California company . [SEP] sentence 2: Tibco has used the Rendezvous name since 1994 for several of its technology products , it said .
06/24/2022 13:43:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:44 - INFO - __main__ -  [glue-mrpc] sentence 1: Yesterday , Taiwan reported 35 new infections , bringing the total number of cases to 418 . [SEP] sentence 2: The island reported another 35 probable cases yesterday , taking its total to 418 .
06/24/2022 13:43:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:44 - INFO - __main__ -  [glue-mrpc] sentence 1: A month ago , the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter . [SEP] sentence 2: A month ago , the Commerce Department said GDP grew at a 7.2 percent rate .
06/24/2022 13:43:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:43:44 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:43:44 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:43:44 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:43:44 - INFO - __main__ - Printing 3 examples
06/24/2022 13:43:44 - INFO - __main__ -  [glue-mrpc] sentence 1: A draft statement , obtained by Reuters on Friday , stopped short of endorsing the U.S. charge but said some aspects of Iran 's programme raised " serious concern " . [SEP] sentence 2: The EU statement stopped short of endorsing the U.S. charge that Tehran is seeking nuclear weapons but said some aspects of Iran 's programme raised " serious concern " .
06/24/2022 13:43:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:44 - INFO - __main__ -  [glue-mrpc] sentence 1: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of the aircraft financing capability in this country , " Mr. Tellier said . [SEP] sentence 2: " Prospects for the whole Canadian aerospace industry are improving with recent developments contributing to the enhancement of aircraft financing in this country , " said Paul Tellier , Bombardier chief executive .
06/24/2022 13:43:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:44 - INFO - __main__ -  [glue-mrpc] sentence 1: All of those governments have said their support will not waver , though public sentiment is rising against it . [SEP] sentence 2: The governments of those countries have said that despite rising public opposition , their support will not waver .
06/24/2022 13:43:44 - INFO - __main__ - ['equivalent']
06/24/2022 13:43:44 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:43:44 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:43:44 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:43:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:43:49 - INFO - __main__ - Starting training!
06/24/2022 13:43:51 - INFO - __main__ - Step 10 Global step 10 Train loss 16.470011 on epoch=4
06/24/2022 13:43:53 - INFO - __main__ - Step 20 Global step 20 Train loss 15.533587 on epoch=9
06/24/2022 13:43:55 - INFO - __main__ - Step 30 Global step 30 Train loss 12.115275 on epoch=14
06/24/2022 13:43:58 - INFO - __main__ - Step 40 Global step 40 Train loss 9.297746 on epoch=19
06/24/2022 13:44:00 - INFO - __main__ - Step 50 Global step 50 Train loss 8.531717 on epoch=24
06/24/2022 13:44:03 - INFO - __main__ - Global step 50 Train loss 12.389666 ACC 0.0 on epoch=24
06/24/2022 13:44:06 - INFO - __main__ - Step 60 Global step 60 Train loss 7.428632 on epoch=29
06/24/2022 13:44:08 - INFO - __main__ - Step 70 Global step 70 Train loss 6.553570 on epoch=34
06/24/2022 13:44:10 - INFO - __main__ - Step 80 Global step 80 Train loss 5.788070 on epoch=39
06/24/2022 13:44:13 - INFO - __main__ - Step 90 Global step 90 Train loss 5.672934 on epoch=44
06/24/2022 13:44:15 - INFO - __main__ - Step 100 Global step 100 Train loss 5.020940 on epoch=49
06/24/2022 13:44:16 - INFO - __main__ - Global step 100 Train loss 6.092829 ACC 0.0 on epoch=49
06/24/2022 13:44:19 - INFO - __main__ - Step 110 Global step 110 Train loss 4.268747 on epoch=54
06/24/2022 13:44:21 - INFO - __main__ - Step 120 Global step 120 Train loss 4.493733 on epoch=59
06/24/2022 13:44:23 - INFO - __main__ - Step 130 Global step 130 Train loss 4.228281 on epoch=64
06/24/2022 13:44:26 - INFO - __main__ - Step 140 Global step 140 Train loss 4.400067 on epoch=69
06/24/2022 13:44:28 - INFO - __main__ - Step 150 Global step 150 Train loss 3.950871 on epoch=74
06/24/2022 13:44:29 - INFO - __main__ - Global step 150 Train loss 4.268340 ACC 0.03125 on epoch=74
06/24/2022 13:44:32 - INFO - __main__ - Step 160 Global step 160 Train loss 3.190266 on epoch=79
06/24/2022 13:44:34 - INFO - __main__ - Step 170 Global step 170 Train loss 2.838832 on epoch=84
06/24/2022 13:44:37 - INFO - __main__ - Step 180 Global step 180 Train loss 3.209516 on epoch=89
06/24/2022 13:44:39 - INFO - __main__ - Step 190 Global step 190 Train loss 2.564029 on epoch=94
06/24/2022 13:44:42 - INFO - __main__ - Step 200 Global step 200 Train loss 2.688386 on epoch=99
06/24/2022 13:44:42 - INFO - __main__ - Global step 200 Train loss 2.898206 ACC 0.5 on epoch=99
06/24/2022 13:44:45 - INFO - __main__ - Step 210 Global step 210 Train loss 2.404814 on epoch=104
06/24/2022 13:44:47 - INFO - __main__ - Step 220 Global step 220 Train loss 1.996541 on epoch=109
06/24/2022 13:44:50 - INFO - __main__ - Step 230 Global step 230 Train loss 1.840255 on epoch=114
06/24/2022 13:44:52 - INFO - __main__ - Step 240 Global step 240 Train loss 1.815708 on epoch=119
06/24/2022 13:44:55 - INFO - __main__ - Step 250 Global step 250 Train loss 1.217264 on epoch=124
06/24/2022 13:44:55 - INFO - __main__ - Global step 250 Train loss 1.854917 ACC 0.5 on epoch=124
06/24/2022 13:44:57 - INFO - __main__ - Step 260 Global step 260 Train loss 1.444480 on epoch=129
06/24/2022 13:45:00 - INFO - __main__ - Step 270 Global step 270 Train loss 1.734809 on epoch=134
06/24/2022 13:45:02 - INFO - __main__ - Step 280 Global step 280 Train loss 1.198184 on epoch=139
06/24/2022 13:45:05 - INFO - __main__ - Step 290 Global step 290 Train loss 1.321711 on epoch=144
06/24/2022 13:45:07 - INFO - __main__ - Step 300 Global step 300 Train loss 1.473882 on epoch=149
06/24/2022 13:45:08 - INFO - __main__ - Global step 300 Train loss 1.434613 ACC 0.5 on epoch=149
06/24/2022 13:45:10 - INFO - __main__ - Step 310 Global step 310 Train loss 1.814664 on epoch=154
06/24/2022 13:45:13 - INFO - __main__ - Step 320 Global step 320 Train loss 1.384532 on epoch=159
06/24/2022 13:45:15 - INFO - __main__ - Step 330 Global step 330 Train loss 1.479810 on epoch=164
06/24/2022 13:45:18 - INFO - __main__ - Step 340 Global step 340 Train loss 1.032611 on epoch=169
06/24/2022 13:45:20 - INFO - __main__ - Step 350 Global step 350 Train loss 1.288844 on epoch=174
06/24/2022 13:45:21 - INFO - __main__ - Global step 350 Train loss 1.400092 ACC 0.5 on epoch=174
06/24/2022 13:45:23 - INFO - __main__ - Step 360 Global step 360 Train loss 1.027698 on epoch=179
06/24/2022 13:45:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.896758 on epoch=184
06/24/2022 13:45:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.925735 on epoch=189
06/24/2022 13:45:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.987532 on epoch=194
06/24/2022 13:45:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.928158 on epoch=199
06/24/2022 13:45:33 - INFO - __main__ - Global step 400 Train loss 0.953176 ACC 0.5 on epoch=199
06/24/2022 13:45:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.621791 on epoch=204
06/24/2022 13:45:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.581636 on epoch=209
06/24/2022 13:45:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.604674 on epoch=214
06/24/2022 13:45:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.949407 on epoch=219
06/24/2022 13:45:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.717297 on epoch=224
06/24/2022 13:45:46 - INFO - __main__ - Global step 450 Train loss 0.694961 ACC 0.5 on epoch=224
06/24/2022 13:45:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.702748 on epoch=229
06/24/2022 13:45:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.537946 on epoch=234
06/24/2022 13:45:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.387157 on epoch=239
06/24/2022 13:45:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.714086 on epoch=244
06/24/2022 13:45:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.426995 on epoch=249
06/24/2022 13:45:59 - INFO - __main__ - Global step 500 Train loss 0.553786 ACC 0.5 on epoch=249
06/24/2022 13:46:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.700444 on epoch=254
06/24/2022 13:46:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.591306 on epoch=259
06/24/2022 13:46:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.547841 on epoch=264
06/24/2022 13:46:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.565975 on epoch=269
06/24/2022 13:46:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.607653 on epoch=274
06/24/2022 13:46:12 - INFO - __main__ - Global step 550 Train loss 0.602644 ACC 0.5 on epoch=274
06/24/2022 13:46:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.595469 on epoch=279
06/24/2022 13:46:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.579400 on epoch=284
06/24/2022 13:46:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.625218 on epoch=289
06/24/2022 13:46:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.634665 on epoch=294
06/24/2022 13:46:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.604689 on epoch=299
06/24/2022 13:46:25 - INFO - __main__ - Global step 600 Train loss 0.607888 ACC 0.5 on epoch=299
06/24/2022 13:46:25 - INFO - __main__ - save last model!
06/24/2022 13:46:25 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:46:25 - INFO - __main__ - Printing 3 examples
06/24/2022 13:46:25 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:46:25 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:25 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:46:25 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:25 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:46:25 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:25 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:46:25 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:46:26 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:46:26 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:46:26 - INFO - __main__ - Printing 3 examples
06/24/2022 13:46:26 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:46:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:26 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:46:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:26 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:46:26 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:26 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:46:26 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:46:26 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:46:28 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:46:28 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:46:28 - INFO - __main__ - Printing 3 examples
06/24/2022 13:46:28 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:46:28 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:28 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:46:28 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:46:28 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:46:28 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:46:28 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:46:28 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:46:28 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:46:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:46:29 - INFO - __main__ - Starting training!
06/24/2022 13:46:33 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_42_0.0001_8_predictions.txt
06/24/2022 13:46:33 - INFO - __main__ - ACC on test data: 0.6838
06/24/2022 13:46:33 - INFO - __main__ - prefix=glue-mrpc_16_42, lr=0.0001, bsz=8, dev_performance=0.5, test_performance=0.6838235294117647
06/24/2022 13:46:33 - INFO - __main__ - Running ... prefix=glue-mrpc_16_87, lr=0.0005, bsz=8 ...
06/24/2022 13:46:34 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:46:34 - INFO - __main__ - Printing 3 examples
06/24/2022 13:46:34 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:46:34 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:34 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:46:34 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:34 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:46:34 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:34 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:46:34 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:46:34 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:46:34 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:46:34 - INFO - __main__ - Printing 3 examples
06/24/2022 13:46:34 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:46:34 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:34 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:46:34 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:34 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:46:34 - INFO - __main__ - ['equivalent']
06/24/2022 13:46:34 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:46:34 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:46:34 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:46:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:46:38 - INFO - __main__ - Starting training!
06/24/2022 13:46:40 - INFO - __main__ - Step 10 Global step 10 Train loss 16.788933 on epoch=4
06/24/2022 13:46:42 - INFO - __main__ - Step 20 Global step 20 Train loss 10.971513 on epoch=9
06/24/2022 13:46:45 - INFO - __main__ - Step 30 Global step 30 Train loss 4.685573 on epoch=14
06/24/2022 13:46:47 - INFO - __main__ - Step 40 Global step 40 Train loss 3.618041 on epoch=19
06/24/2022 13:46:50 - INFO - __main__ - Step 50 Global step 50 Train loss 2.363402 on epoch=24
06/24/2022 13:46:50 - INFO - __main__ - Global step 50 Train loss 7.685493 ACC 0.5 on epoch=24
06/24/2022 13:46:53 - INFO - __main__ - Step 60 Global step 60 Train loss 1.357523 on epoch=29
06/24/2022 13:46:55 - INFO - __main__ - Step 70 Global step 70 Train loss 1.416727 on epoch=34
06/24/2022 13:46:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.641994 on epoch=39
06/24/2022 13:47:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.920386 on epoch=44
06/24/2022 13:47:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.601355 on epoch=49
06/24/2022 13:47:03 - INFO - __main__ - Global step 100 Train loss 0.987597 ACC 0.5 on epoch=49
06/24/2022 13:47:05 - INFO - __main__ - Step 110 Global step 110 Train loss 0.633341 on epoch=54
06/24/2022 13:47:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.452224 on epoch=59
06/24/2022 13:47:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.452887 on epoch=64
06/24/2022 13:47:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.385591 on epoch=69
06/24/2022 13:47:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.567432 on epoch=74
06/24/2022 13:47:16 - INFO - __main__ - Global step 150 Train loss 0.498295 ACC 0.5 on epoch=74
06/24/2022 13:47:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.409768 on epoch=79
06/24/2022 13:47:21 - INFO - __main__ - Step 170 Global step 170 Train loss 0.384104 on epoch=84
06/24/2022 13:47:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.479414 on epoch=89
06/24/2022 13:47:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.325372 on epoch=94
06/24/2022 13:47:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.379002 on epoch=99
06/24/2022 13:47:28 - INFO - __main__ - Global step 200 Train loss 0.395532 ACC 0.5 on epoch=99
06/24/2022 13:47:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.296413 on epoch=104
06/24/2022 13:47:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.246408 on epoch=109
06/24/2022 13:47:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.157363 on epoch=114
06/24/2022 13:47:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.128392 on epoch=119
06/24/2022 13:47:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.089064 on epoch=124
06/24/2022 13:47:41 - INFO - __main__ - Global step 250 Train loss 0.183528 ACC 0.5 on epoch=124
06/24/2022 13:47:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.037099 on epoch=129
06/24/2022 13:47:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.067976 on epoch=134
06/24/2022 13:47:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.050529 on epoch=139
06/24/2022 13:47:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.302912 on epoch=144
06/24/2022 13:47:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.064025 on epoch=149
06/24/2022 13:47:54 - INFO - __main__ - Global step 300 Train loss 0.104508 ACC 0.5 on epoch=149
06/24/2022 13:47:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.062853 on epoch=154
06/24/2022 13:47:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.006884 on epoch=159
06/24/2022 13:48:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.016017 on epoch=164
06/24/2022 13:48:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.012547 on epoch=169
06/24/2022 13:48:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.002648 on epoch=174
06/24/2022 13:48:06 - INFO - __main__ - Global step 350 Train loss 0.020190 ACC 0.53125 on epoch=174
06/24/2022 13:48:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.008996 on epoch=179
06/24/2022 13:48:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.001992 on epoch=184
06/24/2022 13:48:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.004001 on epoch=189
06/24/2022 13:48:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.002025 on epoch=194
06/24/2022 13:48:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.007890 on epoch=199
06/24/2022 13:48:19 - INFO - __main__ - Global step 400 Train loss 0.004981 ACC 0.5 on epoch=199
06/24/2022 13:48:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.011319 on epoch=204
06/24/2022 13:48:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.001299 on epoch=209
06/24/2022 13:48:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.011498 on epoch=214
06/24/2022 13:48:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.002584 on epoch=219
06/24/2022 13:48:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.003089 on epoch=224
06/24/2022 13:48:32 - INFO - __main__ - Global step 450 Train loss 0.005958 ACC 0.53125 on epoch=224
06/24/2022 13:48:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.001555 on epoch=229
06/24/2022 13:48:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000169 on epoch=234
06/24/2022 13:48:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000319 on epoch=239
06/24/2022 13:48:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.005014 on epoch=244
06/24/2022 13:48:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000542 on epoch=249
06/24/2022 13:48:45 - INFO - __main__ - Global step 500 Train loss 0.001520 ACC 0.5 on epoch=249
06/24/2022 13:48:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.001151 on epoch=254
06/24/2022 13:48:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000068 on epoch=259
06/24/2022 13:48:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.001954 on epoch=264
06/24/2022 13:48:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.041078 on epoch=269
06/24/2022 13:48:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.023383 on epoch=274
06/24/2022 13:48:57 - INFO - __main__ - Global step 550 Train loss 0.013527 ACC 0.5 on epoch=274
06/24/2022 13:49:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.005739 on epoch=279
06/24/2022 13:49:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000022 on epoch=284
06/24/2022 13:49:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000378 on epoch=289
06/24/2022 13:49:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000015 on epoch=294
06/24/2022 13:49:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000007 on epoch=299
06/24/2022 13:49:10 - INFO - __main__ - Global step 600 Train loss 0.001232 ACC 0.46875 on epoch=299
06/24/2022 13:49:10 - INFO - __main__ - save last model!
06/24/2022 13:49:11 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:49:11 - INFO - __main__ - Printing 3 examples
06/24/2022 13:49:11 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:49:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:11 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:49:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:11 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:49:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:11 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:49:11 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:49:11 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:49:11 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:49:11 - INFO - __main__ - Printing 3 examples
06/24/2022 13:49:11 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:49:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:11 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:49:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:11 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:49:11 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:11 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:49:11 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:49:11 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:49:13 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:49:13 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:49:13 - INFO - __main__ - Printing 3 examples
06/24/2022 13:49:13 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:49:13 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:13 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:49:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:49:13 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:49:13 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:49:13 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:49:13 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:49:14 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:49:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:49:15 - INFO - __main__ - Starting training!
06/24/2022 13:49:19 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_87_0.0005_8_predictions.txt
06/24/2022 13:49:19 - INFO - __main__ - ACC on test data: 0.6740
06/24/2022 13:49:19 - INFO - __main__ - prefix=glue-mrpc_16_87, lr=0.0005, bsz=8, dev_performance=0.53125, test_performance=0.6740196078431373
06/24/2022 13:49:19 - INFO - __main__ - Running ... prefix=glue-mrpc_16_87, lr=0.0003, bsz=8 ...
06/24/2022 13:49:20 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:49:20 - INFO - __main__ - Printing 3 examples
06/24/2022 13:49:20 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:49:20 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:20 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:49:20 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:20 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:49:20 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:20 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:49:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:49:20 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:49:20 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:49:20 - INFO - __main__ - Printing 3 examples
06/24/2022 13:49:20 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:49:20 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:20 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:49:20 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:20 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:49:20 - INFO - __main__ - ['equivalent']
06/24/2022 13:49:20 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:49:20 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:49:20 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:49:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:49:24 - INFO - __main__ - Starting training!
06/24/2022 13:49:26 - INFO - __main__ - Step 10 Global step 10 Train loss 16.583843 on epoch=4
06/24/2022 13:49:28 - INFO - __main__ - Step 20 Global step 20 Train loss 11.551314 on epoch=9
06/24/2022 13:49:31 - INFO - __main__ - Step 30 Global step 30 Train loss 7.308434 on epoch=14
06/24/2022 13:49:33 - INFO - __main__ - Step 40 Global step 40 Train loss 6.259741 on epoch=19
06/24/2022 13:49:35 - INFO - __main__ - Step 50 Global step 50 Train loss 4.565417 on epoch=24
06/24/2022 13:49:36 - INFO - __main__ - Global step 50 Train loss 9.253751 ACC 0.40625 on epoch=24
06/24/2022 13:49:39 - INFO - __main__ - Step 60 Global step 60 Train loss 3.801456 on epoch=29
06/24/2022 13:49:41 - INFO - __main__ - Step 70 Global step 70 Train loss 2.925162 on epoch=34
06/24/2022 13:49:44 - INFO - __main__ - Step 80 Global step 80 Train loss 2.533160 on epoch=39
06/24/2022 13:49:46 - INFO - __main__ - Step 90 Global step 90 Train loss 1.907071 on epoch=44
06/24/2022 13:49:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.222392 on epoch=49
06/24/2022 13:49:49 - INFO - __main__ - Global step 100 Train loss 2.477848 ACC 0.5 on epoch=49
06/24/2022 13:49:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.428416 on epoch=54
06/24/2022 13:49:54 - INFO - __main__ - Step 120 Global step 120 Train loss 1.133335 on epoch=59
06/24/2022 13:49:57 - INFO - __main__ - Step 130 Global step 130 Train loss 1.048619 on epoch=64
06/24/2022 13:49:59 - INFO - __main__ - Step 140 Global step 140 Train loss 1.308988 on epoch=69
06/24/2022 13:50:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.749155 on epoch=74
06/24/2022 13:50:02 - INFO - __main__ - Global step 150 Train loss 1.133703 ACC 0.53125 on epoch=74
06/24/2022 13:50:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.930697 on epoch=79
06/24/2022 13:50:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.685063 on epoch=84
06/24/2022 13:50:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.590712 on epoch=89
06/24/2022 13:50:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.678829 on epoch=94
06/24/2022 13:50:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.527621 on epoch=99
06/24/2022 13:50:15 - INFO - __main__ - Global step 200 Train loss 0.682584 ACC 0.5 on epoch=99
06/24/2022 13:50:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.633319 on epoch=104
06/24/2022 13:50:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.718696 on epoch=109
06/24/2022 13:50:23 - INFO - __main__ - Step 230 Global step 230 Train loss 0.643660 on epoch=114
06/24/2022 13:50:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.532655 on epoch=119
06/24/2022 13:50:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.398206 on epoch=124
06/24/2022 13:50:28 - INFO - __main__ - Global step 250 Train loss 0.585307 ACC 0.5 on epoch=124
06/24/2022 13:50:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.694563 on epoch=129
06/24/2022 13:50:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.539255 on epoch=134
06/24/2022 13:50:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.566693 on epoch=139
06/24/2022 13:50:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.402699 on epoch=144
06/24/2022 13:50:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.524057 on epoch=149
06/24/2022 13:50:41 - INFO - __main__ - Global step 300 Train loss 0.545453 ACC 0.5 on epoch=149
06/24/2022 13:50:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.420732 on epoch=154
06/24/2022 13:50:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.458053 on epoch=159
06/24/2022 13:50:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.599411 on epoch=164
06/24/2022 13:50:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.537420 on epoch=169
06/24/2022 13:50:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.507246 on epoch=174
06/24/2022 13:50:54 - INFO - __main__ - Global step 350 Train loss 0.504573 ACC 0.5 on epoch=174
06/24/2022 13:50:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.486022 on epoch=179
06/24/2022 13:50:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.437559 on epoch=184
06/24/2022 13:51:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.348343 on epoch=189
06/24/2022 13:51:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.504150 on epoch=194
06/24/2022 13:51:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.403470 on epoch=199
06/24/2022 13:51:06 - INFO - __main__ - Global step 400 Train loss 0.435909 ACC 0.46875 on epoch=199
06/24/2022 13:51:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.344915 on epoch=204
06/24/2022 13:51:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.378900 on epoch=209
06/24/2022 13:51:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.454338 on epoch=214
06/24/2022 13:51:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.343903 on epoch=219
06/24/2022 13:51:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.394040 on epoch=224
06/24/2022 13:51:20 - INFO - __main__ - Global step 450 Train loss 0.383219 ACC 0.3125 on epoch=224
06/24/2022 13:51:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.345498 on epoch=229
06/24/2022 13:51:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.288551 on epoch=234
06/24/2022 13:51:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.294403 on epoch=239
06/24/2022 13:51:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.327655 on epoch=244
06/24/2022 13:51:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.437288 on epoch=249
06/24/2022 13:51:33 - INFO - __main__ - Global step 500 Train loss 0.338679 ACC 0.46875 on epoch=249
06/24/2022 13:51:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.255264 on epoch=254
06/24/2022 13:51:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.291323 on epoch=259
06/24/2022 13:51:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.221288 on epoch=264
06/24/2022 13:51:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.281183 on epoch=269
06/24/2022 13:51:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.193965 on epoch=274
06/24/2022 13:51:46 - INFO - __main__ - Global step 550 Train loss 0.248605 ACC 0.53125 on epoch=274
06/24/2022 13:51:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.191368 on epoch=279
06/24/2022 13:51:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.243910 on epoch=284
06/24/2022 13:51:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.232146 on epoch=289
06/24/2022 13:51:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.283167 on epoch=294
06/24/2022 13:51:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.180435 on epoch=299
06/24/2022 13:51:59 - INFO - __main__ - Global step 600 Train loss 0.226205 ACC 0.5625 on epoch=299
06/24/2022 13:51:59 - INFO - __main__ - save last model!
06/24/2022 13:51:59 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:51:59 - INFO - __main__ - Printing 3 examples
06/24/2022 13:51:59 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:51:59 - INFO - __main__ - ['equivalent']
06/24/2022 13:51:59 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:51:59 - INFO - __main__ - ['equivalent']
06/24/2022 13:51:59 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:51:59 - INFO - __main__ - ['equivalent']
06/24/2022 13:51:59 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:52:00 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:52:00 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:52:00 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:52:00 - INFO - __main__ - Printing 3 examples
06/24/2022 13:52:00 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:52:00 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:00 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:52:00 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:00 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:52:00 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:00 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:52:00 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:52:00 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:52:02 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:52:02 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:52:02 - INFO - __main__ - Printing 3 examples
06/24/2022 13:52:02 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:52:02 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:02 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:52:02 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:52:02 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:52:02 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:52:02 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:52:02 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:52:03 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:52:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:52:03 - INFO - __main__ - Starting training!
06/24/2022 13:52:08 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_87_0.0003_8_predictions.txt
06/24/2022 13:52:08 - INFO - __main__ - ACC on test data: 0.6176
06/24/2022 13:52:08 - INFO - __main__ - prefix=glue-mrpc_16_87, lr=0.0003, bsz=8, dev_performance=0.5625, test_performance=0.6176470588235294
06/24/2022 13:52:08 - INFO - __main__ - Running ... prefix=glue-mrpc_16_87, lr=0.0002, bsz=8 ...
06/24/2022 13:52:09 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:52:09 - INFO - __main__ - Printing 3 examples
06/24/2022 13:52:09 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:52:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:09 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:52:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:09 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:52:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:52:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:52:09 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:52:09 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:52:09 - INFO - __main__ - Printing 3 examples
06/24/2022 13:52:09 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:52:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:09 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:52:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:09 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:52:09 - INFO - __main__ - ['equivalent']
06/24/2022 13:52:09 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:52:09 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:52:09 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:52:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:52:13 - INFO - __main__ - Starting training!
06/24/2022 13:52:15 - INFO - __main__ - Step 10 Global step 10 Train loss 16.825024 on epoch=4
06/24/2022 13:52:18 - INFO - __main__ - Step 20 Global step 20 Train loss 13.526380 on epoch=9
06/24/2022 13:52:20 - INFO - __main__ - Step 30 Global step 30 Train loss 9.423085 on epoch=14
06/24/2022 13:52:23 - INFO - __main__ - Step 40 Global step 40 Train loss 7.526269 on epoch=19
06/24/2022 13:52:25 - INFO - __main__ - Step 50 Global step 50 Train loss 6.877139 on epoch=24
06/24/2022 13:52:26 - INFO - __main__ - Global step 50 Train loss 10.835580 ACC 0.125 on epoch=24
06/24/2022 13:52:28 - INFO - __main__ - Step 60 Global step 60 Train loss 5.268384 on epoch=29
06/24/2022 13:52:31 - INFO - __main__ - Step 70 Global step 70 Train loss 4.507007 on epoch=34
06/24/2022 13:52:33 - INFO - __main__ - Step 80 Global step 80 Train loss 3.761143 on epoch=39
06/24/2022 13:52:36 - INFO - __main__ - Step 90 Global step 90 Train loss 3.786615 on epoch=44
06/24/2022 13:52:38 - INFO - __main__ - Step 100 Global step 100 Train loss 2.185703 on epoch=49
06/24/2022 13:52:39 - INFO - __main__ - Global step 100 Train loss 3.901770 ACC 0.5 on epoch=49
06/24/2022 13:52:42 - INFO - __main__ - Step 110 Global step 110 Train loss 1.796842 on epoch=54
06/24/2022 13:52:44 - INFO - __main__ - Step 120 Global step 120 Train loss 2.400627 on epoch=59
06/24/2022 13:52:47 - INFO - __main__ - Step 130 Global step 130 Train loss 2.089113 on epoch=64
06/24/2022 13:52:49 - INFO - __main__ - Step 140 Global step 140 Train loss 1.689797 on epoch=69
06/24/2022 13:52:52 - INFO - __main__ - Step 150 Global step 150 Train loss 1.722287 on epoch=74
06/24/2022 13:52:52 - INFO - __main__ - Global step 150 Train loss 1.939733 ACC 0.5 on epoch=74
06/24/2022 13:52:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.744206 on epoch=79
06/24/2022 13:52:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.802680 on epoch=84
06/24/2022 13:53:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.841509 on epoch=89
06/24/2022 13:53:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.948815 on epoch=94
06/24/2022 13:53:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.996529 on epoch=99
06/24/2022 13:53:05 - INFO - __main__ - Global step 200 Train loss 0.866748 ACC 0.5 on epoch=99
06/24/2022 13:53:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.729235 on epoch=104
06/24/2022 13:53:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.883541 on epoch=109
06/24/2022 13:53:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.629174 on epoch=114
06/24/2022 13:53:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.541667 on epoch=119
06/24/2022 13:53:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.638093 on epoch=124
06/24/2022 13:53:18 - INFO - __main__ - Global step 250 Train loss 0.684342 ACC 0.5 on epoch=124
06/24/2022 13:53:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.548028 on epoch=129
06/24/2022 13:53:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.433263 on epoch=134
06/24/2022 13:53:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.605507 on epoch=139
06/24/2022 13:53:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.527501 on epoch=144
06/24/2022 13:53:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.491330 on epoch=149
06/24/2022 13:53:30 - INFO - __main__ - Global step 300 Train loss 0.521126 ACC 0.5 on epoch=149
06/24/2022 13:53:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.490766 on epoch=154
06/24/2022 13:53:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.476901 on epoch=159
06/24/2022 13:53:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.614568 on epoch=164
06/24/2022 13:53:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.433843 on epoch=169
06/24/2022 13:53:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.373619 on epoch=174
06/24/2022 13:53:43 - INFO - __main__ - Global step 350 Train loss 0.477939 ACC 0.5 on epoch=174
06/24/2022 13:53:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.401802 on epoch=179
06/24/2022 13:53:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.472204 on epoch=184
06/24/2022 13:53:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.406805 on epoch=189
06/24/2022 13:53:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.312730 on epoch=194
06/24/2022 13:53:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.378085 on epoch=199
06/24/2022 13:53:56 - INFO - __main__ - Global step 400 Train loss 0.394325 ACC 0.5 on epoch=199
06/24/2022 13:53:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.428581 on epoch=204
06/24/2022 13:54:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.310060 on epoch=209
06/24/2022 13:54:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.366985 on epoch=214
06/24/2022 13:54:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.429540 on epoch=219
06/24/2022 13:54:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.451687 on epoch=224
06/24/2022 13:54:09 - INFO - __main__ - Global step 450 Train loss 0.397371 ACC 0.4375 on epoch=224
06/24/2022 13:54:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.322895 on epoch=229
06/24/2022 13:54:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.430716 on epoch=234
06/24/2022 13:54:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.633810 on epoch=239
06/24/2022 13:54:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.351768 on epoch=244
06/24/2022 13:54:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.271250 on epoch=249
06/24/2022 13:54:22 - INFO - __main__ - Global step 500 Train loss 0.402088 ACC 0.40625 on epoch=249
06/24/2022 13:54:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.360285 on epoch=254
06/24/2022 13:54:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.300599 on epoch=259
06/24/2022 13:54:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.403202 on epoch=264
06/24/2022 13:54:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.267326 on epoch=269
06/24/2022 13:54:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.233891 on epoch=274
06/24/2022 13:54:35 - INFO - __main__ - Global step 550 Train loss 0.313061 ACC 0.46875 on epoch=274
06/24/2022 13:54:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.207040 on epoch=279
06/24/2022 13:54:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.298870 on epoch=284
06/24/2022 13:54:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.235629 on epoch=289
06/24/2022 13:54:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.212784 on epoch=294
06/24/2022 13:54:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.190526 on epoch=299
06/24/2022 13:54:47 - INFO - __main__ - Global step 600 Train loss 0.228970 ACC 0.46875 on epoch=299
06/24/2022 13:54:47 - INFO - __main__ - save last model!
06/24/2022 13:54:48 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:54:48 - INFO - __main__ - Printing 3 examples
06/24/2022 13:54:48 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:54:48 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:48 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:54:48 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:48 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:54:48 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:48 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:54:48 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:54:48 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:54:48 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:54:48 - INFO - __main__ - Printing 3 examples
06/24/2022 13:54:48 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:54:48 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:48 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:54:48 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:48 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:54:48 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:48 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:54:48 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:54:48 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:54:50 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:54:50 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:54:50 - INFO - __main__ - Printing 3 examples
06/24/2022 13:54:50 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:54:50 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:50 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:54:50 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:54:50 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:54:50 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:54:50 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:54:51 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:54:51 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:54:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:54:52 - INFO - __main__ - Starting training!
06/24/2022 13:54:55 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_87_0.0002_8_predictions.txt
06/24/2022 13:54:55 - INFO - __main__ - ACC on test data: 0.6838
06/24/2022 13:54:55 - INFO - __main__ - prefix=glue-mrpc_16_87, lr=0.0002, bsz=8, dev_performance=0.5, test_performance=0.6838235294117647
06/24/2022 13:54:55 - INFO - __main__ - Running ... prefix=glue-mrpc_16_87, lr=0.0001, bsz=8 ...
06/24/2022 13:54:56 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:54:56 - INFO - __main__ - Printing 3 examples
06/24/2022 13:54:56 - INFO - __main__ -  [glue-mrpc] sentence 1: His dissent was joined by Chief Justice William H. Rehnquist and Justice Clarence Thomas . [SEP] sentence 2: Chief Justice William H. Rehnquist and Justices Antonin Scalia and Clarence Thomas dissented .
06/24/2022 13:54:56 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:56 - INFO - __main__ -  [glue-mrpc] sentence 1: The 20 master computers are located in the United States , Canada and Korea , Mr. Kuo said . [SEP] sentence 2: The computers were located in the United States , Canada and South Korea , he said .
06/24/2022 13:54:56 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:56 - INFO - __main__ -  [glue-mrpc] sentence 1: He said there were complex reasons for the increased numbers of cases and scientists were only just beginning to understand the risk factors . [SEP] sentence 2: However , he said , The reasons behind the increase in incidence are more complex and were just beginning to understand the risk factors .
06/24/2022 13:54:56 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:56 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:54:56 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:54:57 - INFO - __main__ - Loaded 32 examples from train data
06/24/2022 13:54:57 - INFO - __main__ - Start tokenizing ... 32 instances
06/24/2022 13:54:57 - INFO - __main__ - Printing 3 examples
06/24/2022 13:54:57 - INFO - __main__ -  [glue-mrpc] sentence 1: Treasury prices rose slightly , sending the 10-year note yield down to 4.38 percent from 4.39 percent late Friday . [SEP] sentence 2: Treasury prices gained for the third day in a row , pushing the 10-year note yield down to 4.35 percent from 4.36 percent late Monday .
06/24/2022 13:54:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:57 - INFO - __main__ -  [glue-mrpc] sentence 1: That means that if the planet is in a season , it will continue to brighten for the next 20 years . [SEP] sentence 2: If what scientists are observing is truly seasonal change , the planet will continue to brighten for another 20 years .
06/24/2022 13:54:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:57 - INFO - __main__ -  [glue-mrpc] sentence 1: Meanwhile , rival contender , General Electric 's NBC , submitted a letter of interest , a source familiar with the matter said . [SEP] sentence 2: Other contenders included General Electric 's GE.N NBC , which submitted a letter of interest , a source familiar with the matter said .
06/24/2022 13:54:57 - INFO - __main__ - ['equivalent']
06/24/2022 13:54:57 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:54:57 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:54:57 - INFO - __main__ - Loaded 32 examples from dev data
06/24/2022 13:55:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.11M parameters
06/24/2022 13:55:01 - INFO - __main__ - Starting training!
06/24/2022 13:55:03 - INFO - __main__ - Step 10 Global step 10 Train loss 16.747484 on epoch=4
06/24/2022 13:55:05 - INFO - __main__ - Step 20 Global step 20 Train loss 15.652324 on epoch=9
06/24/2022 13:55:08 - INFO - __main__ - Step 30 Global step 30 Train loss 12.530157 on epoch=14
06/24/2022 13:55:10 - INFO - __main__ - Step 40 Global step 40 Train loss 9.831985 on epoch=19
06/24/2022 13:55:13 - INFO - __main__ - Step 50 Global step 50 Train loss 8.264404 on epoch=24
06/24/2022 13:55:15 - INFO - __main__ - Global step 50 Train loss 12.605271 ACC 0.0 on epoch=24
06/24/2022 13:55:18 - INFO - __main__ - Step 60 Global step 60 Train loss 8.082253 on epoch=29
06/24/2022 13:55:20 - INFO - __main__ - Step 70 Global step 70 Train loss 6.776243 on epoch=34
06/24/2022 13:55:23 - INFO - __main__ - Step 80 Global step 80 Train loss 6.886922 on epoch=39
06/24/2022 13:55:25 - INFO - __main__ - Step 90 Global step 90 Train loss 6.061449 on epoch=44
06/24/2022 13:55:28 - INFO - __main__ - Step 100 Global step 100 Train loss 5.904142 on epoch=49
06/24/2022 13:55:29 - INFO - __main__ - Global step 100 Train loss 6.742202 ACC 0.1875 on epoch=49
06/24/2022 13:55:32 - INFO - __main__ - Step 110 Global step 110 Train loss 5.100109 on epoch=54
06/24/2022 13:55:34 - INFO - __main__ - Step 120 Global step 120 Train loss 4.990197 on epoch=59
06/24/2022 13:55:37 - INFO - __main__ - Step 130 Global step 130 Train loss 4.885708 on epoch=64
06/24/2022 13:55:39 - INFO - __main__ - Step 140 Global step 140 Train loss 4.700754 on epoch=69
06/24/2022 13:55:42 - INFO - __main__ - Step 150 Global step 150 Train loss 4.251595 on epoch=74
06/24/2022 13:55:42 - INFO - __main__ - Global step 150 Train loss 4.785672 ACC 0.03125 on epoch=74
06/24/2022 13:55:45 - INFO - __main__ - Step 160 Global step 160 Train loss 4.053708 on epoch=79
06/24/2022 13:55:47 - INFO - __main__ - Step 170 Global step 170 Train loss 3.625203 on epoch=84
06/24/2022 13:55:50 - INFO - __main__ - Step 180 Global step 180 Train loss 2.895851 on epoch=89
06/24/2022 13:55:52 - INFO - __main__ - Step 190 Global step 190 Train loss 2.719900 on epoch=94
06/24/2022 13:55:55 - INFO - __main__ - Step 200 Global step 200 Train loss 2.949079 on epoch=99
06/24/2022 13:55:55 - INFO - __main__ - Global step 200 Train loss 3.248748 ACC 0.46875 on epoch=99
06/24/2022 13:55:58 - INFO - __main__ - Step 210 Global step 210 Train loss 2.146370 on epoch=104
06/24/2022 13:56:01 - INFO - __main__ - Step 220 Global step 220 Train loss 2.146764 on epoch=109
06/24/2022 13:56:03 - INFO - __main__ - Step 230 Global step 230 Train loss 2.401010 on epoch=114
06/24/2022 13:56:05 - INFO - __main__ - Step 240 Global step 240 Train loss 1.919098 on epoch=119
06/24/2022 13:56:08 - INFO - __main__ - Step 250 Global step 250 Train loss 2.035860 on epoch=124
06/24/2022 13:56:08 - INFO - __main__ - Global step 250 Train loss 2.129821 ACC 0.5 on epoch=124
06/24/2022 13:56:11 - INFO - __main__ - Step 260 Global step 260 Train loss 1.558028 on epoch=129
06/24/2022 13:56:14 - INFO - __main__ - Step 270 Global step 270 Train loss 1.434635 on epoch=134
06/24/2022 13:56:16 - INFO - __main__ - Step 280 Global step 280 Train loss 1.514666 on epoch=139
06/24/2022 13:56:19 - INFO - __main__ - Step 290 Global step 290 Train loss 1.760831 on epoch=144
06/24/2022 13:56:21 - INFO - __main__ - Step 300 Global step 300 Train loss 1.604246 on epoch=149
06/24/2022 13:56:22 - INFO - __main__ - Global step 300 Train loss 1.574481 ACC 0.5 on epoch=149
06/24/2022 13:56:24 - INFO - __main__ - Step 310 Global step 310 Train loss 1.392370 on epoch=154
06/24/2022 13:56:26 - INFO - __main__ - Step 320 Global step 320 Train loss 1.422456 on epoch=159
06/24/2022 13:56:29 - INFO - __main__ - Step 330 Global step 330 Train loss 1.162135 on epoch=164
06/24/2022 13:56:31 - INFO - __main__ - Step 340 Global step 340 Train loss 1.377022 on epoch=169
06/24/2022 13:56:34 - INFO - __main__ - Step 350 Global step 350 Train loss 1.188496 on epoch=174
06/24/2022 13:56:34 - INFO - __main__ - Global step 350 Train loss 1.308496 ACC 0.5 on epoch=174
06/24/2022 13:56:37 - INFO - __main__ - Step 360 Global step 360 Train loss 1.255075 on epoch=179
06/24/2022 13:56:39 - INFO - __main__ - Step 370 Global step 370 Train loss 1.110776 on epoch=184
06/24/2022 13:56:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.899142 on epoch=189
06/24/2022 13:56:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.878883 on epoch=194
06/24/2022 13:56:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.810127 on epoch=199
06/24/2022 13:56:47 - INFO - __main__ - Global step 400 Train loss 0.990801 ACC 0.46875 on epoch=199
06/24/2022 13:56:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.878022 on epoch=204
06/24/2022 13:56:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.970891 on epoch=209
06/24/2022 13:56:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.764877 on epoch=214
06/24/2022 13:56:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.653750 on epoch=219
06/24/2022 13:56:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.682091 on epoch=224
06/24/2022 13:57:00 - INFO - __main__ - Global step 450 Train loss 0.789926 ACC 0.5 on epoch=224
06/24/2022 13:57:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.659567 on epoch=229
06/24/2022 13:57:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.555607 on epoch=234
06/24/2022 13:57:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.683476 on epoch=239
06/24/2022 13:57:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.672007 on epoch=244
06/24/2022 13:57:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.665155 on epoch=249
06/24/2022 13:57:13 - INFO - __main__ - Global step 500 Train loss 0.647163 ACC 0.5 on epoch=249
06/24/2022 13:57:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.432146 on epoch=254
06/24/2022 13:57:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.759478 on epoch=259
06/24/2022 13:57:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.749544 on epoch=264
06/24/2022 13:57:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.678233 on epoch=269
06/24/2022 13:57:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.638410 on epoch=274
06/24/2022 13:57:25 - INFO - __main__ - Global step 550 Train loss 0.651562 ACC 0.5 on epoch=274
06/24/2022 13:57:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.687389 on epoch=279
06/24/2022 13:57:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.502532 on epoch=284
06/24/2022 13:57:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.574616 on epoch=289
06/24/2022 13:57:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.366707 on epoch=294
06/24/2022 13:57:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.561205 on epoch=299
06/24/2022 13:57:38 - INFO - __main__ - Global step 600 Train loss 0.538490 ACC 0.5 on epoch=299
06/24/2022 13:57:38 - INFO - __main__ - save last model!
06/24/2022 13:57:41 - INFO - __main__ - Loading checkpoint on the fly
06/24/2022 13:57:41 - INFO - __main__ - Start tokenizing ... 408 instances
06/24/2022 13:57:41 - INFO - __main__ - Printing 3 examples
06/24/2022 13:57:41 - INFO - __main__ -  [glue-mrpc] sentence 1: He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . [SEP] sentence 2: " The foodservice pie business does not fit our long-term growth strategy .
06/24/2022 13:57:41 - INFO - __main__ - ['equivalent']
06/24/2022 13:57:41 - INFO - __main__ -  [glue-mrpc] sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . [SEP] sentence 2: His wife said he was " 100 percent behind George Bush " and looked forward to using his years of training in the war .
06/24/2022 13:57:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:57:41 - INFO - __main__ -  [glue-mrpc] sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat . [SEP] sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .
06/24/2022 13:57:41 - INFO - __main__ - ['not_equivalent']
06/24/2022 13:57:41 - INFO - __main__ - Tokenizing Input ...
06/24/2022 13:57:41 - INFO - __main__ - Tokenizing Output ...
06/24/2022 13:57:42 - INFO - __main__ - Loaded 408 examples from test data
06/24/2022 13:57:46 - INFO - __main__ - Saved prediction in models/T5-base-ft-nopara2para/singletask-glue-mrpc/glue-mrpc_16_87_0.0001_8_predictions.txt
06/24/2022 13:57:46 - INFO - __main__ - ACC on test data: 0.6838
06/24/2022 13:57:46 - INFO - __main__ - prefix=glue-mrpc_16_87, lr=0.0001, bsz=8, dev_performance=0.5, test_performance=0.6838235294117647
